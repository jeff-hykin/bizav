[32m[I 2022-11-13 13:53:52,633][0m A new study created in RDB with name: halfcheetah_sync__no_malicious_2[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 0.07, 
        "beta": 7.000000000000001e-05, 
        "t_max": 10, 
        "activation": 2, 
        "hidden_size": 16, 
        "variance_scaling_factor": 0.01, 
        "permaban_threshold": 2000, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 760144655, 
    "outdir": "results", 
    "t_max": 10, 
    "beta": 7.000000000000001e-05, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 0.07, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 2000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 16, 
    "activation": 2, 
}

{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -93195947143875.72, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Hit early stopping because per_episode_reward: -93195947143875.72 < -700
exited at when_all_processes_are_updated(): 8
None
None
None
None
None
exited at update_barrier.wait(): 5
exited at update_barrier.wait(): 0
exited at update_barrier.wait(): 2
exited at update_barrier.wait(): 9
exited at update_barrier.wait(): 6
exited at update_barrier.wait(): 1
None
[32m[I 2022-11-13 13:53:59,553][0m Trial 0 finished with value: -128783703212528.92 and parameters: {'activation': 2, 't_max': 2, 'hidden_size': 0, 'variance_scaling_factor': 0, 'permaban_threshold': 3, 'learning_rate_base': 3, 'learning_rate_exponent': 1, 'beta_base': 3, 'beta_exponent': 4}. Best is trial 0 with value: -128783703212528.92.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 4.9999999999999996e-06, 
        "beta": 7e-07, 
        "t_max": 30, 
        "activation": 1, 
        "hidden_size": 16, 
        "variance_scaling_factor": 0.01, 
        "permaban_threshold": 1000, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 1718985606, 
    "outdir": "results", 
    "t_max": 30, 
    "beta": 7e-07, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 4.9999999999999996e-06, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 1000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 16, 
    "activation": 1, 
}
None
None
None
exited at update_barrier.wait(): 6
exited at update_barrier.wait(): 8
exited at update_barrier.wait(): 2
None
None
None
exited at update_barrier.wait(): 1
{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -690.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"total_number_of_episodes": 30, "number_of_timesteps": 30000, "per_episode_reward": -703.73, "episode_reward_trend_value": -1.2828067406346577, "biggest_recent_change": NaN},
Hit early stopping because per_episode_reward: -703.7301265460271 < -700
exited at when_all_processes_are_updated(): 7
exited at update_barrier.wait(): 0
exited at update_barrier.wait(): 5
[32m[I 2022-11-13 13:54:05,065][0m Trial 1 finished with value: -704.5390541816616 and parameters: {'activation': 1, 't_max': 4, 'hidden_size': 0, 'variance_scaling_factor': 0, 'permaban_threshold': 2, 'learning_rate_base': 2, 'learning_rate_exponent': 5, 'beta_base': 3, 'beta_exponent': 6}. Best is trial 1 with value: -704.5390541816616.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 0.005, 
        "beta": 9e-07, 
        "t_max": 20, 
        "activation": 2, 
        "hidden_size": 32, 
        "variance_scaling_factor": 0.01, 
        "permaban_threshold": 500, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 3179616192, 
    "outdir": "results", 
    "t_max": 20, 
    "beta": 9e-07, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 0.005, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 500, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 32, 
    "activation": 2, 
}
None
None
exited at update_barrier.wait(): 5
exited at update_barrier.wait(): 3
exited at update_barrier.wait(): 0
exited at update_barrier.wait(): 9
None
None
None
None
None
None
exited at update_barrier.wait(): 2
exited at update_barrier.wait(): 6
exited at update_barrier.wait(): 4
exited at update_barrier.wait(): 1
{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -1332.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Hit early stopping because per_episode_reward: -1332.6003897195715 < -700
exited at when_all_processes_are_updated(): 7
[32m[I 2022-11-13 13:54:10,437][0m Trial 2 finished with value: -1460.3949249745724 and parameters: {'activation': 2, 't_max': 3, 'hidden_size': 1, 'variance_scaling_factor': 0, 'permaban_threshold': 1, 'learning_rate_base': 2, 'learning_rate_exponent': 2, 'beta_base': 4, 'beta_exponent': 6}. Best is trial 1 with value: -704.5390541816616.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 3.0000000000000004e-08, 
        "beta": 7e-08, 
        "t_max": 30, 
        "activation": 2, 
        "hidden_size": 128, 
        "variance_scaling_factor": 1, 
        "permaban_threshold": 10000, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 614297613, 
    "outdir": "results", 
    "t_max": 30, 
    "beta": 7e-08, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 3.0000000000000004e-08, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 10000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 128, 
    "activation": 2, 
}
Process Process-33:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 178, in train_loop
    update_barrier.wait()   # Wait for all agents to contribute their gradients to global model, the sync_updates() to step it's optimizer
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-37:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 178, in train_loop
    update_barrier.wait()   # Wait for all agents to contribute their gradients to global model, the sync_updates() to step it's optimizer
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-36:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 178, in train_loop
    update_barrier.wait()   # Wait for all agents to contribute their gradients to global model, the sync_updates() to step it's optimizer
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -628.41, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"total_number_of_episodes": 30, "number_of_timesteps": 30000, "per_episode_reward": -637.42, "episode_reward_trend_value": -0.9012739026739496, "biggest_recent_change": NaN},
{"total_number_of_episodes": 40, "number_of_timesteps": 40000, "per_episode_reward": -637.31, "episode_reward_trend_value": -0.44517772044816867, "biggest_recent_change": NaN},
{"total_number_of_episodes": 50, "number_of_timesteps": 50000, "per_episode_reward": -652.18, "episode_reward_trend_value": -0.792334037873934, "biggest_recent_change": NaN},
{"total_number_of_episodes": 60, "number_of_timesteps": 60000, "per_episode_reward": -644.25, "episode_reward_trend_value": -0.39609826546385707, "biggest_recent_change": NaN},
{"total_number_of_episodes": 70, "number_of_timesteps": 70000, "per_episode_reward": -645.17, "episode_reward_trend_value": -0.335302095528466, "biggest_recent_change": NaN},
{"total_number_of_episodes": 80, "number_of_timesteps": 80000, "per_episode_reward": -645.62, "episode_reward_trend_value": -0.28696067667282443, "biggest_recent_change": NaN},
{"total_number_of_episodes": 90, "number_of_timesteps": 90000, "per_episode_reward": -643.43, "episode_reward_trend_value": -0.21458483739647655, "biggest_recent_change": NaN},
{"total_number_of_episodes": 100, "number_of_timesteps": 100000, "per_episode_reward": -639.62, "episode_reward_trend_value": -0.14022822918900318, "biggest_recent_change": NaN},
{"total_number_of_episodes": 110, "number_of_timesteps": 110000, "per_episode_reward": -641.9, "episode_reward_trend_value": -0.1499436362073286, "biggest_recent_change": 14.866466727254647},
{"total_number_of_episodes": 120, "number_of_timesteps": 120000, "per_episode_reward": -638.73, "episode_reward_trend_value": -0.014621855537899997, "biggest_recent_change": 14.866466727254647},
{"total_number_of_episodes": 130, "number_of_timesteps": 130000, "per_episode_reward": -640.05, "episode_reward_trend_value": -0.030480199335405207, "biggest_recent_change": 14.866466727254647},
{"total_number_of_episodes": 140, "number_of_timesteps": 140000, "per_episode_reward": -641.23, "episode_reward_trend_value": 0.1215654939262663, "biggest_recent_change": 7.926090517663738},
{"total_number_of_episodes": 150, "number_of_timesteps": 150000, "per_episode_reward": -637.66, "episode_reward_trend_value": 0.07326113733700544, "biggest_recent_change": 3.802680282633105},
{"total_number_of_episodes": 160, "number_of_timesteps": 160000, "per_episode_reward": -640.03, "episode_reward_trend_value": 0.05708971066477235, "biggest_recent_change": 3.802680282633105},
{"total_number_of_episodes": 170, "number_of_timesteps": 170000, "per_episode_reward": -637.15, "episode_reward_trend_value": 0.094149948636468, "biggest_recent_change": 3.802680282633105},
{"total_number_of_episodes": 180, "number_of_timesteps": 180000, "per_episode_reward": -637.67, "episode_reward_trend_value": 0.0639776026758606, "biggest_recent_change": 3.802680282633105},
{"total_number_of_episodes": 190, "number_of_timesteps": 190000, "per_episode_reward": -636.6, "episode_reward_trend_value": 0.033567713646117325, "biggest_recent_change": 3.578698424630261},
{"total_number_of_episodes": 200, "number_of_timesteps": 200000, "per_episode_reward": -637.35, "episode_reward_trend_value": 0.050605798037440766, "biggest_recent_change": 3.578698424630261},
{"total_number_of_episodes": 210, "number_of_timesteps": 210000, "per_episode_reward": -637.23, "episode_reward_trend_value": 0.016727467117409058, "biggest_recent_change": 3.578698424630261},
{"total_number_of_episodes": 220, "number_of_timesteps": 220000, "per_episode_reward": -638.51, "episode_reward_trend_value": 0.017174552285776676, "biggest_recent_change": 3.578698424630261},
{"total_number_of_episodes": 230, "number_of_timesteps": 230000, "per_episode_reward": -639.75, "episode_reward_trend_value": 0.01651163180425657, "biggest_recent_change": 3.578698424630261},
{"total_number_of_episodes": 240, "number_of_timesteps": 240000, "per_episode_reward": -639.5, "episode_reward_trend_value": -0.020480053571684996, "biggest_recent_change": 2.882885593506444},
{"total_number_of_episodes": 250, "number_of_timesteps": 250000, "per_episode_reward": -640.34, "episode_reward_trend_value": -0.003389884813941535, "biggest_recent_change": 2.882885593506444},
{"total_number_of_episodes": 260, "number_of_timesteps": 260000, "per_episode_reward": -642.25, "episode_reward_trend_value": -0.05665853966354208, "biggest_recent_change": 1.911293342957606},
{"total_number_of_episodes": 270, "number_of_timesteps": 270000, "per_episode_reward": -642.98, "episode_reward_trend_value": -0.05904807301343958, "biggest_recent_change": 1.911293342957606},
{"total_number_of_episodes": 280, "number_of_timesteps": 280000, "per_episode_reward": -641.27, "episode_reward_trend_value": -0.05185204903737663, "biggest_recent_change": 1.911293342957606},
{"total_number_of_episodes": 290, "number_of_timesteps": 290000, "per_episode_reward": -641.39, "episode_reward_trend_value": -0.04496416118711043, "biggest_recent_change": 1.911293342957606},
{"total_number_of_episodes": 300, "number_of_timesteps": 300000, "per_episode_reward": -640.67, "episode_reward_trend_value": -0.038274358179209385, "biggest_recent_change": 1.911293342957606},
{"total_number_of_episodes": 310, "number_of_timesteps": 310000, "per_episode_reward": -640.95, "episode_reward_trend_value": -0.027177177266623352, "biggest_recent_change": 1.911293342957606},
{"total_number_of_episodes": 320, "number_of_timesteps": 320000, "per_episode_reward": -640.89, "episode_reward_trend_value": -0.012715364895409998, "biggest_recent_change": 1.911293342957606},
{"total_number_of_episodes": 330, "number_of_timesteps": 330000, "per_episode_reward": -641.05, "episode_reward_trend_value": -0.017268551321026532, "biggest_recent_change": 1.911293342957606},
{"total_number_of_episodes": 340, "number_of_timesteps": 340000, "per_episode_reward": -641.22, "episode_reward_trend_value": -0.009822732058518744, "biggest_recent_change": 1.911293342957606},
{"total_number_of_episodes": 350, "number_of_timesteps": 350000, "per_episode_reward": -640.73, "episode_reward_trend_value": 0.016917132467708346, "biggest_recent_change": 1.7134324278018767},
{"total_number_of_episodes": 360, "number_of_timesteps": 360000, "per_episode_reward": -641.88, "episode_reward_trend_value": 0.01224390829060111, "biggest_recent_change": 1.7134324278018767},
{"total_number_of_episodes": 370, "number_of_timesteps": 370000, "per_episode_reward": -641.22, "episode_reward_trend_value": 0.0005247180424134967, "biggest_recent_change": 1.1544573312689863},
{"total_number_of_episodes": 380, "number_of_timesteps": 380000, "per_episode_reward": -641.37, "episode_reward_trend_value": 0.00025250778042062744, "biggest_recent_change": 1.1544573312689863},
{"total_number_of_episodes": 390, "number_of_timesteps": 390000, "per_episode_reward": -641.55, "episode_reward_trend_value": -0.009689208516110487, "biggest_recent_change": 1.1544573312689863},
{"total_number_of_episodes": 400, "number_of_timesteps": 400000, "per_episode_reward": -642.05, "episode_reward_trend_value": -0.012221421013578038, "biggest_recent_change": 1.1544573312689863},
{"total_number_of_episodes": 410, "number_of_timesteps": 410000, "per_episode_reward": -642.94, "episode_reward_trend_value": -0.02272601035560658, "biggest_recent_change": 1.1544573312689863},
Process Process-40:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 178, in train_loop
    update_barrier.wait()   # Wait for all agents to contribute their gradients to global model, the sync_updates() to step it's optimizer
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-32:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 178, in train_loop
    update_barrier.wait()   # Wait for all agents to contribute their gradients to global model, the sync_updates() to step it's optimizer
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-38:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 178, in train_loop
    update_barrier.wait()   # Wait for all agents to contribute their gradients to global model, the sync_updates() to step it's optimizer
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-35:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 167, in train_loop
    when_all_processes_are_updated()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 481, in when_all_processes_are_updated
    ucb_reward = ucb.reward_func(ucb.smart_gradient_of_agents)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 413, in smart_gradient_of_agents
    all_grads.append(np.asarray(my_grad))
KeyboardInterrupt
Process Process-34:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 178, in train_loop
    update_barrier.wait()   # Wait for all agents to contribute their gradients to global model, the sync_updates() to step it's optimizer
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-39:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 178, in train_loop
    update_barrier.wait()   # Wait for all agents to contribute their gradients to global model, the sync_updates() to step it's optimizer
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-31:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 178, in train_loop
    update_barrier.wait()   # Wait for all agents to contribute their gradients to global model, the sync_updates() to step it's optimizer
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
[33m[W 2022-11-13 13:56:13,144][0m Trial 3 failed because of the following error: KeyboardInterrupt()[0m
Traceback (most recent call last):
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "./main/0_hyp_tuning.py", line 31, in stage1_tuning
    fitness_value = float(train_a3c.train_a3c(args, trial))
  File "/home/jeffhykin/repos/bizav/examples/atari/reproduction/a3c/train_a3c.py", line 268, in train_a3c
    experiments.train_agent_async(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 628, in train_agent_async
    async_.run_async(processes, run_func)
  File "/home/jeffhykin/repos/bizav/pfrl/utils/async_.py", line 28, in run_async
    each_process.join()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 47, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
Traceback (most recent call last):
  File "./main/0_hyp_tuning.py", line 122, in <module>
    start_running_trials(objective=stage1_tuning, number_of_trials=config.tuning.number_of_trials)
  File "./main/0_hyp_tuning.py", line 96, in start_running_trials
    study.optimize(objective, n_trials=number_of_trials, gc_after_trial=True)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/study.py", line 419, in optimize
    _optimize(
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 66, in _optimize
    _optimize_sequential(
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 234, in _run_trial
    raise func_err
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "./main/0_hyp_tuning.py", line 31, in stage1_tuning
    fitness_value = float(train_a3c.train_a3c(args, trial))
  File "/home/jeffhykin/repos/bizav/examples/atari/reproduction/a3c/train_a3c.py", line 268, in train_a3c
    experiments.train_agent_async(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 628, in train_agent_async
    async_.run_async(processes, run_func)
  File "/home/jeffhykin/repos/bizav/pfrl/utils/async_.py", line 28, in run_async
    each_process.join()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 47, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
[32m[I 2022-11-13 13:56:29,381][0m Using an existing study with name 'halfcheetah_sync__no_malicious_2' instead of creating a new one.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 5e-07, 
        "beta": 0.009000000000000001, 
        "t_max": 30, 
        "activation": 0, 
        "hidden_size": 64, 
        "variance_scaling_factor": 0.01, 
        "permaban_threshold": 2000, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 1211599551, 
    "outdir": "results", 
    "t_max": 30, 
    "beta": 0.009000000000000001, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 5e-07, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 2000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 0, 
}

exited at update_barrier.wait(): 2
None
exited at update_barrier.wait(): 7
None
exited at update_barrier.wait(): 5
None
exited at update_barrier.wait(): 8
None
{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -705.51, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Hit early stopping because per_episode_reward: -705.5092522066735 < -700
exited at when_all_processes_are_updated(): 9
exited at update_barrier.wait(): 1
None
exited at update_barrier.wait(): 3
None
[32m[I 2022-11-13 13:56:34,926][0m Trial 4 finished with value: -697.9788391554436 and parameters: {'activation': 0, 't_max': 4, 'hidden_size': 2, 'variance_scaling_factor': 0, 'permaban_threshold': 3, 'learning_rate_base': 2, 'learning_rate_exponent': 6, 'beta_base': 4, 'beta_exponent': 2}. Best is trial 4 with value: -697.9788391554436.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 0.007, 
        "beta": 0.9, 
        "t_max": 10, 
        "activation": 2, 
        "hidden_size": 128, 
        "variance_scaling_factor": 0.01, 
        "permaban_threshold": 500, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 742294678, 
    "outdir": "results", 
    "t_max": 10, 
    "beta": 0.9, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 0.007, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 500, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 128, 
    "activation": 2, 
}
exited at update_barrier.wait(): 4
None
{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -139462.19, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Hit early stopping because per_episode_reward: -139462.18928133036 < -700
exited at when_all_processes_are_updated(): 0
exited at update_barrier.wait(): 8
None
exited at update_barrier.wait(): 1
None
exited at update_barrier.wait(): 9
None
exited at update_barrier.wait(): 6
None
[32m[I 2022-11-13 13:56:54,388][0m Trial 5 finished with value: -211516.44332448332 and parameters: {'activation': 2, 't_max': 2, 'hidden_size': 3, 'variance_scaling_factor': 0, 'permaban_threshold': 1, 'learning_rate_base': 3, 'learning_rate_exponent': 2, 'beta_base': 4, 'beta_exponent': 0}. Best is trial 4 with value: -697.9788391554436.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 5e-07, 
        "beta": 4.9999999999999996e-06, 
        "t_max": 3, 
        "activation": 1, 
        "hidden_size": 16, 
        "variance_scaling_factor": 1000, 
        "permaban_threshold": 2000, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 2050000865, 
    "outdir": "results", 
    "t_max": 3, 
    "beta": 4.9999999999999996e-06, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 5e-07, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 2000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 16, 
    "activation": 1, 
}
Process Process-30:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 156, in train_loop
    agent.observe(obs, r, done, reset)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 295, in observe
    self._observe_train(obs, reward, done, reset)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 342, in _observe_train
    self.past_rewards[self.t - 1] = reward
KeyboardInterrupt
Process Process-26:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 156, in train_loop
    agent.observe(obs, r, done, reset)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 295, in observe
    self._observe_train(obs, reward, done, reset)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 351, in _observe_train
    statevar = self.batch_states([obs], self.device, self.phi)
  File "/home/jeffhykin/repos/bizav/pfrl/utils/batch_states.py", line 31, in batch_states
    features = [phi(s) for s in states]
  File "/home/jeffhykin/repos/bizav/pfrl/utils/batch_states.py", line 31, in <listcomp>
    features = [phi(s) for s in states]
  File "/home/jeffhykin/repos/bizav/examples/atari/reproduction/a3c/train_a3c.py", line 207, in phi
    return np.asarray(x, dtype=np.float32)
KeyboardInterrupt
{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -676.21, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"total_number_of_episodes": 30, "number_of_timesteps": 30000, "per_episode_reward": -659.3, "episode_reward_trend_value": 1.690954670923088, "biggest_recent_change": NaN},
{"total_number_of_episodes": 40, "number_of_timesteps": 40000, "per_episode_reward": -645.22, "episode_reward_trend_value": 1.5494767440419879, "biggest_recent_change": NaN},
{"total_number_of_episodes": 50, "number_of_timesteps": 50000, "per_episode_reward": -655.83, "episode_reward_trend_value": 0.6795040468268856, "biggest_recent_change": NaN},
{"total_number_of_episodes": 60, "number_of_timesteps": 60000, "per_episode_reward": -654.42, "episode_reward_trend_value": 0.5447836632608698, "biggest_recent_change": NaN},
{"total_number_of_episodes": 70, "number_of_timesteps": 70000, "per_episode_reward": -584.48, "episode_reward_trend_value": 1.8346893867002698, "biggest_recent_change": NaN},
{"total_number_of_episodes": 80, "number_of_timesteps": 80000, "per_episode_reward": -586.08, "episode_reward_trend_value": 1.502308253419858, "biggest_recent_change": NaN},
{"total_number_of_episodes": 90, "number_of_timesteps": 90000, "per_episode_reward": -584.25, "episode_reward_trend_value": 1.313753919453997, "biggest_recent_change": NaN},
{"total_number_of_episodes": 100, "number_of_timesteps": 100000, "per_episode_reward": -585.51, "episode_reward_trend_value": 1.1338337604316364, "biggest_recent_change": NaN},
{"total_number_of_episodes": 110, "number_of_timesteps": 110000, "per_episode_reward": -584.75, "episode_reward_trend_value": 1.0162500107622854, "biggest_recent_change": 69.9431228045787},
{"total_number_of_episodes": 120, "number_of_timesteps": 120000, "per_episode_reward": -581.21, "episode_reward_trend_value": 0.8676776885914401, "biggest_recent_change": 69.9431228045787},
{"total_number_of_episodes": 130, "number_of_timesteps": 130000, "per_episode_reward": -582.18, "episode_reward_trend_value": 0.7004543062331259, "biggest_recent_change": 69.9431228045787},
{"total_number_of_episodes": 140, "number_of_timesteps": 140000, "per_episode_reward": -581.77, "episode_reward_trend_value": 0.8228403071537489, "biggest_recent_change": 69.9431228045787},
{"total_number_of_episodes": 150, "number_of_timesteps": 150000, "per_episode_reward": -582.63, "episode_reward_trend_value": 0.797718003752929, "biggest_recent_change": 69.9431228045787},
{"total_number_of_episodes": 160, "number_of_timesteps": 160000, "per_episode_reward": -581.03, "episode_reward_trend_value": 0.038315065013039704, "biggest_recent_change": 3.5380377138548056},
{"total_number_of_episodes": 170, "number_of_timesteps": 170000, "per_episode_reward": -581.52, "episode_reward_trend_value": 0.050617777491701564, "biggest_recent_change": 3.5380377138548056},
{"total_number_of_episodes": 180, "number_of_timesteps": 180000, "per_episode_reward": -581.97, "episode_reward_trend_value": 0.02532586298871517, "biggest_recent_change": 3.5380377138548056},
{"total_number_of_episodes": 190, "number_of_timesteps": 190000, "per_episode_reward": -581.88, "episode_reward_trend_value": 0.04031815968074979, "biggest_recent_change": 3.5380377138548056},
{"total_number_of_episodes": 200, "number_of_timesteps": 200000, "per_episode_reward": -583.6, "episode_reward_trend_value": 0.012794098812880999, "biggest_recent_change": 3.5380377138548056},
{"total_number_of_episodes": 210, "number_of_timesteps": 210000, "per_episode_reward": -583.93, "episode_reward_trend_value": -0.030148792864521413, "biggest_recent_change": 1.7213653440334156},
{"total_number_of_episodes": 220, "number_of_timesteps": 220000, "per_episode_reward": -583.37, "episode_reward_trend_value": -0.013211717388493424, "biggest_recent_change": 1.7213653440334156},
{"total_number_of_episodes": 230, "number_of_timesteps": 230000, "per_episode_reward": -582.88, "episode_reward_trend_value": -0.012344632172084858, "biggest_recent_change": 1.7213653440334156},
Process Process-27:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 160, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-28:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 160, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-24:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 160, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-25:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 156, in train_loop
    agent.observe(obs, r, done, reset)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 295, in observe
    self._observe_train(obs, reward, done, reset)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 352, in _observe_train
    self.update(statevar)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 211, in update
    batch_entropy = batch_distrib.entropy()
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/distributions/independent.py", line 95, in entropy
    entropy = self.base_dist.entropy()
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/distributions/normal.py", line 88, in entropy
    return 0.5 + 0.5 * math.log(2 * math.pi) + torch.log(self.scale)
KeyboardInterrupt
Process Process-21:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 156, in train_loop
    agent.observe(obs, r, done, reset)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 295, in observe
    self._observe_train(obs, reward, done, reset)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 352, in _observe_train
    self.update(statevar)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 241, in update
    self.total_loss.backward()
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Process Process-22:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 160, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-29:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 160, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-23:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 619, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 592, in <lambda>
    f = lambda : train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 160, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
[33m[W 2022-11-13 13:58:28,169][0m Trial 6 failed because of the following error: KeyboardInterrupt()[0m
Traceback (most recent call last):
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "./main/0_hyp_tuning.py", line 31, in stage1_tuning
    fitness_value = float(train_a3c.train_a3c(args, trial))
  File "/home/jeffhykin/repos/bizav/examples/atari/reproduction/a3c/train_a3c.py", line 268, in train_a3c
    experiments.train_agent_async(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 628, in train_agent_async
    async_.run_async(processes, run_func)
  File "/home/jeffhykin/repos/bizav/pfrl/utils/async_.py", line 28, in run_async
    each_process.join()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 47, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
Traceback (most recent call last):
  File "./main/0_hyp_tuning.py", line 122, in <module>
    start_running_trials(objective=stage1_tuning, number_of_trials=config.tuning.number_of_trials)
  File "./main/0_hyp_tuning.py", line 96, in start_running_trials
    study.optimize(objective, n_trials=number_of_trials, gc_after_trial=True)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/study.py", line 419, in optimize
    _optimize(
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 66, in _optimize
    _optimize_sequential(
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 234, in _run_trial
    raise func_err
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "./main/0_hyp_tuning.py", line 31, in stage1_tuning
    fitness_value = float(train_a3c.train_a3c(args, trial))
  File "/home/jeffhykin/repos/bizav/examples/atari/reproduction/a3c/train_a3c.py", line 268, in train_a3c
    experiments.train_agent_async(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 628, in train_agent_async
    async_.run_async(processes, run_func)
  File "/home/jeffhykin/repos/bizav/pfrl/utils/async_.py", line 28, in run_async
    each_process.join()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 47, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
[32m[I 2022-11-13 13:58:33,739][0m Using an existing study with name 'halfcheetah_sync__no_malicious_2' instead of creating a new one.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 3000, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 0.0005, 
        "beta": 9e-06, 
        "t_max": 10, 
        "activation": 2, 
        "hidden_size": 128, 
        "variance_scaling_factor": 1, 
        "permaban_threshold": 2000, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 3957826240, 
    "outdir": "results", 
    "t_max": 10, 
    "beta": 9e-06, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 0.0005, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 2000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 128, 
    "activation": 2, 
}

{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -617.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"total_number_of_episodes": 30, "number_of_timesteps": 30000, "per_episode_reward": -618.6, "episode_reward_trend_value": -0.10512289113696624, "biggest_recent_change": NaN},
{"total_number_of_episodes": 40, "number_of_timesteps": 40000, "per_episode_reward": -632.66, "episode_reward_trend_value": -0.755755998774589, "biggest_recent_change": NaN},
{"total_number_of_episodes": 50, "number_of_timesteps": 50000, "per_episode_reward": -635.32, "episode_reward_trend_value": -0.5923285447349674, "biggest_recent_change": NaN},
{"total_number_of_episodes": 60, "number_of_timesteps": 60000, "per_episode_reward": -643.5, "episode_reward_trend_value": -0.6488124569528196, "biggest_recent_change": NaN},
{"total_number_of_episodes": 70, "number_of_timesteps": 70000, "per_episode_reward": -646.79, "episode_reward_trend_value": -0.5848984667768196, "biggest_recent_change": NaN},
{"total_number_of_episodes": 80, "number_of_timesteps": 80000, "per_episode_reward": -642.27, "episode_reward_trend_value": -0.4120485755748973, "biggest_recent_change": NaN},
{"total_number_of_episodes": 90, "number_of_timesteps": 90000, "per_episode_reward": -645.26, "episode_reward_trend_value": -0.3958465075232977, "biggest_recent_change": NaN},
{"total_number_of_episodes": 100, "number_of_timesteps": 100000, "per_episode_reward": -643.74, "episode_reward_trend_value": -0.3273336237768021, "biggest_recent_change": NaN},
{"total_number_of_episodes": 110, "number_of_timesteps": 110000, "per_episode_reward": -648.15, "episode_reward_trend_value": -0.34006630877955024, "biggest_recent_change": 14.063891064122117},
{"total_number_of_episodes": 120, "number_of_timesteps": 120000, "per_episode_reward": -645.95, "episode_reward_trend_value": -0.3038549904255269, "biggest_recent_change": 14.063891064122117},
{"total_number_of_episodes": 130, "number_of_timesteps": 130000, "per_episode_reward": -648.64, "episode_reward_trend_value": -0.17753607685088657, "biggest_recent_change": 8.18264193606376},
{"total_number_of_episodes": 140, "number_of_timesteps": 140000, "per_episode_reward": -649.64, "episode_reward_trend_value": -0.15914968542607666, "biggest_recent_change": 8.18264193606376},
{"total_number_of_episodes": 150, "number_of_timesteps": 150000, "per_episode_reward": -646.44, "episode_reward_trend_value": -0.032637181324134366, "biggest_recent_change": 4.522008804347138},
{"total_number_of_episodes": 160, "number_of_timesteps": 160000, "per_episode_reward": -649.56, "episode_reward_trend_value": -0.030728345275682994, "biggest_recent_change": 4.522008804347138},
{"total_number_of_episodes": 170, "number_of_timesteps": 170000, "per_episode_reward": -648.69, "episode_reward_trend_value": -0.07126578484686155, "biggest_recent_change": 4.419277888015358},
{"total_number_of_episodes": 180, "number_of_timesteps": 180000, "per_episode_reward": -648.0, "episode_reward_trend_value": -0.030517988814395065, "biggest_recent_change": 4.419277888015358},
{"total_number_of_episodes": 190, "number_of_timesteps": 190000, "per_episode_reward": -649.7, "episode_reward_trend_value": -0.06626434939177242, "biggest_recent_change": 4.419277888015358},
{"total_number_of_episodes": 200, "number_of_timesteps": 200000, "per_episode_reward": -648.11, "episode_reward_trend_value": 0.0004977220308470957, "biggest_recent_change": 3.203483433111046},
{"total_number_of_episodes": 210, "number_of_timesteps": 210000, "per_episode_reward": -580.39, "episode_reward_trend_value": 0.7284128747140509, "biggest_recent_change": 67.72015348198079},
{"total_number_of_episodes": 220, "number_of_timesteps": 220000, "per_episode_reward": -580.52, "episode_reward_trend_value": 0.7569412281745359, "biggest_recent_change": 67.72015348198079},
{"total_number_of_episodes": 230, "number_of_timesteps": 230000, "per_episode_reward": -581.84, "episode_reward_trend_value": 0.7533140801172055, "biggest_recent_change": 67.72015348198079},
{"total_number_of_episodes": 240, "number_of_timesteps": 240000, "per_episode_reward": -579.82, "episode_reward_trend_value": 0.7402315688479032, "biggest_recent_change": 67.72015348198079},
{"total_number_of_episodes": 250, "number_of_timesteps": 250000, "per_episode_reward": -578.65, "episode_reward_trend_value": 0.7878479114624396, "biggest_recent_change": 67.72015348198079},
{"total_number_of_episodes": 260, "number_of_timesteps": 260000, "per_episode_reward": -577.95, "episode_reward_trend_value": 0.7859282449865216, "biggest_recent_change": 67.72015348198079},
{"total_number_of_episodes": 270, "number_of_timesteps": 270000, "per_episode_reward": -577.57, "episode_reward_trend_value": 0.7826265822241908, "biggest_recent_change": 67.72015348198079},
{"total_number_of_episodes": 280, "number_of_timesteps": 280000, "per_episode_reward": -576.32, "episode_reward_trend_value": 0.8153094984752064, "biggest_recent_change": 67.72015348198079},
{"total_number_of_episodes": 290, "number_of_timesteps": 290000, "per_episode_reward": -577.2, "episode_reward_trend_value": 0.7879055702316401, "biggest_recent_change": 67.72015348198079},
{"total_number_of_episodes": 300, "number_of_timesteps": 300000, "per_episode_reward": -576.74, "episode_reward_trend_value": 0.04059007408975756, "biggest_recent_change": 2.0260574188738474},
{"total_number_of_episodes": 310, "number_of_timesteps": 310000, "per_episode_reward": -577.8, "episode_reward_trend_value": 0.030178631124166105, "biggest_recent_change": 2.0260574188738474},
{"total_number_of_episodes": 320, "number_of_timesteps": 320000, "per_episode_reward": -577.13, "episode_reward_trend_value": 0.05232114615325069, "biggest_recent_change": 2.0260574188738474},
{"total_number_of_episodes": 330, "number_of_timesteps": 330000, "per_episode_reward": -577.43, "episode_reward_trend_value": 0.026497673879079132, "biggest_recent_change": 1.246855635114116},
{"total_number_of_episodes": 340, "number_of_timesteps": 340000, "per_episode_reward": -577.79, "episode_reward_trend_value": 0.00964209042419826, "biggest_recent_change": 1.246855635114116},
{"total_number_of_episodes": 350, "number_of_timesteps": 350000, "per_episode_reward": -577.72, "episode_reward_trend_value": 0.002539436984979046, "biggest_recent_change": 1.246855635114116},
{"total_number_of_episodes": 360, "number_of_timesteps": 360000, "per_episode_reward": -577.34, "episode_reward_trend_value": 0.002572955834042053, "biggest_recent_change": 1.246855635114116},
{"total_number_of_episodes": 370, "number_of_timesteps": 370000, "per_episode_reward": -576.15, "episode_reward_trend_value": 0.0019466769550730433, "biggest_recent_change": 1.1904905360069051},
{"total_number_of_episodes": 380, "number_of_timesteps": 380000, "per_episode_reward": -575.75, "episode_reward_trend_value": 0.016117967555927256, "biggest_recent_change": 1.1904905360069051},
{"total_number_of_episodes": 390, "number_of_timesteps": 390000, "per_episode_reward": -575.78, "episode_reward_trend_value": 0.010624976576500305, "biggest_recent_change": 1.1904905360069051},
{"total_number_of_episodes": 400, "number_of_timesteps": 400000, "per_episode_reward": -575.92, "episode_reward_trend_value": 0.0209116233999781, "biggest_recent_change": 1.1904905360069051},
{"total_number_of_episodes": 410, "number_of_timesteps": 410000, "per_episode_reward": -576.26, "episode_reward_trend_value": 0.009702141070907703, "biggest_recent_change": 1.1904905360069051},
{"total_number_of_episodes": 420, "number_of_timesteps": 420000, "per_episode_reward": -576.83, "episode_reward_trend_value": 0.0067156104077601714, "biggest_recent_change": 1.1904905360069051},
{"total_number_of_episodes": 430, "number_of_timesteps": 430000, "per_episode_reward": -576.65, "episode_reward_trend_value": 0.012573568182325643, "biggest_recent_change": 1.1904905360069051},
{"total_number_of_episodes": 440, "number_of_timesteps": 440000, "per_episode_reward": -576.8, "episode_reward_trend_value": 0.010210100699367154, "biggest_recent_change": 1.1904905360069051},
{"total_number_of_episodes": 450, "number_of_timesteps": 450000, "per_episode_reward": -577.43, "episode_reward_trend_value": -0.0010857670273303989, "biggest_recent_change": 1.1904905360069051},
{"total_number_of_episodes": 460, "number_of_timesteps": 460000, "per_episode_reward": -576.46, "episode_reward_trend_value": -0.0034889234891402844, "biggest_recent_change": 0.9742064544440154},
{"total_number_of_episodes": 470, "number_of_timesteps": 470000, "per_episode_reward": -575.69, "episode_reward_trend_value": 0.0006342127305174472, "biggest_recent_change": 0.9742064544440154},
{"total_number_of_episodes": 480, "number_of_timesteps": 480000, "per_episode_reward": -576.24, "episode_reward_trend_value": -0.005091664658651654, "biggest_recent_change": 0.9742064544440154},
{"total_number_of_episodes": 490, "number_of_timesteps": 490000, "per_episode_reward": -575.98, "episode_reward_trend_value": -0.0006795575620521454, "biggest_recent_change": 0.9742064544440154},
{"total_number_of_episodes": 500, "number_of_timesteps": 500000, "per_episode_reward": -575.09, "episode_reward_trend_value": 0.012974162529192451, "biggest_recent_change": 0.9742064544440154},
{"total_number_of_episodes": 510, "number_of_timesteps": 510000, "per_episode_reward": -576.4, "episode_reward_trend_value": 0.004761094929729855, "biggest_recent_change": 1.3060189294365045},
{"total_number_of_episodes": 520, "number_of_timesteps": 520000, "per_episode_reward": -575.71, "episode_reward_trend_value": 0.010448844424891173, "biggest_recent_change": 1.3060189294365045},
{"total_number_of_episodes": 530, "number_of_timesteps": 530000, "per_episode_reward": -575.22, "episode_reward_trend_value": 0.017653347725288565, "biggest_recent_change": 1.3060189294365045},
{"total_number_of_episodes": 540, "number_of_timesteps": 540000, "per_episode_reward": -575.41, "episode_reward_trend_value": 0.022445954524251497, "biggest_recent_change": 1.3060189294365045},
{"total_number_of_episodes": 550, "number_of_timesteps": 550000, "per_episode_reward": -575.47, "episode_reward_trend_value": 0.010991221769740555, "biggest_recent_change": 1.3060189294365045},
{"total_number_of_episodes": 560, "number_of_timesteps": 560000, "per_episode_reward": -574.89, "episode_reward_trend_value": 0.008924495423914575, "biggest_recent_change": 1.3060189294365045},
{"total_number_of_episodes": 570, "number_of_timesteps": 570000, "per_episode_reward": -574.17, "episode_reward_trend_value": 0.022934964638477596, "biggest_recent_change": 1.3060189294365045},
{"total_number_of_episodes": 580, "number_of_timesteps": 580000, "per_episode_reward": -573.74, "episode_reward_trend_value": 0.024876343810331037, "biggest_recent_change": 1.3060189294365045},
{"total_number_of_episodes": 590, "number_of_timesteps": 590000, "per_episode_reward": -573.09, "episode_reward_trend_value": 0.022258198811434544, "biggest_recent_change": 1.3060189294365045},
{"total_number_of_episodes": 600, "number_of_timesteps": 600000, "per_episode_reward": -572.98, "episode_reward_trend_value": 0.03802843483099423, "biggest_recent_change": 0.7130029053483895},
{"total_number_of_episodes": 610, "number_of_timesteps": 610000, "per_episode_reward": -573.54, "episode_reward_trend_value": 0.024171324983428298, "biggest_recent_change": 0.7130029053483895},
{"total_number_of_episodes": 620, "number_of_timesteps": 620000, "per_episode_reward": -573.44, "episode_reward_trend_value": 0.019692252698795678, "biggest_recent_change": 0.7130029053483895},
{"total_number_of_episodes": 630, "number_of_timesteps": 630000, "per_episode_reward": -573.91, "episode_reward_trend_value": 0.01670786404727475, "biggest_recent_change": 0.7130029053483895},
{"total_number_of_episodes": 640, "number_of_timesteps": 640000, "per_episode_reward": -573.01, "episode_reward_trend_value": 0.027348891608032017, "biggest_recent_change": 0.9009729870061847},
{"total_number_of_episodes": 650, "number_of_timesteps": 650000, "per_episode_reward": -572.99, "episode_reward_trend_value": 0.021083361854876633, "biggest_recent_change": 0.9009729870061847},
{"total_number_of_episodes": 660, "number_of_timesteps": 660000, "per_episode_reward": -573.84, "episode_reward_trend_value": 0.0037111890109713386, "biggest_recent_change": 0.9009729870061847},
{"total_number_of_episodes": 670, "number_of_timesteps": 670000, "per_episode_reward": -573.38, "episode_reward_trend_value": 0.004010951507834508, "biggest_recent_change": 0.9009729870061847},
{"total_number_of_episodes": 680, "number_of_timesteps": 680000, "per_episode_reward": -573.37, "episode_reward_trend_value": -0.0030807376021989006, "biggest_recent_change": 0.9009729870061847},
{"total_number_of_episodes": 690, "number_of_timesteps": 690000, "per_episode_reward": -573.38, "episode_reward_trend_value": -0.004435557522896892, "biggest_recent_change": 0.9009729870061847},
{"total_number_of_episodes": 700, "number_of_timesteps": 700000, "per_episode_reward": -574.04, "episode_reward_trend_value": -0.005592293367929971, "biggest_recent_change": 0.9009729870061847},
{"total_number_of_episodes": 710, "number_of_timesteps": 710000, "per_episode_reward": -574.77, "episode_reward_trend_value": -0.014750940461882087, "biggest_recent_change": 0.9009729870061847},
{"total_number_of_episodes": 720, "number_of_timesteps": 720000, "per_episode_reward": -575.39, "episode_reward_trend_value": -0.016394533865674375, "biggest_recent_change": 0.9009729870061847},
{"total_number_of_episodes": 730, "number_of_timesteps": 730000, "per_episode_reward": -575.2, "episode_reward_trend_value": -0.02435998878757649, "biggest_recent_change": 0.850492650603087},
{"total_number_of_episodes": 740, "number_of_timesteps": 740000, "per_episode_reward": -575.33, "episode_reward_trend_value": -0.025977615876404847, "biggest_recent_change": 0.850492650603087},
{"total_number_of_episodes": 750, "number_of_timesteps": 750000, "per_episode_reward": -575.05, "episode_reward_trend_value": -0.013460477033326392, "biggest_recent_change": 0.7300710699244064},
{"total_number_of_episodes": 760, "number_of_timesteps": 760000, "per_episode_reward": -575.02, "episode_reward_trend_value": -0.01824718381138079, "biggest_recent_change": 0.7300710699244064},
{"total_number_of_episodes": 770, "number_of_timesteps": 770000, "per_episode_reward": -575.63, "episode_reward_trend_value": -0.025102152191282635, "biggest_recent_change": 0.7300710699244064},
{"total_number_of_episodes": 780, "number_of_timesteps": 780000, "per_episode_reward": -576.01, "episode_reward_trend_value": -0.029274412481264434, "biggest_recent_change": 0.7300710699244064},
{"total_number_of_episodes": 790, "number_of_timesteps": 790000, "per_episode_reward": -576.32, "episode_reward_trend_value": -0.02529834334018738, "biggest_recent_change": 0.7300710699244064},
{"total_number_of_episodes": 800, "number_of_timesteps": 800000, "per_episode_reward": -575.7, "episode_reward_trend_value": -0.010287434641134042, "biggest_recent_change": 0.6209107129903941},
{"total_number_of_episodes": 810, "number_of_timesteps": 810000, "per_episode_reward": -575.94, "episode_reward_trend_value": -0.00617656674517851, "biggest_recent_change": 0.6209107129903941},
{"total_number_of_episodes": 820, "number_of_timesteps": 820000, "per_episode_reward": -576.21, "episode_reward_trend_value": -0.01119806685584687, "biggest_recent_change": 0.6209107129903941},
{"total_number_of_episodes": 830, "number_of_timesteps": 830000, "per_episode_reward": -576.31, "episode_reward_trend_value": -0.01093458783991284, "biggest_recent_change": 0.6209107129903941},
{"total_number_of_episodes": 840, "number_of_timesteps": 840000, "per_episode_reward": -576.6, "episode_reward_trend_value": -0.017230422686178474, "biggest_recent_change": 0.6209107129903941},
{"total_number_of_episodes": 850, "number_of_timesteps": 850000, "per_episode_reward": -577.15, "episode_reward_trend_value": -0.023647954625425884, "biggest_recent_change": 0.6209107129903941},
{"total_number_of_episodes": 860, "number_of_timesteps": 860000, "per_episode_reward": -576.94, "episode_reward_trend_value": -0.014600158946562816, "biggest_recent_change": 0.6209107129903941},
{"total_number_of_episodes": 870, "number_of_timesteps": 870000, "per_episode_reward": -576.89, "episode_reward_trend_value": -0.009776032780623861, "biggest_recent_change": 0.6209107129903941},
{"total_number_of_episodes": 880, "number_of_timesteps": 880000, "per_episode_reward": -577.14, "episode_reward_trend_value": -0.009141808437191735, "biggest_recent_change": 0.6209107129903941},
{"total_number_of_episodes": 890, "number_of_timesteps": 890000, "per_episode_reward": -576.99, "episode_reward_trend_value": -0.014339648870980503, "biggest_recent_change": 0.548457779429782},
{"total_number_of_episodes": 900, "number_of_timesteps": 900000, "per_episode_reward": -576.73, "episode_reward_trend_value": -0.008752168713989603, "biggest_recent_change": 0.548457779429782},
{"total_number_of_episodes": 910, "number_of_timesteps": 910000, "per_episode_reward": -576.63, "episode_reward_trend_value": -0.00467290488505796, "biggest_recent_change": 0.548457779429782},
{"total_number_of_episodes": 920, "number_of_timesteps": 920000, "per_episode_reward": -576.72, "episode_reward_trend_value": -0.004547689230085123, "biggest_recent_change": 0.548457779429782},
{"total_number_of_episodes": 930, "number_of_timesteps": 930000, "per_episode_reward": -576.44, "episode_reward_trend_value": 0.0018482946829635693, "biggest_recent_change": 0.548457779429782},
{"total_number_of_episodes": 940, "number_of_timesteps": 940000, "per_episode_reward": -576.68, "episode_reward_trend_value": 0.0052620164998744366, "biggest_recent_change": 0.28506326128444925},
{"total_number_of_episodes": 950, "number_of_timesteps": 950000, "per_episode_reward": -577.07, "episode_reward_trend_value": -0.00147613684702416, "biggest_recent_change": 0.39656112638886043},
{"total_number_of_episodes": 960, "number_of_timesteps": 960000, "per_episode_reward": -577.2, "episode_reward_trend_value": -0.0034850989030537167, "biggest_recent_change": 0.39656112638886043},
{"total_number_of_episodes": 970, "number_of_timesteps": 970000, "per_episode_reward": -576.9, "episode_reward_trend_value": 0.002696360449779907, "biggest_recent_change": 0.39656112638886043},
{"total_number_of_episodes": 980, "number_of_timesteps": 980000, "per_episode_reward": -577.04, "episode_reward_trend_value": -0.0006288604999200389, "biggest_recent_change": 0.39656112638886043},
{"total_number_of_episodes": 990, "number_of_timesteps": 990000, "per_episode_reward": -577.57, "episode_reward_trend_value": -0.009353006758638255, "biggest_recent_change": 0.5273060084028884},
{"total_number_of_episodes": 1000, "number_of_timesteps": 1000000, "per_episode_reward": -577.48, "episode_reward_trend_value": -0.00941329769576795, "biggest_recent_change": 0.5273060084028884},
{"total_number_of_episodes": 1010, "number_of_timesteps": 1010000, "per_episode_reward": -577.55, "episode_reward_trend_value": -0.00920020649759989, "biggest_recent_change": 0.5273060084028884},
{"total_number_of_episodes": 1020, "number_of_timesteps": 1020000, "per_episode_reward": -577.76, "episode_reward_trend_value": -0.014760866746516716, "biggest_recent_change": 0.5273060084028884},
{"total_number_of_episodes": 1030, "number_of_timesteps": 1030000, "per_episode_reward": -578.12, "episode_reward_trend_value": -0.01597931891697802, "biggest_recent_change": 0.5273060084028884},
{"total_number_of_episodes": 1040, "number_of_timesteps": 1040000, "per_episode_reward": -578.39, "episode_reward_trend_value": -0.014662861122087634, "biggest_recent_change": 0.5273060084028884},
{"total_number_of_episodes": 1050, "number_of_timesteps": 1050000, "per_episode_reward": -578.75, "episode_reward_trend_value": -0.017154535766288368, "biggest_recent_change": 0.5273060084028884},
{"total_number_of_episodes": 1060, "number_of_timesteps": 1060000, "per_episode_reward": -578.92, "episode_reward_trend_value": -0.022449236703089858, "biggest_recent_change": 0.5273060084028884},
{"total_number_of_episodes": 1070, "number_of_timesteps": 1070000, "per_episode_reward": -578.87, "episode_reward_trend_value": -0.020342463696427636, "biggest_recent_change": 0.5273060084028884},
{"total_number_of_episodes": 1080, "number_of_timesteps": 1080000, "per_episode_reward": -579.35, "episode_reward_trend_value": -0.01979037197452524, "biggest_recent_change": 0.477617753431673},
{"total_number_of_episodes": 1090, "number_of_timesteps": 1090000, "per_episode_reward": -578.87, "episode_reward_trend_value": -0.01547095701597401, "biggest_recent_change": 0.482601940606628},
{"total_number_of_episodes": 1100, "number_of_timesteps": 1100000, "per_episode_reward": -578.98, "episode_reward_trend_value": -0.015875959009253572, "biggest_recent_change": 0.482601940606628},
{"total_number_of_episodes": 1110, "number_of_timesteps": 1110000, "per_episode_reward": -578.92, "episode_reward_trend_value": -0.012781997313254578, "biggest_recent_change": 0.482601940606628},
{"total_number_of_episodes": 1120, "number_of_timesteps": 1120000, "per_episode_reward": -578.77, "episode_reward_trend_value": -0.007286114321203109, "biggest_recent_change": 0.482601940606628},
{"total_number_of_episodes": 1130, "number_of_timesteps": 1130000, "per_episode_reward": -579.02, "episode_reward_trend_value": -0.007006797825641166, "biggest_recent_change": 0.482601940606628},
{"total_number_of_episodes": 1140, "number_of_timesteps": 1140000, "per_episode_reward": -578.99, "episode_reward_trend_value": -0.0026824204626829367, "biggest_recent_change": 0.482601940606628},
{"total_number_of_episodes": 1150, "number_of_timesteps": 1150000, "per_episode_reward": -579.5, "episode_reward_trend_value": -0.00643688828046278, "biggest_recent_change": 0.5074613826085397},
{"total_number_of_episodes": 1160, "number_of_timesteps": 1160000, "per_episode_reward": -579.58, "episode_reward_trend_value": -0.007826819045251593, "biggest_recent_change": 0.5074613826085397},
{"total_number_of_episodes": 1170, "number_of_timesteps": 1170000, "per_episode_reward": -579.65, "episode_reward_trend_value": -0.0033137971984223843, "biggest_recent_change": 0.5074613826085397},
{"total_number_of_episodes": 1180, "number_of_timesteps": 1180000, "per_episode_reward": -579.34, "episode_reward_trend_value": -0.005182014459088198, "biggest_recent_change": 0.5074613826085397},
{"total_number_of_episodes": 1190, "number_of_timesteps": 1190000, "per_episode_reward": -579.34, "episode_reward_trend_value": -0.0040356591542920085, "biggest_recent_change": 0.5074613826085397},
{"total_number_of_episodes": 1200, "number_of_timesteps": 1200000, "per_episode_reward": -578.99, "episode_reward_trend_value": -0.0008580065956822283, "biggest_recent_change": 0.5074613826085397},
{"total_number_of_episodes": 1210, "number_of_timesteps": 1210000, "per_episode_reward": -578.89, "episode_reward_trend_value": -0.0013597878442687438, "biggest_recent_change": 0.5074613826085397},
{"total_number_of_episodes": 1220, "number_of_timesteps": 1220000, "per_episode_reward": -579.13, "episode_reward_trend_value": -0.0011397149611399172, "biggest_recent_change": 0.5074613826085397},
{"total_number_of_episodes": 1230, "number_of_timesteps": 1230000, "per_episode_reward": -578.79, "episode_reward_trend_value": 0.0021703279275256037, "biggest_recent_change": 0.5074613826085397},
{"total_number_of_episodes": 1240, "number_of_timesteps": 1240000, "per_episode_reward": -578.61, "episode_reward_trend_value": 0.00989917213397449, "biggest_recent_change": 0.34904912179672465},
{"total_number_of_episodes": 1250, "number_of_timesteps": 1250000, "per_episode_reward": -578.69, "episode_reward_trend_value": 0.009899139434507258, "biggest_recent_change": 0.34904912179672465},
{"total_number_of_episodes": 1260, "number_of_timesteps": 1260000, "per_episode_reward": -578.84, "episode_reward_trend_value": 0.008964110653462537, "biggest_recent_change": 0.34904912179672465},
{"total_number_of_episodes": 1270, "number_of_timesteps": 1270000, "per_episode_reward": -578.93, "episode_reward_trend_value": 0.004533960242189198, "biggest_recent_change": 0.34904912179672465},
{"total_number_of_episodes": 1280, "number_of_timesteps": 1280000, "per_episode_reward": -579.08, "episode_reward_trend_value": 0.002853850230887171, "biggest_recent_change": 0.34904912179672465},
{"total_number_of_episodes": 1290, "number_of_timesteps": 1290000, "per_episode_reward": -579.12, "episode_reward_trend_value": -0.001366249104353301, "biggest_recent_change": 0.3320769679226032},
{"total_number_of_episodes": 1300, "number_of_timesteps": 1300000, "per_episode_reward": -578.81, "episode_reward_trend_value": 0.0009567985247056439, "biggest_recent_change": 0.3320769679226032},
{"total_number_of_episodes": 1310, "number_of_timesteps": 1310000, "per_episode_reward": -578.72, "episode_reward_trend_value": 0.004487596403227043, "biggest_recent_change": 0.3320769679226032},
{"total_number_of_episodes": 1320, "number_of_timesteps": 1320000, "per_episode_reward": -578.53, "episode_reward_trend_value": 0.0029954839910361544, "biggest_recent_change": 0.3076599322778293},
{"total_number_of_episodes": 1330, "number_of_timesteps": 1330000, "per_episode_reward": -578.76, "episode_reward_trend_value": -0.0017156100267559141, "biggest_recent_change": 0.3076599322778293},
{"total_number_of_episodes": 1340, "number_of_timesteps": 1340000, "per_episode_reward": -579.41, "episode_reward_trend_value": -0.008067821433574965, "biggest_recent_change": 0.6533509793207486},
{"total_number_of_episodes": 1350, "number_of_timesteps": 1350000, "per_episode_reward": -579.85, "episode_reward_trend_value": -0.01115359664664892, "biggest_recent_change": 0.6533509793207486},
{"total_number_of_episodes": 1360, "number_of_timesteps": 1360000, "per_episode_reward": -580.02, "episode_reward_trend_value": -0.012143992748288686, "biggest_recent_change": 0.6533509793207486},
{"total_number_of_episodes": 1370, "number_of_timesteps": 1370000, "per_episode_reward": -580.05, "episode_reward_trend_value": -0.01067558532071568, "biggest_recent_change": 0.6533509793207486},
{"total_number_of_episodes": 1380, "number_of_timesteps": 1380000, "per_episode_reward": -579.89, "episode_reward_trend_value": -0.008600491954801883, "biggest_recent_change": 0.6533509793207486},
{"total_number_of_episodes": 1390, "number_of_timesteps": 1390000, "per_episode_reward": -580.05, "episode_reward_trend_value": -0.013822601954927904, "biggest_recent_change": 0.6533509793207486},
{"total_number_of_episodes": 1400, "number_of_timesteps": 1400000, "per_episode_reward": -579.73, "episode_reward_trend_value": -0.011198103778264743, "biggest_recent_change": 0.6533509793207486},
{"total_number_of_episodes": 1410, "number_of_timesteps": 1410000, "per_episode_reward": -580.22, "episode_reward_trend_value": -0.018824272606290528, "biggest_recent_change": 0.6533509793207486},
{"total_number_of_episodes": 1420, "number_of_timesteps": 1420000, "per_episode_reward": -580.08, "episode_reward_trend_value": -0.01466851282010945, "biggest_recent_change": 0.6533509793207486},
{"total_number_of_episodes": 1430, "number_of_timesteps": 1430000, "per_episode_reward": -580.53, "episode_reward_trend_value": -0.012430609673903189, "biggest_recent_change": 0.4885683436968975},
{"total_number_of_episodes": 1440, "number_of_timesteps": 1440000, "per_episode_reward": -580.54, "episode_reward_trend_value": -0.007696810277661825, "biggest_recent_change": 0.4885683436968975},
{"total_number_of_episodes": 1450, "number_of_timesteps": 1450000, "per_episode_reward": -580.28, "episode_reward_trend_value": -0.002930211937871263, "biggest_recent_change": 0.4885683436968975},
{"total_number_of_episodes": 1460, "number_of_timesteps": 1460000, "per_episode_reward": -580.09, "episode_reward_trend_value": -0.0005120270384180812, "biggest_recent_change": 0.4885683436968975},
{"total_number_of_episodes": 1470, "number_of_timesteps": 1470000, "per_episode_reward": -579.89, "episode_reward_trend_value": 7.70616362362691e-06, "biggest_recent_change": 0.4885683436968975},
{"total_number_of_episodes": 1480, "number_of_timesteps": 1480000, "per_episode_reward": -579.82, "episode_reward_trend_value": 0.002537978843444459, "biggest_recent_change": 0.4885683436968975},
{"total_number_of_episodes": 1490, "number_of_timesteps": 1490000, "per_episode_reward": -580.13, "episode_reward_trend_value": -0.004481834068620729, "biggest_recent_change": 0.4885683436968975},
{"total_number_of_episodes": 1500, "number_of_timesteps": 1500000, "per_episode_reward": -579.94, "episode_reward_trend_value": 0.0030617199856452417, "biggest_recent_change": 0.4519396961621851},
{"total_number_of_episodes": 1510, "number_of_timesteps": 1510000, "per_episode_reward": -579.7, "episode_reward_trend_value": 0.004269491176564265, "biggest_recent_change": 0.4519396961621851},
{"total_number_of_episodes": 1520, "number_of_timesteps": 1520000, "per_episode_reward": -579.39, "episode_reward_trend_value": 0.012717395410154746, "biggest_recent_change": 0.3109413978858129},
{"total_number_of_episodes": 1530, "number_of_timesteps": 1530000, "per_episode_reward": -579.76, "episode_reward_trend_value": 0.008687326244473246, "biggest_recent_change": 0.3699824259373372},
{"total_number_of_episodes": 1540, "number_of_timesteps": 1540000, "per_episode_reward": -579.91, "episode_reward_trend_value": 0.004159810885132882, "biggest_recent_change": 0.3699824259373372},
{"total_number_of_episodes": 1550, "number_of_timesteps": 1550000, "per_episode_reward": -579.97, "episode_reward_trend_value": 0.0013184572290318405, "biggest_recent_change": 0.3699824259373372},
{"total_number_of_episodes": 1560, "number_of_timesteps": 1560000, "per_episode_reward": -580.18, "episode_reward_trend_value": -0.0032173167969618693, "biggest_recent_change": 0.3699824259373372},
{"total_number_of_episodes": 1570, "number_of_timesteps": 1570000, "per_episode_reward": -580.08, "episode_reward_trend_value": -0.0028868507049221786, "biggest_recent_change": 0.3699824259373372},
{"total_number_of_episodes": 1580, "number_of_timesteps": 1580000, "per_episode_reward": -580.12, "episode_reward_trend_value": 0.00012138090039949627, "biggest_recent_change": 0.3699824259373372},
{"total_number_of_episodes": 1590, "number_of_timesteps": 1590000, "per_episode_reward": -580.09, "episode_reward_trend_value": -0.001579074964841867, "biggest_recent_change": 0.3699824259373372},
{"total_number_of_episodes": 1600, "number_of_timesteps": 1600000, "per_episode_reward": -580.02, "episode_reward_trend_value": -0.003629300490997088, "biggest_recent_change": 0.3699824259373372},
{"total_number_of_episodes": 1610, "number_of_timesteps": 1610000, "per_episode_reward": -579.87, "episode_reward_trend_value": -0.005339454607709134, "biggest_recent_change": 0.3699824259373372},
{"total_number_of_episodes": 1620, "number_of_timesteps": 1620000, "per_episode_reward": -580.31, "episode_reward_trend_value": -0.006136308004057708, "biggest_recent_change": 0.44169923160870894},
{"total_number_of_episodes": 1630, "number_of_timesteps": 1630000, "per_episode_reward": -580.28, "episode_reward_trend_value": -0.004156482519397287, "biggest_recent_change": 0.44169923160870894},
{"total_number_of_episodes": 1640, "number_of_timesteps": 1640000, "per_episode_reward": -580.24, "episode_reward_trend_value": -0.0029482833004294664, "biggest_recent_change": 0.44169923160870894},
{"total_number_of_episodes": 1650, "number_of_timesteps": 1650000, "per_episode_reward": -580.17, "episode_reward_trend_value": 0.0001293574644149784, "biggest_recent_change": 0.44169923160870894},
{"total_number_of_episodes": 1660, "number_of_timesteps": 1660000, "per_episode_reward": -579.96, "episode_reward_trend_value": 0.0014035754566925284, "biggest_recent_change": 0.44169923160870894},
{"total_number_of_episodes": 1670, "number_of_timesteps": 1670000, "per_episode_reward": -580.2, "episode_reward_trend_value": -0.0008362366849079686, "biggest_recent_change": 0.44169923160870894},
{"total_number_of_episodes": 1680, "number_of_timesteps": 1680000, "per_episode_reward": -580.45, "episode_reward_trend_value": -0.0040057486456476, "biggest_recent_change": 0.44169923160870894},
{"total_number_of_episodes": 1690, "number_of_timesteps": 1690000, "per_episode_reward": -580.44, "episode_reward_trend_value": -0.004662004335561202, "biggest_recent_change": 0.44169923160870894},
{"total_number_of_episodes": 1700, "number_of_timesteps": 1700000, "per_episode_reward": -580.26, "episode_reward_trend_value": -0.004355442961674625, "biggest_recent_change": 0.44169923160870894},
{"total_number_of_episodes": 1710, "number_of_timesteps": 1710000, "per_episode_reward": -580.23, "episode_reward_trend_value": 0.0008572343097992214, "biggest_recent_change": 0.2479455831512496},
{"total_number_of_episodes": 1720, "number_of_timesteps": 1720000, "per_episode_reward": -580.42, "episode_reward_trend_value": -0.0015525996889424378, "biggest_recent_change": 0.2479455831512496},
{"total_number_of_episodes": 1730, "number_of_timesteps": 1730000, "per_episode_reward": -580.44, "episode_reward_trend_value": -0.0022236721981446156, "biggest_recent_change": 0.2479455831512496},
{"total_number_of_episodes": 1740, "number_of_timesteps": 1740000, "per_episode_reward": -580.28, "episode_reward_trend_value": -0.0012289576021140016, "biggest_recent_change": 0.2479455831512496},
{"total_number_of_episodes": 1750, "number_of_timesteps": 1750000, "per_episode_reward": -580.0, "episode_reward_trend_value": -0.0004946077731523878, "biggest_recent_change": 0.2759076256454591},
{"total_number_of_episodes": 1760, "number_of_timesteps": 1760000, "per_episode_reward": -580.04, "episode_reward_trend_value": 0.0018069381504308996, "biggest_recent_change": 0.2759076256454591},
{"total_number_of_episodes": 1770, "number_of_timesteps": 1770000, "per_episode_reward": -580.16, "episode_reward_trend_value": 0.0031709690969591977, "biggest_recent_change": 0.2759076256454591},
{"total_number_of_episodes": 1780, "number_of_timesteps": 1780000, "per_episode_reward": -580.28, "episode_reward_trend_value": 0.0017944320791255248, "biggest_recent_change": 0.2759076256454591},
{"total_number_of_episodes": 1790, "number_of_timesteps": 1790000, "per_episode_reward": -580.21, "episode_reward_trend_value": 0.0005864784905598854, "biggest_recent_change": 0.2759076256454591},
{"total_number_of_episodes": 1800, "number_of_timesteps": 1800000, "per_episode_reward": -580.27, "episode_reward_trend_value": -0.0003863288395261103, "biggest_recent_change": 0.2759076256454591},
{"total_number_of_episodes": 1810, "number_of_timesteps": 1810000, "per_episode_reward": -580.08, "episode_reward_trend_value": 0.003801337873846933, "biggest_recent_change": 0.2759076256454591},
{"total_number_of_episodes": 1820, "number_of_timesteps": 1820000, "per_episode_reward": -580.46, "episode_reward_trend_value": -0.00022078954842881, "biggest_recent_change": 0.37594203346395716},
{"total_number_of_episodes": 1830, "number_of_timesteps": 1830000, "per_episode_reward": -580.74, "episode_reward_trend_value": -0.005169987981231669, "biggest_recent_change": 0.37594203346395716},
{"total_number_of_episodes": 1840, "number_of_timesteps": 1840000, "per_episode_reward": -580.79, "episode_reward_trend_value": -0.00874366159645332, "biggest_recent_change": 0.37594203346395716},
{"total_number_of_episodes": 1850, "number_of_timesteps": 1850000, "per_episode_reward": -580.6, "episode_reward_trend_value": -0.006312819586561444, "biggest_recent_change": 0.37594203346395716},
{"total_number_of_episodes": 1860, "number_of_timesteps": 1860000, "per_episode_reward": -580.57, "episode_reward_trend_value": -0.004585101656727551, "biggest_recent_change": 0.37594203346395716},
{"total_number_of_episodes": 1870, "number_of_timesteps": 1870000, "per_episode_reward": -580.76, "episode_reward_trend_value": -0.005328848310469109, "biggest_recent_change": 0.37594203346395716},
{"total_number_of_episodes": 1880, "number_of_timesteps": 1880000, "per_episode_reward": -581.0, "episode_reward_trend_value": -0.008819994639590175, "biggest_recent_change": 0.37594203346395716},
{"total_number_of_episodes": 1890, "number_of_timesteps": 1890000, "per_episode_reward": -580.99, "episode_reward_trend_value": -0.007973841531253988, "biggest_recent_change": 0.37594203346395716},
{"total_number_of_episodes": 1900, "number_of_timesteps": 1900000, "per_episode_reward": -580.97, "episode_reward_trend_value": -0.009809455826350838, "biggest_recent_change": 0.37594203346395716},
{"total_number_of_episodes": 1910, "number_of_timesteps": 1910000, "per_episode_reward": -580.89, "episode_reward_trend_value": -0.004837924030334761, "biggest_recent_change": 0.28436096607185846},
{"total_number_of_episodes": 1920, "number_of_timesteps": 1920000, "per_episode_reward": -580.7, "episode_reward_trend_value": 0.00042291905828809224, "biggest_recent_change": 0.24087065458513734},
{"total_number_of_episodes": 1930, "number_of_timesteps": 1930000, "per_episode_reward": -580.72, "episode_reward_trend_value": 0.0007548586637590738, "biggest_recent_change": 0.24087065458513734},
{"total_number_of_episodes": 1940, "number_of_timesteps": 1940000, "per_episode_reward": -580.57, "episode_reward_trend_value": 0.00036386619164608823, "biggest_recent_change": 0.24087065458513734},
{"total_number_of_episodes": 1950, "number_of_timesteps": 1950000, "per_episode_reward": -580.71, "episode_reward_trend_value": -0.0015601898514597046, "biggest_recent_change": 0.24087065458513734},
{"total_number_of_episodes": 1960, "number_of_timesteps": 1960000, "per_episode_reward": -580.54, "episode_reward_trend_value": 0.002465335026235809, "biggest_recent_change": 0.24087065458513734},
{"total_number_of_episodes": 1970, "number_of_timesteps": 1970000, "per_episode_reward": -580.64, "episode_reward_trend_value": 0.004064533390688515, "biggest_recent_change": 0.18911491190419838},
{"total_number_of_episodes": 1980, "number_of_timesteps": 1980000, "per_episode_reward": -580.74, "episode_reward_trend_value": 0.0027233760344289393, "biggest_recent_change": 0.18911491190419838},
{"total_number_of_episodes": 1990, "number_of_timesteps": 1990000, "per_episode_reward": -580.82, "episode_reward_trend_value": 0.0015978783823407464, "biggest_recent_change": 0.18911491190419838},
{"total_number_of_episodes": 2000, "number_of_timesteps": 2000000, "per_episode_reward": -580.91, "episode_reward_trend_value": -0.00016095228986740846, "biggest_recent_change": 0.18911491190419838},
{"total_number_of_episodes": 2010, "number_of_timesteps": 2010000, "per_episode_reward": -515.89, "episode_reward_trend_value": 0.7202021071747506, "biggest_recent_change": 65.02179026371982},
{"total_number_of_episodes": 2020, "number_of_timesteps": 2020000, "per_episode_reward": -515.95, "episode_reward_trend_value": 0.7197058007689836, "biggest_recent_change": 65.02179026371982},
{"total_number_of_episodes": 2030, "number_of_timesteps": 2030000, "per_episode_reward": -515.73, "episode_reward_trend_value": 0.7204678007340792, "biggest_recent_change": 65.02179026371982},
{"total_number_of_episodes": 2040, "number_of_timesteps": 2040000, "per_episode_reward": -515.53, "episode_reward_trend_value": 0.7242716920719482, "biggest_recent_change": 65.02179026371982},
{"total_number_of_episodes": 2050, "number_of_timesteps": 2050000, "per_episode_reward": -515.62, "episode_reward_trend_value": 0.7212964501319814, "biggest_recent_change": 65.02179026371982},
{"total_number_of_episodes": 2060, "number_of_timesteps": 2060000, "per_episode_reward": -515.46, "episode_reward_trend_value": 0.7241970288644854, "biggest_recent_change": 65.02179026371982},
{"total_number_of_episodes": 2070, "number_of_timesteps": 2070000, "per_episode_reward": -515.52, "episode_reward_trend_value": 0.7246546625922583, "biggest_recent_change": 65.02179026371982},
{"total_number_of_episodes": 2080, "number_of_timesteps": 2080000, "per_episode_reward": -515.53, "episode_reward_trend_value": 0.7254740593688628, "biggest_recent_change": 65.02179026371982},
{"total_number_of_episodes": 2090, "number_of_timesteps": 2090000, "per_episode_reward": -515.7, "episode_reward_trend_value": 0.7245536316922728, "biggest_recent_change": 65.02179026371982},
{"total_number_of_episodes": 2100, "number_of_timesteps": 2100000, "per_episode_reward": -515.65, "episode_reward_trend_value": 0.002662157532832528, "biggest_recent_change": 0.21752194223029164},
{"total_number_of_episodes": 2110, "number_of_timesteps": 2110000, "per_episode_reward": -515.68, "episode_reward_trend_value": 0.002983215838353064, "biggest_recent_change": 0.21752194223029164},
{"total_number_of_episodes": 2120, "number_of_timesteps": 2120000, "per_episode_reward": -515.59, "episode_reward_trend_value": 0.0015351963671289721, "biggest_recent_change": 0.19949699225003314},
{"total_number_of_episodes": 2130, "number_of_timesteps": 2130000, "per_episode_reward": -515.45, "episode_reward_trend_value": 0.000837888467190674, "biggest_recent_change": 0.16963742321433983},
{"total_number_of_episodes": 2140, "number_of_timesteps": 2140000, "per_episode_reward": -515.54, "episode_reward_trend_value": 0.0008904055153885161, "biggest_recent_change": 0.16963742321433983},
{"total_number_of_episodes": 2150, "number_of_timesteps": 2150000, "per_episode_reward": -515.44, "episode_reward_trend_value": 0.00015670903191373025, "biggest_recent_change": 0.16963742321433983},
{"total_number_of_episodes": 2160, "number_of_timesteps": 2160000, "per_episode_reward": -515.28, "episode_reward_trend_value": 0.0026457487851896783, "biggest_recent_change": 0.16963742321433983},
{"total_number_of_episodes": 2170, "number_of_timesteps": 2170000, "per_episode_reward": -515.36, "episode_reward_trend_value": 0.0018645259996093147, "biggest_recent_change": 0.16963742321433983},
{"total_number_of_episodes": 2180, "number_of_timesteps": 2180000, "per_episode_reward": -515.37, "episode_reward_trend_value": 0.003619491993169453, "biggest_recent_change": 0.16053929409747525},
{"total_number_of_episodes": 2190, "number_of_timesteps": 2190000, "per_episode_reward": -515.34, "episode_reward_trend_value": 0.0033940555880892335, "biggest_recent_change": 0.16053929409747525},
{"total_number_of_episodes": 2200, "number_of_timesteps": 2200000, "per_episode_reward": -515.19, "episode_reward_trend_value": 0.0054222820170126505, "biggest_recent_change": 0.16053929409747525},
{"total_number_of_episodes": 2210, "number_of_timesteps": 2210000, "per_episode_reward": -515.1, "episode_reward_trend_value": 0.005472402985277666, "biggest_recent_change": 0.16053929409747525},
{"total_number_of_episodes": 2220, "number_of_timesteps": 2220000, "per_episode_reward": -514.95, "episode_reward_trend_value": 0.005625525717072024, "biggest_recent_change": 0.16053929409747525},
{"total_number_of_episodes": 2230, "number_of_timesteps": 2230000, "per_episode_reward": -514.86, "episode_reward_trend_value": 0.0076383052321527135, "biggest_recent_change": 0.16053929409747525},
{"total_number_of_episodes": 2240, "number_of_timesteps": 2240000, "per_episode_reward": -514.87, "episode_reward_trend_value": 0.0063706038931741205, "biggest_recent_change": 0.16053929409747525},
{"total_number_of_episodes": 2250, "number_of_timesteps": 2250000, "per_episode_reward": -515.01, "episode_reward_trend_value": 0.0030044339757334154, "biggest_recent_change": 0.1509196143488225},
{"total_number_of_episodes": 2260, "number_of_timesteps": 2260000, "per_episode_reward": -514.86, "episode_reward_trend_value": 0.005513889755613692, "biggest_recent_change": 0.1509196143488225},
{"total_number_of_episodes": 2270, "number_of_timesteps": 2270000, "per_episode_reward": -514.85, "episode_reward_trend_value": 0.005845230660747802, "biggest_recent_change": 0.1509196143488225},
{"total_number_of_episodes": 2280, "number_of_timesteps": 2280000, "per_episode_reward": -514.92, "episode_reward_trend_value": 0.004681984382736775, "biggest_recent_change": 0.1509196143488225},
{"total_number_of_episodes": 2290, "number_of_timesteps": 2290000, "per_episode_reward": -514.92, "episode_reward_trend_value": 0.0030323999286995078, "biggest_recent_change": 0.15052032711707852},
{"total_number_of_episodes": 2300, "number_of_timesteps": 2300000, "per_episode_reward": -515.13, "episode_reward_trend_value": -0.00038883837561722127, "biggest_recent_change": 0.21620037042453077},
{"total_number_of_episodes": 2310, "number_of_timesteps": 2310000, "per_episode_reward": -515.24, "episode_reward_trend_value": -0.003262784186452134, "biggest_recent_change": 0.21620037042453077},
{"total_number_of_episodes": 2320, "number_of_timesteps": 2320000, "per_episode_reward": -515.23, "episode_reward_trend_value": -0.004165355364394449, "biggest_recent_change": 0.21620037042453077},
{"total_number_of_episodes": 2330, "number_of_timesteps": 2330000, "per_episode_reward": -515.12, "episode_reward_trend_value": -0.0027232275468830067, "biggest_recent_change": 0.21620037042453077},
{"total_number_of_episodes": 2340, "number_of_timesteps": 2340000, "per_episode_reward": -515.07, "episode_reward_trend_value": -0.0006807357043410573, "biggest_recent_change": 0.21620037042453077},
{"total_number_of_episodes": 2350, "number_of_timesteps": 2350000, "per_episode_reward": -515.23, "episode_reward_trend_value": -0.004075829266491837, "biggest_recent_change": 0.21620037042453077},
{"total_number_of_episodes": 2360, "number_of_timesteps": 2360000, "per_episode_reward": -515.23, "episode_reward_trend_value": -0.0042387957494282895, "biggest_recent_change": 0.21620037042453077},
{"total_number_of_episodes": 2370, "number_of_timesteps": 2370000, "per_episode_reward": -515.1, "episode_reward_trend_value": -0.0020134010470554938, "biggest_recent_change": 0.21620037042453077},
{"total_number_of_episodes": 2380, "number_of_timesteps": 2380000, "per_episode_reward": -515.21, "episode_reward_trend_value": -0.003204702485685276, "biggest_recent_change": 0.21620037042453077},
{"total_number_of_episodes": 2390, "number_of_timesteps": 2390000, "per_episode_reward": -515.19, "episode_reward_trend_value": -0.000605517539567144, "biggest_recent_change": 0.15645190929751607},
{"total_number_of_episodes": 2400, "number_of_timesteps": 2400000, "per_episode_reward": -515.17, "episode_reward_trend_value": 0.0008476522419666961, "biggest_recent_change": 0.15645190929751607},
{"total_number_of_episodes": 2410, "number_of_timesteps": 2410000, "per_episode_reward": -515.27, "episode_reward_trend_value": -0.000409825955754665, "biggest_recent_change": 0.15645190929751607},
{"total_number_of_episodes": 2420, "number_of_timesteps": 2420000, "per_episode_reward": -515.18, "episode_reward_trend_value": -0.0006744919224426364, "biggest_recent_change": 0.15645190929751607},
{"total_number_of_episodes": 2430, "number_of_timesteps": 2430000, "per_episode_reward": -515.15, "episode_reward_trend_value": -0.0007914928162411647, "biggest_recent_change": 0.15645190929751607},
{"total_number_of_episodes": 2440, "number_of_timesteps": 2440000, "per_episode_reward": -515.25, "episode_reward_trend_value": -0.00016769180729422965, "biggest_recent_change": 0.12686167110553015},
{"total_number_of_episodes": 2450, "number_of_timesteps": 2450000, "per_episode_reward": -515.0, "episode_reward_trend_value": 0.0025028926393979925, "biggest_recent_change": 0.24381581440616173},
{"total_number_of_episodes": 2460, "number_of_timesteps": 2460000, "per_episode_reward": -514.98, "episode_reward_trend_value": 0.0013189787313889509, "biggest_recent_change": 0.24381581440616173},
{"total_number_of_episodes": 2470, "number_of_timesteps": 2470000, "per_episode_reward": -514.91, "episode_reward_trend_value": 0.0032788641651980777, "biggest_recent_change": 0.24381581440616173},
{"total_number_of_episodes": 2480, "number_of_timesteps": 2480000, "per_episode_reward": -514.99, "episode_reward_trend_value": 0.0022167339519165176, "biggest_recent_change": 0.24381581440616173},
{"total_number_of_episodes": 2490, "number_of_timesteps": 2490000, "per_episode_reward": -515.03, "episode_reward_trend_value": 0.001553378081877731, "biggest_recent_change": 0.24381581440616173},
{"total_number_of_episodes": 2500, "number_of_timesteps": 2500000, "per_episode_reward": -515.09, "episode_reward_trend_value": 0.0019406455115750358, "biggest_recent_change": 0.24381581440616173},
{"total_number_of_episodes": 2510, "number_of_timesteps": 2510000, "per_episode_reward": -515.07, "episode_reward_trend_value": 0.0011890461521400337, "biggest_recent_change": 0.24381581440616173},
{"total_number_of_episodes": 2520, "number_of_timesteps": 2520000, "per_episode_reward": -514.97, "episode_reward_trend_value": 0.0019566109574371796, "biggest_recent_change": 0.24381581440616173},
{"total_number_of_episodes": 2530, "number_of_timesteps": 2530000, "per_episode_reward": -515.0, "episode_reward_trend_value": 0.002751486828199429, "biggest_recent_change": 0.24381581440616173},
Hit early stopping because biggest_recent_change: 0.09995901939146279 < 0.1
exited at when_all_processes_are_updated(): 6
exited at update_barrier.wait(): 3
None
exited at update_barrier.wait(): 5
None
exited at update_barrier.wait(): 7
None
exited at update_barrier.wait(): 4
None
exited at update_barrier.wait(): 0
None
exited at update_barrier.wait(): 8
None
[32m[I 2022-11-13 14:23:00,179][0m Trial 7 finished with value: -515.0416942541734 and parameters: {'activation': 2, 't_max': 2, 'hidden_size': 3, 'variance_scaling_factor': 1, 'permaban_threshold': 3, 'learning_rate_base': 2, 'learning_rate_exponent': 3, 'beta_base': 4, 'beta_exponent': 5}. Best is trial 7 with value: -515.0416942541734.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 3000, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 9e-05, 
        "beta": 9e-06, 
        "t_max": 50, 
        "activation": 0, 
        "hidden_size": 64, 
        "variance_scaling_factor": 0.01, 
        "permaban_threshold": 100, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 1017612908, 
    "outdir": "results", 
    "t_max": 50, 
    "beta": 9e-06, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 9e-05, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 100, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 0, 
}
{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -648.32, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"total_number_of_episodes": 30, "number_of_timesteps": 30000, "per_episode_reward": -639.92, "episode_reward_trend_value": 0.8396986881442217, "biggest_recent_change": NaN},
{"total_number_of_episodes": 40, "number_of_timesteps": 40000, "per_episode_reward": -634.4, "episode_reward_trend_value": 0.6957023806856512, "biggest_recent_change": NaN},
{"total_number_of_episodes": 50, "number_of_timesteps": 50000, "per_episode_reward": -637.12, "episode_reward_trend_value": 0.373120590186636, "biggest_recent_change": NaN},
{"total_number_of_episodes": 60, "number_of_timesteps": 60000, "per_episode_reward": -644.69, "episode_reward_trend_value": 0.09080002876201831, "biggest_recent_change": NaN},
{"total_number_of_episodes": 70, "number_of_timesteps": 70000, "per_episode_reward": -653.41, "episode_reward_trend_value": -0.1018573296135969, "biggest_recent_change": NaN},
{"total_number_of_episodes": 80, "number_of_timesteps": 80000, "per_episode_reward": -646.69, "episode_reward_trend_value": 0.02719865424205068, "biggest_recent_change": NaN},
{"total_number_of_episodes": 90, "number_of_timesteps": 90000, "per_episode_reward": -647.25, "episode_reward_trend_value": 0.01518873482896684, "biggest_recent_change": NaN},
{"total_number_of_episodes": 100, "number_of_timesteps": 100000, "per_episode_reward": -650.63, "episode_reward_trend_value": -0.028908908340821427, "biggest_recent_change": NaN},
{"total_number_of_episodes": 110, "number_of_timesteps": 110000, "per_episode_reward": -653.42, "episode_reward_trend_value": -0.056669217521313285, "biggest_recent_change": 8.724867631160578},
{"total_number_of_episodes": 120, "number_of_timesteps": 120000, "per_episode_reward": -650.56, "episode_reward_trend_value": -0.11821589913515078, "biggest_recent_change": 8.724867631160578},
{"total_number_of_episodes": 130, "number_of_timesteps": 130000, "per_episode_reward": -650.33, "episode_reward_trend_value": -0.17695029399993573, "biggest_recent_change": 8.724867631160578},
{"total_number_of_episodes": 140, "number_of_timesteps": 140000, "per_episode_reward": -650.11, "episode_reward_trend_value": -0.1443118519481345, "biggest_recent_change": 8.724867631160578},
{"total_number_of_episodes": 150, "number_of_timesteps": 150000, "per_episode_reward": -647.55, "episode_reward_trend_value": -0.03187435411789718, "biggest_recent_change": 8.724867631160578},
{"total_number_of_episodes": 160, "number_of_timesteps": 160000, "per_episode_reward": -648.98, "episode_reward_trend_value": 0.049269635578092316, "biggest_recent_change": 6.724785735202886},
{"total_number_of_episodes": 170, "number_of_timesteps": 170000, "per_episode_reward": -651.98, "episode_reward_trend_value": -0.058774531196125836, "biggest_recent_change": 3.375924105293393},
{"total_number_of_episodes": 180, "number_of_timesteps": 180000, "per_episode_reward": -654.33, "episode_reward_trend_value": -0.07860194969257969, "biggest_recent_change": 3.375924105293393},
{"total_number_of_episodes": 190, "number_of_timesteps": 190000, "per_episode_reward": -653.95, "episode_reward_trend_value": -0.036940666022451295, "biggest_recent_change": 2.9991892744767483},
{"total_number_of_episodes": 200, "number_of_timesteps": 200000, "per_episode_reward": -657.57, "episode_reward_trend_value": -0.046142589982441175, "biggest_recent_change": 3.6156900660515703},
{"total_number_of_episodes": 210, "number_of_timesteps": 210000, "per_episode_reward": -659.07, "episode_reward_trend_value": -0.09450302635350075, "biggest_recent_change": 3.6156900660515703},
{"total_number_of_episodes": 220, "number_of_timesteps": 220000, "per_episode_reward": -658.99, "episode_reward_trend_value": -0.09624121779519454, "biggest_recent_change": 3.6156900660515703},
{"total_number_of_episodes": 230, "number_of_timesteps": 230000, "per_episode_reward": -661.25, "episode_reward_trend_value": -0.12373516291521203, "biggest_recent_change": 3.6156900660515703},
{"total_number_of_episodes": 240, "number_of_timesteps": 240000, "per_episode_reward": -658.75, "episode_reward_trend_value": -0.12438610190671018, "biggest_recent_change": 3.6156900660515703},
{"total_number_of_episodes": 250, "number_of_timesteps": 250000, "per_episode_reward": -659.7, "episode_reward_trend_value": -0.11910269752691723, "biggest_recent_change": 3.6156900660515703},
{"total_number_of_episodes": 260, "number_of_timesteps": 260000, "per_episode_reward": -660.55, "episode_reward_trend_value": -0.09532369425705332, "biggest_recent_change": 3.6156900660515703},
{"total_number_of_episodes": 270, "number_of_timesteps": 270000, "per_episode_reward": -660.64, "episode_reward_trend_value": -0.07017373066996192, "biggest_recent_change": 3.6156900660515703},
{"total_number_of_episodes": 280, "number_of_timesteps": 280000, "per_episode_reward": -660.21, "episode_reward_trend_value": -0.06953459624731093, "biggest_recent_change": 3.6156900660515703},
{"total_number_of_episodes": 290, "number_of_timesteps": 290000, "per_episode_reward": -659.02, "episode_reward_trend_value": -0.016091691197414094, "biggest_recent_change": 2.499173740368178},
{"total_number_of_episodes": 300, "number_of_timesteps": 300000, "per_episode_reward": -661.08, "episode_reward_trend_value": -0.022419227316745744, "biggest_recent_change": 2.499173740368178},
{"total_number_of_episodes": 310, "number_of_timesteps": 310000, "per_episode_reward": -663.29, "episode_reward_trend_value": -0.04774137434588334, "biggest_recent_change": 2.499173740368178},
{"total_number_of_episodes": 320, "number_of_timesteps": 320000, "per_episode_reward": -596.68, "episode_reward_trend_value": 0.7174562546706069, "biggest_recent_change": 66.61036142723071},
{"total_number_of_episodes": 330, "number_of_timesteps": 330000, "per_episode_reward": -596.3, "episode_reward_trend_value": 0.6939129946224916, "biggest_recent_change": 66.61036142723071},
{"total_number_of_episodes": 340, "number_of_timesteps": 340000, "per_episode_reward": -596.92, "episode_reward_trend_value": 0.6975505531877337, "biggest_recent_change": 66.61036142723071},
{"total_number_of_episodes": 350, "number_of_timesteps": 350000, "per_episode_reward": -596.57, "episode_reward_trend_value": 0.7109736573333407, "biggest_recent_change": 66.61036142723071},
{"total_number_of_episodes": 360, "number_of_timesteps": 360000, "per_episode_reward": -595.87, "episode_reward_trend_value": 0.7196596234824104, "biggest_recent_change": 66.61036142723071},
{"total_number_of_episodes": 370, "number_of_timesteps": 370000, "per_episode_reward": -597.11, "episode_reward_trend_value": 0.7011714772155819, "biggest_recent_change": 66.61036142723071},
{"total_number_of_episodes": 380, "number_of_timesteps": 380000, "per_episode_reward": -597.87, "episode_reward_trend_value": 0.6794080362937255, "biggest_recent_change": 66.61036142723071},
{"total_number_of_episodes": 390, "number_of_timesteps": 390000, "per_episode_reward": -596.52, "episode_reward_trend_value": 0.7173402527767065, "biggest_recent_change": 66.61036142723071},
{"total_number_of_episodes": 400, "number_of_timesteps": 400000, "per_episode_reward": -595.65, "episode_reward_trend_value": 0.7515212318253058, "biggest_recent_change": 66.61036142723071},
{"total_number_of_episodes": 410, "number_of_timesteps": 410000, "per_episode_reward": -595.65, "episode_reward_trend_value": 0.01145551555213918, "biggest_recent_change": 1.3497674955299317},
{"total_number_of_episodes": 420, "number_of_timesteps": 420000, "per_episode_reward": -594.87, "episode_reward_trend_value": 0.015850230142557896, "biggest_recent_change": 1.3497674955299317},
{"total_number_of_episodes": 430, "number_of_timesteps": 430000, "per_episode_reward": -594.92, "episode_reward_trend_value": 0.022166832219991446, "biggest_recent_change": 1.3497674955299317},
{"total_number_of_episodes": 440, "number_of_timesteps": 440000, "per_episode_reward": -594.27, "episode_reward_trend_value": 0.025511922085634825, "biggest_recent_change": 1.3497674955299317},
{"total_number_of_episodes": 450, "number_of_timesteps": 450000, "per_episode_reward": -595.51, "episode_reward_trend_value": 0.00400842703557929, "biggest_recent_change": 1.3497674955299317},
{"total_number_of_episodes": 460, "number_of_timesteps": 460000, "per_episode_reward": -595.23, "episode_reward_trend_value": 0.020884580393774537, "biggest_recent_change": 1.3497674955299317},
{"total_number_of_episodes": 470, "number_of_timesteps": 470000, "per_episode_reward": -593.9, "episode_reward_trend_value": 0.044078467131166435, "biggest_recent_change": 1.3497674955299317},
{"total_number_of_episodes": 480, "number_of_timesteps": 480000, "per_episode_reward": -593.94, "episode_reward_trend_value": 0.028649577965342767, "biggest_recent_change": 1.322911511837333},
{"total_number_of_episodes": 490, "number_of_timesteps": 490000, "per_episode_reward": -592.89, "episode_reward_trend_value": 0.03062965354661426, "biggest_recent_change": 1.322911511837333},
{"total_number_of_episodes": 500, "number_of_timesteps": 500000, "per_episode_reward": -592.26, "episode_reward_trend_value": 0.0376221792818026, "biggest_recent_change": 1.322911511837333},
{"total_number_of_episodes": 510, "number_of_timesteps": 510000, "per_episode_reward": -592.03, "episode_reward_trend_value": 0.031533530665588685, "biggest_recent_change": 1.322911511837333},
{"total_number_of_episodes": 520, "number_of_timesteps": 520000, "per_episode_reward": -592.78, "episode_reward_trend_value": 0.02378867536993615, "biggest_recent_change": 1.322911511837333},
{"total_number_of_episodes": 530, "number_of_timesteps": 530000, "per_episode_reward": -593.3, "episode_reward_trend_value": 0.01081585514492897, "biggest_recent_change": 1.322911511837333},
{"total_number_of_episodes": 540, "number_of_timesteps": 540000, "per_episode_reward": -594.38, "episode_reward_trend_value": 0.012653743989440297, "biggest_recent_change": 1.322911511837333},
{"total_number_of_episodes": 550, "number_of_timesteps": 550000, "per_episode_reward": -595.66, "episode_reward_trend_value": -0.00476847881679987, "biggest_recent_change": 1.322911511837333},
{"total_number_of_episodes": 560, "number_of_timesteps": 560000, "per_episode_reward": -595.34, "episode_reward_trend_value": -0.015949153233005595, "biggest_recent_change": 1.2819658912818568},
{"total_number_of_episodes": 570, "number_of_timesteps": 570000, "per_episode_reward": -595.38, "episode_reward_trend_value": -0.01596992606145654, "biggest_recent_change": 1.2819658912818568},
{"total_number_of_episodes": 580, "number_of_timesteps": 580000, "per_episode_reward": -595.66, "episode_reward_trend_value": -0.030787363247612932, "biggest_recent_change": 1.2819658912818568},
{"total_number_of_episodes": 590, "number_of_timesteps": 590000, "per_episode_reward": -595.62, "episode_reward_trend_value": -0.03737212156593286, "biggest_recent_change": 1.2819658912818568},
{"total_number_of_episodes": 600, "number_of_timesteps": 600000, "per_episode_reward": -594.91, "episode_reward_trend_value": -0.03198588462861128, "biggest_recent_change": 1.2819658912818568},
{"total_number_of_episodes": 610, "number_of_timesteps": 610000, "per_episode_reward": -594.22, "episode_reward_trend_value": -0.016037058371723055, "biggest_recent_change": 1.2819658912818568},
{"total_number_of_episodes": 620, "number_of_timesteps": 620000, "per_episode_reward": -595.14, "episode_reward_trend_value": -0.02049246859260418, "biggest_recent_change": 1.2819658912818568},
{"total_number_of_episodes": 630, "number_of_timesteps": 630000, "per_episode_reward": -595.95, "episode_reward_trend_value": -0.017482538351048838, "biggest_recent_change": 1.2819658912818568},
{"total_number_of_episodes": 640, "number_of_timesteps": 640000, "per_episode_reward": -595.45, "episode_reward_trend_value": 0.002264380291006142, "biggest_recent_change": 0.9184822593064155},
{"total_number_of_episodes": 650, "number_of_timesteps": 650000, "per_episode_reward": -594.42, "episode_reward_trend_value": 0.010218919856050787, "biggest_recent_change": 1.032559375232836},
{"total_number_of_episodes": 660, "number_of_timesteps": 660000, "per_episode_reward": -594.27, "episode_reward_trend_value": 0.012318313392015372, "biggest_recent_change": 1.032559375232836},
{"total_number_of_episodes": 670, "number_of_timesteps": 670000, "per_episode_reward": -594.19, "episode_reward_trend_value": 0.01641803755645823, "biggest_recent_change": 1.032559375232836},
{"total_number_of_episodes": 680, "number_of_timesteps": 680000, "per_episode_reward": -594.07, "episode_reward_trend_value": 0.017207927911008232, "biggest_recent_change": 1.032559375232836},
{"total_number_of_episodes": 690, "number_of_timesteps": 690000, "per_episode_reward": -594.83, "episode_reward_trend_value": 0.0008848157968903555, "biggest_recent_change": 1.032559375232836},
{"total_number_of_episodes": 700, "number_of_timesteps": 700000, "per_episode_reward": -594.56, "episode_reward_trend_value": -0.00378087696132449, "biggest_recent_change": 1.032559375232836},
{"total_number_of_episodes": 710, "number_of_timesteps": 710000, "per_episode_reward": -594.67, "episode_reward_trend_value": 0.00522164308780854, "biggest_recent_change": 1.032559375232836},
{"total_number_of_episodes": 720, "number_of_timesteps": 720000, "per_episode_reward": -595.09, "episode_reward_trend_value": 0.009545362512823077, "biggest_recent_change": 1.032559375232836},
{"total_number_of_episodes": 730, "number_of_timesteps": 730000, "per_episode_reward": -594.7, "episode_reward_trend_value": 0.008375940090997524, "biggest_recent_change": 1.032559375232836},
{"total_number_of_episodes": 740, "number_of_timesteps": 740000, "per_episode_reward": -594.95, "episode_reward_trend_value": -0.0059171823612587104, "biggest_recent_change": 0.7564924921954344},
{"total_number_of_episodes": 750, "number_of_timesteps": 750000, "per_episode_reward": -595.11, "episode_reward_trend_value": -0.009360588285109214, "biggest_recent_change": 0.7564924921954344},
{"total_number_of_episodes": 760, "number_of_timesteps": 760000, "per_episode_reward": -529.75, "episode_reward_trend_value": 0.7159940845224899, "biggest_recent_change": 65.3673560294834},
{"total_number_of_episodes": 770, "number_of_timesteps": 770000, "per_episode_reward": -529.96, "episode_reward_trend_value": 0.7123347217153094, "biggest_recent_change": 65.3673560294834},
{"total_number_of_episodes": 780, "number_of_timesteps": 780000, "per_episode_reward": -530.2, "episode_reward_trend_value": 0.7180713005650798, "biggest_recent_change": 65.3673560294834},
{"total_number_of_episodes": 790, "number_of_timesteps": 790000, "per_episode_reward": -530.1, "episode_reward_trend_value": 0.716240840855835, "biggest_recent_change": 65.3673560294834},
{"total_number_of_episodes": 800, "number_of_timesteps": 800000, "per_episode_reward": -530.02, "episode_reward_trend_value": 0.7183556431266084, "biggest_recent_change": 65.3673560294834},
{"total_number_of_episodes": 810, "number_of_timesteps": 810000, "per_episode_reward": -530.13, "episode_reward_trend_value": 0.7218168586111562, "biggest_recent_change": 65.3673560294834},
{"total_number_of_episodes": 820, "number_of_timesteps": 820000, "per_episode_reward": -530.33, "episode_reward_trend_value": 0.7151909684289649, "biggest_recent_change": 65.3673560294834},
{"total_number_of_episodes": 830, "number_of_timesteps": 830000, "per_episode_reward": -530.38, "episode_reward_trend_value": 0.7174448445076387, "biggest_recent_change": 65.3673560294834},
{"total_number_of_episodes": 840, "number_of_timesteps": 840000, "per_episode_reward": -530.96, "episode_reward_trend_value": 0.712867193819664, "biggest_recent_change": 65.3673560294834},
{"total_number_of_episodes": 850, "number_of_timesteps": 850000, "per_episode_reward": -530.58, "episode_reward_trend_value": -0.009254939959496116, "biggest_recent_change": 0.5736517607822407},
{"total_number_of_episodes": 860, "number_of_timesteps": 860000, "per_episode_reward": -530.67, "episode_reward_trend_value": -0.00780022210450271, "biggest_recent_change": 0.5736517607822407},
{"total_number_of_episodes": 870, "number_of_timesteps": 870000, "per_episode_reward": -530.61, "episode_reward_trend_value": -0.0045148060095256265, "biggest_recent_change": 0.5736517607822407},
{"total_number_of_episodes": 880, "number_of_timesteps": 880000, "per_episode_reward": -530.29, "episode_reward_trend_value": -0.0021107996389282055, "biggest_recent_change": 0.5736517607822407},
{"total_number_of_episodes": 890, "number_of_timesteps": 890000, "per_episode_reward": -530.26, "episode_reward_trend_value": -0.002678372518161925, "biggest_recent_change": 0.5736517607822407},
{"total_number_of_episodes": 900, "number_of_timesteps": 900000, "per_episode_reward": -530.27, "episode_reward_trend_value": -0.00159523222743903, "biggest_recent_change": 0.5736517607822407},
{"total_number_of_episodes": 910, "number_of_timesteps": 910000, "per_episode_reward": -530.11, "episode_reward_trend_value": 0.002492049436101398, "biggest_recent_change": 0.5736517607822407},
{"total_number_of_episodes": 920, "number_of_timesteps": 920000, "per_episode_reward": -530.17, "episode_reward_trend_value": 0.002335949021797508, "biggest_recent_change": 0.5736517607822407},
{"total_number_of_episodes": 930, "number_of_timesteps": 930000, "per_episode_reward": -530.08, "episode_reward_trend_value": 0.009724439500214682, "biggest_recent_change": 0.3763639893589925},
{"total_number_of_episodes": 940, "number_of_timesteps": 940000, "per_episode_reward": -529.92, "episode_reward_trend_value": 0.00734796123773928, "biggest_recent_change": 0.3195365312942613},
{"total_number_of_episodes": 950, "number_of_timesteps": 950000, "per_episode_reward": -530.07, "episode_reward_trend_value": 0.006613645721152908, "biggest_recent_change": 0.3195365312942613},
{"total_number_of_episodes": 960, "number_of_timesteps": 960000, "per_episode_reward": -529.97, "episode_reward_trend_value": 0.00712909931645653, "biggest_recent_change": 0.3195365312942613},
{"total_number_of_episodes": 970, "number_of_timesteps": 970000, "per_episode_reward": -529.79, "episode_reward_trend_value": 0.0055857008779905, "biggest_recent_change": 0.1806306718323185},
{"total_number_of_episodes": 980, "number_of_timesteps": 980000, "per_episode_reward": -530.2, "episode_reward_trend_value": 0.0007217690093802452, "biggest_recent_change": 0.40675867782078967},
{"total_number_of_episodes": 990, "number_of_timesteps": 990000, "per_episode_reward": -529.62, "episode_reward_trend_value": 0.007230155224194984, "biggest_recent_change": 0.576928885678285},
{"total_number_of_episodes": 1000, "number_of_timesteps": 1000000, "per_episode_reward": -529.96, "episode_reward_trend_value": 0.0016241177938683096, "biggest_recent_change": 0.576928885678285},
{"total_number_of_episodes": 1010, "number_of_timesteps": 1010000, "per_episode_reward": -529.36, "episode_reward_trend_value": 0.009039165345747177, "biggest_recent_change": 0.602332443992168},
{"total_number_of_episodes": 1020, "number_of_timesteps": 1020000, "per_episode_reward": -529.72, "episode_reward_trend_value": 0.003971986935968946, "biggest_recent_change": 0.602332443992168},
{"total_number_of_episodes": 1030, "number_of_timesteps": 1030000, "per_episode_reward": -529.59, "episode_reward_trend_value": 0.003608891515452544, "biggest_recent_change": 0.602332443992168},
{"total_number_of_episodes": 1040, "number_of_timesteps": 1040000, "per_episode_reward": -529.77, "episode_reward_trend_value": 0.003334326304731247, "biggest_recent_change": 0.602332443992168},
{"total_number_of_episodes": 1050, "number_of_timesteps": 1050000, "per_episode_reward": -530.05, "episode_reward_trend_value": -0.0008734495642822063, "biggest_recent_change": 0.602332443992168},
{"total_number_of_episodes": 1060, "number_of_timesteps": 1060000, "per_episode_reward": -529.94, "episode_reward_trend_value": -0.0016880852023872547, "biggest_recent_change": 0.602332443992168},
{"total_number_of_episodes": 1070, "number_of_timesteps": 1070000, "per_episode_reward": -530.55, "episode_reward_trend_value": -0.003953297920376523, "biggest_recent_change": 0.6106278224398238},
{"total_number_of_episodes": 1080, "number_of_timesteps": 1080000, "per_episode_reward": -530.21, "episode_reward_trend_value": -0.006557525754472711, "biggest_recent_change": 0.6106278224398238},
{"total_number_of_episodes": 1090, "number_of_timesteps": 1090000, "per_episode_reward": -530.26, "episode_reward_trend_value": -0.003298328316888425, "biggest_recent_change": 0.6106278224398238},
{"total_number_of_episodes": 1100, "number_of_timesteps": 1100000, "per_episode_reward": -530.61, "episode_reward_trend_value": -0.013908697742659923, "biggest_recent_change": 0.6106278224398238},
{"total_number_of_episodes": 1110, "number_of_timesteps": 1110000, "per_episode_reward": -531.44, "episode_reward_trend_value": -0.019081086136395697, "biggest_recent_change": 0.8302486300409555},
{"total_number_of_episodes": 1120, "number_of_timesteps": 1120000, "per_episode_reward": -530.85, "episode_reward_trend_value": -0.013906397340603385, "biggest_recent_change": 0.8302486300409555},
{"total_number_of_episodes": 1130, "number_of_timesteps": 1130000, "per_episode_reward": -530.39, "episode_reward_trend_value": -0.0069120915294926515, "biggest_recent_change": 0.8302486300409555},
{"total_number_of_episodes": 1140, "number_of_timesteps": 1140000, "per_episode_reward": -530.19, "episode_reward_trend_value": -0.0015900894156970935, "biggest_recent_change": 0.8302486300409555},
{"total_number_of_episodes": 1150, "number_of_timesteps": 1150000, "per_episode_reward": -530.34, "episode_reward_trend_value": -0.0043845114182002164, "biggest_recent_change": 0.8302486300409555},
{"total_number_of_episodes": 1160, "number_of_timesteps": 1160000, "per_episode_reward": -463.9, "episode_reward_trend_value": 0.7405603215854614, "biggest_recent_change": 66.43440714788971},
{"total_number_of_episodes": 1170, "number_of_timesteps": 1170000, "per_episode_reward": -464.04, "episode_reward_trend_value": 0.73522942129533, "biggest_recent_change": 66.43440714788971},
{"total_number_of_episodes": 1180, "number_of_timesteps": 1180000, "per_episode_reward": -463.95, "episode_reward_trend_value": 0.7367675221402818, "biggest_recent_change": 66.43440714788971},
{"total_number_of_episodes": 1190, "number_of_timesteps": 1190000, "per_episode_reward": -463.57, "episode_reward_trend_value": 0.7448739719620998, "biggest_recent_change": 66.43440714788971},
{"total_number_of_episodes": 1200, "number_of_timesteps": 1200000, "per_episode_reward": -463.71, "episode_reward_trend_value": 0.7525724741024773, "biggest_recent_change": 66.43440714788971},
{"total_number_of_episodes": 1210, "number_of_timesteps": 1210000, "per_episode_reward": -463.56, "episode_reward_trend_value": 0.7475808453639047, "biggest_recent_change": 66.43440714788971},
{"total_number_of_episodes": 1220, "number_of_timesteps": 1220000, "per_episode_reward": -463.81, "episode_reward_trend_value": 0.7398402815300175, "biggest_recent_change": 66.43440714788971},
{"total_number_of_episodes": 1230, "number_of_timesteps": 1230000, "per_episode_reward": -463.98, "episode_reward_trend_value": 0.7356704110368735, "biggest_recent_change": 66.43440714788971},
{"total_number_of_episodes": 1240, "number_of_timesteps": 1240000, "per_episode_reward": -463.73, "episode_reward_trend_value": 0.7400676428038246, "biggest_recent_change": 66.43440714788971},
{"total_number_of_episodes": 1250, "number_of_timesteps": 1250000, "per_episode_reward": -463.6, "episode_reward_trend_value": 0.0033410710742644927, "biggest_recent_change": 0.3769796796363494},
{"total_number_of_episodes": 1260, "number_of_timesteps": 1260000, "per_episode_reward": -463.47, "episode_reward_trend_value": 0.006294107284606475, "biggest_recent_change": 0.3769796796363494},
{"total_number_of_episodes": 1270, "number_of_timesteps": 1270000, "per_episode_reward": -463.64, "episode_reward_trend_value": 0.003426849996981218, "biggest_recent_change": 0.3769796796363494},
{"total_number_of_episodes": 1280, "number_of_timesteps": 1280000, "per_episode_reward": -463.51, "episode_reward_trend_value": 0.0007440468005976679, "biggest_recent_change": 0.25156634320319426},
{"total_number_of_episodes": 1290, "number_of_timesteps": 1290000, "per_episode_reward": -463.73, "episode_reward_trend_value": -0.00022031418693902399, "biggest_recent_change": 0.25156634320319426},
{"total_number_of_episodes": 1300, "number_of_timesteps": 1300000, "per_episode_reward": -463.41, "episode_reward_trend_value": 0.001734794995211865, "biggest_recent_change": 0.32223758943308667},
{"total_number_of_episodes": 1310, "number_of_timesteps": 1310000, "per_episode_reward": -463.39, "episode_reward_trend_value": 0.004660390135003607, "biggest_recent_change": 0.32223758943308667},
{"total_number_of_episodes": 1320, "number_of_timesteps": 1320000, "per_episode_reward": -463.59, "episode_reward_trend_value": 0.004342338640760899, "biggest_recent_change": 0.32223758943308667},
{"total_number_of_episodes": 1330, "number_of_timesteps": 1330000, "per_episode_reward": -463.41, "episode_reward_trend_value": 0.003553181065431469, "biggest_recent_change": 0.32223758943308667},
{"total_number_of_episodes": 1340, "number_of_timesteps": 1340000, "per_episode_reward": -463.7, "episode_reward_trend_value": -0.001100824529092708, "biggest_recent_change": 0.32223758943308667},
{"total_number_of_episodes": 1350, "number_of_timesteps": 1350000, "per_episode_reward": -463.29, "episode_reward_trend_value": 0.001989838280264343, "biggest_recent_change": 0.4067002662707182},
{"total_number_of_episodes": 1360, "number_of_timesteps": 1360000, "per_episode_reward": -463.25, "episode_reward_trend_value": 0.004303130419937259, "biggest_recent_change": 0.4067002662707182},
{"total_number_of_episodes": 1370, "number_of_timesteps": 1370000, "per_episode_reward": -462.92, "episode_reward_trend_value": 0.00648909722399872, "biggest_recent_change": 0.4067002662707182},
{"total_number_of_episodes": 1380, "number_of_timesteps": 1380000, "per_episode_reward": -462.78, "episode_reward_trend_value": 0.010537131580223204, "biggest_recent_change": 0.4067002662707182},
{"total_number_of_episodes": 1390, "number_of_timesteps": 1390000, "per_episode_reward": -462.81, "episode_reward_trend_value": 0.006691026083272947, "biggest_recent_change": 0.4067002662707182},
{"total_number_of_episodes": 1400, "number_of_timesteps": 1400000, "per_episode_reward": -463.24, "episode_reward_trend_value": 0.0016562614302327145, "biggest_recent_change": 0.4339696273233926},
{"total_number_of_episodes": 1410, "number_of_timesteps": 1410000, "per_episode_reward": -463.74, "episode_reward_trend_value": -0.0016266112306798023, "biggest_recent_change": 0.49721327990738473},
{"total_number_of_episodes": 1420, "number_of_timesteps": 1420000, "per_episode_reward": -463.3, "episode_reward_trend_value": 0.0011879582987281386, "biggest_recent_change": 0.49721327990738473},
{"total_number_of_episodes": 1430, "number_of_timesteps": 1430000, "per_episode_reward": -463.6, "episode_reward_trend_value": 0.001122402420337999, "biggest_recent_change": 0.49721327990738473},
{"total_number_of_episodes": 1440, "number_of_timesteps": 1440000, "per_episode_reward": -463.62, "episode_reward_trend_value": -0.0036123150112555577, "biggest_recent_change": 0.49721327990738473},
{"total_number_of_episodes": 1450, "number_of_timesteps": 1450000, "per_episode_reward": -463.58, "episode_reward_trend_value": -0.0036385933841302175, "biggest_recent_change": 0.49721327990738473},
{"total_number_of_episodes": 1460, "number_of_timesteps": 1460000, "per_episode_reward": -463.35, "episode_reward_trend_value": -0.004761083609235407, "biggest_recent_change": 0.49721327990738473},
{"total_number_of_episodes": 1470, "number_of_timesteps": 1470000, "per_episode_reward": -463.33, "episode_reward_trend_value": -0.006111090557922378, "biggest_recent_change": 0.49721327990738473},
{"total_number_of_episodes": 1480, "number_of_timesteps": 1480000, "per_episode_reward": -462.8, "episode_reward_trend_value": 4.5433645460156586e-05, "biggest_recent_change": 0.5301752730119915},
{"total_number_of_episodes": 1490, "number_of_timesteps": 1490000, "per_episode_reward": -463.16, "episode_reward_trend_value": 0.0008469573952646038, "biggest_recent_change": 0.5301752730119915},
{"total_number_of_episodes": 1500, "number_of_timesteps": 1500000, "per_episode_reward": -462.69, "episode_reward_trend_value": 0.011601010020317265, "biggest_recent_change": 0.5301752730119915},
{"total_number_of_episodes": 1510, "number_of_timesteps": 1510000, "per_episode_reward": -462.93, "episode_reward_trend_value": 0.00419543338080454, "biggest_recent_change": 0.5301752730119915},
{"total_number_of_episodes": 1520, "number_of_timesteps": 1520000, "per_episode_reward": -462.92, "episode_reward_trend_value": 0.0075347932510295675, "biggest_recent_change": 0.5301752730119915},
{"total_number_of_episodes": 1530, "number_of_timesteps": 1530000, "per_episode_reward": -463.08, "episode_reward_trend_value": 0.0059965987727770825, "biggest_recent_change": 0.5301752730119915},
{"total_number_of_episodes": 1540, "number_of_timesteps": 1540000, "per_episode_reward": -462.97, "episode_reward_trend_value": 0.006745124816577824, "biggest_recent_change": 0.5301752730119915},
{"total_number_of_episodes": 1550, "number_of_timesteps": 1550000, "per_episode_reward": -462.53, "episode_reward_trend_value": 0.009083260158144589, "biggest_recent_change": 0.5301752730119915},
{"total_number_of_episodes": 1560, "number_of_timesteps": 1560000, "per_episode_reward": -462.87, "episode_reward_trend_value": 0.005155737801052536, "biggest_recent_change": 0.5301752730119915},
{"total_number_of_episodes": 1570, "number_of_timesteps": 1570000, "per_episode_reward": -462.84, "episode_reward_trend_value": -0.00045850330558513025, "biggest_recent_change": 0.4706514563473547},
{"total_number_of_episodes": 1580, "number_of_timesteps": 1580000, "per_episode_reward": -462.86, "episode_reward_trend_value": 0.0033893002258417308, "biggest_recent_change": 0.4706514563473547},
{"total_number_of_episodes": 1590, "number_of_timesteps": 1590000, "per_episode_reward": -462.57, "episode_reward_trend_value": 0.0013940192745767236, "biggest_recent_change": 0.441672464808903},
{"total_number_of_episodes": 1600, "number_of_timesteps": 1600000, "per_episode_reward": -462.66, "episode_reward_trend_value": 0.0029819020703175485, "biggest_recent_change": 0.441672464808903},
{"total_number_of_episodes": 1610, "number_of_timesteps": 1610000, "per_episode_reward": -462.78, "episode_reward_trend_value": 0.0015929567110624196, "biggest_recent_change": 0.441672464808903},
{"total_number_of_episodes": 1620, "number_of_timesteps": 1620000, "per_episode_reward": -462.74, "episode_reward_trend_value": 0.0037969317615635296, "biggest_recent_change": 0.441672464808903},
{"total_number_of_episodes": 1630, "number_of_timesteps": 1630000, "per_episode_reward": -462.94, "episode_reward_trend_value": 0.000431014245306945, "biggest_recent_change": 0.441672464808903},
{"total_number_of_episodes": 1640, "number_of_timesteps": 1640000, "per_episode_reward": -463.15, "episode_reward_trend_value": -0.006904332642066417, "biggest_recent_change": 0.3348304717451924},
{"total_number_of_episodes": 1650, "number_of_timesteps": 1650000, "per_episode_reward": -463.04, "episode_reward_trend_value": -0.0018941878934880506, "biggest_recent_change": 0.2910761707335041},
{"total_number_of_episodes": 1660, "number_of_timesteps": 1660000, "per_episode_reward": -463.0, "episode_reward_trend_value": -0.001762076410164405, "biggest_recent_change": 0.2910761707335041},
{"total_number_of_episodes": 1670, "number_of_timesteps": 1670000, "per_episode_reward": -463.09, "episode_reward_trend_value": -0.0025583877306435926, "biggest_recent_change": 0.2910761707335041},
{"total_number_of_episodes": 1680, "number_of_timesteps": 1680000, "per_episode_reward": -463.2, "episode_reward_trend_value": -0.007088523646568648, "biggest_recent_change": 0.21850875505469958},
{"total_number_of_episodes": 1690, "number_of_timesteps": 1690000, "per_episode_reward": -463.18, "episode_reward_trend_value": -0.005838125285847203, "biggest_recent_change": 0.21850875505469958},
{"total_number_of_episodes": 1700, "number_of_timesteps": 1700000, "per_episode_reward": -463.34, "episode_reward_trend_value": -0.00622996349846403, "biggest_recent_change": 0.21850875505469958},
{"total_number_of_episodes": 1710, "number_of_timesteps": 1710000, "per_episode_reward": -463.66, "episode_reward_trend_value": -0.010231608250199998, "biggest_recent_change": 0.31965207872656265},
{"total_number_of_episodes": 1720, "number_of_timesteps": 1720000, "per_episode_reward": -464.22, "episode_reward_trend_value": -0.014299138081405418, "biggest_recent_change": 0.5651173556448725},
{"total_number_of_episodes": 1730, "number_of_timesteps": 1730000, "per_episode_reward": -464.43, "episode_reward_trend_value": -0.014196222961773072, "biggest_recent_change": 0.5651173556448725},
{"total_number_of_episodes": 1740, "number_of_timesteps": 1740000, "per_episode_reward": -464.65, "episode_reward_trend_value": -0.017865123769296234, "biggest_recent_change": 0.5651173556448725},
{"total_number_of_episodes": 1750, "number_of_timesteps": 1750000, "per_episode_reward": -464.73, "episode_reward_trend_value": -0.019217167362075495, "biggest_recent_change": 0.5651173556448725},
{"total_number_of_episodes": 1760, "number_of_timesteps": 1760000, "per_episode_reward": -464.94, "episode_reward_trend_value": -0.020541507616486064, "biggest_recent_change": 0.5651173556448725},
{"total_number_of_episodes": 1770, "number_of_timesteps": 1770000, "per_episode_reward": -464.83, "episode_reward_trend_value": -0.018100031983006047, "biggest_recent_change": 0.5651173556448725},
{"total_number_of_episodes": 1780, "number_of_timesteps": 1780000, "per_episode_reward": -465.05, "episode_reward_trend_value": -0.02080098237047423, "biggest_recent_change": 0.5651173556448725},
{"total_number_of_episodes": 1790, "number_of_timesteps": 1790000, "per_episode_reward": -465.2, "episode_reward_trend_value": -0.020687756768885242, "biggest_recent_change": 0.5651173556448725},
{"total_number_of_episodes": 1800, "number_of_timesteps": 1800000, "per_episode_reward": -465.28, "episode_reward_trend_value": -0.01807388395836824, "biggest_recent_change": 0.5651173556448725},
{"total_number_of_episodes": 1810, "number_of_timesteps": 1810000, "per_episode_reward": -465.41, "episode_reward_trend_value": -0.01323665307471692, "biggest_recent_change": 0.2202887092764172},
{"total_number_of_episodes": 1820, "number_of_timesteps": 1820000, "per_episode_reward": -465.56, "episode_reward_trend_value": -0.012495440074132426, "biggest_recent_change": 0.2202887092764172},
{"total_number_of_episodes": 1830, "number_of_timesteps": 1830000, "per_episode_reward": -465.64, "episode_reward_trend_value": -0.011102303560644107, "biggest_recent_change": 0.2202887092764172},
{"total_number_of_episodes": 1840, "number_of_timesteps": 1840000, "per_episode_reward": -465.84, "episode_reward_trend_value": -0.01237706246706946, "biggest_recent_change": 0.2202887092764172},
{"total_number_of_episodes": 1850, "number_of_timesteps": 1850000, "per_episode_reward": -465.94, "episode_reward_trend_value": -0.011114731929611328, "biggest_recent_change": 0.2202887092764172},
{"total_number_of_episodes": 1860, "number_of_timesteps": 1860000, "per_episode_reward": -465.99, "episode_reward_trend_value": -0.012858355547779688, "biggest_recent_change": 0.2202887092764172},
{"total_number_of_episodes": 1870, "number_of_timesteps": 1870000, "per_episode_reward": -466.19, "episode_reward_trend_value": -0.012621699922232842, "biggest_recent_change": 0.19962861801468534},
{"total_number_of_episodes": 1880, "number_of_timesteps": 1880000, "per_episode_reward": -466.16, "episode_reward_trend_value": -0.010681638869904949, "biggest_recent_change": 0.19962861801468534},
{"total_number_of_episodes": 1890, "number_of_timesteps": 1890000, "per_episode_reward": -466.39, "episode_reward_trend_value": -0.012326937272814576, "biggest_recent_change": 0.23248038204189925},
{"total_number_of_episodes": 1900, "number_of_timesteps": 1900000, "per_episode_reward": -466.2, "episode_reward_trend_value": -0.00876479568342145, "biggest_recent_change": 0.23248038204189925},
{"total_number_of_episodes": 1910, "number_of_timesteps": 1910000, "per_episode_reward": -466.46, "episode_reward_trend_value": -0.010077206840399337, "biggest_recent_change": 0.26065422836319385},
{"total_number_of_episodes": 1920, "number_of_timesteps": 1920000, "per_episode_reward": -466.41, "episode_reward_trend_value": -0.008490512534408228, "biggest_recent_change": 0.26065422836319385},
{"total_number_of_episodes": 1930, "number_of_timesteps": 1930000, "per_episode_reward": -466.48, "episode_reward_trend_value": -0.007112902962087572, "biggest_recent_change": 0.26065422836319385},
{"total_number_of_episodes": 1940, "number_of_timesteps": 1940000, "per_episode_reward": -466.45, "episode_reward_trend_value": -0.005700758336339125, "biggest_recent_change": 0.26065422836319385},
{"total_number_of_episodes": 1950, "number_of_timesteps": 1950000, "per_episode_reward": -466.67, "episode_reward_trend_value": -0.007513664417105145, "biggest_recent_change": 0.26065422836319385},
{"total_number_of_episodes": 1960, "number_of_timesteps": 1960000, "per_episode_reward": -466.62, "episode_reward_trend_value": -0.004831286643382606, "biggest_recent_change": 0.26065422836319385},
{"total_number_of_episodes": 1970, "number_of_timesteps": 1970000, "per_episode_reward": -466.74, "episode_reward_trend_value": -0.006483082376351174, "biggest_recent_change": 0.26065422836319385},
{"total_number_of_episodes": 1980, "number_of_timesteps": 1980000, "per_episode_reward": -466.62, "episode_reward_trend_value": -0.002537925964722692, "biggest_recent_change": 0.26065422836319385},
{"total_number_of_episodes": 1990, "number_of_timesteps": 1990000, "per_episode_reward": -466.58, "episode_reward_trend_value": -0.0042387701396389985, "biggest_recent_change": 0.26065422836319385},
{"total_number_of_episodes": 2000, "number_of_timesteps": 2000000, "per_episode_reward": -466.32, "episode_reward_trend_value": 0.0015935252117155112, "biggest_recent_change": 0.264252353258712},
{"total_number_of_episodes": 2010, "number_of_timesteps": 2010000, "per_episode_reward": -466.47, "episode_reward_trend_value": -0.0007135345366704214, "biggest_recent_change": 0.264252353258712},
{"total_number_of_episodes": 2020, "number_of_timesteps": 2020000, "per_episode_reward": -466.47, "episode_reward_trend_value": 0.00013806517200691814, "biggest_recent_change": 0.264252353258712},
{"total_number_of_episodes": 2030, "number_of_timesteps": 2030000, "per_episode_reward": -466.48, "episode_reward_trend_value": -0.00030387829024915744, "biggest_recent_change": 0.264252353258712},
{"total_number_of_episodes": 2040, "number_of_timesteps": 2040000, "per_episode_reward": -466.6, "episode_reward_trend_value": 0.0007067445688562657, "biggest_recent_change": 0.264252353258712},
{"total_number_of_episodes": 2050, "number_of_timesteps": 2050000, "per_episode_reward": -466.72, "episode_reward_trend_value": -0.0010348125315267176, "biggest_recent_change": 0.264252353258712},
{"total_number_of_episodes": 2060, "number_of_timesteps": 2060000, "per_episode_reward": -466.71, "episode_reward_trend_value": 0.0003720683587068329, "biggest_recent_change": 0.264252353258712},
{"total_number_of_episodes": 2070, "number_of_timesteps": 2070000, "per_episode_reward": -466.7, "episode_reward_trend_value": -0.0008656777114285634, "biggest_recent_change": 0.264252353258712},
{"total_number_of_episodes": 2080, "number_of_timesteps": 2080000, "per_episode_reward": -466.57, "episode_reward_trend_value": 0.00012183810759501689, "biggest_recent_change": 0.264252353258712},
{"total_number_of_episodes": 2090, "number_of_timesteps": 2090000, "per_episode_reward": -466.55, "episode_reward_trend_value": -0.002598516043230524, "biggest_recent_change": 0.1535691206518095},
{"total_number_of_episodes": 2100, "number_of_timesteps": 2100000, "per_episode_reward": -466.42, "episode_reward_trend_value": 0.0005506296426890206, "biggest_recent_change": 0.12985399108094953},
{"total_number_of_episodes": 2110, "number_of_timesteps": 2110000, "per_episode_reward": -466.4, "episode_reward_trend_value": 0.0008174880637903294, "biggest_recent_change": 0.12985399108094953},
{"total_number_of_episodes": 2120, "number_of_timesteps": 2120000, "per_episode_reward": -466.45, "episode_reward_trend_value": 0.0003148132048623767, "biggest_recent_change": 0.12985399108094953},
{"total_number_of_episodes": 2130, "number_of_timesteps": 2130000, "per_episode_reward": -466.26, "episode_reward_trend_value": 0.0038350515002371645, "biggest_recent_change": 0.19078657631257556},
{"total_number_of_episodes": 2140, "number_of_timesteps": 2140000, "per_episode_reward": -466.4, "episode_reward_trend_value": 0.003522932364114695, "biggest_recent_change": 0.19078657631257556},
{"total_number_of_episodes": 2150, "number_of_timesteps": 2150000, "per_episode_reward": -466.57, "episode_reward_trend_value": 0.0016078639573006766, "biggest_recent_change": 0.19078657631257556},
{"total_number_of_episodes": 2160, "number_of_timesteps": 2160000, "per_episode_reward": -466.45, "episode_reward_trend_value": 0.002797961579570559, "biggest_recent_change": 0.19078657631257556},
{"total_number_of_episodes": 2170, "number_of_timesteps": 2170000, "per_episode_reward": -466.66, "episode_reward_trend_value": -0.0009745143035584332, "biggest_recent_change": 0.21289621458282681},
{"total_number_of_episodes": 2180, "number_of_timesteps": 2180000, "per_episode_reward": -466.79, "episode_reward_trend_value": -0.0026134385735986144, "biggest_recent_change": 0.21289621458282681},
{"total_number_of_episodes": 2190, "number_of_timesteps": 2190000, "per_episode_reward": -466.87, "episode_reward_trend_value": -0.005001318365645426, "biggest_recent_change": 0.21289621458282681},
{"total_number_of_episodes": 2200, "number_of_timesteps": 2200000, "per_episode_reward": -467.13, "episode_reward_trend_value": -0.008079124420080082, "biggest_recent_change": 0.2519850697248671},
{"total_number_of_episodes": 2210, "number_of_timesteps": 2210000, "per_episode_reward": -467.12, "episode_reward_trend_value": -0.0074299037380329645, "biggest_recent_change": 0.2519850697248671},
{"total_number_of_episodes": 2220, "number_of_timesteps": 2220000, "per_episode_reward": -467.11, "episode_reward_trend_value": -0.009408450072518487, "biggest_recent_change": 0.2519850697248671},
{"total_number_of_episodes": 2230, "number_of_timesteps": 2230000, "per_episode_reward": -467.37, "episode_reward_trend_value": -0.01081358833585, "biggest_recent_change": 0.26886900832749916},
{"total_number_of_episodes": 2240, "number_of_timesteps": 2240000, "per_episode_reward": -467.19, "episode_reward_trend_value": -0.0068960949040489244, "biggest_recent_change": 0.26886900832749916},
{"total_number_of_episodes": 2250, "number_of_timesteps": 2250000, "per_episode_reward": -467.41, "episode_reward_trend_value": -0.01067417654664003, "biggest_recent_change": 0.26886900832749916},
{"total_number_of_episodes": 2260, "number_of_timesteps": 2260000, "per_episode_reward": -467.19, "episode_reward_trend_value": -0.005837265066648772, "biggest_recent_change": 0.26886900832749916},
{"total_number_of_episodes": 2270, "number_of_timesteps": 2270000, "per_episode_reward": -466.9, "episode_reward_trend_value": -0.001189296088104028, "biggest_recent_change": 0.29023450344982393},
{"total_number_of_episodes": 2280, "number_of_timesteps": 2280000, "per_episode_reward": -466.95, "episode_reward_trend_value": -0.000888282309711662, "biggest_recent_change": 0.29023450344982393},
{"total_number_of_episodes": 2290, "number_of_timesteps": 2290000, "per_episode_reward": -467.17, "episode_reward_trend_value": -0.0005130672685582895, "biggest_recent_change": 0.29023450344982393},
{"total_number_of_episodes": 2300, "number_of_timesteps": 2300000, "per_episode_reward": -467.53, "episode_reward_trend_value": -0.00463085388714401, "biggest_recent_change": 0.3628726322590978},
{"total_number_of_episodes": 2310, "number_of_timesteps": 2310000, "per_episode_reward": -467.82, "episode_reward_trend_value": -0.00799149961397158, "biggest_recent_change": 0.3628726322590978},
{"total_number_of_episodes": 2320, "number_of_timesteps": 2320000, "per_episode_reward": -468.0, "episode_reward_trend_value": -0.006988538483055133, "biggest_recent_change": 0.3628726322590978},
{"total_number_of_episodes": 2330, "number_of_timesteps": 2330000, "per_episode_reward": -468.21, "episode_reward_trend_value": -0.011337328655687567, "biggest_recent_change": 0.3628726322590978},
{"total_number_of_episodes": 2340, "number_of_timesteps": 2340000, "per_episode_reward": -468.43, "episode_reward_trend_value": -0.011326848945788646, "biggest_recent_change": 0.3628726322590978},
{"total_number_of_episodes": 2350, "number_of_timesteps": 2350000, "per_episode_reward": -468.65, "episode_reward_trend_value": -0.016251456255366115, "biggest_recent_change": 0.3628726322590978},
{"total_number_of_episodes": 2360, "number_of_timesteps": 2360000, "per_episode_reward": -469.04, "episode_reward_trend_value": -0.023831184037166823, "biggest_recent_change": 0.3919409969122398},
{"total_number_of_episodes": 2370, "number_of_timesteps": 2370000, "per_episode_reward": -469.38, "episode_reward_trend_value": -0.026963395900534377, "biggest_recent_change": 0.3919409969122398},
{"total_number_of_episodes": 2380, "number_of_timesteps": 2380000, "per_episode_reward": -469.58, "episode_reward_trend_value": -0.0267325921294053, "biggest_recent_change": 0.3919409969122398},
{"total_number_of_episodes": 2390, "number_of_timesteps": 2390000, "per_episode_reward": -469.81, "episode_reward_trend_value": -0.025269689302042608, "biggest_recent_change": 0.3919409969122398},
{"total_number_of_episodes": 2400, "number_of_timesteps": 2400000, "per_episode_reward": -469.87, "episode_reward_trend_value": -0.022722495017876553, "biggest_recent_change": 0.3919409969122398},
{"total_number_of_episodes": 2410, "number_of_timesteps": 2410000, "per_episode_reward": -469.97, "episode_reward_trend_value": -0.021907448658447494, "biggest_recent_change": 0.3919409969122398},
{"total_number_of_episodes": 2420, "number_of_timesteps": 2420000, "per_episode_reward": -470.44, "episode_reward_trend_value": -0.024834325946669525, "biggest_recent_change": 0.467311329702909},
{"total_number_of_episodes": 2430, "number_of_timesteps": 2430000, "per_episode_reward": -470.98, "episode_reward_trend_value": -0.02839342382128949, "biggest_recent_change": 0.5411076479613257},
{"total_number_of_episodes": 2440, "number_of_timesteps": 2440000, "per_episode_reward": -471.6, "episode_reward_trend_value": -0.032832976888892064, "biggest_recent_change": 0.6203486153298172},
{"total_number_of_episodes": 2450, "number_of_timesteps": 2450000, "per_episode_reward": -472.22, "episode_reward_trend_value": -0.0353708393157553, "biggest_recent_change": 0.6203486153299309},
{"total_number_of_episodes": 2460, "number_of_timesteps": 2460000, "per_episode_reward": -472.48, "episode_reward_trend_value": -0.03449133980782525, "biggest_recent_change": 0.6203486153299309},
{"total_number_of_episodes": 2470, "number_of_timesteps": 2470000, "per_episode_reward": -472.7, "episode_reward_trend_value": -0.034659445849357304, "biggest_recent_change": 0.6203486153299309},
{"total_number_of_episodes": 2480, "number_of_timesteps": 2480000, "per_episode_reward": -472.99, "episode_reward_trend_value": -0.03534426733711358, "biggest_recent_change": 0.6203486153299309},
{"total_number_of_episodes": 2490, "number_of_timesteps": 2490000, "per_episode_reward": -473.19, "episode_reward_trend_value": -0.03687907699127335, "biggest_recent_change": 0.6203486153299309},
{"total_number_of_episodes": 2500, "number_of_timesteps": 2500000, "per_episode_reward": -473.58, "episode_reward_trend_value": -0.04007190463535469, "biggest_recent_change": 0.6203486153299309},
{"total_number_of_episodes": 2510, "number_of_timesteps": 2510000, "per_episode_reward": -473.74, "episode_reward_trend_value": -0.03663210673347963, "biggest_recent_change": 0.6203486153299309},
exited at update_barrier.wait(): 9
exited at update_barrier.wait(): 8
None
None
{"total_number_of_episodes": 2520, "number_of_timesteps": 2520000, "per_episode_reward": -473.88, "episode_reward_trend_value": -0.03221666900164956, "biggest_recent_change": 0.6203486153299309},
{"total_number_of_episodes": 2530, "number_of_timesteps": 2530000, "per_episode_reward": -474.02, "episode_reward_trend_value": -0.026884964890588336, "biggest_recent_change": 0.6203486153299309},
{"total_number_of_episodes": 2540, "number_of_timesteps": 2540000, "per_episode_reward": -474.07, "episode_reward_trend_value": -0.020492340178446967, "biggest_recent_change": 0.3926028221637239},
{"total_number_of_episodes": 2550, "number_of_timesteps": 2550000, "per_episode_reward": -474.28, "episode_reward_trend_value": -0.01999358416848117, "biggest_recent_change": 0.3926028221637239},
{"total_number_of_episodes": 2560, "number_of_timesteps": 2560000, "per_episode_reward": -474.06, "episode_reward_trend_value": -0.015190785373862228, "biggest_recent_change": 0.3926028221637239},
{"total_number_of_episodes": 2570, "number_of_timesteps": 2570000, "per_episode_reward": -474.03, "episode_reward_trend_value": -0.011513755184085993, "biggest_recent_change": 0.3926028221637239},
{"total_number_of_episodes": 2580, "number_of_timesteps": 2580000, "per_episode_reward": -473.9, "episode_reward_trend_value": -0.007892230262036214, "biggest_recent_change": 0.3926028221637239},
{"total_number_of_episodes": 2590, "number_of_timesteps": 2590000, "per_episode_reward": -474.04, "episode_reward_trend_value": -0.005149275366455994, "biggest_recent_change": 0.21967897115837332},
{"total_number_of_episodes": 2600, "number_of_timesteps": 2600000, "per_episode_reward": -474.07, "episode_reward_trend_value": -0.0036349777817861195, "biggest_recent_change": 0.21967897115837332},
{"total_number_of_episodes": 2610, "number_of_timesteps": 2610000, "per_episode_reward": -474.23, "episode_reward_trend_value": -0.0038674254762118684, "biggest_recent_change": 0.21967897115837332},
{"total_number_of_episodes": 2620, "number_of_timesteps": 2620000, "per_episode_reward": -474.14, "episode_reward_trend_value": -0.001249170879968157, "biggest_recent_change": 0.21967897115837332},
{"total_number_of_episodes": 2630, "number_of_timesteps": 2630000, "per_episode_reward": -474.31, "episode_reward_trend_value": -0.0027341822497981465, "biggest_recent_change": 0.21967897115837332},
{"total_number_of_episodes": 2640, "number_of_timesteps": 2640000, "per_episode_reward": -474.14, "episode_reward_trend_value": 0.001569423295982612, "biggest_recent_change": 0.21967897115837332},
{"total_number_of_episodes": 2650, "number_of_timesteps": 2650000, "per_episode_reward": -474.17, "episode_reward_trend_value": -0.0011906199093775487, "biggest_recent_change": 0.17866341452190682},
{"total_number_of_episodes": 2660, "number_of_timesteps": 2660000, "per_episode_reward": -474.17, "episode_reward_trend_value": -0.0016227996766954474, "biggest_recent_change": 0.17866341452190682},
{"total_number_of_episodes": 2670, "number_of_timesteps": 2670000, "per_episode_reward": -474.16, "episode_reward_trend_value": -0.002894522001973125, "biggest_recent_change": 0.17866341452190682},
{"total_number_of_episodes": 2680, "number_of_timesteps": 2680000, "per_episode_reward": -474.11, "episode_reward_trend_value": -0.0006969876750462037, "biggest_recent_change": 0.17866341452190682},
{"total_number_of_episodes": 2690, "number_of_timesteps": 2690000, "per_episode_reward": -474.09, "episode_reward_trend_value": -0.00031808368862079486, "biggest_recent_change": 0.17866341452190682},
{"total_number_of_episodes": 2700, "number_of_timesteps": 2700000, "per_episode_reward": -474.14, "episode_reward_trend_value": 0.001021362927196555, "biggest_recent_change": 0.17866341452190682},
{"total_number_of_episodes": 2710, "number_of_timesteps": 2710000, "per_episode_reward": -474.25, "episode_reward_trend_value": -0.0013071826557898526, "biggest_recent_change": 0.17866341452190682},
{"total_number_of_episodes": 2720, "number_of_timesteps": 2720000, "per_episode_reward": -474.18, "episode_reward_trend_value": 0.001534604755276329, "biggest_recent_change": 0.17150447787986423},
{"total_number_of_episodes": 2730, "number_of_timesteps": 2730000, "per_episode_reward": -474.28, "episode_reward_trend_value": -0.0015707724403512201, "biggest_recent_change": 0.1144214341411498},
{"total_number_of_episodes": 2740, "number_of_timesteps": 2740000, "per_episode_reward": -474.24, "episode_reward_trend_value": -0.0007200858315545449, "biggest_recent_change": 0.1144214341411498},
{"total_number_of_episodes": 2750, "number_of_timesteps": 2750000, "per_episode_reward": -474.26, "episode_reward_trend_value": -0.0010000312164891057, "biggest_recent_change": 0.1144214341411498},
{"total_number_of_episodes": 2760, "number_of_timesteps": 2760000, "per_episode_reward": -474.51, "episode_reward_trend_value": -0.003858137193254328, "biggest_recent_change": 0.24437339670441816},
{"total_number_of_episodes": 2770, "number_of_timesteps": 2770000, "per_episode_reward": -474.42, "episode_reward_trend_value": -0.0034298115261258825, "biggest_recent_change": 0.24437339670441816},
{"total_number_of_episodes": 2780, "number_of_timesteps": 2780000, "per_episode_reward": -474.4, "episode_reward_trend_value": -0.0034124973624974097, "biggest_recent_change": 0.24437339670441816},
{"total_number_of_episodes": 2790, "number_of_timesteps": 2790000, "per_episode_reward": -474.21, "episode_reward_trend_value": -0.000785211506096554, "biggest_recent_change": 0.24437339670441816},
{"total_number_of_episodes": 2800, "number_of_timesteps": 2800000, "per_episode_reward": -474.29, "episode_reward_trend_value": -0.00041544999348527904, "biggest_recent_change": 0.24437339670441816},
{"total_number_of_episodes": 2810, "number_of_timesteps": 2810000, "per_episode_reward": -474.37, "episode_reward_trend_value": -0.0021752725247008837, "biggest_recent_change": 0.24437339670441816},
{"total_number_of_episodes": 2820, "number_of_timesteps": 2820000, "per_episode_reward": -474.43, "episode_reward_trend_value": -0.001610799948112016, "biggest_recent_change": 0.24437339670441816},
{"total_number_of_episodes": 2830, "number_of_timesteps": 2830000, "per_episode_reward": -474.48, "episode_reward_trend_value": -0.002693931104042551, "biggest_recent_change": 0.24437339670441816},
{"total_number_of_episodes": 2840, "number_of_timesteps": 2840000, "per_episode_reward": -474.44, "episode_reward_trend_value": -0.0020062676568632773, "biggest_recent_change": 0.24437339670441816},
{"total_number_of_episodes": 2850, "number_of_timesteps": 2850000, "per_episode_reward": -474.54, "episode_reward_trend_value": -0.00037922077679834526, "biggest_recent_change": 0.19236737790470215},
{"total_number_of_episodes": 2860, "number_of_timesteps": 2860000, "per_episode_reward": -474.55, "episode_reward_trend_value": -0.0014874884741737384, "biggest_recent_change": 0.19236737790470215},
{"total_number_of_episodes": 2870, "number_of_timesteps": 2870000, "per_episode_reward": -474.59, "episode_reward_trend_value": -0.002076406174542929, "biggest_recent_change": 0.19236737790470215},
Hit early stopping because biggest_recent_change: 0.09793917749857428 < 0.1
exited at when_all_processes_are_updated(): 3
exited at update_barrier.wait(): 1
None
exited at update_barrier.wait(): 0
None
[32m[I 2022-11-13 14:29:07,245][0m Trial 8 finished with value: -474.81943435273513 and parameters: {'activation': 0, 't_max': 5, 'hidden_size': 2, 'variance_scaling_factor': 0, 'permaban_threshold': 0, 'learning_rate_base': 4, 'learning_rate_exponent': 4, 'beta_base': 4, 'beta_exponent': 5}. Best is trial 8 with value: -474.81943435273513.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 3000, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 0.01, 
        "beta": 0.0009000000000000001, 
        "t_max": 5, 
        "activation": 1, 
        "hidden_size": 64, 
        "variance_scaling_factor": 0.01, 
        "permaban_threshold": 1000, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 950733047, 
    "outdir": "results", 
    "t_max": 5, 
    "beta": 0.0009000000000000001, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 0.01, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 1000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 1, 
}
exited at when_all_processes_are_updated(): 6
exited at update_barrier.wait(): 4
None
exited at update_barrier.wait(): 5
None
exited at update_barrier.wait(): 7
None
exited at update_barrier.wait(): 0
None
exited at update_barrier.wait(): 9
None
[32m[I 2022-11-13 14:29:22,419][0m Trial 9 finished with value: -1692.8818046365122 and parameters: {'activation': 1, 't_max': 1, 'hidden_size': 2, 'variance_scaling_factor': 0, 'permaban_threshold': 2, 'learning_rate_base': 0, 'learning_rate_exponent': 1, 'beta_base': 4, 'beta_exponent': 3}. Best is trial 8 with value: -474.81943435273513.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 3000, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 0.05, 
        "beta": 0.007, 
        "t_max": 5, 
        "activation": 0, 
        "hidden_size": 128, 
        "variance_scaling_factor": 0.01, 
        "permaban_threshold": 10000, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 1010773062, 
    "outdir": "results", 
    "t_max": 5, 
    "beta": 0.007, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 0.05, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 10000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 128, 
    "activation": 0, 
}
exited at when_all_processes_are_updated(): 8
exited at update_barrier.wait(): 5
None
exited at update_barrier.wait(): 9
None
exited at update_barrier.wait(): 7
None
exited at update_barrier.wait(): 1
None
exited at update_barrier.wait(): 0
None
exited at update_barrier.wait(): 3
None
[32m[I 2022-11-13 14:29:57,339][0m Trial 10 finished with value: -257639747597122.2 and parameters: {'activation': 0, 't_max': 1, 'hidden_size': 3, 'variance_scaling_factor': 0, 'permaban_threshold': 4, 'learning_rate_base': 2, 'learning_rate_exponent': 1, 'beta_base': 3, 'beta_exponent': 2}. Best is trial 8 with value: -474.81943435273513.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 3000, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 0.1, 
        "beta": 1e-08, 
        "t_max": 20, 
        "activation": 2, 
        "hidden_size": 64, 
        "variance_scaling_factor": 1000, 
        "permaban_threshold": 500, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 2489745099, 
    "outdir": "results", 
    "t_max": 20, 
    "beta": 1e-08, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 0.1, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 500, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 2, 
}
exited at update_barrier.wait(): 6
exited at update_barrier.wait(): 1
None
None
exited at update_barrier.wait(): 5
None
exited at update_barrier.wait(): 9
None
exited at update_barrier.wait(): 7
None
exited at when_all_processes_are_updated(): 2
exited at update_barrier.wait(): 8
None
[32m[I 2022-11-13 14:30:03,964][0m Trial 11 finished with value: -792393.5839579313 and parameters: {'activation': 2, 't_max': 3, 'hidden_size': 2, 'variance_scaling_factor': 3, 'permaban_threshold': 1, 'learning_rate_base': 0, 'learning_rate_exponent': 0, 'beta_base': 0, 'beta_exponent': 7}. Best is trial 8 with value: -474.81943435273513.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 3000, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 0.009000000000000001, 
        "beta": 9e-07, 
        "t_max": 50, 
        "activation": 0, 
        "hidden_size": 64, 
        "variance_scaling_factor": 1, 
        "permaban_threshold": 100, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 2610008477, 
    "outdir": "results", 
    "t_max": 50, 
    "beta": 9e-07, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 0.009000000000000001, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 100, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 0, 
}
{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -757.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Hit early stopping because per_episode_reward: -756.996768140741 < -700
exited at when_all_processes_are_updated(): 2
exited at update_barrier.wait(): 4
None
exited at update_barrier.wait(): 5
None
exited at update_barrier.wait(): 3
None
exited at update_barrier.wait(): 8
None
exited at update_barrier.wait(): 9
None
[32m[I 2022-11-13 14:30:08,597][0m Trial 12 finished with value: -764.1968126306805 and parameters: {'activation': 0, 't_max': 5, 'hidden_size': 2, 'variance_scaling_factor': 1, 'permaban_threshold': 0, 'learning_rate_base': 4, 'learning_rate_exponent': 2, 'beta_base': 4, 'beta_exponent': 6}. Best is trial 8 with value: -474.81943435273513.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 3000, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 0.00030000000000000003, 
        "beta": 9e-06, 
        "t_max": 5, 
        "activation": 2, 
        "hidden_size": 128, 
        "variance_scaling_factor": 100, 
        "permaban_threshold": 1000, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 3629516421, 
    "outdir": "results", 
    "t_max": 5, 
    "beta": 9e-06, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 0.00030000000000000003, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 1000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 128, 
    "activation": 2, 
}
{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -632.63, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"total_number_of_episodes": 30, "number_of_timesteps": 30000, "per_episode_reward": -615.97, "episode_reward_trend_value": 1.66639149006769, "biggest_recent_change": NaN},
{"total_number_of_episodes": 40, "number_of_timesteps": 40000, "per_episode_reward": -619.29, "episode_reward_trend_value": 0.667035864296372, "biggest_recent_change": NaN},
{"total_number_of_episodes": 50, "number_of_timesteps": 50000, "per_episode_reward": -623.11, "episode_reward_trend_value": 0.3174912394192385, "biggest_recent_change": NaN},
{"total_number_of_episodes": 60, "number_of_timesteps": 60000, "per_episode_reward": -567.48, "episode_reward_trend_value": 1.6288864835931407, "biggest_recent_change": NaN},
{"total_number_of_episodes": 70, "number_of_timesteps": 70000, "per_episode_reward": -568.37, "episode_reward_trend_value": 1.2851399453501426, "biggest_recent_change": NaN},
{"total_number_of_episodes": 80, "number_of_timesteps": 80000, "per_episode_reward": -566.59, "episode_reward_trend_value": 1.1007154499261067, "biggest_recent_change": NaN},
{"total_number_of_episodes": 90, "number_of_timesteps": 90000, "per_episode_reward": -566.26, "episode_reward_trend_value": 0.9481747755951281, "biggest_recent_change": NaN},
{"total_number_of_episodes": 100, "number_of_timesteps": 100000, "per_episode_reward": -567.32, "episode_reward_trend_value": 0.8163870971032111, "biggest_recent_change": NaN},
{"total_number_of_episodes": 110, "number_of_timesteps": 110000, "per_episode_reward": -562.45, "episode_reward_trend_value": 0.779746770007806, "biggest_recent_change": 55.63072216114847},
{"total_number_of_episodes": 120, "number_of_timesteps": 120000, "per_episode_reward": -564.67, "episode_reward_trend_value": 0.5699728730969065, "biggest_recent_change": 55.63072216114847},
{"total_number_of_episodes": 130, "number_of_timesteps": 130000, "per_episode_reward": -565.45, "episode_reward_trend_value": 0.5982005126268329, "biggest_recent_change": 55.63072216114847},
{"total_number_of_episodes": 140, "number_of_timesteps": 140000, "per_episode_reward": -565.33, "episode_reward_trend_value": 0.6419508084895369, "biggest_recent_change": 55.63072216114847},
{"total_number_of_episodes": 150, "number_of_timesteps": 150000, "per_episode_reward": -569.47, "episode_reward_trend_value": -0.022120704429971737, "biggest_recent_change": 4.866241532445656},
{"total_number_of_episodes": 160, "number_of_timesteps": 160000, "per_episode_reward": -568.18, "episode_reward_trend_value": 0.0022018776630589954, "biggest_recent_change": 4.866241532445656},
{"total_number_of_episodes": 170, "number_of_timesteps": 170000, "per_episode_reward": -570.88, "episode_reward_trend_value": -0.04772160900255358, "biggest_recent_change": 4.866241532445656},
{"total_number_of_episodes": 180, "number_of_timesteps": 180000, "per_episode_reward": -571.61, "episode_reward_trend_value": -0.05944394057786566, "biggest_recent_change": 4.866241532445656},
{"total_number_of_episodes": 190, "number_of_timesteps": 190000, "per_episode_reward": -571.09, "episode_reward_trend_value": -0.041880801720403975, "biggest_recent_change": 4.866241532445656},
{"total_number_of_episodes": 200, "number_of_timesteps": 200000, "per_episode_reward": -572.85, "episode_reward_trend_value": -0.11552980564855615, "biggest_recent_change": 4.135714001607312},
{"total_number_of_episodes": 210, "number_of_timesteps": 210000, "per_episode_reward": -572.58, "episode_reward_trend_value": -0.08793669055880729, "biggest_recent_change": 4.135714001607312},
{"total_number_of_episodes": 220, "number_of_timesteps": 220000, "per_episode_reward": -570.13, "episode_reward_trend_value": -0.052007605743545404, "biggest_recent_change": 4.135714001607312},
{"total_number_of_episodes": 230, "number_of_timesteps": 230000, "per_episode_reward": -572.68, "episode_reward_trend_value": -0.08162546314470596, "biggest_recent_change": 4.135714001607312},
{"total_number_of_episodes": 240, "number_of_timesteps": 240000, "per_episode_reward": -571.8, "episode_reward_trend_value": -0.025904290555279708, "biggest_recent_change": 2.707184071845859},
{"total_number_of_episodes": 250, "number_of_timesteps": 250000, "per_episode_reward": -570.53, "episode_reward_trend_value": -0.02615201992154223, "biggest_recent_change": 2.707184071845859},
{"total_number_of_episodes": 260, "number_of_timesteps": 260000, "per_episode_reward": -569.91, "episode_reward_trend_value": 0.010861119403695182, "biggest_recent_change": 2.5440606418113703},
{"total_number_of_episodes": 270, "number_of_timesteps": 270000, "per_episode_reward": -569.79, "episode_reward_trend_value": 0.02014912326763023, "biggest_recent_change": 2.5440606418113703},
{"total_number_of_episodes": 280, "number_of_timesteps": 280000, "per_episode_reward": -570.29, "episode_reward_trend_value": 0.008931510263928683, "biggest_recent_change": 2.5440606418113703},
{"total_number_of_episodes": 290, "number_of_timesteps": 290000, "per_episode_reward": -570.42, "episode_reward_trend_value": 0.02702601425761107, "biggest_recent_change": 2.5440606418113703},
{"total_number_of_episodes": 300, "number_of_timesteps": 300000, "per_episode_reward": -570.19, "episode_reward_trend_value": 0.02655349776847642, "biggest_recent_change": 2.5440606418113703},
{"total_number_of_episodes": 310, "number_of_timesteps": 310000, "per_episode_reward": -569.73, "episode_reward_trend_value": 0.004444959546526661, "biggest_recent_change": 2.5440606418113703},
{"total_number_of_episodes": 320, "number_of_timesteps": 320000, "per_episode_reward": -570.52, "episode_reward_trend_value": 0.0240024371329898, "biggest_recent_change": 1.268274669190646},
{"total_number_of_episodes": 330, "number_of_timesteps": 330000, "per_episode_reward": -570.91, "episode_reward_trend_value": 0.009874679713657821, "biggest_recent_change": 1.268274669190646},
{"total_number_of_episodes": 340, "number_of_timesteps": 340000, "per_episode_reward": -571.11, "episode_reward_trend_value": -0.006471304259684984, "biggest_recent_change": 0.7838876590296877},
{"total_number_of_episodes": 350, "number_of_timesteps": 350000, "per_episode_reward": -570.56, "episode_reward_trend_value": -0.0072859809639794545, "biggest_recent_change": 0.7838876590296877},
{"total_number_of_episodes": 360, "number_of_timesteps": 360000, "per_episode_reward": -571.19, "episode_reward_trend_value": -0.015468777642204007, "biggest_recent_change": 0.7838876590296877},
{"total_number_of_episodes": 370, "number_of_timesteps": 370000, "per_episode_reward": -570.85, "episode_reward_trend_value": -0.006301198158793239, "biggest_recent_change": 0.7838876590296877},
{"total_number_of_episodes": 380, "number_of_timesteps": 380000, "per_episode_reward": -571.55, "episode_reward_trend_value": -0.012535885426171312, "biggest_recent_change": 0.7838876590296877},
{"total_number_of_episodes": 390, "number_of_timesteps": 390000, "per_episode_reward": -572.38, "episode_reward_trend_value": -0.024285898923840754, "biggest_recent_change": 0.8323831620390365},
{"total_number_of_episodes": 400, "number_of_timesteps": 400000, "per_episode_reward": -573.44, "episode_reward_trend_value": -0.041193514928145054, "biggest_recent_change": 1.0605463040453742},
{"total_number_of_episodes": 410, "number_of_timesteps": 410000, "per_episode_reward": -572.97, "episode_reward_trend_value": -0.027279477339178966, "biggest_recent_change": 1.0605463040453742},
{"total_number_of_episodes": 420, "number_of_timesteps": 420000, "per_episode_reward": -572.67, "episode_reward_trend_value": -0.01953529732414078, "biggest_recent_change": 1.0605463040453742},
{"total_number_of_episodes": 430, "number_of_timesteps": 430000, "per_episode_reward": -572.85, "episode_reward_trend_value": -0.019271856085520588, "biggest_recent_change": 1.0605463040453742},
{"total_number_of_episodes": 440, "number_of_timesteps": 440000, "per_episode_reward": -572.49, "episode_reward_trend_value": -0.021388732454799234, "biggest_recent_change": 1.0605463040453742},
{"total_number_of_episodes": 450, "number_of_timesteps": 450000, "per_episode_reward": -572.23, "episode_reward_trend_value": -0.011590901301990976, "biggest_recent_change": 1.0605463040453742},
{"total_number_of_episodes": 460, "number_of_timesteps": 460000, "per_episode_reward": -570.93, "episode_reward_trend_value": -0.0008944576493301307, "biggest_recent_change": 1.297592885682775},
{"total_number_of_episodes": 470, "number_of_timesteps": 470000, "per_episode_reward": -569.82, "episode_reward_trend_value": 0.019218600513529006, "biggest_recent_change": 1.297592885682775},
{"total_number_of_episodes": 480, "number_of_timesteps": 480000, "per_episode_reward": -571.16, "episode_reward_trend_value": 0.013560517415962498, "biggest_recent_change": 1.3416106408200221},
{"total_number_of_episodes": 490, "number_of_timesteps": 490000, "per_episode_reward": -570.47, "episode_reward_trend_value": 0.033045709218908495, "biggest_recent_change": 1.3416106408200221},
{"total_number_of_episodes": 500, "number_of_timesteps": 500000, "per_episode_reward": -569.85, "episode_reward_trend_value": 0.03464086076643677, "biggest_recent_change": 1.3416106408200221},
{"total_number_of_episodes": 510, "number_of_timesteps": 510000, "per_episode_reward": -505.28, "episode_reward_trend_value": 0.7487620113781146, "biggest_recent_change": 64.57557312010562},
{"total_number_of_episodes": 520, "number_of_timesteps": 520000, "per_episode_reward": -506.14, "episode_reward_trend_value": 0.7411605626548976, "biggest_recent_change": 64.57557312010562},
{"total_number_of_episodes": 530, "number_of_timesteps": 530000, "per_episode_reward": -505.42, "episode_reward_trend_value": 0.7451811129338618, "biggest_recent_change": 64.57557312010562},
{"total_number_of_episodes": 540, "number_of_timesteps": 540000, "per_episode_reward": -506.25, "episode_reward_trend_value": 0.7330601711326797, "biggest_recent_change": 64.57557312010562},
{"total_number_of_episodes": 550, "number_of_timesteps": 550000, "per_episode_reward": -506.94, "episode_reward_trend_value": 0.7110110942798011, "biggest_recent_change": 64.57557312010562},
{"total_number_of_episodes": 560, "number_of_timesteps": 560000, "per_episode_reward": -506.83, "episode_reward_trend_value": 0.699860085776535, "biggest_recent_change": 64.57557312010562},
{"total_number_of_episodes": 570, "number_of_timesteps": 570000, "per_episode_reward": -507.14, "episode_reward_trend_value": 0.7113539393194868, "biggest_recent_change": 64.57557312010562},
{"total_number_of_episodes": 580, "number_of_timesteps": 580000, "per_episode_reward": -506.51, "episode_reward_trend_value": 0.7105805498188917, "biggest_recent_change": 64.57557312010562},
{"total_number_of_episodes": 590, "number_of_timesteps": 590000, "per_episode_reward": -506.05, "episode_reward_trend_value": 0.7089563886624205, "biggest_recent_change": 64.57557312010562},
{"total_number_of_episodes": 600, "number_of_timesteps": 600000, "per_episode_reward": -506.11, "episode_reward_trend_value": -0.00925379418913192, "biggest_recent_change": 0.8632845620239209},
{"total_number_of_episodes": 610, "number_of_timesteps": 610000, "per_episode_reward": -505.49, "episode_reward_trend_value": 0.0072680248073721835, "biggest_recent_change": 0.8353138573252181},
{"total_number_of_episodes": 620, "number_of_timesteps": 620000, "per_episode_reward": -505.7, "episode_reward_trend_value": -0.0031525284237046785, "biggest_recent_change": 0.8353138573252181},
{"total_number_of_episodes": 630, "number_of_timesteps": 630000, "per_episode_reward": -506.02, "episode_reward_trend_value": 0.00266299004080679, "biggest_recent_change": 0.6868240310762985},
{"total_number_of_episodes": 640, "number_of_timesteps": 640000, "per_episode_reward": -504.94, "episode_reward_trend_value": 0.022287128600173546, "biggest_recent_change": 1.0793484392667096},
{"total_number_of_episodes": 650, "number_of_timesteps": 650000, "per_episode_reward": -504.72, "episode_reward_trend_value": 0.023481946076767853, "biggest_recent_change": 1.0793484392667096},
{"total_number_of_episodes": 660, "number_of_timesteps": 660000, "per_episode_reward": -504.91, "episode_reward_trend_value": 0.024689662177180733, "biggest_recent_change": 1.0793484392667096},
{"total_number_of_episodes": 670, "number_of_timesteps": 670000, "per_episode_reward": -504.53, "episode_reward_trend_value": 0.02203864057743519, "biggest_recent_change": 1.0793484392667096},
{"total_number_of_episodes": 680, "number_of_timesteps": 680000, "per_episode_reward": -504.58, "episode_reward_trend_value": 0.01629438159682574, "biggest_recent_change": 1.0793484392667096},
{"total_number_of_episodes": 690, "number_of_timesteps": 690000, "per_episode_reward": -503.33, "episode_reward_trend_value": 0.030940834500801075, "biggest_recent_change": 1.2548374248236769},
{"total_number_of_episodes": 700, "number_of_timesteps": 700000, "per_episode_reward": -504.52, "episode_reward_trend_value": 0.01078213934537631, "biggest_recent_change": 1.2548374248236769},
{"total_number_of_episodes": 710, "number_of_timesteps": 710000, "per_episode_reward": -504.28, "episode_reward_trend_value": 0.01579466082783938, "biggest_recent_change": 1.2548374248236769},
{"total_number_of_episodes": 720, "number_of_timesteps": 720000, "per_episode_reward": -505.22, "episode_reward_trend_value": 0.00883345933446233, "biggest_recent_change": 1.2548374248236769},
{"total_number_of_episodes": 730, "number_of_timesteps": 730000, "per_episode_reward": -505.81, "episode_reward_trend_value": -0.009723926580334642, "biggest_recent_change": 1.2548374248236769},
{"total_number_of_episodes": 740, "number_of_timesteps": 740000, "per_episode_reward": -504.65, "episode_reward_trend_value": 0.0007406245917555528, "biggest_recent_change": 1.2548374248236769},
{"total_number_of_episodes": 750, "number_of_timesteps": 750000, "per_episode_reward": -504.5, "episode_reward_trend_value": 0.004623474364346217, "biggest_recent_change": 1.2548374248236769},
{"total_number_of_episodes": 760, "number_of_timesteps": 760000, "per_episode_reward": -504.58, "episode_reward_trend_value": -0.0005945652643276844, "biggest_recent_change": 1.2548374248236769},
{"total_number_of_episodes": 770, "number_of_timesteps": 770000, "per_episode_reward": -504.75, "episode_reward_trend_value": -0.0018360307812839791, "biggest_recent_change": 1.2548374248236769},
{"total_number_of_episodes": 780, "number_of_timesteps": 780000, "per_episode_reward": -505.36, "episode_reward_trend_value": -0.022642991435921227, "biggest_recent_change": 1.1906034163267805},
{"total_number_of_episodes": 790, "number_of_timesteps": 790000, "per_episode_reward": -505.38, "episode_reward_trend_value": -0.009625072276247693, "biggest_recent_change": 1.1611423320243262},
{"total_number_of_episodes": 800, "number_of_timesteps": 800000, "per_episode_reward": -505.28, "episode_reward_trend_value": -0.011044036009428106, "biggest_recent_change": 1.1611423320243262},
{"total_number_of_episodes": 810, "number_of_timesteps": 810000, "per_episode_reward": -505.51, "episode_reward_trend_value": -0.0031700575074239622, "biggest_recent_change": 1.1611423320243262},
{"total_number_of_episodes": 820, "number_of_timesteps": 820000, "per_episode_reward": -505.57, "episode_reward_trend_value": 0.002712231443178502, "biggest_recent_change": 1.1611423320243262},
{"total_number_of_episodes": 830, "number_of_timesteps": 830000, "per_episode_reward": -505.09, "episode_reward_trend_value": -0.0048395236396541145, "biggest_recent_change": 0.6177890340936756},
{"total_number_of_episodes": 840, "number_of_timesteps": 840000, "per_episode_reward": -505.28, "episode_reward_trend_value": -0.008626100367295445, "biggest_recent_change": 0.6177890340936756},
{"total_number_of_episodes": 850, "number_of_timesteps": 850000, "per_episode_reward": -505.92, "episode_reward_trend_value": -0.014819044574098448, "biggest_recent_change": 0.6420645860038121},
{"total_number_of_episodes": 860, "number_of_timesteps": 860000, "per_episode_reward": -505.53, "episode_reward_trend_value": -0.008707117878763408, "biggest_recent_change": 0.6420645860038121},
{"total_number_of_episodes": 870, "number_of_timesteps": 870000, "per_episode_reward": -505.51, "episode_reward_trend_value": -0.0015659836601211435, "biggest_recent_change": 0.6420645860038121},
{"total_number_of_episodes": 880, "number_of_timesteps": 880000, "per_episode_reward": -505.57, "episode_reward_trend_value": -0.0021256059053617565, "biggest_recent_change": 0.6420645860038121},
{"total_number_of_episodes": 890, "number_of_timesteps": 890000, "per_episode_reward": -505.37, "episode_reward_trend_value": -0.0009964871716161069, "biggest_recent_change": 0.6420645860038121},
{"total_number_of_episodes": 900, "number_of_timesteps": 900000, "per_episode_reward": -442.27, "episode_reward_trend_value": 0.702613509370367, "biggest_recent_change": 63.09513242403574},
{"total_number_of_episodes": 910, "number_of_timesteps": 910000, "per_episode_reward": -443.54, "episode_reward_trend_value": 0.6891804459083706, "biggest_recent_change": 63.09513242403574},
{"total_number_of_episodes": 920, "number_of_timesteps": 920000, "per_episode_reward": -444.41, "episode_reward_trend_value": 0.6742091952379787, "biggest_recent_change": 63.09513242403574},
{"total_number_of_episodes": 930, "number_of_timesteps": 930000, "per_episode_reward": -444.4, "episode_reward_trend_value": 0.6764217624158391, "biggest_recent_change": 63.09513242403574},
{"total_number_of_episodes": 940, "number_of_timesteps": 940000, "per_episode_reward": -445.29, "episode_reward_trend_value": 0.6736295457465656, "biggest_recent_change": 63.09513242403574},
{"total_number_of_episodes": 950, "number_of_timesteps": 950000, "per_episode_reward": -445.45, "episode_reward_trend_value": 0.6675230027345277, "biggest_recent_change": 63.09513242403574},
{"total_number_of_episodes": 960, "number_of_timesteps": 960000, "per_episode_reward": -446.03, "episode_reward_trend_value": 0.6608177644545112, "biggest_recent_change": 63.09513242403574},
{"total_number_of_episodes": 970, "number_of_timesteps": 970000, "per_episode_reward": -446.61, "episode_reward_trend_value": 0.65515996772574, "biggest_recent_change": 63.09513242403574},
{"total_number_of_episodes": 980, "number_of_timesteps": 980000, "per_episode_reward": -447.52, "episode_reward_trend_value": 0.6427265653720017, "biggest_recent_change": 63.09513242403574},
{"total_number_of_episodes": 990, "number_of_timesteps": 990000, "per_episode_reward": -448.43, "episode_reward_trend_value": -0.06843942715339608, "biggest_recent_change": 1.270385999090479},
{"total_number_of_episodes": 1000, "number_of_timesteps": 1000000, "per_episode_reward": -449.22, "episode_reward_trend_value": -0.06308759484875597, "biggest_recent_change": 0.9098069032501144},
{"total_number_of_episodes": 1010, "number_of_timesteps": 1010000, "per_episode_reward": -450.01, "episode_reward_trend_value": -0.062229738247723765, "biggest_recent_change": 0.9098069032501144},
{"total_number_of_episodes": 1020, "number_of_timesteps": 1020000, "per_episode_reward": -450.34, "episode_reward_trend_value": -0.06598659709918972, "biggest_recent_change": 0.9098069032501144},
{"total_number_of_episodes": 1030, "number_of_timesteps": 1030000, "per_episode_reward": -450.66, "episode_reward_trend_value": -0.05971356335760952, "biggest_recent_change": 0.9098069032501144},
{"total_number_of_episodes": 1040, "number_of_timesteps": 1040000, "per_episode_reward": -451.29, "episode_reward_trend_value": -0.06481910848750848, "biggest_recent_change": 0.9098069032501144},
{"total_number_of_episodes": 1050, "number_of_timesteps": 1050000, "per_episode_reward": -451.91, "episode_reward_trend_value": -0.06530140266734684, "biggest_recent_change": 0.9098069032501144},
{"total_number_of_episodes": 1060, "number_of_timesteps": 1060000, "per_episode_reward": -452.43, "episode_reward_trend_value": -0.06468674068581777, "biggest_recent_change": 0.9098069032501144},
{"total_number_of_episodes": 1070, "number_of_timesteps": 1070000, "per_episode_reward": -452.96, "episode_reward_trend_value": -0.06039153977503512, "biggest_recent_change": 0.9098069032500575},
{"total_number_of_episodes": 1080, "number_of_timesteps": 1080000, "per_episode_reward": -453.19, "episode_reward_trend_value": -0.05286235613446087, "biggest_recent_change": 0.7887210916729828},
{"total_number_of_episodes": 1090, "number_of_timesteps": 1090000, "per_episode_reward": -453.42, "episode_reward_trend_value": -0.04667857040029983, "biggest_recent_change": 0.7887210916729828},
{"total_number_of_episodes": 1100, "number_of_timesteps": 1100000, "per_episode_reward": -454.08, "episode_reward_trend_value": -0.045272660037622044, "biggest_recent_change": 0.6621891590319819},
{"total_number_of_episodes": 1110, "number_of_timesteps": 1110000, "per_episode_reward": -455.5, "episode_reward_trend_value": -0.057324424932956065, "biggest_recent_change": 1.413449890076322},
{"total_number_of_episodes": 1120, "number_of_timesteps": 1120000, "per_episode_reward": -455.83, "episode_reward_trend_value": -0.05733761253007843, "biggest_recent_change": 1.413449890076322},
{"total_number_of_episodes": 1130, "number_of_timesteps": 1130000, "per_episode_reward": -456.16, "episode_reward_trend_value": -0.05409331316823922, "biggest_recent_change": 1.413449890076322},
{"total_number_of_episodes": 1140, "number_of_timesteps": 1140000, "per_episode_reward": -456.77, "episode_reward_trend_value": -0.054041114504018925, "biggest_recent_change": 1.413449890076322},
{"total_number_of_episodes": 1150, "number_of_timesteps": 1150000, "per_episode_reward": -457.39, "episode_reward_trend_value": -0.055085872001167345, "biggest_recent_change": 1.413449890076322},
{"total_number_of_episodes": 1160, "number_of_timesteps": 1160000, "per_episode_reward": -458.32, "episode_reward_trend_value": -0.05958725773374075, "biggest_recent_change": 1.413449890076322},
{"total_number_of_episodes": 1170, "number_of_timesteps": 1170000, "per_episode_reward": -459.25, "episode_reward_trend_value": -0.06732262619610765, "biggest_recent_change": 1.413449890076322},
{"total_number_of_episodes": 1180, "number_of_timesteps": 1180000, "per_episode_reward": -459.75, "episode_reward_trend_value": -0.07031338734336272, "biggest_recent_change": 1.413449890076322},
{"total_number_of_episodes": 1190, "number_of_timesteps": 1190000, "per_episode_reward": -460.25, "episode_reward_trend_value": -0.06852627311913326, "biggest_recent_change": 1.413449890076322},
{"total_number_of_episodes": 1200, "number_of_timesteps": 1200000, "per_episode_reward": -461.13, "episode_reward_trend_value": -0.06257798231327709, "biggest_recent_change": 0.9283635372113963},
{"total_number_of_episodes": 1210, "number_of_timesteps": 1210000, "per_episode_reward": -462.01, "episode_reward_trend_value": -0.06866826880563255, "biggest_recent_change": 0.9283635372113963},
{"total_number_of_episodes": 1220, "number_of_timesteps": 1220000, "per_episode_reward": -462.65, "episode_reward_trend_value": -0.0721463452545423, "biggest_recent_change": 0.9283635372113963},
{"total_number_of_episodes": 1230, "number_of_timesteps": 1230000, "per_episode_reward": -463.29, "episode_reward_trend_value": -0.07243232100583377, "biggest_recent_change": 0.9283635372113963},
{"total_number_of_episodes": 1240, "number_of_timesteps": 1240000, "per_episode_reward": -463.9, "episode_reward_trend_value": -0.07229122654299987, "biggest_recent_change": 0.9283635372113963},
{"total_number_of_episodes": 1250, "number_of_timesteps": 1250000, "per_episode_reward": -464.5, "episode_reward_trend_value": -0.06869350384474096, "biggest_recent_change": 0.9283635372113963},
{"total_number_of_episodes": 1260, "number_of_timesteps": 1260000, "per_episode_reward": -464.86, "episode_reward_trend_value": -0.06242300576865634, "biggest_recent_change": 0.8781037175492656},
{"total_number_of_episodes": 1270, "number_of_timesteps": 1270000, "per_episode_reward": -465.23, "episode_reward_trend_value": -0.060897115007684174, "biggest_recent_change": 0.8781037175492656},
{"total_number_of_episodes": 1280, "number_of_timesteps": 1280000, "per_episode_reward": -465.81, "episode_reward_trend_value": -0.061832184444001036, "biggest_recent_change": 0.8781037175492656},
{"total_number_of_episodes": 1290, "number_of_timesteps": 1290000, "per_episode_reward": -466.4, "episode_reward_trend_value": -0.0585810890058945, "biggest_recent_change": 0.8781037175492088},
{"total_number_of_episodes": 1300, "number_of_timesteps": 1300000, "per_episode_reward": -467.13, "episode_reward_trend_value": -0.056993922960967634, "biggest_recent_change": 0.7352587735057909},
{"total_number_of_episodes": 1310, "number_of_timesteps": 1310000, "per_episode_reward": -467.87, "episode_reward_trend_value": -0.05801896695948459, "biggest_recent_change": 0.7352587735057909},
{"total_number_of_episodes": 1320, "number_of_timesteps": 1320000, "per_episode_reward": -468.86, "episode_reward_trend_value": -0.06188073398353835, "biggest_recent_change": 0.9905638458040471},
{"total_number_of_episodes": 1330, "number_of_timesteps": 1330000, "per_episode_reward": -469.85, "episode_reward_trend_value": -0.06616957122171811, "biggest_recent_change": 0.990563845804104},
{"total_number_of_episodes": 1340, "number_of_timesteps": 1340000, "per_episode_reward": -470.28, "episode_reward_trend_value": -0.06416639958528284, "biggest_recent_change": 0.990563845804104},
{"total_number_of_episodes": 1350, "number_of_timesteps": 1350000, "per_episode_reward": -470.7, "episode_reward_trend_value": -0.06483600332667139, "biggest_recent_change": 0.990563845804104},
{"total_number_of_episodes": 1360, "number_of_timesteps": 1360000, "per_episode_reward": -471.34, "episode_reward_trend_value": -0.06789227144848078, "biggest_recent_change": 0.990563845804104},
{"total_number_of_episodes": 1370, "number_of_timesteps": 1370000, "per_episode_reward": -471.98, "episode_reward_trend_value": -0.06848757937299992, "biggest_recent_change": 0.990563845804104},
{"total_number_of_episodes": 1380, "number_of_timesteps": 1380000, "per_episode_reward": -472.82, "episode_reward_trend_value": -0.07139257268545217, "biggest_recent_change": 0.990563845804104},
{"total_number_of_episodes": 1390, "number_of_timesteps": 1390000, "per_episode_reward": -473.67, "episode_reward_trend_value": -0.07263363660472603, "biggest_recent_change": 0.990563845804104},
{"total_number_of_episodes": 1400, "number_of_timesteps": 1400000, "per_episode_reward": -474.55, "episode_reward_trend_value": -0.07424628500014971, "biggest_recent_change": 0.990563845804104},
{"total_number_of_episodes": 1410, "number_of_timesteps": 1410000, "per_episode_reward": -475.43, "episode_reward_trend_value": -0.07302221037003215, "biggest_recent_change": 0.990563845804104},
{"total_number_of_episodes": 1420, "number_of_timesteps": 1420000, "per_episode_reward": -476.06, "episode_reward_trend_value": -0.0689375618745967, "biggest_recent_change": 0.8803971290936943},
{"total_number_of_episodes": 1430, "number_of_timesteps": 1430000, "per_episode_reward": -476.68, "episode_reward_trend_value": -0.07114492225377375, "biggest_recent_change": 0.8803971290936943},
{"total_number_of_episodes": 1440, "number_of_timesteps": 1440000, "per_episode_reward": -477.13, "episode_reward_trend_value": -0.07142373876950248, "biggest_recent_change": 0.8803971290936943},
{"total_number_of_episodes": 1450, "number_of_timesteps": 1450000, "per_episode_reward": -477.58, "episode_reward_trend_value": -0.0693158909048091, "biggest_recent_change": 0.8803971290936943},
{"total_number_of_episodes": 1460, "number_of_timesteps": 1460000, "per_episode_reward": -478.74, "episode_reward_trend_value": -0.07510718627796488, "biggest_recent_change": 1.1602994249105905},
{"total_number_of_episodes": 1470, "number_of_timesteps": 1470000, "per_episode_reward": -479.9, "episode_reward_trend_value": -0.07858879626318943, "biggest_recent_change": 1.1602994249105905},
{"total_number_of_episodes": 1480, "number_of_timesteps": 1480000, "per_episode_reward": -480.37, "episode_reward_trend_value": -0.07447656135253296, "biggest_recent_change": 1.1602994249105905},
{"total_number_of_episodes": 1490, "number_of_timesteps": 1490000, "per_episode_reward": -480.85, "episode_reward_trend_value": -0.06999274196572919, "biggest_recent_change": 1.1602994249105905},
{"total_number_of_episodes": 1500, "number_of_timesteps": 1500000, "per_episode_reward": -481.23, "episode_reward_trend_value": -0.06441569441004605, "biggest_recent_change": 1.1602994249105905},
{"total_number_of_episodes": 1510, "number_of_timesteps": 1510000, "per_episode_reward": -481.61, "episode_reward_trend_value": -0.06169922071967954, "biggest_recent_change": 1.1602994249105905},
{"total_number_of_episodes": 1520, "number_of_timesteps": 1520000, "per_episode_reward": -482.36, "episode_reward_trend_value": -0.06307831743730566, "biggest_recent_change": 1.1602994249105905},
{"total_number_of_episodes": 1530, "number_of_timesteps": 1530000, "per_episode_reward": -483.1, "episode_reward_trend_value": -0.06638595801837886, "biggest_recent_change": 1.1602994249105905},
{"total_number_of_episodes": 1540, "number_of_timesteps": 1540000, "per_episode_reward": -484.74, "episode_reward_trend_value": -0.07956203676774799, "biggest_recent_change": 1.6352236209474995},
{"total_number_of_episodes": 1550, "number_of_timesteps": 1550000, "per_episode_reward": -486.37, "episode_reward_trend_value": -0.0848389722792692, "biggest_recent_change": 1.6352236209474995},
{"total_number_of_episodes": 1560, "number_of_timesteps": 1560000, "per_episode_reward": -488.02, "episode_reward_trend_value": -0.09019595446594494, "biggest_recent_change": 1.6424278217114079},
{"total_number_of_episodes": 1570, "number_of_timesteps": 1570000, "per_episode_reward": -489.66, "episode_reward_trend_value": -0.1031467815485011, "biggest_recent_change": 1.6424278217114079},
{"total_number_of_episodes": 1580, "number_of_timesteps": 1580000, "per_episode_reward": -491.37, "episode_reward_trend_value": -0.11692649144106326, "biggest_recent_change": 1.7170272746119508},
{"total_number_of_episodes": 1590, "number_of_timesteps": 1590000, "per_episode_reward": -493.09, "episode_reward_trend_value": -0.13179942950250986, "biggest_recent_change": 1.7170272746121782},
{"total_number_of_episodes": 1600, "number_of_timesteps": 1600000, "per_episode_reward": -494.5, "episode_reward_trend_value": -0.14326189369077155, "biggest_recent_change": 1.7170272746121782},
{"total_number_of_episodes": 1610, "number_of_timesteps": 1610000, "per_episode_reward": -495.91, "episode_reward_trend_value": -0.1506287874710444, "biggest_recent_change": 1.7170272746121782},
{"total_number_of_episodes": 1620, "number_of_timesteps": 1620000, "per_episode_reward": -496.41, "episode_reward_trend_value": -0.14787014357415654, "biggest_recent_change": 1.7170272746121782},
{"total_number_of_episodes": 1630, "number_of_timesteps": 1630000, "per_episode_reward": -496.91, "episode_reward_trend_value": -0.13524306150897397, "biggest_recent_change": 1.7170272746121782},
{"total_number_of_episodes": 1640, "number_of_timesteps": 1640000, "per_episode_reward": -498.84, "episode_reward_trend_value": -0.13856320938754782, "biggest_recent_change": 1.934036930019147},
{"total_number_of_episodes": 1650, "number_of_timesteps": 1650000, "per_episode_reward": -500.78, "episode_reward_trend_value": -0.14180331059096715, "biggest_recent_change": 1.934036930019147},
{"total_number_of_episodes": 1660, "number_of_timesteps": 1660000, "per_episode_reward": -505.95, "episode_reward_trend_value": -0.18096871345319981, "biggest_recent_change": 5.167314079312348},
{"total_number_of_episodes": 1670, "number_of_timesteps": 1670000, "per_episode_reward": -508.46, "episode_reward_trend_value": -0.18985309397433714, "biggest_recent_change": 5.167314079312348},
{"total_number_of_episodes": 1680, "number_of_timesteps": 1680000, "per_episode_reward": -510.95, "episode_reward_trend_value": -0.19841853440363164, "biggest_recent_change": 5.167314079312348},
{"total_number_of_episodes": 1690, "number_of_timesteps": 1690000, "per_episode_reward": -513.44, "episode_reward_trend_value": -0.2103944487061104, "biggest_recent_change": 5.167314079312348},
exited at update_barrier.wait(): 7
None
exited at update_barrier.wait(): 6
None
exited at update_barrier.wait(): 3
None
{"total_number_of_episodes": 1700, "number_of_timesteps": 1700000, "per_episode_reward": -515.53, "episode_reward_trend_value": -0.21797774567150188, "biggest_recent_change": 5.167314079312348},
{"total_number_of_episodes": 1710, "number_of_timesteps": 1710000, "per_episode_reward": -517.62, "episode_reward_trend_value": -0.23568658031405473, "biggest_recent_change": 5.167314079312348},
{"total_number_of_episodes": 1720, "number_of_timesteps": 1720000, "per_episode_reward": -520.8, "episode_reward_trend_value": -0.2654150230787713, "biggest_recent_change": 5.167314079312348},
{"total_number_of_episodes": 1730, "number_of_timesteps": 1730000, "per_episode_reward": -523.97, "episode_reward_trend_value": -0.279196235899734, "biggest_recent_change": 5.167314079312348},
{"total_number_of_episodes": 1740, "number_of_timesteps": 1740000, "per_episode_reward": -527.99, "episode_reward_trend_value": -0.30237615392456596, "biggest_recent_change": 5.167314079312348},
{"total_number_of_episodes": 1750, "number_of_timesteps": 1750000, "per_episode_reward": -532.01, "episode_reward_trend_value": -0.28963077029058704, "biggest_recent_change": 4.02022955225425},
{"total_number_of_episodes": 1760, "number_of_timesteps": 1760000, "per_episode_reward": -534.73, "episode_reward_trend_value": -0.2918757840552012, "biggest_recent_change": 4.02022955225425},
{"total_number_of_episodes": 1770, "number_of_timesteps": 1770000, "per_episode_reward": -537.45, "episode_reward_trend_value": -0.2944397379116557, "biggest_recent_change": 4.02022955225425},
{"total_number_of_episodes": 1780, "number_of_timesteps": 1780000, "per_episode_reward": -547.12, "episode_reward_trend_value": -0.37429417902450524, "biggest_recent_change": 9.674816613405028},
{"total_number_of_episodes": 1790, "number_of_timesteps": 1790000, "per_episode_reward": -556.8, "episode_reward_trend_value": -0.4585412374744389, "biggest_recent_change": 9.674816613405028},
{"total_number_of_episodes": 1800, "number_of_timesteps": 1800000, "per_episode_reward": -564.19, "episode_reward_trend_value": -0.5173693194631962, "biggest_recent_change": 9.674816613405028},
{"total_number_of_episodes": 1810, "number_of_timesteps": 1810000, "per_episode_reward": -571.57, "episode_reward_trend_value": -0.5641777933297892, "biggest_recent_change": 9.674816613405028},
{"total_number_of_episodes": 1820, "number_of_timesteps": 1820000, "per_episode_reward": -579.9, "episode_reward_trend_value": -0.6213791203035701, "biggest_recent_change": 9.674816613405028},
{"total_number_of_episodes": 1830, "number_of_timesteps": 1830000, "per_episode_reward": -588.22, "episode_reward_trend_value": -0.6691817420734789, "biggest_recent_change": 9.674816613405028},
{"total_number_of_episodes": 1840, "number_of_timesteps": 1840000, "per_episode_reward": -592.87, "episode_reward_trend_value": -0.6762319647048975, "biggest_recent_change": 9.674816613405028},
{"total_number_of_episodes": 1850, "number_of_timesteps": 1850000, "per_episode_reward": -597.53, "episode_reward_trend_value": -0.6977439294688124, "biggest_recent_change": 9.674816613405028},
{"total_number_of_episodes": 1860, "number_of_timesteps": 1860000, "per_episode_reward": -603.03, "episode_reward_trend_value": -0.7286766783342639, "biggest_recent_change": 9.674816613405028},
{"total_number_of_episodes": 1870, "number_of_timesteps": 1870000, "per_episode_reward": -608.53, "episode_reward_trend_value": -0.6823189399433243, "biggest_recent_change": 9.674816613404914},
{"total_number_of_episodes": 1880, "number_of_timesteps": 1880000, "per_episode_reward": -615.48, "episode_reward_trend_value": -0.652042112276197, "biggest_recent_change": 8.322465511546056},
{"total_number_of_episodes": 1890, "number_of_timesteps": 1890000, "per_episode_reward": -622.43, "episode_reward_trend_value": -0.6471842610702475, "biggest_recent_change": 8.322465511546056},
{"total_number_of_episodes": 1900, "number_of_timesteps": 1900000, "per_episode_reward": -634.66, "episode_reward_trend_value": -0.7009721006407542, "biggest_recent_change": 12.228014293244541},
{"total_number_of_episodes": 1910, "number_of_timesteps": 1910000, "per_episode_reward": -646.89, "episode_reward_trend_value": -0.7443670871040695, "biggest_recent_change": 12.228014293244541},
{"total_number_of_episodes": 1920, "number_of_timesteps": 1920000, "per_episode_reward": -673.9, "episode_reward_trend_value": -0.9520584265213768, "biggest_recent_change": 27.014686059103497},
{"total_number_of_episodes": 1930, "number_of_timesteps": 1930000, "per_episode_reward": -700.92, "episode_reward_trend_value": -1.200502165077171, "biggest_recent_change": 27.014686059103497},
Hit early stopping because per_episode_reward: -700.9179785466728 < -700
exited at when_all_processes_are_updated(): 1
exited at update_barrier.wait(): 1
None
exited at update_barrier.wait(): 4
None
[32m[I 2022-11-13 14:50:37,811][0m Trial 13 finished with value: -706.4750811763313 and parameters: {'activation': 2, 't_max': 1, 'hidden_size': 3, 'variance_scaling_factor': 2, 'permaban_threshold': 2, 'learning_rate_base': 1, 'learning_rate_exponent': 3, 'beta_base': 4, 'beta_exponent': 5}. Best is trial 8 with value: -474.81943435273513.[0m
config = {
    "evaluation": {
        "enabled": False, 
        "number_of_episodes_before_eval": 550, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": None, 
            "number_of_episodes": 10, 
        }, 
    }, 
    "verbose": False, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0.1, 
        "min_number_of_episodes": 10, 
        "thresholds": {10: -700, }, 
    }, 
    "tuning": {
        "number_of_trials": 3000, 
        "phase_1": {
            "categorical_options": {"activation": [0, 1, 2, ], }, 
            "sequential_options": {
                "t_max": [3, 5, 10, 20, 30, 50, ], 
                "hidden_size": [16, 32, 64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-1, -2, -3, -4, -5, -6, -7, -8, ], 
                }, 
            }, 
        }, 
        "phase_2": {
            "sequential_options": {
                "t_max": [3, 5, ], 
                "hidden_size": [64, 128, ], 
                "variance_scaling_factor": [0.01, 1, 100, 1000, ], 
                "permaban_threshold": [100, 500, 1000, 2000, 10000, ], 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, ], 
                }, 
                "beta": {
                    "base": [1, 3, 5, 7, 9, ], 
                    "exponent": [-4, -5, -6, -7, ], 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 80000, }, 
    "env_config": {
        "env_name": "HalfCheetah-v2", 
        "learning_rate": 9e-05, 
        "beta": 9e-07, 
        "t_max": 10, 
        "activation": 0, 
        "hidden_size": 128, 
        "variance_scaling_factor": 0.01, 
        "permaban_threshold": 500, 
    }, 
}
args = {
    "processes": 10, 
    "env": "HalfCheetah-v2", 
    "seed": 1142411245, 
    "outdir": "results", 
    "t_max": 10, 
    "beta": 9e-07, 
    "profile": False, 
    "steps": 80000, 
    "max_frames": (108000, ), 
    "lr": 9e-05, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 500, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 128, 
    "activation": 0, 
}
{"total_number_of_episodes": 20, "number_of_timesteps": 20000, "per_episode_reward": -654.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"total_number_of_episodes": 30, "number_of_timesteps": 30000, "per_episode_reward": -644.32, "episode_reward_trend_value": 0.9671849164785045, "biggest_recent_change": NaN},
{"total_number_of_episodes": 40, "number_of_timesteps": 40000, "per_episode_reward": -650.87, "episode_reward_trend_value": 0.15637657651521977, "biggest_recent_change": NaN},
{"total_number_of_episodes": 50, "number_of_timesteps": 50000, "per_episode_reward": -659.39, "episode_reward_trend_value": -0.1798888080725078, "biggest_recent_change": NaN},
{"total_number_of_episodes": 60, "number_of_timesteps": 60000, "per_episode_reward": -652.18, "episode_reward_trend_value": 0.045290380978073586, "biggest_recent_change": NaN},
{"total_number_of_episodes": 70, "number_of_timesteps": 70000, "per_episode_reward": -651.82, "episode_reward_trend_value": 0.04342188196704001, "biggest_recent_change": NaN},
{"total_number_of_episodes": 80, "number_of_timesteps": 80000, "per_episode_reward": -651.08, "episode_reward_trend_value": 0.04865997561226057, "biggest_recent_change": NaN},
{"total_number_of_episodes": 90, "number_of_timesteps": 90000, "per_episode_reward": -649.0, "episode_reward_trend_value": 0.07132078885373241, "biggest_recent_change": NaN},
{"total_number_of_episodes": 100, "number_of_timesteps": 100000, "per_episode_reward": -651.51, "episode_reward_trend_value": 0.0310063982243463, "biggest_recent_change": NaN},
{"total_number_of_episodes": 110, "number_of_timesteps": 110000, "per_episode_reward": -653.85, "episode_reward_trend_value": 0.0015881245053378733, "biggest_recent_change": 9.671849164785044},
{"total_number_of_episodes": 120, "number_of_timesteps": 120000, "per_episode_reward": -651.64, "episode_reward_trend_value": -0.0813418833917126, "biggest_recent_change": 8.52419577247963},
{"total_number_of_episodes": 130, "number_of_timesteps": 130000, "per_episode_reward": -657.2, "episode_reward_trend_value": -0.07034970984567003, "biggest_recent_change": 8.52419577247963},
{"total_number_of_episodes": 140, "number_of_timesteps": 140000, "per_episode_reward": -657.03, "episode_reward_trend_value": 0.026259557413484597, "biggest_recent_change": 7.208279481298177},
{"total_number_of_episodes": 150, "number_of_timesteps": 150000, "per_episode_reward": -658.82, "episode_reward_trend_value": -0.07375566287344479, "biggest_recent_change": 5.555022015336817},
{"total_number_of_episodes": 160, "number_of_timesteps": 160000, "per_episode_reward": -658.19, "episode_reward_trend_value": -0.07073795720993985, "biggest_recent_change": 5.555022015336817},
{"total_number_of_episodes": 170, "number_of_timesteps": 170000, "per_episode_reward": -664.86, "episode_reward_trend_value": -0.1531723343081833, "biggest_recent_change": 6.670589500458277},
{"total_number_of_episodes": 180, "number_of_timesteps": 180000, "per_episode_reward": -660.14, "episode_reward_trend_value": -0.12374684289073912, "biggest_recent_change": 6.670589500458277},
{"total_number_of_episodes": 190, "number_of_timesteps": 190000, "per_episode_reward": -662.37, "episode_reward_trend_value": -0.12056051115158399, "biggest_recent_change": 6.670589500458277},
{"total_number_of_episodes": 200, "number_of_timesteps": 200000, "per_episode_reward": -663.8, "episode_reward_trend_value": -0.11054659416453963, "biggest_recent_change": 6.670589500458277},
{"total_number_of_episodes": 210, "number_of_timesteps": 210000, "per_episode_reward": -665.67, "episode_reward_trend_value": -0.15581381428206542, "biggest_recent_change": 6.670589500458277},
{"total_number_of_episodes": 220, "number_of_timesteps": 220000, "per_episode_reward": -599.65, "episode_reward_trend_value": 0.6394526680305552, "biggest_recent_change": 66.01896139279904},
{"total_number_of_episodes": 230, "number_of_timesteps": 230000, "per_episode_reward": -600.01, "episode_reward_trend_value": 0.6335465562018903, "biggest_recent_change": 66.01896139279904},
{"total_number_of_episodes": 240, "number_of_timesteps": 240000, "per_episode_reward": -599.91, "episode_reward_trend_value": 0.6545827836395688, "biggest_recent_change": 66.01896139279904},
{"total_number_of_episodes": 250, "number_of_timesteps": 250000, "per_episode_reward": -600.74, "episode_reward_trend_value": 0.6382912086947601, "biggest_recent_change": 66.01896139279904},
{"total_number_of_episodes": 260, "number_of_timesteps": 260000, "per_episode_reward": -601.33, "episode_reward_trend_value": 0.7058798867724666, "biggest_recent_change": 66.01896139279904},
{"total_number_of_episodes": 270, "number_of_timesteps": 270000, "per_episode_reward": -602.37, "episode_reward_trend_value": 0.6419000451422145, "biggest_recent_change": 66.01896139279904},
{"total_number_of_episodes": 280, "number_of_timesteps": 280000, "per_episode_reward": -602.5, "episode_reward_trend_value": 0.6652022148258273, "biggest_recent_change": 66.01896139279904},
{"total_number_of_episodes": 290, "number_of_timesteps": 290000, "per_episode_reward": -603.24, "episode_reward_trend_value": 0.6729255557293312, "biggest_recent_change": 66.01896139279904},
{"total_number_of_episodes": 300, "number_of_timesteps": 300000, "per_episode_reward": -603.61, "episode_reward_trend_value": 0.6895002826369263, "biggest_recent_change": 66.01896139279904},
{"total_number_of_episodes": 310, "number_of_timesteps": 310000, "per_episode_reward": -604.23, "episode_reward_trend_value": -0.05092273909295323, "biggest_recent_change": 1.0370348361270771},
{"total_number_of_episodes": 320, "number_of_timesteps": 320000, "per_episode_reward": -604.83, "episode_reward_trend_value": -0.05360518007418654, "biggest_recent_change": 1.0370348361270771},
{"total_number_of_episodes": 330, "number_of_timesteps": 330000, "per_episode_reward": -604.49, "episode_reward_trend_value": -0.05091005019512775, "biggest_recent_change": 1.0370348361270771},
{"total_number_of_episodes": 340, "number_of_timesteps": 340000, "per_episode_reward": -604.03, "episode_reward_trend_value": -0.036481288084288126, "biggest_recent_change": 1.0370348361270771},
{"total_number_of_episodes": 350, "number_of_timesteps": 350000, "per_episode_reward": -603.82, "episode_reward_trend_value": -0.027599120823278, "biggest_recent_change": 1.0370348361270771},
{"total_number_of_episodes": 360, "number_of_timesteps": 360000, "per_episode_reward": -602.83, "episode_reward_trend_value": -0.00511205622715099, "biggest_recent_change": 0.9868009775243536},
{"total_number_of_episodes": 370, "number_of_timesteps": 370000, "per_episode_reward": -603.24, "episode_reward_trend_value": -0.00824072766252281, "biggest_recent_change": 0.9868009775243536},
{"total_number_of_episodes": 380, "number_of_timesteps": 380000, "per_episode_reward": -603.23, "episode_reward_trend_value": 0.0001318596312987413, "biggest_recent_change": 0.9868009775243536},
{"total_number_of_episodes": 390, "number_of_timesteps": 390000, "per_episode_reward": -604.26, "episode_reward_trend_value": -0.007163216804494571, "biggest_recent_change": 1.0307328140646632},
{"total_number_of_episodes": 400, "number_of_timesteps": 400000, "per_episode_reward": -604.12, "episode_reward_trend_value": 0.0012020357334816053, "biggest_recent_change": 1.0307328140646632},
{"total_number_of_episodes": 410, "number_of_timesteps": 410000, "per_episode_reward": -604.98, "episode_reward_trend_value": -0.0016087333268514057, "biggest_recent_change": 1.0307328140646632},
{"total_number_of_episodes": 420, "number_of_timesteps": 420000, "per_episode_reward": -604.76, "episode_reward_trend_value": -0.0029371489948870374, "biggest_recent_change": 1.0307328140646632},
{"total_number_of_episodes": 430, "number_of_timesteps": 430000, "per_episode_reward": -604.85, "episode_reward_trend_value": -0.009099105125382164, "biggest_recent_change": 1.0307328140646632},
{"total_number_of_episodes": 440, "number_of_timesteps": 440000, "per_episode_reward": -604.68, "episode_reward_trend_value": -0.009619369725602508, "biggest_recent_change": 1.0307328140646632},
{"total_number_of_episodes": 450, "number_of_timesteps": 450000, "per_episode_reward": -604.8, "episode_reward_trend_value": -0.021867086834882025, "biggest_recent_change": 1.0307328140646632},
{"total_number_of_episodes": 460, "number_of_timesteps": 460000, "per_episode_reward": -605.26, "episode_reward_trend_value": -0.022502565830649877, "biggest_recent_change": 1.0307328140646632},
{"total_number_of_episodes": 470, "number_of_timesteps": 470000, "per_episode_reward": -604.81, "episode_reward_trend_value": -0.017543634284273444, "biggest_recent_change": 1.0307328140646632},
{"total_number_of_episodes": 480, "number_of_timesteps": 480000, "per_episode_reward": -604.79, "episode_reward_trend_value": -0.005962895138357757, "biggest_recent_change": 0.8553006874765288},
{"total_number_of_episodes": 490, "number_of_timesteps": 490000, "per_episode_reward": -604.42, "episode_reward_trend_value": -0.0033268240245522265, "biggest_recent_change": 0.8553006874765288},
{"total_number_of_episodes": 500, "number_of_timesteps": 500000, "per_episode_reward": -605.39, "episode_reward_trend_value": -0.004610753972732104, "biggest_recent_change": 0.9708543828127176},
{"total_number_of_episodes": 510, "number_of_timesteps": 510000, "per_episode_reward": -605.43, "episode_reward_trend_value": -0.007450489338311349, "biggest_recent_change": 0.9708543828127176},
{"total_number_of_episodes": 520, "number_of_timesteps": 520000, "per_episode_reward": -605.11, "episode_reward_trend_value": -0.0029572410145710312, "biggest_recent_change": 0.9708543828127176},
{"total_number_of_episodes": 530, "number_of_timesteps": 530000, "per_episode_reward": -604.86, "episode_reward_trend_value": -0.0019844972776367183, "biggest_recent_change": 0.9708543828127176},
{"total_number_of_episodes": 540, "number_of_timesteps": 540000, "per_episode_reward": -605.18, "episode_reward_trend_value": -0.0042836288561855125, "biggest_recent_change": 0.9708543828127176},
{"total_number_of_episodes": 550, "number_of_timesteps": 550000, "per_episode_reward": -605.69, "episode_reward_trend_value": -0.0047411570654452995, "biggest_recent_change": 0.9708543828127176},
{"total_number_of_episodes": 560, "number_of_timesteps": 560000, "per_episode_reward": -605.45, "episode_reward_trend_value": -0.007202378234449548, "biggest_recent_change": 0.9708543828127176},
{"total_number_of_episodes": 570, "number_of_timesteps": 570000, "per_episode_reward": -605.5, "episode_reward_trend_value": -0.007848925502560177, "biggest_recent_change": 0.9708543828127176},
{"total_number_of_episodes": 580, "number_of_timesteps": 580000, "per_episode_reward": -606.01, "episode_reward_trend_value": -0.017601464711327074, "biggest_recent_change": 0.9708543828127176},
{"total_number_of_episodes": 590, "number_of_timesteps": 590000, "per_episode_reward": -606.09, "episode_reward_trend_value": -0.00774817384891296, "biggest_recent_change": 0.5079293114004031},
{"total_number_of_episodes": 600, "number_of_timesteps": 600000, "per_episode_reward": -606.42, "episode_reward_trend_value": -0.011034326806654665, "biggest_recent_change": 0.5079293114004031},
{"total_number_of_episodes": 610, "number_of_timesteps": 610000, "per_episode_reward": -606.35, "episode_reward_trend_value": -0.013788018633147204, "biggest_recent_change": 0.5079293114004031},
{"total_number_of_episodes": 620, "number_of_timesteps": 620000, "per_episode_reward": -606.42, "episode_reward_trend_value": -0.017314706161535773, "biggest_recent_change": 0.5079293114004031},
{"total_number_of_episodes": 630, "number_of_timesteps": 630000, "per_episode_reward": -606.07, "episode_reward_trend_value": -0.009884182751500247, "biggest_recent_change": 0.5079293114004031},
{"total_number_of_episodes": 640, "number_of_timesteps": 640000, "per_episode_reward": -606.07, "episode_reward_trend_value": -0.004216996282399224, "biggest_recent_change": 0.5067199630187815},
{"total_number_of_episodes": 650, "number_of_timesteps": 650000, "per_episode_reward": -606.79, "episode_reward_trend_value": -0.01490304675904781, "biggest_recent_change": 0.7246451948088861},
{"total_number_of_episodes": 660, "number_of_timesteps": 660000, "per_episode_reward": -606.7, "episode_reward_trend_value": -0.013365515693389321, "biggest_recent_change": 0.7246451948088861},
{"total_number_of_episodes": 670, "number_of_timesteps": 670000, "per_episode_reward": -538.69, "episode_reward_trend_value": 0.7479846083873831, "biggest_recent_change": 68.01479120425074},
{"total_number_of_episodes": 680, "number_of_timesteps": 680000, "per_episode_reward": -538.76, "episode_reward_trend_value": 0.7481450855509252, "biggest_recent_change": 68.01479120425074},
{"total_number_of_episodes": 690, "number_of_timesteps": 690000, "per_episode_reward": -538.19, "episode_reward_trend_value": 0.7580854790325311, "biggest_recent_change": 68.01479120425074},
{"total_number_of_episodes": 700, "number_of_timesteps": 700000, "per_episode_reward": -538.22, "episode_reward_trend_value": 0.7570859684799505, "biggest_recent_change": 68.01479120425074},
{"total_number_of_episodes": 710, "number_of_timesteps": 710000, "per_episode_reward": -538.07, "episode_reward_trend_value": 0.7594307243844658, "biggest_recent_change": 68.01479120425074},
{"total_number_of_episodes": 720, "number_of_timesteps": 720000, "per_episode_reward": -538.85, "episode_reward_trend_value": 0.7469642719300837, "biggest_recent_change": 68.01479120425074},
{"total_number_of_episodes": 730, "number_of_timesteps": 730000, "per_episode_reward": -538.94, "episode_reward_trend_value": 0.745895413317669, "biggest_recent_change": 68.01479120425074},
{"total_number_of_episodes": 740, "number_of_timesteps": 740000, "per_episode_reward": -538.86, "episode_reward_trend_value": 0.7548725662660546, "biggest_recent_change": 68.01479120425074},
{"total_number_of_episodes": 750, "number_of_timesteps": 750000, "per_episode_reward": -538.77, "episode_reward_trend_value": 0.7547789698182644, "biggest_recent_change": 68.01479120425074},
{"total_number_of_episodes": 760, "number_of_timesteps": 760000, "per_episode_reward": -538.39, "episode_reward_trend_value": 0.0033329312453335863, "biggest_recent_change": 0.7756490183713822},
{"total_number_of_episodes": 770, "number_of_timesteps": 770000, "per_episode_reward": -538.17, "episode_reward_trend_value": 0.006488530133277789, "biggest_recent_change": 0.7756490183713822},
{"total_number_of_episodes": 780, "number_of_timesteps": 780000, "per_episode_reward": -538.5, "episode_reward_trend_value": -0.003440865923487814, "biggest_recent_change": 0.7756490183713822},
{"total_number_of_episodes": 790, "number_of_timesteps": 790000, "per_episode_reward": -538.44, "episode_reward_trend_value": -0.0024714516240224938, "biggest_recent_change": 0.7756490183713822},
{"total_number_of_episodes": 800, "number_of_timesteps": 800000, "per_episode_reward": -538.84, "episode_reward_trend_value": -0.008555206807550854, "biggest_recent_change": 0.7756490183713822},
{"total_number_of_episodes": 810, "number_of_timesteps": 810000, "per_episode_reward": -538.9, "episode_reward_trend_value": -0.0006345730340020357, "biggest_recent_change": 0.40140211033565265},
{"total_number_of_episodes": 820, "number_of_timesteps": 820000, "per_episode_reward": -538.96, "episode_reward_trend_value": -0.00019596187263712432, "biggest_recent_change": 0.40140211033565265},
{"total_number_of_episodes": 830, "number_of_timesteps": 830000, "per_episode_reward": -538.97, "episode_reward_trend_value": -0.0012279875967515686, "biggest_recent_change": 0.40140211033565265},
{"total_number_of_episodes": 840, "number_of_timesteps": 840000, "per_episode_reward": -539.3, "episode_reward_trend_value": -0.0058372837832280314, "biggest_recent_change": 0.40140211033565265},
{"total_number_of_episodes": 850, "number_of_timesteps": 850000, "per_episode_reward": -539.16, "episode_reward_trend_value": -0.00856175337561985, "biggest_recent_change": 0.40140211033565265},
{"total_number_of_episodes": 860, "number_of_timesteps": 860000, "per_episode_reward": -539.15, "episode_reward_trend_value": -0.010854948654716484, "biggest_recent_change": 0.40140211033565265},
{"total_number_of_episodes": 870, "number_of_timesteps": 870000, "per_episode_reward": -539.37, "episode_reward_trend_value": -0.009615530911826733, "biggest_recent_change": 0.40140211033565265},
{"total_number_of_episodes": 880, "number_of_timesteps": 880000, "per_episode_reward": -539.48, "episode_reward_trend_value": -0.01153262912496555, "biggest_recent_change": 0.40140211033565265},
{"total_number_of_episodes": 890, "number_of_timesteps": 890000, "per_episode_reward": -539.22, "episode_reward_trend_value": -0.00426410363270659, "biggest_recent_change": 0.3315380862369466},
{"total_number_of_episodes": 900, "number_of_timesteps": 900000, "per_episode_reward": -538.99, "episode_reward_trend_value": -0.0009612361773810739, "biggest_recent_change": 0.3315380862369466},
{"total_number_of_episodes": 910, "number_of_timesteps": 910000, "per_episode_reward": -539.18, "episode_reward_trend_value": -0.0024837308367801196, "biggest_recent_change": 0.3315380862369466},
{"total_number_of_episodes": 920, "number_of_timesteps": 920000, "per_episode_reward": -539.34, "episode_reward_trend_value": -0.0041423698741911924, "biggest_recent_change": 0.3315380862369466},
{"total_number_of_episodes": 930, "number_of_timesteps": 930000, "per_episode_reward": -539.46, "episode_reward_trend_value": -0.0017580969166285994, "biggest_recent_change": 0.2527651839676537},
{"total_number_of_episodes": 940, "number_of_timesteps": 940000, "per_episode_reward": -539.62, "episode_reward_trend_value": -0.0051005961426098005, "biggest_recent_change": 0.2527651839676537},
{"total_number_of_episodes": 950, "number_of_timesteps": 950000, "per_episode_reward": -539.4, "episode_reward_trend_value": -0.002728914626794045, "biggest_recent_change": 0.2527651839676537},
{"total_number_of_episodes": 960, "number_of_timesteps": 960000, "per_episode_reward": -539.05, "episode_reward_trend_value": 0.0035379825610625123, "biggest_recent_change": 0.3484025667615924},
{"total_number_of_episodes": 970, "number_of_timesteps": 970000, "per_episode_reward": -538.79, "episode_reward_trend_value": 0.007614702504501263, "biggest_recent_change": 0.3484025667615924},
{"total_number_of_episodes": 980, "number_of_timesteps": 980000, "per_episode_reward": -539.02, "episode_reward_trend_value": 0.002241863485950388, "biggest_recent_change": 0.3484025667615924},
{"total_number_of_episodes": 990, "number_of_timesteps": 990000, "per_episode_reward": -539.25, "episode_reward_trend_value": -0.0029369391462713184, "biggest_recent_change": 0.3484025667615924},
{"total_number_of_episodes": 1000, "number_of_timesteps": 1000000, "per_episode_reward": -538.92, "episode_reward_trend_value": 0.002844496967802317, "biggest_recent_change": 0.3484025667615924},
{"total_number_of_episodes": 1010, "number_of_timesteps": 1010000, "per_episode_reward": -538.62, "episode_reward_trend_value": 0.008039218213021589, "biggest_recent_change": 0.3484025667615924},
{"total_number_of_episodes": 1020, "number_of_timesteps": 1020000, "per_episode_reward": -539.05, "episode_reward_trend_value": 0.004483307851352139, "biggest_recent_change": 0.43698545260656374},
{"total_number_of_episodes": 1030, "number_of_timesteps": 1030000, "per_episode_reward": -538.84, "episode_reward_trend_value": 0.008621475499162696, "biggest_recent_change": 0.43698545260656374},
{"total_number_of_episodes": 1040, "number_of_timesteps": 1040000, "per_episode_reward": -538.99, "episode_reward_trend_value": 0.004513294607042756, "biggest_recent_change": 0.43698545260656374},
{"total_number_of_episodes": 1050, "number_of_timesteps": 1050000, "per_episode_reward": -538.99, "episode_reward_trend_value": 0.0006931482203653003, "biggest_recent_change": 0.43698545260656374},
{"total_number_of_episodes": 1060, "number_of_timesteps": 1060000, "per_episode_reward": -539.23, "episode_reward_trend_value": -0.0048417557931315965, "biggest_recent_change": 0.43698545260656374},
{"total_number_of_episodes": 1070, "number_of_timesteps": 1070000, "per_episode_reward": -472.71, "episode_reward_trend_value": 0.7367971448123601, "biggest_recent_change": 66.51671072679233},
{"total_number_of_episodes": 1080, "number_of_timesteps": 1080000, "per_episode_reward": -473.27, "episode_reward_trend_value": 0.7331285419268309, "biggest_recent_change": 66.51671072679233},
{"total_number_of_episodes": 1090, "number_of_timesteps": 1090000, "per_episode_reward": -473.44, "episode_reward_trend_value": 0.7276090417894137, "biggest_recent_change": 66.51671072679233},
{"total_number_of_episodes": 1100, "number_of_timesteps": 1100000, "per_episode_reward": -472.84, "episode_reward_trend_value": 0.7307990261030972, "biggest_recent_change": 66.51671072679233},
{"total_number_of_episodes": 1110, "number_of_timesteps": 1110000, "per_episode_reward": -472.76, "episode_reward_trend_value": 0.736590068813862, "biggest_recent_change": 66.51671072679233},
{"total_number_of_episodes": 1120, "number_of_timesteps": 1120000, "per_episode_reward": -473.01, "episode_reward_trend_value": 0.7314351672754198, "biggest_recent_change": 66.51671072679233},
{"total_number_of_episodes": 1130, "number_of_timesteps": 1130000, "per_episode_reward": -473.35, "episode_reward_trend_value": 0.7293454585103525, "biggest_recent_change": 66.51671072679233},
{"total_number_of_episodes": 1140, "number_of_timesteps": 1140000, "per_episode_reward": -472.99, "episode_reward_trend_value": 0.7332987970199617, "biggest_recent_change": 66.51671072679233},
{"total_number_of_episodes": 1150, "number_of_timesteps": 1150000, "per_episode_reward": -473.38, "episode_reward_trend_value": 0.7316646615648222, "biggest_recent_change": 66.51671072679233},
{"total_number_of_episodes": 1160, "number_of_timesteps": 1160000, "per_episode_reward": -473.61, "episode_reward_trend_value": -0.009956436236081521, "biggest_recent_change": 0.5957622423097746},
{"total_number_of_episodes": 1170, "number_of_timesteps": 1170000, "per_episode_reward": -473.99, "episode_reward_trend_value": -0.007924540830282467, "biggest_recent_change": 0.5957622423097746},
{"total_number_of_episodes": 1180, "number_of_timesteps": 1180000, "per_episode_reward": -473.79, "episode_reward_trend_value": -0.0039058369696483115, "biggest_recent_change": 0.5957622423097746},
{"total_number_of_episodes": 1190, "number_of_timesteps": 1190000, "per_episode_reward": -474.13, "episode_reward_trend_value": -0.01425917851410582, "biggest_recent_change": 0.3881530123356356},
{"total_number_of_episodes": 1200, "number_of_timesteps": 1200000, "per_episode_reward": -474.23, "episode_reward_trend_value": -0.0163062904215211, "biggest_recent_change": 0.3881530123356356},
{"total_number_of_episodes": 1210, "number_of_timesteps": 1210000, "per_episode_reward": -474.69, "episode_reward_trend_value": -0.018585838325529697, "biggest_recent_change": 0.45804482248422573},
{"total_number_of_episodes": 1220, "number_of_timesteps": 1220000, "per_episode_reward": -474.55, "episode_reward_trend_value": -0.013328412078052704, "biggest_recent_change": 0.45804482248422573},
{"total_number_of_episodes": 1230, "number_of_timesteps": 1230000, "per_episode_reward": -474.39, "episode_reward_trend_value": -0.015604345552506832, "biggest_recent_change": 0.45804482248422573},
{"total_number_of_episodes": 1240, "number_of_timesteps": 1240000, "per_episode_reward": -473.84, "episode_reward_trend_value": -0.005117097195803429, "biggest_recent_change": 0.5556993397676706},
{"total_number_of_episodes": 1250, "number_of_timesteps": 1250000, "per_episode_reward": -474.37, "episode_reward_trend_value": -0.008499817852048687, "biggest_recent_change": 0.5556993397676706},
{"total_number_of_episodes": 1260, "number_of_timesteps": 1260000, "per_episode_reward": -474.87, "episode_reward_trend_value": -0.009876527956612336, "biggest_recent_change": 0.5556993397676706},
{"total_number_of_episodes": 1270, "number_of_timesteps": 1270000, "per_episode_reward": -475.38, "episode_reward_trend_value": -0.01761499455098361, "biggest_recent_change": 0.5556993397676706},
{"total_number_of_episodes": 1280, "number_of_timesteps": 1280000, "per_episode_reward": -475.64, "episode_reward_trend_value": -0.016819530482129925, "biggest_recent_change": 0.5556993397676706},
{"total_number_of_episodes": 1290, "number_of_timesteps": 1290000, "per_episode_reward": -475.91, "episode_reward_trend_value": -0.018646364373121414, "biggest_recent_change": 0.5556993397676706},
{"total_number_of_episodes": 1300, "number_of_timesteps": 1300000, "per_episode_reward": -476.08, "episode_reward_trend_value": -0.015489818904959898, "biggest_recent_change": 0.5556993397676706},
{"total_number_of_episodes": 1310, "number_of_timesteps": 1310000, "per_episode_reward": -476.28, "episode_reward_trend_value": -0.019278484122744053, "biggest_recent_change": 0.5556993397676706},
{"total_number_of_episodes": 1320, "number_of_timesteps": 1320000, "per_episode_reward": -476.77, "episode_reward_trend_value": -0.026454566100668826, "biggest_recent_change": 0.5556993397676706},
{"total_number_of_episodes": 1330, "number_of_timesteps": 1330000, "per_episode_reward": -477.26, "episode_reward_trend_value": -0.038076686907961246, "biggest_recent_change": 0.5336329343510897},
{"total_number_of_episodes": 1340, "number_of_timesteps": 1340000, "per_episode_reward": -477.81, "episode_reward_trend_value": -0.03825279324179418, "biggest_recent_change": 0.5494825043960532},
{"total_number_of_episodes": 1350, "number_of_timesteps": 1350000, "per_episode_reward": -478.36, "episode_reward_trend_value": -0.0387711129877611, "biggest_recent_change": 0.54948250439611},
{"total_number_of_episodes": 1360, "number_of_timesteps": 1360000, "per_episode_reward": -478.7, "episode_reward_trend_value": -0.03687761838555288, "biggest_recent_change": 0.54948250439611},
{"total_number_of_episodes": 1370, "number_of_timesteps": 1370000, "per_episode_reward": -479.03, "episode_reward_trend_value": -0.037632868191838045, "biggest_recent_change": 0.54948250439611},
{"total_number_of_episodes": 1380, "number_of_timesteps": 1380000, "per_episode_reward": -479.5, "episode_reward_trend_value": -0.03996108652307713, "biggest_recent_change": 0.54948250439611},
{"total_number_of_episodes": 1390, "number_of_timesteps": 1390000, "per_episode_reward": -479.98, "episode_reward_trend_value": -0.04329476041147713, "biggest_recent_change": 0.54948250439611},
{"total_number_of_episodes": 1400, "number_of_timesteps": 1400000, "per_episode_reward": -480.5, "episode_reward_trend_value": -0.04682095737067521, "biggest_recent_change": 0.54948250439611},
{"total_number_of_episodes": 1410, "number_of_timesteps": 1410000, "per_episode_reward": -481.02, "episode_reward_trend_value": -0.04716801702812619, "biggest_recent_change": 0.54948250439611},
{"total_number_of_episodes": 1420, "number_of_timesteps": 1420000, "per_episode_reward": -481.38, "episode_reward_trend_value": -0.045712922186309395, "biggest_recent_change": 0.54948250439611},
{"total_number_of_episodes": 1430, "number_of_timesteps": 1430000, "per_episode_reward": -481.74, "episode_reward_trend_value": -0.04360014988329921, "biggest_recent_change": 0.54948250439611},
{"total_number_of_episodes": 1440, "number_of_timesteps": 1440000, "per_episode_reward": -482.22, "episode_reward_trend_value": -0.04290021418062035, "biggest_recent_change": 0.5215269020592928},
{"total_number_of_episodes": 1450, "number_of_timesteps": 1450000, "per_episode_reward": -482.71, "episode_reward_trend_value": -0.04461209282612104, "biggest_recent_change": 0.5215269020592928},
{"total_number_of_episodes": 1460, "number_of_timesteps": 1460000, "per_episode_reward": -483.01, "episode_reward_trend_value": -0.04424752901835265, "biggest_recent_change": 0.5215269020592928},
{"total_number_of_episodes": 1470, "number_of_timesteps": 1470000, "per_episode_reward": -483.31, "episode_reward_trend_value": -0.04230999668563224, "biggest_recent_change": 0.5215269020592928},
{"total_number_of_episodes": 1480, "number_of_timesteps": 1480000, "per_episode_reward": -483.83, "episode_reward_trend_value": -0.04283981687309506, "biggest_recent_change": 0.5216701971773432},
{"total_number_of_episodes": 1490, "number_of_timesteps": 1490000, "per_episode_reward": -484.35, "episode_reward_trend_value": -0.042841409041072136, "biggest_recent_change": 0.5216701971773432},
{"total_number_of_episodes": 1500, "number_of_timesteps": 1500000, "per_episode_reward": -485.12, "episode_reward_trend_value": -0.04551457921021817, "biggest_recent_change": 0.7621122172823789},
{"total_number_of_episodes": 1510, "number_of_timesteps": 1510000, "per_episode_reward": -485.88, "episode_reward_trend_value": -0.049989903878631975, "biggest_recent_change": 0.7621122172823789},
{"total_number_of_episodes": 1520, "number_of_timesteps": 1520000, "per_episode_reward": -486.36, "episode_reward_trend_value": -0.0513320942716291, "biggest_recent_change": 0.7621122172823789},
{"total_number_of_episodes": 1530, "number_of_timesteps": 1530000, "per_episode_reward": -486.84, "episode_reward_trend_value": -0.05126144806429428, "biggest_recent_change": 0.7621122172823789},
{"total_number_of_episodes": 1540, "number_of_timesteps": 1540000, "per_episode_reward": -487.01, "episode_reward_trend_value": -0.04777588566243228, "biggest_recent_change": 0.7621122172823789},
{"total_number_of_episodes": 1550, "number_of_timesteps": 1550000, "per_episode_reward": -487.18, "episode_reward_trend_value": -0.046366765713837466, "biggest_recent_change": 0.7621122172823789},
{"total_number_of_episodes": 1560, "number_of_timesteps": 1560000, "per_episode_reward": -487.68, "episode_reward_trend_value": -0.048498303352038696, "biggest_recent_change": 0.7621122172823789},
{"total_number_of_episodes": 1570, "number_of_timesteps": 1570000, "per_episode_reward": -488.17, "episode_reward_trend_value": -0.048162488470057316, "biggest_recent_change": 0.7621122172823789},
{"total_number_of_episodes": 1580, "number_of_timesteps": 1580000, "per_episode_reward": -488.48, "episode_reward_trend_value": -0.04588817836918982, "biggest_recent_change": 0.7621122172823789},
{"total_number_of_episodes": 1590, "number_of_timesteps": 1590000, "per_episode_reward": -488.8, "episode_reward_trend_value": -0.04094229026715463, "biggest_recent_change": 0.7621122172823789},
{"total_number_of_episodes": 1600, "number_of_timesteps": 1600000, "per_episode_reward": -489.06, "episode_reward_trend_value": -0.03535583194320048, "biggest_recent_change": 0.4914468577991329},
{"total_number_of_episodes": 1610, "number_of_timesteps": 1610000, "per_episode_reward": -489.32, "episode_reward_trend_value": -0.032902507894661745, "biggest_recent_change": 0.4914468577991329},
{"total_number_of_episodes": 1620, "number_of_timesteps": 1620000, "per_episode_reward": -489.75, "episode_reward_trend_value": -0.03239816832354134, "biggest_recent_change": 0.4914468577991329},
{"total_number_of_episodes": 1630, "number_of_timesteps": 1630000, "per_episode_reward": -490.19, "episode_reward_trend_value": -0.035308744946943055, "biggest_recent_change": 0.4914468577991329},
{"total_number_of_episodes": 1640, "number_of_timesteps": 1640000, "per_episode_reward": -490.62, "episode_reward_trend_value": -0.03815645372602603, "biggest_recent_change": 0.4914468577991329},
{"total_number_of_episodes": 1650, "number_of_timesteps": 1650000, "per_episode_reward": -491.05, "episode_reward_trend_value": -0.037463504918314225, "biggest_recent_change": 0.4914468577990192},
{"total_number_of_episodes": 1660, "number_of_timesteps": 1660000, "per_episode_reward": -492.59, "episode_reward_trend_value": -0.04916564291833715, "biggest_recent_change": 1.5446392778010818},
{"total_number_of_episodes": 1670, "number_of_timesteps": 1670000, "per_episode_reward": -493.0, "episode_reward_trend_value": -0.05016216208065821, "biggest_recent_change": 1.5446392778010818},
{"total_number_of_episodes": 1680, "number_of_timesteps": 1680000, "per_episode_reward": -493.34, "episode_reward_trend_value": -0.05049267666147885, "biggest_recent_change": 1.5446392778010818},
{"total_number_of_episodes": 1690, "number_of_timesteps": 1690000, "per_episode_reward": -493.69, "episode_reward_trend_value": -0.05146376146422098, "biggest_recent_change": 1.5446392778010818},
{"total_number_of_episodes": 1700, "number_of_timesteps": 1700000, "per_episode_reward": -493.97, "episode_reward_trend_value": -0.05168953245248657, "biggest_recent_change": 1.5446392778010818},
{"total_number_of_episodes": 1710, "number_of_timesteps": 1710000, "per_episode_reward": -494.25, "episode_reward_trend_value": -0.04996631896333383, "biggest_recent_change": 1.5446392778010818},
{"total_number_of_episodes": 1720, "number_of_timesteps": 1720000, "per_episode_reward": -494.74, "episode_reward_trend_value": -0.05056660717004825, "biggest_recent_change": 1.5446392778010818},
{"total_number_of_episodes": 1730, "number_of_timesteps": 1730000, "per_episode_reward": -495.23, "episode_reward_trend_value": -0.051229763221083933, "biggest_recent_change": 1.5446392778010818},
{"total_number_of_episodes": 1740, "number_of_timesteps": 1740000, "per_episode_reward": -495.79, "episode_reward_trend_value": -0.0527140762740209, "biggest_recent_change": 1.5446392778010818},
{"total_number_of_episodes": 1750, "number_of_timesteps": 1750000, "per_episode_reward": -496.35, "episode_reward_trend_value": -0.04180330251922253, "biggest_recent_change": 0.562669639869398},
{"total_number_of_episodes": 1760, "number_of_timesteps": 1760000, "per_episode_reward": -496.72, "episode_reward_trend_value": -0.04134327276617, "biggest_recent_change": 0.562669639869398},
{"total_number_of_episodes": 1770, "number_of_timesteps": 1770000, "per_episode_reward": -497.08, "episode_reward_trend_value": -0.041549247594617277, "biggest_recent_change": 0.562669639869398},
{"total_number_of_episodes": 1780, "number_of_timesteps": 1780000, "per_episode_reward": -497.7, "episode_reward_trend_value": -0.04451788649061983, "biggest_recent_change": 0.6139061010135265},
{"total_number_of_episodes": 1790, "number_of_timesteps": 1790000, "per_episode_reward": -498.31, "episode_reward_trend_value": -0.048231839201098914, "biggest_recent_change": 0.6139061010135265},
{"total_number_of_episodes": 1800, "number_of_timesteps": 1800000, "per_episode_reward": -498.68, "episode_reward_trend_value": -0.049243982749000124, "biggest_recent_change": 0.6139061010135265},
{"total_number_of_episodes": 1810, "number_of_timesteps": 1810000, "per_episode_reward": -499.05, "episode_reward_trend_value": -0.0479326246010367, "biggest_recent_change": 0.6139061010135265},
{"total_number_of_episodes": 1820, "number_of_timesteps": 1820000, "per_episode_reward": -499.25, "episode_reward_trend_value": -0.04469554702664975, "biggest_recent_change": 0.6139061010135265},
{"total_number_of_episodes": 1830, "number_of_timesteps": 1830000, "per_episode_reward": -499.45, "episode_reward_trend_value": -0.04063731245035835, "biggest_recent_change": 0.6139061010135265},
{"total_number_of_episodes": 1840, "number_of_timesteps": 1840000, "per_episode_reward": -499.95, "episode_reward_trend_value": -0.03999201035886699, "biggest_recent_change": 0.6139061010135265},
{"total_number_of_episodes": 1850, "number_of_timesteps": 1850000, "per_episode_reward": -500.46, "episode_reward_trend_value": -0.04154007832221838, "biggest_recent_change": 0.6139061010135265},
{"total_number_of_episodes": 1860, "number_of_timesteps": 1860000, "per_episode_reward": -501.14, "episode_reward_trend_value": -0.04505666626293608, "biggest_recent_change": 0.681759249597917},
{"total_number_of_episodes": 1870, "number_of_timesteps": 1870000, "per_episode_reward": -501.82, "episode_reward_trend_value": -0.04581059013609597, "biggest_recent_change": 0.681759249597917},
{"total_number_of_episodes": 1880, "number_of_timesteps": 1880000, "per_episode_reward": -502.23, "episode_reward_trend_value": -0.043506469512899076, "biggest_recent_change": 0.681759249597917},
{"total_number_of_episodes": 1890, "number_of_timesteps": 1890000, "per_episode_reward": -502.63, "episode_reward_trend_value": -0.04390415805227942, "biggest_recent_change": 0.681759249597917},
{"total_number_of_episodes": 1900, "number_of_timesteps": 1900000, "per_episode_reward": -503.43, "episode_reward_trend_value": -0.048640316562054725, "biggest_recent_change": 0.7969975422612379},
{"total_number_of_episodes": 1910, "number_of_timesteps": 1910000, "per_episode_reward": -504.23, "episode_reward_trend_value": -0.05530219449824977, "biggest_recent_change": 0.7969975422612379},
{"total_number_of_episodes": 1920, "number_of_timesteps": 1920000, "per_episode_reward": -505.09, "episode_reward_trend_value": -0.06269178104419856, "biggest_recent_change": 0.8624913171385629},
{"total_number_of_episodes": 1930, "number_of_timesteps": 1930000, "per_episode_reward": -505.95, "episode_reward_trend_value": -0.06666843510534919, "biggest_recent_change": 0.8624913171385629},
{"total_number_of_episodes": 1940, "number_of_timesteps": 1940000, "per_episode_reward": -506.37, "episode_reward_trend_value": -0.06573025476386393, "biggest_recent_change": 0.8624913171385629},
{"total_number_of_episodes": 1950, "number_of_timesteps": 1950000, "per_episode_reward": -506.79, "episode_reward_trend_value": -0.06282355444501364, "biggest_recent_change": 0.8624913171385629},
{"total_number_of_episodes": 1960, "number_of_timesteps": 1960000, "per_episode_reward": -507.34, "episode_reward_trend_value": -0.06137437537593402, "biggest_recent_change": 0.8624913171385629},
{"total_number_of_episodes": 1970, "number_of_timesteps": 1970000, "per_episode_reward": -507.9, "episode_reward_trend_value": -0.0629832408032112, "biggest_recent_change": 0.8624913171385629},
{"total_number_of_episodes": 1980, "number_of_timesteps": 1980000, "per_episode_reward": -508.32, "episode_reward_trend_value": -0.0631970637212204, "biggest_recent_change": 0.8624913171385629},
{"total_number_of_episodes": 1990, "number_of_timesteps": 1990000, "per_episode_reward": -508.75, "episode_reward_trend_value": -0.059072416668836544, "biggest_recent_change": 0.8624913171385629},
{"total_number_of_episodes": 2000, "number_of_timesteps": 2000000, "per_episode_reward": -509.27, "episode_reward_trend_value": -0.05597846168575921, "biggest_recent_change": 0.8624913171385629},
{"total_number_of_episodes": 2010, "number_of_timesteps": 2010000, "per_episode_reward": -509.78, "episode_reward_trend_value": -0.052156798092932555, "biggest_recent_change": 0.8624913171385629},
{"total_number_of_episodes": 2020, "number_of_timesteps": 2020000, "per_episode_reward": -510.09, "episode_reward_trend_value": -0.04591829213381655, "biggest_recent_change": 0.5513331333807514},
{"total_number_of_episodes": 2030, "number_of_timesteps": 2030000, "per_episode_reward": -510.39, "episode_reward_trend_value": -0.04459462057733769, "biggest_recent_change": 0.5513331333807514},
{"total_number_of_episodes": 2040, "number_of_timesteps": 2040000, "per_episode_reward": -510.87, "episode_reward_trend_value": -0.045309520807918106, "biggest_recent_change": 0.5513331333807514},
{"total_number_of_episodes": 2050, "number_of_timesteps": 2050000, "per_episode_reward": -511.36, "episode_reward_trend_value": -0.044566899788727216, "biggest_recent_change": 0.5513331333806377},
{"total_number_of_episodes": 2060, "number_of_timesteps": 2060000, "per_episode_reward": -512.16, "episode_reward_trend_value": -0.047420178625276956, "biggest_recent_change": 0.8081282286701139},
{"total_number_of_episodes": 2070, "number_of_timesteps": 2070000, "per_episode_reward": -512.97, "episode_reward_trend_value": -0.05166849997109466, "biggest_recent_change": 0.8081282286701139},
{"total_number_of_episodes": 2080, "number_of_timesteps": 2080000, "per_episode_reward": -513.28, "episode_reward_trend_value": -0.050414095373853086, "biggest_recent_change": 0.8081282286701139},
{"total_number_of_episodes": 2090, "number_of_timesteps": 2090000, "per_episode_reward": -513.6, "episode_reward_trend_value": -0.048128998707308156, "biggest_recent_change": 0.8081282286701139},
{"total_number_of_episodes": 2100, "number_of_timesteps": 2100000, "per_episode_reward": -514.48, "episode_reward_trend_value": -0.05216146731492459, "biggest_recent_change": 0.8814637684696436},
{"total_number_of_episodes": 2110, "number_of_timesteps": 2110000, "per_episode_reward": -515.36, "episode_reward_trend_value": -0.05861077828882786, "biggest_recent_change": 0.8814637684696436},
{"total_number_of_episodes": 2120, "number_of_timesteps": 2120000, "per_episode_reward": -515.98, "episode_reward_trend_value": -0.0621629035418525, "biggest_recent_change": 0.8814637684696436},
{"total_number_of_episodes": 2130, "number_of_timesteps": 2130000, "per_episode_reward": -516.6, "episode_reward_trend_value": -0.0636764570078166, "biggest_recent_change": 0.8814637684696436},
{"total_number_of_episodes": 2140, "number_of_timesteps": 2140000, "per_episode_reward": -517.04, "episode_reward_trend_value": -0.06314332176830817, "biggest_recent_change": 0.8814637684696436},
{"total_number_of_episodes": 2150, "number_of_timesteps": 2150000, "per_episode_reward": -517.48, "episode_reward_trend_value": -0.05901428667306163, "biggest_recent_change": 0.8814637684696436},
{"total_number_of_episodes": 2160, "number_of_timesteps": 2160000, "per_episode_reward": -518.17, "episode_reward_trend_value": -0.05774361936664213, "biggest_recent_change": 0.8814637684696436},
{"total_number_of_episodes": 2170, "number_of_timesteps": 2170000, "per_episode_reward": -518.86, "episode_reward_trend_value": -0.061975678003279376, "biggest_recent_change": 0.8814637684696436},
{"total_number_of_episodes": 2180, "number_of_timesteps": 2180000, "per_episode_reward": -520.7, "episode_reward_trend_value": -0.07891358482775357, "biggest_recent_change": 1.8372945079976262},
{"total_number_of_episodes": 2190, "number_of_timesteps": 2190000, "per_episode_reward": -522.54, "episode_reward_trend_value": -0.08953392637806322, "biggest_recent_change": 1.8372945079976262},
{"total_number_of_episodes": 2200, "number_of_timesteps": 2200000, "per_episode_reward": -522.91, "episode_reward_trend_value": -0.08389080705058581, "biggest_recent_change": 1.8372945079976262},
{"total_number_of_episodes": 2210, "number_of_timesteps": 2210000, "per_episode_reward": -523.28, "episode_reward_trend_value": -0.08114487344398387, "biggest_recent_change": 1.8372945079976262},
{"total_number_of_episodes": 2220, "number_of_timesteps": 2220000, "per_episode_reward": -523.93, "episode_reward_trend_value": -0.0814330989481151, "biggest_recent_change": 1.8372945079976262},
{"total_number_of_episodes": 2230, "number_of_timesteps": 2230000, "per_episode_reward": -524.58, "episode_reward_trend_value": -0.08376801315771823, "biggest_recent_change": 1.8372945079976262},
{"total_number_of_episodes": 2240, "number_of_timesteps": 2240000, "per_episode_reward": -525.8, "episode_reward_trend_value": -0.09252048526625585, "biggest_recent_change": 1.8372945079976262},
{"total_number_of_episodes": 2250, "number_of_timesteps": 2250000, "per_episode_reward": -527.03, "episode_reward_trend_value": -0.09841458958596452, "biggest_recent_change": 1.8372945079976262},
{"total_number_of_episodes": 2260, "number_of_timesteps": 2260000, "per_episode_reward": -528.28, "episode_reward_trend_value": -0.10468210899220923, "biggest_recent_change": 1.8372945079976262},
{"total_number_of_episodes": 2270, "number_of_timesteps": 2270000, "per_episode_reward": -529.54, "episode_reward_trend_value": -0.09824378021061572, "biggest_recent_change": 1.8372945079975125},
{"total_number_of_episodes": 2280, "number_of_timesteps": 2280000, "per_episode_reward": -530.81, "episode_reward_trend_value": -0.09187824776261348, "biggest_recent_change": 1.264396587677311},
{"total_number_of_episodes": 2290, "number_of_timesteps": 2290000, "per_episode_reward": -532.07, "episode_reward_trend_value": -0.10177617619240083, "biggest_recent_change": 1.264396587677311},
{"total_number_of_episodes": 2300, "number_of_timesteps": 2300000, "per_episode_reward": -533.03, "episode_reward_trend_value": -0.10832028240244855, "biggest_recent_change": 1.264396587677311},
{"total_number_of_episodes": 2310, "number_of_timesteps": 2310000, "per_episode_reward": -534.0, "episode_reward_trend_value": -0.11183022950176565, "biggest_recent_change": 1.264396587677311},
{"total_number_of_episodes": 2320, "number_of_timesteps": 2320000, "per_episode_reward": -535.8, "episode_reward_trend_value": -0.12471209552819826, "biggest_recent_change": 1.8060252913410295},
{"total_number_of_episodes": 2330, "number_of_timesteps": 2330000, "per_episode_reward": -537.61, "episode_reward_trend_value": -0.1311764036556964, "biggest_recent_change": 1.8060252913411432},
{"total_number_of_episodes": 2340, "number_of_timesteps": 2340000, "per_episode_reward": -538.38, "episode_reward_trend_value": -0.12614210934070796, "biggest_recent_change": 1.8060252913411432},
{"total_number_of_episodes": 2350, "number_of_timesteps": 2350000, "per_episode_reward": -539.15, "episode_reward_trend_value": -0.12073439993918227, "biggest_recent_change": 1.8060252913411432},
{"total_number_of_episodes": 2360, "number_of_timesteps": 2360000, "per_episode_reward": -540.25, "episode_reward_trend_value": -0.1189504771932914, "biggest_recent_change": 1.8060252913411432},
{"total_number_of_episodes": 2370, "number_of_timesteps": 2370000, "per_episode_reward": -541.34, "episode_reward_trend_value": -0.11709375811381051, "biggest_recent_change": 1.8060252913411432},
{"total_number_of_episodes": 2380, "number_of_timesteps": 2380000, "per_episode_reward": -542.8, "episode_reward_trend_value": -0.11919903704104451, "biggest_recent_change": 1.8060252913411432},
{"total_number_of_episodes": 2390, "number_of_timesteps": 2390000, "per_episode_reward": -544.25, "episode_reward_trend_value": -0.12465813818802063, "biggest_recent_change": 1.8060252913411432},
{"total_number_of_episodes": 2400, "number_of_timesteps": 2400000, "per_episode_reward": -545.48, "episode_reward_trend_value": -0.1275843605267394, "biggest_recent_change": 1.8060252913411432},
{"total_number_of_episodes": 2410, "number_of_timesteps": 2410000, "per_episode_reward": -546.7, "episode_reward_trend_value": -0.1211386639383439, "biggest_recent_change": 1.8060252913411432},
{"total_number_of_episodes": 2420, "number_of_timesteps": 2420000, "per_episode_reward": -548.04, "episode_reward_trend_value": -0.11587697102369374, "biggest_recent_change": 1.45387169112837},
{"total_number_of_episodes": 2430, "number_of_timesteps": 2430000, "per_episode_reward": -549.37, "episode_reward_trend_value": -0.1221138805515352, "biggest_recent_change": 1.45387169112837},
{"total_number_of_episodes": 2440, "number_of_timesteps": 2440000, "per_episode_reward": -550.37, "episode_reward_trend_value": -0.12469059853830862, "biggest_recent_change": 1.45387169112837},
{"total_number_of_episodes": 2450, "number_of_timesteps": 2450000, "per_episode_reward": -551.38, "episode_reward_trend_value": -0.12364352986944975, "biggest_recent_change": 1.45387169112837},
{"total_number_of_episodes": 2460, "number_of_timesteps": 2460000, "per_episode_reward": -554.6, "episode_reward_trend_value": -0.14731227929057822, "biggest_recent_change": 3.227479318425594},
{"total_number_of_episodes": 2470, "number_of_timesteps": 2470000, "per_episode_reward": -557.83, "episode_reward_trend_value": -0.16701903070499183, "biggest_recent_change": 3.227479318425594},
{"total_number_of_episodes": 2480, "number_of_timesteps": 2480000, "per_episode_reward": -564.1, "episode_reward_trend_value": -0.22053289341352209, "biggest_recent_change": 6.270119334896094},
{"total_number_of_episodes": 2490, "number_of_timesteps": 2490000, "per_episode_reward": -570.37, "episode_reward_trend_value": -0.2765796349303072, "biggest_recent_change": 6.270119334896094},
{"total_number_of_episodes": 2500, "number_of_timesteps": 2500000, "per_episode_reward": -573.21, "episode_reward_trend_value": -0.29447192092870234, "biggest_recent_change": 6.270119334896094},
{"total_number_of_episodes": 2510, "number_of_timesteps": 2510000, "per_episode_reward": -576.04, "episode_reward_trend_value": -0.3111802032533521, "biggest_recent_change": 6.270119334896094},
{"total_number_of_episodes": 2520, "number_of_timesteps": 2520000, "per_episode_reward": -578.62, "episode_reward_trend_value": -0.3250053387185403, "biggest_recent_change": 6.270119334896094},
{"total_number_of_episodes": 2530, "number_of_timesteps": 2530000, "per_episode_reward": -581.99, "episode_reward_trend_value": -0.3513210973412192, "biggest_recent_change": 6.270119334896094},
{"total_number_of_episodes": 2540, "number_of_timesteps": 2540000, "per_episode_reward": -580.36, "episode_reward_trend_value": -0.322042000576414, "biggest_recent_change": 6.270119334896094},
{"total_number_of_episodes": 2550, "number_of_timesteps": 2550000, "per_episode_reward": -577.93, "episode_reward_trend_value": -0.25921840934355866, "biggest_recent_change": 6.270119334896094},
{"total_number_of_episodes": 2560, "number_of_timesteps": 2560000, "per_episode_reward": -577.46, "episode_reward_trend_value": -0.2181457801411486, "biggest_recent_change": 6.270119334896094},
{"total_number_of_episodes": 2570, "number_of_timesteps": 2570000, "per_episode_reward": -576.62, "episode_reward_trend_value": -0.13907377242025706, "biggest_recent_change": 6.270119334896094},
{"total_number_of_episodes": 2580, "number_of_timesteps": 2580000, "per_episode_reward": -580.12, "episode_reward_trend_value": -0.10828893868380948, "biggest_recent_change": 3.499484298615812},
{"total_number_of_episodes": 2590, "number_of_timesteps": 2590000, "per_episode_reward": -580.16, "episode_reward_trend_value": -0.0772698830683339, "biggest_recent_change": 3.499484298615812},
{"total_number_of_episodes": 2600, "number_of_timesteps": 2600000, "per_episode_reward": -581.48, "episode_reward_trend_value": -0.060431435730236495, "biggest_recent_change": 3.499484298615812},
{"total_number_of_episodes": 2610, "number_of_timesteps": 2610000, "per_episode_reward": -580.97, "episode_reward_trend_value": -0.026101115718279288, "biggest_recent_change": 3.499484298615812},
{"total_number_of_episodes": 2620, "number_of_timesteps": 2620000, "per_episode_reward": -582.46, "episode_reward_trend_value": -0.005249535299507594, "biggest_recent_change": 3.499484298615812},
{"total_number_of_episodes": 2630, "number_of_timesteps": 2630000, "per_episode_reward": -581.59, "episode_reward_trend_value": -0.01365954605387161, "biggest_recent_change": 3.499484298615812},
{"total_number_of_episodes": 2640, "number_of_timesteps": 2640000, "per_episode_reward": -580.66, "episode_reward_trend_value": -0.030327437130473655, "biggest_recent_change": 3.499484298615812},
{"total_number_of_episodes": 2650, "number_of_timesteps": 2650000, "per_episode_reward": -579.5, "episode_reward_trend_value": -0.022643731691535628, "biggest_recent_change": 3.499484298615812},
{"total_number_of_episodes": 2660, "number_of_timesteps": 2660000, "per_episode_reward": -580.14, "episode_reward_trend_value": -0.0391748422218446, "biggest_recent_change": 3.499484298615812},
{"total_number_of_episodes": 2670, "number_of_timesteps": 2670000, "per_episode_reward": -580.02, "episode_reward_trend_value": 0.0010353952395032845, "biggest_recent_change": 1.494831728678264},
{"total_number_of_episodes": 2680, "number_of_timesteps": 2680000, "per_episode_reward": -578.87, "episode_reward_trend_value": 0.014364446729494931, "biggest_recent_change": 1.494831728678264},
{"total_number_of_episodes": 2690, "number_of_timesteps": 2690000, "per_episode_reward": -579.09, "episode_reward_trend_value": 0.026630426877535585, "biggest_recent_change": 1.494831728678264},
{"total_number_of_episodes": 2700, "number_of_timesteps": 2700000, "per_episode_reward": -578.78, "episode_reward_trend_value": 0.02428777090192524, "biggest_recent_change": 1.494831728678264},
{"total_number_of_episodes": 2710, "number_of_timesteps": 2710000, "per_episode_reward": -579.92, "episode_reward_trend_value": 0.028317315808710143, "biggest_recent_change": 1.1605907992957327},
{"total_number_of_episodes": 2720, "number_of_timesteps": 2720000, "per_episode_reward": -579.97, "episode_reward_trend_value": 0.017932496386775812, "biggest_recent_change": 1.1605907992957327},
{"total_number_of_episodes": 2730, "number_of_timesteps": 2730000, "per_episode_reward": -577.95, "episode_reward_trend_value": 0.030081300878715765, "biggest_recent_change": 2.0199260999117996},
{"total_number_of_episodes": 2740, "number_of_timesteps": 2740000, "per_episode_reward": -578.42, "episode_reward_trend_value": 0.01202495572803678, "biggest_recent_change": 2.0199260999117996},
{"total_number_of_episodes": 2750, "number_of_timesteps": 2750000, "per_episode_reward": -579.21, "episode_reward_trend_value": 0.010366895359734623, "biggest_recent_change": 2.0199260999117996},
{"total_number_of_episodes": 2760, "number_of_timesteps": 2760000, "per_episode_reward": -573.02, "episode_reward_trend_value": 0.07784816462391796, "biggest_recent_change": 6.192751306681998},
{"total_number_of_episodes": 2770, "number_of_timesteps": 2770000, "per_episode_reward": -574.4, "episode_reward_trend_value": 0.04959974892768362, "biggest_recent_change": 6.192751306681998},
{"total_number_of_episodes": 2780, "number_of_timesteps": 2780000, "per_episode_reward": -573.5, "episode_reward_trend_value": 0.06203677392876948, "biggest_recent_change": 6.192751306681998},
{"total_number_of_episodes": 2790, "number_of_timesteps": 2790000, "per_episode_reward": -572.61, "episode_reward_trend_value": 0.06854913149969283, "biggest_recent_change": 6.192751306681998},
{"total_number_of_episodes": 2800, "number_of_timesteps": 2800000, "per_episode_reward": -573.08, "episode_reward_trend_value": 0.07594794662310657, "biggest_recent_change": 6.192751306681998},
{"total_number_of_episodes": 2810, "number_of_timesteps": 2810000, "per_episode_reward": -574.24, "episode_reward_trend_value": 0.06377128868575205, "biggest_recent_change": 6.192751306681998},
{"total_number_of_episodes": 2820, "number_of_timesteps": 2820000, "per_episode_reward": -573.23, "episode_reward_trend_value": 0.052505123527800554, "biggest_recent_change": 6.192751306681998},
{"total_number_of_episodes": 2830, "number_of_timesteps": 2830000, "per_episode_reward": -573.24, "episode_reward_trend_value": 0.05758143172238685, "biggest_recent_change": 6.192751306681998},
{"total_number_of_episodes": 2840, "number_of_timesteps": 2840000, "per_episode_reward": -572.26, "episode_reward_trend_value": 0.07722192537179985, "biggest_recent_change": 6.192751306681998},
{"total_number_of_episodes": 2850, "number_of_timesteps": 2850000, "per_episode_reward": -571.65, "episode_reward_trend_value": 0.015143219204051345, "biggest_recent_change": 1.387246111410036},
{"total_number_of_episodes": 2860, "number_of_timesteps": 2860000, "per_episode_reward": -572.6, "episode_reward_trend_value": 0.02002724160612388, "biggest_recent_change": 1.1553709117230255},
{"total_number_of_episodes": 2870, "number_of_timesteps": 2870000, "per_episode_reward": -571.08, "episode_reward_trend_value": 0.02695675042210597, "biggest_recent_change": 1.5261681790474313},
{"total_number_of_episodes": 2880, "number_of_timesteps": 2880000, "per_episode_reward": -570.13, "episode_reward_trend_value": 0.0275512924173414, "biggest_recent_change": 1.5261681790474313},
{"total_number_of_episodes": 2890, "number_of_timesteps": 2890000, "per_episode_reward": -569.8, "episode_reward_trend_value": 0.03642833854884834, "biggest_recent_change": 1.5261681790474313},
{"total_number_of_episodes": 2900, "number_of_timesteps": 2900000, "per_episode_reward": -568.35, "episode_reward_trend_value": 0.06535717717818115, "biggest_recent_change": 1.5261681790474313},
{"total_number_of_episodes": 2910, "number_of_timesteps": 2910000, "per_episode_reward": -568.42, "episode_reward_trend_value": 0.05345549165267458, "biggest_recent_change": 1.5261681790474313},
{"total_number_of_episodes": 2920, "number_of_timesteps": 2920000, "per_episode_reward": -566.18, "episode_reward_trend_value": 0.07842370404357299, "biggest_recent_change": 2.239526588428248},
{"total_number_of_episodes": 2930, "number_of_timesteps": 2930000, "per_episode_reward": -564.79, "episode_reward_trend_value": 0.08299119403324969, "biggest_recent_change": 2.239526588428248},
{"total_number_of_episodes": 2940, "number_of_timesteps": 2940000, "per_episode_reward": -565.89, "episode_reward_trend_value": 0.06403874924489072, "biggest_recent_change": 2.239526588428248},
{"total_number_of_episodes": 2950, "number_of_timesteps": 2950000, "per_episode_reward": -564.61, "episode_reward_trend_value": 0.08882917689780546, "biggest_recent_change": 2.239526588428248},
{"total_number_of_episodes": 2960, "number_of_timesteps": 2960000, "per_episode_reward": -565.65, "episode_reward_trend_value": 0.0602960319354439, "biggest_recent_change": 2.239526588428248},
{"total_number_of_episodes": 2970, "number_of_timesteps": 2970000, "per_episode_reward": -564.57, "episode_reward_trend_value": 0.06179512342699177, "biggest_recent_change": 2.239526588428248},
{"total_number_of_episodes": 2980, "number_of_timesteps": 2980000, "per_episode_reward": -565.02, "episode_reward_trend_value": 0.05313471686635265, "biggest_recent_change": 2.239526588428248},
{"total_number_of_episodes": 2990, "number_of_timesteps": 2990000, "per_episode_reward": -565.99, "episode_reward_trend_value": 0.026225209794387815, "biggest_recent_change": 2.239526588428248},
{"total_number_of_episodes": 3000, "number_of_timesteps": 3000000, "per_episode_reward": -564.87, "episode_reward_trend_value": 0.039454521385992945, "biggest_recent_change": 2.239526588428248},
{"total_number_of_episodes": 3010, "number_of_timesteps": 3010000, "per_episode_reward": -562.74, "episode_reward_trend_value": 0.03816456360811521, "biggest_recent_change": 2.1234303884192514},
{"total_number_of_episodes": 3020, "number_of_timesteps": 3020000, "per_episode_reward": -562.2, "episode_reward_trend_value": 0.028732303115502116, "biggest_recent_change": 2.1234303884192514},
{"total_number_of_episodes": 3030, "number_of_timesteps": 3030000, "per_episode_reward": -561.53, "episode_reward_trend_value": 0.04848120367582346, "biggest_recent_change": 2.1234303884192514},
{"total_number_of_episodes": 3040, "number_of_timesteps": 3040000, "per_episode_reward": -561.03, "episode_reward_trend_value": 0.03977957191646182, "biggest_recent_change": 2.1234303884192514},
{"total_number_of_episodes": 3050, "number_of_timesteps": 3050000, "per_episode_reward": -560.89, "episode_reward_trend_value": 0.05288832219101146, "biggest_recent_change": 2.1234303884192514},
{"total_number_of_episodes": 3060, "number_of_timesteps": 3060000, "per_episode_reward": -560.16, "episode_reward_trend_value": 0.048980269470161555, "biggest_recent_change": 2.1234303884192514},
{"total_number_of_episodes": 3070, "number_of_timesteps": 3070000, "per_episode_reward": -559.54, "episode_reward_trend_value": 0.06087913655000471, "biggest_recent_change": 2.1234303884192514},
{"total_number_of_episodes": 3080, "number_of_timesteps": 3080000, "per_episode_reward": -559.04, "episode_reward_trend_value": 0.07725678116113133, "biggest_recent_change": 2.1234303884192514},
{"total_number_of_episodes": 3090, "number_of_timesteps": 3090000, "per_episode_reward": -559.05, "episode_reward_trend_value": 0.0646401777118841, "biggest_recent_change": 2.1234303884192514},
{"total_number_of_episodes": 3100, "number_of_timesteps": 3100000, "per_episode_reward": -558.78, "episode_reward_trend_value": 0.044056463183670125, "biggest_recent_change": 0.7249690926985295},
{"total_number_of_episodes": 3110, "number_of_timesteps": 3110000, "per_episode_reward": -558.89, "episode_reward_trend_value": 0.03686206527909614, "biggest_recent_change": 0.7249690926985295},
{"total_number_of_episodes": 3120, "number_of_timesteps": 3120000, "per_episode_reward": -558.21, "episode_reward_trend_value": 0.036819931008954476, "biggest_recent_change": 0.7249690926985295},
{"total_number_of_episodes": 3130, "number_of_timesteps": 3130000, "per_episode_reward": -557.54, "episode_reward_trend_value": 0.038744921581757, "biggest_recent_change": 0.7249690926985295},
{"total_number_of_episodes": 3140, "number_of_timesteps": 3140000, "per_episode_reward": -556.78, "episode_reward_trend_value": 0.0456595761190076, "biggest_recent_change": 0.7602915654969138},
{"total_number_of_episodes": 3150, "number_of_timesteps": 3150000, "per_episode_reward": -556.02, "episode_reward_trend_value": 0.04605204803898964, "biggest_recent_change": 0.7602915654969138},
{"total_number_of_episodes": 3160, "number_of_timesteps": 3160000, "per_episode_reward": -555.08, "episode_reward_trend_value": 0.04950161601647475, "biggest_recent_change": 0.9345773905772603},
{"total_number_of_episodes": 3170, "number_of_timesteps": 3170000, "per_episode_reward": -554.29, "episode_reward_trend_value": 0.05274727362670369, "biggest_recent_change": 0.9345773905772603},
{"total_number_of_episodes": 3180, "number_of_timesteps": 3180000, "per_episode_reward": -554.29, "episode_reward_trend_value": 0.0529226164015275, "biggest_recent_change": 0.9345773905772603},
{"total_number_of_episodes": 3190, "number_of_timesteps": 3190000, "per_episode_reward": -553.94, "episode_reward_trend_value": 0.053792171145476506, "biggest_recent_change": 0.9345773905772603},
{"total_number_of_episodes": 3200, "number_of_timesteps": 3200000, "per_episode_reward": -553.08, "episode_reward_trend_value": 0.06455993449474388, "biggest_recent_change": 0.9345773905772603},
{"total_number_of_episodes": 3210, "number_of_timesteps": 3210000, "per_episode_reward": -552.3, "episode_reward_trend_value": 0.06571638737473222, "biggest_recent_change": 0.9345773905772603},
{"total_number_of_episodes": 3220, "number_of_timesteps": 3220000, "per_episode_reward": -551.64, "episode_reward_trend_value": 0.06555127496694695, "biggest_recent_change": 0.9345773905772603},
{"total_number_of_episodes": 3230, "number_of_timesteps": 3230000, "per_episode_reward": -550.98, "episode_reward_trend_value": 0.06442244168417674, "biggest_recent_change": 0.9345773905772603},
{"total_number_of_episodes": 3240, "number_of_timesteps": 3240000, "per_episode_reward": -550.26, "episode_reward_trend_value": 0.06404425062640055, "biggest_recent_change": 0.9345773905772603},
{"total_number_of_episodes": 3250, "number_of_timesteps": 3250000, "per_episode_reward": -549.58, "episode_reward_trend_value": 0.06121743721174021, "biggest_recent_change": 0.8607539523144396},
{"total_number_of_episodes": 3260, "number_of_timesteps": 3260000, "per_episode_reward": -549.17, "episode_reward_trend_value": 0.05693720513300806, "biggest_recent_change": 0.8607539523144396},
{"total_number_of_episodes": 3270, "number_of_timesteps": 3270000, "per_episode_reward": -548.76, "episode_reward_trend_value": 0.06139832869222219, "biggest_recent_change": 0.8607539523144396},
{"total_number_of_episodes": 3280, "number_of_timesteps": 3280000, "per_episode_reward": -547.66, "episode_reward_trend_value": 0.0697656034044826, "biggest_recent_change": 1.1022107319388397},
{"total_number_of_episodes": 3290, "number_of_timesteps": 3290000, "per_episode_reward": -546.56, "episode_reward_trend_value": 0.07244845651142037, "biggest_recent_change": 1.1022107319388397},
{"total_number_of_episodes": 3300, "number_of_timesteps": 3300000, "per_episode_reward": -545.06, "episode_reward_trend_value": 0.08039090991420608, "biggest_recent_change": 1.492458252198162},
{"total_number_of_episodes": 3310, "number_of_timesteps": 3310000, "per_episode_reward": -543.2, "episode_reward_trend_value": 0.09382893689885982, "biggest_recent_change": 1.8681189986666595},
{"total_number_of_episodes": 3320, "number_of_timesteps": 3320000, "per_episode_reward": -541.85, "episode_reward_trend_value": 0.1014112423915233, "biggest_recent_change": 1.8681189986666595},
{"total_number_of_episodes": 3330, "number_of_timesteps": 3330000, "per_episode_reward": -540.51, "episode_reward_trend_value": 0.10824290565919278, "biggest_recent_change": 1.8681189986666595},
{"total_number_of_episodes": 3340, "number_of_timesteps": 3340000, "per_episode_reward": -539.64, "episode_reward_trend_value": 0.11036501834784455, "biggest_recent_change": 1.8681189986666595},
{"total_number_of_episodes": 3350, "number_of_timesteps": 3350000, "per_episode_reward": -538.77, "episode_reward_trend_value": 0.11551956372518361, "biggest_recent_change": 1.8681189986666595},
{"total_number_of_episodes": 3360, "number_of_timesteps": 3360000, "per_episode_reward": -538.11, "episode_reward_trend_value": 0.11839693534419035, "biggest_recent_change": 1.8681189986666595},
{"total_number_of_episodes": 3370, "number_of_timesteps": 3370000, "per_episode_reward": -537.44, "episode_reward_trend_value": 0.11355246817805664, "biggest_recent_change": 1.8681189986666595},
{"total_number_of_episodes": 3380, "number_of_timesteps": 3380000, "per_episode_reward": -537.04, "episode_reward_trend_value": 0.10576782016667545, "biggest_recent_change": 1.8681189986666595},
{"total_number_of_episodes": 3390, "number_of_timesteps": 3390000, "per_episode_reward": -536.64, "episode_reward_trend_value": 0.09364708859685986, "biggest_recent_change": 1.8681189986666595},
{"total_number_of_episodes": 3400, "number_of_timesteps": 3400000, "per_episode_reward": -535.9, "episode_reward_trend_value": 0.08101882118280627, "biggest_recent_change": 1.3411040643873093},
{"total_number_of_episodes": 3410, "number_of_timesteps": 3410000, "per_episode_reward": -535.17, "episode_reward_trend_value": 0.07424627526074674, "biggest_recent_change": 1.3411040643873093},
{"total_number_of_episodes": 3420, "number_of_timesteps": 3420000, "per_episode_reward": -534.48, "episode_reward_trend_value": 0.06705668144731666, "biggest_recent_change": 0.8711543252367164},
{"total_number_of_episodes": 3430, "number_of_timesteps": 3430000, "per_episode_reward": -533.78, "episode_reward_trend_value": 0.06508875140223028, "biggest_recent_change": 0.8711543252367164},
{"total_number_of_episodes": 3440, "number_of_timesteps": 3440000, "per_episode_reward": -532.93, "episode_reward_trend_value": 0.06488108958112535, "biggest_recent_change": 0.8524647613372736},
{"total_number_of_episodes": 3450, "number_of_timesteps": 3450000, "per_episode_reward": -532.08, "episode_reward_trend_value": 0.06695060151835278, "biggest_recent_change": 0.8524647613372736},
{"total_number_of_episodes": 3460, "number_of_timesteps": 3460000, "per_episode_reward": -531.5, "episode_reward_trend_value": 0.0659490662129378, "biggest_recent_change": 0.8524647613372736},
{"total_number_of_episodes": 3470, "number_of_timesteps": 3470000, "per_episode_reward": -530.93, "episode_reward_trend_value": 0.0678877117527678, "biggest_recent_change": 0.8524647613372736},
{"total_number_of_episodes": 3480, "number_of_timesteps": 3480000, "per_episode_reward": -530.55, "episode_reward_trend_value": 0.06765464445189764, "biggest_recent_change": 0.8524647613372736},
{"total_number_of_episodes": 3490, "number_of_timesteps": 3490000, "per_episode_reward": -530.17, "episode_reward_trend_value": 0.06375510470117104, "biggest_recent_change": 0.8524647613372736},
{"total_number_of_episodes": 3500, "number_of_timesteps": 3500000, "per_episode_reward": -529.49, "episode_reward_trend_value": 0.06309486903327424, "biggest_recent_change": 0.8524647613372736},
{"total_number_of_episodes": 3510, "number_of_timesteps": 3510000, "per_episode_reward": -528.82, "episode_reward_trend_value": 0.06285168125674671, "biggest_recent_change": 0.8524647613372736},
{"total_number_of_episodes": 3520, "number_of_timesteps": 3520000, "per_episode_reward": -528.37, "episode_reward_trend_value": 0.0601588908212054, "biggest_recent_change": 0.8524647613372736},
{"total_number_of_episodes": 3530, "number_of_timesteps": 3530000, "per_episode_reward": -527.92, "episode_reward_trend_value": 0.05570583216168011, "biggest_recent_change": 0.8524647613372736},
{"total_number_of_episodes": 3540, "number_of_timesteps": 3540000, "per_episode_reward": -527.14, "episode_reward_trend_value": 0.054879662667095395, "biggest_recent_change": 0.7781095068246486},
{"total_number_of_episodes": 3550, "number_of_timesteps": 3550000, "per_episode_reward": -526.36, "episode_reward_trend_value": 0.05712454041515179, "biggest_recent_change": 0.7781095068246486},
{"total_number_of_episodes": 3560, "number_of_timesteps": 3560000, "per_episode_reward": -525.27, "episode_reward_trend_value": 0.06289590288519725, "biggest_recent_change": 1.0954931318033232},
{"total_number_of_episodes": 3570, "number_of_timesteps": 3570000, "per_episode_reward": -524.17, "episode_reward_trend_value": 0.07083897819594162, "biggest_recent_change": 1.0954931318034369},
{"total_number_of_episodes": 3580, "number_of_timesteps": 3580000, "per_episode_reward": -523.52, "episode_reward_trend_value": 0.07386304512068591, "biggest_recent_change": 1.0954931318034369},
{"total_number_of_episodes": 3590, "number_of_timesteps": 3590000, "per_episode_reward": -522.87, "episode_reward_trend_value": 0.07364780796259665, "biggest_recent_change": 1.0954931318034369},
{"total_number_of_episodes": 3600, "number_of_timesteps": 3600000, "per_episode_reward": -522.51, "episode_reward_trend_value": 0.07013039304090525, "biggest_recent_change": 1.0954931318034369},
{"total_number_of_episodes": 3610, "number_of_timesteps": 3610000, "per_episode_reward": -522.15, "episode_reward_trend_value": 0.06906258077822384, "biggest_recent_change": 1.0954931318034369},
{"total_number_of_episodes": 3620, "number_of_timesteps": 3620000, "per_episode_reward": -521.53, "episode_reward_trend_value": 0.07093952549830647, "biggest_recent_change": 1.0954931318034369},
{"total_number_of_episodes": 3630, "number_of_timesteps": 3630000, "per_episode_reward": -520.91, "episode_reward_trend_value": 0.06918958105344851, "biggest_recent_change": 1.0954931318034369},
{"total_number_of_episodes": 3640, "number_of_timesteps": 3640000, "per_episode_reward": -520.19, "episode_reward_trend_value": 0.06857411056563605, "biggest_recent_change": 1.0954931318034369},
{"total_number_of_episodes": 3650, "number_of_timesteps": 3650000, "per_episode_reward": -519.47, "episode_reward_trend_value": 0.06443215535583831, "biggest_recent_change": 1.0954931318034369},
{"total_number_of_episodes": 3660, "number_of_timesteps": 3660000, "per_episode_reward": -518.91, "episode_reward_trend_value": 0.058460683720658026, "biggest_recent_change": 0.7227171629215263},
{"total_number_of_episodes": 3670, "number_of_timesteps": 3670000, "per_episode_reward": -518.35, "episode_reward_trend_value": 0.057408220471479074, "biggest_recent_change": 0.7227171629215263},
{"total_number_of_episodes": 3680, "number_of_timesteps": 3680000, "per_episode_reward": -518.13, "episode_reward_trend_value": 0.05260764931300501, "biggest_recent_change": 0.7227171629215263},
{"total_number_of_episodes": 3690, "number_of_timesteps": 3690000, "per_episode_reward": -517.91, "episode_reward_trend_value": 0.051109255918134346, "biggest_recent_change": 0.7227171629215263},
{"total_number_of_episodes": 3700, "number_of_timesteps": 3700000, "per_episode_reward": -517.49, "episode_reward_trend_value": 0.05186158252570168, "biggest_recent_change": 0.7227171629215263},
{"total_number_of_episodes": 3710, "number_of_timesteps": 3710000, "per_episode_reward": -517.06, "episode_reward_trend_value": 0.049669152150506254, "biggest_recent_change": 0.7227171629215263},
{"total_number_of_episodes": 3720, "number_of_timesteps": 3720000, "per_episode_reward": -516.9, "episode_reward_trend_value": 0.0446482021729619, "biggest_recent_change": 0.7227171629215263},
{"total_number_of_episodes": 3730, "number_of_timesteps": 3730000, "per_episode_reward": -516.73, "episode_reward_trend_value": 0.03849277823837459, "biggest_recent_change": 0.7227171629215263},
{"total_number_of_episodes": 3740, "number_of_timesteps": 3740000, "per_episode_reward": -516.48, "episode_reward_trend_value": 0.03318435073314024, "biggest_recent_change": 0.5580606846373257},
{"total_number_of_episodes": 3750, "number_of_timesteps": 3750000, "per_episode_reward": -516.24, "episode_reward_trend_value": 0.029705439653287157, "biggest_recent_change": 0.5580606846373257},
{"total_number_of_episodes": 3760, "number_of_timesteps": 3760000, "per_episode_reward": -515.58, "episode_reward_trend_value": 0.0308242054521189, "biggest_recent_change": 0.658749606532183},
{"total_number_of_episodes": 3770, "number_of_timesteps": 3770000, "per_episode_reward": -514.92, "episode_reward_trend_value": 0.03569107916024829, "biggest_recent_change": 0.658749606532183},
{"total_number_of_episodes": 3780, "number_of_timesteps": 3780000, "per_episode_reward": -514.56, "episode_reward_trend_value": 0.03720164528863658, "biggest_recent_change": 0.658749606532183},
{"total_number_of_episodes": 3790, "number_of_timesteps": 3790000, "per_episode_reward": -514.21, "episode_reward_trend_value": 0.03646149141459066, "biggest_recent_change": 0.658749606532183},
{"total_number_of_episodes": 3800, "number_of_timesteps": 3800000, "per_episode_reward": -513.63, "episode_reward_trend_value": 0.038140268844802, "biggest_recent_change": 0.658749606532183},
{"total_number_of_episodes": 3810, "number_of_timesteps": 3810000, "per_episode_reward": -513.06, "episode_reward_trend_value": 0.04264756587736605, "biggest_recent_change": 0.658749606532183},
{"total_number_of_episodes": 3820, "number_of_timesteps": 3820000, "per_episode_reward": -512.4, "episode_reward_trend_value": 0.048072854024851744, "biggest_recent_change": 0.658749606532183},
{"total_number_of_episodes": 3830, "number_of_timesteps": 3830000, "per_episode_reward": -511.74, "episode_reward_trend_value": 0.05265114574298385, "biggest_recent_change": 0.658749606532183},
{"total_number_of_episodes": 3840, "number_of_timesteps": 3840000, "per_episode_reward": -511.52, "episode_reward_trend_value": 0.05245437500490134, "biggest_recent_change": 0.658749606532183},
{"total_number_of_episodes": 3850, "number_of_timesteps": 3850000, "per_episode_reward": -511.29, "episode_reward_trend_value": 0.04765992738813275, "biggest_recent_change": 0.658749606532183},
{"total_number_of_episodes": 3860, "number_of_timesteps": 3860000, "per_episode_reward": -510.08, "episode_reward_trend_value": 0.05377316226613339, "biggest_recent_change": 1.2089407455522405},
{"total_number_of_episodes": 3870, "number_of_timesteps": 3870000, "per_episode_reward": -509.72, "episode_reward_trend_value": 0.05382677430719822, "biggest_recent_change": 1.2089407455522405},
{"total_number_of_episodes": 3880, "number_of_timesteps": 3880000, "per_episode_reward": -509.29, "episode_reward_trend_value": 0.054637323829523944, "biggest_recent_change": 1.2089407455522405},
{"total_number_of_episodes": 3890, "number_of_timesteps": 3890000, "per_episode_reward": -508.86, "episode_reward_trend_value": 0.053028942047594306, "biggest_recent_change": 1.2089407455522405},
{"total_number_of_episodes": 3900, "number_of_timesteps": 3900000, "per_episode_reward": -508.62, "episode_reward_trend_value": 0.04925467969302733, "biggest_recent_change": 1.2089407455522405},
{"total_number_of_episodes": 3910, "number_of_timesteps": 3910000, "per_episode_reward": -508.39, "episode_reward_trend_value": 0.04456242622353809, "biggest_recent_change": 1.2089407455522405},
{"total_number_of_episodes": 3920, "number_of_timesteps": 3920000, "per_episode_reward": -508.17, "episode_reward_trend_value": 0.03973987060104933, "biggest_recent_change": 1.2089407455522405},
{"total_number_of_episodes": 3930, "number_of_timesteps": 3930000, "per_episode_reward": -507.94, "episode_reward_trend_value": 0.039692377434775813, "biggest_recent_change": 1.2089407455522405},
{"total_number_of_episodes": 3940, "number_of_timesteps": 3940000, "per_episode_reward": -507.59, "episode_reward_trend_value": 0.041113340904620245, "biggest_recent_change": 1.2089407455522405},
{"total_number_of_episodes": 3950, "number_of_timesteps": 3950000, "per_episode_reward": -507.23, "episode_reward_trend_value": 0.03162662187969482, "biggest_recent_change": 0.42963138136519774},
{"total_number_of_episodes": 3960, "number_of_timesteps": 3960000, "per_episode_reward": -507.08, "episode_reward_trend_value": 0.029267228755127737, "biggest_recent_change": 0.42963138136519774},
{"total_number_of_episodes": 3970, "number_of_timesteps": 3970000, "per_episode_reward": -506.93, "episode_reward_trend_value": 0.02615089814929661, "biggest_recent_change": 0.42963138136519774},
{"total_number_of_episodes": 3980, "number_of_timesteps": 3980000, "per_episode_reward": -506.51, "episode_reward_trend_value": 0.026079967353364784, "biggest_recent_change": 0.4232476097313338},
{"total_number_of_episodes": 3990, "number_of_timesteps": 3990000, "per_episode_reward": -506.09, "episode_reward_trend_value": 0.028174917130064613, "biggest_recent_change": 0.4232476097313338},
{"total_number_of_episodes": 4000, "number_of_timesteps": 4000000, "per_episode_reward": -505.8, "episode_reward_trend_value": 0.028772825959147968, "biggest_recent_change": 0.4232476097313338},
{"total_number_of_episodes": 4010, "number_of_timesteps": 4010000, "per_episode_reward": -505.51, "episode_reward_trend_value": 0.02950103694123148, "biggest_recent_change": 0.4232476097313338},
{"total_number_of_episodes": 4020, "number_of_timesteps": 4020000, "per_episode_reward": -505.16, "episode_reward_trend_value": 0.030913387721130902, "biggest_recent_change": 0.4232476097313338},
{"total_number_of_episodes": 4030, "number_of_timesteps": 4030000, "per_episode_reward": -504.81, "episode_reward_trend_value": 0.030857281864912996, "biggest_recent_change": 0.4232476097313338},
{"total_number_of_episodes": 4040, "number_of_timesteps": 4040000, "per_episode_reward": -504.63, "episode_reward_trend_value": 0.028937424387352924, "biggest_recent_change": 0.4232476097313338},
{"total_number_of_episodes": 4050, "number_of_timesteps": 4050000, "per_episode_reward": -504.45, "episode_reward_trend_value": 0.029306171426112037, "biggest_recent_change": 0.4232476097313338},
{"total_number_of_episodes": 4060, "number_of_timesteps": 4060000, "per_episode_reward": -503.82, "episode_reward_trend_value": 0.034642234552991466, "biggest_recent_change": 0.6294073082592604},
{"total_number_of_episodes": 4070, "number_of_timesteps": 4070000, "per_episode_reward": -503.19, "episode_reward_trend_value": 0.03693289786997222, "biggest_recent_change": 0.6294073082596015},
{"total_number_of_episodes": 4080, "number_of_timesteps": 4080000, "per_episode_reward": -502.8, "episode_reward_trend_value": 0.036584341316603916, "biggest_recent_change": 0.6294073082596015},
{"total_number_of_episodes": 4090, "number_of_timesteps": 4090000, "per_episode_reward": -502.4, "episode_reward_trend_value": 0.03773282571085272, "biggest_recent_change": 0.6294073082596015},
{"total_number_of_episodes": 4100, "number_of_timesteps": 4100000, "per_episode_reward": -502.13, "episode_reward_trend_value": 0.03753665431317283, "biggest_recent_change": 0.6294073082596015},
{"total_number_of_episodes": 4110, "number_of_timesteps": 4110000, "per_episode_reward": -501.86, "episode_reward_trend_value": 0.03665634311767576, "biggest_recent_change": 0.6294073082596015},
{"total_number_of_episodes": 4120, "number_of_timesteps": 4120000, "per_episode_reward": -501.46, "episode_reward_trend_value": 0.03719247892892794, "biggest_recent_change": 0.6294073082596015},
{"total_number_of_episodes": 4130, "number_of_timesteps": 4130000, "per_episode_reward": -501.07, "episode_reward_trend_value": 0.039592366361524176, "biggest_recent_change": 0.6294073082596015},
{"total_number_of_episodes": 4140, "number_of_timesteps": 4140000, "per_episode_reward": -500.63, "episode_reward_trend_value": 0.042424655269341985, "biggest_recent_change": 0.6294073082596015},
{"total_number_of_episodes": 4150, "number_of_timesteps": 4150000, "per_episode_reward": -500.19, "episode_reward_trend_value": 0.040289628089042004, "biggest_recent_change": 0.6294073082596015},
{"total_number_of_episodes": 4160, "number_of_timesteps": 4160000, "per_episode_reward": -499.74, "episode_reward_trend_value": 0.03829100823110202, "biggest_recent_change": 0.44953152104500305},
{"total_number_of_episodes": 4170, "number_of_timesteps": 4170000, "per_episode_reward": -499.29, "episode_reward_trend_value": 0.03893160824351298, "biggest_recent_change": 0.44953152104500305},
{"total_number_of_episodes": 4180, "number_of_timesteps": 4180000, "per_episode_reward": -499.01, "episode_reward_trend_value": 0.03774731076902703, "biggest_recent_change": 0.44953152104500305},
{"total_number_of_episodes": 4190, "number_of_timesteps": 4190000, "per_episode_reward": -498.72, "episode_reward_trend_value": 0.037907669086464715, "biggest_recent_change": 0.44953152104500305},
{"total_number_of_episodes": 4200, "number_of_timesteps": 4200000, "per_episode_reward": -498.43, "episode_reward_trend_value": 0.03809254937459817, "biggest_recent_change": 0.44953152104500305},
{"total_number_of_episodes": 4210, "number_of_timesteps": 4210000, "per_episode_reward": -498.15, "episode_reward_trend_value": 0.03686098265598174, "biggest_recent_change": 0.44953152104500305},
{"total_number_of_episodes": 4220, "number_of_timesteps": 4220000, "per_episode_reward": -497.9, "episode_reward_trend_value": 0.03513838970531853, "biggest_recent_change": 0.44953152104500305},
{"total_number_of_episodes": 4230, "number_of_timesteps": 4230000, "per_episode_reward": -497.66, "episode_reward_trend_value": 0.032983395279435015, "biggest_recent_change": 0.44953152104500305},
{"total_number_of_episodes": 4240, "number_of_timesteps": 4240000, "per_episode_reward": -497.34, "episode_reward_trend_value": 0.03172761240708218, "biggest_recent_change": 0.44953152104500305},
{"total_number_of_episodes": 4250, "number_of_timesteps": 4250000, "per_episode_reward": -497.01, "episode_reward_trend_value": 0.030335422212366188, "biggest_recent_change": 0.44953152104500305},
{"total_number_of_episodes": 4260, "number_of_timesteps": 4260000, "per_episode_reward": -496.61, "episode_reward_trend_value": 0.029775548648580574, "biggest_recent_change": 0.3991429003042981},
{"total_number_of_episodes": 4270, "number_of_timesteps": 4270000, "per_episode_reward": -496.21, "episode_reward_trend_value": 0.031040572571691884, "biggest_recent_change": 0.3991429003044118},
{"total_number_of_episodes": 4280, "number_of_timesteps": 4280000, "per_episode_reward": -495.83, "episode_reward_trend_value": 0.03207206976355792, "biggest_recent_change": 0.3991429003044118},
{"total_number_of_episodes": 4290, "number_of_timesteps": 4290000, "per_episode_reward": -495.46, "episode_reward_trend_value": 0.033079044984727565, "biggest_recent_change": 0.3991429003044118},
{"total_number_of_episodes": 4300, "number_of_timesteps": 4300000, "per_episode_reward": -494.85, "episode_reward_trend_value": 0.036668799783655635, "biggest_recent_change": 0.6105756564901412},
{"total_number_of_episodes": 4310, "number_of_timesteps": 4310000, "per_episode_reward": -494.24, "episode_reward_trend_value": 0.04074958081462986, "biggest_recent_change": 0.6105756564901981},
{"total_number_of_episodes": 4320, "number_of_timesteps": 4320000, "per_episode_reward": -493.87, "episode_reward_trend_value": 0.04205300008172862, "biggest_recent_change": 0.6105756564901981},
{"total_number_of_episodes": 4330, "number_of_timesteps": 4330000, "per_episode_reward": -493.51, "episode_reward_trend_value": 0.04245720779529734, "biggest_recent_change": 0.6105756564901981},
{"total_number_of_episodes": 4340, "number_of_timesteps": 4340000, "per_episode_reward": -493.13, "episode_reward_trend_value": 0.043127098190413764, "biggest_recent_change": 0.6105756564901981},
{"total_number_of_episodes": 4350, "number_of_timesteps": 4350000, "per_episode_reward": -492.75, "episode_reward_trend_value": 0.04296467195459854, "biggest_recent_change": 0.6105756564901981},
{"total_number_of_episodes": 4360, "number_of_timesteps": 4360000, "per_episode_reward": -492.26, "episode_reward_trend_value": 0.0439720139398566, "biggest_recent_change": 0.6105756564901981},
{"total_number_of_episodes": 4370, "number_of_timesteps": 4370000, "per_episode_reward": -491.77, "episode_reward_trend_value": 0.045212882656364986, "biggest_recent_change": 0.6105756564901981},
{"total_number_of_episodes": 4380, "number_of_timesteps": 4380000, "per_episode_reward": -491.42, "episode_reward_trend_value": 0.04488183887522092, "biggest_recent_change": 0.6105756564901981},
{"total_number_of_episodes": 4390, "number_of_timesteps": 4390000, "per_episode_reward": -491.07, "episode_reward_trend_value": 0.04196801551631779, "biggest_recent_change": 0.6105756564901981},
{"total_number_of_episodes": 4400, "number_of_timesteps": 4400000, "per_episode_reward": -490.8, "episode_reward_trend_value": 0.038188508979878105, "biggest_recent_change": 0.4898036789777507},
{"total_number_of_episodes": 4410, "number_of_timesteps": 4410000, "per_episode_reward": -490.53, "episode_reward_trend_value": 0.03718636420731261, "biggest_recent_change": 0.4898036789777507},
{"total_number_of_episodes": 4420, "number_of_timesteps": 4420000, "per_episode_reward": -490.26, "episode_reward_trend_value": 0.03617134249469321, "biggest_recent_change": 0.4898036789777507},
{"total_number_of_episodes": 4430, "number_of_timesteps": 4430000, "per_episode_reward": -489.99, "episode_reward_trend_value": 0.0348906381005261, "biggest_recent_change": 0.4898036789777507},
{"total_number_of_episodes": 4440, "number_of_timesteps": 4440000, "per_episode_reward": -489.68, "episode_reward_trend_value": 0.03402944789294351, "biggest_recent_change": 0.4898036789777507},
{"total_number_of_episodes": 4450, "number_of_timesteps": 4450000, "per_episode_reward": -489.38, "episode_reward_trend_value": 0.031998489464287, "biggest_recent_change": 0.4898036789777507},
{"total_number_of_episodes": 4460, "number_of_timesteps": 4460000, "per_episode_reward": -489.08, "episode_reward_trend_value": 0.029859176390120486, "biggest_recent_change": 0.3483315541889169},
{"total_number_of_episodes": 4470, "number_of_timesteps": 4470000, "per_episode_reward": -488.78, "episode_reward_trend_value": 0.029291775813611465, "biggest_recent_change": 0.3483315541888601},
{"total_number_of_episodes": 4480, "number_of_timesteps": 4480000, "per_episode_reward": -488.53, "episode_reward_trend_value": 0.02825435643045403, "biggest_recent_change": 0.3070174203985516},
{"total_number_of_episodes": 4490, "number_of_timesteps": 4490000, "per_episode_reward": -488.27, "episode_reward_trend_value": 0.02808262022483316, "biggest_recent_change": 0.3070174203985516},
{"total_number_of_episodes": 4500, "number_of_timesteps": 4500000, "per_episode_reward": -487.76, "episode_reward_trend_value": 0.03080013242182026, "biggest_recent_change": 0.5149961659395217},
{"total_number_of_episodes": 4510, "number_of_timesteps": 4510000, "per_episode_reward": -487.24, "episode_reward_trend_value": 0.033530521558860625, "biggest_recent_change": 0.5149961659395785},
{"total_number_of_episodes": 4520, "number_of_timesteps": 4520000, "per_episode_reward": -487.0, "episode_reward_trend_value": 0.03324076675870502, "biggest_recent_change": 0.5149961659395785},
{"total_number_of_episodes": 4530, "number_of_timesteps": 4530000, "per_episode_reward": -486.75, "episode_reward_trend_value": 0.03253149777196553, "biggest_recent_change": 0.5149961659395785},
{"total_number_of_episodes": 4540, "number_of_timesteps": 4540000, "per_episode_reward": -486.45, "episode_reward_trend_value": 0.03246473549253703, "biggest_recent_change": 0.5149961659395785},
{"total_number_of_episodes": 4550, "number_of_timesteps": 4550000, "per_episode_reward": -486.15, "episode_reward_trend_value": 0.0325063278586179, "biggest_recent_change": 0.5149961659395785},
{"total_number_of_episodes": 4560, "number_of_timesteps": 4560000, "per_episode_reward": -485.75, "episode_reward_trend_value": 0.03366454202570708, "biggest_recent_change": 0.5149961659395785},
{"total_number_of_episodes": 4570, "number_of_timesteps": 4570000, "per_episode_reward": -485.35, "episode_reward_trend_value": 0.035292774999446566, "biggest_recent_change": 0.5149961659395785},
{"total_number_of_episodes": 4580, "number_of_timesteps": 4580000, "per_episode_reward": -484.99, "episode_reward_trend_value": 0.03649765103228522, "biggest_recent_change": 0.5149961659395785},
{"total_number_of_episodes": 4590, "number_of_timesteps": 4590000, "per_episode_reward": -484.62, "episode_reward_trend_value": 0.034813278662517176, "biggest_recent_change": 0.5149961659395785},
{"total_number_of_episodes": 4600, "number_of_timesteps": 4600000, "per_episode_reward": -484.3, "episode_reward_trend_value": 0.032684407973484514, "biggest_recent_change": 0.4015047773412448},
{"total_number_of_episodes": 4610, "number_of_timesteps": 4610000, "per_episode_reward": -483.98, "episode_reward_trend_value": 0.03357568122164973, "biggest_recent_change": 0.4015047773412448},
{"total_number_of_episodes": 4620, "number_of_timesteps": 4620000, "per_episode_reward": -483.69, "episode_reward_trend_value": 0.03404277072132484, "biggest_recent_change": 0.4015047773412448},
{"total_number_of_episodes": 4630, "number_of_timesteps": 4630000, "per_episode_reward": -483.41, "episode_reward_trend_value": 0.03386735351368834, "biggest_recent_change": 0.4015047773412448},
{"total_number_of_episodes": 4640, "number_of_timesteps": 4640000, "per_episode_reward": -482.93, "episode_reward_trend_value": 0.03580712748395613, "biggest_recent_change": 0.47558847257414527},
{"total_number_of_episodes": 4650, "number_of_timesteps": 4650000, "per_episode_reward": -482.45, "episode_reward_trend_value": 0.036630279653211216, "biggest_recent_change": 0.47558847257414527},
{"total_number_of_episodes": 4660, "number_of_timesteps": 4660000, "per_episode_reward": -482.28, "episode_reward_trend_value": 0.03414659830477894, "biggest_recent_change": 0.47558847257414527},
{"total_number_of_episodes": 4670, "number_of_timesteps": 4670000, "per_episode_reward": -482.1, "episode_reward_trend_value": 0.032086273897245596, "biggest_recent_change": 0.47558847257414527},
{"total_number_of_episodes": 4680, "number_of_timesteps": 4680000, "per_episode_reward": -481.97, "episode_reward_trend_value": 0.029507479338249393, "biggest_recent_change": 0.47558847257414527},
{"total_number_of_episodes": 4690, "number_of_timesteps": 4690000, "per_episode_reward": -481.84, "episode_reward_trend_value": 0.027373183098517172, "biggest_recent_change": 0.47558847257414527},
{"total_number_of_episodes": 4700, "number_of_timesteps": 4700000, "per_episode_reward": -481.57, "episode_reward_trend_value": 0.026785625207303255, "biggest_recent_change": 0.47558847257414527},
{"total_number_of_episodes": 4710, "number_of_timesteps": 4710000, "per_episode_reward": -481.29, "episode_reward_trend_value": 0.02662225106457943, "biggest_recent_change": 0.47558847257414527},
{"total_number_of_episodes": 4720, "number_of_timesteps": 4720000, "per_episode_reward": -480.95, "episode_reward_trend_value": 0.027254355210821913, "biggest_recent_change": 0.47558847257414527},
{"total_number_of_episodes": 4730, "number_of_timesteps": 4730000, "per_episode_reward": -480.61, "episode_reward_trend_value": 0.02577126817915819, "biggest_recent_change": 0.47558847257408843},
{"total_number_of_episodes": 4740, "number_of_timesteps": 4740000, "per_episode_reward": -480.43, "episode_reward_trend_value": 0.022460549369494882, "biggest_recent_change": 0.34211063972452394},
{"total_number_of_episodes": 4750, "number_of_timesteps": 4750000, "per_episode_reward": -480.26, "episode_reward_trend_value": 0.022456664077516404, "biggest_recent_change": 0.34211063972452394},
{"total_number_of_episodes": 4760, "number_of_timesteps": 4760000, "per_episode_reward": -479.94, "episode_reward_trend_value": 0.0240173468054296, "biggest_recent_change": 0.34211063972452394},
{"total_number_of_episodes": 4770, "number_of_timesteps": 4770000, "per_episode_reward": -479.62, "episode_reward_trend_value": 0.026096499684805645, "biggest_recent_change": 0.34211063972452394},
{"total_number_of_episodes": 4780, "number_of_timesteps": 4780000, "per_episode_reward": -479.28, "episode_reward_trend_value": 0.028371206531299247, "biggest_recent_change": 0.34211063972452394},
{"total_number_of_episodes": 4790, "number_of_timesteps": 4790000, "per_episode_reward": -478.95, "episode_reward_trend_value": 0.029099175029275177, "biggest_recent_change": 0.34211063972452394},
{"total_number_of_episodes": 4800, "number_of_timesteps": 4800000, "per_episode_reward": -478.31, "episode_reward_trend_value": 0.033195109272881815, "biggest_recent_change": 0.6391516756421538},
{"total_number_of_episodes": 4810, "number_of_timesteps": 4810000, "per_episode_reward": -477.67, "episode_reward_trend_value": 0.03649556522752151, "biggest_recent_change": 0.6391516756421538},
{"total_number_of_episodes": 4820, "number_of_timesteps": 4820000, "per_episode_reward": -477.46, "episode_reward_trend_value": 0.03503884196444965, "biggest_recent_change": 0.6391516756421538},
{"total_number_of_episodes": 4830, "number_of_timesteps": 4830000, "per_episode_reward": -477.25, "episode_reward_trend_value": 0.03540975047937549, "biggest_recent_change": 0.6391516756421538},
{"total_number_of_episodes": 4840, "number_of_timesteps": 4840000, "per_episode_reward": -476.87, "episode_reward_trend_value": 0.03761967248622366, "biggest_recent_change": 0.6391516756421538},
{"total_number_of_episodes": 4850, "number_of_timesteps": 4850000, "per_episode_reward": -476.49, "episode_reward_trend_value": 0.038265026473182064, "biggest_recent_change": 0.6391516756421538},
{"total_number_of_episodes": 4860, "number_of_timesteps": 4860000, "per_episode_reward": -476.23, "episode_reward_trend_value": 0.037616295887926934, "biggest_recent_change": 0.6391516756421538},
{"total_number_of_episodes": 4870, "number_of_timesteps": 4870000, "per_episode_reward": -475.97, "episode_reward_trend_value": 0.03677201133555362, "biggest_recent_change": 0.6391516756421538},
{"total_number_of_episodes": 4880, "number_of_timesteps": 4880000, "per_episode_reward": -475.66, "episode_reward_trend_value": 0.036561365956770765, "biggest_recent_change": 0.6391516756421538},
{"total_number_of_episodes": 4890, "number_of_timesteps": 4890000, "per_episode_reward": -475.34, "episode_reward_trend_value": 0.03298275483235784, "biggest_recent_change": 0.639151675642097},
{"total_number_of_episodes": 4900, "number_of_timesteps": 4900000, "per_episode_reward": -474.95, "episode_reward_trend_value": 0.03024698995180175, "biggest_recent_change": 0.392932836392049},
{"total_number_of_episodes": 4910, "number_of_timesteps": 4910000, "per_episode_reward": -474.55, "episode_reward_trend_value": 0.03226840428896101, "biggest_recent_change": 0.3929328363922764},
{"total_number_of_episodes": 4920, "number_of_timesteps": 4920000, "per_episode_reward": -474.24, "episode_reward_trend_value": 0.03339382397517486, "biggest_recent_change": 0.3929328363922764},
{"total_number_of_episodes": 4930, "number_of_timesteps": 4930000, "per_episode_reward": -473.93, "episode_reward_trend_value": 0.03268023016946889, "biggest_recent_change": 0.3929328363922764},
{"total_number_of_episodes": 4940, "number_of_timesteps": 4940000, "per_episode_reward": -473.49, "episode_reward_trend_value": 0.033316802563304763, "biggest_recent_change": 0.4338082757658981},
{"total_number_of_episodes": 4950, "number_of_timesteps": 4950000, "per_episode_reward": -473.06, "episode_reward_trend_value": 0.03524745952935291, "biggest_recent_change": 0.43380827576595493},
{"total_number_of_episodes": 4960, "number_of_timesteps": 4960000, "per_episode_reward": -472.2, "episode_reward_trend_value": 0.041865962635836876, "biggest_recent_change": 0.8557144284051219},
{"total_number_of_episodes": 4970, "number_of_timesteps": 4970000, "per_episode_reward": -471.9, "episode_reward_trend_value": 0.04172586092758037, "biggest_recent_change": 0.8557144284051219},
{"total_number_of_episodes": 4980, "number_of_timesteps": 4980000, "per_episode_reward": -471.62, "episode_reward_trend_value": 0.041323708927080816, "biggest_recent_change": 0.8557144284051219},
{"total_number_of_episodes": 4990, "number_of_timesteps": 4990000, "per_episode_reward": -471.34, "episode_reward_trend_value": 0.04007871068272632, "biggest_recent_change": 0.8557144284051219},
{"total_number_of_episodes": 5000, "number_of_timesteps": 5000000, "per_episode_reward": -470.93, "episode_reward_trend_value": 0.04029249295575773, "biggest_recent_change": 0.8557144284051219},
{"total_number_of_episodes": 5010, "number_of_timesteps": 5010000, "per_episode_reward": -470.51, "episode_reward_trend_value": 0.04140226987973645, "biggest_recent_change": 0.8557144284051219},
{"total_number_of_episodes": 5020, "number_of_timesteps": 5020000, "per_episode_reward": -470.15, "episode_reward_trend_value": 0.042007271553282204, "biggest_recent_change": 0.8557144284051219},
{"total_number_of_episodes": 5030, "number_of_timesteps": 5030000, "per_episode_reward": -469.78, "episode_reward_trend_value": 0.041262107027286124, "biggest_recent_change": 0.8557144284051219},
{"total_number_of_episodes": 5040, "number_of_timesteps": 5040000, "per_episode_reward": -469.59, "episode_reward_trend_value": 0.038538812296800666, "biggest_recent_change": 0.8557144284051219},
{"total_number_of_episodes": 5050, "number_of_timesteps": 5050000, "per_episode_reward": -469.4, "episode_reward_trend_value": 0.03112767142588066, "biggest_recent_change": 0.4121732409651031},
{"total_number_of_episodes": 5060, "number_of_timesteps": 5060000, "per_episode_reward": -469.23, "episode_reward_trend_value": 0.02965552204667511, "biggest_recent_change": 0.4121732409651031},
{"total_number_of_episodes": 5070, "number_of_timesteps": 5070000, "per_episode_reward": -469.06, "episode_reward_trend_value": 0.028445422959712613, "biggest_recent_change": 0.4121732409651031},
{"total_number_of_episodes": 5080, "number_of_timesteps": 5080000, "per_episode_reward": -468.68, "episode_reward_trend_value": 0.029588929321267367, "biggest_recent_change": 0.4121732409651031},
{"total_number_of_episodes": 5090, "number_of_timesteps": 5090000, "per_episode_reward": -468.29, "episode_reward_trend_value": 0.02927365516543432, "biggest_recent_change": 0.41217324096504626},
{"total_number_of_episodes": 5100, "number_of_timesteps": 5100000, "per_episode_reward": -468.03, "episode_reward_trend_value": 0.027629225558529112, "biggest_recent_change": 0.38379856694012915},
{"total_number_of_episodes": 5110, "number_of_timesteps": 5110000, "per_episode_reward": -467.76, "episode_reward_trend_value": 0.02648957120205624, "biggest_recent_change": 0.38379856694012915},
{"total_number_of_episodes": 5120, "number_of_timesteps": 5120000, "per_episode_reward": -467.45, "episode_reward_trend_value": 0.025911407301394872, "biggest_recent_change": 0.38379856694012915},
{"total_number_of_episodes": 5130, "number_of_timesteps": 5130000, "per_episode_reward": -467.13, "episode_reward_trend_value": 0.027311373605223503, "biggest_recent_change": 0.38379856694012915},
{"total_number_of_episodes": 5140, "number_of_timesteps": 5140000, "per_episode_reward": -466.92, "episode_reward_trend_value": 0.02761154811960359, "biggest_recent_change": 0.38379856694012915},
{"total_number_of_episodes": 5150, "number_of_timesteps": 5150000, "per_episode_reward": -466.7, "episode_reward_trend_value": 0.028097696783414804, "biggest_recent_change": 0.38379856694012915},
{"total_number_of_episodes": 5160, "number_of_timesteps": 5160000, "per_episode_reward": -466.44, "episode_reward_trend_value": 0.029082378583879947, "biggest_recent_change": 0.38379856694012915},
{"total_number_of_episodes": 5170, "number_of_timesteps": 5170000, "per_episode_reward": -466.18, "episode_reward_trend_value": 0.027713454935824684, "biggest_recent_change": 0.38379856694012915},
{"total_number_of_episodes": 5180, "number_of_timesteps": 5180000, "per_episode_reward": -465.94, "episode_reward_trend_value": 0.026127127567027248, "biggest_recent_change": 0.31470871736684103},
{"total_number_of_episodes": 5190, "number_of_timesteps": 5190000, "per_episode_reward": -465.7, "episode_reward_trend_value": 0.02586995564930261, "biggest_recent_change": 0.31470871736684103},
{"total_number_of_episodes": 5200, "number_of_timesteps": 5200000, "per_episode_reward": -465.44, "episode_reward_trend_value": 0.025847775181504558, "biggest_recent_change": 0.31470871736684103},
{"total_number_of_episodes": 5210, "number_of_timesteps": 5210000, "per_episode_reward": -465.18, "episode_reward_trend_value": 0.02526410425789436, "biggest_recent_change": 0.31470871736684103},
{"total_number_of_episodes": 5220, "number_of_timesteps": 5220000, "per_episode_reward": -465.04, "episode_reward_trend_value": 0.0232744259708871, "biggest_recent_change": 0.2621783342418098},
{"total_number_of_episodes": 5230, "number_of_timesteps": 5230000, "per_episode_reward": -464.9, "episode_reward_trend_value": 0.022384539473329017, "biggest_recent_change": 0.2621783342418098},
{"total_number_of_episodes": 5240, "number_of_timesteps": 5240000, "per_episode_reward": -464.81, "episode_reward_trend_value": 0.021071152653591853, "biggest_recent_change": 0.2621783342418098},
{"total_number_of_episodes": 5250, "number_of_timesteps": 5250000, "per_episode_reward": -464.71, "episode_reward_trend_value": 0.019259232697200764, "biggest_recent_change": 0.2621783342418098},
{"total_number_of_episodes": 5260, "number_of_timesteps": 5260000, "per_episode_reward": -464.43, "episode_reward_trend_value": 0.01946146629707578, "biggest_recent_change": 0.27879646260385016},
{"total_number_of_episodes": 5270, "number_of_timesteps": 5270000, "per_episode_reward": -464.15, "episode_reward_trend_value": 0.019881103617692335, "biggest_recent_change": 0.27879646260385016},
{"total_number_of_episodes": 5280, "number_of_timesteps": 5280000, "per_episode_reward": -463.84, "episode_reward_trend_value": 0.020606866411672323, "biggest_recent_change": 0.3063477552065592},
{"total_number_of_episodes": 5290, "number_of_timesteps": 5290000, "per_episode_reward": -463.54, "episode_reward_trend_value": 0.0210976377557232, "biggest_recent_change": 0.3063477552065592},
{"total_number_of_episodes": 5300, "number_of_timesteps": 5300000, "per_episode_reward": -463.23, "episode_reward_trend_value": 0.021559796626252136, "biggest_recent_change": 0.3063477552065592},
{"total_number_of_episodes": 5310, "number_of_timesteps": 5310000, "per_episode_reward": -462.93, "episode_reward_trend_value": 0.023427962860176243, "biggest_recent_change": 0.3063477552065592},
{"total_number_of_episodes": 5320, "number_of_timesteps": 5320000, "per_episode_reward": -462.72, "episode_reward_trend_value": 0.024275041228541263, "biggest_recent_change": 0.3063477552065592},
{"total_number_of_episodes": 5330, "number_of_timesteps": 5330000, "per_episode_reward": -462.51, "episode_reward_trend_value": 0.02554561991908915, "biggest_recent_change": 0.3063477552065592},
{"total_number_of_episodes": 5340, "number_of_timesteps": 5340000, "per_episode_reward": -462.2, "episode_reward_trend_value": 0.027845384841519816, "biggest_recent_change": 0.3063477552065592},
{"total_number_of_episodes": 5350, "number_of_timesteps": 5350000, "per_episode_reward": -461.9, "episode_reward_trend_value": 0.028130996207686266, "biggest_recent_change": 0.3063477552065592},
{"total_number_of_episodes": 5360, "number_of_timesteps": 5360000, "per_episode_reward": -461.61, "episode_reward_trend_value": 0.02818405324198352, "biggest_recent_change": 0.3063477552065592},
{"total_number_of_episodes": 5370, "number_of_timesteps": 5370000, "per_episode_reward": -461.33, "episode_reward_trend_value": 0.027930984802916076, "biggest_recent_change": 0.3063477552063887},
{"total_number_of_episodes": 5380, "number_of_timesteps": 5380000, "per_episode_reward": -461.09, "episode_reward_trend_value": 0.027259516738548782, "biggest_recent_change": 0.3045014855588306},
{"total_number_of_episodes": 5390, "number_of_timesteps": 5390000, "per_episode_reward": -460.84, "episode_reward_trend_value": 0.026616661147704057, "biggest_recent_change": 0.3045014855588306},
{"total_number_of_episodes": 5400, "number_of_timesteps": 5400000, "per_episode_reward": -460.61, "episode_reward_trend_value": 0.025813996841508112, "biggest_recent_change": 0.3045014855588306},
{"total_number_of_episodes": 5410, "number_of_timesteps": 5410000, "per_episode_reward": -460.38, "episode_reward_trend_value": 0.02603242040086747, "biggest_recent_change": 0.3045014855588306},
{"total_number_of_episodes": 5420, "number_of_timesteps": 5420000, "per_episode_reward": -460.12, "episode_reward_trend_value": 0.026503705901665675, "biggest_recent_change": 0.3045014855588306},
{"total_number_of_episodes": 5430, "number_of_timesteps": 5430000, "per_episode_reward": -459.87, "episode_reward_trend_value": 0.0259458051705811, "biggest_recent_change": 0.3045014855588306},
{"total_number_of_episodes": 5440, "number_of_timesteps": 5440000, "per_episode_reward": -459.57, "episode_reward_trend_value": 0.025826840355077568, "biggest_recent_change": 0.29379465216351264},
{"total_number_of_episodes": 5450, "number_of_timesteps": 5450000, "per_episode_reward": -459.28, "episode_reward_trend_value": 0.025940429871444494, "biggest_recent_change": 0.2937946521636263},
{"total_number_of_episodes": 5460, "number_of_timesteps": 5460000, "per_episode_reward": -458.98, "episode_reward_trend_value": 0.026068203036872246, "biggest_recent_change": 0.2950711805789865},
{"total_number_of_episodes": 5470, "number_of_timesteps": 5470000, "per_episode_reward": -458.69, "episode_reward_trend_value": 0.026614375827601733, "biggest_recent_change": 0.2950711805789865},
{"total_number_of_episodes": 5480, "number_of_timesteps": 5480000, "per_episode_reward": -458.43, "episode_reward_trend_value": 0.026806951785296934, "biggest_recent_change": 0.2950711805789865},
{"total_number_of_episodes": 5490, "number_of_timesteps": 5490000, "per_episode_reward": -458.16, "episode_reward_trend_value": 0.027159336458345885, "biggest_recent_change": 0.2950711805789865},
{"total_number_of_episodes": 5500, "number_of_timesteps": 5500000, "per_episode_reward": -458.07, "episode_reward_trend_value": 0.025611833168066922, "biggest_recent_change": 0.2950711805789865},
{"total_number_of_episodes": 5510, "number_of_timesteps": 5510000, "per_episode_reward": -457.57, "episode_reward_trend_value": 0.028367587798458594, "biggest_recent_change": 0.5023083364964691},
{"total_number_of_episodes": 5520, "number_of_timesteps": 5520000, "per_episode_reward": -457.22, "episode_reward_trend_value": 0.029374519648388286, "biggest_recent_change": 0.5023083364964691},
{"total_number_of_episodes": 5530, "number_of_timesteps": 5530000, "per_episode_reward": -456.88, "episode_reward_trend_value": 0.029942515582735675, "biggest_recent_change": 0.5023083364964691},
{"total_number_of_episodes": 5540, "number_of_timesteps": 5540000, "per_episode_reward": -456.58, "episode_reward_trend_value": 0.030024317697970242, "biggest_recent_change": 0.5023083364964691},
{"total_number_of_episodes": 5550, "number_of_timesteps": 5550000, "per_episode_reward": -456.28, "episode_reward_trend_value": 0.030091936164143362, "biggest_recent_change": 0.5023083364964691},
{"total_number_of_episodes": 5560, "number_of_timesteps": 5560000, "per_episode_reward": -456.07, "episode_reward_trend_value": 0.029114930678049534, "biggest_recent_change": 0.5023083364964691},
{"total_number_of_episodes": 5570, "number_of_timesteps": 5570000, "per_episode_reward": -455.86, "episode_reward_trend_value": 0.028491522024990622, "biggest_recent_change": 0.5023083364964691},
{"total_number_of_episodes": 5580, "number_of_timesteps": 5580000, "per_episode_reward": -455.71, "episode_reward_trend_value": 0.027227018237432, "biggest_recent_change": 0.5023083364964691},
{"total_number_of_episodes": 5590, "number_of_timesteps": 5590000, "per_episode_reward": -455.56, "episode_reward_trend_value": 0.027862402413203174, "biggest_recent_change": 0.5023083364964691},
{"total_number_of_episodes": 5600, "number_of_timesteps": 5600000, "per_episode_reward": -454.85, "episode_reward_trend_value": 0.030209525793836494, "biggest_recent_change": 0.7135494407534679},
{"total_number_of_episodes": 5610, "number_of_timesteps": 5610000, "per_episode_reward": -454.14, "episode_reward_trend_value": 0.03430547195493179, "biggest_recent_change": 0.7135494407534679},
{"total_number_of_episodes": 5620, "number_of_timesteps": 5620000, "per_episode_reward": -453.79, "episode_reward_trend_value": 0.03430994943188479, "biggest_recent_change": 0.7135494407534679},
{"total_number_of_episodes": 5630, "number_of_timesteps": 5630000, "per_episode_reward": -453.45, "episode_reward_trend_value": 0.03480062072794933, "biggest_recent_change": 0.7135494407534679},
{"total_number_of_episodes": 5640, "number_of_timesteps": 5640000, "per_episode_reward": -453.21, "episode_reward_trend_value": 0.034055151845843866, "biggest_recent_change": 0.7135494407534679},
{"total_number_of_episodes": 5650, "number_of_timesteps": 5650000, "per_episode_reward": -452.98, "episode_reward_trend_value": 0.03435430691600472, "biggest_recent_change": 0.7135494407534679},
{"total_number_of_episodes": 5660, "number_of_timesteps": 5660000, "per_episode_reward": -452.59, "episode_reward_trend_value": 0.03638505168184199, "biggest_recent_change": 0.7135494407534679},
{"total_number_of_episodes": 5670, "number_of_timesteps": 5670000, "per_episode_reward": -452.2, "episode_reward_trend_value": 0.039056891582175825, "biggest_recent_change": 0.7135494407534679},
{"total_number_of_episodes": 5680, "number_of_timesteps": 5680000, "per_episode_reward": -451.77, "episode_reward_trend_value": 0.042093973438006874, "biggest_recent_change": 0.7135494407534679},
{"total_number_of_episodes": 5690, "number_of_timesteps": 5690000, "per_episode_reward": -451.35, "episode_reward_trend_value": 0.03886319622686187, "biggest_recent_change": 0.7135494407534679},
{"total_number_of_episodes": 5700, "number_of_timesteps": 5700000, "per_episode_reward": -450.94, "episode_reward_trend_value": 0.03555292008125232, "biggest_recent_change": 0.42277949175058893},
{"total_number_of_episodes": 5710, "number_of_timesteps": 5710000, "per_episode_reward": -450.52, "episode_reward_trend_value": 0.03633411261978697, "biggest_recent_change": 0.42277949175058893},
{"total_number_of_episodes": 5720, "number_of_timesteps": 5720000, "per_episode_reward": -450.11, "episode_reward_trend_value": 0.037028243958776685, "biggest_recent_change": 0.42277949175058893},
{"total_number_of_episodes": 5730, "number_of_timesteps": 5730000, "per_episode_reward": -449.71, "episode_reward_trend_value": 0.03895851547593831, "biggest_recent_change": 0.42277949175058893},
{"total_number_of_episodes": 5740, "number_of_timesteps": 5740000, "per_episode_reward": -449.58, "episode_reward_trend_value": 0.03776941457907697, "biggest_recent_change": 0.42277949175058893},
{"total_number_of_episodes": 5750, "number_of_timesteps": 5750000, "per_episode_reward": -449.45, "episode_reward_trend_value": 0.034848723986539196, "biggest_recent_change": 0.42277949175058893},
{"total_number_of_episodes": 5760, "number_of_timesteps": 5760000, "per_episode_reward": -449.11, "episode_reward_trend_value": 0.034289363597039504, "biggest_recent_change": 0.42277949175058893},
{"total_number_of_episodes": 5770, "number_of_timesteps": 5770000, "per_episode_reward": -448.77, "episode_reward_trend_value": 0.033364761252044496, "biggest_recent_change": 0.4227794917504184},
{"total_number_of_episodes": 5780, "number_of_timesteps": 5780000, "per_episode_reward": -448.25, "episode_reward_trend_value": 0.03446094247216378, "biggest_recent_change": 0.5214358015611538},
{"total_number_of_episodes": 5790, "number_of_timesteps": 5790000, "per_episode_reward": -447.73, "episode_reward_trend_value": 0.03563662262674825, "biggest_recent_change": 0.5214358015612106},
{"total_number_of_episodes": 5800, "number_of_timesteps": 5800000, "per_episode_reward": -447.01, "episode_reward_trend_value": 0.039019400743015034, "biggest_recent_change": 0.720074618112676},
{"total_number_of_episodes": 5810, "number_of_timesteps": 5810000, "per_episode_reward": -446.29, "episode_reward_trend_value": 0.042489240058826754, "biggest_recent_change": 0.720074618112676},
{"total_number_of_episodes": 5820, "number_of_timesteps": 5820000, "per_episode_reward": -445.9, "episode_reward_trend_value": 0.04232500129938457, "biggest_recent_change": 0.720074618112676},
{"total_number_of_episodes": 5830, "number_of_timesteps": 5830000, "per_episode_reward": -445.5, "episode_reward_trend_value": 0.04528013495396913, "biggest_recent_change": 0.720074618112676},
{"total_number_of_episodes": 5840, "number_of_timesteps": 5840000, "per_episode_reward": -445.11, "episode_reward_trend_value": 0.04824517515936135, "biggest_recent_change": 0.720074618112676},
{"total_number_of_episodes": 5850, "number_of_timesteps": 5850000, "per_episode_reward": -444.72, "episode_reward_trend_value": 0.048848885161717384, "biggest_recent_change": 0.720074618112676},
{"total_number_of_episodes": 5860, "number_of_timesteps": 5860000, "per_episode_reward": -444.42, "episode_reward_trend_value": 0.04832369312978686, "biggest_recent_change": 0.720074618112676},
{"total_number_of_episodes": 5870, "number_of_timesteps": 5870000, "per_episode_reward": -444.13, "episode_reward_trend_value": 0.04577771753274267, "biggest_recent_change": 0.720074618112676},
{"total_number_of_episodes": 5880, "number_of_timesteps": 5880000, "per_episode_reward": -443.6, "episode_reward_trend_value": 0.04585414102102605, "biggest_recent_change": 0.720074618112676},
{"total_number_of_episodes": 5890, "number_of_timesteps": 5890000, "per_episode_reward": -443.07, "episode_reward_trend_value": 0.043723466547625225, "biggest_recent_change": 0.720074618112676},
{"total_number_of_episodes": 5900, "number_of_timesteps": 5900000, "per_episode_reward": -442.83, "episode_reward_trend_value": 0.038472398427648435, "biggest_recent_change": 0.5283139155067147},
{"total_number_of_episodes": 5910, "number_of_timesteps": 5910000, "per_episode_reward": -442.58, "episode_reward_trend_value": 0.036855408382925565, "biggest_recent_change": 0.5283139155067147},
{"total_number_of_episodes": 5920, "number_of_timesteps": 5920000, "per_episode_reward": -442.38, "episode_reward_trend_value": 0.03468870187881205, "biggest_recent_change": 0.5283139155067147},
{"total_number_of_episodes": 5930, "number_of_timesteps": 5930000, "per_episode_reward": -442.18, "episode_reward_trend_value": 0.03251208882388836, "biggest_recent_change": 0.5283139155067147},
{"total_number_of_episodes": 5940, "number_of_timesteps": 5940000, "per_episode_reward": -441.78, "episode_reward_trend_value": 0.03261751228365218, "biggest_recent_change": 0.5283139155067147},
{"total_number_of_episodes": 5950, "number_of_timesteps": 5950000, "per_episode_reward": -441.38, "episode_reward_trend_value": 0.0338518377777013, "biggest_recent_change": 0.5283139155067147},
{"total_number_of_episodes": 5960, "number_of_timesteps": 5960000, "per_episode_reward": -441.04, "episode_reward_trend_value": 0.034322589735505615, "biggest_recent_change": 0.5283139155067147},
{"total_number_of_episodes": 5970, "number_of_timesteps": 5970000, "per_episode_reward": -440.71, "episode_reward_trend_value": 0.03217094260798048, "biggest_recent_change": 0.528313915506601},
{"total_number_of_episodes": 5980, "number_of_timesteps": 5980000, "per_episode_reward": -440.25, "episode_reward_trend_value": 0.031407727353975665, "biggest_recent_change": 0.4596245426461678},
{"total_number_of_episodes": 5990, "number_of_timesteps": 5990000, "per_episode_reward": -439.79, "episode_reward_trend_value": 0.03376490574654617, "biggest_recent_change": 0.4596245426461678},
{"total_number_of_episodes": 6000, "number_of_timesteps": 6000000, "per_episode_reward": -439.37, "episode_reward_trend_value": 0.03566895729268506, "biggest_recent_change": 0.4596245426461678},
{"total_number_of_episodes": 6010, "number_of_timesteps": 6010000, "per_episode_reward": -438.95, "episode_reward_trend_value": 0.0381227252982108, "biggest_recent_change": 0.4596245426461678},
{"total_number_of_episodes": 6020, "number_of_timesteps": 6020000, "per_episode_reward": -438.58, "episode_reward_trend_value": 0.04003428351682601, "biggest_recent_change": 0.4596245426461678},
{"total_number_of_episodes": 6030, "number_of_timesteps": 6030000, "per_episode_reward": -438.21, "episode_reward_trend_value": 0.03966380522075244, "biggest_recent_change": 0.4596245426461678},
{"total_number_of_episodes": 6040, "number_of_timesteps": 6040000, "per_episode_reward": -437.56, "episode_reward_trend_value": 0.04243308261036355, "biggest_recent_change": 0.6526222573567111},
{"total_number_of_episodes": 6050, "number_of_timesteps": 6050000, "per_episode_reward": -436.9, "episode_reward_trend_value": 0.045965933536218195, "biggest_recent_change": 0.6526222573567111},
{"total_number_of_episodes": 6060, "number_of_timesteps": 6060000, "per_episode_reward": -436.26, "episode_reward_trend_value": 0.04938358604745822, "biggest_recent_change": 0.6526222573567111},
{"total_number_of_episodes": 6070, "number_of_timesteps": 6070000, "per_episode_reward": -435.62, "episode_reward_trend_value": 0.05141280668517854, "biggest_recent_change": 0.6526222573567111},
{"total_number_of_episodes": 6080, "number_of_timesteps": 6080000, "per_episode_reward": -435.29, "episode_reward_trend_value": 0.049931287722077715, "biggest_recent_change": 0.6526222573567111},
{"total_number_of_episodes": 6090, "number_of_timesteps": 6090000, "per_episode_reward": -434.97, "episode_reward_trend_value": 0.048902895605409766, "biggest_recent_change": 0.6526222573567111},
{"total_number_of_episodes": 6100, "number_of_timesteps": 6100000, "per_episode_reward": -434.26, "episode_reward_trend_value": 0.05215515048533663, "biggest_recent_change": 0.7115460656606274},
{"total_number_of_episodes": 6110, "number_of_timesteps": 6110000, "per_episode_reward": -433.54, "episode_reward_trend_value": 0.05594961515217593, "biggest_recent_change": 0.7115460656606842},
{"total_number_of_episodes": 6120, "number_of_timesteps": 6120000, "per_episode_reward": -433.15, "episode_reward_trend_value": 0.056209132537964654, "biggest_recent_change": 0.7115460656606842},
{"total_number_of_episodes": 6130, "number_of_timesteps": 6130000, "per_episode_reward": -432.76, "episode_reward_trend_value": 0.05332889423806869, "biggest_recent_change": 0.7115460656606842},
{"total_number_of_episodes": 6140, "number_of_timesteps": 6140000, "per_episode_reward": -432.51, "episode_reward_trend_value": 0.04888443212158475, "biggest_recent_change": 0.7115460656606842},
{"total_number_of_episodes": 6150, "number_of_timesteps": 6150000, "per_episode_reward": -432.25, "episode_reward_trend_value": 0.04455516841971669, "biggest_recent_change": 0.7115460656606842},
{"total_number_of_episodes": 6160, "number_of_timesteps": 6160000, "per_episode_reward": -431.88, "episode_reward_trend_value": 0.04150620824875154, "biggest_recent_change": 0.7115460656606842},
{"total_number_of_episodes": 6170, "number_of_timesteps": 6170000, "per_episode_reward": -431.52, "episode_reward_trend_value": 0.04196798767860817, "biggest_recent_change": 0.7115460656606842},
{"total_number_of_episodes": 6180, "number_of_timesteps": 6180000, "per_episode_reward": -431.06, "episode_reward_trend_value": 0.043453302894777654, "biggest_recent_change": 0.7115460656606842},
{"total_number_of_episodes": 6190, "number_of_timesteps": 6190000, "per_episode_reward": -430.6, "episode_reward_trend_value": 0.04065797111435106, "biggest_recent_change": 0.7115460656606842},
{"total_number_of_episodes": 6200, "number_of_timesteps": 6200000, "per_episode_reward": -429.94, "episode_reward_trend_value": 0.0400243286592753, "biggest_recent_change": 0.6545182447038655},
{"total_number_of_episodes": 6210, "number_of_timesteps": 6210000, "per_episode_reward": -429.29, "episode_reward_trend_value": 0.04292563348524949, "biggest_recent_change": 0.6545182447038655},
{"total_number_of_episodes": 6220, "number_of_timesteps": 6220000, "per_episode_reward": -428.57, "episode_reward_trend_value": 0.046526958269087496, "biggest_recent_change": 0.717520040911495},
{"total_number_of_episodes": 6230, "number_of_timesteps": 6230000, "per_episode_reward": -427.85, "episode_reward_trend_value": 0.05169250686951664, "biggest_recent_change": 0.7175200409115519},
{"total_number_of_episodes": 6240, "number_of_timesteps": 6240000, "per_episode_reward": -427.48, "episode_reward_trend_value": 0.05299916981017785, "biggest_recent_change": 0.7175200409115519},
{"total_number_of_episodes": 6250, "number_of_timesteps": 6250000, "per_episode_reward": -427.11, "episode_reward_trend_value": 0.05302552921993803, "biggest_recent_change": 0.7175200409115519},
{"total_number_of_episodes": 6260, "number_of_timesteps": 6260000, "per_episode_reward": -426.64, "episode_reward_trend_value": 0.05413655881151082, "biggest_recent_change": 0.7175200409115519},
{"total_number_of_episodes": 6270, "number_of_timesteps": 6270000, "per_episode_reward": -426.18, "episode_reward_trend_value": 0.05422405261677012, "biggest_recent_change": 0.7175200409115519},
{"total_number_of_episodes": 6280, "number_of_timesteps": 6280000, "per_episode_reward": -425.5, "episode_reward_trend_value": 0.05658606973067763, "biggest_recent_change": 0.7175200409115519},
{"total_number_of_episodes": 6290, "number_of_timesteps": 6290000, "per_episode_reward": -424.83, "episode_reward_trend_value": 0.056786397519233686, "biggest_recent_change": 0.7175200409115519},
{"total_number_of_episodes": 6300, "number_of_timesteps": 6300000, "per_episode_reward": -424.25, "episode_reward_trend_value": 0.055974625739968864, "biggest_recent_change": 0.7175200409115519},
{"total_number_of_episodes": 6310, "number_of_timesteps": 6310000, "per_episode_reward": -423.67, "episode_reward_trend_value": 0.05446283400283897, "biggest_recent_change": 0.7175200409115519},
{"total_number_of_episodes": 6320, "number_of_timesteps": 6320000, "per_episode_reward": -423.13, "episode_reward_trend_value": 0.052460108800914895, "biggest_recent_change": 0.67254774567391},
{"total_number_of_episodes": 6330, "number_of_timesteps": 6330000, "per_episode_reward": -422.59, "episode_reward_trend_value": 0.0543162692587575, "biggest_recent_change": 0.67254774567391},
{"total_number_of_episodes": 6340, "number_of_timesteps": 6340000, "per_episode_reward": -421.8, "episode_reward_trend_value": 0.059043527185479484, "biggest_recent_change": 0.7956735449375287},
{"total_number_of_episodes": 6350, "number_of_timesteps": 6350000, "per_episode_reward": -421.0, "episode_reward_trend_value": 0.06268611493038949, "biggest_recent_change": 0.7956735449375856},
{"total_number_of_episodes": 6360, "number_of_timesteps": 6360000, "per_episode_reward": -420.62, "episode_reward_trend_value": 0.06179252404249761, "biggest_recent_change": 0.7956735449375856},
{"total_number_of_episodes": 6370, "number_of_timesteps": 6370000, "per_episode_reward": -420.23, "episode_reward_trend_value": 0.05862440984596005, "biggest_recent_change": 0.7956735449375856},
{"total_number_of_episodes": 6380, "number_of_timesteps": 6380000, "per_episode_reward": -419.54, "episode_reward_trend_value": 0.05877825502845566, "biggest_recent_change": 0.7956735449375856},
{"total_number_of_episodes": 6390, "number_of_timesteps": 6390000, "per_episode_reward": -418.86, "episode_reward_trend_value": 0.05994419977877341, "biggest_recent_change": 0.7956735449375856},
{"total_number_of_episodes": 6400, "number_of_timesteps": 6400000, "per_episode_reward": -418.57, "episode_reward_trend_value": 0.0566927106709588, "biggest_recent_change": 0.7956735449375856},
{"total_number_of_episodes": 6410, "number_of_timesteps": 6410000, "per_episode_reward": -418.28, "episode_reward_trend_value": 0.053932155027937745, "biggest_recent_change": 0.7956735449375856},
{"total_number_of_episodes": 6420, "number_of_timesteps": 6420000, "per_episode_reward": -417.21, "episode_reward_trend_value": 0.05983707507431354, "biggest_recent_change": 1.0687175769120927},
{"total_number_of_episodes": 6430, "number_of_timesteps": 6430000, "per_episode_reward": -416.14, "episode_reward_trend_value": 0.06287089765180744, "biggest_recent_change": 1.0687175769120927},
{"total_number_of_episodes": 6440, "number_of_timesteps": 6440000, "per_episode_reward": -415.81, "episode_reward_trend_value": 0.0577369577216416, "biggest_recent_change": 1.0687175769120927},
{"total_number_of_episodes": 6450, "number_of_timesteps": 6450000, "per_episode_reward": -415.47, "episode_reward_trend_value": 0.05713919642427767, "biggest_recent_change": 1.0687175769120927},
{"total_number_of_episodes": 6460, "number_of_timesteps": 6460000, "per_episode_reward": -415.2, "episode_reward_trend_value": 0.05588889177621152, "biggest_recent_change": 1.0687175769120927},
{"total_number_of_episodes": 6470, "number_of_timesteps": 6470000, "per_episode_reward": -414.92, "episode_reward_trend_value": 0.051316627749111554, "biggest_recent_change": 1.0687175769120927},
{"total_number_of_episodes": 6480, "number_of_timesteps": 6480000, "per_episode_reward": -414.69, "episode_reward_trend_value": 0.0462794241169604, "biggest_recent_change": 1.0687175769120927},
{"total_number_of_episodes": 6490, "number_of_timesteps": 6490000, "per_episode_reward": -414.46, "episode_reward_trend_value": 0.04565965434294539, "biggest_recent_change": 1.0687175769120927},
{"total_number_of_episodes": 6500, "number_of_timesteps": 6500000, "per_episode_reward": -413.98, "episode_reward_trend_value": 0.04774106049225869, "biggest_recent_change": 1.0687175769120927},
{"total_number_of_episodes": 6510, "number_of_timesteps": 6510000, "per_episode_reward": -413.5, "episode_reward_trend_value": 0.041156990952176405, "biggest_recent_change": 1.068717576911979},
{"total_number_of_episodes": 6520, "number_of_timesteps": 6520000, "per_episode_reward": -412.91, "episode_reward_trend_value": 0.03589490241513052, "biggest_recent_change": 0.5951296085778495},
{"total_number_of_episodes": 6530, "number_of_timesteps": 6530000, "per_episode_reward": -412.31, "episode_reward_trend_value": 0.038800576385743725, "biggest_recent_change": 0.5951296085778495},
{"total_number_of_episodes": 6540, "number_of_timesteps": 6540000, "per_episode_reward": -411.12, "episode_reward_trend_value": 0.04834541025508467, "biggest_recent_change": 1.1926539994634027},
{"total_number_of_episodes": 6550, "number_of_timesteps": 6550000, "per_episode_reward": -409.93, "episode_reward_trend_value": 0.058542787475127825, "biggest_recent_change": 1.1926539994634595},
{"total_number_of_episodes": 6560, "number_of_timesteps": 6560000, "per_episode_reward": -408.82, "episode_reward_trend_value": 0.06783327565323008, "biggest_recent_change": 1.1926539994634595},
{"total_number_of_episodes": 6570, "number_of_timesteps": 6570000, "per_episode_reward": -407.71, "episode_reward_trend_value": 0.07758870343638415, "biggest_recent_change": 1.1926539994634595},
{"total_number_of_episodes": 6580, "number_of_timesteps": 6580000, "per_episode_reward": -406.19, "episode_reward_trend_value": 0.09187177611271914, "biggest_recent_change": 1.5185220260752885},
{"total_number_of_episodes": 6590, "number_of_timesteps": 6590000, "per_episode_reward": -404.67, "episode_reward_trend_value": 0.10345367286572582, "biggest_recent_change": 1.5185220260752885},
{"total_number_of_episodes": 6600, "number_of_timesteps": 6600000, "per_episode_reward": -403.82, "episode_reward_trend_value": 0.10762790157922193, "biggest_recent_change": 1.5185220260752885},
{"total_number_of_episodes": 6610, "number_of_timesteps": 6610000, "per_episode_reward": -402.97, "episode_reward_trend_value": 0.11048014928968353, "biggest_recent_change": 1.5185220260752885},
{"total_number_of_episodes": 6620, "number_of_timesteps": 6620000, "per_episode_reward": -402.38, "episode_reward_trend_value": 0.11042139386945311, "biggest_recent_change": 1.5185220260752885},
{"total_number_of_episodes": 6630, "number_of_timesteps": 6630000, "per_episode_reward": -401.79, "episode_reward_trend_value": 0.1037234785504956, "biggest_recent_change": 1.5185220260752885},
{"total_number_of_episodes": 6640, "number_of_timesteps": 6640000, "per_episode_reward": -401.21, "episode_reward_trend_value": 0.09683559165394198, "biggest_recent_change": 1.5185220260752885},
{"total_number_of_episodes": 6650, "number_of_timesteps": 6650000, "per_episode_reward": -400.64, "episode_reward_trend_value": 0.09085459379932988, "biggest_recent_change": 1.5185220260752885},
{"total_number_of_episodes": 6660, "number_of_timesteps": 6660000, "per_episode_reward": -399.8, "episode_reward_trend_value": 0.0878982344992576, "biggest_recent_change": 1.5185220260752885},
{"total_number_of_episodes": 6670, "number_of_timesteps": 6670000, "per_episode_reward": -398.95, "episode_reward_trend_value": 0.08041423030600249, "biggest_recent_change": 1.5185220260752885},
{"total_number_of_episodes": 6680, "number_of_timesteps": 6680000, "per_episode_reward": -398.12, "episode_reward_trend_value": 0.07279789769953722, "biggest_recent_change": 0.8518319025193932},
{"total_number_of_episodes": 6690, "number_of_timesteps": 6690000, "per_episode_reward": -397.29, "episode_reward_trend_value": 0.07258923313258442, "biggest_recent_change": 0.8518319025193932},
{"total_number_of_episodes": 6700, "number_of_timesteps": 6700000, "per_episode_reward": -396.65, "episode_reward_trend_value": 0.07012840532876857, "biggest_recent_change": 0.8449616486823288},
{"total_number_of_episodes": 6710, "number_of_timesteps": 6710000, "per_episode_reward": -396.02, "episode_reward_trend_value": 0.07057858065564536, "biggest_recent_change": 0.8449616486823288},
{"total_number_of_episodes": 6720, "number_of_timesteps": 6720000, "per_episode_reward": -394.82, "episode_reward_trend_value": 0.07746218354742306, "biggest_recent_change": 1.20936588101722},
{"total_number_of_episodes": 6730, "number_of_timesteps": 6730000, "per_episode_reward": -393.61, "episode_reward_trend_value": 0.08453575801679752, "biggest_recent_change": 1.2093658810173338},
{"total_number_of_episodes": 6740, "number_of_timesteps": 6740000, "per_episode_reward": -392.42, "episode_reward_trend_value": 0.09135721885832342, "biggest_recent_change": 1.2093658810173338},
{"total_number_of_episodes": 6750, "number_of_timesteps": 6750000, "per_episode_reward": -391.23, "episode_reward_trend_value": 0.09515404114530826, "biggest_recent_change": 1.2093658810173338},
{"total_number_of_episodes": 6760, "number_of_timesteps": 6760000, "per_episode_reward": -390.53, "episode_reward_trend_value": 0.0935451239268913, "biggest_recent_change": 1.2093658810173338},
{"total_number_of_episodes": 6770, "number_of_timesteps": 6770000, "per_episode_reward": -389.83, "episode_reward_trend_value": 0.09206853512168386, "biggest_recent_change": 1.2093658810173338},
{"total_number_of_episodes": 6780, "number_of_timesteps": 6780000, "per_episode_reward": -389.19, "episode_reward_trend_value": 0.08997269031809702, "biggest_recent_change": 1.2093658810173338},
{"total_number_of_episodes": 6790, "number_of_timesteps": 6790000, "per_episode_reward": -388.54, "episode_reward_trend_value": 0.09012900875137322, "biggest_recent_change": 1.2093658810173338},
{"total_number_of_episodes": 6800, "number_of_timesteps": 6800000, "per_episode_reward": -387.47, "episode_reward_trend_value": 0.09508392703070917, "biggest_recent_change": 1.2093658810173338},
{"total_number_of_episodes": 6810, "number_of_timesteps": 6810000, "per_episode_reward": -386.39, "episode_reward_trend_value": 0.09360541774514357, "biggest_recent_change": 1.2093658810173338},
{"total_number_of_episodes": 6820, "number_of_timesteps": 6820000, "per_episode_reward": -385.3, "episode_reward_trend_value": 0.09228241936450873, "biggest_recent_change": 1.1866756545109638},
{"total_number_of_episodes": 6830, "number_of_timesteps": 6830000, "per_episode_reward": -384.21, "episode_reward_trend_value": 0.09121153461172311, "biggest_recent_change": 1.186675654510907},
{"total_number_of_episodes": 6840, "number_of_timesteps": 6840000, "per_episode_reward": -383.59, "episode_reward_trend_value": 0.0849150972538641, "biggest_recent_change": 1.0902960267602566},
{"total_number_of_episodes": 6850, "number_of_timesteps": 6850000, "per_episode_reward": -382.97, "episode_reward_trend_value": 0.08402439940140691, "biggest_recent_change": 1.0902960267602566},
{"total_number_of_episodes": 6860, "number_of_timesteps": 6860000, "per_episode_reward": -382.02, "episode_reward_trend_value": 0.08674697455441308, "biggest_recent_change": 1.0902960267602566},
{"total_number_of_episodes": 6870, "number_of_timesteps": 6870000, "per_episode_reward": -381.08, "episode_reward_trend_value": 0.09008880570579739, "biggest_recent_change": 1.0902960267602566},
{"total_number_of_episodes": 6880, "number_of_timesteps": 6880000, "per_episode_reward": -380.29, "episode_reward_trend_value": 0.09170394263252193, "biggest_recent_change": 1.0902960267602566},
{"total_number_of_episodes": 6890, "number_of_timesteps": 6890000, "per_episode_reward": -379.5, "episode_reward_trend_value": 0.0885204797131842, "biggest_recent_change": 1.0902960267602566},
{"total_number_of_episodes": 6900, "number_of_timesteps": 6900000, "per_episode_reward": -378.29, "episode_reward_trend_value": 0.09006069087112109, "biggest_recent_change": 1.2149190495306357},
{"total_number_of_episodes": 6910, "number_of_timesteps": 6910000, "per_episode_reward": -377.07, "episode_reward_trend_value": 0.09144539112412467, "biggest_recent_change": 1.2149190495306357},
{"total_number_of_episodes": 6920, "number_of_timesteps": 6920000, "per_episode_reward": -375.86, "episode_reward_trend_value": 0.09279021987026871, "biggest_recent_change": 1.2149190495306357},
{"total_number_of_episodes": 6930, "number_of_timesteps": 6930000, "per_episode_reward": -374.65, "episode_reward_trend_value": 0.09936060122148546, "biggest_recent_change": 1.2149190495306357},
{"total_number_of_episodes": 6940, "number_of_timesteps": 6940000, "per_episode_reward": -373.44, "episode_reward_trend_value": 0.10585672026156265, "biggest_recent_change": 1.2149190495306357},
{"total_number_of_episodes": 6950, "number_of_timesteps": 6950000, "per_episode_reward": -372.24, "episode_reward_trend_value": 0.1087395662961765, "biggest_recent_change": 1.2149190495306357},
{"total_number_of_episodes": 6960, "number_of_timesteps": 6960000, "per_episode_reward": -371.54, "episode_reward_trend_value": 0.1060202722573403, "biggest_recent_change": 1.2149190495306357},
{"total_number_of_episodes": 6970, "number_of_timesteps": 6970000, "per_episode_reward": -370.84, "episode_reward_trend_value": 0.10502767244316513, "biggest_recent_change": 1.2149190495306357},
{"total_number_of_episodes": 6980, "number_of_timesteps": 6980000, "per_episode_reward": -369.93, "episode_reward_trend_value": 0.10633500445804189, "biggest_recent_change": 1.2149190495306357},
{"total_number_of_episodes": 6990, "number_of_timesteps": 6990000, "per_episode_reward": -369.02, "episode_reward_trend_value": 0.1029186623956428, "biggest_recent_change": 1.214919049530522},
{"total_number_of_episodes": 7000, "number_of_timesteps": 7000000, "per_episode_reward": -368.35, "episode_reward_trend_value": 0.09692206981802151, "biggest_recent_change": 1.2113306139132192},
{"total_number_of_episodes": 7010, "number_of_timesteps": 7010000, "per_episode_reward": -367.67, "episode_reward_trend_value": 0.09096534874725788, "biggest_recent_change": 1.2113306139131055},
{"total_number_of_episodes": 7020, "number_of_timesteps": 7020000, "per_episode_reward": -367.24, "episode_reward_trend_value": 0.08233994521469046, "biggest_recent_change": 1.2046470059106014},
{"total_number_of_episodes": 7030, "number_of_timesteps": 7030000, "per_episode_reward": -366.8, "episode_reward_trend_value": 0.07378880399326262, "biggest_recent_change": 1.2046470059105445},
{"total_number_of_episodes": 7040, "number_of_timesteps": 7040000, "per_episode_reward": -366.53, "episode_reward_trend_value": 0.06337048005107009, "biggest_recent_change": 0.9074482639147732},
{"total_number_of_episodes": 7050, "number_of_timesteps": 7050000, "per_episode_reward": -366.27, "episode_reward_trend_value": 0.058554296182328214, "biggest_recent_change": 0.9074482639147732},
{"total_number_of_episodes": 7060, "number_of_timesteps": 7060000, "per_episode_reward": -365.63, "episode_reward_trend_value": 0.057810516705405414, "biggest_recent_change": 0.9074482639147732},
{"total_number_of_episodes": 7070, "number_of_timesteps": 7070000, "per_episode_reward": -365.0, "episode_reward_trend_value": 0.0547668053994332, "biggest_recent_change": 0.9074482639147163},
{"total_number_of_episodes": 7080, "number_of_timesteps": 7080000, "per_episode_reward": -364.59, "episode_reward_trend_value": 0.04921657658647531, "biggest_recent_change": 0.6752257175446061},
{"total_number_of_episodes": 7090, "number_of_timesteps": 7090000, "per_episode_reward": -364.19, "episode_reward_trend_value": 0.046246598288742134, "biggest_recent_change": 0.6752257175444925},
{"total_number_of_episodes": 7100, "number_of_timesteps": 7100000, "per_episode_reward": -363.26, "episode_reward_trend_value": 0.04898000411135336, "biggest_recent_change": 0.9212322415795029},
{"total_number_of_episodes": 7110, "number_of_timesteps": 7110000, "per_episode_reward": -362.34, "episode_reward_trend_value": 0.054382092395769, "biggest_recent_change": 0.9212322415795029},
{"total_number_of_episodes": 7120, "number_of_timesteps": 7120000, "per_episode_reward": -361.73, "episode_reward_trend_value": 0.056382770599701516, "biggest_recent_change": 0.9212322415795029},
{"total_number_of_episodes": 7130, "number_of_timesteps": 7130000, "per_episode_reward": -361.11, "episode_reward_trend_value": 0.06025063152439998, "biggest_recent_change": 0.9212322415795029},
{"total_number_of_episodes": 7140, "number_of_timesteps": 7140000, "per_episode_reward": -360.25, "episode_reward_trend_value": 0.0668529794241983, "biggest_recent_change": 0.9212322415795029},
{"total_number_of_episodes": 7150, "number_of_timesteps": 7150000, "per_episode_reward": -359.39, "episode_reward_trend_value": 0.06938292293217564, "biggest_recent_change": 0.9212322415795029},
{"total_number_of_episodes": 7160, "number_of_timesteps": 7160000, "per_episode_reward": -357.71, "episode_reward_trend_value": 0.08100726750322261, "biggest_recent_change": 1.6797052577715021},
{"total_number_of_episodes": 7170, "number_of_timesteps": 7170000, "per_episode_reward": -357.38, "episode_reward_trend_value": 0.08019149683649844, "biggest_recent_change": 1.6797052577715021},
{"total_number_of_episodes": 7180, "number_of_timesteps": 7180000, "per_episode_reward": -356.96, "episode_reward_trend_value": 0.08032717227460656, "biggest_recent_change": 1.6797052577715021},
{"total_number_of_episodes": 7190, "number_of_timesteps": 7190000, "per_episode_reward": -356.54, "episode_reward_trend_value": 0.07475946359237154, "biggest_recent_change": 1.6797052577715021},
{"total_number_of_episodes": 7200, "number_of_timesteps": 7200000, "per_episode_reward": -355.26, "episode_reward_trend_value": 0.07870289480072061, "biggest_recent_change": 1.6797052577715021},
{"total_number_of_episodes": 7210, "number_of_timesteps": 7210000, "per_episode_reward": -353.98, "episode_reward_trend_value": 0.08604773608955282, "biggest_recent_change": 1.6797052577715021},
{"total_number_of_episodes": 7220, "number_of_timesteps": 7220000, "per_episode_reward": -353.49, "episode_reward_trend_value": 0.08468893808228017, "biggest_recent_change": 1.6797052577715021},
{"total_number_of_episodes": 7230, "number_of_timesteps": 7230000, "per_episode_reward": -353.0, "episode_reward_trend_value": 0.08059565309990577, "biggest_recent_change": 1.6797052577715021},
{"total_number_of_episodes": 7240, "number_of_timesteps": 7240000, "per_episode_reward": -351.58, "episode_reward_trend_value": 0.08675944085534044, "biggest_recent_change": 1.6797052577715021},
{"total_number_of_episodes": 7250, "number_of_timesteps": 7250000, "per_episode_reward": -350.17, "episode_reward_trend_value": 0.08382882754770613, "biggest_recent_change": 1.4159500600844126},
{"total_number_of_episodes": 7260, "number_of_timesteps": 7260000, "per_episode_reward": -349.5, "episode_reward_trend_value": 0.08746401190492116, "biggest_recent_change": 1.4159500600844126},
{"total_number_of_episodes": 7270, "number_of_timesteps": 7270000, "per_episode_reward": -348.84, "episode_reward_trend_value": 0.09014775015730139, "biggest_recent_change": 1.4159500600844126},
{"total_number_of_episodes": 7280, "number_of_timesteps": 7280000, "per_episode_reward": -348.19, "episode_reward_trend_value": 0.09276357370740634, "biggest_recent_change": 1.4159500600844126},
{"total_number_of_episodes": 7290, "number_of_timesteps": 7290000, "per_episode_reward": -347.53, "episode_reward_trend_value": 0.08586825736692719, "biggest_recent_change": 1.4159500600844126},
{"total_number_of_episodes": 7300, "number_of_timesteps": 7300000, "per_episode_reward": -346.4, "episode_reward_trend_value": 0.0842626159615621, "biggest_recent_change": 1.4159500600844126},
{"total_number_of_episodes": 7310, "number_of_timesteps": 7310000, "per_episode_reward": -345.27, "episode_reward_trend_value": 0.09136061385229936, "biggest_recent_change": 1.4159500600844126},
{"total_number_of_episodes": 7320, "number_of_timesteps": 7320000, "per_episode_reward": -344.42, "episode_reward_trend_value": 0.0952872980652627, "biggest_recent_change": 1.4159500600844126},
{"total_number_of_episodes": 7330, "number_of_timesteps": 7330000, "per_episode_reward": -343.58, "episode_reward_trend_value": 0.08895690954041571, "biggest_recent_change": 1.4159500600844126},
{"total_number_of_episodes": 7340, "number_of_timesteps": 7340000, "per_episode_reward": -342.75, "episode_reward_trend_value": 0.08237503888792932, "biggest_recent_change": 1.1316333238480638},
{"total_number_of_episodes": 7350, "number_of_timesteps": 7350000, "per_episode_reward": -341.93, "episode_reward_trend_value": 0.08417400331534913, "biggest_recent_change": 1.1316333238480638},
{"total_number_of_episodes": 7360, "number_of_timesteps": 7360000, "per_episode_reward": -341.31, "episode_reward_trend_value": 0.08371121394535963, "biggest_recent_change": 1.1316333238480638},
{"total_number_of_episodes": 7370, "number_of_timesteps": 7370000, "per_episode_reward": -340.69, "episode_reward_trend_value": 0.08331633927764667, "biggest_recent_change": 1.1316333238480638},
{"total_number_of_episodes": 7380, "number_of_timesteps": 7380000, "per_episode_reward": -340.0, "episode_reward_trend_value": 0.08371620219666245, "biggest_recent_change": 1.1316333238480638},
{"total_number_of_episodes": 7390, "number_of_timesteps": 7390000, "per_episode_reward": -339.31, "episode_reward_trend_value": 0.07882639018056416, "biggest_recent_change": 1.1316333238478933},
{"total_number_of_episodes": 7400, "number_of_timesteps": 7400000, "per_episode_reward": -338.63, "episode_reward_trend_value": 0.07374634270289498, "biggest_recent_change": 0.8462150928481833},
{"total_number_of_episodes": 7410, "number_of_timesteps": 7410000, "per_episode_reward": -337.96, "episode_reward_trend_value": 0.071837608903001, "biggest_recent_change": 0.8462150928480696},
{"total_number_of_episodes": 7420, "number_of_timesteps": 7420000, "per_episode_reward": -337.19, "episode_reward_trend_value": 0.07093257368442842, "biggest_recent_change": 0.8235817013606379},
{"total_number_of_episodes": 7430, "number_of_timesteps": 7430000, "per_episode_reward": -336.43, "episode_reward_trend_value": 0.07027902059349331, "biggest_recent_change": 0.8235817013604674},
{"total_number_of_episodes": 7440, "number_of_timesteps": 7440000, "per_episode_reward": -335.81, "episode_reward_trend_value": 0.06799554510655462, "biggest_recent_change": 0.7647619231765361},
{"total_number_of_episodes": 7450, "number_of_timesteps": 7450000, "per_episode_reward": -335.19, "episode_reward_trend_value": 0.06797382341702714, "biggest_recent_change": 0.7647619231765361},
{"total_number_of_episodes": 7460, "number_of_timesteps": 7460000, "per_episode_reward": -334.57, "episode_reward_trend_value": 0.0679636131071801, "biggest_recent_change": 0.7647619231765361},
{"total_number_of_episodes": 7470, "number_of_timesteps": 7470000, "per_episode_reward": -333.95, "episode_reward_trend_value": 0.06715866521060497, "biggest_recent_change": 0.7647619231765361},
{"total_number_of_episodes": 7480, "number_of_timesteps": 7480000, "per_episode_reward": -333.32, "episode_reward_trend_value": 0.06655320350245372, "biggest_recent_change": 0.7647619231765361},
{"total_number_of_episodes": 7490, "number_of_timesteps": 7490000, "per_episode_reward": -332.68, "episode_reward_trend_value": 0.0661379772558765, "biggest_recent_change": 0.7647619231765361},
{"total_number_of_episodes": 7500, "number_of_timesteps": 7500000, "per_episode_reward": -332.03, "episode_reward_trend_value": 0.06579211421300593, "biggest_recent_change": 0.7647619231765361},
{"total_number_of_episodes": 7510, "number_of_timesteps": 7510000, "per_episode_reward": -331.39, "episode_reward_trend_value": 0.06444255258881526, "biggest_recent_change": 0.7647619231764793},
{"total_number_of_episodes": 7520, "number_of_timesteps": 7520000, "per_episode_reward": -330.75, "episode_reward_trend_value": 0.06304904017085404, "biggest_recent_change": 0.643301376999375},
{"total_number_of_episodes": 7530, "number_of_timesteps": 7530000, "per_episode_reward": -330.11, "episode_reward_trend_value": 0.06328545014889705, "biggest_recent_change": 0.643301376999375},
{"total_number_of_episodes": 7540, "number_of_timesteps": 7540000, "per_episode_reward": -329.31, "episode_reward_trend_value": 0.06529013445955785, "biggest_recent_change": 0.7984904954955141},
{"total_number_of_episodes": 7550, "number_of_timesteps": 7550000, "per_episode_reward": -328.52, "episode_reward_trend_value": 0.0672833073905363, "biggest_recent_change": 0.7984904954955141},
{"total_number_of_episodes": 7560, "number_of_timesteps": 7560000, "per_episode_reward": -327.82, "episode_reward_trend_value": 0.06815230945236471, "biggest_recent_change": 0.7984904954955141},
{"total_number_of_episodes": 7570, "number_of_timesteps": 7570000, "per_episode_reward": -327.12, "episode_reward_trend_value": 0.06882182532576861, "biggest_recent_change": 0.7984904954955141},
{"total_number_of_episodes": 7580, "number_of_timesteps": 7580000, "per_episode_reward": -326.55, "episode_reward_trend_value": 0.06810912775134297, "biggest_recent_change": 0.7984904954955141},
{"total_number_of_episodes": 7590, "number_of_timesteps": 7590000, "per_episode_reward": -325.98, "episode_reward_trend_value": 0.06732706697320938, "biggest_recent_change": 0.7984904954955141},
{"total_number_of_episodes": 7600, "number_of_timesteps": 7600000, "per_episode_reward": -325.53, "episode_reward_trend_value": 0.06507950778062713, "biggest_recent_change": 0.7984904954955141},
{"total_number_of_episodes": 7610, "number_of_timesteps": 7610000, "per_episode_reward": -325.09, "episode_reward_trend_value": 0.06287589938181605, "biggest_recent_change": 0.7984904954955141},
{"total_number_of_episodes": 7620, "number_of_timesteps": 7620000, "per_episode_reward": -324.11, "episode_reward_trend_value": 0.0667179725746261, "biggest_recent_change": 0.9851323929127602},
{"total_number_of_episodes": 7630, "number_of_timesteps": 7630000, "per_episode_reward": -323.12, "episode_reward_trend_value": 0.06879177143481835, "biggest_recent_change": 0.9851323929128171},
{"total_number_of_episodes": 7640, "number_of_timesteps": 7640000, "per_episode_reward": -322.71, "episode_reward_trend_value": 0.06452812260467086, "biggest_recent_change": 0.9851323929128171},
{"total_number_of_episodes": 7650, "number_of_timesteps": 7650000, "per_episode_reward": -322.29, "episode_reward_trend_value": 0.06138864464367404, "biggest_recent_change": 0.9851323929128171},
{"total_number_of_episodes": 7660, "number_of_timesteps": 7660000, "per_episode_reward": -321.47, "episode_reward_trend_value": 0.06273781739425191, "biggest_recent_change": 0.9851323929128171},
{"total_number_of_episodes": 7670, "number_of_timesteps": 7670000, "per_episode_reward": -320.66, "episode_reward_trend_value": 0.06546920359265869, "biggest_recent_change": 0.9851323929128171},
{"total_number_of_episodes": 7680, "number_of_timesteps": 7680000, "per_episode_reward": -319.98, "episode_reward_trend_value": 0.06663246792488925, "biggest_recent_change": 0.9851323929128171},
{"total_number_of_episodes": 7690, "number_of_timesteps": 7690000, "per_episode_reward": -319.3, "episode_reward_trend_value": 0.06926123067156911, "biggest_recent_change": 0.9851323929128171},
{"total_number_of_episodes": 7700, "number_of_timesteps": 7700000, "per_episode_reward": -318.84, "episode_reward_trend_value": 0.06949051365261186, "biggest_recent_change": 0.9851323929128171},
{"total_number_of_episodes": 7710, "number_of_timesteps": 7710000, "per_episode_reward": -317.58, "episode_reward_trend_value": 0.0725695972281566, "biggest_recent_change": 1.2622499147117878},
{"total_number_of_episodes": 7720, "number_of_timesteps": 7720000, "per_episode_reward": -316.98, "episode_reward_trend_value": 0.06828180247712415, "biggest_recent_change": 1.2622499147117878},
{"total_number_of_episodes": 7730, "number_of_timesteps": 7730000, "per_episode_reward": -316.38, "episode_reward_trend_value": 0.07033145541643207, "biggest_recent_change": 1.2622499147117878},
{"total_number_of_episodes": 7740, "number_of_timesteps": 7740000, "per_episode_reward": -316.0, "episode_reward_trend_value": 0.06991510396141318, "biggest_recent_change": 1.2622499147117878},
{"total_number_of_episodes": 7750, "number_of_timesteps": 7750000, "per_episode_reward": -315.62, "episode_reward_trend_value": 0.06501010179481834, "biggest_recent_change": 1.2622499147117878},
{"total_number_of_episodes": 7760, "number_of_timesteps": 7760000, "per_episode_reward": -315.03, "episode_reward_trend_value": 0.06253366373597752, "biggest_recent_change": 1.2622499147117878},
{"total_number_of_episodes": 7770, "number_of_timesteps": 7770000, "per_episode_reward": -314.43, "episode_reward_trend_value": 0.06162534754331356, "biggest_recent_change": 1.2622499147117878},
{"total_number_of_episodes": 7780, "number_of_timesteps": 7780000, "per_episode_reward": -314.08, "episode_reward_trend_value": 0.05804033039410998, "biggest_recent_change": 1.2622499147117878},
{"total_number_of_episodes": 7790, "number_of_timesteps": 7790000, "per_episode_reward": -313.72, "episode_reward_trend_value": 0.05685479301054417, "biggest_recent_change": 1.2622499147117878},
{"total_number_of_episodes": 7800, "number_of_timesteps": 7800000, "per_episode_reward": -312.53, "episode_reward_trend_value": 0.05613250096739143, "biggest_recent_change": 1.1972436308280408},
{"total_number_of_episodes": 7810, "number_of_timesteps": 7810000, "per_episode_reward": -311.33, "episode_reward_trend_value": 0.06277708725081525, "biggest_recent_change": 1.1972436308280408},
{"total_number_of_episodes": 7820, "number_of_timesteps": 7820000, "per_episode_reward": -310.8, "episode_reward_trend_value": 0.06200698200712951, "biggest_recent_change": 1.1972436308280408},
{"total_number_of_episodes": 7830, "number_of_timesteps": 7830000, "per_episode_reward": -310.27, "episode_reward_trend_value": 0.0637028811577712, "biggest_recent_change": 1.1972436308280408},
{"total_number_of_episodes": 7840, "number_of_timesteps": 7840000, "per_episode_reward": -310.06, "episode_reward_trend_value": 0.06187605690496665, "biggest_recent_change": 1.1972436308280408},
{"total_number_of_episodes": 7850, "number_of_timesteps": 7850000, "per_episode_reward": -309.84, "episode_reward_trend_value": 0.057620668544407436, "biggest_recent_change": 1.1972436308280408},
{"total_number_of_episodes": 7860, "number_of_timesteps": 7860000, "per_episode_reward": -309.29, "episode_reward_trend_value": 0.05716342783289039, "biggest_recent_change": 1.1972436308280408},
{"total_number_of_episodes": 7870, "number_of_timesteps": 7870000, "per_episode_reward": -308.73, "episode_reward_trend_value": 0.05938288807791233, "biggest_recent_change": 1.1972436308280408},
{"total_number_of_episodes": 7880, "number_of_timesteps": 7880000, "per_episode_reward": -308.25, "episode_reward_trend_value": 0.060816324851146596, "biggest_recent_change": 1.1972436308280408},
{"total_number_of_episodes": 7890, "number_of_timesteps": 7890000, "per_episode_reward": -307.77, "episode_reward_trend_value": 0.0528910340978459, "biggest_recent_change": 1.1972436308280408},
{"total_number_of_episodes": 7900, "number_of_timesteps": 7900000, "per_episode_reward": -307.24, "episode_reward_trend_value": 0.04538243535781703, "biggest_recent_change": 0.5547095754918132},
{"total_number_of_episodes": 7910, "number_of_timesteps": 7910000, "per_episode_reward": -306.72, "episode_reward_trend_value": 0.0452885281448971, "biggest_recent_change": 0.5547095754918132},
{"total_number_of_episodes": 7920, "number_of_timesteps": 7920000, "per_episode_reward": -305.96, "episode_reward_trend_value": 0.04788108115905566, "biggest_recent_change": 0.763251164662563},
{"total_number_of_episodes": 7930, "number_of_timesteps": 7930000, "per_episode_reward": -305.2, "episode_reward_trend_value": 0.05399635757666109, "biggest_recent_change": 0.763251164662563},
{"total_number_of_episodes": 7940, "number_of_timesteps": 7940000, "per_episode_reward": -304.74, "episode_reward_trend_value": 0.056686804269959465, "biggest_recent_change": 0.763251164662563},
{"total_number_of_episodes": 7950, "number_of_timesteps": 7950000, "per_episode_reward": -304.29, "episode_reward_trend_value": 0.05557910331421567, "biggest_recent_change": 0.763251164662563},
{"total_number_of_episodes": 7960, "number_of_timesteps": 7960000, "per_episode_reward": -303.78, "episode_reward_trend_value": 0.055045367398346604, "biggest_recent_change": 0.763251164662563},
{"total_number_of_episodes": 7970, "number_of_timesteps": 7970000, "per_episode_reward": -303.27, "episode_reward_trend_value": 0.05529765495426394, "biggest_recent_change": 0.763251164662563},
{"total_number_of_episodes": 7980, "number_of_timesteps": 7980000, "per_episode_reward": -302.29, "episode_reward_trend_value": 0.06088632481014744, "biggest_recent_change": 0.9869477500604944},
{"total_number_of_episodes": 7990, "number_of_timesteps": 7990000, "per_episode_reward": -301.3, "episode_reward_trend_value": 0.06605830265275914, "biggest_recent_change": 0.9869477500604944},
{"total_number_of_episodes": 8000, "number_of_timesteps": 8000000, "per_episode_reward": -300.77, "episode_reward_trend_value": 0.0661320637815335, "biggest_recent_change": 0.9869477500604944},
{"total_number_of_episodes": 8010, "number_of_timesteps": 8010000, "per_episode_reward": -300.24, "episode_reward_trend_value": 0.0635193646832287, "biggest_recent_change": 0.9869477500604944},
{"total_number_of_episodes": 8020, "number_of_timesteps": 8020000, "per_episode_reward": -299.89, "episode_reward_trend_value": 0.05891308307605401, "biggest_recent_change": 0.9869477500604944},
{"total_number_of_episodes": 8030, "number_of_timesteps": 8030000, "per_episode_reward": -299.54, "episode_reward_trend_value": 0.057731631193186986, "biggest_recent_change": 0.9869477500604944},
{"total_number_of_episodes": 8040, "number_of_timesteps": 8040000, "per_episode_reward": -299.34, "episode_reward_trend_value": 0.05492320655078957, "biggest_recent_change": 0.9869477500604944},
{"total_number_of_episodes": 8050, "number_of_timesteps": 8050000, "per_episode_reward": -299.14, "episode_reward_trend_value": 0.05154081686851682, "biggest_recent_change": 0.9869477500604944},
{"total_number_of_episodes": 8060, "number_of_timesteps": 8060000, "per_episode_reward": -298.78, "episode_reward_trend_value": 0.0498686682426315, "biggest_recent_change": 0.9869477500604944},
{"total_number_of_episodes": 8070, "number_of_timesteps": 8070000, "per_episode_reward": -298.43, "episode_reward_trend_value": 0.04286013731678003, "biggest_recent_change": 0.9869477500604944},
{"total_number_of_episodes": 8080, "number_of_timesteps": 8080000, "per_episode_reward": -298.07, "episode_reward_trend_value": 0.03588650061102562, "biggest_recent_change": 0.5281082458151332},
{"total_number_of_episodes": 8090, "number_of_timesteps": 8090000, "per_episode_reward": -297.71, "episode_reward_trend_value": 0.03401108061910855, "biggest_recent_change": 0.5281082458151332},
{"total_number_of_episodes": 8100, "number_of_timesteps": 8100000, "per_episode_reward": -296.97, "episode_reward_trend_value": 0.03630390616195819, "biggest_recent_change": 0.7344625446716009},
{"total_number_of_episodes": 8110, "number_of_timesteps": 8110000, "per_episode_reward": -296.24, "episode_reward_trend_value": 0.04059031421367838, "biggest_recent_change": 0.7344625446716009},
{"total_number_of_episodes": 8120, "number_of_timesteps": 8120000, "per_episode_reward": -295.67, "episode_reward_trend_value": 0.04302553125205577, "biggest_recent_change": 0.7344625446716009},
{"total_number_of_episodes": 8130, "number_of_timesteps": 8130000, "per_episode_reward": -295.1, "episode_reward_trend_value": 0.04708772104996418, "biggest_recent_change": 0.7344625446716009},
{"total_number_of_episodes": 8140, "number_of_timesteps": 8140000, "per_episode_reward": -294.58, "episode_reward_trend_value": 0.05065003885758175, "biggest_recent_change": 0.7344625446716009},
{"total_number_of_episodes": 8150, "number_of_timesteps": 8150000, "per_episode_reward": -294.06, "episode_reward_trend_value": 0.05250211560881439, "biggest_recent_change": 0.7344625446716009},
{"total_number_of_episodes": 8160, "number_of_timesteps": 8160000, "per_episode_reward": -293.61, "episode_reward_trend_value": 0.05354051063504307, "biggest_recent_change": 0.7344625446716009},
{"total_number_of_episodes": 8170, "number_of_timesteps": 8170000, "per_episode_reward": -293.16, "episode_reward_trend_value": 0.05454401144117469, "biggest_recent_change": 0.7344625446716009},
{"total_number_of_episodes": 8180, "number_of_timesteps": 8180000, "per_episode_reward": -292.57, "episode_reward_trend_value": 0.057115045677367485, "biggest_recent_change": 0.7344625446716009},
{"total_number_of_episodes": 8190, "number_of_timesteps": 8190000, "per_episode_reward": -291.98, "episode_reward_trend_value": 0.055517834378792943, "biggest_recent_change": 0.7344625446716009},
{"total_number_of_episodes": 8200, "number_of_timesteps": 8200000, "per_episode_reward": -291.63, "episode_reward_trend_value": 0.05127998805038172, "biggest_recent_change": 0.5907135277998918},
{"total_number_of_episodes": 8210, "number_of_timesteps": 8210000, "per_episode_reward": -291.27, "episode_reward_trend_value": 0.04889333273531204, "biggest_recent_change": 0.5907135277998918},
{"total_number_of_episodes": 8220, "number_of_timesteps": 8220000, "per_episode_reward": -290.6, "episode_reward_trend_value": 0.05001206152845535, "biggest_recent_change": 0.6685409448537598},
{"total_number_of_episodes": 8230, "number_of_timesteps": 8230000, "per_episode_reward": -289.93, "episode_reward_trend_value": 0.05163066231188951, "biggest_recent_change": 0.6685409448537598},
{"total_number_of_episodes": 8240, "number_of_timesteps": 8240000, "per_episode_reward": -289.09, "episode_reward_trend_value": 0.055253291619122055, "biggest_recent_change": 0.8489035119957293},
{"total_number_of_episodes": 8250, "number_of_timesteps": 8250000, "per_episode_reward": -288.24, "episode_reward_trend_value": 0.05968960265135921, "biggest_recent_change": 0.8489035119957862},
{"total_number_of_episodes": 8260, "number_of_timesteps": 8260000, "per_episode_reward": -286.99, "episode_reward_trend_value": 0.06860502971052256, "biggest_recent_change": 1.252023954419144},
{"total_number_of_episodes": 8270, "number_of_timesteps": 8270000, "per_episode_reward": -286.61, "episode_reward_trend_value": 0.06615976278849303, "biggest_recent_change": 1.252023954419144},
{"total_number_of_episodes": 8280, "number_of_timesteps": 8280000, "per_episode_reward": -286.09, "episode_reward_trend_value": 0.06538556667728636, "biggest_recent_change": 1.252023954419144},
{"total_number_of_episodes": 8290, "number_of_timesteps": 8290000, "per_episode_reward": -285.57, "episode_reward_trend_value": 0.067252005595917, "biggest_recent_change": 1.252023954419144},
{"total_number_of_episodes": 8300, "number_of_timesteps": 8300000, "per_episode_reward": -285.09, "episode_reward_trend_value": 0.06864212348459091, "biggest_recent_change": 1.252023954419144},
{"total_number_of_episodes": 8310, "number_of_timesteps": 8310000, "per_episode_reward": -284.62, "episode_reward_trend_value": 0.06652685726505246, "biggest_recent_change": 1.252023954419144},
{"total_number_of_episodes": 8320, "number_of_timesteps": 8320000, "per_episode_reward": -284.03, "episode_reward_trend_value": 0.06562186665328543, "biggest_recent_change": 1.252023954419144},
{"total_number_of_episodes": 8330, "number_of_timesteps": 8330000, "per_episode_reward": -283.44, "episode_reward_trend_value": 0.06271284751771747, "biggest_recent_change": 1.252023954419144},
{"total_number_of_episodes": 8340, "number_of_timesteps": 8340000, "per_episode_reward": -283.23, "episode_reward_trend_value": 0.05563381372242462, "biggest_recent_change": 1.252023954419144},
{"total_number_of_episodes": 8350, "number_of_timesteps": 8350000, "per_episode_reward": -283.02, "episode_reward_trend_value": 0.044075663900204315, "biggest_recent_change": 0.5870917897946697},
{"total_number_of_episodes": 8360, "number_of_timesteps": 8360000, "per_episode_reward": -282.23, "episode_reward_trend_value": 0.04876123837959136, "biggest_recent_change": 0.7923412079620675},
{"total_number_of_episodes": 8370, "number_of_timesteps": 8370000, "per_episode_reward": -281.43, "episode_reward_trend_value": 0.05177574204815616, "biggest_recent_change": 0.7923412079621244},
{"total_number_of_episodes": 8380, "number_of_timesteps": 8380000, "per_episode_reward": -281.21, "episode_reward_trend_value": 0.04851347634988643, "biggest_recent_change": 0.7923412079621244},
{"total_number_of_episodes": 8390, "number_of_timesteps": 8390000, "per_episode_reward": -280.98, "episode_reward_trend_value": 0.04572753168157344, "biggest_recent_change": 0.7923412079621244},
{"total_number_of_episodes": 8400, "number_of_timesteps": 8400000, "per_episode_reward": -280.6, "episode_reward_trend_value": 0.044655860086368196, "biggest_recent_change": 0.7923412079621244},
{"total_number_of_episodes": 8410, "number_of_timesteps": 8410000, "per_episode_reward": -280.22, "episode_reward_trend_value": 0.042373912883393434, "biggest_recent_change": 0.7923412079621244},
{"total_number_of_episodes": 8420, "number_of_timesteps": 8420000, "per_episode_reward": -279.94, "episode_reward_trend_value": 0.038864455397497166, "biggest_recent_change": 0.7923412079621244},
{"total_number_of_episodes": 8430, "number_of_timesteps": 8430000, "per_episode_reward": -279.67, "episode_reward_trend_value": 0.039525012571326415, "biggest_recent_change": 0.7923412079621244},
{"total_number_of_episodes": 8440, "number_of_timesteps": 8440000, "per_episode_reward": -279.15, "episode_reward_trend_value": 0.04295674071486499, "biggest_recent_change": 0.7923412079621244},
{"total_number_of_episodes": 8450, "number_of_timesteps": 8450000, "per_episode_reward": -278.63, "episode_reward_trend_value": 0.03993790510792792, "biggest_recent_change": 0.7923412079621244},
{"total_number_of_episodes": 8460, "number_of_timesteps": 8460000, "per_episode_reward": -278.2, "episode_reward_trend_value": 0.035886149279420146, "biggest_recent_change": 0.520646003337788},
{"total_number_of_episodes": 8470, "number_of_timesteps": 8470000, "per_episode_reward": -277.78, "episode_reward_trend_value": 0.038111162817746916, "biggest_recent_change": 0.520646003337788},
{"total_number_of_episodes": 8480, "number_of_timesteps": 8480000, "per_episode_reward": -277.29, "episode_reward_trend_value": 0.04093683823595977, "biggest_recent_change": 0.520646003337788},
{"total_number_of_episodes": 8490, "number_of_timesteps": 8490000, "per_episode_reward": -276.81, "episode_reward_trend_value": 0.04204824058106422, "biggest_recent_change": 0.520646003337788},
{"total_number_of_episodes": 8500, "number_of_timesteps": 8500000, "per_episode_reward": -276.49, "episode_reward_trend_value": 0.04142365820153486, "biggest_recent_change": 0.520646003337788},
{"total_number_of_episodes": 8510, "number_of_timesteps": 8510000, "per_episode_reward": -276.16, "episode_reward_trend_value": 0.04202658610492765, "biggest_recent_change": 0.520646003337788},
{"total_number_of_episodes": 8520, "number_of_timesteps": 8520000, "per_episode_reward": -275.93, "episode_reward_trend_value": 0.04156925881553851, "biggest_recent_change": 0.520646003337788},
{"total_number_of_episodes": 8530, "number_of_timesteps": 8530000, "per_episode_reward": -275.7, "episode_reward_trend_value": 0.03834076055644131, "biggest_recent_change": 0.5206460033377311},
{"total_number_of_episodes": 8540, "number_of_timesteps": 8540000, "per_episode_reward": -275.24, "episode_reward_trend_value": 0.03763155021287869, "biggest_recent_change": 0.48174275258622856},
{"total_number_of_episodes": 8550, "number_of_timesteps": 8550000, "per_episode_reward": -274.79, "episode_reward_trend_value": 0.03795526009088677, "biggest_recent_change": 0.48174275258622856},
{"total_number_of_episodes": 8560, "number_of_timesteps": 8560000, "per_episode_reward": -274.23, "episode_reward_trend_value": 0.03938594833557861, "biggest_recent_change": 0.5564451254187475},
{"total_number_of_episodes": 8570, "number_of_timesteps": 8570000, "per_episode_reward": -273.67, "episode_reward_trend_value": 0.04021597470038564, "biggest_recent_change": 0.5564451254188043},
{"total_number_of_episodes": 8580, "number_of_timesteps": 8580000, "per_episode_reward": -273.06, "episode_reward_trend_value": 0.04174164572532896, "biggest_recent_change": 0.6190531448311276},
{"total_number_of_episodes": 8590, "number_of_timesteps": 8590000, "per_episode_reward": -272.44, "episode_reward_trend_value": 0.045003301474904195, "biggest_recent_change": 0.6190531448311276},
{"total_number_of_episodes": 8600, "number_of_timesteps": 8600000, "per_episode_reward": -271.92, "episode_reward_trend_value": 0.047140033393782234, "biggest_recent_change": 0.6190531448311276},
{"total_number_of_episodes": 8610, "number_of_timesteps": 8610000, "per_episode_reward": -271.4, "episode_reward_trend_value": 0.05033702050544283, "biggest_recent_change": 0.6190531448311276},
{"total_number_of_episodes": 8620, "number_of_timesteps": 8620000, "per_episode_reward": -270.95, "episode_reward_trend_value": 0.05276345377978815, "biggest_recent_change": 0.6190531448311276},
{"total_number_of_episodes": 8630, "number_of_timesteps": 8630000, "per_episode_reward": -270.5, "episode_reward_trend_value": 0.05267059913860206, "biggest_recent_change": 0.6190531448311276},
{"total_number_of_episodes": 8640, "number_of_timesteps": 8640000, "per_episode_reward": -270.24, "episode_reward_trend_value": 0.05050235395805329, "biggest_recent_change": 0.6190531448311276},
{"total_number_of_episodes": 8650, "number_of_timesteps": 8650000, "per_episode_reward": -269.98, "episode_reward_trend_value": 0.047227130410820765, "biggest_recent_change": 0.6190531448311276},
{"total_number_of_episodes": 8660, "number_of_timesteps": 8660000, "per_episode_reward": -269.75, "episode_reward_trend_value": 0.043584418734954194, "biggest_recent_change": 0.6190531448311276},
{"total_number_of_episodes": 8670, "number_of_timesteps": 8670000, "per_episode_reward": -269.52, "episode_reward_trend_value": 0.0392460623989507, "biggest_recent_change": 0.6190531448310708},
{"total_number_of_episodes": 8680, "number_of_timesteps": 8680000, "per_episode_reward": -268.61, "episode_reward_trend_value": 0.04254584195558348, "biggest_recent_change": 0.9160333049280212},
{"total_number_of_episodes": 8690, "number_of_timesteps": 8690000, "per_episode_reward": -267.69, "episode_reward_trend_value": 0.046970545342912826, "biggest_recent_change": 0.9160333049280212},
{"total_number_of_episodes": 8700, "number_of_timesteps": 8700000, "per_episode_reward": -267.31, "episode_reward_trend_value": 0.04548358621560106, "biggest_recent_change": 0.9160333049280212},
{"total_number_of_episodes": 8710, "number_of_timesteps": 8710000, "per_episode_reward": -266.92, "episode_reward_trend_value": 0.04476718092560393, "biggest_recent_change": 0.9160333049280212},
{"total_number_of_episodes": 8720, "number_of_timesteps": 8720000, "per_episode_reward": -266.62, "episode_reward_trend_value": 0.04319884253866348, "biggest_recent_change": 0.9160333049280212},
{"total_number_of_episodes": 8730, "number_of_timesteps": 8730000, "per_episode_reward": -266.31, "episode_reward_trend_value": 0.04370589469108508, "biggest_recent_change": 0.9160333049280212},
{"total_number_of_episodes": 8740, "number_of_timesteps": 8740000, "per_episode_reward": -265.54, "episode_reward_trend_value": 0.04932923799491012, "biggest_recent_change": 0.9160333049280212},
{"total_number_of_episodes": 8750, "number_of_timesteps": 8750000, "per_episode_reward": -264.77, "episode_reward_trend_value": 0.055320069427367946, "biggest_recent_change": 0.9160333049280212},
{"total_number_of_episodes": 8760, "number_of_timesteps": 8760000, "per_episode_reward": -264.38, "episode_reward_trend_value": 0.05716007982363434, "biggest_recent_change": 0.9160333049280212},
{"total_number_of_episodes": 8770, "number_of_timesteps": 8770000, "per_episode_reward": -263.99, "episode_reward_trend_value": 0.05136195432726507, "biggest_recent_change": 0.9160333049279643},
{"total_number_of_episodes": 8780, "number_of_timesteps": 8780000, "per_episode_reward": -263.56, "episode_reward_trend_value": 0.04595637819088425, "biggest_recent_change": 0.7677759035120744},
{"total_number_of_episodes": 8790, "number_of_timesteps": 8790000, "per_episode_reward": -263.13, "episode_reward_trend_value": 0.0464624645691433, "biggest_recent_change": 0.7677759035120744},
{"total_number_of_episodes": 8800, "number_of_timesteps": 8800000, "per_episode_reward": -262.51, "episode_reward_trend_value": 0.04907351920825438, "biggest_recent_change": 0.7677759035120744},
{"total_number_of_episodes": 8810, "number_of_timesteps": 8810000, "per_episode_reward": -261.56, "episode_reward_trend_value": 0.056151487571098516, "biggest_recent_change": 0.9443268525416784},
{"total_number_of_episodes": 8820, "number_of_timesteps": 8820000, "per_episode_reward": -261.27, "episode_reward_trend_value": 0.05598262081827493, "biggest_recent_change": 0.9443268525416784},
{"total_number_of_episodes": 8830, "number_of_timesteps": 8830000, "per_episode_reward": -261.0, "episode_reward_trend_value": 0.05041327279422743, "biggest_recent_change": 0.9443268525416784},
{"total_number_of_episodes": 8840, "number_of_timesteps": 8840000, "per_episode_reward": -260.7, "episode_reward_trend_value": 0.045286942168570474, "biggest_recent_change": 0.9443268525416784},
{"total_number_of_episodes": 8850, "number_of_timesteps": 8850000, "per_episode_reward": -260.39, "episode_reward_trend_value": 0.044311432579103714, "biggest_recent_change": 0.9443268525416784},
{"total_number_of_episodes": 8860, "number_of_timesteps": 8860000, "per_episode_reward": -259.93, "episode_reward_trend_value": 0.045049875482787785, "biggest_recent_change": 0.9443268525416784},
{"total_number_of_episodes": 8870, "number_of_timesteps": 8870000, "per_episode_reward": -259.47, "episode_reward_trend_value": 0.04539576902648277, "biggest_recent_change": 0.9443268525416784},
{"total_number_of_episodes": 8880, "number_of_timesteps": 8880000, "per_episode_reward": -259.37, "episode_reward_trend_value": 0.041729013664264715, "biggest_recent_change": 0.9443268525416784},
{"total_number_of_episodes": 8890, "number_of_timesteps": 8890000, "per_episode_reward": -259.21, "episode_reward_trend_value": 0.036675280213460656, "biggest_recent_change": 0.9443268525416784},
{"total_number_of_episodes": 8900, "number_of_timesteps": 8900000, "per_episode_reward": -259.03, "episode_reward_trend_value": 0.028166935265895494, "biggest_recent_change": 0.4606618715863533},
{"total_number_of_episodes": 8910, "number_of_timesteps": 8910000, "per_episode_reward": -258.75, "episode_reward_trend_value": 0.02805582880868403, "biggest_recent_change": 0.4606618715863533},
{"total_number_of_episodes": 8920, "number_of_timesteps": 8920000, "per_episode_reward": -258.53, "episode_reward_trend_value": 0.027475178228832598, "biggest_recent_change": 0.4606618715863533},
{"total_number_of_episodes": 8930, "number_of_timesteps": 8930000, "per_episode_reward": -258.41, "episode_reward_trend_value": 0.025395440441320714, "biggest_recent_change": 0.4606618715863533},
{"total_number_of_episodes": 8940, "number_of_timesteps": 8940000, "per_episode_reward": -258.29, "episode_reward_trend_value": 0.023312682911995987, "biggest_recent_change": 0.4606618715863533},
{"total_number_of_episodes": 8950, "number_of_timesteps": 8950000, "per_episode_reward": -257.94, "episode_reward_trend_value": 0.022119722103937218, "biggest_recent_change": 0.4606618715862396},
{"total_number_of_episodes": 8960, "number_of_timesteps": 8960000, "per_episode_reward": -257.41, "episode_reward_trend_value": 0.022922072988082062, "biggest_recent_change": 0.5328734511592756},
{"total_number_of_episodes": 8970, "number_of_timesteps": 8970000, "per_episode_reward": -256.87, "episode_reward_trend_value": 0.027737072778139943, "biggest_recent_change": 0.5328734511593325},
{"total_number_of_episodes": 8980, "number_of_timesteps": 8980000, "per_episode_reward": -256.62, "episode_reward_trend_value": 0.028716082860098725, "biggest_recent_change": 0.5328734511593325},
{"total_number_of_episodes": 8990, "number_of_timesteps": 8990000, "per_episode_reward": -256.27, "episode_reward_trend_value": 0.030614905959035037, "biggest_recent_change": 0.5328734511593325},
{"total_number_of_episodes": 9000, "number_of_timesteps": 9000000, "per_episode_reward": -255.84, "episode_reward_trend_value": 0.03223370726937687, "biggest_recent_change": 0.5328734511593325},
{"total_number_of_episodes": 9010, "number_of_timesteps": 9010000, "per_episode_reward": -255.42, "episode_reward_trend_value": 0.03460624282217913, "biggest_recent_change": 0.5328734511593325},
{"total_number_of_episodes": 9020, "number_of_timesteps": 9020000, "per_episode_reward": -255.16, "episode_reward_trend_value": 0.03615044576945081, "biggest_recent_change": 0.5328734511593325},
{"total_number_of_episodes": 9030, "number_of_timesteps": 9030000, "per_episode_reward": -254.8, "episode_reward_trend_value": 0.03882468162633283, "biggest_recent_change": 0.5328734511593325},
{"total_number_of_episodes": 9040, "number_of_timesteps": 9040000, "per_episode_reward": -254.53, "episode_reward_trend_value": 0.03784415450960523, "biggest_recent_change": 0.5328734511593325},
{"total_number_of_episodes": 9050, "number_of_timesteps": 9050000, "per_episode_reward": -254.27, "episode_reward_trend_value": 0.03481858295249809, "biggest_recent_change": 0.5328734511593325},
{"total_number_of_episodes": 9060, "number_of_timesteps": 9060000, "per_episode_reward": -253.94, "episode_reward_trend_value": 0.03257667298184085, "biggest_recent_change": 0.42780422891337366},
{"total_number_of_episodes": 9070, "number_of_timesteps": 9070000, "per_episode_reward": -253.61, "episode_reward_trend_value": 0.033452762547017616, "biggest_recent_change": 0.42780422891337366},
{"total_number_of_episodes": 9080, "number_of_timesteps": 9080000, "per_episode_reward": -253.5, "episode_reward_trend_value": 0.030804189327273614, "biggest_recent_change": 0.42780422891337366},
{"total_number_of_episodes": 9090, "number_of_timesteps": 9090000, "per_episode_reward": -253.33, "episode_reward_trend_value": 0.027892065042557118, "biggest_recent_change": 0.42780422891337366},
{"total_number_of_episodes": 9100, "number_of_timesteps": 9100000, "per_episode_reward": -253.04, "episode_reward_trend_value": 0.02635984626854761, "biggest_recent_change": 0.3596391966829344},
{"total_number_of_episodes": 9110, "number_of_timesteps": 9110000, "per_episode_reward": -252.75, "episode_reward_trend_value": 0.02671202990933826, "biggest_recent_change": 0.3596391966829344},
{"total_number_of_episodes": 9120, "number_of_timesteps": 9120000, "per_episode_reward": -252.39, "episode_reward_trend_value": 0.026821035873862482, "biggest_recent_change": 0.36944973349011434},
{"total_number_of_episodes": 9130, "number_of_timesteps": 9130000, "per_episode_reward": -251.74, "episode_reward_trend_value": 0.031045258332813498, "biggest_recent_change": 0.645227979661172},
{"total_number_of_episodes": 9140, "number_of_timesteps": 9140000, "per_episode_reward": -251.31, "episode_reward_trend_value": 0.03293384540867142, "biggest_recent_change": 0.645227979661172},
{"total_number_of_episodes": 9150, "number_of_timesteps": 9150000, "per_episode_reward": -250.78, "episode_reward_trend_value": 0.03510531131471832, "biggest_recent_change": 0.645227979661172},
{"total_number_of_episodes": 9160, "number_of_timesteps": 9160000, "per_episode_reward": -250.94, "episode_reward_trend_value": 0.029654426656989585, "biggest_recent_change": 0.645227979661172},
{"total_number_of_episodes": 9170, "number_of_timesteps": 9170000, "per_episode_reward": -250.42, "episode_reward_trend_value": 0.03420298210602653, "biggest_recent_change": 0.645227979661172},
{"total_number_of_episodes": 9180, "number_of_timesteps": 9180000, "per_episode_reward": -250.17, "episode_reward_trend_value": 0.03511046276652034, "biggest_recent_change": 0.645227979661172},
{"total_number_of_episodes": 9190, "number_of_timesteps": 9190000, "per_episode_reward": -249.99, "episode_reward_trend_value": 0.03393593047881262, "biggest_recent_change": 0.645227979661172},
{"total_number_of_episodes": 9200, "number_of_timesteps": 9200000, "per_episode_reward": -249.76, "episode_reward_trend_value": 0.033308358066864545, "biggest_recent_change": 0.645227979661172},
{"total_number_of_episodes": 9210, "number_of_timesteps": 9210000, "per_episode_reward": -249.46, "episode_reward_trend_value": 0.03253596627512094, "biggest_recent_change": 0.645227979661172},
{"total_number_of_episodes": 9220, "number_of_timesteps": 9220000, "per_episode_reward": -249.36, "episode_reward_trend_value": 0.026476000468290156, "biggest_recent_change": 0.5265334853444017},
{"total_number_of_episodes": 9230, "number_of_timesteps": 9230000, "per_episode_reward": -249.3, "episode_reward_trend_value": 0.022370521113119126, "biggest_recent_change": 0.5265334853444017},
{"total_number_of_episodes": 9240, "number_of_timesteps": 9240000, "per_episode_reward": -248.92, "episode_reward_trend_value": 0.02068004214932747, "biggest_recent_change": 0.5204682868014459},
{"total_number_of_episodes": 9250, "number_of_timesteps": 9250000, "per_episode_reward": -248.55, "episode_reward_trend_value": 0.026611913749311118, "biggest_recent_change": 0.5204682868014459},
{"total_number_of_episodes": 9260, "number_of_timesteps": 9260000, "per_episode_reward": -248.33, "episode_reward_trend_value": 0.0232884973263465, "biggest_recent_change": 0.3743903786031524},
{"total_number_of_episodes": 9270, "number_of_timesteps": 9270000, "per_episode_reward": -247.94, "episode_reward_trend_value": 0.02482704027105235, "biggest_recent_change": 0.3858551677568016},
{"total_number_of_episodes": 9280, "number_of_timesteps": 9280000, "per_episode_reward": -247.49, "episode_reward_trend_value": 0.027797722885921732, "biggest_recent_change": 0.45155806869706794},
{"total_number_of_episodes": 9290, "number_of_timesteps": 9290000, "per_episode_reward": -247.42, "episode_reward_trend_value": 0.02599260011272217, "biggest_recent_change": 0.45155806869706794},
{"total_number_of_episodes": 9300, "number_of_timesteps": 9300000, "per_episode_reward": -246.94, "episode_reward_trend_value": 0.02801717675210903, "biggest_recent_change": 0.4821463697780075},
{"total_number_of_episodes": 9310, "number_of_timesteps": 9310000, "per_episode_reward": -246.63, "episode_reward_trend_value": 0.03025260232218538, "biggest_recent_change": 0.4821463697780075},
{"total_number_of_episodes": 9320, "number_of_timesteps": 9320000, "per_episode_reward": -246.45, "episode_reward_trend_value": 0.03164120587447441, "biggest_recent_change": 0.4821463697780075},
{"total_number_of_episodes": 9330, "number_of_timesteps": 9330000, "per_episode_reward": -246.02, "episode_reward_trend_value": 0.03226296769913435, "biggest_recent_change": 0.4821463697780075},
{"total_number_of_episodes": 9340, "number_of_timesteps": 9340000, "per_episode_reward": -245.82, "episode_reward_trend_value": 0.03034111147149853, "biggest_recent_change": 0.4821463697780075},
{"total_number_of_episodes": 9350, "number_of_timesteps": 9350000, "per_episode_reward": -245.85, "episode_reward_trend_value": 0.027543138931737432, "biggest_recent_change": 0.4821463697780075},
{"total_number_of_episodes": 9360, "number_of_timesteps": 9360000, "per_episode_reward": -244.97, "episode_reward_trend_value": 0.03294810675571777, "biggest_recent_change": 0.8723022719150322},
{"total_number_of_episodes": 9370, "number_of_timesteps": 9370000, "per_episode_reward": -244.62, "episode_reward_trend_value": 0.0318800391902354, "biggest_recent_change": 0.8723022719150322},
{"total_number_of_episodes": 9380, "number_of_timesteps": 9380000, "per_episode_reward": -244.66, "episode_reward_trend_value": 0.030660213554309874, "biggest_recent_change": 0.8723022719150322},
{"total_number_of_episodes": 9390, "number_of_timesteps": 9390000, "per_episode_reward": -244.35, "episode_reward_trend_value": 0.02870346763045354, "biggest_recent_change": 0.8723022719150322},
{"total_number_of_episodes": 9400, "number_of_timesteps": 9400000, "per_episode_reward": -244.27, "episode_reward_trend_value": 0.026224705865330277, "biggest_recent_change": 0.8723022719150322},
{"total_number_of_episodes": 9410, "number_of_timesteps": 9410000, "per_episode_reward": -243.89, "episode_reward_trend_value": 0.028390739675182252, "biggest_recent_change": 0.8723022719150322},
{"total_number_of_episodes": 9420, "number_of_timesteps": 9420000, "per_episode_reward": -243.47, "episode_reward_trend_value": 0.02835282025814586, "biggest_recent_change": 0.8723022719150322},
{"total_number_of_episodes": 9430, "number_of_timesteps": 9430000, "per_episode_reward": -243.31, "episode_reward_trend_value": 0.027871075483148565, "biggest_recent_change": 0.8723022719150322},
{"total_number_of_episodes": 9440, "number_of_timesteps": 9440000, "per_episode_reward": -242.78, "episode_reward_trend_value": 0.03410183819391111, "biggest_recent_change": 0.8723022719150322},
{"total_number_of_episodes": 9450, "number_of_timesteps": 9450000, "per_episode_reward": -242.25, "episode_reward_trend_value": 0.030301945440686495, "biggest_recent_change": 0.5303119241248169},
{"total_number_of_episodes": 9460, "number_of_timesteps": 9460000, "per_episode_reward": -241.85, "episode_reward_trend_value": 0.030766468618668656, "biggest_recent_change": 0.5303119241248169},
{"total_number_of_episodes": 9470, "number_of_timesteps": 9470000, "per_episode_reward": -241.45, "episode_reward_trend_value": 0.035611595379404545, "biggest_recent_change": 0.5303119241248169},
{"total_number_of_episodes": 9480, "number_of_timesteps": 9480000, "per_episode_reward": -240.95, "episode_reward_trend_value": 0.03782570758319252, "biggest_recent_change": 0.5303119241248169},
{"total_number_of_episodes": 9490, "number_of_timesteps": 9490000, "per_episode_reward": -240.44, "episode_reward_trend_value": 0.042574357977410514, "biggest_recent_change": 0.5303119241248169},
{"total_number_of_episodes": 9500, "number_of_timesteps": 9500000, "per_episode_reward": -240.26, "episode_reward_trend_value": 0.04039531823876277, "biggest_recent_change": 0.5303119241248169},
{"total_number_of_episodes": 9510, "number_of_timesteps": 9510000, "per_episode_reward": -239.94, "episode_reward_trend_value": 0.03920561365151766, "biggest_recent_change": 0.5303119241248169},
{"total_number_of_episodes": 9520, "number_of_timesteps": 9520000, "per_episode_reward": -239.82, "episode_reward_trend_value": 0.038761027505800724, "biggest_recent_change": 0.5303119241248169},
{"total_number_of_episodes": 9530, "number_of_timesteps": 9530000, "per_episode_reward": -239.68, "episode_reward_trend_value": 0.03446557828046998, "biggest_recent_change": 0.5303119241248169},
{"total_number_of_episodes": 9540, "number_of_timesteps": 9540000, "per_episode_reward": -239.62, "episode_reward_trend_value": 0.029202670296633138, "biggest_recent_change": 0.5053093349718552},
{"total_number_of_episodes": 9550, "number_of_timesteps": 9550000, "per_episode_reward": -239.49, "episode_reward_trend_value": 0.026169490007992458, "biggest_recent_change": 0.5053093349718552},
{"total_number_of_episodes": 9560, "number_of_timesteps": 9560000, "per_episode_reward": -239.31, "episode_reward_trend_value": 0.02384465125774966, "biggest_recent_change": 0.5053093349718552},
{"total_number_of_episodes": 9570, "number_of_timesteps": 9570000, "per_episode_reward": -239.12, "episode_reward_trend_value": 0.02031903182806521, "biggest_recent_change": 0.5053093349717983},
{"total_number_of_episodes": 9580, "number_of_timesteps": 9580000, "per_episode_reward": -238.63, "episode_reward_trend_value": 0.020176075793623405, "biggest_recent_change": 0.4924432918720356},
{"total_number_of_episodes": 9590, "number_of_timesteps": 9590000, "per_episode_reward": -238.13, "episode_reward_trend_value": 0.02359371801447057, "biggest_recent_change": 0.49244329187209246},
{"total_number_of_episodes": 9600, "number_of_timesteps": 9600000, "per_episode_reward": -237.89, "episode_reward_trend_value": 0.022751292138325614, "biggest_recent_change": 0.49244329187209246},
{"total_number_of_episodes": 9610, "number_of_timesteps": 9610000, "per_episode_reward": -237.8, "episode_reward_trend_value": 0.022440471244084076, "biggest_recent_change": 0.49244329187209246},
{"total_number_of_episodes": 9620, "number_of_timesteps": 9620000, "per_episode_reward": -237.35, "episode_reward_trend_value": 0.025852074333077568, "biggest_recent_change": 0.49244329187209246},
{"total_number_of_episodes": 9630, "number_of_timesteps": 9630000, "per_episode_reward": -237.03, "episode_reward_trend_value": 0.028758161888633383, "biggest_recent_change": 0.49244329187209246},
{"total_number_of_episodes": 9640, "number_of_timesteps": 9640000, "per_episode_reward": -236.87, "episode_reward_trend_value": 0.029138542520357507, "biggest_recent_change": 0.49244329187209246},
{"total_number_of_episodes": 9650, "number_of_timesteps": 9650000, "per_episode_reward": -236.41, "episode_reward_trend_value": 0.0321713404312959, "biggest_recent_change": 0.49244329187209246},
{"total_number_of_episodes": 9660, "number_of_timesteps": 9660000, "per_episode_reward": -236.11, "episode_reward_trend_value": 0.03342735711990864, "biggest_recent_change": 0.49244329187209246},
{"total_number_of_episodes": 9670, "number_of_timesteps": 9670000, "per_episode_reward": -235.73, "episode_reward_trend_value": 0.03221977330357977, "biggest_recent_change": 0.49244329187209246},
{"total_number_of_episodes": 9680, "number_of_timesteps": 9680000, "per_episode_reward": -235.44, "episode_reward_trend_value": 0.029880144231212415, "biggest_recent_change": 0.4609553982846819},
{"total_number_of_episodes": 9690, "number_of_timesteps": 9690000, "per_episode_reward": -235.16, "episode_reward_trend_value": 0.03030050225093343, "biggest_recent_change": 0.4609553982846819},
{"total_number_of_episodes": 9700, "number_of_timesteps": 9700000, "per_episode_reward": -234.9, "episode_reward_trend_value": 0.03225928717701108, "biggest_recent_change": 0.4609553982846819},
{"total_number_of_episodes": 9710, "number_of_timesteps": 9710000, "per_episode_reward": -234.65, "episode_reward_trend_value": 0.0300318832107103, "biggest_recent_change": 0.4609553982846819},
{"total_number_of_episodes": 9720, "number_of_timesteps": 9720000, "per_episode_reward": -234.09, "episode_reward_trend_value": 0.03263223861644191, "biggest_recent_change": 0.5522300720953695},
{"total_number_of_episodes": 9730, "number_of_timesteps": 9730000, "per_episode_reward": -233.56, "episode_reward_trend_value": 0.03675644801605402, "biggest_recent_change": 0.5522300720953695},
{"total_number_of_episodes": 9740, "number_of_timesteps": 9740000, "per_episode_reward": -233.37, "episode_reward_trend_value": 0.03376942873953794, "biggest_recent_change": 0.5522300720953695},
{"total_number_of_episodes": 9750, "number_of_timesteps": 9750000, "per_episode_reward": -233.11, "episode_reward_trend_value": 0.03331682001413362, "biggest_recent_change": 0.5522300720953695},
{"total_number_of_episodes": 9760, "number_of_timesteps": 9760000, "per_episode_reward": -232.65, "episode_reward_trend_value": 0.034138232383744416, "biggest_recent_change": 0.5522300720953695},
{"total_number_of_episodes": 9770, "number_of_timesteps": 9770000, "per_episode_reward": -232.2, "episode_reward_trend_value": 0.03609169000939308, "biggest_recent_change": 0.5522300720953695},
{"total_number_of_episodes": 9780, "number_of_timesteps": 9780000, "per_episode_reward": -231.87, "episode_reward_trend_value": 0.03655297690333505, "biggest_recent_change": 0.5522300720953695},
{"total_number_of_episodes": 9790, "number_of_timesteps": 9790000, "per_episode_reward": -231.55, "episode_reward_trend_value": 0.03718655687774483, "biggest_recent_change": 0.5522300720953695},
{"total_number_of_episodes": 9800, "number_of_timesteps": 9800000, "per_episode_reward": -231.03, "episode_reward_trend_value": 0.04019083713717243, "biggest_recent_change": 0.5522300720953695},
{"total_number_of_episodes": 9810, "number_of_timesteps": 9810000, "per_episode_reward": -230.5, "episode_reward_trend_value": 0.03995721604272262, "biggest_recent_change": 0.5312041735948867},
{"total_number_of_episodes": 9820, "number_of_timesteps": 9820000, "per_episode_reward": -230.07, "episode_reward_trend_value": 0.038786913609270515, "biggest_recent_change": 0.5312041735948867},
{"total_number_of_episodes": 9830, "number_of_timesteps": 9830000, "per_episode_reward": -229.65, "episode_reward_trend_value": 0.04136708103433414, "biggest_recent_change": 0.5312041735948867},
{"total_number_of_episodes": 9840, "number_of_timesteps": 9840000, "per_episode_reward": -229.35, "episode_reward_trend_value": 0.04183075438126972, "biggest_recent_change": 0.5312041735948867},
{"total_number_of_episodes": 9850, "number_of_timesteps": 9850000, "per_episode_reward": -229.05, "episode_reward_trend_value": 0.04010134374288946, "biggest_recent_change": 0.5312041735948867},
{"total_number_of_episodes": 9860, "number_of_timesteps": 9860000, "per_episode_reward": -228.49, "episode_reward_trend_value": 0.04115217354564101, "biggest_recent_change": 0.5522625439150488},
{"total_number_of_episodes": 9870, "number_of_timesteps": 9870000, "per_episode_reward": -227.94, "episode_reward_trend_value": 0.043695174080098945, "biggest_recent_change": 0.5522625439150488},
{"total_number_of_episodes": 9880, "number_of_timesteps": 9880000, "per_episode_reward": -227.65, "episode_reward_trend_value": 0.04338430688430732, "biggest_recent_change": 0.5522625439150488},
{"total_number_of_episodes": 9890, "number_of_timesteps": 9890000, "per_episode_reward": -227.3, "episode_reward_trend_value": 0.04146227447125928, "biggest_recent_change": 0.5522625439150488},
{"total_number_of_episodes": 9900, "number_of_timesteps": 9900000, "per_episode_reward": -227.07, "episode_reward_trend_value": 0.0381434764689421, "biggest_recent_change": 0.5522625439150488},
{"total_number_of_episodes": 9910, "number_of_timesteps": 9910000, "per_episode_reward": -226.22, "episode_reward_trend_value": 0.04277883982712751, "biggest_recent_change": 0.841521433890648},
{"total_number_of_episodes": 9920, "number_of_timesteps": 9920000, "per_episode_reward": -226.07, "episode_reward_trend_value": 0.03974793403279446, "biggest_recent_change": 0.841521433890648},
{"total_number_of_episodes": 9930, "number_of_timesteps": 9930000, "per_episode_reward": -225.92, "episode_reward_trend_value": 0.03807589298780335, "biggest_recent_change": 0.841521433890648},
{"total_number_of_episodes": 9940, "number_of_timesteps": 9940000, "per_episode_reward": -225.46, "episode_reward_trend_value": 0.03986440211016411, "biggest_recent_change": 0.841521433890648},
{"total_number_of_episodes": 9950, "number_of_timesteps": 9950000, "per_episode_reward": -224.99, "episode_reward_trend_value": 0.03892488935022413, "biggest_recent_change": 0.841521433890648},
{"total_number_of_episodes": 9960, "number_of_timesteps": 9960000, "per_episode_reward": -224.71, "episode_reward_trend_value": 0.035883530375253436, "biggest_recent_change": 0.841521433890648},
{"total_number_of_episodes": 9970, "number_of_timesteps": 9970000, "per_episode_reward": -224.41, "episode_reward_trend_value": 0.03592978849769016, "biggest_recent_change": 0.841521433890648},
{"total_number_of_episodes": 9980, "number_of_timesteps": 9980000, "per_episode_reward": -223.97, "episode_reward_trend_value": 0.036949098346570966, "biggest_recent_change": 0.841521433890648},
{"total_number_of_episodes": 9990, "number_of_timesteps": 9990000, "per_episode_reward": -223.53, "episode_reward_trend_value": 0.03924829005850938, "biggest_recent_change": 0.841521433890648},
{"total_number_of_episodes": 10000, "number_of_timesteps": 10000000, "per_episode_reward": -223.42, "episode_reward_trend_value": 0.031132772743589183, "biggest_recent_change": 0.4677063955204517},
{"total_number_of_episodes": 10010, "number_of_timesteps": 10010000, "per_episode_reward": -223.03, "episode_reward_trend_value": 0.033758929382051724, "biggest_recent_change": 0.4677063955204517},
{"total_number_of_episodes": 10020, "number_of_timesteps": 10020000, "per_episode_reward": -222.78, "episode_reward_trend_value": 0.034844203024080554, "biggest_recent_change": 0.4677063955204517},
{"total_number_of_episodes": 10030, "number_of_timesteps": 10030000, "per_episode_reward": -222.54, "episode_reward_trend_value": 0.03246892649875753, "biggest_recent_change": 0.4677063955204517},
{"total_number_of_episodes": 10040, "number_of_timesteps": 10040000, "per_episode_reward": -222.15, "episode_reward_trend_value": 0.031499981188250106, "biggest_recent_change": 0.43943960746079824},
{"total_number_of_episodes": 10050, "number_of_timesteps": 10050000, "per_episode_reward": -221.77, "episode_reward_trend_value": 0.03263288209277278, "biggest_recent_change": 0.43943960746079824},
{"total_number_of_episodes": 10060, "number_of_timesteps": 10060000, "per_episode_reward": -221.54, "episode_reward_trend_value": 0.03189328654264393, "biggest_recent_change": 0.43943960746079824},
{"total_number_of_episodes": 10070, "number_of_timesteps": 10070000, "per_episode_reward": -221.24, "episode_reward_trend_value": 0.030306096575500558, "biggest_recent_change": 0.43943960746079824},
{"total_number_of_episodes": 10080, "number_of_timesteps": 10080000, "per_episode_reward": -220.69, "episode_reward_trend_value": 0.0315480820254837, "biggest_recent_change": 0.5512182979592808},
{"total_number_of_episodes": 10090, "number_of_timesteps": 10090000, "per_episode_reward": -220.14, "episode_reward_trend_value": 0.03643800894116775, "biggest_recent_change": 0.5512182979593945},
{"total_number_of_episodes": 10100, "number_of_timesteps": 10100000, "per_episode_reward": -219.81, "episode_reward_trend_value": 0.03578575688751123, "biggest_recent_change": 0.5512182979593945},
{"total_number_of_episodes": 10110, "number_of_timesteps": 10110000, "per_episode_reward": -219.48, "episode_reward_trend_value": 0.03667438783028747, "biggest_recent_change": 0.5512182979593945},
{"total_number_of_episodes": 10120, "number_of_timesteps": 10120000, "per_episode_reward": -219.0, "episode_reward_trend_value": 0.03929009887414547, "biggest_recent_change": 0.5512182979593945},
{"total_number_of_episodes": 10130, "number_of_timesteps": 10130000, "per_episode_reward": -218.51, "episode_reward_trend_value": 0.040447260144356775, "biggest_recent_change": 0.5512182979593945},
{"total_number_of_episodes": 10140, "number_of_timesteps": 10140000, "per_episode_reward": -218.15, "episode_reward_trend_value": 0.04027405348171398, "biggest_recent_change": 0.5512182979593945},
{"total_number_of_episodes": 10150, "number_of_timesteps": 10150000, "per_episode_reward": -217.78, "episode_reward_trend_value": 0.04173959390656484, "biggest_recent_change": 0.5512182979593945},
{"total_number_of_episodes": 10160, "number_of_timesteps": 10160000, "per_episode_reward": -217.6, "episode_reward_trend_value": 0.040446126733711986, "biggest_recent_change": 0.5512182979593945},
{"total_number_of_episodes": 10170, "number_of_timesteps": 10170000, "per_episode_reward": -217.42, "episode_reward_trend_value": 0.03632348414373357, "biggest_recent_change": 0.5512182979593945},
{"total_number_of_episodes": 10180, "number_of_timesteps": 10180000, "per_episode_reward": -217.04, "episode_reward_trend_value": 0.03448409849108505, "biggest_recent_change": 0.4846458318938005},
{"total_number_of_episodes": 10190, "number_of_timesteps": 10190000, "per_episode_reward": -217.06, "episode_reward_trend_value": 0.030550553879794506, "biggest_recent_change": 0.4846458318938005},
{"total_number_of_episodes": 10200, "number_of_timesteps": 10200000, "per_episode_reward": -216.46, "episode_reward_trend_value": 0.03360961456061899, "biggest_recent_change": 0.6045240840706754},
{"total_number_of_episodes": 10210, "number_of_timesteps": 10210000, "per_episode_reward": -215.85, "episode_reward_trend_value": 0.03494159514036268, "biggest_recent_change": 0.6045240840707322},
{"total_number_of_episodes": 10220, "number_of_timesteps": 10220000, "per_episode_reward": -215.58, "episode_reward_trend_value": 0.0326525264463631, "biggest_recent_change": 0.6045240840707322},
{"total_number_of_episodes": 10230, "number_of_timesteps": 10230000, "per_episode_reward": -215.3, "episode_reward_trend_value": 0.03169382568521794, "biggest_recent_change": 0.6045240840707322},
{"total_number_of_episodes": 10240, "number_of_timesteps": 10240000, "per_episode_reward": -214.92, "episode_reward_trend_value": 0.031836377863643545, "biggest_recent_change": 0.6045240840707322},
{"total_number_of_episodes": 10250, "number_of_timesteps": 10250000, "per_episode_reward": -214.54, "episode_reward_trend_value": 0.034031510631798614, "biggest_recent_change": 0.6045240840707322},
{"total_number_of_episodes": 10260, "number_of_timesteps": 10260000, "per_episode_reward": -214.07, "episode_reward_trend_value": 0.03726611912416773, "biggest_recent_change": 0.6045240840707322},
{"total_number_of_episodes": 10270, "number_of_timesteps": 10270000, "per_episode_reward": -213.6, "episode_reward_trend_value": 0.038217470679204425, "biggest_recent_change": 0.6045240840707322},
{"total_number_of_episodes": 10280, "number_of_timesteps": 10280000, "per_episode_reward": -213.34, "episode_reward_trend_value": 0.04133268279655213, "biggest_recent_change": 0.6045240840707322},
{"total_number_of_episodes": 10290, "number_of_timesteps": 10290000, "per_episode_reward": -213.09, "episode_reward_trend_value": 0.037455289621785126, "biggest_recent_change": 0.6045240840707322},
{"total_number_of_episodes": 10300, "number_of_timesteps": 10300000, "per_episode_reward": -212.7, "episode_reward_trend_value": 0.03504541756483219, "biggest_recent_change": 0.47129522917444433},
{"total_number_of_episodes": 10310, "number_of_timesteps": 10310000, "per_episode_reward": -212.33, "episode_reward_trend_value": 0.03604053874438477, "biggest_recent_change": 0.47129522917444433},
{"total_number_of_episodes": 10320, "number_of_timesteps": 10320000, "per_episode_reward": -211.91, "episode_reward_trend_value": 0.03762533329402105, "biggest_recent_change": 0.47129522917444433},
{"total_number_of_episodes": 10330, "number_of_timesteps": 10330000, "per_episode_reward": -211.49, "episode_reward_trend_value": 0.038108874904086876, "biggest_recent_change": 0.47129522917444433},
{"total_number_of_episodes": 10340, "number_of_timesteps": 10340000, "per_episode_reward": -211.3, "episode_reward_trend_value": 0.0360177804298186, "biggest_recent_change": 0.47129522917444433},
{"total_number_of_episodes": 10350, "number_of_timesteps": 10350000, "per_episode_reward": -211.11, "episode_reward_trend_value": 0.03284659685827289, "biggest_recent_change": 0.47129522917433064},
{"total_number_of_episodes": 10360, "number_of_timesteps": 10360000, "per_episode_reward": -210.87, "episode_reward_trend_value": 0.03027993253176457, "biggest_recent_change": 0.42126115890107485},
{"total_number_of_episodes": 10370, "number_of_timesteps": 10370000, "per_episode_reward": -210.63, "episode_reward_trend_value": 0.03011034077006356, "biggest_recent_change": 0.42126115890107485},
{"total_number_of_episodes": 10380, "number_of_timesteps": 10380000, "per_episode_reward": -210.21, "episode_reward_trend_value": 0.03193562885476966, "biggest_recent_change": 0.42126115890107485},
{"total_number_of_episodes": 10390, "number_of_timesteps": 10390000, "per_episode_reward": -209.79, "episode_reward_trend_value": 0.032293395821660756, "biggest_recent_change": 0.42126115890107485},
{"total_number_of_episodes": 10400, "number_of_timesteps": 10400000, "per_episode_reward": -209.38, "episode_reward_trend_value": 0.03277005899150254, "biggest_recent_change": 0.42126115890107485},
{"total_number_of_episodes": 10410, "number_of_timesteps": 10410000, "per_episode_reward": -208.97, "episode_reward_trend_value": 0.032657048791261585, "biggest_recent_change": 0.42126115890104643},
{"total_number_of_episodes": 10420, "number_of_timesteps": 10420000, "per_episode_reward": -209.01, "episode_reward_trend_value": 0.02753309778384947, "biggest_recent_change": 0.41983462596519416},
{"total_number_of_episodes": 10430, "number_of_timesteps": 10430000, "per_episode_reward": -208.65, "episode_reward_trend_value": 0.029455976756577545, "biggest_recent_change": 0.41983462596519416},
{"total_number_of_episodes": 10440, "number_of_timesteps": 10440000, "per_episode_reward": -208.35, "episode_reward_trend_value": 0.030679555260139248, "biggest_recent_change": 0.41983462596519416},
{"total_number_of_episodes": 10450, "number_of_timesteps": 10450000, "per_episode_reward": -208.06, "episode_reward_trend_value": 0.03129861451866418, "biggest_recent_change": 0.41983462596519416},
{"total_number_of_episodes": 10460, "number_of_timesteps": 10460000, "per_episode_reward": -207.35, "episode_reward_trend_value": 0.036506030615486414, "biggest_recent_change": 0.7089628885025832},
{"total_number_of_episodes": 10470, "number_of_timesteps": 10470000, "per_episode_reward": -207.03, "episode_reward_trend_value": 0.03536471354970211, "biggest_recent_change": 0.7089628885025832},
{"total_number_of_episodes": 10480, "number_of_timesteps": 10480000, "per_episode_reward": -206.47, "episode_reward_trend_value": 0.036905400878802334, "biggest_recent_change": 0.7089628885025832},
{"total_number_of_episodes": 10490, "number_of_timesteps": 10490000, "per_episode_reward": -205.91, "episode_reward_trend_value": 0.03854324804218929, "biggest_recent_change": 0.7089628885025832},
{"total_number_of_episodes": 10500, "number_of_timesteps": 10500000, "per_episode_reward": -205.6, "episode_reward_trend_value": 0.03747943649927095, "biggest_recent_change": 0.7089628885025832},
{"total_number_of_episodes": 10510, "number_of_timesteps": 10510000, "per_episode_reward": -205.28, "episode_reward_trend_value": 0.041426565763523764, "biggest_recent_change": 0.7089628885025832},
{"total_number_of_episodes": 10520, "number_of_timesteps": 10520000, "per_episode_reward": -204.92, "episode_reward_trend_value": 0.04144913528088902, "biggest_recent_change": 0.7089628885025832},
{"total_number_of_episodes": 10530, "number_of_timesteps": 10530000, "per_episode_reward": -204.55, "episode_reward_trend_value": 0.042211618640482444, "biggest_recent_change": 0.7089628885025832},
{"total_number_of_episodes": 10540, "number_of_timesteps": 10540000, "per_episode_reward": -204.33, "episode_reward_trend_value": 0.04139259290083872, "biggest_recent_change": 0.7089628885025832},
{"total_number_of_episodes": 10550, "number_of_timesteps": 10550000, "per_episode_reward": -204.11, "episode_reward_trend_value": 0.03598521032289802, "biggest_recent_change": 0.5584964855841861},
{"total_number_of_episodes": 10560, "number_of_timesteps": 10560000, "per_episode_reward": -203.9, "episode_reward_trend_value": 0.03479420682016041, "biggest_recent_change": 0.5584964855841861},
{"total_number_of_episodes": 10570, "number_of_timesteps": 10570000, "per_episode_reward": -203.69, "episode_reward_trend_value": 0.03092119892253764, "biggest_recent_change": 0.5584964855841577},
{"total_number_of_episodes": 10580, "number_of_timesteps": 10580000, "per_episode_reward": -203.23, "episode_reward_trend_value": 0.029833142837259175, "biggest_recent_change": 0.4605714379090955},
{"total_number_of_episodes": 10590, "number_of_timesteps": 10590000, "per_episode_reward": -203.12, "episode_reward_trend_value": 0.027489030923142522, "biggest_recent_change": 0.4605714379090955},
{"total_number_of_episodes": 10600, "number_of_timesteps": 10600000, "per_episode_reward": -202.91, "episode_reward_trend_value": 0.026377682762304743, "biggest_recent_change": 0.4605714379090955},
{"total_number_of_episodes": 10610, "number_of_timesteps": 10610000, "per_episode_reward": -202.72, "episode_reward_trend_value": 0.024388671618679168, "biggest_recent_change": 0.4605714379090955},
{"total_number_of_episodes": 10620, "number_of_timesteps": 10620000, "per_episode_reward": -202.37, "episode_reward_trend_value": 0.02431310404637309, "biggest_recent_change": 0.4605714379090955},
{"total_number_of_episodes": 10630, "number_of_timesteps": 10630000, "per_episode_reward": -202.01, "episode_reward_trend_value": 0.025819045573304795, "biggest_recent_change": 0.4605714379090955},
{"total_number_of_episodes": 10640, "number_of_timesteps": 10640000, "per_episode_reward": -201.79, "episode_reward_trend_value": 0.02575354259169684, "biggest_recent_change": 0.4605714379090955},
{"total_number_of_episodes": 10650, "number_of_timesteps": 10650000, "per_episode_reward": -201.58, "episode_reward_trend_value": 0.025825513851085523, "biggest_recent_change": 0.4605714379090955},
{"total_number_of_episodes": 10660, "number_of_timesteps": 10660000, "per_episode_reward": -201.35, "episode_reward_trend_value": 0.025976969918112835, "biggest_recent_change": 0.4605714379090955},
{"total_number_of_episodes": 10670, "number_of_timesteps": 10670000, "per_episode_reward": -201.13, "episode_reward_trend_value": 0.023343474172796162, "biggest_recent_change": 0.35783319391174473},
{"total_number_of_episodes": 10680, "number_of_timesteps": 10680000, "per_episode_reward": -200.9, "episode_reward_trend_value": 0.024715868509392815, "biggest_recent_change": 0.35783319391174473},
{"total_number_of_episodes": 10690, "number_of_timesteps": 10690000, "per_episode_reward": -200.67, "episode_reward_trend_value": 0.024855499092710905, "biggest_recent_change": 0.35783319391174473},
{"total_number_of_episodes": 10700, "number_of_timesteps": 10700000, "per_episode_reward": -200.43, "episode_reward_trend_value": 0.025499250906270594, "biggest_recent_change": 0.35783319391174473},
{"total_number_of_episodes": 10710, "number_of_timesteps": 10710000, "per_episode_reward": -200.19, "episode_reward_trend_value": 0.024229559148510778, "biggest_recent_change": 0.35783319391174473},
{"total_number_of_episodes": 10720, "number_of_timesteps": 10720000, "per_episode_reward": -199.82, "episode_reward_trend_value": 0.024358600265751484, "biggest_recent_change": 0.36944689446340817},
{"total_number_of_episodes": 10730, "number_of_timesteps": 10730000, "per_episode_reward": -199.45, "episode_reward_trend_value": 0.026059085891531213, "biggest_recent_change": 0.36944689446340817},
{"total_number_of_episodes": 10740, "number_of_timesteps": 10740000, "per_episode_reward": -199.11, "episode_reward_trend_value": 0.02735699525535943, "biggest_recent_change": 0.36944689446340817},
{"total_number_of_episodes": 10750, "number_of_timesteps": 10750000, "per_episode_reward": -198.78, "episode_reward_trend_value": 0.02857541981155028, "biggest_recent_change": 0.36944689446340817},
{"total_number_of_episodes": 10760, "number_of_timesteps": 10760000, "per_episode_reward": -198.5, "episode_reward_trend_value": 0.029196493788455135, "biggest_recent_change": 0.36944689446340817},
{"total_number_of_episodes": 10770, "number_of_timesteps": 10770000, "per_episode_reward": -198.23, "episode_reward_trend_value": 0.029688814342331837, "biggest_recent_change": 0.36944689446340817},
{"total_number_of_episodes": 10780, "number_of_timesteps": 10780000, "per_episode_reward": -197.78, "episode_reward_trend_value": 0.03214684437874414, "biggest_recent_change": 0.44911532331704507},
{"total_number_of_episodes": 10790, "number_of_timesteps": 10790000, "per_episode_reward": -197.33, "episode_reward_trend_value": 0.03443078201878412, "biggest_recent_change": 0.44911532331704507},
{"total_number_of_episodes": 10800, "number_of_timesteps": 10800000, "per_episode_reward": -197.13, "episode_reward_trend_value": 0.033902763491009735, "biggest_recent_change": 0.44911532331704507},
{"total_number_of_episodes": 10810, "number_of_timesteps": 10810000, "per_episode_reward": -196.94, "episode_reward_trend_value": 0.031976012088235785, "biggest_recent_change": 0.44911532331704507},
{"total_number_of_episodes": 10820, "number_of_timesteps": 10820000, "per_episode_reward": -196.79, "episode_reward_trend_value": 0.029547211933979155, "biggest_recent_change": 0.44911532331704507},
{"total_number_of_episodes": 10830, "number_of_timesteps": 10830000, "per_episode_reward": -196.64, "episode_reward_trend_value": 0.027520988041673734, "biggest_recent_change": 0.44911532331704507},
{"total_number_of_episodes": 10840, "number_of_timesteps": 10840000, "per_episode_reward": -196.14, "episode_reward_trend_value": 0.029358995467855364, "biggest_recent_change": 0.49863569924411877},
{"total_number_of_episodes": 10850, "number_of_timesteps": 10850000, "per_episode_reward": -195.64, "episode_reward_trend_value": 0.031794353473322365, "biggest_recent_change": 0.49863569924411877},
{"total_number_of_episodes": 10860, "number_of_timesteps": 10860000, "per_episode_reward": -195.4, "episode_reward_trend_value": 0.03140912813557198, "biggest_recent_change": 0.49863569924411877},
{"total_number_of_episodes": 10870, "number_of_timesteps": 10870000, "per_episode_reward": -195.16, "episode_reward_trend_value": 0.029058193315286, "biggest_recent_change": 0.49863569924411877},
{"total_number_of_episodes": 10880, "number_of_timesteps": 10880000, "per_episode_reward": -195.05, "episode_reward_trend_value": 0.02529683457899523, "biggest_recent_change": 0.49863569924411877},
{"total_number_of_episodes": 10890, "number_of_timesteps": 10890000, "per_episode_reward": -194.94, "episode_reward_trend_value": 0.024347432010519456, "biggest_recent_change": 0.49863569924411877},
{"total_number_of_episodes": 10900, "number_of_timesteps": 10900000, "per_episode_reward": -194.59, "episode_reward_trend_value": 0.026044170292832153, "biggest_recent_change": 0.49863569924411877},
{"total_number_of_episodes": 10910, "number_of_timesteps": 10910000, "per_episode_reward": -194.25, "episode_reward_trend_value": 0.028242957326627523, "biggest_recent_change": 0.49863569924411877},
{"total_number_of_episodes": 10920, "number_of_timesteps": 10920000, "per_episode_reward": -193.92, "episode_reward_trend_value": 0.030160783426800387, "biggest_recent_change": 0.49863569924411877},
{"total_number_of_episodes": 10930, "number_of_timesteps": 10930000, "per_episode_reward": -193.6, "episode_reward_trend_value": 0.028214378208485234, "biggest_recent_change": 0.4986356992440619},
{"total_number_of_episodes": 10940, "number_of_timesteps": 10940000, "per_episode_reward": -193.39, "episode_reward_trend_value": 0.024974945898294562, "biggest_recent_change": 0.348745713621895},
{"total_number_of_episodes": 10950, "number_of_timesteps": 10950000, "per_episode_reward": -193.18, "episode_reward_trend_value": 0.024636674807578314, "biggest_recent_change": 0.348745713621895},
{"total_number_of_episodes": 10960, "number_of_timesteps": 10960000, "per_episode_reward": -192.86, "episode_reward_trend_value": 0.0256184717604782, "biggest_recent_change": 0.348745713621895},
{"total_number_of_episodes": 10970, "number_of_timesteps": 10970000, "per_episode_reward": -192.53, "episode_reward_trend_value": 0.028010692629383827, "biggest_recent_change": 0.348745713621895},
{"total_number_of_episodes": 10980, "number_of_timesteps": 10980000, "per_episode_reward": -192.27, "episode_reward_trend_value": 0.029690804363627876, "biggest_recent_change": 0.348745713621895},
{"total_number_of_episodes": 10990, "number_of_timesteps": 10990000, "per_episode_reward": -192.01, "episode_reward_trend_value": 0.02872477524708251, "biggest_recent_change": 0.34874571362186657},
{"total_number_of_episodes": 11000, "number_of_timesteps": 11000000, "per_episode_reward": -191.82, "episode_reward_trend_value": 0.026912745498604652, "biggest_recent_change": 0.3258929152523251},
{"total_number_of_episodes": 11010, "number_of_timesteps": 11010000, "per_episode_reward": -191.64, "episode_reward_trend_value": 0.025381676683750243, "biggest_recent_change": 0.3258929152523251},
{"total_number_of_episodes": 11020, "number_of_timesteps": 11020000, "per_episode_reward": -191.21, "episode_reward_trend_value": 0.02653204708379191, "biggest_recent_change": 0.42699256559950527},
{"total_number_of_episodes": 11030, "number_of_timesteps": 11030000, "per_episode_reward": -190.88, "episode_reward_trend_value": 0.02791688807173721, "biggest_recent_change": 0.42699256559950527},
{"total_number_of_episodes": 11040, "number_of_timesteps": 11040000, "per_episode_reward": -190.58, "episode_reward_trend_value": 0.02892776405778837, "biggest_recent_change": 0.42699256559950527},
{"total_number_of_episodes": 11050, "number_of_timesteps": 11050000, "per_episode_reward": -190.28, "episode_reward_trend_value": 0.028618572000224655, "biggest_recent_change": 0.42699256559950527},
{"total_number_of_episodes": 11060, "number_of_timesteps": 11060000, "per_episode_reward": -189.96, "episode_reward_trend_value": 0.02853290709053245, "biggest_recent_change": 0.42699256559950527},
{"total_number_of_episodes": 11070, "number_of_timesteps": 11070000, "per_episode_reward": -189.63, "episode_reward_trend_value": 0.029296977348758448, "biggest_recent_change": 0.42699256559950527},
{"total_number_of_episodes": 11080, "number_of_timesteps": 11080000, "per_episode_reward": -189.43, "episode_reward_trend_value": 0.028642297678029154, "biggest_recent_change": 0.42699256559950527},
{"total_number_of_episodes": 11090, "number_of_timesteps": 11090000, "per_episode_reward": -189.23, "episode_reward_trend_value": 0.028833618639232683, "biggest_recent_change": 0.42699256559950527},
{"total_number_of_episodes": 11100, "number_of_timesteps": 11100000, "per_episode_reward": -188.9, "episode_reward_trend_value": 0.030381434156767438, "biggest_recent_change": 0.42699256559950527},
{"total_number_of_episodes": 11110, "number_of_timesteps": 11110000, "per_episode_reward": -188.58, "episode_reward_trend_value": 0.029247810459406765, "biggest_recent_change": 0.3317224802419787},
{"total_number_of_episodes": 11120, "number_of_timesteps": 11120000, "per_episode_reward": -188.34, "episode_reward_trend_value": 0.028197369362429624, "biggest_recent_change": 0.3305694163731516},
{"total_number_of_episodes": 11130, "number_of_timesteps": 11130000, "per_episode_reward": -188.1, "episode_reward_trend_value": 0.027520893267346636, "biggest_recent_change": 0.3305694163731516},
{"total_number_of_episodes": 11140, "number_of_timesteps": 11140000, "per_episode_reward": -187.9, "episode_reward_trend_value": 0.026470894509696703, "biggest_recent_change": 0.3305694163731516},
{"total_number_of_episodes": 11150, "number_of_timesteps": 11150000, "per_episode_reward": -187.7, "episode_reward_trend_value": 0.02519736860417431, "biggest_recent_change": 0.3305694163731516},
{"total_number_of_episodes": 11160, "number_of_timesteps": 11160000, "per_episode_reward": -187.51, "episode_reward_trend_value": 0.02362290227296455, "biggest_recent_change": 0.3249664328370443},
{"total_number_of_episodes": 11170, "number_of_timesteps": 11170000, "per_episode_reward": -187.32, "episode_reward_trend_value": 0.023467185870710082, "biggest_recent_change": 0.3249664328370443},
{"total_number_of_episodes": 11180, "number_of_timesteps": 11180000, "per_episode_reward": -186.95, "episode_reward_trend_value": 0.025349939901911017, "biggest_recent_change": 0.37232978557526053},
{"total_number_of_episodes": 11190, "number_of_timesteps": 11190000, "per_episode_reward": -186.57, "episode_reward_trend_value": 0.025876199376780717, "biggest_recent_change": 0.3723297855753174},
{"total_number_of_episodes": 11200, "number_of_timesteps": 11200000, "per_episode_reward": -186.08, "episode_reward_trend_value": 0.02780509364850477, "biggest_recent_change": 0.4985669172922087},
{"total_number_of_episodes": 11210, "number_of_timesteps": 11210000, "per_episode_reward": -185.58, "episode_reward_trend_value": 0.030709361823817793, "biggest_recent_change": 0.4985669172922087},
{"total_number_of_episodes": 11220, "number_of_timesteps": 11220000, "per_episode_reward": -185.46, "episode_reward_trend_value": 0.02942528929257517, "biggest_recent_change": 0.4985669172922087},
{"total_number_of_episodes": 11230, "number_of_timesteps": 11230000, "per_episode_reward": -185.33, "episode_reward_trend_value": 0.028514739423898226, "biggest_recent_change": 0.4985669172922087},
{"total_number_of_episodes": 11240, "number_of_timesteps": 11240000, "per_episode_reward": -185.22, "episode_reward_trend_value": 0.027534295574398647, "biggest_recent_change": 0.4985669172922087},
{"total_number_of_episodes": 11250, "number_of_timesteps": 11250000, "per_episode_reward": -185.1, "episode_reward_trend_value": 0.026717166117329483, "biggest_recent_change": 0.4985669172922087},
{"total_number_of_episodes": 11260, "number_of_timesteps": 11260000, "per_episode_reward": -184.9, "episode_reward_trend_value": 0.02684353590845869, "biggest_recent_change": 0.4985669172922087},
{"total_number_of_episodes": 11270, "number_of_timesteps": 11270000, "per_episode_reward": -184.7, "episode_reward_trend_value": 0.024931435266132475, "biggest_recent_change": 0.4985669172922087},
{"total_number_of_episodes": 11280, "number_of_timesteps": 11280000, "per_episode_reward": -184.23, "episode_reward_trend_value": 0.026019797570957494, "biggest_recent_change": 0.4985669172922087},
{"total_number_of_episodes": 11290, "number_of_timesteps": 11290000, "per_episode_reward": -183.64, "episode_reward_trend_value": 0.027049748432721305, "biggest_recent_change": 0.5912624948509517},
{"total_number_of_episodes": 11300, "number_of_timesteps": 11300000, "per_episode_reward": -183.3, "episode_reward_trend_value": 0.025345103411575882, "biggest_recent_change": 0.5912624948509517},
{"total_number_of_episodes": 11310, "number_of_timesteps": 11310000, "per_episode_reward": -182.95, "episode_reward_trend_value": 0.027828799096987683, "biggest_recent_change": 0.5912624948509517},
{"total_number_of_episodes": 11320, "number_of_timesteps": 11320000, "per_episode_reward": -182.81, "episode_reward_trend_value": 0.027988351142489404, "biggest_recent_change": 0.5912624948509517},
{"total_number_of_episodes": 11330, "number_of_timesteps": 11330000, "per_episode_reward": -182.68, "episode_reward_trend_value": 0.028217797168814385, "biggest_recent_change": 0.5912624948509517},
{"total_number_of_episodes": 11340, "number_of_timesteps": 11340000, "per_episode_reward": -182.5, "episode_reward_trend_value": 0.028968887595936126, "biggest_recent_change": 0.5912624948509517},
{"total_number_of_episodes": 11350, "number_of_timesteps": 11350000, "per_episode_reward": -182.31, "episode_reward_trend_value": 0.028776478774859192, "biggest_recent_change": 0.5912624948509517},
{"total_number_of_episodes": 11360, "number_of_timesteps": 11360000, "per_episode_reward": -182.17, "episode_reward_trend_value": 0.02812431680564329, "biggest_recent_change": 0.5912624948509517},
{"total_number_of_episodes": 11370, "number_of_timesteps": 11370000, "per_episode_reward": -182.03, "episode_reward_trend_value": 0.02447169188927521, "biggest_recent_change": 0.5912624948509517},
{"total_number_of_episodes": 11380, "number_of_timesteps": 11380000, "per_episode_reward": -181.82, "episode_reward_trend_value": 0.020271143950054377, "biggest_recent_change": 0.34514886538920564},
{"total_number_of_episodes": 11390, "number_of_timesteps": 11390000, "per_episode_reward": -181.6, "episode_reward_trend_value": 0.0188051918937431, "biggest_recent_change": 0.34514886538920564},
{"total_number_of_episodes": 11400, "number_of_timesteps": 11400000, "per_episode_reward": -181.15, "episode_reward_trend_value": 0.019979456812173644, "biggest_recent_change": 0.4508327080479546},
{"total_number_of_episodes": 11410, "number_of_timesteps": 11410000, "per_episode_reward": -180.7, "episode_reward_trend_value": 0.02347786537051396, "biggest_recent_change": 0.4508327080479546},
{"total_number_of_episodes": 11420, "number_of_timesteps": 11420000, "per_episode_reward": -180.33, "episode_reward_trend_value": 0.02609072952438491, "biggest_recent_change": 0.4508327080479546},
{"total_number_of_episodes": 11430, "number_of_timesteps": 11430000, "per_episode_reward": -179.96, "episode_reward_trend_value": 0.028181949277459102, "biggest_recent_change": 0.4508327080479546},
{"total_number_of_episodes": 11440, "number_of_timesteps": 11440000, "per_episode_reward": -179.71, "episode_reward_trend_value": 0.028922960704755633, "biggest_recent_change": 0.4508327080479546},
{"total_number_of_episodes": 11450, "number_of_timesteps": 11450000, "per_episode_reward": -179.46, "episode_reward_trend_value": 0.030123725280191138, "biggest_recent_change": 0.4508327080479546},
{"total_number_of_episodes": 11460, "number_of_timesteps": 11460000, "per_episode_reward": -179.22, "episode_reward_trend_value": 0.031172566269322032, "biggest_recent_change": 0.4508327080479546},
{"total_number_of_episodes": 11470, "number_of_timesteps": 11470000, "per_episode_reward": -178.99, "episode_reward_trend_value": 0.031425106927513484, "biggest_recent_change": 0.4508327080479546},
{"total_number_of_episodes": 11480, "number_of_timesteps": 11480000, "per_episode_reward": -178.7, "episode_reward_trend_value": 0.032214513760635874, "biggest_recent_change": 0.4508327080479546},
{"total_number_of_episodes": 11490, "number_of_timesteps": 11490000, "per_episode_reward": -178.42, "episode_reward_trend_value": 0.03036370361901548, "biggest_recent_change": 0.4508327080479262},
{"total_number_of_episodes": 11500, "number_of_timesteps": 11500000, "per_episode_reward": -178.22, "episode_reward_trend_value": 0.027523096753648703, "biggest_recent_change": 0.3711337116456832},
{"total_number_of_episodes": 11510, "number_of_timesteps": 11510000, "per_episode_reward": -178.03, "episode_reward_trend_value": 0.025568034292751916, "biggest_recent_change": 0.3711337116456832},
{"total_number_of_episodes": 11520, "number_of_timesteps": 11520000, "per_episode_reward": -177.78, "episode_reward_trend_value": 0.02419581826270145, "biggest_recent_change": 0.28425979530211976},
{"total_number_of_episodes": 11530, "number_of_timesteps": 11530000, "per_episode_reward": -177.53, "episode_reward_trend_value": 0.0241738105584299, "biggest_recent_change": 0.28425979530211976},
{"total_number_of_episodes": 11540, "number_of_timesteps": 11540000, "per_episode_reward": -177.2, "episode_reward_trend_value": 0.02507001329935545, "biggest_recent_change": 0.33027320900896484},
{"total_number_of_episodes": 11550, "number_of_timesteps": 11550000, "per_episode_reward": -176.87, "episode_reward_trend_value": 0.026118139626585917, "biggest_recent_change": 0.33027320900896484},
{"total_number_of_episodes": 11560, "number_of_timesteps": 11560000, "per_episode_reward": -176.13, "episode_reward_trend_value": 0.031717803628012575, "biggest_recent_change": 0.7399115996867067},
{"total_number_of_episodes": 11570, "number_of_timesteps": 11570000, "per_episode_reward": -175.78, "episode_reward_trend_value": 0.032473915593426585, "biggest_recent_change": 0.7399115996867067},
{"total_number_of_episodes": 11580, "number_of_timesteps": 11580000, "per_episode_reward": -175.52, "episode_reward_trend_value": 0.03219026464317033, "biggest_recent_change": 0.7399115996867067},
{"total_number_of_episodes": 11590, "number_of_timesteps": 11590000, "per_episode_reward": -175.26, "episode_reward_trend_value": 0.03289641041666048, "biggest_recent_change": 0.7399115996867067},
{"total_number_of_episodes": 11600, "number_of_timesteps": 11600000, "per_episode_reward": -174.85, "episode_reward_trend_value": 0.035313454021677945, "biggest_recent_change": 0.7399115996867067},
{"total_number_of_episodes": 11610, "number_of_timesteps": 11610000, "per_episode_reward": -174.44, "episode_reward_trend_value": 0.037147651195849105, "biggest_recent_change": 0.7399115996867067},
{"total_number_of_episodes": 11620, "number_of_timesteps": 11620000, "per_episode_reward": -174.43, "episode_reward_trend_value": 0.03447867729995109, "biggest_recent_change": 0.7399115996867067},
{"total_number_of_episodes": 11630, "number_of_timesteps": 11630000, "per_episode_reward": -174.27, "episode_reward_trend_value": 0.03257670293285016, "biggest_recent_change": 0.7399115996867067},
{"total_number_of_episodes": 11640, "number_of_timesteps": 11640000, "per_episode_reward": -174.13, "episode_reward_trend_value": 0.030473729597063466, "biggest_recent_change": 0.7399115996867067},
{"total_number_of_episodes": 11650, "number_of_timesteps": 11650000, "per_episode_reward": -173.99, "episode_reward_trend_value": 0.023819218587079326, "biggest_recent_change": 0.4127120146165453},
{"total_number_of_episodes": 11660, "number_of_timesteps": 11660000, "per_episode_reward": -173.6, "episode_reward_trend_value": 0.024213991343509, "biggest_recent_change": 0.4127120146165453},
{"total_number_of_episodes": 11670, "number_of_timesteps": 11670000, "per_episode_reward": -173.21, "episode_reward_trend_value": 0.025648527015608935, "biggest_recent_change": 0.4127120146165453},
{"total_number_of_episodes": 11680, "number_of_timesteps": 11680000, "per_episode_reward": -172.95, "episode_reward_trend_value": 0.025723984074314088, "biggest_recent_change": 0.4127120146165453},
{"total_number_of_episodes": 11690, "number_of_timesteps": 11690000, "per_episode_reward": -172.68, "episode_reward_trend_value": 0.024088543301491287, "biggest_recent_change": 0.4127120146165453},
{"total_number_of_episodes": 11700, "number_of_timesteps": 11700000, "per_episode_reward": -172.53, "episode_reward_trend_value": 0.021194007564842663, "biggest_recent_change": 0.38783942026805107},
{"total_number_of_episodes": 11710, "number_of_timesteps": 11710000, "per_episode_reward": -172.38, "episode_reward_trend_value": 0.022802642898262584, "biggest_recent_change": 0.38783942026805107},
{"total_number_of_episodes": 11720, "number_of_timesteps": 11720000, "per_episode_reward": -172.19, "episode_reward_trend_value": 0.023145063863179237, "biggest_recent_change": 0.38783942026805107},
{"total_number_of_episodes": 11730, "number_of_timesteps": 11730000, "per_episode_reward": -172.0, "episode_reward_trend_value": 0.023688483796782282, "biggest_recent_change": 0.38783942026805107},
{"total_number_of_episodes": 11740, "number_of_timesteps": 11740000, "per_episode_reward": -171.93, "episode_reward_trend_value": 0.022862782269730687, "biggest_recent_change": 0.38783942026805107},
{"total_number_of_episodes": 11750, "number_of_timesteps": 11750000, "per_episode_reward": -171.87, "episode_reward_trend_value": 0.019294482837347006, "biggest_recent_change": 0.38783942026805107},
{"total_number_of_episodes": 11760, "number_of_timesteps": 11760000, "per_episode_reward": -171.63, "episode_reward_trend_value": 0.017582265287761186, "biggest_recent_change": 0.26552234506249306},
{"total_number_of_episodes": 11770, "number_of_timesteps": 11770000, "per_episode_reward": -171.4, "episode_reward_trend_value": 0.017229126351570142, "biggest_recent_change": 0.26552234506249306},
{"total_number_of_episodes": 11780, "number_of_timesteps": 11780000, "per_episode_reward": -171.18, "episode_reward_trend_value": 0.0167073515873546, "biggest_recent_change": 0.2337398408053275},
{"total_number_of_episodes": 11790, "number_of_timesteps": 11790000, "per_episode_reward": -170.96, "episode_reward_trend_value": 0.017444671786965196, "biggest_recent_change": 0.2337398408053275},
{"total_number_of_episodes": 11800, "number_of_timesteps": 11800000, "per_episode_reward": -170.78, "episode_reward_trend_value": 0.01776343724172528, "biggest_recent_change": 0.2337398408053275},
{"total_number_of_episodes": 11810, "number_of_timesteps": 11810000, "per_episode_reward": -170.6, "episode_reward_trend_value": 0.01766320709099508, "biggest_recent_change": 0.2337398408053275},
{"total_number_of_episodes": 11820, "number_of_timesteps": 11820000, "per_episode_reward": -170.46, "episode_reward_trend_value": 0.017153920973495614, "biggest_recent_change": 0.2337398408053275},
{"total_number_of_episodes": 11830, "number_of_timesteps": 11830000, "per_episode_reward": -170.31, "episode_reward_trend_value": 0.018013756316651097, "biggest_recent_change": 0.2337398408053275},
{"total_number_of_episodes": 11840, "number_of_timesteps": 11840000, "per_episode_reward": -170.15, "episode_reward_trend_value": 0.019042990257107956, "biggest_recent_change": 0.2337398408053275},
{"total_number_of_episodes": 11850, "number_of_timesteps": 11850000, "per_episode_reward": -169.99, "episode_reward_trend_value": 0.018216142314766946, "biggest_recent_change": 0.23373984080529908},
{"total_number_of_episodes": 11860, "number_of_timesteps": 11860000, "per_episode_reward": -169.75, "episode_reward_trend_value": 0.018324408204270524, "biggest_recent_change": 0.243483770860621},
{"total_number_of_episodes": 11870, "number_of_timesteps": 11870000, "per_episode_reward": -169.53, "episode_reward_trend_value": 0.018370774574831078, "biggest_recent_change": 0.243483770860621},
{"total_number_of_episodes": 11880, "number_of_timesteps": 11880000, "per_episode_reward": -169.3, "episode_reward_trend_value": 0.01846094602687142, "biggest_recent_change": 0.243483770860621},
{"total_number_of_episodes": 11890, "number_of_timesteps": 11890000, "per_episode_reward": -169.07, "episode_reward_trend_value": 0.01896967222376165, "biggest_recent_change": 0.243483770860621},
{"total_number_of_episodes": 11900, "number_of_timesteps": 11900000, "per_episode_reward": -168.79, "episode_reward_trend_value": 0.020066908681468477, "biggest_recent_change": 0.2796439704402758},
{"total_number_of_episodes": 11910, "number_of_timesteps": 11910000, "per_episode_reward": -168.51, "episode_reward_trend_value": 0.021573201105943303, "biggest_recent_change": 0.2796439704402758},
{"total_number_of_episodes": 11920, "number_of_timesteps": 11920000, "per_episode_reward": -168.29, "episode_reward_trend_value": 0.02245292830169553, "biggest_recent_change": 0.2796439704402758},
{"total_number_of_episodes": 11930, "number_of_timesteps": 11930000, "per_episode_reward": -168.07, "episode_reward_trend_value": 0.02316325690014512, "biggest_recent_change": 0.2796439704402758},
{"total_number_of_episodes": 11940, "number_of_timesteps": 11940000, "per_episode_reward": -167.83, "episode_reward_trend_value": 0.023993055205541066, "biggest_recent_change": 0.2796439704402758},
{"total_number_of_episodes": 11950, "number_of_timesteps": 11950000, "per_episode_reward": -167.6, "episode_reward_trend_value": 0.023887739679091486, "biggest_recent_change": 0.2796439704402758},
{"total_number_of_episodes": 11960, "number_of_timesteps": 11960000, "per_episode_reward": -167.26, "episode_reward_trend_value": 0.025172563620011107, "biggest_recent_change": 0.33836974431631006},
{"total_number_of_episodes": 11970, "number_of_timesteps": 11970000, "per_episode_reward": -166.92, "episode_reward_trend_value": 0.02641358247945031, "biggest_recent_change": 0.33836974431631006},
{"total_number_of_episodes": 11980, "number_of_timesteps": 11980000, "per_episode_reward": -166.71, "episode_reward_trend_value": 0.026245655524880996, "biggest_recent_change": 0.33836974431631006},
{"total_number_of_episodes": 11990, "number_of_timesteps": 11990000, "per_episode_reward": -166.5, "episode_reward_trend_value": 0.02548921830949477, "biggest_recent_change": 0.33836974431631006},
{"total_number_of_episodes": 12000, "number_of_timesteps": 12000000, "per_episode_reward": -166.15, "episode_reward_trend_value": 0.026264680529471385, "biggest_recent_change": 0.3494355702381142},
{"total_number_of_episodes": 12010, "number_of_timesteps": 12010000, "per_episode_reward": -165.8, "episode_reward_trend_value": 0.027666707978170595, "biggest_recent_change": 0.3494355702381142},
{"total_number_of_episodes": 12020, "number_of_timesteps": 12020000, "per_episode_reward": -165.63, "episode_reward_trend_value": 0.027085890884439183, "biggest_recent_change": 0.3494355702381142},
{"total_number_of_episodes": 12030, "number_of_timesteps": 12030000, "per_episode_reward": -165.46, "episode_reward_trend_value": 0.02638560408376141, "biggest_recent_change": 0.3494355702381142},
{"total_number_of_episodes": 12040, "number_of_timesteps": 12040000, "per_episode_reward": -165.22, "episode_reward_trend_value": 0.026450308026972874, "biggest_recent_change": 0.3494355702381142},
{"total_number_of_episodes": 12050, "number_of_timesteps": 12050000, "per_episode_reward": -164.98, "episode_reward_trend_value": 0.025355407849782963, "biggest_recent_change": 0.3494355702381142},
{"total_number_of_episodes": 12060, "number_of_timesteps": 12060000, "per_episode_reward": -164.77, "episode_reward_trend_value": 0.02387774437006745, "biggest_recent_change": 0.3494355702381142},
{"total_number_of_episodes": 12070, "number_of_timesteps": 12070000, "per_episode_reward": -164.57, "episode_reward_trend_value": 0.02380902670436045, "biggest_recent_change": 0.3494355702381142},
{"total_number_of_episodes": 12080, "number_of_timesteps": 12080000, "per_episode_reward": -164.26, "episode_reward_trend_value": 0.0248754368378065, "biggest_recent_change": 0.3494355702381142},
{"total_number_of_episodes": 12090, "number_of_timesteps": 12090000, "per_episode_reward": -164.14, "episode_reward_trend_value": 0.022364310847496606, "biggest_recent_change": 0.3494355702381142},
{"total_number_of_episodes": 12100, "number_of_timesteps": 12100000, "per_episode_reward": -163.89, "episode_reward_trend_value": 0.021228460804853296, "biggest_recent_change": 0.3075415330656597},
{"total_number_of_episodes": 12110, "number_of_timesteps": 12110000, "per_episode_reward": -163.69, "episode_reward_trend_value": 0.021559756746800142, "biggest_recent_change": 0.3075415330656597},
{"total_number_of_episodes": 12120, "number_of_timesteps": 12120000, "per_episode_reward": -163.47, "episode_reward_trend_value": 0.022074408456726737, "biggest_recent_change": 0.3075415330656597},
{"total_number_of_episodes": 12130, "number_of_timesteps": 12130000, "per_episode_reward": -163.25, "episode_reward_trend_value": 0.021824069422764738, "biggest_recent_change": 0.3075415330656597},
{"total_number_of_episodes": 12140, "number_of_timesteps": 12140000, "per_episode_reward": -163.04, "episode_reward_trend_value": 0.02151701568093295, "biggest_recent_change": 0.3075415330656597},
{"total_number_of_episodes": 12150, "number_of_timesteps": 12150000, "per_episode_reward": -162.83, "episode_reward_trend_value": 0.021592725241627087, "biggest_recent_change": 0.3075415330656597},
{"total_number_of_episodes": 12160, "number_of_timesteps": 12160000, "per_episode_reward": -162.55, "episode_reward_trend_value": 0.022429736170850686, "biggest_recent_change": 0.3075415330656597},
{"total_number_of_episodes": 12170, "number_of_timesteps": 12170000, "per_episode_reward": -162.27, "episode_reward_trend_value": 0.022131619300920925, "biggest_recent_change": 0.2807110147719811},
{"total_number_of_episodes": 12180, "number_of_timesteps": 12180000, "per_episode_reward": -162.02, "episode_reward_trend_value": 0.02351348893603592, "biggest_recent_change": 0.2807110147719811},
{"total_number_of_episodes": 12190, "number_of_timesteps": 12190000, "per_episode_reward": -161.77, "episode_reward_trend_value": 0.023520082623484324, "biggest_recent_change": 0.2807110147719811},
{"total_number_of_episodes": 12200, "number_of_timesteps": 12200000, "per_episode_reward": -161.55, "episode_reward_trend_value": 0.023748743548025194, "biggest_recent_change": 0.2807110147719811},
{"total_number_of_episodes": 12210, "number_of_timesteps": 12210000, "per_episode_reward": -161.33, "episode_reward_trend_value": 0.023794048704586936, "biggest_recent_change": 0.2807110147719811},
{"total_number_of_episodes": 12220, "number_of_timesteps": 12220000, "per_episode_reward": -161.12, "episode_reward_trend_value": 0.023661338350948805, "biggest_recent_change": 0.2807110147719811},
{"total_number_of_episodes": 12230, "number_of_timesteps": 12230000, "per_episode_reward": -160.92, "episode_reward_trend_value": 0.02358534270518046, "biggest_recent_change": 0.2807110147719811},
{"total_number_of_episodes": 12240, "number_of_timesteps": 12240000, "per_episode_reward": -160.54, "episode_reward_trend_value": 0.02547789388086035, "biggest_recent_change": 0.3825234974155478},
{"total_number_of_episodes": 12250, "number_of_timesteps": 12250000, "per_episode_reward": -160.15, "episode_reward_trend_value": 0.026609143688011094, "biggest_recent_change": 0.3825234974155478},
{"total_number_of_episodes": 12260, "number_of_timesteps": 12260000, "per_episode_reward": -159.84, "episode_reward_trend_value": 0.027005445287108566, "biggest_recent_change": 0.3825234974155478},
{"total_number_of_episodes": 12270, "number_of_timesteps": 12270000, "per_episode_reward": -159.52, "episode_reward_trend_value": 0.027767397069555323, "biggest_recent_change": 0.3825234974155478},
{"total_number_of_episodes": 12280, "number_of_timesteps": 12280000, "per_episode_reward": -159.35, "episode_reward_trend_value": 0.026914268306717302, "biggest_recent_change": 0.3825234974155478},
{"total_number_of_episodes": 12290, "number_of_timesteps": 12290000, "per_episode_reward": -159.18, "episode_reward_trend_value": 0.026354770864628247, "biggest_recent_change": 0.3825234974155478},
{"total_number_of_episodes": 12300, "number_of_timesteps": 12300000, "per_episode_reward": -158.97, "episode_reward_trend_value": 0.02618423124908386, "biggest_recent_change": 0.3825234974155478},
{"total_number_of_episodes": 12310, "number_of_timesteps": 12310000, "per_episode_reward": -158.77, "episode_reward_trend_value": 0.026191707143740296, "biggest_recent_change": 0.3825234974155478},
{"total_number_of_episodes": 12320, "number_of_timesteps": 12320000, "per_episode_reward": -158.59, "episode_reward_trend_value": 0.02591631268496365, "biggest_recent_change": 0.3825234974155478},
{"total_number_of_episodes": 12330, "number_of_timesteps": 12330000, "per_episode_reward": -158.41, "episode_reward_trend_value": 0.023672371404738456, "biggest_recent_change": 0.3825234974155478},
{"total_number_of_episodes": 12340, "number_of_timesteps": 12340000, "per_episode_reward": -158.25, "episode_reward_trend_value": 0.02112204525017426, "biggest_recent_change": 0.3163781586907817},
{"total_number_of_episodes": 12350, "number_of_timesteps": 12350000, "per_episode_reward": -158.1, "episode_reward_trend_value": 0.01930666730366271, "biggest_recent_change": 0.3163781586907817},
{"total_number_of_episodes": 12360, "number_of_timesteps": 12360000, "per_episode_reward": -157.85, "episode_reward_trend_value": 0.018539415930673108, "biggest_recent_change": 0.24732553512171762},
{"total_number_of_episodes": 12370, "number_of_timesteps": 12370000, "per_episode_reward": -157.63, "episode_reward_trend_value": 0.01917272839884087, "biggest_recent_change": 0.24732553512171762},
{"total_number_of_episodes": 12380, "number_of_timesteps": 12380000, "per_episode_reward": -157.44, "episode_reward_trend_value": 0.0192993070412519, "biggest_recent_change": 0.24732553512171762},
{"total_number_of_episodes": 12390, "number_of_timesteps": 12390000, "per_episode_reward": -157.26, "episode_reward_trend_value": 0.019036927857117626, "biggest_recent_change": 0.24732553512171762},
{"total_number_of_episodes": 12400, "number_of_timesteps": 12400000, "per_episode_reward": -157.14, "episode_reward_trend_value": 0.01803740094958673, "biggest_recent_change": 0.24732553512171762},
{"total_number_of_episodes": 12410, "number_of_timesteps": 12410000, "per_episode_reward": -157.03, "episode_reward_trend_value": 0.01732074439548891, "biggest_recent_change": 0.24732553512171762},
{"total_number_of_episodes": 12420, "number_of_timesteps": 12420000, "per_episode_reward": -156.94, "episode_reward_trend_value": 0.016304030059747752, "biggest_recent_change": 0.24732553512171762},
{"total_number_of_episodes": 12430, "number_of_timesteps": 12430000, "per_episode_reward": -156.85, "episode_reward_trend_value": 0.015593700598345273, "biggest_recent_change": 0.24732553512171762},
{"total_number_of_episodes": 12440, "number_of_timesteps": 12440000, "per_episode_reward": -156.67, "episode_reward_trend_value": 0.015898658408889647, "biggest_recent_change": 0.24732553512171762},
{"total_number_of_episodes": 12450, "number_of_timesteps": 12450000, "per_episode_reward": -156.49, "episode_reward_trend_value": 0.01515548964591239, "biggest_recent_change": 0.22801903175025018},
{"total_number_of_episodes": 12460, "number_of_timesteps": 12460000, "per_episode_reward": -156.22, "episode_reward_trend_value": 0.015633300205843487, "biggest_recent_change": 0.27102198214404893},
{"total_number_of_episodes": 12470, "number_of_timesteps": 12470000, "per_episode_reward": -155.78, "episode_reward_trend_value": 0.01848045094127334, "biggest_recent_change": 0.4386565536208309},
{"total_number_of_episodes": 12480, "number_of_timesteps": 12480000, "per_episode_reward": -155.63, "episode_reward_trend_value": 0.01809505644062502, "biggest_recent_change": 0.4386565536208309},
{"total_number_of_episodes": 12490, "number_of_timesteps": 12490000, "per_episode_reward": -155.27, "episode_reward_trend_value": 0.020823076185971307, "biggest_recent_change": 0.4386565536208309},
{"total_number_of_episodes": 12500, "number_of_timesteps": 12500000, "per_episode_reward": -154.98, "episode_reward_trend_value": 0.022782297689351104, "biggest_recent_change": 0.4386565536208309},
{"total_number_of_episodes": 12510, "number_of_timesteps": 12510000, "per_episode_reward": -154.69, "episode_reward_trend_value": 0.02504157697437361, "biggest_recent_change": 0.4386565536208309},
{"total_number_of_episodes": 12520, "number_of_timesteps": 12520000, "per_episode_reward": -154.66, "episode_reward_trend_value": 0.02428335286346434, "biggest_recent_change": 0.4386565536208309},
{"total_number_of_episodes": 12530, "number_of_timesteps": 12530000, "per_episode_reward": -154.56, "episode_reward_trend_value": 0.02345790806501403, "biggest_recent_change": 0.4386565536208309},
{"total_number_of_episodes": 12540, "number_of_timesteps": 12540000, "per_episode_reward": -154.38, "episode_reward_trend_value": 0.02345668179083494, "biggest_recent_change": 0.4386565536208309},
{"total_number_of_episodes": 12550, "number_of_timesteps": 12550000, "per_episode_reward": -154.2, "episode_reward_trend_value": 0.02244899289787428, "biggest_recent_change": 0.4386565536208309},
{"total_number_of_episodes": 12560, "number_of_timesteps": 12560000, "per_episode_reward": -153.9, "episode_reward_trend_value": 0.020877905831356555, "biggest_recent_change": 0.3615914694076423},
{"total_number_of_episodes": 12570, "number_of_timesteps": 12570000, "per_episode_reward": -153.71, "episode_reward_trend_value": 0.021345101483815496, "biggest_recent_change": 0.3615914694076423},
{"total_number_of_episodes": 12580, "number_of_timesteps": 12580000, "per_episode_reward": -153.46, "episode_reward_trend_value": 0.020159917074814064, "biggest_recent_change": 0.29725871763423584},
{"total_number_of_episodes": 12590, "number_of_timesteps": 12590000, "per_episode_reward": -153.2, "episode_reward_trend_value": 0.019743530907778802, "biggest_recent_change": 0.29725871763423584},
{"total_number_of_episodes": 12600, "number_of_timesteps": 12600000, "per_episode_reward": -153.0, "episode_reward_trend_value": 0.018758636249224185, "biggest_recent_change": 0.29725871763423584},
{"total_number_of_episodes": 12610, "number_of_timesteps": 12610000, "per_episode_reward": -152.79, "episode_reward_trend_value": 0.020791244986601974, "biggest_recent_change": 0.29725871763423584},
{"total_number_of_episodes": 12620, "number_of_timesteps": 12620000, "per_episode_reward": -152.52, "episode_reward_trend_value": 0.022646244991601824, "biggest_recent_change": 0.29725871763423584},
{"total_number_of_episodes": 12630, "number_of_timesteps": 12630000, "per_episode_reward": -152.25, "episode_reward_trend_value": 0.023677026472330137, "biggest_recent_change": 0.29725871763423584},
{"total_number_of_episodes": 12640, "number_of_timesteps": 12640000, "per_episode_reward": -152.06, "episode_reward_trend_value": 0.02371033005223732, "biggest_recent_change": 0.29725871763423584},
{"total_number_of_episodes": 12650, "number_of_timesteps": 12650000, "per_episode_reward": -151.88, "episode_reward_trend_value": 0.022444425455959226, "biggest_recent_change": 0.27310031504319454},
{"total_number_of_episodes": 12660, "number_of_timesteps": 12660000, "per_episode_reward": -151.41, "episode_reward_trend_value": 0.025576033246932185, "biggest_recent_change": 0.4716197922826666},
{"total_number_of_episodes": 12670, "number_of_timesteps": 12670000, "per_episode_reward": -151.21, "episode_reward_trend_value": 0.02493535466076714, "biggest_recent_change": 0.4716197922826666},
{"total_number_of_episodes": 12680, "number_of_timesteps": 12680000, "per_episode_reward": -151.02, "episode_reward_trend_value": 0.024189426994160435, "biggest_recent_change": 0.4716197922826666},
{"total_number_of_episodes": 12690, "number_of_timesteps": 12690000, "per_episode_reward": -150.86, "episode_reward_trend_value": 0.023721802292210884, "biggest_recent_change": 0.4716197922826666},
{"total_number_of_episodes": 12700, "number_of_timesteps": 12700000, "per_episode_reward": -150.66, "episode_reward_trend_value": 0.023757653598799937, "biggest_recent_change": 0.4716197922826666},
{"total_number_of_episodes": 12710, "number_of_timesteps": 12710000, "per_episode_reward": -150.45, "episode_reward_trend_value": 0.023023047053361424, "biggest_recent_change": 0.4716197922826666},
{"total_number_of_episodes": 12720, "number_of_timesteps": 12720000, "per_episode_reward": -150.24, "episode_reward_trend_value": 0.022277913620712613, "biggest_recent_change": 0.4716197922826666},
{"total_number_of_episodes": 12730, "number_of_timesteps": 12730000, "per_episode_reward": -150.04, "episode_reward_trend_value": 0.022530258088885566, "biggest_recent_change": 0.4716197922826666},
{"total_number_of_episodes": 12740, "number_of_timesteps": 12740000, "per_episode_reward": -149.89, "episode_reward_trend_value": 0.0220635838803067, "biggest_recent_change": 0.4716197922826666},
{"total_number_of_episodes": 12750, "number_of_timesteps": 12750000, "per_episode_reward": -149.75, "episode_reward_trend_value": 0.018393659801577655, "biggest_recent_change": 0.20698572595372866},
{"total_number_of_episodes": 12760, "number_of_timesteps": 12760000, "per_episode_reward": -149.5, "episode_reward_trend_value": 0.019062162253392027, "biggest_recent_change": 0.2574290205059526},
{"total_number_of_episodes": 12770, "number_of_timesteps": 12770000, "per_episode_reward": -149.24, "episode_reward_trend_value": 0.019835913785648054, "biggest_recent_change": 0.2574290205059526},
{"total_number_of_episodes": 12780, "number_of_timesteps": 12780000, "per_episode_reward": -148.91, "episode_reward_trend_value": 0.021696401800282514, "biggest_recent_change": 0.3291168065023271},
{"total_number_of_episodes": 12790, "number_of_timesteps": 12790000, "per_episode_reward": -148.58, "episode_reward_trend_value": 0.023053413806377737, "biggest_recent_change": 0.3291168065023271},
{"total_number_of_episodes": 12800, "number_of_timesteps": 12800000, "per_episode_reward": -148.18, "episode_reward_trend_value": 0.025158126699455212, "biggest_recent_change": 0.3964098863306731},
{"total_number_of_episodes": 12810, "number_of_timesteps": 12810000, "per_episode_reward": -147.79, "episode_reward_trend_value": 0.02727336647974299, "biggest_recent_change": 0.3964098863307015},
{"total_number_of_episodes": 12820, "number_of_timesteps": 12820000, "per_episode_reward": -147.5, "episode_reward_trend_value": 0.028162334850052973, "biggest_recent_change": 0.3964098863307015},
{"total_number_of_episodes": 12830, "number_of_timesteps": 12830000, "per_episode_reward": -147.22, "episode_reward_trend_value": 0.029770321897114132, "biggest_recent_change": 0.3964098863307015},
{"total_number_of_episodes": 12840, "number_of_timesteps": 12840000, "per_episode_reward": -146.9, "episode_reward_trend_value": 0.03166879694174283, "biggest_recent_change": 0.3964098863307015},
{"total_number_of_episodes": 12850, "number_of_timesteps": 12850000, "per_episode_reward": -146.72, "episode_reward_trend_value": 0.030806907034486623, "biggest_recent_change": 0.3964098863307015},
{"total_number_of_episodes": 12860, "number_of_timesteps": 12860000, "per_episode_reward": -146.57, "episode_reward_trend_value": 0.029678588771055402, "biggest_recent_change": 0.3964098863307015},
{"total_number_of_episodes": 12870, "number_of_timesteps": 12870000, "per_episode_reward": -146.41, "episode_reward_trend_value": 0.027753739552109226, "biggest_recent_change": 0.3964098863307015},
{"total_number_of_episodes": 12880, "number_of_timesteps": 12880000, "per_episode_reward": -146.3, "episode_reward_trend_value": 0.02535461199912656, "biggest_recent_change": 0.3964098863307015},
{"total_number_of_episodes": 12890, "number_of_timesteps": 12890000, "per_episode_reward": -146.19, "episode_reward_trend_value": 0.02220778355916227, "biggest_recent_change": 0.3964098863307015},
{"total_number_of_episodes": 12900, "number_of_timesteps": 12900000, "per_episode_reward": -146.03, "episode_reward_trend_value": 0.019524488266558317, "biggest_recent_change": 0.31218937921363477},
{"total_number_of_episodes": 12910, "number_of_timesteps": 12910000, "per_episode_reward": -145.89, "episode_reward_trend_value": 0.017956394360969817, "biggest_recent_change": 0.31218937921363477},
{"total_number_of_episodes": 12920, "number_of_timesteps": 12920000, "per_episode_reward": -145.66, "episode_reward_trend_value": 0.01723366849068826, "biggest_recent_change": 0.31218937921363477},
{"total_number_of_episodes": 12930, "number_of_timesteps": 12930000, "per_episode_reward": -145.44, "episode_reward_trend_value": 0.016220454622839813, "biggest_recent_change": 0.22100013110727446},
{"total_number_of_episodes": 12940, "number_of_timesteps": 12940000, "per_episode_reward": -145.23, "episode_reward_trend_value": 0.016593711118744636, "biggest_recent_change": 0.22100013110727446},
{"total_number_of_episodes": 12950, "number_of_timesteps": 12950000, "per_episode_reward": -145.02, "episode_reward_trend_value": 0.01723339597082511, "biggest_recent_change": 0.22100013110727446},
{"total_number_of_episodes": 12960, "number_of_timesteps": 12960000, "per_episode_reward": -144.89, "episode_reward_trend_value": 0.016867535294369733, "biggest_recent_change": 0.22100013110727446},
{"total_number_of_episodes": 12970, "number_of_timesteps": 12970000, "per_episode_reward": -144.77, "episode_reward_trend_value": 0.016975952951951475, "biggest_recent_change": 0.22100013110727446},
{"total_number_of_episodes": 12980, "number_of_timesteps": 12980000, "per_episode_reward": -144.61, "episode_reward_trend_value": 0.017463002542297407, "biggest_recent_change": 0.22100013110727446},
{"total_number_of_episodes": 12990, "number_of_timesteps": 12990000, "per_episode_reward": -144.46, "episode_reward_trend_value": 0.017486518985282373, "biggest_recent_change": 0.22100013110727446},
{"total_number_of_episodes": 13000, "number_of_timesteps": 13000000, "per_episode_reward": -144.16, "episode_reward_trend_value": 0.019171762883107134, "biggest_recent_change": 0.2965889587339632},
{"total_number_of_episodes": 13010, "number_of_timesteps": 13010000, "per_episode_reward": -143.86, "episode_reward_trend_value": 0.0200116387456259, "biggest_recent_change": 0.2965889587339632},
{"total_number_of_episodes": 13020, "number_of_timesteps": 13020000, "per_episode_reward": -143.68, "episode_reward_trend_value": 0.019562081801895677, "biggest_recent_change": 0.2965889587339632},
{"total_number_of_episodes": 13030, "number_of_timesteps": 13030000, "per_episode_reward": -143.5, "episode_reward_trend_value": 0.01919639283175343, "biggest_recent_change": 0.2965889587339632},
{"total_number_of_episodes": 13040, "number_of_timesteps": 13040000, "per_episode_reward": -143.23, "episode_reward_trend_value": 0.01985324818078501, "biggest_recent_change": 0.2965889587339632},
{"total_number_of_episodes": 13050, "number_of_timesteps": 13050000, "per_episode_reward": -142.96, "episode_reward_trend_value": 0.02151564905835212, "biggest_recent_change": 0.2965889587339632},
{"total_number_of_episodes": 13060, "number_of_timesteps": 13060000, "per_episode_reward": -142.8, "episode_reward_trend_value": 0.02185260466600975, "biggest_recent_change": 0.2965889587339632},
{"total_number_of_episodes": 13070, "number_of_timesteps": 13070000, "per_episode_reward": -142.65, "episode_reward_trend_value": 0.02181092834090287, "biggest_recent_change": 0.2965889587339632},
{"total_number_of_episodes": 13080, "number_of_timesteps": 13080000, "per_episode_reward": -142.46, "episode_reward_trend_value": 0.02222147944367489, "biggest_recent_change": 0.2965889587339632},
{"total_number_of_episodes": 13090, "number_of_timesteps": 13090000, "per_episode_reward": -142.26, "episode_reward_trend_value": 0.021081373114569462, "biggest_recent_change": 0.2965889587339632},
{"total_number_of_episodes": 13100, "number_of_timesteps": 13100000, "per_episode_reward": -142.02, "episode_reward_trend_value": 0.02051358374593077, "biggest_recent_change": 0.2725689948972274},
{"total_number_of_episodes": 13110, "number_of_timesteps": 13110000, "per_episode_reward": -141.77, "episode_reward_trend_value": 0.021235227183541067, "biggest_recent_change": 0.2725689948972274},
{"total_number_of_episodes": 13120, "number_of_timesteps": 13120000, "per_episode_reward": -141.49, "episode_reward_trend_value": 0.022339753827624046, "biggest_recent_change": 0.2799474041389942},
{"total_number_of_episodes": 13130, "number_of_timesteps": 13130000, "per_episode_reward": -141.21, "episode_reward_trend_value": 0.022421736152532568, "biggest_recent_change": 0.2799474041389942},
{"total_number_of_episodes": 13140, "number_of_timesteps": 13140000, "per_episode_reward": -140.96, "episode_reward_trend_value": 0.022175713279141796, "biggest_recent_change": 0.2799474041389942},
{"total_number_of_episodes": 13150, "number_of_timesteps": 13150000, "per_episode_reward": -140.71, "episode_reward_trend_value": 0.023255135675659882, "biggest_recent_change": 0.2799474041389942},
{"total_number_of_episodes": 13160, "number_of_timesteps": 13160000, "per_episode_reward": -140.49, "episode_reward_trend_value": 0.023972463621067655, "biggest_recent_change": 0.2799474041389942},
{"total_number_of_episodes": 13170, "number_of_timesteps": 13170000, "per_episode_reward": -140.28, "episode_reward_trend_value": 0.02423756413859653, "biggest_recent_change": 0.2799474041389942},
{"total_number_of_episodes": 13180, "number_of_timesteps": 13180000, "per_episode_reward": -140.09, "episode_reward_trend_value": 0.024098295236410334, "biggest_recent_change": 0.2799474041389942},
{"total_number_of_episodes": 13190, "number_of_timesteps": 13190000, "per_episode_reward": -139.91, "episode_reward_trend_value": 0.023386709373757083, "biggest_recent_change": 0.2799474041389942},
{"total_number_of_episodes": 13200, "number_of_timesteps": 13200000, "per_episode_reward": -139.56, "episode_reward_trend_value": 0.02452414938230005, "biggest_recent_change": 0.3478575163253481},
{"total_number_of_episodes": 13210, "number_of_timesteps": 13210000, "per_episode_reward": -138.87, "episode_reward_trend_value": 0.029175085924267326, "biggest_recent_change": 0.698531692916049},
{"total_number_of_episodes": 13220, "number_of_timesteps": 13220000, "per_episode_reward": -138.66, "episode_reward_trend_value": 0.028367008412117735, "biggest_recent_change": 0.698531692916049},
{"total_number_of_episodes": 13230, "number_of_timesteps": 13230000, "per_episode_reward": -138.45, "episode_reward_trend_value": 0.02788693609826775, "biggest_recent_change": 0.698531692916049},
{"total_number_of_episodes": 13240, "number_of_timesteps": 13240000, "per_episode_reward": -138.22, "episode_reward_trend_value": 0.02766985931918321, "biggest_recent_change": 0.698531692916049},
{"total_number_of_episodes": 13250, "number_of_timesteps": 13250000, "per_episode_reward": -137.99, "episode_reward_trend_value": 0.027814876991208985, "biggest_recent_change": 0.698531692916049},
{"total_number_of_episodes": 13260, "number_of_timesteps": 13260000, "per_episode_reward": -137.68, "episode_reward_trend_value": 0.028870485492723218, "biggest_recent_change": 0.698531692916049},
{"total_number_of_episodes": 13270, "number_of_timesteps": 13270000, "per_episode_reward": -137.36, "episode_reward_trend_value": 0.03033046341395252, "biggest_recent_change": 0.698531692916049},
{"total_number_of_episodes": 13280, "number_of_timesteps": 13280000, "per_episode_reward": -137.22, "episode_reward_trend_value": 0.029868489452529602, "biggest_recent_change": 0.698531692916049},
{"total_number_of_episodes": 13290, "number_of_timesteps": 13290000, "per_episode_reward": -137.17, "episode_reward_trend_value": 0.02663189184185815, "biggest_recent_change": 0.698531692916049},
{"total_number_of_episodes": 13300, "number_of_timesteps": 13300000, "per_episode_reward": -137.0, "episode_reward_trend_value": 0.02072124919082575, "biggest_recent_change": 0.31284320082835393},
{"total_number_of_episodes": 13310, "number_of_timesteps": 13310000, "per_episode_reward": -136.83, "episode_reward_trend_value": 0.020269620593911165, "biggest_recent_change": 0.31284320082835393},
{"total_number_of_episodes": 13320, "number_of_timesteps": 13320000, "per_episode_reward": -136.59, "episode_reward_trend_value": 0.020731411436162896, "biggest_recent_change": 0.31284320082835393},
{"total_number_of_episodes": 13330, "number_of_timesteps": 13330000, "per_episode_reward": -136.34, "episode_reward_trend_value": 0.020930206743649173, "biggest_recent_change": 0.31284320082835393},
{"total_number_of_episodes": 13340, "number_of_timesteps": 13340000, "per_episode_reward": -136.0, "episode_reward_trend_value": 0.022062598790984427, "biggest_recent_change": 0.33280531043459405},
{"total_number_of_episodes": 13350, "number_of_timesteps": 13350000, "per_episode_reward": -135.67, "episode_reward_trend_value": 0.022284400008831855, "biggest_recent_change": 0.33280531043462247},
{"total_number_of_episodes": 13360, "number_of_timesteps": 13360000, "per_episode_reward": -135.27, "episode_reward_trend_value": 0.02326337233648985, "biggest_recent_change": 0.40095071031757357},
{"total_number_of_episodes": 13370, "number_of_timesteps": 13370000, "per_episode_reward": -134.87, "episode_reward_trend_value": 0.02616429654680069, "biggest_recent_change": 0.400950710317602},
{"total_number_of_episodes": 13380, "number_of_timesteps": 13380000, "per_episode_reward": -134.58, "episode_reward_trend_value": 0.028731647530075732, "biggest_recent_change": 0.400950710317602},
{"total_number_of_episodes": 13390, "number_of_timesteps": 13390000, "per_episode_reward": -134.14, "episode_reward_trend_value": 0.03174789325459086, "biggest_recent_change": 0.4380359695294942},
{"total_number_of_episodes": 13400, "number_of_timesteps": 13400000, "per_episode_reward": -133.89, "episode_reward_trend_value": 0.03269730230611919, "biggest_recent_change": 0.4380359695294942},
{"total_number_of_episodes": 13410, "number_of_timesteps": 13410000, "per_episode_reward": -133.64, "episode_reward_trend_value": 0.03273329191848152, "biggest_recent_change": 0.4380359695294942},
{"total_number_of_episodes": 13420, "number_of_timesteps": 13420000, "per_episode_reward": -133.51, "episode_reward_trend_value": 0.031459547849983796, "biggest_recent_change": 0.4380359695294942},
{"total_number_of_episodes": 13430, "number_of_timesteps": 13430000, "per_episode_reward": -133.28, "episode_reward_trend_value": 0.03030815497557171, "biggest_recent_change": 0.4380359695294942},
{"total_number_of_episodes": 13440, "number_of_timesteps": 13440000, "per_episode_reward": -133.19, "episode_reward_trend_value": 0.02757364125850567, "biggest_recent_change": 0.4380359695294942},
{"total_number_of_episodes": 13450, "number_of_timesteps": 13450000, "per_episode_reward": -133.1, "episode_reward_trend_value": 0.024081956431628745, "biggest_recent_change": 0.4380359695294942},
{"total_number_of_episodes": 13460, "number_of_timesteps": 13460000, "per_episode_reward": -132.95, "episode_reward_trend_value": 0.02127623537367135, "biggest_recent_change": 0.4380359695294942},
{"total_number_of_episodes": 13470, "number_of_timesteps": 13470000, "per_episode_reward": -132.81, "episode_reward_trend_value": 0.01972968532080238, "biggest_recent_change": 0.4380359695294942},
{"total_number_of_episodes": 13480, "number_of_timesteps": 13480000, "per_episode_reward": -132.73, "episode_reward_trend_value": 0.01575499162693335, "biggest_recent_change": 0.2520206689608244},
{"total_number_of_episodes": 13490, "number_of_timesteps": 13490000, "per_episode_reward": -132.58, "episode_reward_trend_value": 0.014568425290280138, "biggest_recent_change": 0.2520206689608244},
{"total_number_of_episodes": 13500, "number_of_timesteps": 13500000, "per_episode_reward": -132.46, "episode_reward_trend_value": 0.01314927860053798, "biggest_recent_change": 0.22917995173750683},
{"total_number_of_episodes": 13510, "number_of_timesteps": 13510000, "per_episode_reward": -132.27, "episode_reward_trend_value": 0.013761156275885847, "biggest_recent_change": 0.22917995173750683},
{"total_number_of_episodes": 13520, "number_of_timesteps": 13520000, "per_episode_reward": -132.09, "episode_reward_trend_value": 0.013197328543625986, "biggest_recent_change": 0.18921362846469947},
{"total_number_of_episodes": 13530, "number_of_timesteps": 13530000, "per_episode_reward": -131.91, "episode_reward_trend_value": 0.014216621654019454, "biggest_recent_change": 0.18921362846469947},
{"total_number_of_episodes": 13540, "number_of_timesteps": 13540000, "per_episode_reward": -131.63, "episode_reward_trend_value": 0.016356055802024923, "biggest_recent_change": 0.27924814921914276},
{"total_number_of_episodes": 13550, "number_of_timesteps": 13550000, "per_episode_reward": -131.35, "episode_reward_trend_value": 0.017809526181110237, "biggest_recent_change": 0.27924814921914276},
{"total_number_of_episodes": 13560, "number_of_timesteps": 13560000, "per_episode_reward": -131.24, "episode_reward_trend_value": 0.017434457497609263, "biggest_recent_change": 0.27924814921914276},
{"total_number_of_episodes": 13570, "number_of_timesteps": 13570000, "per_episode_reward": -131.09, "episode_reward_trend_value": 0.018149596913956303, "biggest_recent_change": 0.27924814921914276},
{"total_number_of_episodes": 13580, "number_of_timesteps": 13580000, "per_episode_reward": -131.0, "episode_reward_trend_value": 0.017545086382897857, "biggest_recent_change": 0.27924814921914276},
{"total_number_of_episodes": 13590, "number_of_timesteps": 13590000, "per_episode_reward": -130.83, "episode_reward_trend_value": 0.018093899780749705, "biggest_recent_change": 0.27924814921914276},
{"total_number_of_episodes": 13600, "number_of_timesteps": 13600000, "per_episode_reward": -130.7, "episode_reward_trend_value": 0.017418042134400163, "biggest_recent_change": 0.27924814921914276},
{"total_number_of_episodes": 13610, "number_of_timesteps": 13610000, "per_episode_reward": -130.57, "episode_reward_trend_value": 0.016861941961724053, "biggest_recent_change": 0.27924814921914276},
{"total_number_of_episodes": 13620, "number_of_timesteps": 13620000, "per_episode_reward": -130.33, "episode_reward_trend_value": 0.017521608186837373, "biggest_recent_change": 0.27924814921914276},
{"total_number_of_episodes": 13630, "number_of_timesteps": 13630000, "per_episode_reward": -130.08, "episode_reward_trend_value": 0.01724951435534226, "biggest_recent_change": 0.27924814921911434},
{"total_number_of_episodes": 13640, "number_of_timesteps": 13640000, "per_episode_reward": -129.95, "episode_reward_trend_value": 0.015539175476149896, "biggest_recent_change": 0.2547597043845826},
{"total_number_of_episodes": 13650, "number_of_timesteps": 13650000, "per_episode_reward": -129.81, "episode_reward_trend_value": 0.015845756640547076, "biggest_recent_change": 0.2547597043845826},
{"total_number_of_episodes": 13660, "number_of_timesteps": 13660000, "per_episode_reward": -129.66, "episode_reward_trend_value": 0.015959534411369544, "biggest_recent_change": 0.2547597043845826},
{"total_number_of_episodes": 13670, "number_of_timesteps": 13670000, "per_episode_reward": -129.5, "episode_reward_trend_value": 0.016671671445367527, "biggest_recent_change": 0.2547597043845826},
{"total_number_of_episodes": 13680, "number_of_timesteps": 13680000, "per_episode_reward": -129.29, "episode_reward_trend_value": 0.017090037367936853, "biggest_recent_change": 0.2547597043845826},
{"total_number_of_episodes": 13690, "number_of_timesteps": 13690000, "per_episode_reward": -129.08, "episode_reward_trend_value": 0.018011783650478227, "biggest_recent_change": 0.2547597043845826},
{"total_number_of_episodes": 13700, "number_of_timesteps": 13700000, "per_episode_reward": -128.75, "episode_reward_trend_value": 0.020215733361658293, "biggest_recent_change": 0.3267419142994754},
{"total_number_of_episodes": 13710, "number_of_timesteps": 13710000, "per_episode_reward": -128.42, "episode_reward_trend_value": 0.021203916675048933, "biggest_recent_change": 0.3267419142994754},
{"total_number_of_episodes": 13720, "number_of_timesteps": 13720000, "per_episode_reward": -128.2, "episode_reward_trend_value": 0.020817935996423228, "biggest_recent_change": 0.3267419142994754},
{"total_number_of_episodes": 13730, "number_of_timesteps": 13730000, "per_episode_reward": -127.97, "episode_reward_trend_value": 0.022017869714146817, "biggest_recent_change": 0.3267419142994754},
{"total_number_of_episodes": 13740, "number_of_timesteps": 13740000, "per_episode_reward": -127.7, "episode_reward_trend_value": 0.023443237821038406, "biggest_recent_change": 0.3267419142994754},
{"total_number_of_episodes": 13750, "number_of_timesteps": 13750000, "per_episode_reward": -127.43, "episode_reward_trend_value": 0.024728115421880956, "biggest_recent_change": 0.3267419142994754},
{"total_number_of_episodes": 13760, "number_of_timesteps": 13760000, "per_episode_reward": -127.19, "episode_reward_trend_value": 0.02565751619462762, "biggest_recent_change": 0.3267419142994754},
{"total_number_of_episodes": 13770, "number_of_timesteps": 13770000, "per_episode_reward": -126.89, "episode_reward_trend_value": 0.026663982344109473, "biggest_recent_change": 0.3267419142994754},
{"total_number_of_episodes": 13780, "number_of_timesteps": 13780000, "per_episode_reward": -126.67, "episode_reward_trend_value": 0.02677503498577873, "biggest_recent_change": 0.3267419142994754},
{"total_number_of_episodes": 13790, "number_of_timesteps": 13790000, "per_episode_reward": -126.45, "episode_reward_trend_value": 0.0256038841988085, "biggest_recent_change": 0.326741914299447},
{"total_number_of_episodes": 13800, "number_of_timesteps": 13800000, "per_episode_reward": -126.32, "episode_reward_trend_value": 0.02335718596651538, "biggest_recent_change": 0.3019255591753023},
{"total_number_of_episodes": 13810, "number_of_timesteps": 13810000, "per_episode_reward": -126.2, "episode_reward_trend_value": 0.022296270745235346, "biggest_recent_change": 0.3019255591753023},
{"total_number_of_episodes": 13820, "number_of_timesteps": 13820000, "per_episode_reward": -126.05, "episode_reward_trend_value": 0.02133073961635748, "biggest_recent_change": 0.3019255591753023},
{"total_number_of_episodes": 13830, "number_of_timesteps": 13830000, "per_episode_reward": -125.91, "episode_reward_trend_value": 0.019951393117308036, "biggest_recent_change": 0.3019255591753023},
{"total_number_of_episodes": 13840, "number_of_timesteps": 13840000, "per_episode_reward": -125.61, "episode_reward_trend_value": 0.020171731206093092, "biggest_recent_change": 0.3019255591753023},
{"total_number_of_episodes": 13850, "number_of_timesteps": 13850000, "per_episode_reward": -125.32, "episode_reward_trend_value": 0.020747546122974036, "biggest_recent_change": 0.3019255591753023},
{"total_number_of_episodes": 13860, "number_of_timesteps": 13860000, "per_episode_reward": -125.21, "episode_reward_trend_value": 0.018623736568462355, "biggest_recent_change": 0.29038549599302144},
{"total_number_of_episodes": 13870, "number_of_timesteps": 13870000, "per_episode_reward": -125.09, "episode_reward_trend_value": 0.017500674217931098, "biggest_recent_change": 0.29038549599302144},
{"total_number_of_episodes": 13880, "number_of_timesteps": 13880000, "per_episode_reward": -124.89, "episode_reward_trend_value": 0.01731569673789516, "biggest_recent_change": 0.29038549599302144},
{"total_number_of_episodes": 13890, "number_of_timesteps": 13890000, "per_episode_reward": -124.68, "episode_reward_trend_value": 0.018206266703182906, "biggest_recent_change": 0.29038549599302144},
{"total_number_of_episodes": 13900, "number_of_timesteps": 13900000, "per_episode_reward": -124.65, "episode_reward_trend_value": 0.01720940977623826, "biggest_recent_change": 0.29038549599302144},
{"total_number_of_episodes": 13910, "number_of_timesteps": 13910000, "per_episode_reward": -124.5, "episode_reward_trend_value": 0.0172464504121998, "biggest_recent_change": 0.29038549599302144},
{"total_number_of_episodes": 13920, "number_of_timesteps": 13920000, "per_episode_reward": -124.25, "episode_reward_trend_value": 0.0183925996371831, "biggest_recent_change": 0.29038549599302144},
{"total_number_of_episodes": 13930, "number_of_timesteps": 13930000, "per_episode_reward": -124.0, "episode_reward_trend_value": 0.017939064274331902, "biggest_recent_change": 0.29038549599302144},
{"total_number_of_episodes": 13940, "number_of_timesteps": 13940000, "per_episode_reward": -123.92, "episode_reward_trend_value": 0.015638510136914224, "biggest_recent_change": 0.24956731333641358},
{"total_number_of_episodes": 13950, "number_of_timesteps": 13950000, "per_episode_reward": -123.83, "episode_reward_trend_value": 0.015429097211867632, "biggest_recent_change": 0.24956731333641358},
{"total_number_of_episodes": 13960, "number_of_timesteps": 13960000, "per_episode_reward": -123.56, "episode_reward_trend_value": 0.017091336052971133, "biggest_recent_change": 0.26986422762369955},
{"total_number_of_episodes": 13970, "number_of_timesteps": 13970000, "per_episode_reward": -123.29, "episode_reward_trend_value": 0.017815490023580103, "biggest_recent_change": 0.26986422762372797},
{"total_number_of_episodes": 13980, "number_of_timesteps": 13980000, "per_episode_reward": -123.04, "episode_reward_trend_value": 0.018307114142025207, "biggest_recent_change": 0.26986422762372797},
{"total_number_of_episodes": 13990, "number_of_timesteps": 13990000, "per_episode_reward": -122.79, "episode_reward_trend_value": 0.020686165152702708, "biggest_recent_change": 0.26986422762372797},
{"total_number_of_episodes": 14000, "number_of_timesteps": 14000000, "per_episode_reward": -122.65, "episode_reward_trend_value": 0.02056734028725218, "biggest_recent_change": 0.26986422762372797},
{"total_number_of_episodes": 14010, "number_of_timesteps": 14010000, "per_episode_reward": -122.51, "episode_reward_trend_value": 0.01933940683278005, "biggest_recent_change": 0.26986422762372797},
{"total_number_of_episodes": 14020, "number_of_timesteps": 14020000, "per_episode_reward": -122.24, "episode_reward_trend_value": 0.019507548005191843, "biggest_recent_change": 0.26986422762372797},
{"total_number_of_episodes": 14030, "number_of_timesteps": 14030000, "per_episode_reward": -121.98, "episode_reward_trend_value": 0.021522707952170587, "biggest_recent_change": 0.26986422762372797},
{"total_number_of_episodes": 14040, "number_of_timesteps": 14040000, "per_episode_reward": -121.33, "episode_reward_trend_value": 0.02769556252822254, "biggest_recent_change": 0.647492447859733},
{"total_number_of_episodes": 14050, "number_of_timesteps": 14050000, "per_episode_reward": -120.69, "episode_reward_trend_value": 0.03189143164195608, "biggest_recent_change": 0.647492447859733},
{"total_number_of_episodes": 14060, "number_of_timesteps": 14060000, "per_episode_reward": -120.54, "episode_reward_trend_value": 0.03050536395852706, "biggest_recent_change": 0.647492447859733},
{"total_number_of_episodes": 14070, "number_of_timesteps": 14070000, "per_episode_reward": -120.39, "episode_reward_trend_value": 0.02935182612726142, "biggest_recent_change": 0.647492447859733},
{"total_number_of_episodes": 14080, "number_of_timesteps": 14080000, "per_episode_reward": -120.22, "episode_reward_trend_value": 0.0284900334024987, "biggest_recent_change": 0.647492447859733},
{"total_number_of_episodes": 14090, "number_of_timesteps": 14090000, "per_episode_reward": -120.05, "episode_reward_trend_value": 0.028849165549903612, "biggest_recent_change": 0.647492447859733},
{"total_number_of_episodes": 14100, "number_of_timesteps": 14100000, "per_episode_reward": -119.85, "episode_reward_trend_value": 0.029528672425984344, "biggest_recent_change": 0.647492447859733},
{"total_number_of_episodes": 14110, "number_of_timesteps": 14110000, "per_episode_reward": -119.65, "episode_reward_trend_value": 0.028812104675181315, "biggest_recent_change": 0.647492447859733},
{"total_number_of_episodes": 14120, "number_of_timesteps": 14120000, "per_episode_reward": -119.41, "episode_reward_trend_value": 0.028581533256576742, "biggest_recent_change": 0.647492447859733},
{"total_number_of_episodes": 14130, "number_of_timesteps": 14130000, "per_episode_reward": -119.16, "episode_reward_trend_value": 0.024097712626792146, "biggest_recent_change": 0.6474924478597188},
{"total_number_of_episodes": 14140, "number_of_timesteps": 14140000, "per_episode_reward": -118.87, "episode_reward_trend_value": 0.02020833934337437, "biggest_recent_change": 0.2974488523521188},
{"total_number_of_episodes": 14150, "number_of_timesteps": 14150000, "per_episode_reward": -118.57, "episode_reward_trend_value": 0.021900902857118532, "biggest_recent_change": 0.2974488523521188},
{"total_number_of_episodes": 14160, "number_of_timesteps": 14160000, "per_episode_reward": -118.45, "episode_reward_trend_value": 0.021608313914798317, "biggest_recent_change": 0.2974488523521188},
{"total_number_of_episodes": 14170, "number_of_timesteps": 14170000, "per_episode_reward": -118.33, "episode_reward_trend_value": 0.021023979865975505, "biggest_recent_change": 0.2974488523521188},
{"total_number_of_episodes": 14180, "number_of_timesteps": 14180000, "per_episode_reward": -118.15, "episode_reward_trend_value": 0.02113204020292269, "biggest_recent_change": 0.2974488523521188},
{"total_number_of_episodes": 14190, "number_of_timesteps": 14190000, "per_episode_reward": -117.97, "episode_reward_trend_value": 0.020919725811194053, "biggest_recent_change": 0.2974488523521188},
{"total_number_of_episodes": 14200, "number_of_timesteps": 14200000, "per_episode_reward": -117.78, "episode_reward_trend_value": 0.020759415412488616, "biggest_recent_change": 0.2974488523521188},
{"total_number_of_episodes": 14210, "number_of_timesteps": 14210000, "per_episode_reward": -117.6, "episode_reward_trend_value": 0.020113108681584575, "biggest_recent_change": 0.2974488523521188},
{"total_number_of_episodes": 14220, "number_of_timesteps": 14220000, "per_episode_reward": -117.33, "episode_reward_trend_value": 0.020339417003926975, "biggest_recent_change": 0.2974488523521188},
{"total_number_of_episodes": 14230, "number_of_timesteps": 14230000, "per_episode_reward": -117.07, "episode_reward_trend_value": 0.01997127797990288, "biggest_recent_change": 0.2974488523520904},
{"total_number_of_episodes": 14240, "number_of_timesteps": 14240000, "per_episode_reward": -116.88, "episode_reward_trend_value": 0.018751547173226236, "biggest_recent_change": 0.26431634018995},
{"total_number_of_episodes": 14250, "number_of_timesteps": 14250000, "per_episode_reward": -116.69, "episode_reward_trend_value": 0.01951696882261413, "biggest_recent_change": 0.26431634018995},
{"total_number_of_episodes": 14260, "number_of_timesteps": 14260000, "per_episode_reward": -116.34, "episode_reward_trend_value": 0.022131406685891225, "biggest_recent_change": 0.35408453900126347},
{"total_number_of_episodes": 14270, "number_of_timesteps": 14270000, "per_episode_reward": -115.99, "episode_reward_trend_value": 0.02405345016339879, "biggest_recent_change": 0.3540845390012777},
{"total_number_of_episodes": 14280, "number_of_timesteps": 14280000, "per_episode_reward": -115.73, "episode_reward_trend_value": 0.0248614236763288, "biggest_recent_change": 0.3540845390012777},
{"total_number_of_episodes": 14290, "number_of_timesteps": 14290000, "per_episode_reward": -115.48, "episode_reward_trend_value": 0.025617393196235443, "biggest_recent_change": 0.3540845390012777},
{"total_number_of_episodes": 14300, "number_of_timesteps": 14300000, "per_episode_reward": -115.2, "episode_reward_trend_value": 0.026605104840093614, "biggest_recent_change": 0.3540845390012777},
{"total_number_of_episodes": 14310, "number_of_timesteps": 14310000, "per_episode_reward": -114.45, "episode_reward_trend_value": 0.03198651605787717, "biggest_recent_change": 0.7486433497904557},
{"total_number_of_episodes": 14320, "number_of_timesteps": 14320000, "per_episode_reward": -114.15, "episode_reward_trend_value": 0.03247950052306202, "biggest_recent_change": 0.7486433497904557},
{"total_number_of_episodes": 14330, "number_of_timesteps": 14330000, "per_episode_reward": -113.84, "episode_reward_trend_value": 0.033824076770899734, "biggest_recent_change": 0.7486433497904557},
{"total_number_of_episodes": 14340, "number_of_timesteps": 14340000, "per_episode_reward": -113.53, "episode_reward_trend_value": 0.03516059080229247, "biggest_recent_change": 0.7486433497904557},
{"total_number_of_episodes": 14350, "number_of_timesteps": 14350000, "per_episode_reward": -113.22, "episode_reward_trend_value": 0.03464808861979489, "biggest_recent_change": 0.7486433497904557},
{"total_number_of_episodes": 14360, "number_of_timesteps": 14360000, "per_episode_reward": -112.9, "episode_reward_trend_value": 0.03425711176601346, "biggest_recent_change": 0.7486433497904557},
{"total_number_of_episodes": 14370, "number_of_timesteps": 14370000, "per_episode_reward": -112.58, "episode_reward_trend_value": 0.03498020487680943, "biggest_recent_change": 0.7486433497904557},
{"total_number_of_episodes": 14380, "number_of_timesteps": 14380000, "per_episode_reward": -112.31, "episode_reward_trend_value": 0.03518382683134276, "biggest_recent_change": 0.7486433497904557},
{"total_number_of_episodes": 14390, "number_of_timesteps": 14390000, "per_episode_reward": -112.2, "episode_reward_trend_value": 0.033406450480114966, "biggest_recent_change": 0.7486433497904557},
{"total_number_of_episodes": 14400, "number_of_timesteps": 14400000, "per_episode_reward": -112.05, "episode_reward_trend_value": 0.026706545718309688, "biggest_recent_change": 0.31889662216094905},
{"total_number_of_episodes": 14410, "number_of_timesteps": 14410000, "per_episode_reward": -112.03, "episode_reward_trend_value": 0.023475416532903796, "biggest_recent_change": 0.31889662216094905},
{"total_number_of_episodes": 14420, "number_of_timesteps": 14420000, "per_episode_reward": -111.61, "episode_reward_trend_value": 0.024721159021108483, "biggest_recent_change": 0.42080176599500874},
{"total_number_of_episodes": 14430, "number_of_timesteps": 14430000, "per_episode_reward": -111.19, "episode_reward_trend_value": 0.025974963725758, "biggest_recent_change": 0.42080176599500874},
{"total_number_of_episodes": 14440, "number_of_timesteps": 14440000, "per_episode_reward": -110.83, "episode_reward_trend_value": 0.026540190236688625, "biggest_recent_change": 0.42080176599500874},
{"total_number_of_episodes": 14450, "number_of_timesteps": 14450000, "per_episode_reward": -110.47, "episode_reward_trend_value": 0.02698389141890247, "biggest_recent_change": 0.42080176599500874},
{"total_number_of_episodes": 14460, "number_of_timesteps": 14460000, "per_episode_reward": -110.06, "episode_reward_trend_value": 0.027999378640644085, "biggest_recent_change": 0.42080176599500874},
{"total_number_of_episodes": 14470, "number_of_timesteps": 14470000, "per_episode_reward": -109.65, "episode_reward_trend_value": 0.0295343370186482, "biggest_recent_change": 0.42080176599500874},
{"total_number_of_episodes": 14480, "number_of_timesteps": 14480000, "per_episode_reward": -109.36, "episode_reward_trend_value": 0.031476226094768515, "biggest_recent_change": 0.42080176599500874},
{"total_number_of_episodes": 14490, "number_of_timesteps": 14490000, "per_episode_reward": -109.07, "episode_reward_trend_value": 0.033074328954294505, "biggest_recent_change": 0.42080176599500874},
{"total_number_of_episodes": 14500, "number_of_timesteps": 14500000, "per_episode_reward": -108.76, "episode_reward_trend_value": 0.036328329971905125, "biggest_recent_change": 0.42080176599500874},
{"total_number_of_episodes": 14510, "number_of_timesteps": 14510000, "per_episode_reward": -108.45, "episode_reward_trend_value": 0.03510545931590501, "biggest_recent_change": 0.42080176599500874},
{"total_number_of_episodes": 14520, "number_of_timesteps": 14520000, "per_episode_reward": -108.27, "episode_reward_trend_value": 0.032439661059309954, "biggest_recent_change": 0.4102904721176941},
{"total_number_of_episodes": 14530, "number_of_timesteps": 14530000, "per_episode_reward": -108.09, "episode_reward_trend_value": 0.03046244099643458, "biggest_recent_change": 0.4102904721176941},
{"total_number_of_episodes": 14540, "number_of_timesteps": 14540000, "per_episode_reward": -107.86, "episode_reward_trend_value": 0.029046584277468274, "biggest_recent_change": 0.4102904721176941},
{"total_number_of_episodes": 14550, "number_of_timesteps": 14550000, "per_episode_reward": -107.63, "episode_reward_trend_value": 0.027058941518974523, "biggest_recent_change": 0.4102904721176799},
{"total_number_of_episodes": 14560, "number_of_timesteps": 14560000, "per_episode_reward": -107.36, "episode_reward_trend_value": 0.025500332702207452, "biggest_recent_change": 0.31074340695501235},
{"total_number_of_episodes": 14570, "number_of_timesteps": 14570000, "per_episode_reward": -107.09, "episode_reward_trend_value": 0.025284049369133123, "biggest_recent_change": 0.31074340695501235},
{"total_number_of_episodes": 14580, "number_of_timesteps": 14580000, "per_episode_reward": -106.99, "episode_reward_trend_value": 0.023134599460796483, "biggest_recent_change": 0.31074340695501235},
{"total_number_of_episodes": 14590, "number_of_timesteps": 14590000, "per_episode_reward": -106.9, "episode_reward_trend_value": 0.020748902570574046, "biggest_recent_change": 0.31074340695499814},
{"total_number_of_episodes": 14600, "number_of_timesteps": 14600000, "per_episode_reward": -106.43, "episode_reward_trend_value": 0.022444923092250553, "biggest_recent_change": 0.4633852539058836},
{"total_number_of_episodes": 14610, "number_of_timesteps": 14610000, "per_episode_reward": -105.97, "episode_reward_trend_value": 0.025583871214521676, "biggest_recent_change": 0.4633852539058836},
{"total_number_of_episodes": 14620, "number_of_timesteps": 14620000, "per_episode_reward": -105.55, "episode_reward_trend_value": 0.028205400466261056, "biggest_recent_change": 0.4633852539058836},
{"total_number_of_episodes": 14630, "number_of_timesteps": 14630000, "per_episode_reward": -105.14, "episode_reward_trend_value": 0.030265566374091356, "biggest_recent_change": 0.4633852539058836},
{"total_number_of_episodes": 14640, "number_of_timesteps": 14640000, "per_episode_reward": -104.78, "episode_reward_trend_value": 0.031662541082588466, "biggest_recent_change": 0.4633852539058836},
{"total_number_of_episodes": 14650, "number_of_timesteps": 14650000, "per_episode_reward": -104.42, "episode_reward_trend_value": 0.03263048184935889, "biggest_recent_change": 0.4633852539058836},
{"total_number_of_episodes": 14660, "number_of_timesteps": 14660000, "per_episode_reward": -104.22, "episode_reward_trend_value": 0.03182198791186437, "biggest_recent_change": 0.4633852539058836},
{"total_number_of_episodes": 14670, "number_of_timesteps": 14670000, "per_episode_reward": -104.03, "episode_reward_trend_value": 0.032946660549632155, "biggest_recent_change": 0.4633852539058836},
{"total_number_of_episodes": 14680, "number_of_timesteps": 14680000, "per_episode_reward": -103.65, "episode_reward_trend_value": 0.03601694741052042, "biggest_recent_change": 0.4633852539058836},
{"total_number_of_episodes": 14690, "number_of_timesteps": 14690000, "per_episode_reward": -103.28, "episode_reward_trend_value": 0.035005516859509735, "biggest_recent_change": 0.46338525390585517},
{"total_number_of_episodes": 14700, "number_of_timesteps": 14700000, "per_episode_reward": -103.14, "episode_reward_trend_value": 0.0314793111633757, "biggest_recent_change": 0.4168175555579978},
{"total_number_of_episodes": 14710, "number_of_timesteps": 14710000, "per_episode_reward": -102.99, "episode_reward_trend_value": 0.028445161190462427, "biggest_recent_change": 0.4168175555579552},
{"total_number_of_episodes": 14720, "number_of_timesteps": 14720000, "per_episode_reward": -102.9, "episode_reward_trend_value": 0.024871978884781733, "biggest_recent_change": 0.3723565043149364},
{"total_number_of_episodes": 14730, "number_of_timesteps": 14730000, "per_episode_reward": -102.8, "episode_reward_trend_value": 0.021961987778433924, "biggest_recent_change": 0.3723565043149364},
{"total_number_of_episodes": 14740, "number_of_timesteps": 14740000, "per_episode_reward": -102.47, "episode_reward_trend_value": 0.02169356368635612, "biggest_recent_change": 0.3723565043149364},
{"total_number_of_episodes": 14750, "number_of_timesteps": 14750000, "per_episode_reward": -102.14, "episode_reward_trend_value": 0.023201574298543904, "biggest_recent_change": 0.3723565043149364},
{"total_number_of_episodes": 14760, "number_of_timesteps": 14760000, "per_episode_reward": -101.92, "episode_reward_trend_value": 0.023433085411405822, "biggest_recent_change": 0.3723565043149364},
{"total_number_of_episodes": 14770, "number_of_timesteps": 14770000, "per_episode_reward": -101.7, "episode_reward_trend_value": 0.021718982301147584, "biggest_recent_change": 0.3723565043149222},
{"total_number_of_episodes": 14780, "number_of_timesteps": 14780000, "per_episode_reward": -101.47, "episode_reward_trend_value": 0.02009891551661364, "biggest_recent_change": 0.33297217933100853},
{"total_number_of_episodes": 14790, "number_of_timesteps": 14790000, "per_episode_reward": -101.25, "episode_reward_trend_value": 0.020993623877203365, "biggest_recent_change": 0.33297217933100853},
{"total_number_of_episodes": 14800, "number_of_timesteps": 14800000, "per_episode_reward": -101.05, "episode_reward_trend_value": 0.021585407131042365, "biggest_recent_change": 0.33297217933100853},
{"total_number_of_episodes": 14810, "number_of_timesteps": 14810000, "per_episode_reward": -100.85, "episode_reward_trend_value": 0.02271622271764926, "biggest_recent_change": 0.33297217933100853},
{"total_number_of_episodes": 14820, "number_of_timesteps": 14820000, "per_episode_reward": -100.71, "episode_reward_trend_value": 0.023293237451965217, "biggest_recent_change": 0.33297217933100853},
{"total_number_of_episodes": 14830, "number_of_timesteps": 14830000, "per_episode_reward": -100.56, "episode_reward_trend_value": 0.021228685172011, "biggest_recent_change": 0.33297217933100853},
{"total_number_of_episodes": 14840, "number_of_timesteps": 14840000, "per_episode_reward": -100.18, "episode_reward_trend_value": 0.021755574762465497, "biggest_recent_change": 0.3803922424719133},
{"total_number_of_episodes": 14850, "number_of_timesteps": 14850000, "per_episode_reward": -99.8, "episode_reward_trend_value": 0.02355896385224554, "biggest_recent_change": 0.3803922424719133},
{"total_number_of_episodes": 14860, "number_of_timesteps": 14860000, "per_episode_reward": -99.42, "episode_reward_trend_value": 0.025297995746528874, "biggest_recent_change": 0.3803922424719133},
{"total_number_of_episodes": 14870, "number_of_timesteps": 14870000, "per_episode_reward": -99.27, "episode_reward_trend_value": 0.02445567633140655, "biggest_recent_change": 0.3803922424719133},
{"total_number_of_episodes": 14880, "number_of_timesteps": 14880000, "per_episode_reward": -98.95, "episode_reward_trend_value": 0.025492818097151038, "biggest_recent_change": 0.3803922424719133},
{"total_number_of_episodes": 14890, "number_of_timesteps": 14890000, "per_episode_reward": -98.63, "episode_reward_trend_value": 0.026858248116957067, "biggest_recent_change": 0.3803922424719133},
{"total_number_of_episodes": 14900, "number_of_timesteps": 14900000, "per_episode_reward": -98.49, "episode_reward_trend_value": 0.026219652534310474, "biggest_recent_change": 0.3803922424719133},
{"total_number_of_episodes": 14910, "number_of_timesteps": 14910000, "per_episode_reward": -98.35, "episode_reward_trend_value": 0.02613485780395482, "biggest_recent_change": 0.3803922424719133},
{"total_number_of_episodes": 14920, "number_of_timesteps": 14920000, "per_episode_reward": -98.07, "episode_reward_trend_value": 0.027661849276471327, "biggest_recent_change": 0.3803922424719133},
{"total_number_of_episodes": 14930, "number_of_timesteps": 14930000, "per_episode_reward": -97.78, "episode_reward_trend_value": 0.02659739887857897, "biggest_recent_change": 0.38039224247189907},
{"total_number_of_episodes": 14940, "number_of_timesteps": 14940000, "per_episode_reward": -97.55, "episode_reward_trend_value": 0.025007197825930267, "biggest_recent_change": 0.37460009487719503},
{"total_number_of_episodes": 14950, "number_of_timesteps": 14950000, "per_episode_reward": -97.31, "episode_reward_trend_value": 0.023481353968778113, "biggest_recent_change": 0.3198932526238707},
{"total_number_of_episodes": 14960, "number_of_timesteps": 14960000, "per_episode_reward": -97.01, "episode_reward_trend_value": 0.02518897315705778, "biggest_recent_change": 0.3198932526238707},
{"total_number_of_episodes": 14970, "number_of_timesteps": 14970000, "per_episode_reward": -96.7, "episode_reward_trend_value": 0.025017131164470796, "biggest_recent_change": 0.3198932526238565},
{"total_number_of_episodes": 14980, "number_of_timesteps": 14980000, "per_episode_reward": -96.43, "episode_reward_trend_value": 0.024466242574993025, "biggest_recent_change": 0.30442747329104236},
{"total_number_of_episodes": 14990, "number_of_timesteps": 14990000, "per_episode_reward": -96.16, "episode_reward_trend_value": 0.02591937958796788, "biggest_recent_change": 0.30442747329104236},
{"total_number_of_episodes": 15000, "number_of_timesteps": 15000000, "per_episode_reward": -95.93, "episode_reward_trend_value": 0.026977736543076957, "biggest_recent_change": 0.30442747329104236},
{"total_number_of_episodes": 15010, "number_of_timesteps": 15010000, "per_episode_reward": -95.69, "episode_reward_trend_value": 0.026424307295314187, "biggest_recent_change": 0.30442747329104236},
{"total_number_of_episodes": 15020, "number_of_timesteps": 15020000, "per_episode_reward": -95.36, "episode_reward_trend_value": 0.026979179201701543, "biggest_recent_change": 0.3345301782364629},
{"total_number_of_episodes": 15030, "number_of_timesteps": 15030000, "per_episode_reward": -95.02, "episode_reward_trend_value": 0.028059801762845244, "biggest_recent_change": 0.3345301782364629},
{"total_number_of_episodes": 15040, "number_of_timesteps": 15040000, "per_episode_reward": -94.64, "episode_reward_trend_value": 0.029613734352554388, "biggest_recent_change": 0.3771280808073243},
{"total_number_of_episodes": 15050, "number_of_timesteps": 15050000, "per_episode_reward": -94.27, "episode_reward_trend_value": 0.030421518880513077, "biggest_recent_change": 0.3771280808073243},
{"total_number_of_episodes": 15060, "number_of_timesteps": 15060000, "per_episode_reward": -94.08, "episode_reward_trend_value": 0.02906442846413613, "biggest_recent_change": 0.3771280808073243},
{"total_number_of_episodes": 15070, "number_of_timesteps": 15070000, "per_episode_reward": -93.9, "episode_reward_trend_value": 0.028086384644649815, "biggest_recent_change": 0.3771280808073243},
{"total_number_of_episodes": 15080, "number_of_timesteps": 15080000, "per_episode_reward": -93.6, "episode_reward_trend_value": 0.02844213145027415, "biggest_recent_change": 0.3771280808073243},
{"total_number_of_episodes": 15090, "number_of_timesteps": 15090000, "per_episode_reward": -93.3, "episode_reward_trend_value": 0.029192658313764257, "biggest_recent_change": 0.3771280808073243},
{"total_number_of_episodes": 15100, "number_of_timesteps": 15100000, "per_episode_reward": -93.06, "episode_reward_trend_value": 0.029183734999299004, "biggest_recent_change": 0.3771280808073243},
{"total_number_of_episodes": 15110, "number_of_timesteps": 15110000, "per_episode_reward": -92.83, "episode_reward_trend_value": 0.02806651053068347, "biggest_recent_change": 0.3771280808073243},
{"total_number_of_episodes": 15120, "number_of_timesteps": 15120000, "per_episode_reward": -92.58, "episode_reward_trend_value": 0.027124409244540005, "biggest_recent_change": 0.3771280808073243},
{"total_number_of_episodes": 15130, "number_of_timesteps": 15130000, "per_episode_reward": -92.33, "episode_reward_trend_value": 0.025708997929831095, "biggest_recent_change": 0.3771280808073101},
{"total_number_of_episodes": 15140, "number_of_timesteps": 15140000, "per_episode_reward": -92.14, "episode_reward_trend_value": 0.023636911202520296, "biggest_recent_change": 0.3023304920770471},
{"total_number_of_episodes": 15150, "number_of_timesteps": 15150000, "per_episode_reward": -91.95, "episode_reward_trend_value": 0.023729699419544975, "biggest_recent_change": 0.3023304920770471},
{"total_number_of_episodes": 15160, "number_of_timesteps": 15160000, "per_episode_reward": -91.57, "episode_reward_trend_value": 0.02590875157119225, "biggest_recent_change": 0.3784040294653437},
{"total_number_of_episodes": 15170, "number_of_timesteps": 15170000, "per_episode_reward": -91.19, "episode_reward_trend_value": 0.026754013097728725, "biggest_recent_change": 0.3784040294653437},
{"total_number_of_episodes": 15180, "number_of_timesteps": 15180000, "per_episode_reward": -90.71, "episode_reward_trend_value": 0.028796254600872512, "biggest_recent_change": 0.4861322273599882},
{"total_number_of_episodes": 15190, "number_of_timesteps": 15190000, "per_episode_reward": -90.22, "episode_reward_trend_value": 0.03159794628197119, "biggest_recent_change": 0.4861322273599882},
{"total_number_of_episodes": 15200, "number_of_timesteps": 15200000, "per_episode_reward": -89.94, "episode_reward_trend_value": 0.03216109841449284, "biggest_recent_change": 0.4861322273599882},
{"total_number_of_episodes": 15210, "number_of_timesteps": 15210000, "per_episode_reward": -89.65, "episode_reward_trend_value": 0.03254912736454227, "biggest_recent_change": 0.4861322273599882},
{"total_number_of_episodes": 15220, "number_of_timesteps": 15220000, "per_episode_reward": -89.46, "episode_reward_trend_value": 0.031843759096374276, "biggest_recent_change": 0.4861322273599882},
{"total_number_of_episodes": 15230, "number_of_timesteps": 15230000, "per_episode_reward": -89.24, "episode_reward_trend_value": 0.032219795378045216, "biggest_recent_change": 0.4861322273599882},
{"total_number_of_episodes": 15240, "number_of_timesteps": 15240000, "per_episode_reward": -89.11, "episode_reward_trend_value": 0.031593821868986696, "biggest_recent_change": 0.4861322273599882},
{"total_number_of_episodes": 15250, "number_of_timesteps": 15250000, "per_episode_reward": -88.97, "episode_reward_trend_value": 0.028866011528772145, "biggest_recent_change": 0.4861322273599882},
{"total_number_of_episodes": 15260, "number_of_timesteps": 15260000, "per_episode_reward": -88.49, "episode_reward_trend_value": 0.030026765749429453, "biggest_recent_change": 0.4861322273599882},
{"total_number_of_episodes": 15270, "number_of_timesteps": 15270000, "per_episode_reward": -88.01, "episode_reward_trend_value": 0.029990539993479597, "biggest_recent_change": 0.48613222735994555},
{"total_number_of_episodes": 15280, "number_of_timesteps": 15280000, "per_episode_reward": -87.77, "episode_reward_trend_value": 0.02724536883741848, "biggest_recent_change": 0.4828719093245013},
{"total_number_of_episodes": 15290, "number_of_timesteps": 15290000, "per_episode_reward": -87.53, "episode_reward_trend_value": 0.026738737229934233, "biggest_recent_change": 0.4828719093245013},
{"total_number_of_episodes": 15300, "number_of_timesteps": 15300000, "per_episode_reward": -87.25, "episode_reward_trend_value": 0.026623436037514457, "biggest_recent_change": 0.4828719093245013},
{"total_number_of_episodes": 15310, "number_of_timesteps": 15310000, "per_episode_reward": -86.98, "episode_reward_trend_value": 0.027601532063312107, "biggest_recent_change": 0.4828719093245013},
{"total_number_of_episodes": 15320, "number_of_timesteps": 15320000, "per_episode_reward": -86.77, "episode_reward_trend_value": 0.02739344650848763, "biggest_recent_change": 0.4828719093245013},
{"total_number_of_episodes": 15330, "number_of_timesteps": 15330000, "per_episode_reward": -86.57, "episode_reward_trend_value": 0.02818737074439276, "biggest_recent_change": 0.4828719093245013},
{"total_number_of_episodes": 15340, "number_of_timesteps": 15340000, "per_episode_reward": -86.23, "episode_reward_trend_value": 0.030440795891097928, "biggest_recent_change": 0.4828719093245013},
{"total_number_of_episodes": 15350, "number_of_timesteps": 15350000, "per_episode_reward": -85.9, "episode_reward_trend_value": 0.028805656476931396, "biggest_recent_change": 0.4828719093245013},
{"total_number_of_episodes": 15360, "number_of_timesteps": 15360000, "per_episode_reward": -85.65, "episode_reward_trend_value": 0.02620251533896657, "biggest_recent_change": 0.3357093620494993},
{"total_number_of_episodes": 15370, "number_of_timesteps": 15370000, "per_episode_reward": -85.4, "episode_reward_trend_value": 0.026308319601113007, "biggest_recent_change": 0.3357093620494993},
{"total_number_of_episodes": 15380, "number_of_timesteps": 15380000, "per_episode_reward": -85.07, "episode_reward_trend_value": 0.02729609087820866, "biggest_recent_change": 0.3357093620494993},
{"total_number_of_episodes": 15390, "number_of_timesteps": 15390000, "per_episode_reward": -84.74, "episode_reward_trend_value": 0.027892531740240478, "biggest_recent_change": 0.3357093620494993},
{"total_number_of_episodes": 15400, "number_of_timesteps": 15400000, "per_episode_reward": -84.34, "episode_reward_trend_value": 0.029379695822625406, "biggest_recent_change": 0.4081313280848349},
{"total_number_of_episodes": 15410, "number_of_timesteps": 15410000, "per_episode_reward": -83.76, "episode_reward_trend_value": 0.03352445527346583, "biggest_recent_change": 0.5787841913411569},
{"total_number_of_episodes": 15420, "number_of_timesteps": 15420000, "per_episode_reward": -83.45, "episode_reward_trend_value": 0.034687273342543457, "biggest_recent_change": 0.5787841913411569},
{"total_number_of_episodes": 15430, "number_of_timesteps": 15430000, "per_episode_reward": -83.13, "episode_reward_trend_value": 0.03446942589878369, "biggest_recent_change": 0.5787841913411569},
{"total_number_of_episodes": 15440, "number_of_timesteps": 15440000, "per_episode_reward": -82.88, "episode_reward_trend_value": 0.033527306192095804, "biggest_recent_change": 0.5787841913411569},
{"total_number_of_episodes": 15450, "number_of_timesteps": 15450000, "per_episode_reward": -82.63, "episode_reward_trend_value": 0.03355318820920606, "biggest_recent_change": 0.5787841913411569},
{"total_number_of_episodes": 15460, "number_of_timesteps": 15460000, "per_episode_reward": -82.21, "episode_reward_trend_value": 0.03540420095231174, "biggest_recent_change": 0.5787841913411569},
{"total_number_of_episodes": 15470, "number_of_timesteps": 15470000, "per_episode_reward": -81.8, "episode_reward_trend_value": 0.0363732466804682, "biggest_recent_change": 0.5787841913411569},
{"total_number_of_episodes": 15480, "number_of_timesteps": 15480000, "per_episode_reward": -81.35, "episode_reward_trend_value": 0.037746922148759805, "biggest_recent_change": 0.5787841913411569},
{"total_number_of_episodes": 15490, "number_of_timesteps": 15490000, "per_episode_reward": -80.9, "episode_reward_trend_value": 0.03814216660881537, "biggest_recent_change": 0.5787841913411569},
{"total_number_of_episodes": 15500, "number_of_timesteps": 15500000, "per_episode_reward": -80.72, "episode_reward_trend_value": 0.03374396872726398, "biggest_recent_change": 0.45159703039931287},
{"total_number_of_episodes": 15510, "number_of_timesteps": 15510000, "per_episode_reward": -80.69, "episode_reward_trend_value": 0.030595858788489416, "biggest_recent_change": 0.45159703039931287},
{"total_number_of_episodes": 15520, "number_of_timesteps": 15520000, "per_episode_reward": -80.28, "episode_reward_trend_value": 0.03172158429509453, "biggest_recent_change": 0.45159703039931287},
{"total_number_of_episodes": 15530, "number_of_timesteps": 15530000, "per_episode_reward": -79.86, "episode_reward_trend_value": 0.03357158206462745, "biggest_recent_change": 0.45159703039931287},
{"total_number_of_episodes": 15540, "number_of_timesteps": 15540000, "per_episode_reward": -79.65, "episode_reward_trend_value": 0.03305693577280017, "biggest_recent_change": 0.45159703039931287},
{"total_number_of_episodes": 15550, "number_of_timesteps": 15550000, "per_episode_reward": -79.47, "episode_reward_trend_value": 0.030515481687941003, "biggest_recent_change": 0.45159703039931287},
{"total_number_of_episodes": 15560, "number_of_timesteps": 15560000, "per_episode_reward": -79.18, "episode_reward_trend_value": 0.02911619995153924, "biggest_recent_change": 0.45159703039931287},
{"total_number_of_episodes": 15570, "number_of_timesteps": 15570000, "per_episode_reward": -78.89, "episode_reward_trend_value": 0.0273122884750017, "biggest_recent_change": 0.4437033294898356},
{"total_number_of_episodes": 15580, "number_of_timesteps": 15580000, "per_episode_reward": -78.48, "episode_reward_trend_value": 0.026895738817947445, "biggest_recent_change": 0.41741838770558104},
{"total_number_of_episodes": 15590, "number_of_timesteps": 15590000, "per_episode_reward": -78.08, "episode_reward_trend_value": 0.02937648857743006, "biggest_recent_change": 0.41741838770558104},
{"total_number_of_episodes": 15600, "number_of_timesteps": 15600000, "per_episode_reward": -77.75, "episode_reward_trend_value": 0.032691518611453474, "biggest_recent_change": 0.41741838770558104},
{"total_number_of_episodes": 15610, "number_of_timesteps": 15610000, "per_episode_reward": -77.43, "episode_reward_trend_value": 0.03166945069866848, "biggest_recent_change": 0.4174183877055526},
{"total_number_of_episodes": 15620, "number_of_timesteps": 15620000, "per_episode_reward": -77.31, "episode_reward_trend_value": 0.028291293812342782, "biggest_recent_change": 0.406213860354967},
{"total_number_of_episodes": 15630, "number_of_timesteps": 15630000, "per_episode_reward": -77.2, "episode_reward_trend_value": 0.027277780987377452, "biggest_recent_change": 0.406213860354967},
{"total_number_of_episodes": 15640, "number_of_timesteps": 15640000, "per_episode_reward": -77.01, "episode_reward_trend_value": 0.027294618124608407, "biggest_recent_change": 0.406213860354967},
{"total_number_of_episodes": 15650, "number_of_timesteps": 15650000, "per_episode_reward": -76.82, "episode_reward_trend_value": 0.026169282913381962, "biggest_recent_change": 0.406213860354967},
{"total_number_of_episodes": 15660, "number_of_timesteps": 15660000, "per_episode_reward": -76.5, "episode_reward_trend_value": 0.026525009399987847, "biggest_recent_change": 0.406213860354967},
{"total_number_of_episodes": 15670, "number_of_timesteps": 15670000, "per_episode_reward": -76.18, "episode_reward_trend_value": 0.025581081854993533, "biggest_recent_change": 0.406213860354967},
{"total_number_of_episodes": 15680, "number_of_timesteps": 15680000, "per_episode_reward": -75.76, "episode_reward_trend_value": 0.025720361770844136, "biggest_recent_change": 0.4187490527815214},
{"total_number_of_episodes": 15690, "number_of_timesteps": 15690000, "per_episode_reward": -75.34, "episode_reward_trend_value": 0.0267572148511399, "biggest_recent_change": 0.4187490527815356},
{"total_number_of_episodes": 15700, "number_of_timesteps": 15700000, "per_episode_reward": -75.07, "episode_reward_trend_value": 0.026194905545291802, "biggest_recent_change": 0.4187490527815356},
{"total_number_of_episodes": 15710, "number_of_timesteps": 15710000, "per_episode_reward": -74.79, "episode_reward_trend_value": 0.027988685212984876, "biggest_recent_change": 0.4187490527815356},
{"total_number_of_episodes": 15720, "number_of_timesteps": 15720000, "per_episode_reward": -74.49, "episode_reward_trend_value": 0.03006908299619384, "biggest_recent_change": 0.4187490527815356},
{"total_number_of_episodes": 15730, "number_of_timesteps": 15730000, "per_episode_reward": -74.19, "episode_reward_trend_value": 0.03132080788424361, "biggest_recent_change": 0.4187490527815356},
{"total_number_of_episodes": 15740, "number_of_timesteps": 15740000, "per_episode_reward": -73.95, "episode_reward_trend_value": 0.03196461666146241, "biggest_recent_change": 0.4187490527815356},
{"total_number_of_episodes": 15750, "number_of_timesteps": 15750000, "per_episode_reward": -73.7, "episode_reward_trend_value": 0.031127363740849033, "biggest_recent_change": 0.4187490527815356},
{"total_number_of_episodes": 15760, "number_of_timesteps": 15760000, "per_episode_reward": -73.44, "episode_reward_trend_value": 0.03048844679531315, "biggest_recent_change": 0.4187490527815356},
{"total_number_of_episodes": 15770, "number_of_timesteps": 15770000, "per_episode_reward": -73.17, "episode_reward_trend_value": 0.028766322388931877, "biggest_recent_change": 0.4187490527815356},
{"total_number_of_episodes": 15780, "number_of_timesteps": 15780000, "per_episode_reward": -72.83, "episode_reward_trend_value": 0.02791156942942242, "biggest_recent_change": 0.34182128642568443},
{"total_number_of_episodes": 15790, "number_of_timesteps": 15790000, "per_episode_reward": -72.49, "episode_reward_trend_value": 0.02865597885605666, "biggest_recent_change": 0.34182128642568443},
{"total_number_of_episodes": 15800, "number_of_timesteps": 15800000, "per_episode_reward": -72.28, "episode_reward_trend_value": 0.02793627969495181, "biggest_recent_change": 0.34182128642568443},
{"total_number_of_episodes": 15810, "number_of_timesteps": 15810000, "per_episode_reward": -72.07, "episode_reward_trend_value": 0.026929962418331066, "biggest_recent_change": 0.34182128642568443},
{"total_number_of_episodes": 15820, "number_of_timesteps": 15820000, "per_episode_reward": -71.72, "episode_reward_trend_value": 0.02748384484467247, "biggest_recent_change": 0.35046948679580225},
{"total_number_of_episodes": 15830, "number_of_timesteps": 15830000, "per_episode_reward": -71.37, "episode_reward_trend_value": 0.02864564338184484, "biggest_recent_change": 0.35046948679580225},
{"total_number_of_episodes": 15840, "number_of_timesteps": 15840000, "per_episode_reward": -71.07, "episode_reward_trend_value": 0.029266871258183374, "biggest_recent_change": 0.35046948679580225},
{"total_number_of_episodes": 15850, "number_of_timesteps": 15850000, "per_episode_reward": -70.91, "episode_reward_trend_value": 0.02811736033649655, "biggest_recent_change": 0.35046948679580225},
{"total_number_of_episodes": 15860, "number_of_timesteps": 15860000, "per_episode_reward": -70.34, "episode_reward_trend_value": 0.03150446054862041, "biggest_recent_change": 0.5685968752983541},
{"total_number_of_episodes": 15870, "number_of_timesteps": 15870000, "per_episode_reward": -69.77, "episode_reward_trend_value": 0.03402418931387245, "biggest_recent_change": 0.5685968752983683},
{"total_number_of_episodes": 15880, "number_of_timesteps": 15880000, "per_episode_reward": -69.44, "episode_reward_trend_value": 0.033911057529407644, "biggest_recent_change": 0.5685968752983683},
{"total_number_of_episodes": 15890, "number_of_timesteps": 15890000, "per_episode_reward": -69.11, "episode_reward_trend_value": 0.03526203433268146, "biggest_recent_change": 0.5685968752983683},
{"total_number_of_episodes": 15900, "number_of_timesteps": 15900000, "per_episode_reward": -68.98, "episode_reward_trend_value": 0.034376542838487484, "biggest_recent_change": 0.5685968752983683},
{"total_number_of_episodes": 15910, "number_of_timesteps": 15910000, "per_episode_reward": -68.84, "episode_reward_trend_value": 0.03193085164133088, "biggest_recent_change": 0.5685968752983683},
{"total_number_of_episodes": 15920, "number_of_timesteps": 15920000, "per_episode_reward": -68.59, "episode_reward_trend_value": 0.030819476422672666, "biggest_recent_change": 0.5685968752983683},
{"total_number_of_episodes": 15930, "number_of_timesteps": 15930000, "per_episode_reward": -68.34, "episode_reward_trend_value": 0.030248671864848593, "biggest_recent_change": 0.5685968752983683},
{"total_number_of_episodes": 15940, "number_of_timesteps": 15940000, "per_episode_reward": -67.99, "episode_reward_trend_value": 0.032393208811039007, "biggest_recent_change": 0.5685968752983683},
{"total_number_of_episodes": 15950, "number_of_timesteps": 15950000, "per_episode_reward": -67.64, "episode_reward_trend_value": 0.030001134623418895, "biggest_recent_change": 0.5685968752983683},
{"total_number_of_episodes": 15960, "number_of_timesteps": 15960000, "per_episode_reward": -67.33, "episode_reward_trend_value": 0.027048393574960826, "biggest_recent_change": 0.35331019841255795},
{"total_number_of_episodes": 15970, "number_of_timesteps": 15970000, "per_episode_reward": -67.03, "episode_reward_trend_value": 0.026728513076219762, "biggest_recent_change": 0.35331019841255795},
{"total_number_of_episodes": 15980, "number_of_timesteps": 15980000, "per_episode_reward": -66.93, "episode_reward_trend_value": 0.024131729021510118, "biggest_recent_change": 0.35331019841255795},
{"total_number_of_episodes": 15990, "number_of_timesteps": 15990000, "per_episode_reward": -66.84, "episode_reward_trend_value": 0.023771413264268425, "biggest_recent_change": 0.35331019841255795},
{"total_number_of_episodes": 16000, "number_of_timesteps": 16000000, "per_episode_reward": -66.47, "episode_reward_trend_value": 0.026353715840974068, "biggest_recent_change": 0.3627645109552162},
{"total_number_of_episodes": 16010, "number_of_timesteps": 16010000, "per_episode_reward": -66.11, "episode_reward_trend_value": 0.02760170243918133, "biggest_recent_change": 0.3627645109552162},
{"total_number_of_episodes": 16020, "number_of_timesteps": 16020000, "per_episode_reward": -65.61, "episode_reward_trend_value": 0.030332174258699735, "biggest_recent_change": 0.4961881808732187},
{"total_number_of_episodes": 16030, "number_of_timesteps": 16030000, "per_episode_reward": -65.12, "episode_reward_trend_value": 0.03191970739715104, "biggest_recent_change": 0.4961881808732187},
{"total_number_of_episodes": 16040, "number_of_timesteps": 16040000, "per_episode_reward": -64.71, "episode_reward_trend_value": 0.03255972764617812, "biggest_recent_change": 0.4961881808732187},
{"total_number_of_episodes": 16050, "number_of_timesteps": 16050000, "per_episode_reward": -64.3, "episode_reward_trend_value": 0.033760414756042995, "biggest_recent_change": 0.4961881808732187},
{"total_number_of_episodes": 16060, "number_of_timesteps": 16060000, "per_episode_reward": -63.98, "episode_reward_trend_value": 0.03394429947456372, "biggest_recent_change": 0.4961881808732187},
{"total_number_of_episodes": 16070, "number_of_timesteps": 16070000, "per_episode_reward": -63.66, "episode_reward_trend_value": 0.03640508774905334, "biggest_recent_change": 0.4961881808732187},
{"total_number_of_episodes": 16080, "number_of_timesteps": 16080000, "per_episode_reward": -63.2, "episode_reward_trend_value": 0.04040440212250268, "biggest_recent_change": 0.4961881808732187},
{"total_number_of_episodes": 16090, "number_of_timesteps": 16090000, "per_episode_reward": -62.74, "episode_reward_trend_value": 0.041461098162004995, "biggest_recent_change": 0.4961881808732187},
{"total_number_of_episodes": 16100, "number_of_timesteps": 16100000, "per_episode_reward": -62.32, "episode_reward_trend_value": 0.04213714059386733, "biggest_recent_change": 0.4961881808732187},
{"total_number_of_episodes": 16110, "number_of_timesteps": 16110000, "per_episode_reward": -62.49, "episode_reward_trend_value": 0.034711558439159754, "biggest_recent_change": 0.49618818087317607},
{"total_number_of_episodes": 16120, "number_of_timesteps": 16120000, "per_episode_reward": -62.41, "episode_reward_trend_value": 0.030077371003763176, "biggest_recent_change": 0.45786715451042426},
{"total_number_of_episodes": 16130, "number_of_timesteps": 16130000, "per_episode_reward": -62.21, "episode_reward_trend_value": 0.027729566484238903, "biggest_recent_change": 0.45786715451042426},
{"total_number_of_episodes": 16140, "number_of_timesteps": 16140000, "per_episode_reward": -61.7, "episode_reward_trend_value": 0.02882758916768837, "biggest_recent_change": 0.5097340623354327},
{"total_number_of_episodes": 16150, "number_of_timesteps": 16150000, "per_episode_reward": -61.19, "episode_reward_trend_value": 0.030942414242481675, "biggest_recent_change": 0.5097340623354327},
{"total_number_of_episodes": 16160, "number_of_timesteps": 16160000, "per_episode_reward": -60.88, "episode_reward_trend_value": 0.0309037969634343, "biggest_recent_change": 0.5097340623354327},
{"total_number_of_episodes": 16170, "number_of_timesteps": 16170000, "per_episode_reward": -60.56, "episode_reward_trend_value": 0.029326653585426892, "biggest_recent_change": 0.5097340623354327},
{"total_number_of_episodes": 16180, "number_of_timesteps": 16180000, "per_episode_reward": -60.17, "episode_reward_trend_value": 0.02854830364864035, "biggest_recent_change": 0.5097340623354327},
{"total_number_of_episodes": 16190, "number_of_timesteps": 16190000, "per_episode_reward": -59.81, "episode_reward_trend_value": 0.02784708814447272, "biggest_recent_change": 0.5097340623354327},
{"total_number_of_episodes": 16200, "number_of_timesteps": 16200000, "per_episode_reward": -59.47, "episode_reward_trend_value": 0.03356814825931601, "biggest_recent_change": 0.5097340623354327},
{"total_number_of_episodes": 16210, "number_of_timesteps": 16210000, "per_episode_reward": -59.25, "episode_reward_trend_value": 0.03512359979689926, "biggest_recent_change": 0.5097340623354327},
{"total_number_of_episodes": 16220, "number_of_timesteps": 16220000, "per_episode_reward": -58.86, "episode_reward_trend_value": 0.03726634800740314, "biggest_recent_change": 0.5097340623354327},
{"total_number_of_episodes": 16230, "number_of_timesteps": 16230000, "per_episode_reward": -58.46, "episode_reward_trend_value": 0.03596326901493335, "biggest_recent_change": 0.5097340623354185},
{"total_number_of_episodes": 16240, "number_of_timesteps": 16240000, "per_episode_reward": -58.18, "episode_reward_trend_value": 0.03347816303609861, "biggest_recent_change": 0.3924569530131521},
{"total_number_of_episodes": 16250, "number_of_timesteps": 16250000, "per_episode_reward": -57.89, "episode_reward_trend_value": 0.033146499411104535, "biggest_recent_change": 0.3924569530131521},
{"total_number_of_episodes": 16260, "number_of_timesteps": 16260000, "per_episode_reward": -57.67, "episode_reward_trend_value": 0.0321567538809266, "biggest_recent_change": 0.3924569530131521},
{"total_number_of_episodes": 16270, "number_of_timesteps": 16270000, "per_episode_reward": -57.44, "episode_reward_trend_value": 0.030368214909527718, "biggest_recent_change": 0.3924569530131521},
{"total_number_of_episodes": 16280, "number_of_timesteps": 16280000, "per_episode_reward": -57.23, "episode_reward_trend_value": 0.02866631706555975, "biggest_recent_change": 0.3924569530131521},
{"total_number_of_episodes": 16290, "number_of_timesteps": 16290000, "per_episode_reward": -57.02, "episode_reward_trend_value": 0.027161282967839484, "biggest_recent_change": 0.3924569530131521},
{"total_number_of_episodes": 16300, "number_of_timesteps": 16300000, "per_episode_reward": -56.79, "episode_reward_trend_value": 0.027323507378264368, "biggest_recent_change": 0.3924569530131521},
{"total_number_of_episodes": 16310, "number_of_timesteps": 16310000, "per_episode_reward": -56.55, "episode_reward_trend_value": 0.02568344032332348, "biggest_recent_change": 0.3924569530131521},
{"total_number_of_episodes": 16320, "number_of_timesteps": 16320000, "per_episode_reward": -56.05, "episode_reward_trend_value": 0.02687928390546727, "biggest_recent_change": 0.5000828754060933},
{"total_number_of_episodes": 16330, "number_of_timesteps": 16330000, "per_episode_reward": -55.55, "episode_reward_trend_value": 0.02925715447397618, "biggest_recent_change": 0.5000828754060933},
{"total_number_of_episodes": 16340, "number_of_timesteps": 16340000, "per_episode_reward": -55.25, "episode_reward_trend_value": 0.02940057263170625, "biggest_recent_change": 0.5000828754060933},
{"total_number_of_episodes": 16350, "number_of_timesteps": 16350000, "per_episode_reward": -54.95, "episode_reward_trend_value": 0.0302020726946201, "biggest_recent_change": 0.5000828754060933},
{"total_number_of_episodes": 16360, "number_of_timesteps": 16360000, "per_episode_reward": -54.45, "episode_reward_trend_value": 0.03321548992833867, "biggest_recent_change": 0.5000828754060933},
{"total_number_of_episodes": 16370, "number_of_timesteps": 16370000, "per_episode_reward": -53.95, "episode_reward_trend_value": 0.03644578520964754, "biggest_recent_change": 0.5000828754060933},
{"total_number_of_episodes": 16380, "number_of_timesteps": 16380000, "per_episode_reward": -53.55, "episode_reward_trend_value": 0.038659667693480455, "biggest_recent_change": 0.5000828754060933},
{"total_number_of_episodes": 16390, "number_of_timesteps": 16390000, "per_episode_reward": -53.14, "episode_reward_trend_value": 0.040580505527117734, "biggest_recent_change": 0.5000828754060933},
{"total_number_of_episodes": 16400, "number_of_timesteps": 16400000, "per_episode_reward": -52.81, "episode_reward_trend_value": 0.04152155794721339, "biggest_recent_change": 0.5000828754060933},
{"total_number_of_episodes": 16410, "number_of_timesteps": 16410000, "per_episode_reward": -52.48, "episode_reward_trend_value": 0.03962669973022438, "biggest_recent_change": 0.5000828754060933},
{"total_number_of_episodes": 16420, "number_of_timesteps": 16420000, "per_episode_reward": -52.16, "episode_reward_trend_value": 0.037590944477694815, "biggest_recent_change": 0.4980547038084069},
{"total_number_of_episodes": 16430, "number_of_timesteps": 16430000, "per_episode_reward": -51.85, "episode_reward_trend_value": 0.03778964163594441, "biggest_recent_change": 0.4980547038084069},
{"total_number_of_episodes": 16440, "number_of_timesteps": 16440000, "per_episode_reward": -51.61, "episode_reward_trend_value": 0.037098234654171905, "biggest_recent_change": 0.4980547038084069},
{"total_number_of_episodes": 16450, "number_of_timesteps": 16450000, "per_episode_reward": -51.37, "episode_reward_trend_value": 0.03419491050159486, "biggest_recent_change": 0.4980547038084069},
{"total_number_of_episodes": 16460, "number_of_timesteps": 16460000, "per_episode_reward": -50.97, "episode_reward_trend_value": 0.03314828365353719, "biggest_recent_change": 0.40657755203557144},
{"total_number_of_episodes": 16470, "number_of_timesteps": 16470000, "per_episode_reward": -50.56, "episode_reward_trend_value": 0.0331180696029554, "biggest_recent_change": 0.40657755203557144},
{"total_number_of_episodes": 16480, "number_of_timesteps": 16480000, "per_episode_reward": -50.36, "episode_reward_trend_value": 0.030838985092325227, "biggest_recent_change": 0.4038582874832173},
{"total_number_of_episodes": 16490, "number_of_timesteps": 16490000, "per_episode_reward": -50.16, "episode_reward_trend_value": 0.029415810761233906, "biggest_recent_change": 0.4038582874832173},
{"total_number_of_episodes": 16500, "number_of_timesteps": 16500000, "per_episode_reward": -49.67, "episode_reward_trend_value": 0.031202124516868046, "biggest_recent_change": 0.4903138738841548},
{"total_number_of_episodes": 16510, "number_of_timesteps": 16510000, "per_episode_reward": -49.18, "episode_reward_trend_value": 0.03312933530804282, "biggest_recent_change": 0.4903138738841619},
{"total_number_of_episodes": 16520, "number_of_timesteps": 16520000, "per_episode_reward": -48.63, "episode_reward_trend_value": 0.03576753453267038, "biggest_recent_change": 0.5543028328949404},
{"total_number_of_episodes": 16530, "number_of_timesteps": 16530000, "per_episode_reward": -48.07, "episode_reward_trend_value": 0.03929583789732018, "biggest_recent_change": 0.5543028328949475},
{"total_number_of_episodes": 16540, "number_of_timesteps": 16540000, "per_episode_reward": -47.62, "episode_reward_trend_value": 0.04167964684414211, "biggest_recent_change": 0.5543028328949475},
{"total_number_of_episodes": 16550, "number_of_timesteps": 16550000, "per_episode_reward": -47.17, "episode_reward_trend_value": 0.04220675848644472, "biggest_recent_change": 0.5543028328949475},
{"total_number_of_episodes": 16560, "number_of_timesteps": 16560000, "per_episode_reward": -46.78, "episode_reward_trend_value": 0.042091503668301146, "biggest_recent_change": 0.5543028328949475},
{"total_number_of_episodes": 16570, "number_of_timesteps": 16570000, "per_episode_reward": -46.38, "episode_reward_trend_value": 0.04422511931020586, "biggest_recent_change": 0.5543028328949475},
{"total_number_of_episodes": 16580, "number_of_timesteps": 16580000, "per_episode_reward": -45.86, "episode_reward_trend_value": 0.04779932068441294, "biggest_recent_change": 0.5543028328949475},
{"total_number_of_episodes": 16590, "number_of_timesteps": 16590000, "per_episode_reward": -45.34, "episode_reward_trend_value": 0.048164033971894483, "biggest_recent_change": 0.5543028328949475},
{"total_number_of_episodes": 16600, "number_of_timesteps": 16600000, "per_episode_reward": -45.0, "episode_reward_trend_value": 0.04641171861623145, "biggest_recent_change": 0.5543028328949475},
{"total_number_of_episodes": 16610, "number_of_timesteps": 16610000, "per_episode_reward": -44.67, "episode_reward_trend_value": 0.04394841482711508, "biggest_recent_change": 0.5543028328949475},
{"total_number_of_episodes": 16620, "number_of_timesteps": 16620000, "per_episode_reward": -44.17, "episode_reward_trend_value": 0.04338750270708687, "biggest_recent_change": 0.5231380697574934},
{"total_number_of_episodes": 16630, "number_of_timesteps": 16630000, "per_episode_reward": -43.66, "episode_reward_trend_value": 0.04397108500488629, "biggest_recent_change": 0.5231380697574934},
{"total_number_of_episodes": 16640, "number_of_timesteps": 16640000, "per_episode_reward": -43.32, "episode_reward_trend_value": 0.04274514747137038, "biggest_recent_change": 0.5231380697574934},
{"total_number_of_episodes": 16650, "number_of_timesteps": 16650000, "per_episode_reward": -42.98, "episode_reward_trend_value": 0.0421615763983009, "biggest_recent_change": 0.5231380697574934},
{"total_number_of_episodes": 16660, "number_of_timesteps": 16660000, "per_episode_reward": -42.41, "episode_reward_trend_value": 0.04414293174610838, "biggest_recent_change": 0.571807335152954},
{"total_number_of_episodes": 16670, "number_of_timesteps": 16670000, "per_episode_reward": -41.84, "episode_reward_trend_value": 0.044683701361613495, "biggest_recent_change": 0.571807335152954},
{"total_number_of_episodes": 16680, "number_of_timesteps": 16680000, "per_episode_reward": -41.51, "episode_reward_trend_value": 0.04253487992576355, "biggest_recent_change": 0.571807335152954},
{"total_number_of_episodes": 16690, "number_of_timesteps": 16690000, "per_episode_reward": -41.18, "episode_reward_trend_value": 0.0425030871330581, "biggest_recent_change": 0.571807335152954},
{"total_number_of_episodes": 16700, "number_of_timesteps": 16700000, "per_episode_reward": -40.83, "episode_reward_trend_value": 0.04266362927304878, "biggest_recent_change": 0.571807335152954},
{"total_number_of_episodes": 16710, "number_of_timesteps": 16710000, "per_episode_reward": -40.48, "episode_reward_trend_value": 0.04092177974395115, "biggest_recent_change": 0.571807335152954},
{"total_number_of_episodes": 16720, "number_of_timesteps": 16720000, "per_episode_reward": -40.12, "episode_reward_trend_value": 0.03940887360939509, "biggest_recent_change": 0.571807335152954},
{"total_number_of_episodes": 16730, "number_of_timesteps": 16730000, "per_episode_reward": -39.75, "episode_reward_trend_value": 0.0397054873061542, "biggest_recent_change": 0.571807335152954},
{"total_number_of_episodes": 16740, "number_of_timesteps": 16740000, "per_episode_reward": -39.53, "episode_reward_trend_value": 0.03834146590739011, "biggest_recent_change": 0.571807335152954},
{"total_number_of_episodes": 16750, "number_of_timesteps": 16750000, "per_episode_reward": -39.31, "episode_reward_trend_value": 0.034412518087749, "biggest_recent_change": 0.571807335152954},
{"total_number_of_episodes": 16760, "number_of_timesteps": 16760000, "per_episode_reward": -38.74, "episode_reward_trend_value": 0.034438533118232015, "biggest_recent_change": 0.5741486878964253},
{"total_number_of_episodes": 16770, "number_of_timesteps": 16770000, "per_episode_reward": -38.16, "episode_reward_trend_value": 0.03715413920007009, "biggest_recent_change": 0.5741486878964253},
{"total_number_of_episodes": 16780, "number_of_timesteps": 16780000, "per_episode_reward": -38.02, "episode_reward_trend_value": 0.035137534643830924, "biggest_recent_change": 0.5741486878964253},
{"total_number_of_episodes": 16790, "number_of_timesteps": 16790000, "per_episode_reward": -37.87, "episode_reward_trend_value": 0.032928595154895865, "biggest_recent_change": 0.5741486878964253},
{"total_number_of_episodes": 16800, "number_of_timesteps": 16800000, "per_episode_reward": -37.35, "episode_reward_trend_value": 0.03480913001588372, "biggest_recent_change": 0.5741486878964253},
{"total_number_of_episodes": 16810, "number_of_timesteps": 16810000, "per_episode_reward": -36.86, "episode_reward_trend_value": 0.036191860104569276, "biggest_recent_change": 0.5741486878964253},
{"total_number_of_episodes": 16820, "number_of_timesteps": 16820000, "per_episode_reward": -36.48, "episode_reward_trend_value": 0.036308438276037455, "biggest_recent_change": 0.5741486878964253},
{"total_number_of_episodes": 16830, "number_of_timesteps": 16830000, "per_episode_reward": -36.1, "episode_reward_trend_value": 0.03808565154302859, "biggest_recent_change": 0.5741486878964253},
{"total_number_of_episodes": 16840, "number_of_timesteps": 16840000, "per_episode_reward": -35.83, "episode_reward_trend_value": 0.03873795159117621, "biggest_recent_change": 0.5741486878964253},
{"total_number_of_episodes": 16850, "number_of_timesteps": 16850000, "per_episode_reward": -35.55, "episode_reward_trend_value": 0.0354352887891997, "biggest_recent_change": 0.5741486878964253},
{"total_number_of_episodes": 16860, "number_of_timesteps": 16860000, "per_episode_reward": -35.14, "episode_reward_trend_value": 0.033576955954620756, "biggest_recent_change": 0.5163024219625285},
{"total_number_of_episodes": 16870, "number_of_timesteps": 16870000, "per_episode_reward": -34.74, "episode_reward_trend_value": 0.03645083375811914, "biggest_recent_change": 0.5163024219625285},
{"total_number_of_episodes": 16880, "number_of_timesteps": 16880000, "per_episode_reward": -34.54, "episode_reward_trend_value": 0.03695049368122562, "biggest_recent_change": 0.5163024219625285},
{"total_number_of_episodes": 16890, "number_of_timesteps": 16890000, "per_episode_reward": -34.35, "episode_reward_trend_value": 0.03336067925440918, "biggest_recent_change": 0.49210489796404744},
{"total_number_of_episodes": 16900, "number_of_timesteps": 16900000, "per_episode_reward": -34.02, "episode_reward_trend_value": 0.03152831111446162, "biggest_recent_change": 0.4068987327843274},
{"total_number_of_episodes": 16910, "number_of_timesteps": 16910000, "per_episode_reward": -33.67, "episode_reward_trend_value": 0.03126771984580796, "biggest_recent_change": 0.4068987327843274},
{"total_number_of_episodes": 16920, "number_of_timesteps": 16920000, "per_episode_reward": -33.37, "episode_reward_trend_value": 0.030337202580813183, "biggest_recent_change": 0.4068987327843274},
{"total_number_of_episodes": 16930, "number_of_timesteps": 16930000, "per_episode_reward": -33.08, "episode_reward_trend_value": 0.030531598534662092, "biggest_recent_change": 0.4068987327843274},
{"total_number_of_episodes": 16940, "number_of_timesteps": 16940000, "per_episode_reward": -32.72, "episode_reward_trend_value": 0.03142540510401612, "biggest_recent_change": 0.4068987327843274},
{"total_number_of_episodes": 16950, "number_of_timesteps": 16950000, "per_episode_reward": -32.36, "episode_reward_trend_value": 0.030874881705972496, "biggest_recent_change": 0.4068987327843274},
{"total_number_of_episodes": 16960, "number_of_timesteps": 16960000, "per_episode_reward": -31.57, "episode_reward_trend_value": 0.03515709343501874, "biggest_recent_change": 0.7922977883984892},
{"total_number_of_episodes": 16970, "number_of_timesteps": 16970000, "per_episode_reward": -30.78, "episode_reward_trend_value": 0.04181352304445688, "biggest_recent_change": 0.7922977883984892},
{"total_number_of_episodes": 16980, "number_of_timesteps": 16980000, "per_episode_reward": -30.17, "episode_reward_trend_value": 0.0464168704070732, "biggest_recent_change": 0.7922977883984892},
{"total_number_of_episodes": 16990, "number_of_timesteps": 16990000, "per_episode_reward": -29.56, "episode_reward_trend_value": 0.04953163286058163, "biggest_recent_change": 0.7922977883984892},
{"total_number_of_episodes": 17000, "number_of_timesteps": 17000000, "per_episode_reward": -29.17, "episode_reward_trend_value": 0.04994392644320445, "biggest_recent_change": 0.7922977883984892},
{"total_number_of_episodes": 17010, "number_of_timesteps": 17010000, "per_episode_reward": -28.78, "episode_reward_trend_value": 0.0510261460221683, "biggest_recent_change": 0.7922977883984892},
{"total_number_of_episodes": 17020, "number_of_timesteps": 17020000, "per_episode_reward": -28.38, "episode_reward_trend_value": 0.05216509336006013, "biggest_recent_change": 0.7922977883984892},
{"total_number_of_episodes": 17030, "number_of_timesteps": 17030000, "per_episode_reward": -27.99, "episode_reward_trend_value": 0.05260463008244669, "biggest_recent_change": 0.7922977883984892},
{"total_number_of_episodes": 17040, "number_of_timesteps": 17040000, "per_episode_reward": -27.64, "episode_reward_trend_value": 0.05243356081980066, "biggest_recent_change": 0.7922977883984892},
{"total_number_of_episodes": 17050, "number_of_timesteps": 17050000, "per_episode_reward": -27.3, "episode_reward_trend_value": 0.047429756430064765, "biggest_recent_change": 0.7922977883984892},
{"total_number_of_episodes": 17060, "number_of_timesteps": 17060000, "per_episode_reward": -26.45, "episode_reward_trend_value": 0.048142099395076736, "biggest_recent_change": 0.8564086552495667},
{"total_number_of_episodes": 17070, "number_of_timesteps": 17070000, "per_episode_reward": -25.59, "episode_reward_trend_value": 0.05090752460691065, "biggest_recent_change": 0.8564086552495702},
{"total_number_of_episodes": 17080, "number_of_timesteps": 17080000, "per_episode_reward": -25.08, "episode_reward_trend_value": 0.0497927679047683, "biggest_recent_change": 0.8564086552495702},
{"total_number_of_episodes": 17090, "number_of_timesteps": 17090000, "per_episode_reward": -24.58, "episode_reward_trend_value": 0.05107485511943509, "biggest_recent_change": 0.8564086552495702},
{"total_number_of_episodes": 17100, "number_of_timesteps": 17100000, "per_episode_reward": -23.97, "episode_reward_trend_value": 0.05345253974702283, "biggest_recent_change": 0.8564086552495702},
{"total_number_of_episodes": 17110, "number_of_timesteps": 17110000, "per_episode_reward": -23.33, "episode_reward_trend_value": 0.056158435301762843, "biggest_recent_change": 0.8564086552495702},
{"total_number_of_episodes": 17120, "number_of_timesteps": 17120000, "per_episode_reward": -22.98, "episode_reward_trend_value": 0.055585551950455905, "biggest_recent_change": 0.8564086552495702},
{"total_number_of_episodes": 17130, "number_of_timesteps": 17130000, "per_episode_reward": -22.64, "episode_reward_trend_value": 0.05562327458418174, "biggest_recent_change": 0.8564086552495702},
{"total_number_of_episodes": 17140, "number_of_timesteps": 17140000, "per_episode_reward": -22.98, "episode_reward_trend_value": 0.04798654320996134, "biggest_recent_change": 0.8564086552495702},
{"total_number_of_episodes": 17150, "number_of_timesteps": 17150000, "per_episode_reward": -23.33, "episode_reward_trend_value": 0.03463366448099319, "biggest_recent_change": 0.8564086552495702},
{"total_number_of_episodes": 17160, "number_of_timesteps": 17160000, "per_episode_reward": -23.97, "episode_reward_trend_value": 0.018002006845977903, "biggest_recent_change": 0.640440531901806},
{"total_number_of_episodes": 17170, "number_of_timesteps": 17170000, "per_episode_reward": -24.61, "episode_reward_trend_value": 0.005250531124938796, "biggest_recent_change": 0.640440531901806},
{"total_number_of_episodes": 17180, "number_of_timesteps": 17180000, "per_episode_reward": -25.34, "episode_reward_trend_value": -0.008538894171833889, "biggest_recent_change": 0.7338559937178282},
{"total_number_of_episodes": 17190, "number_of_timesteps": 17190000, "per_episode_reward": -26.08, "episode_reward_trend_value": -0.02342391688152728, "biggest_recent_change": 0.7338559937178282},
{"total_number_of_episodes": 17200, "number_of_timesteps": 17200000, "per_episode_reward": -26.7, "episode_reward_trend_value": -0.037419122050948536, "biggest_recent_change": 0.7338559937178282},
{"total_number_of_episodes": 17210, "number_of_timesteps": 17210000, "per_episode_reward": -27.32, "episode_reward_trend_value": -0.0481355483143226, "biggest_recent_change": 0.7338559937178282},
{"total_number_of_episodes": 17220, "number_of_timesteps": 17220000, "per_episode_reward": -27.66, "episode_reward_trend_value": -0.0557563615727498, "biggest_recent_change": 0.7338559937178282},
{"total_number_of_episodes": 17230, "number_of_timesteps": 17230000, "per_episode_reward": -28.0, "episode_reward_trend_value": -0.055702720823230814, "biggest_recent_change": 0.7338559937178282},
{"total_number_of_episodes": 17240, "number_of_timesteps": 17240000, "per_episode_reward": -28.45, "episode_reward_trend_value": -0.05693910542444987, "biggest_recent_change": 0.7338559937178282},
{"total_number_of_episodes": 17250, "number_of_timesteps": 17250000, "per_episode_reward": -28.91, "episode_reward_trend_value": -0.05489671111962176, "biggest_recent_change": 0.7338559937178282},
{"total_number_of_episodes": 17260, "number_of_timesteps": 17260000, "per_episode_reward": -29.37, "episode_reward_trend_value": -0.052849451378588576, "biggest_recent_change": 0.7338559937178282},
{"total_number_of_episodes": 17270, "number_of_timesteps": 17270000, "per_episode_reward": -29.82, "episode_reward_trend_value": -0.04976424206182178, "biggest_recent_change": 0.7338559937178211},
{"total_number_of_episodes": 17280, "number_of_timesteps": 17280000, "per_episode_reward": -30.4, "episode_reward_trend_value": -0.04801650510684176, "biggest_recent_change": 0.6191279333461068},
{"total_number_of_episodes": 17290, "number_of_timesteps": 17290000, "per_episode_reward": -30.98, "episode_reward_trend_value": -0.04754352437821403, "biggest_recent_change": 0.6191279333460997},
{"total_number_of_episodes": 17300, "number_of_timesteps": 17300000, "per_episode_reward": -31.75, "episode_reward_trend_value": -0.049306512972269914, "biggest_recent_change": 0.7777969068111297},
{"total_number_of_episodes": 17310, "number_of_timesteps": 17310000, "per_episode_reward": -32.53, "episode_reward_trend_value": -0.05416511457127286, "biggest_recent_change": 0.7777969068111368},
{"total_number_of_episodes": 17320, "number_of_timesteps": 17320000, "per_episode_reward": -32.91, "episode_reward_trend_value": -0.05460023779286902, "biggest_recent_change": 0.7777969068111368},
{"total_number_of_episodes": 17330, "number_of_timesteps": 17330000, "per_episode_reward": -33.29, "episode_reward_trend_value": -0.053745335663727425, "biggest_recent_change": 0.7777969068111368},
{"total_number_of_episodes": 17340, "number_of_timesteps": 17340000, "per_episode_reward": -33.74, "episode_reward_trend_value": -0.053624897537290064, "biggest_recent_change": 0.7777969068111368},
{"total_number_of_episodes": 17350, "number_of_timesteps": 17350000, "per_episode_reward": -34.18, "episode_reward_trend_value": -0.05350932484705785, "biggest_recent_change": 0.7777969068111368},
{"total_number_of_episodes": 17360, "number_of_timesteps": 17360000, "per_episode_reward": -34.4, "episode_reward_trend_value": -0.05086156722915018, "biggest_recent_change": 0.7777969068111368},
{"total_number_of_episodes": 17370, "number_of_timesteps": 17370000, "per_episode_reward": -34.62, "episode_reward_trend_value": -0.046876337249455904, "biggest_recent_change": 0.7777969068111368},
{"total_number_of_episodes": 17380, "number_of_timesteps": 17380000, "per_episode_reward": -34.82, "episode_reward_trend_value": -0.04265574933009933, "biggest_recent_change": 0.7777969068111368},
{"total_number_of_episodes": 17390, "number_of_timesteps": 17390000, "per_episode_reward": -35.01, "episode_reward_trend_value": -0.036199192088059225, "biggest_recent_change": 0.7777969068111368},
{"total_number_of_episodes": 17400, "number_of_timesteps": 17400000, "per_episode_reward": -35.32, "episode_reward_trend_value": -0.03101950643162752, "biggest_recent_change": 0.44578561308792075},
{"total_number_of_episodes": 17410, "number_of_timesteps": 17410000, "per_episode_reward": -35.63, "episode_reward_trend_value": -0.030263299152602723, "biggest_recent_change": 0.44578561308792075},
{"total_number_of_episodes": 17420, "number_of_timesteps": 17420000, "per_episode_reward": -35.99, "episode_reward_trend_value": -0.030022691036752275, "biggest_recent_change": 0.44578561308792075},
{"total_number_of_episodes": 17430, "number_of_timesteps": 17430000, "per_episode_reward": -36.35, "episode_reward_trend_value": -0.029047618918197633, "biggest_recent_change": 0.44578561308792075},
{"total_number_of_episodes": 17440, "number_of_timesteps": 17440000, "per_episode_reward": -36.8, "episode_reward_trend_value": -0.02908204622257347, "biggest_recent_change": 0.4488840704817463},
{"total_number_of_episodes": 17450, "number_of_timesteps": 17450000, "per_episode_reward": -37.25, "episode_reward_trend_value": -0.03164865845462504, "biggest_recent_change": 0.4488840704817676},
{"total_number_of_episodes": 17460, "number_of_timesteps": 17460000, "per_episode_reward": -37.6, "episode_reward_trend_value": -0.033120153849763134, "biggest_recent_change": 0.4488840704817676},
{"total_number_of_episodes": 17470, "number_of_timesteps": 17470000, "per_episode_reward": -37.95, "episode_reward_trend_value": -0.03482700718456376, "biggest_recent_change": 0.4488840704817676},
{"total_number_of_episodes": 17480, "number_of_timesteps": 17480000, "per_episode_reward": -38.38, "episode_reward_trend_value": -0.03743947711106909, "biggest_recent_change": 0.4488840704817676},
{"total_number_of_episodes": 17490, "number_of_timesteps": 17490000, "per_episode_reward": -38.81, "episode_reward_trend_value": -0.03877507545196594, "biggest_recent_change": 0.4488840704817676},
{"total_number_of_episodes": 17500, "number_of_timesteps": 17500000, "per_episode_reward": -39.24, "episode_reward_trend_value": -0.040071510291567435, "biggest_recent_change": 0.4488840704817676},
{"total_number_of_episodes": 17510, "number_of_timesteps": 17510000, "per_episode_reward": -39.67, "episode_reward_trend_value": -0.04085234596799441, "biggest_recent_change": 0.4488840704817676},
{"total_number_of_episodes": 17520, "number_of_timesteps": 17520000, "per_episode_reward": -39.96, "episode_reward_trend_value": -0.04005114731229027, "biggest_recent_change": 0.4488840704817676},
{"total_number_of_episodes": 17530, "number_of_timesteps": 17530000, "per_episode_reward": -40.24, "episode_reward_trend_value": -0.03824044923365564, "biggest_recent_change": 0.4488840704817676},
{"total_number_of_episodes": 17540, "number_of_timesteps": 17540000, "per_episode_reward": -40.56, "episode_reward_trend_value": -0.03681412118739655, "biggest_recent_change": 0.4318290484130003},
{"total_number_of_episodes": 17550, "number_of_timesteps": 17550000, "per_episode_reward": -40.88, "episode_reward_trend_value": -0.036482909978050926, "biggest_recent_change": 0.4318290484130003},
{"total_number_of_episodes": 17560, "number_of_timesteps": 17560000, "per_episode_reward": -41.19, "episode_reward_trend_value": -0.03604292396961099, "biggest_recent_change": 0.4318290484130003},
{"total_number_of_episodes": 17570, "number_of_timesteps": 17570000, "per_episode_reward": -41.5, "episode_reward_trend_value": -0.03469732136946651, "biggest_recent_change": 0.4318290484130003},
{"total_number_of_episodes": 17580, "number_of_timesteps": 17580000, "per_episode_reward": -41.9, "episode_reward_trend_value": -0.034323713372637045, "biggest_recent_change": 0.42830433329642403},
{"total_number_of_episodes": 17590, "number_of_timesteps": 17590000, "per_episode_reward": -42.3, "episode_reward_trend_value": -0.03398926887710303, "biggest_recent_change": 0.42830433329642403},
{"total_number_of_episodes": 17600, "number_of_timesteps": 17600000, "per_episode_reward": -42.86, "episode_reward_trend_value": -0.035443997281307635, "biggest_recent_change": 0.5592298896748389},
{"total_number_of_episodes": 17610, "number_of_timesteps": 17610000, "per_episode_reward": -43.42, "episode_reward_trend_value": -0.03848076001764345, "biggest_recent_change": 0.559229889674846},
{"total_number_of_episodes": 17620, "number_of_timesteps": 17620000, "per_episode_reward": -43.72, "episode_reward_trend_value": -0.03870161245761992, "biggest_recent_change": 0.559229889674846},
{"total_number_of_episodes": 17630, "number_of_timesteps": 17630000, "per_episode_reward": -44.03, "episode_reward_trend_value": -0.03853809486522068, "biggest_recent_change": 0.559229889674846},
{"total_number_of_episodes": 17640, "number_of_timesteps": 17640000, "per_episode_reward": -44.47, "episode_reward_trend_value": -0.03983372488565919, "biggest_recent_change": 0.559229889674846},
{"total_number_of_episodes": 17650, "number_of_timesteps": 17650000, "per_episode_reward": -44.9, "episode_reward_trend_value": -0.041238129705192174, "biggest_recent_change": 0.559229889674846},
{"total_number_of_episodes": 17660, "number_of_timesteps": 17660000, "per_episode_reward": -45.36, "episode_reward_trend_value": -0.042804630289137675, "biggest_recent_change": 0.559229889674846},
{"total_number_of_episodes": 17670, "number_of_timesteps": 17670000, "per_episode_reward": -45.81, "episode_reward_trend_value": -0.04339913626976831, "biggest_recent_change": 0.559229889674846},
{"total_number_of_episodes": 17680, "number_of_timesteps": 17680000, "per_episode_reward": -46.44, "episode_reward_trend_value": -0.045968674246546624, "biggest_recent_change": 0.6294627466084108},
{"total_number_of_episodes": 17690, "number_of_timesteps": 17690000, "per_episode_reward": -47.07, "episode_reward_trend_value": -0.04674903932358624, "biggest_recent_change": 0.6294627466084108},
{"total_number_of_episodes": 17700, "number_of_timesteps": 17700000, "per_episode_reward": -47.43, "episode_reward_trend_value": -0.044545238945414276, "biggest_recent_change": 0.6294627466084108},
{"total_number_of_episodes": 17710, "number_of_timesteps": 17710000, "per_episode_reward": -47.79, "episode_reward_trend_value": -0.045157348863601655, "biggest_recent_change": 0.6294627466084108},
{"total_number_of_episodes": 17720, "number_of_timesteps": 17720000, "per_episode_reward": -48.48, "episode_reward_trend_value": -0.049409493246092735, "biggest_recent_change": 0.6884909574267155},
{"total_number_of_episodes": 17730, "number_of_timesteps": 17730000, "per_episode_reward": -49.17, "episode_reward_trend_value": -0.05220249001574599, "biggest_recent_change": 0.6884909574267155},
{"total_number_of_episodes": 17740, "number_of_timesteps": 17740000, "per_episode_reward": -49.57, "episode_reward_trend_value": -0.051845462921872434, "biggest_recent_change": 0.6884909574267155},
{"total_number_of_episodes": 17750, "number_of_timesteps": 17750000, "per_episode_reward": -49.98, "episode_reward_trend_value": -0.05132634006358603, "biggest_recent_change": 0.6884909574267155},
{"total_number_of_episodes": 17760, "number_of_timesteps": 17760000, "per_episode_reward": -50.16, "episode_reward_trend_value": -0.04832568589298923, "biggest_recent_change": 0.6884909574267155},
{"total_number_of_episodes": 17770, "number_of_timesteps": 17770000, "per_episode_reward": -50.34, "episode_reward_trend_value": -0.043349999726244606, "biggest_recent_change": 0.6884909574267155},
{"total_number_of_episodes": 17780, "number_of_timesteps": 17780000, "per_episode_reward": -50.64, "episode_reward_trend_value": -0.03975001499645706, "biggest_recent_change": 0.6884909574267155},
{"total_number_of_episodes": 17790, "number_of_timesteps": 17790000, "per_episode_reward": -50.95, "episode_reward_trend_value": -0.03913419572188101, "biggest_recent_change": 0.6884909574267155},
{"total_number_of_episodes": 17800, "number_of_timesteps": 17800000, "per_episode_reward": -51.29, "episode_reward_trend_value": -0.03893197462750904, "biggest_recent_change": 0.6884909574267155},
{"total_number_of_episodes": 17810, "number_of_timesteps": 17810000, "per_episode_reward": -51.64, "episode_reward_trend_value": -0.03508971906883321, "biggest_recent_change": 0.6884909574267155},
{"total_number_of_episodes": 17820, "number_of_timesteps": 17820000, "per_episode_reward": -51.87, "episode_reward_trend_value": -0.030083461281245227, "biggest_recent_change": 0.40498880970933016},
{"total_number_of_episodes": 17830, "number_of_timesteps": 17830000, "per_episode_reward": -52.11, "episode_reward_trend_value": -0.028227227357183908, "biggest_recent_change": 0.40498880970931594},
{"total_number_of_episodes": 17840, "number_of_timesteps": 17840000, "per_episode_reward": -52.56, "episode_reward_trend_value": -0.02868370940218199, "biggest_recent_change": 0.446072193759143},
{"total_number_of_episodes": 17850, "number_of_timesteps": 17850000, "per_episode_reward": -53.0, "episode_reward_trend_value": -0.031621722759490226, "biggest_recent_change": 0.446072193759143},
{"total_number_of_episodes": 17860, "number_of_timesteps": 17860000, "per_episode_reward": -53.2, "episode_reward_trend_value": -0.031839177025126654, "biggest_recent_change": 0.446072193759143},
{"total_number_of_episodes": 17870, "number_of_timesteps": 17870000, "per_episode_reward": -53.41, "episode_reward_trend_value": -0.030680929853805987, "biggest_recent_change": 0.446072193759143},
{"total_number_of_episodes": 17880, "number_of_timesteps": 17880000, "per_episode_reward": -53.91, "episode_reward_trend_value": -0.03294150925839258, "biggest_recent_change": 0.508916267340318},
{"total_number_of_episodes": 17890, "number_of_timesteps": 17890000, "per_episode_reward": -54.42, "episode_reward_trend_value": -0.03478849048277503, "biggest_recent_change": 0.508916267340318},
{"total_number_of_episodes": 17900, "number_of_timesteps": 17900000, "per_episode_reward": -54.8, "episode_reward_trend_value": -0.03515398092766431, "biggest_recent_change": 0.508916267340318},
{"total_number_of_episodes": 17910, "number_of_timesteps": 17910000, "per_episode_reward": -55.17, "episode_reward_trend_value": -0.03668347360146582, "biggest_recent_change": 0.508916267340318},
{"total_number_of_episodes": 17920, "number_of_timesteps": 17920000, "per_episode_reward": -55.49, "episode_reward_trend_value": -0.03750019435935275, "biggest_recent_change": 0.508916267340318},
{"total_number_of_episodes": 17930, "number_of_timesteps": 17930000, "per_episode_reward": -55.8, "episode_reward_trend_value": -0.03600419914818061, "biggest_recent_change": 0.508916267340318},
{"total_number_of_episodes": 17940, "number_of_timesteps": 17940000, "per_episode_reward": -56.38, "episode_reward_trend_value": -0.03749759610333412, "biggest_recent_change": 0.5804779197229522},
{"total_number_of_episodes": 17950, "number_of_timesteps": 17950000, "per_episode_reward": -56.96, "episode_reward_trend_value": -0.04171155215015937, "biggest_recent_change": 0.5804779197229522},
{"total_number_of_episodes": 17960, "number_of_timesteps": 17960000, "per_episode_reward": -57.04, "episode_reward_trend_value": -0.0404213828532476, "biggest_recent_change": 0.5804779197229522},
{"total_number_of_episodes": 17970, "number_of_timesteps": 17970000, "per_episode_reward": -57.22, "episode_reward_trend_value": -0.03667010797707751, "biggest_recent_change": 0.5804779197229522},
{"total_number_of_episodes": 17980, "number_of_timesteps": 17980000, "per_episode_reward": -57.42, "episode_reward_trend_value": -0.03329684946631859, "biggest_recent_change": 0.5804779197229522},
{"total_number_of_episodes": 17990, "number_of_timesteps": 17990000, "per_episode_reward": -57.57, "episode_reward_trend_value": -0.030734895280806286, "biggest_recent_change": 0.5804779197229522},
{"total_number_of_episodes": 18000, "number_of_timesteps": 18000000, "per_episode_reward": -57.54, "episode_reward_trend_value": -0.026269877926017114, "biggest_recent_change": 0.5804779197229522},
{"total_number_of_episodes": 18010, "number_of_timesteps": 18010000, "per_episode_reward": -57.32, "episode_reward_trend_value": -0.02037388747633994, "biggest_recent_change": 0.5804779197229522},
{"total_number_of_episodes": 18020, "number_of_timesteps": 18020000, "per_episode_reward": -57.61, "episode_reward_trend_value": -0.020103153482886268, "biggest_recent_change": 0.5804779197229522},
{"total_number_of_episodes": 18030, "number_of_timesteps": 18030000, "per_episode_reward": -57.77, "episode_reward_trend_value": -0.01550375178438033, "biggest_recent_change": 0.580477919722945},
{"total_number_of_episodes": 18040, "number_of_timesteps": 18040000, "per_episode_reward": -57.96, "episode_reward_trend_value": -0.011164308535644176, "biggest_recent_change": 0.28706656534281905},
{"total_number_of_episodes": 18050, "number_of_timesteps": 18050000, "per_episode_reward": -57.83, "episode_reward_trend_value": -0.008770776309317165, "biggest_recent_change": 0.28706656534281905},
{"total_number_of_episodes": 18060, "number_of_timesteps": 18060000, "per_episode_reward": -57.77, "episode_reward_trend_value": -0.00612075062955605, "biggest_recent_change": 0.28706656534281905},
{"total_number_of_episodes": 18070, "number_of_timesteps": 18070000, "per_episode_reward": -57.49, "episode_reward_trend_value": -0.0008091058261415343, "biggest_recent_change": 0.28706656534281905},
{"total_number_of_episodes": 18080, "number_of_timesteps": 18080000, "per_episode_reward": -57.42, "episode_reward_trend_value": 0.0016047319596911476, "biggest_recent_change": 0.28706656534281905},
{"total_number_of_episodes": 18090, "number_of_timesteps": 18090000, "per_episode_reward": -57.32, "episode_reward_trend_value": 0.002384560503288371, "biggest_recent_change": 0.28706656534281905},
{"total_number_of_episodes": 18100, "number_of_timesteps": 18100000, "per_episode_reward": -56.93, "episode_reward_trend_value": 0.0043148063765733645, "biggest_recent_change": 0.3929286443129598},
{"total_number_of_episodes": 18110, "number_of_timesteps": 18110000, "per_episode_reward": -56.54, "episode_reward_trend_value": 0.011870308706082177, "biggest_recent_change": 0.39292864431297403},
{"total_number_of_episodes": 18120, "number_of_timesteps": 18120000, "per_episode_reward": -56.18, "episode_reward_trend_value": 0.01771288413670962, "biggest_recent_change": 0.39292864431297403},
{"total_number_of_episodes": 18130, "number_of_timesteps": 18130000, "per_episode_reward": -55.82, "episode_reward_trend_value": 0.023815418017106616, "biggest_recent_change": 0.39292864431297403},
{"total_number_of_episodes": 18140, "number_of_timesteps": 18140000, "per_episode_reward": -55.62, "episode_reward_trend_value": 0.02455319760660449, "biggest_recent_change": 0.39292864431297403},
{"total_number_of_episodes": 18150, "number_of_timesteps": 18150000, "per_episode_reward": -55.43, "episode_reward_trend_value": 0.025992204739317043, "biggest_recent_change": 0.39292864431297403},
{"total_number_of_episodes": 18160, "number_of_timesteps": 18160000, "per_episode_reward": -54.45, "episode_reward_trend_value": 0.03377254916980669, "biggest_recent_change": 0.9729560296793593},
{"total_number_of_episodes": 18170, "number_of_timesteps": 18170000, "per_episode_reward": -53.94, "episode_reward_trend_value": 0.03863111063915873, "biggest_recent_change": 0.9729560296793593},
{"total_number_of_episodes": 18180, "number_of_timesteps": 18180000, "per_episode_reward": -53.68, "episode_reward_trend_value": 0.040450583492376464, "biggest_recent_change": 0.9729560296793593},
{"total_number_of_episodes": 18190, "number_of_timesteps": 18190000, "per_episode_reward": -53.42, "episode_reward_trend_value": 0.038975894005104234, "biggest_recent_change": 0.9729560296793593},
{"total_number_of_episodes": 18200, "number_of_timesteps": 18200000, "per_episode_reward": -53.15, "episode_reward_trend_value": 0.03763541229595009, "biggest_recent_change": 0.9729560296793593},
{"total_number_of_episodes": 18210, "number_of_timesteps": 18210000, "per_episode_reward": -52.88, "episode_reward_trend_value": 0.03666858194695056, "biggest_recent_change": 0.9729560296793593},
{"total_number_of_episodes": 18220, "number_of_timesteps": 18220000, "per_episode_reward": -52.71, "episode_reward_trend_value": 0.034579059635845275, "biggest_recent_change": 0.9729560296793593},
{"total_number_of_episodes": 18230, "number_of_timesteps": 18230000, "per_episode_reward": -52.54, "episode_reward_trend_value": 0.034296077294311306, "biggest_recent_change": 0.9729560296793593},
{"total_number_of_episodes": 18240, "number_of_timesteps": 18240000, "per_episode_reward": -52.29, "episode_reward_trend_value": 0.0348171096067053, "biggest_recent_change": 0.9729560296793593},
{"total_number_of_episodes": 18250, "number_of_timesteps": 18250000, "per_episode_reward": -52.05, "episode_reward_trend_value": 0.026713201863079978, "biggest_recent_change": 0.509509712476806},
{"total_number_of_episodes": 18260, "number_of_timesteps": 18260000, "per_episode_reward": -51.65, "episode_reward_trend_value": 0.02553961157816297, "biggest_recent_change": 0.40388658683427536},
{"total_number_of_episodes": 18270, "number_of_timesteps": 18270000, "per_episode_reward": -51.24, "episode_reward_trend_value": 0.0271360559823391, "biggest_recent_change": 0.4038865868342896},
{"total_number_of_episodes": 18280, "number_of_timesteps": 18280000, "per_episode_reward": -50.86, "episode_reward_trend_value": 0.02851984520038218, "biggest_recent_change": 0.4038865868342896},
{"total_number_of_episodes": 18290, "number_of_timesteps": 18290000, "per_episode_reward": -50.47, "episode_reward_trend_value": 0.029769426640307094, "biggest_recent_change": 0.4038865868342896},
{"total_number_of_episodes": 18300, "number_of_timesteps": 18300000, "per_episode_reward": -50.27, "episode_reward_trend_value": 0.029014208581778826, "biggest_recent_change": 0.4038865868342896},
{"total_number_of_episodes": 18310, "number_of_timesteps": 18310000, "per_episode_reward": -50.06, "episode_reward_trend_value": 0.029381682485356463, "biggest_recent_change": 0.4038865868342896},
{"total_number_of_episodes": 18320, "number_of_timesteps": 18320000, "per_episode_reward": -49.8, "episode_reward_trend_value": 0.03036784026187591, "biggest_recent_change": 0.4038865868342896},
{"total_number_of_episodes": 18330, "number_of_timesteps": 18330000, "per_episode_reward": -49.54, "episode_reward_trend_value": 0.030549983384467398, "biggest_recent_change": 0.4038865868342896},
{"total_number_of_episodes": 18340, "number_of_timesteps": 18340000, "per_episode_reward": -49.24, "episode_reward_trend_value": 0.031211543976594515, "biggest_recent_change": 0.4038865868342896},
{"total_number_of_episodes": 18350, "number_of_timesteps": 18350000, "per_episode_reward": -48.94, "episode_reward_trend_value": 0.030092190634486038, "biggest_recent_change": 0.4038865868342896},
{"total_number_of_episodes": 18360, "number_of_timesteps": 18360000, "per_episode_reward": -48.25, "episode_reward_trend_value": 0.033203523096571215, "biggest_recent_change": 0.6839065084219556},
{"total_number_of_episodes": 18370, "number_of_timesteps": 18370000, "per_episode_reward": -47.57, "episode_reward_trend_value": 0.036527510744789285, "biggest_recent_change": 0.6839065084219627},
{"total_number_of_episodes": 18380, "number_of_timesteps": 18380000, "per_episode_reward": -47.05, "episode_reward_trend_value": 0.03805426156204174, "biggest_recent_change": 0.6839065084219627},
{"total_number_of_episodes": 18390, "number_of_timesteps": 18390000, "per_episode_reward": -46.53, "episode_reward_trend_value": 0.041585811877747465, "biggest_recent_change": 0.6839065084219627},
{"total_number_of_episodes": 18400, "number_of_timesteps": 18400000, "per_episode_reward": -45.91, "episode_reward_trend_value": 0.046122258603685316, "biggest_recent_change": 0.6839065084219627},
{"total_number_of_episodes": 18410, "number_of_timesteps": 18410000, "per_episode_reward": -45.55, "episode_reward_trend_value": 0.04729479683890258, "biggest_recent_change": 0.6839065084219627},
{"total_number_of_episodes": 18420, "number_of_timesteps": 18420000, "per_episode_reward": -45.25, "episode_reward_trend_value": 0.0477305363336686, "biggest_recent_change": 0.6839065084219627},
{"total_number_of_episodes": 18430, "number_of_timesteps": 18430000, "per_episode_reward": -45.08, "episode_reward_trend_value": 0.04622813647946265, "biggest_recent_change": 0.6839065084219627},
{"total_number_of_episodes": 18440, "number_of_timesteps": 18440000, "per_episode_reward": -44.84, "episode_reward_trend_value": 0.04552210522775345, "biggest_recent_change": 0.6839065084219627},
{"total_number_of_episodes": 18450, "number_of_timesteps": 18450000, "per_episode_reward": -44.46, "episode_reward_trend_value": 0.04215088125176823, "biggest_recent_change": 0.6839065084219627},
{"total_number_of_episodes": 18460, "number_of_timesteps": 18460000, "per_episode_reward": -44.5, "episode_reward_trend_value": 0.03406703064855342, "biggest_recent_change": 0.6125958705559569},
{"total_number_of_episodes": 18470, "number_of_timesteps": 18470000, "per_episode_reward": -44.0, "episode_reward_trend_value": 0.033891369971241404, "biggest_recent_change": 0.6125958705559569},
{"total_number_of_episodes": 18480, "number_of_timesteps": 18480000, "per_episode_reward": -44.03, "episode_reward_trend_value": 0.027719401191961562, "biggest_recent_change": 0.6125958705559569},
{"total_number_of_episodes": 18490, "number_of_timesteps": 18490000, "per_episode_reward": -44.39, "episode_reward_trend_value": 0.016922126344575933, "biggest_recent_change": 0.5063457326769836},
{"total_number_of_episodes": 18500, "number_of_timesteps": 18500000, "per_episode_reward": -44.4, "episode_reward_trend_value": 0.012770226147541466, "biggest_recent_change": 0.5063457326769836},
{"total_number_of_episodes": 18510, "number_of_timesteps": 18510000, "per_episode_reward": -43.96, "episode_reward_trend_value": 0.014342200185923637, "biggest_recent_change": 0.5063457326769836},
{"total_number_of_episodes": 18520, "number_of_timesteps": 18520000, "per_episode_reward": -43.53, "episode_reward_trend_value": 0.01719239533957051, "biggest_recent_change": 0.5063457326769836},
{"total_number_of_episodes": 18530, "number_of_timesteps": 18530000, "per_episode_reward": -43.27, "episode_reward_trend_value": 0.017410729230585766, "biggest_recent_change": 0.5063457326769836},
{"total_number_of_episodes": 18540, "number_of_timesteps": 18540000, "per_episode_reward": -43.21, "episode_reward_trend_value": 0.01385584927805523, "biggest_recent_change": 0.5063457326769836},
{"total_number_of_episodes": 18550, "number_of_timesteps": 18550000, "per_episode_reward": -43.22, "episode_reward_trend_value": 0.014269270927923591, "biggest_recent_change": 0.5063457326769836},
{"total_number_of_episodes": 18560, "number_of_timesteps": 18560000, "per_episode_reward": -43.41, "episode_reward_trend_value": 0.006480945656061089, "biggest_recent_change": 0.4406914317696504},
{"total_number_of_episodes": 18570, "number_of_timesteps": 18570000, "per_episode_reward": -43.38, "episode_reward_trend_value": 0.007215378177240142, "biggest_recent_change": 0.4406914317696504},
{"total_number_of_episodes": 18580, "number_of_timesteps": 18580000, "per_episode_reward": -43.58, "episode_reward_trend_value": 0.009027348961313287, "biggest_recent_change": 0.4406914317696504},
{"total_number_of_episodes": 18590, "number_of_timesteps": 18590000, "per_episode_reward": -43.28, "episode_reward_trend_value": 0.012385577580543839, "biggest_recent_change": 0.4406914317696504},
{"total_number_of_episodes": 18600, "number_of_timesteps": 18600000, "per_episode_reward": -43.21, "episode_reward_trend_value": 0.0083273363614443, "biggest_recent_change": 0.42444636299420324},
{"total_number_of_episodes": 18610, "number_of_timesteps": 18610000, "per_episode_reward": -43.05, "episode_reward_trend_value": 0.005336608533779162, "biggest_recent_change": 0.29409521295352903},
{"total_number_of_episodes": 18620, "number_of_timesteps": 18620000, "per_episode_reward": -42.99, "episode_reward_trend_value": 0.0031203938405559325, "biggest_recent_change": 0.29409521295352903},
{"total_number_of_episodes": 18630, "number_of_timesteps": 18630000, "per_episode_reward": -43.18, "episode_reward_trend_value": 0.0003289955917112132, "biggest_recent_change": 0.29409521295352903},
{"total_number_of_episodes": 18640, "number_of_timesteps": 18640000, "per_episode_reward": -43.39, "episode_reward_trend_value": -0.0019189584847482248, "biggest_recent_change": 0.29409521295352903},
{"total_number_of_episodes": 18650, "number_of_timesteps": 18650000, "per_episode_reward": -43.35, "episode_reward_trend_value": 0.0007600178735370851, "biggest_recent_change": 0.29409521295352903},
{"total_number_of_episodes": 18660, "number_of_timesteps": 18660000, "per_episode_reward": -43.46, "episode_reward_trend_value": -0.0009242559352237044, "biggest_recent_change": 0.29409521295352903},
{"total_number_of_episodes": 18670, "number_of_timesteps": 18670000, "per_episode_reward": -43.14, "episode_reward_trend_value": 0.004834182412688096, "biggest_recent_change": 0.3221779561698952},
{"total_number_of_episodes": 18680, "number_of_timesteps": 18680000, "per_episode_reward": -43.11, "episode_reward_trend_value": 0.001962761511101579, "biggest_recent_change": 0.3221779561698952},
{"total_number_of_episodes": 18690, "number_of_timesteps": 18690000, "per_episode_reward": -43.21, "episode_reward_trend_value": 1.1905087731081367e-05, "biggest_recent_change": 0.3221779561698952},
{"total_number_of_episodes": 18700, "number_of_timesteps": 18700000, "per_episode_reward": -43.01, "episode_reward_trend_value": 0.00041518140501608516, "biggest_recent_change": 0.3221779561698952},
{"total_number_of_episodes": 18710, "number_of_timesteps": 18710000, "per_episode_reward": -42.84, "episode_reward_trend_value": 0.001685620695227246, "biggest_recent_change": 0.3221779561698952},
{"total_number_of_episodes": 18720, "number_of_timesteps": 18720000, "per_episode_reward": -42.73, "episode_reward_trend_value": 0.005011354568231891, "biggest_recent_change": 0.3221779561698952},
{"total_number_of_episodes": 18730, "number_of_timesteps": 18730000, "per_episode_reward": -42.54, "episode_reward_trend_value": 0.009517440022663078, "biggest_recent_change": 0.3221779561698952},
{"total_number_of_episodes": 18740, "number_of_timesteps": 18740000, "per_episode_reward": -42.92, "episode_reward_trend_value": 0.004766466508279876, "biggest_recent_change": 0.38108328583945195},
{"total_number_of_episodes": 18750, "number_of_timesteps": 18750000, "per_episode_reward": -42.7, "episode_reward_trend_value": 0.008539597197886984, "biggest_recent_change": 0.38108328583945195},
{"total_number_of_episodes": 18760, "number_of_timesteps": 18760000, "per_episode_reward": -42.55, "episode_reward_trend_value": 0.006604572122203302, "biggest_recent_change": 0.38108328583945195},
{"total_number_of_episodes": 18770, "number_of_timesteps": 18770000, "per_episode_reward": -42.43, "episode_reward_trend_value": 0.007556478606079271, "biggest_recent_change": 0.38108328583945195},
{"total_number_of_episodes": 18780, "number_of_timesteps": 18780000, "per_episode_reward": -42.73, "episode_reward_trend_value": 0.005259178372256517, "biggest_recent_change": 0.38108328583945195},
{"total_number_of_episodes": 18790, "number_of_timesteps": 18790000, "per_episode_reward": -42.93, "episode_reward_trend_value": 0.0009196289771839221, "biggest_recent_change": 0.38108328583945195},
{"total_number_of_episodes": 18800, "number_of_timesteps": 18800000, "per_episode_reward": -42.95, "episode_reward_trend_value": -0.0011999545137771387, "biggest_recent_change": 0.38108328583945195},
{"total_number_of_episodes": 18810, "number_of_timesteps": 18810000, "per_episode_reward": -43.32, "episode_reward_trend_value": -0.006496052615209654, "biggest_recent_change": 0.38108328583945195},
{"total_number_of_episodes": 18820, "number_of_timesteps": 18820000, "per_episode_reward": -43.25, "episode_reward_trend_value": -0.007981732769010503, "biggest_recent_change": 0.38108328583945195},
{"total_number_of_episodes": 18830, "number_of_timesteps": 18830000, "per_episode_reward": -43.41, "episode_reward_trend_value": -0.005512043258702843, "biggest_recent_change": 0.3680014680989956},
{"total_number_of_episodes": 18840, "number_of_timesteps": 18840000, "per_episode_reward": -43.42, "episode_reward_trend_value": -0.008096948509619988, "biggest_recent_change": 0.3680014680989956},
{"total_number_of_episodes": 18850, "number_of_timesteps": 18850000, "per_episode_reward": -43.36, "episode_reward_trend_value": -0.009050834741650407, "biggest_recent_change": 0.3680014680989956},
{"total_number_of_episodes": 18860, "number_of_timesteps": 18860000, "per_episode_reward": -43.47, "episode_reward_trend_value": -0.011548419458283377, "biggest_recent_change": 0.3680014680989956},
{"total_number_of_episodes": 18870, "number_of_timesteps": 18870000, "per_episode_reward": -43.3, "episode_reward_trend_value": -0.006325776140926347, "biggest_recent_change": 0.3680014680989956},
{"total_number_of_episodes": 18880, "number_of_timesteps": 18880000, "per_episode_reward": -43.01, "episode_reward_trend_value": -0.0009137876986679474, "biggest_recent_change": 0.3680014680989956},
{"total_number_of_episodes": 18890, "number_of_timesteps": 18890000, "per_episode_reward": -42.93, "episode_reward_trend_value": 0.00025126333638891336, "biggest_recent_change": 0.3680014680989956},
{"total_number_of_episodes": 18900, "number_of_timesteps": 18900000, "per_episode_reward": -42.65, "episode_reward_trend_value": 0.0073909037717488635, "biggest_recent_change": 0.2880952413067135},
{"total_number_of_episodes": 18910, "number_of_timesteps": 18910000, "per_episode_reward": -42.49, "episode_reward_trend_value": 0.008454761950803105, "biggest_recent_change": 0.2880952413067135},
{"total_number_of_episodes": 18920, "number_of_timesteps": 18920000, "per_episode_reward": -42.65, "episode_reward_trend_value": 0.008441329470682272, "biggest_recent_change": 0.2880952413067135},
{"total_number_of_episodes": 18930, "number_of_timesteps": 18930000, "per_episode_reward": -42.79, "episode_reward_trend_value": 0.007032332789486872, "biggest_recent_change": 0.2880952413067135},
{"total_number_of_episodes": 18940, "number_of_timesteps": 18940000, "per_episode_reward": -42.9, "episode_reward_trend_value": 0.0051367557893258545, "biggest_recent_change": 0.2880952413067135},
{"total_number_of_episodes": 18950, "number_of_timesteps": 18950000, "per_episode_reward": -43.01, "episode_reward_trend_value": 0.005081397095975939, "biggest_recent_change": 0.2880952413067135},
{"total_number_of_episodes": 18960, "number_of_timesteps": 18960000, "per_episode_reward": -43.2, "episode_reward_trend_value": 0.0011069948329467, "biggest_recent_change": 0.2880952413067135},
{"total_number_of_episodes": 18970, "number_of_timesteps": 18970000, "per_episode_reward": -42.88, "episode_reward_trend_value": 0.0015203255667443393, "biggest_recent_change": 0.32529500734850103},
{"total_number_of_episodes": 18980, "number_of_timesteps": 18980000, "per_episode_reward": -42.58, "episode_reward_trend_value": 0.003858116402838934, "biggest_recent_change": 0.32529500734850103},
{"total_number_of_episodes": 18990, "number_of_timesteps": 18990000, "per_episode_reward": -42.73, "episode_reward_trend_value": -0.0009220565980271545, "biggest_recent_change": 0.32529500734850103},
{"total_number_of_episodes": 19000, "number_of_timesteps": 19000000, "per_episode_reward": -42.78, "episode_reward_trend_value": -0.0032266324118628924, "biggest_recent_change": 0.32529500734850103},
{"total_number_of_episodes": 19010, "number_of_timesteps": 19010000, "per_episode_reward": -42.99, "episode_reward_trend_value": -0.003754282293994669, "biggest_recent_change": 0.32529500734850103},
{"total_number_of_episodes": 19020, "number_of_timesteps": 19020000, "per_episode_reward": -42.88, "episode_reward_trend_value": -0.0009281927735829735, "biggest_recent_change": 0.32529500734850103},
{"total_number_of_episodes": 19030, "number_of_timesteps": 19030000, "per_episode_reward": -42.8, "episode_reward_trend_value": 0.0011631344564589105, "biggest_recent_change": 0.32529500734850103},
{"total_number_of_episodes": 19040, "number_of_timesteps": 19040000, "per_episode_reward": -42.45, "episode_reward_trend_value": 0.006219641206257462, "biggest_recent_change": 0.3466596159429898},
{"total_number_of_episodes": 19050, "number_of_timesteps": 19050000, "per_episode_reward": -42.35, "episode_reward_trend_value": 0.009498450781573967, "biggest_recent_change": 0.3466596159429898},
{"total_number_of_episodes": 19060, "number_of_timesteps": 19060000, "per_episode_reward": -42.34, "episode_reward_trend_value": 0.005991155850685144, "biggest_recent_change": 0.3466596159429898},
{"total_number_of_episodes": 19070, "number_of_timesteps": 19070000, "per_episode_reward": -42.52, "episode_reward_trend_value": 0.0006981333663711256, "biggest_recent_change": 0.3466596159429898},
{"total_number_of_episodes": 19080, "number_of_timesteps": 19080000, "per_episode_reward": -42.45, "episode_reward_trend_value": 0.0031557886636512144, "biggest_recent_change": 0.3466596159429898},
{"total_number_of_episodes": 19090, "number_of_timesteps": 19090000, "per_episode_reward": -42.56, "episode_reward_trend_value": 0.0025260634321695994, "biggest_recent_change": 0.3466596159429898},
{"total_number_of_episodes": 19100, "number_of_timesteps": 19100000, "per_episode_reward": -42.3, "episode_reward_trend_value": 0.007674327694832467, "biggest_recent_change": 0.3466596159429898},
{"total_number_of_episodes": 19110, "number_of_timesteps": 19110000, "per_episode_reward": -42.03, "episode_reward_trend_value": 0.009384028787980251, "biggest_recent_change": 0.3466596159429898},
{"total_number_of_episodes": 19120, "number_of_timesteps": 19120000, "per_episode_reward": -41.86, "episode_reward_trend_value": 0.010447312152990742, "biggest_recent_change": 0.3466596159429898},
{"total_number_of_episodes": 19130, "number_of_timesteps": 19130000, "per_episode_reward": -41.88, "episode_reward_trend_value": 0.006351470520839087, "biggest_recent_change": 0.2695440310123871},
{"total_number_of_episodes": 19140, "number_of_timesteps": 19140000, "per_episode_reward": -41.58, "episode_reward_trend_value": 0.008515764953569753, "biggest_recent_change": 0.2953366785170459},
{"total_number_of_episodes": 19150, "number_of_timesteps": 19150000, "per_episode_reward": -41.53, "episode_reward_trend_value": 0.008969564721652211, "biggest_recent_change": 0.2953366785170459},
{"total_number_of_episodes": 19160, "number_of_timesteps": 19160000, "per_episode_reward": -41.83, "episode_reward_trend_value": 0.007618052716219381, "biggest_recent_change": 0.2993826125491097},
{"total_number_of_episodes": 19170, "number_of_timesteps": 19170000, "per_episode_reward": -42.26, "episode_reward_trend_value": 0.0020776789743390763, "biggest_recent_change": 0.43309405900856746},
{"total_number_of_episodes": 19180, "number_of_timesteps": 19180000, "per_episode_reward": -41.83, "episode_reward_trend_value": 0.008059294576295567, "biggest_recent_change": 0.43309405900856746},
{"total_number_of_episodes": 19190, "number_of_timesteps": 19190000, "per_episode_reward": -41.39, "episode_reward_trend_value": 0.010114625754309811, "biggest_recent_change": 0.44081494714644265},
{"total_number_of_episodes": 19200, "number_of_timesteps": 19200000, "per_episode_reward": -41.43, "episode_reward_trend_value": 0.006681379249287763, "biggest_recent_change": 0.44081494714644265},
{"total_number_of_episodes": 19210, "number_of_timesteps": 19210000, "per_episode_reward": -41.18, "episode_reward_trend_value": 0.007513018632258747, "biggest_recent_change": 0.44081494714644265},
{"total_number_of_episodes": 19220, "number_of_timesteps": 19220000, "per_episode_reward": -41.0, "episode_reward_trend_value": 0.009777271407508753, "biggest_recent_change": 0.44081494714644265},
{"total_number_of_episodes": 19230, "number_of_timesteps": 19230000, "per_episode_reward": -41.25, "episode_reward_trend_value": 0.0036485323156107085, "biggest_recent_change": 0.44081494714644265},
{"total_number_of_episodes": 19240, "number_of_timesteps": 19240000, "per_episode_reward": -41.58, "episode_reward_trend_value": -0.000580773589821288, "biggest_recent_change": 0.44081494714644265},
{"total_number_of_episodes": 19250, "number_of_timesteps": 19250000, "per_episode_reward": -41.56, "episode_reward_trend_value": 0.003005669389936985, "biggest_recent_change": 0.44081494714644265},
{"total_number_of_episodes": 19260, "number_of_timesteps": 19260000, "per_episode_reward": -40.36, "episode_reward_trend_value": 0.021115790521706243, "biggest_recent_change": 1.1968168428506658},
{"total_number_of_episodes": 19270, "number_of_timesteps": 19270000, "per_episode_reward": -40.64, "episode_reward_trend_value": 0.013214809948633643, "biggest_recent_change": 1.1968168428506658},
{"total_number_of_episodes": 19280, "number_of_timesteps": 19280000, "per_episode_reward": -40.63, "episode_reward_trend_value": 0.00847215731928925, "biggest_recent_change": 1.1968168428506658},
{"total_number_of_episodes": 19290, "number_of_timesteps": 19290000, "per_episode_reward": -40.25, "episode_reward_trend_value": 0.01313718379058607, "biggest_recent_change": 1.1968168428506658},
{"total_number_of_episodes": 19300, "number_of_timesteps": 19300000, "per_episode_reward": -40.37, "episode_reward_trend_value": 0.008952266872979446, "biggest_recent_change": 1.1968168428506658},
{"total_number_of_episodes": 19310, "number_of_timesteps": 19310000, "per_episode_reward": -40.83, "episode_reward_trend_value": 0.001855976467108415, "biggest_recent_change": 1.1968168428506658},
{"total_number_of_episodes": 19320, "number_of_timesteps": 19320000, "per_episode_reward": -40.37, "episode_reward_trend_value": 0.009779302661112075, "biggest_recent_change": 1.1968168428506658},
{"total_number_of_episodes": 19330, "number_of_timesteps": 19330000, "per_episode_reward": -40.1, "episode_reward_trend_value": 0.01643399522190047, "biggest_recent_change": 1.1968168428506658},
{"total_number_of_episodes": 19340, "number_of_timesteps": 19340000, "per_episode_reward": -39.87, "episode_reward_trend_value": 0.01877944944146211, "biggest_recent_change": 1.1968168428506658},
{"total_number_of_episodes": 19350, "number_of_timesteps": 19350000, "per_episode_reward": -40.0, "episode_reward_trend_value": 0.004062123054422449, "biggest_recent_change": 0.45684951770655147},
{"total_number_of_episodes": 19360, "number_of_timesteps": 19360000, "per_episode_reward": -39.73, "episode_reward_trend_value": 0.010090004066198727, "biggest_recent_change": 0.45684951770655147},
{"total_number_of_episodes": 19370, "number_of_timesteps": 19370000, "per_episode_reward": -39.52, "episode_reward_trend_value": 0.012263576996771282, "biggest_recent_change": 0.45684951770655147},
{"total_number_of_episodes": 19380, "number_of_timesteps": 19380000, "per_episode_reward": -39.58, "episode_reward_trend_value": 0.007430368046414454, "biggest_recent_change": 0.45684951770655147},
{"total_number_of_episodes": 19390, "number_of_timesteps": 19390000, "per_episode_reward": -39.38, "episode_reward_trend_value": 0.010988640578179895, "biggest_recent_change": 0.45684951770655147},
{"total_number_of_episodes": 19400, "number_of_timesteps": 19400000, "per_episode_reward": -39.11, "episode_reward_trend_value": 0.019120774966221728, "biggest_recent_change": 0.45684951770655147},
{"total_number_of_episodes": 19410, "number_of_timesteps": 19410000, "per_episode_reward": -39.31, "episode_reward_trend_value": 0.011779217725926907, "biggest_recent_change": 0.2750425772172136},
{"total_number_of_episodes": 19420, "number_of_timesteps": 19420000, "per_episode_reward": -39.36, "episode_reward_trend_value": 0.00821692631433919, "biggest_recent_change": 0.2750425772172136},
{"total_number_of_episodes": 19430, "number_of_timesteps": 19430000, "per_episode_reward": -39.41, "episode_reward_trend_value": 0.005156635645892038, "biggest_recent_change": 0.2750425772172136},
{"total_number_of_episodes": 19440, "number_of_timesteps": 19440000, "per_episode_reward": -39.05, "episode_reward_trend_value": 0.010486982191163384, "biggest_recent_change": 0.3519886570915176},
{"total_number_of_episodes": 19450, "number_of_timesteps": 19450000, "per_episode_reward": -38.72, "episode_reward_trend_value": 0.011288928646963351, "biggest_recent_change": 0.3519886570915176},
{"total_number_of_episodes": 19460, "number_of_timesteps": 19460000, "per_episode_reward": -38.76, "episode_reward_trend_value": 0.00848141612559014, "biggest_recent_change": 0.3519886570915176},
{"total_number_of_episodes": 19470, "number_of_timesteps": 19470000, "per_episode_reward": -38.78, "episode_reward_trend_value": 0.008834417086905926, "biggest_recent_change": 0.3519886570915176},
{"total_number_of_episodes": 19480, "number_of_timesteps": 19480000, "per_episode_reward": -38.65, "episode_reward_trend_value": 0.00816323909414728, "biggest_recent_change": 0.3519886570915176},
{"total_number_of_episodes": 19490, "number_of_timesteps": 19490000, "per_episode_reward": -38.7, "episode_reward_trend_value": 0.004596526922105918, "biggest_recent_change": 0.3519886570915176},
{"total_number_of_episodes": 19500, "number_of_timesteps": 19500000, "per_episode_reward": -38.54, "episode_reward_trend_value": 0.008584390036315328, "biggest_recent_change": 0.3519886570915176},
{"total_number_of_episodes": 19510, "number_of_timesteps": 19510000, "per_episode_reward": -38.33, "episode_reward_trend_value": 0.011517027126404619, "biggest_recent_change": 0.3519886570915176},
{"total_number_of_episodes": 19520, "number_of_timesteps": 19520000, "per_episode_reward": -38.28, "episode_reward_trend_value": 0.012543531005979564, "biggest_recent_change": 0.3519886570915176},
{"total_number_of_episodes": 19530, "number_of_timesteps": 19530000, "per_episode_reward": -38.41, "episode_reward_trend_value": 0.007163036365191526, "biggest_recent_change": 0.3366902795138955},
{"total_number_of_episodes": 19540, "number_of_timesteps": 19540000, "per_episode_reward": -38.37, "episode_reward_trend_value": 0.0038918156657513714, "biggest_recent_change": 0.21209635274314564},
{"total_number_of_episodes": 19550, "number_of_timesteps": 19550000, "per_episode_reward": -38.32, "episode_reward_trend_value": 0.004865795842682275, "biggest_recent_change": 0.21209635274314564},
{"total_number_of_episodes": 19560, "number_of_timesteps": 19560000, "per_episode_reward": -38.35, "episode_reward_trend_value": 0.004817767241259377, "biggest_recent_change": 0.21209635274314564},
{"total_number_of_episodes": 19570, "number_of_timesteps": 19570000, "per_episode_reward": -38.39, "episode_reward_trend_value": 0.002880570455737165, "biggest_recent_change": 0.21209635274314564},
{"total_number_of_episodes": 19580, "number_of_timesteps": 19580000, "per_episode_reward": -38.37, "episode_reward_trend_value": 0.0035781335382683863, "biggest_recent_change": 0.21209635274314564},
{"total_number_of_episodes": 19590, "number_of_timesteps": 19590000, "per_episode_reward": -38.35, "episode_reward_trend_value": 0.0021594833569104645, "biggest_recent_change": 0.21209635274314564},
{"total_number_of_episodes": 19600, "number_of_timesteps": 19600000, "per_episode_reward": -38.36, "episode_reward_trend_value": -0.00033905683022534086, "biggest_recent_change": 0.13225586057940575},
{"total_number_of_episodes": 19610, "number_of_timesteps": 19610000, "per_episode_reward": -38.43, "episode_reward_trend_value": -0.0017326293703768495, "biggest_recent_change": 0.13225586057940575},
{"total_number_of_episodes": 19620, "number_of_timesteps": 19620000, "per_episode_reward": -38.57, "episode_reward_trend_value": -0.001776587787139287, "biggest_recent_change": 0.13621211808802514},
{"total_number_of_episodes": 19630, "number_of_timesteps": 19630000, "per_episode_reward": -38.52, "episode_reward_trend_value": -0.001710101998276296, "biggest_recent_change": 0.13621211808802514},
{"total_number_of_episodes": 19640, "number_of_timesteps": 19640000, "per_episode_reward": -37.89, "episode_reward_trend_value": 0.004778203394768433, "biggest_recent_change": 0.6285273486311951},
{"total_number_of_episodes": 19650, "number_of_timesteps": 19650000, "per_episode_reward": -37.65, "episode_reward_trend_value": 0.007759315021930588, "biggest_recent_change": 0.6285273486311951},
{"total_number_of_episodes": 19660, "number_of_timesteps": 19660000, "per_episode_reward": -37.24, "episode_reward_trend_value": 0.012780139119602296, "biggest_recent_change": 0.6285273486311951},
{"total_number_of_episodes": 19670, "number_of_timesteps": 19670000, "per_episode_reward": -36.78, "episode_reward_trend_value": 0.01774177409451446, "biggest_recent_change": 0.6285273486311951},
{"total_number_of_episodes": 19680, "number_of_timesteps": 19680000, "per_episode_reward": -36.81, "episode_reward_trend_value": 0.01706548522636003, "biggest_recent_change": 0.6285273486311951},
{"total_number_of_episodes": 19690, "number_of_timesteps": 19690000, "per_episode_reward": -36.3, "episode_reward_trend_value": 0.02288808214467611, "biggest_recent_change": 0.6285273486311951},
{"total_number_of_episodes": 19700, "number_of_timesteps": 19700000, "per_episode_reward": -36.06, "episode_reward_trend_value": 0.02636528828614612, "biggest_recent_change": 0.6285273486311951},
{"total_number_of_episodes": 19710, "number_of_timesteps": 19710000, "per_episode_reward": -36.01, "episode_reward_trend_value": 0.02842379343122674, "biggest_recent_change": 0.6285273486311951},
{"total_number_of_episodes": 19720, "number_of_timesteps": 19720000, "per_episode_reward": -35.72, "episode_reward_trend_value": 0.03108845286487407, "biggest_recent_change": 0.6285273486311951},
{"total_number_of_episodes": 19730, "number_of_timesteps": 19730000, "per_episode_reward": -35.65, "episode_reward_trend_value": 0.024877138027240557, "biggest_recent_change": 0.5112614585493702},
{"total_number_of_episodes": 19740, "number_of_timesteps": 19740000, "per_episode_reward": -35.6, "episode_reward_trend_value": 0.022782661894644306, "biggest_recent_change": 0.5112614585493702},
{"total_number_of_episodes": 19750, "number_of_timesteps": 19750000, "per_episode_reward": -35.68, "episode_reward_trend_value": 0.01736656956516743, "biggest_recent_change": 0.5112614585493702},
{"total_number_of_episodes": 19760, "number_of_timesteps": 19760000, "per_episode_reward": -35.51, "episode_reward_trend_value": 0.014078792568211738, "biggest_recent_change": 0.5112614585493702},
{"total_number_of_episodes": 19770, "number_of_timesteps": 19770000, "per_episode_reward": -35.24, "episode_reward_trend_value": 0.01740094784833646, "biggest_recent_change": 0.5112614585493702},
{"total_number_of_episodes": 19780, "number_of_timesteps": 19780000, "per_episode_reward": -35.12, "episode_reward_trend_value": 0.013071831948643916, "biggest_recent_change": 0.2880834865902102},
{"total_number_of_episodes": 19790, "number_of_timesteps": 19790000, "per_episode_reward": -35.2, "episode_reward_trend_value": 0.009605187791676429, "biggest_recent_change": 0.2880834865902102},
{"total_number_of_episodes": 19800, "number_of_timesteps": 19800000, "per_episode_reward": -35.01, "episode_reward_trend_value": 0.01114123443091341, "biggest_recent_change": 0.2880834865902102},
{"total_number_of_episodes": 19810, "number_of_timesteps": 19810000, "per_episode_reward": -35.12, "episode_reward_trend_value": 0.006716022478612633, "biggest_recent_change": 0.26546650711397746},
{"total_number_of_episodes": 19820, "number_of_timesteps": 19820000, "per_episode_reward": -34.99, "episode_reward_trend_value": 0.007424662965679908, "biggest_recent_change": 0.26546650711397746},
