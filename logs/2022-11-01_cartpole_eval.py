config = {
    "evaluation": {
        "enabled": True, 
        "number_of_epsiodes_during_eval": 10, 
        "number_of_episodes_before_eval": 130, 
    }, 
    "verbose": True, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": [
        0.1, 
        0.08, 
        0.063, 
        0.05, 
        0.04, 
        0.032, 
        0.025, 
        0.02, 
        0.016, 
        0.012, 
        0.01, 
        0.008, 
        0.0063, 
        0.005, 
        0.004, 
        0.0032, 
        0.0025, 
        0.002, 
        0.0016, 
        0.0012, 
        0.001, 
        0.0008, 
        0.00063, 
        0.0005, 
        0.0004, 
        0.00032, 
        0.00025, 
        0.0002, 
        0.00016, 
        0.00012, 
        1e-05, 
        8e-06, 
        6.3e-06, 
        5e-06, 
        4e-06, 
        3.2e-06, 
        2.5e-06, 
        2e-06, 
        1.6e-06, 
        1.2e-06, 
    ], 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": [0, ], 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0, 
        "min_number_of_episodes": 30, 
        "thresholds": {}, 
    }, 
    "training": {
        "episode_count": 100000, 
    },
    "env_config": {
        "env_name": "CartPole-v1", 
        "learning_rate": 0.001, 
        "beta": 2e-05, 
        "t_max": 5, 
        "activation": 1, 
        "hidden_size": 64, 
        "permaban_threshold": 500, 
        "variance_scaling_factor": 1, 
    }, 
}
args = {
    "processes": 10, 
    "env": "CartPole-v1", 
    "seed": 173593691, 
    "outdir": "results", 
    "t_max": 5, 
    "beta": 2e-05, 
    "profile": False, 
    "steps": 100000, 
    "max_frames": (108000, ), 
    "lr": 0.001, 
    "eval_interval": 250000, 
    "eval_n_steps": 125000, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 500, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 1, 
}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]

[starting run_func()]
[starting train_loop()]
Step 0 0 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 1 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-3.24, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 2 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-3.24, -3.009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 3 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 3 q_vals: [-3.24, -3.009, -2.908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 4 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 5 q_vals: [-3.24, -3.009, -2.908, -4.546, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 5 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 7 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, 0.0, 0.0, 0.0, 0.0, 0.0]
Step 6 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 7 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, 0.0, 0.0, 0.0, 0.0]
Step 7 6 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 9 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, 0.0, 0.0, 0.0]
Step 8 7 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 12 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, 0.0]
Step 9 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 13 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, 0.0]
Step 10 9 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 16 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 11 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0]  episode_count: 17 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 12 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0]  episode_count: 18 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 13 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0]  episode_count: 20 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 14 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0, 1.0]  episode_count: 23 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 15 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 6.0, 1.0]  episode_count: 24 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 16 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 7.0, 1.0]  episode_count: 27 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 32, "number_of_timesteps": 751, "per_episode_reward": 27.15, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Step 17 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 8.0, 1.0]  episode_count: 32 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 18 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 9.0, 1.0]  episode_count: 33 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 19 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 10.0, 1.0]  episode_count: 35 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 20 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 11.0, 1.0]  episode_count: 38 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 21 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 12.0, 1.0]  episode_count: 40 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 22 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 13.0, 1.0]  episode_count: 40 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 43, "number_of_timesteps": 951, "per_episode_reward": 20.2, "episode_reward_trend_value": -0.695, "biggest_recent_change": NaN},
Step 23 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 14.0, 1.0]  episode_count: 43 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 24 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 15.0, 1.0]  episode_count: 46 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 25 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 16.0, 1.0]  episode_count: 49 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 26 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 17.0, 1.0]  episode_count: 51 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 53, "number_of_timesteps": 1152, "per_episode_reward": 19.55, "episode_reward_trend_value": -0.3799999999999999, "biggest_recent_change": NaN},
Step 27 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 18.0, 1.0]  episode_count: 53 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 28 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 19.0, 1.0]  episode_count: 54 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 29 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 20.0, 1.0]  episode_count: 60 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 30 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 21.0, 1.0]  episode_count: 61 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 64, "number_of_timesteps": 1369, "per_episode_reward": 19.45, "episode_reward_trend_value": -0.25666666666666665, "biggest_recent_change": NaN},
Step 31 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 22.0, 1.0]  episode_count: 64 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 32 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 23.0, 1.0]  episode_count: 65 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 33 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 24.0, 1.0]  episode_count: 66 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 34 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 25.0, 1.0]  episode_count: 71 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 35 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 26.0, 1.0]  episode_count: 73 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 74, "number_of_timesteps": 1551, "per_episode_reward": 19.35, "episode_reward_trend_value": -0.19499999999999992, "biggest_recent_change": NaN},
Step 36 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 27.0, 1.0]  episode_count: 74 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 37 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 28.0, 1.0]  episode_count: 76 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 38 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 29.0, 1.0]  episode_count: 80 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 39 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 30.0, 1.0]  episode_count: 80 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 40 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 31.0, 1.0]  episode_count: 82 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 84, "number_of_timesteps": 1747, "per_episode_reward": 19.25, "episode_reward_trend_value": -0.15799999999999997, "biggest_recent_change": NaN},
Step 41 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 32.0, 1.0]  episode_count: 84 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 42 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 33.0, 1.0]  episode_count: 85 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 43 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 34.0, 1.0]  episode_count: 87 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 44 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 35.0, 1.0]  episode_count: 89 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 45 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 36.0, 1.0]  episode_count: 93 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 96, "number_of_timesteps": 2042, "per_episode_reward": 19.8, "episode_reward_trend_value": -0.12249999999999997, "biggest_recent_change": NaN},
Step 46 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 37.0, 1.0]  episode_count: 96 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 47 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 38.0, 1.0]  episode_count: 97 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 48 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 39.0, 1.0]  episode_count: 97 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 49 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 40.0, 1.0]  episode_count: 100 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 50 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 41.0, 1.0]  episode_count: 101 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 51 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 42.0, 1.0]  episode_count: 103 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 106, "number_of_timesteps": 2304, "per_episode_reward": 20.2, "episode_reward_trend_value": -0.09928571428571428, "biggest_recent_change": NaN},
Step 52 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 43.0, 1.0]  episode_count: 106 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 53 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 44.0, 1.0]  episode_count: 108 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 54 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 45.0, 1.0]  episode_count: 111 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 55 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 46.0, 1.0]  episode_count: 112 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 56 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 47.0, 1.0]  episode_count: 114 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 117, "number_of_timesteps": 2538, "per_episode_reward": 20.05, "episode_reward_trend_value": -0.08874999999999997, "biggest_recent_change": NaN},
Step 57 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 48.0, 1.0]  episode_count: 117 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 58 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 49.0, 1.0]  episode_count: 118 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 59 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 50.0, 1.0]  episode_count: 120 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 60 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 51.0, 1.0]  episode_count: 124 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 61 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 52.0, 1.0]  episode_count: 125 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 62 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 53.0, 1.0]  episode_count: 125 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 128, "number_of_timesteps": 2789, "per_episode_reward": 19.25, "episode_reward_trend_value": -0.08777777777777776, "biggest_recent_change": 6.949999999999999},
Step 63 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 54.0, 1.0]  episode_count: 128 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 64 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 55.0, 1.0]  episode_count: 128 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 65 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 56.0, 1.0]  episode_count: 132 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 66 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 57.0, 1.0]  episode_count: 135 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 67 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 58.0, 1.0]  episode_count: 135 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 68 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 59.0, 1.0]  episode_count: 137 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 141, "number_of_timesteps": 3121, "per_episode_reward": 19.95, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.8000000000000007},
Step 69 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 60.0, 1.0]  episode_count: 141 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 70 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 61.0, 1.0]  episode_count: 143 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 71 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 62.0, 1.0]  episode_count: 145 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 72 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 63.0, 1.0]  episode_count: 146 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 73 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 64.0, 1.0]  episode_count: 149 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 153, "number_of_timesteps": 3368, "per_episode_reward": 19.1, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.8499999999999979},
Step 74 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 65.0, 1.0]  episode_count: 153 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 75 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 66.0, 1.0]  episode_count: 153 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 76 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 67.0, 1.0]  episode_count: 153 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 77 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 68.0, 1.0]  episode_count: 158 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 78 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 69.0, 1.0]  episode_count: 161 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 163, "number_of_timesteps": 3581, "per_episode_reward": 19.25, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.8499999999999979},
Step 79 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 70.0, 1.0]  episode_count: 163 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 80 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 71.0, 1.0]  episode_count: 164 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 81 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 72.0, 1.0]  episode_count: 167 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 82 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 73.0, 1.0]  episode_count: 168 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 83 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 74.0, 1.0]  episode_count: 169 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 84 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 75.0, 1.0]  episode_count: 171 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 174, "number_of_timesteps": 3830, "per_episode_reward": 18.85, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.8499999999999979},
Step 85 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 76.0, 1.0]  episode_count: 174 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 86 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 77.0, 1.0]  episode_count: 176 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 87 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 78.0, 1.0]  episode_count: 177 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 88 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 79.0, 1.0]  episode_count: 181 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 89 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 80.0, 1.0]  episode_count: 181 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 90 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 81.0, 1.0]  episode_count: 183 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 188, "number_of_timesteps": 4153, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.8499999999999979},
Step 91 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 82.0, 1.0]  episode_count: 188 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 92 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 83.0, 1.0]  episode_count: 190 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 93 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 84.0, 1.0]  episode_count: 190 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 94 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 85.0, 1.0]  episode_count: 194 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 95 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 86.0, 1.0]  episode_count: 196 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 96 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 87.0, 1.0]  episode_count: 197 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 198, "number_of_timesteps": 4338, "per_episode_reward": 18.6, "episode_reward_trend_value": -0.013333333333333326, "biggest_recent_change": 0.8499999999999979},
Step 97 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 88.0, 1.0]  episode_count: 198 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 98 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 89.0, 1.0]  episode_count: 200 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 99 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 90.0, 1.0]  episode_count: 203 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 100 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 91.0, 1.0]  episode_count: 204 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 208, "number_of_timesteps": 4609, "per_episode_reward": 18.95, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.8499999999999979},
Step 101 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 92.0, 1.0]  episode_count: 208 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 102 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 93.0, 1.0]  episode_count: 211 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 103 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 94.0, 1.0]  episode_count: 214 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 104 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 95.0, 1.0]  episode_count: 217 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 219, "number_of_timesteps": 4769, "per_episode_reward": 18.7, "episode_reward_trend_value": -0.015000000000000017, "biggest_recent_change": 0.8499999999999979},
Step 105 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 96.0, 1.0]  episode_count: 219 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 106 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 97.0, 1.0]  episode_count: 221 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 107 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 98.0, 1.0]  episode_count: 224 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 108 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 99.0, 1.0]  episode_count: 227 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 230, "number_of_timesteps": 4973, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 0.8499999999999979},
Step 109 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 100.0, 1.0]  episode_count: 230 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 110 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 101.0, 1.0]  episode_count: 231 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 111 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 102.0, 1.0]  episode_count: 231 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 112 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 103.0, 1.0]  episode_count: 237 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 113 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 104.0, 1.0]  episode_count: 237 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 114 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 105.0, 1.0]  episode_count: 237 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 241, "number_of_timesteps": 5157, "per_episode_reward": 18.05, "episode_reward_trend_value": -0.021111111111111094, "biggest_recent_change": 0.8499999999999979},
Step 115 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 106.0, 1.0]  episode_count: 241 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 116 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 107.0, 1.0]  episode_count: 242 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 117 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 108.0, 1.0]  episode_count: 242 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 118 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 109.0, 1.0]  episode_count: 243 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 119 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 110.0, 1.0]  episode_count: 249 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 120 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 111.0, 1.0]  episode_count: 249 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 121 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 112.0, 1.0]  episode_count: 250 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 252, "number_of_timesteps": 5504, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3999999999999986},
Step 122 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 113.0, 1.0]  episode_count: 252 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 123 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 114.0, 1.0]  episode_count: 256 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 124 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 115.0, 1.0]  episode_count: 260 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 262, "number_of_timesteps": 5703, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.3999999999999986},
Step 125 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 116.0, 1.0]  episode_count: 262 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 126 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 117.0, 1.0]  episode_count: 265 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 127 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 118.0, 1.0]  episode_count: 267 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 128 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 119.0, 1.0]  episode_count: 268 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 129 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 120.0, 1.0]  episode_count: 271 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 272, "number_of_timesteps": 5850, "per_episode_reward": 18.05, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3999999999999986},
Step 130 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 121.0, 1.0]  episode_count: 272 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 131 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 122.0, 1.0]  episode_count: 275 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 132 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 123.0, 1.0]  episode_count: 276 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 133 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 124.0, 1.0]  episode_count: 278 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 134 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 125.0, 1.0]  episode_count: 281 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 282, "number_of_timesteps": 6090, "per_episode_reward": 18.15, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.3999999999999986},
Step 135 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 126.0, 1.0]  episode_count: 282 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 136 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 127.0, 1.0]  episode_count: 285 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 137 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 128.0, 1.0]  episode_count: 288 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 293, "number_of_timesteps": 6314, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.3999999999999986},
Step 138 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 129.0, 1.0]  episode_count: 293 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 139 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 130.0, 1.0]  episode_count: 293 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 140 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 131.0, 1.0]  episode_count: 296 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 141 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 132.0, 1.0]  episode_count: 299 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 142 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 133.0, 1.0]  episode_count: 302 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 303, "number_of_timesteps": 6484, "per_episode_reward": 17.85, "episode_reward_trend_value": -0.012222222222222199, "biggest_recent_change": 0.3999999999999986},
Step 143 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 134.0, 1.0]  episode_count: 303 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 144 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 135.0, 1.0]  episode_count: 304 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 145 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 136.0, 1.0]  episode_count: 304 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 146 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 137.0, 1.0]  episode_count: 309 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 147 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 138.0, 1.0]  episode_count: 311 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 314, "number_of_timesteps": 6726, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3999999999999986},
Step 148 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 139.0, 1.0]  episode_count: 314 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 149 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 140.0, 1.0]  episode_count: 317 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 150 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 141.0, 1.0]  episode_count: 319 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 151 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 142.0, 1.0]  episode_count: 323 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 324, "number_of_timesteps": 6901, "per_episode_reward": 17.85, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
Step 152 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 143.0, 1.0]  episode_count: 324 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 153 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 144.0, 1.0]  episode_count: 327 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 154 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 145.0, 1.0]  episode_count: 332 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 155 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 146.0, 1.0]  episode_count: 332 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 156 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 147.0, 1.0]  episode_count: 332 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 337, "number_of_timesteps": 7136, "per_episode_reward": 17.75, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.25},
Step 157 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 148.0, 1.0]  episode_count: 337 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 158 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 149.0, 1.0]  episode_count: 339 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 159 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 150.0, 1.0]  episode_count: 342 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 160 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 151.0, 1.0]  episode_count: 344 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 161 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 152.0, 1.0]  episode_count: 346 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 349, "number_of_timesteps": 7339, "per_episode_reward": 17.8, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
Step 162 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 153.0, 1.0]  episode_count: 349 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 163 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 154.0, 1.0]  episode_count: 351 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 164 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 155.0, 1.0]  episode_count: 354 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 165 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 156.0, 1.0]  episode_count: 358 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 360, "number_of_timesteps": 7529, "per_episode_reward": 17.85, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
Step 166 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 157.0, 1.0]  episode_count: 360 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 167 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 158.0, 1.0]  episode_count: 362 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 168 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 159.0, 1.0]  episode_count: 365 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 169 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 160.0, 1.0]  episode_count: 367 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 370, "number_of_timesteps": 7684, "per_episode_reward": 17.65, "episode_reward_trend_value": -0.004444444444444468, "biggest_recent_change": 0.20000000000000284},
Step 170 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 161.0, 1.0]  episode_count: 370 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 171 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 162.0, 1.0]  episode_count: 371 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 172 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 163.0, 1.0]  episode_count: 374 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 173 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 164.0, 1.0]  episode_count: 376 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 174 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 165.0, 1.0]  episode_count: 378 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 382, "number_of_timesteps": 7895, "per_episode_reward": 17.6, "episode_reward_trend_value": -0.006111111111111079, "biggest_recent_change": 0.20000000000000284},
Step 175 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 166.0, 1.0]  episode_count: 382 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 176 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 167.0, 1.0]  episode_count: 383 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 177 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 168.0, 1.0]  episode_count: 386 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 178 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 169.0, 1.0]  episode_count: 389 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 179 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 170.0, 1.0]  episode_count: 390 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 394, "number_of_timesteps": 8143, "per_episode_reward": 17.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000284},
Step 180 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 171.0, 1.0]  episode_count: 394 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 181 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 172.0, 1.0]  episode_count: 396 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 182 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 173.0, 1.0]  episode_count: 401 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 183 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 174.0, 1.0]  episode_count: 402 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 184 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 175.0, 1.0]  episode_count: 402 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 405, "number_of_timesteps": 8346, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.20000000000000284},
Step 185 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 176.0, 1.0]  episode_count: 405 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 186 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 177.0, 1.0]  episode_count: 410 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 187 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 178.0, 1.0]  episode_count: 411 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 188 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 179.0, 1.0]  episode_count: 413 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 418, "number_of_timesteps": 8554, "per_episode_reward": 17.4, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.20000000000000284},
Step 189 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 180.0, 1.0]  episode_count: 418 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 190 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 181.0, 1.0]  episode_count: 420 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 191 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 182.0, 1.0]  episode_count: 421 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 192 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 183.0, 1.0]  episode_count: 425 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 193 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 184.0, 1.0]  episode_count: 427 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 428, "number_of_timesteps": 8753, "per_episode_reward": 17.4, "episode_reward_trend_value": -0.005000000000000031, "biggest_recent_change": 0.20000000000000284},
Step 194 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 185.0, 1.0]  episode_count: 428 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 195 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 186.0, 1.0]  episode_count: 429 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 196 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 187.0, 1.0]  episode_count: 430 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 197 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 188.0, 1.0]  episode_count: 431 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 198 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 189.0, 1.0]  episode_count: 436 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 439, "number_of_timesteps": 9012, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.20000000000000284},
Step 199 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 190.0, 1.0]  episode_count: 439 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 200 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 191.0, 1.0]  episode_count: 439 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 201 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 192.0, 1.0]  episode_count: 441 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 202 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 193.0, 1.0]  episode_count: 444 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 203 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 194.0, 1.0]  episode_count: 447 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 450, "number_of_timesteps": 9198, "per_episode_reward": 17.55, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.20000000000000284},
Step 204 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 195.0, 1.0]  episode_count: 450 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 205 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 196.0, 1.0]  episode_count: 452 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 206 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 197.0, 1.0]  episode_count: 455 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 207 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 198.0, 1.0]  episode_count: 458 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 208 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 199.0, 1.0]  episode_count: 459 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 209 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 200.0, 1.0]  episode_count: 459 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 463, "number_of_timesteps": 9484, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.004444444444444468, "biggest_recent_change": 0.20000000000000284},
Step 210 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 201.0, 1.0]  episode_count: 463 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 211 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 202.0, 1.0]  episode_count: 463 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 212 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 203.0, 1.0]  episode_count: 465 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 213 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 204.0, 1.0]  episode_count: 469 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 214 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 205.0, 1.0]  episode_count: 469 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 215 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 206.0, 1.0]  episode_count: 470 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 474, "number_of_timesteps": 9721, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
Step 216 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 207.0, 1.0]  episode_count: 474 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 217 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 208.0, 1.0]  episode_count: 476 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 218 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 209.0, 1.0]  episode_count: 476 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 219 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 210.0, 1.0]  episode_count: 479 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 220 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 211.0, 1.0]  episode_count: 481 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 221 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 212.0, 1.0]  episode_count: 483 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 486, "number_of_timesteps": 10025, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
Step 222 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 213.0, 1.0]  episode_count: 486 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 223 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 214.0, 1.0]  episode_count: 486 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 224 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 215.0, 1.0]  episode_count: 491 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 225 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 216.0, 1.0]  episode_count: 492 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 226 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 217.0, 1.0]  episode_count: 495 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 498, "number_of_timesteps": 10305, "per_episode_reward": 17.6, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.1999999999999993},
Step 227 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 218.0, 1.0]  episode_count: 498 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 228 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 219.0, 1.0]  episode_count: 500 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 229 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 220.0, 1.0]  episode_count: 500 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 230 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 221.0, 1.0]  episode_count: 501 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 231 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 222.0, 1.0]  episode_count: 507 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 508, "number_of_timesteps": 10535, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000213},
Step 232 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 223.0, 1.0]  episode_count: 508 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 233 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 224.0, 1.0]  episode_count: 511 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 234 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 225.0, 1.0]  episode_count: 512 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 235 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 226.0, 1.0]  episode_count: 514 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 236 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 227.0, 1.0]  episode_count: 517 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 519, "number_of_timesteps": 10745, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.15000000000000213},
Step 237 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 228.0, 1.0]  episode_count: 519 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 238 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 229.0, 1.0]  episode_count: 522 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 239 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 230.0, 1.0]  episode_count: 524 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 240 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 231.0, 1.0]  episode_count: 526 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 241 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 232.0, 1.0]  episode_count: 527 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 532, "number_of_timesteps": 10995, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.15000000000000213},
Step 242 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 233.0, 1.0]  episode_count: 532 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 243 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 234.0, 1.0]  episode_count: 534 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 244 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 235.0, 1.0]  episode_count: 536 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 245 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 236.0, 1.0]  episode_count: 538 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 246 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 237.0, 1.0]  episode_count: 541 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 542, "number_of_timesteps": 11200, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000213},
Step 247 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 238.0, 1.0]  episode_count: 542 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 248 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 239.0, 1.0]  episode_count: 545 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 249 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 240.0, 1.0]  episode_count: 546 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 250 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 241.0, 1.0]  episode_count: 548 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 251 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 242.0, 1.0]  episode_count: 549 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 252 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 243.0, 1.0]  episode_count: 551 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 553, "number_of_timesteps": 11444, "per_episode_reward": 17.75, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000213},
Step 253 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 244.0, 1.0]  episode_count: 553 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 254 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 245.0, 1.0]  episode_count: 555 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 255 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 246.0, 1.0]  episode_count: 557 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 256 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 247.0, 1.0]  episode_count: 560 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 257 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 248.0, 1.0]  episode_count: 561 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 564, "number_of_timesteps": 11706, "per_episode_reward": 17.85, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.15000000000000213},
Step 258 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 249.0, 1.0]  episode_count: 564 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 259 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 250.0, 1.0]  episode_count: 567 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 260 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 251.0, 1.0]  episode_count: 569 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 261 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 252.0, 1.0]  episode_count: 572 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 574, "number_of_timesteps": 11884, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.15000000000000213},
Step 262 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 253.0, 1.0]  episode_count: 574 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 263 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 254.0, 1.0]  episode_count: 577 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 264 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 255.0, 1.0]  episode_count: 578 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 265 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 256.0, 1.0]  episode_count: 580 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 584, "number_of_timesteps": 12089, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.10000000000000142},
Step 266 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 257.0, 1.0]  episode_count: 584 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 267 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 258.0, 1.0]  episode_count: 586 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 268 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 259.0, 1.0]  episode_count: 587 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 269 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 260.0, 1.0]  episode_count: 588 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 270 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 261.0, 1.0]  episode_count: 590 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 594, "number_of_timesteps": 12295, "per_episode_reward": 17.65, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.10000000000000142},
Step 271 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 262.0, 1.0]  episode_count: 594 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 272 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 263.0, 1.0]  episode_count: 595 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 273 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 264.0, 1.0]  episode_count: 597 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 274 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 265.0, 1.0]  episode_count: 599 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 275 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 266.0, 1.0]  episode_count: 602 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 605, "number_of_timesteps": 12561, "per_episode_reward": 17.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 276 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 267.0, 1.0]  episode_count: 605 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 277 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 268.0, 1.0]  episode_count: 605 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 278 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 269.0, 1.0]  episode_count: 609 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 279 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 270.0, 1.0]  episode_count: 612 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 280 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 271.0, 1.0]  episode_count: 613 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 281 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 272.0, 1.0]  episode_count: 614 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 618, "number_of_timesteps": 12810, "per_episode_reward": 17.75, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.10000000000000142},
Step 282 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 273.0, 1.0]  episode_count: 618 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 283 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 274.0, 1.0]  episode_count: 620 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 284 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 275.0, 1.0]  episode_count: 623 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 285 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 276.0, 1.0]  episode_count: 624 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 286 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 277.0, 1.0]  episode_count: 626 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 629, "number_of_timesteps": 13004, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.10000000000000142},
Step 287 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 278.0, 1.0]  episode_count: 629 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 288 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 279.0, 1.0]  episode_count: 633 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 289 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 280.0, 1.0]  episode_count: 634 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 290 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 281.0, 1.0]  episode_count: 635 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 639, "number_of_timesteps": 13235, "per_episode_reward": 17.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 291 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 282.0, 1.0]  episode_count: 639 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 292 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 283.0, 1.0]  episode_count: 641 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 293 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 284.0, 1.0]  episode_count: 644 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 294 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 285.0, 1.0]  episode_count: 646 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 649, "number_of_timesteps": 13409, "per_episode_reward": 17.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 295 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 286.0, 1.0]  episode_count: 649 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 296 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 287.0, 1.0]  episode_count: 650 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 297 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 288.0, 1.0]  episode_count: 652 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 298 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 289.0, 1.0]  episode_count: 654 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 299 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 290.0, 1.0]  episode_count: 657 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 661, "number_of_timesteps": 13677, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.1999999999999993},
Step 300 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 291.0, 1.0]  episode_count: 661 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 301 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 292.0, 1.0]  episode_count: 662 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 302 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 293.0, 1.0]  episode_count: 663 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 303 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 294.0, 1.0]  episode_count: 668 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 304 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 295.0, 1.0]  episode_count: 668 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 671, "number_of_timesteps": 13854, "per_episode_reward": 17.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
Step 305 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 296.0, 1.0]  episode_count: 671 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 306 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 297.0, 1.0]  episode_count: 673 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 307 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 298.0, 1.0]  episode_count: 676 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 308 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 299.0, 1.0]  episode_count: 680 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 682, "number_of_timesteps": 14064, "per_episode_reward": 17.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
Step 309 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 300.0, 1.0]  episode_count: 682 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 310 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 301.0, 1.0]  episode_count: 685 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 311 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 302.0, 1.0]  episode_count: 688 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 312 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 303.0, 1.0]  episode_count: 690 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 692, "number_of_timesteps": 14225, "per_episode_reward": 17.6, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.1999999999999993},
Step 313 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 304.0, 1.0]  episode_count: 692 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 314 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 305.0, 1.0]  episode_count: 694 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 315 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 306.0, 1.0]  episode_count: 696 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 316 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 307.0, 1.0]  episode_count: 699 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 317 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 308.0, 1.0]  episode_count: 701 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 707, "number_of_timesteps": 14513, "per_episode_reward": 17.6, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.1999999999999993},
Step 318 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 309.0, 1.0]  episode_count: 707 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 319 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 310.0, 1.0]  episode_count: 709 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 320 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 311.0, 1.0]  episode_count: 709 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 321 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 312.0, 1.0]  episode_count: 712 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 322 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 313.0, 1.0]  episode_count: 713 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 323 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 314.0, 1.0]  episode_count: 714 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 324 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 315.0, 1.0]  episode_count: 715 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 719, "number_of_timesteps": 14747, "per_episode_reward": 17.55, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
Step 325 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 316.0, 1.0]  episode_count: 719 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 326 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 317.0, 1.0]  episode_count: 722 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 327 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 318.0, 1.0]  episode_count: 723 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 328 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 319.0, 1.0]  episode_count: 725 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 329 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 320.0, 1.0]  episode_count: 727 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 729, "number_of_timesteps": 14981, "per_episode_reward": 17.6, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.1999999999999993},
Step 330 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 321.0, 1.0]  episode_count: 729 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 331 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 322.0, 1.0]  episode_count: 731 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 332 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 323.0, 1.0]  episode_count: 734 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 333 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 324.0, 1.0]  episode_count: 737 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 739, "number_of_timesteps": 15200, "per_episode_reward": 17.55, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
Step 334 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 325.0, 1.0]  episode_count: 739 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 335 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 326.0, 1.0]  episode_count: 743 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 336 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 327.0, 1.0]  episode_count: 744 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 337 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 328.0, 1.0]  episode_count: 745 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 338 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 329.0, 1.0]  episode_count: 748 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 751, "number_of_timesteps": 15414, "per_episode_reward": 17.6, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.1999999999999993},
Step 339 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 330.0, 1.0]  episode_count: 751 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 340 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 331.0, 1.0]  episode_count: 751 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 341 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 332.0, 1.0]  episode_count: 753 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 342 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 333.0, 1.0]  episode_count: 756 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 343 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 334.0, 1.0]  episode_count: 759 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 761, "number_of_timesteps": 15650, "per_episode_reward": 17.55, "episode_reward_trend_value": -0.0038888888888888654, "biggest_recent_change": 0.14999999999999858},
Step 344 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 335.0, 1.0]  episode_count: 761 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 345 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 336.0, 1.0]  episode_count: 764 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 346 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 337.0, 1.0]  episode_count: 765 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 347 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 338.0, 1.0]  episode_count: 766 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 348 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 339.0, 1.0]  episode_count: 770 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 349 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 340.0, 1.0]  episode_count: 770 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 775, "number_of_timesteps": 15959, "per_episode_reward": 17.6, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
Step 350 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 341.0, 1.0]  episode_count: 775 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 351 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 342.0, 1.0]  episode_count: 776 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 352 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 343.0, 1.0]  episode_count: 779 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 353 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 344.0, 1.0]  episode_count: 782 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 354 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 345.0, 1.0]  episode_count: 783 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 355 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 346.0, 1.0]  episode_count: 784 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 786, "number_of_timesteps": 16141, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000213},
Step 356 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 347.0, 1.0]  episode_count: 786 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 357 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 348.0, 1.0]  episode_count: 787 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 358 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 349.0, 1.0]  episode_count: 789 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 359 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 350.0, 1.0]  episode_count: 793 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 360 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 351.0, 1.0]  episode_count: 795 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 796, "number_of_timesteps": 16369, "per_episode_reward": 17.4, "episode_reward_trend_value": -0.002222222222222254, "biggest_recent_change": 0.15000000000000213},
Step 361 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 352.0, 1.0]  episode_count: 796 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 362 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 353.0, 1.0]  episode_count: 799 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 363 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 354.0, 1.0]  episode_count: 803 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 364 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 355.0, 1.0]  episode_count: 804 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 365 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 356.0, 1.0]  episode_count: 805 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 809, "number_of_timesteps": 16618, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.15000000000000213},
Step 366 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 357.0, 1.0]  episode_count: 809 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 367 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 358.0, 1.0]  episode_count: 812 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 368 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 359.0, 1.0]  episode_count: 813 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 369 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 360.0, 1.0]  episode_count: 815 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 370 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 361.0, 1.0]  episode_count: 817 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 819, "number_of_timesteps": 16820, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000213},
Step 371 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 362.0, 1.0]  episode_count: 819 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 372 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 363.0, 1.0]  episode_count: 823 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 373 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 364.0, 1.0]  episode_count: 826 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 374 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 365.0, 1.0]  episode_count: 828 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 830, "number_of_timesteps": 17056, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.15000000000000213},
Step 375 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 366.0, 1.0]  episode_count: 830 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 376 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 367.0, 1.0]  episode_count: 832 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 377 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 368.0, 1.0]  episode_count: 836 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 378 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 369.0, 1.0]  episode_count: 837 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 379 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 370.0, 1.0]  episode_count: 839 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 380 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 371.0, 1.0]  episode_count: 839 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 840, "number_of_timesteps": 17231, "per_episode_reward": 17.4, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.15000000000000213},
Step 381 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 372.0, 1.0]  episode_count: 840 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 382 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 373.0, 1.0]  episode_count: 844 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 383 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 374.0, 1.0]  episode_count: 847 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 384 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 375.0, 1.0]  episode_count: 848 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 385 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 376.0, 1.0]  episode_count: 848 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 851, "number_of_timesteps": 17501, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.15000000000000213},
Step 386 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 377.0, 1.0]  episode_count: 851 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 387 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 378.0, 1.0]  episode_count: 855 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 388 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 379.0, 1.0]  episode_count: 857 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 389 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 380.0, 1.0]  episode_count: 859 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 390 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 381.0, 1.0]  episode_count: 860 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 864, "number_of_timesteps": 17791, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 391 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 382.0, 1.0]  episode_count: 864 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 392 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 383.0, 1.0]  episode_count: 866 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 393 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 384.0, 1.0]  episode_count: 868 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 394 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 385.0, 1.0]  episode_count: 870 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 395 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 386.0, 1.0]  episode_count: 870 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 874, "number_of_timesteps": 18012, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 396 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 387.0, 1.0]  episode_count: 874 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 397 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 388.0, 1.0]  episode_count: 877 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 398 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 389.0, 1.0]  episode_count: 878 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 399 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 390.0, 1.0]  episode_count: 878 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 400 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 391.0, 1.0]  episode_count: 881 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 885, "number_of_timesteps": 18262, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 401 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 392.0, 1.0]  episode_count: 885 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 402 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 393.0, 1.0]  episode_count: 886 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 403 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 394.0, 1.0]  episode_count: 889 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 404 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 395.0, 1.0]  episode_count: 891 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 405 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 396.0, 1.0]  episode_count: 892 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 896, "number_of_timesteps": 18466, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
Step 406 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 397.0, 1.0]  episode_count: 896 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 407 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 398.0, 1.0]  episode_count: 898 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 408 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 399.0, 1.0]  episode_count: 900 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 409 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 400.0, 1.0]  episode_count: 902 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 410 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 401.0, 1.0]  episode_count: 905 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 907, "number_of_timesteps": 18716, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 411 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 402.0, 1.0]  episode_count: 907 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 412 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 403.0, 1.0]  episode_count: 908 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 413 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 404.0, 1.0]  episode_count: 912 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 414 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 405.0, 1.0]  episode_count: 913 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 415 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 406.0, 1.0]  episode_count: 915 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 918, "number_of_timesteps": 18919, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 416 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 407.0, 1.0]  episode_count: 918 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 417 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 408.0, 1.0]  episode_count: 922 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 418 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 409.0, 1.0]  episode_count: 924 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 928, "number_of_timesteps": 19097, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 419 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 410.0, 1.0]  episode_count: 928 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 420 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 411.0, 1.0]  episode_count: 929 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 421 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 412.0, 1.0]  episode_count: 931 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 422 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 413.0, 1.0]  episode_count: 934 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 423 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 414.0, 1.0]  episode_count: 935 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 938, "number_of_timesteps": 19302, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
Step 424 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 415.0, 1.0]  episode_count: 938 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 425 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 416.0, 1.0]  episode_count: 940 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 426 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 417.0, 1.0]  episode_count: 943 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 427 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 418.0, 1.0]  episode_count: 943 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 428 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 419.0, 1.0]  episode_count: 945 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 948, "number_of_timesteps": 19481, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 429 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 420.0, 1.0]  episode_count: 948 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 430 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 421.0, 1.0]  episode_count: 951 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 431 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 422.0, 1.0]  episode_count: 952 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 432 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 423.0, 1.0]  episode_count: 954 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 433 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 424.0, 1.0]  episode_count: 956 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 434 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 425.0, 1.0]  episode_count: 957 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 959, "number_of_timesteps": 19755, "per_episode_reward": 17.65, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
Step 435 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 426.0, 1.0]  episode_count: 959 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 436 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 427.0, 1.0]  episode_count: 961 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 437 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 428.0, 1.0]  episode_count: 963 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 438 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 429.0, 1.0]  episode_count: 965 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 969, "number_of_timesteps": 20000, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
Step 439 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 430.0, 1.0]  episode_count: 969 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 440 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 431.0, 1.0]  episode_count: 969 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 441 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 432.0, 1.0]  episode_count: 973 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 442 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 433.0, 1.0]  episode_count: 976 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 443 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 434.0, 1.0]  episode_count: 978 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 980, "number_of_timesteps": 20177, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999787},
Step 444 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 435.0, 1.0]  episode_count: 980 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 445 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 436.0, 1.0]  episode_count: 982 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 446 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 437.0, 1.0]  episode_count: 986 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 447 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 438.0, 1.0]  episode_count: 988 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 990, "number_of_timesteps": 20401, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999787},
Step 448 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 439.0, 1.0]  episode_count: 990 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 449 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 440.0, 1.0]  episode_count: 992 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 450 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 441.0, 1.0]  episode_count: 992 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 451 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 442.0, 1.0]  episode_count: 994 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 452 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 443.0, 1.0]  episode_count: 997 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1000, "number_of_timesteps": 20623, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999787},
Step 453 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 444.0, 1.0]  episode_count: 1000 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 454 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 445.0, 1.0]  episode_count: 1001 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 455 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 446.0, 1.0]  episode_count: 1005 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 456 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 447.0, 1.0]  episode_count: 1007 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 457 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 448.0, 1.0]  episode_count: 1008 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1011, "number_of_timesteps": 20836, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.09999999999999787},
Step 458 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 449.0, 1.0]  episode_count: 1011 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 459 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 450.0, 1.0]  episode_count: 1014 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 460 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 451.0, 1.0]  episode_count: 1014 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 461 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 452.0, 1.0]  episode_count: 1015 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1021, "number_of_timesteps": 21033, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.09999999999999787},
Step 462 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 453.0, 1.0]  episode_count: 1021 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 463 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 454.0, 1.0]  episode_count: 1024 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 464 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 455.0, 1.0]  episode_count: 1024 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 465 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 456.0, 1.0]  episode_count: 1028 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1031, "number_of_timesteps": 21219, "per_episode_reward": 17.65, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
Step 466 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 457.0, 1.0]  episode_count: 1031 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 467 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 458.0, 1.0]  episode_count: 1032 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 468 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 459.0, 1.0]  episode_count: 1034 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 469 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 460.0, 1.0]  episode_count: 1036 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 470 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 461.0, 1.0]  episode_count: 1037 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 471 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 462.0, 1.0]  episode_count: 1040 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1043, "number_of_timesteps": 21479, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999787},
Step 472 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 463.0, 1.0]  episode_count: 1043 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 473 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 464.0, 1.0]  episode_count: 1046 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 474 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 465.0, 1.0]  episode_count: 1048 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 475 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 466.0, 1.0]  episode_count: 1049 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 476 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 467.0, 1.0]  episode_count: 1049 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 477 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 468.0, 1.0]  episode_count: 1052 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1053, "number_of_timesteps": 21651, "per_episode_reward": 17.6, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.09999999999999787},
Step 478 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 469.0, 1.0]  episode_count: 1053 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 479 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 470.0, 1.0]  episode_count: 1056 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 480 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 471.0, 1.0]  episode_count: 1059 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 481 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 472.0, 1.0]  episode_count: 1060 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 482 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 473.0, 1.0]  episode_count: 1062 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1064, "number_of_timesteps": 21964, "per_episode_reward": 17.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
Step 483 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 474.0, 1.0]  episode_count: 1064 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 484 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 475.0, 1.0]  episode_count: 1066 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 485 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 476.0, 1.0]  episode_count: 1069 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 486 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 477.0, 1.0]  episode_count: 1070 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 487 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 478.0, 1.0]  episode_count: 1070 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1074, "number_of_timesteps": 22185, "per_episode_reward": 17.55, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 488 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 479.0, 1.0]  episode_count: 1074 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 489 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 480.0, 1.0]  episode_count: 1079 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 490 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 481.0, 1.0]  episode_count: 1080 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 491 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 482.0, 1.0]  episode_count: 1081 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 492 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 483.0, 1.0]  episode_count: 1082 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1084, "number_of_timesteps": 22380, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 493 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 484.0, 1.0]  episode_count: 1084 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 494 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 485.0, 1.0]  episode_count: 1086 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 495 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 486.0, 1.0]  episode_count: 1090 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 496 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 487.0, 1.0]  episode_count: 1090 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 497 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 488.0, 1.0]  episode_count: 1091 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1094, "number_of_timesteps": 22625, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 498 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 489.0, 1.0]  episode_count: 1094 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 499 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 490.0, 1.0]  episode_count: 1097 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 500 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 491.0, 1.0]  episode_count: 1098 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 501 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 492.0, 1.0]  episode_count: 1100 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 502 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 493.0, 1.0]  episode_count: 1102 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1106, "number_of_timesteps": 22882, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 503 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 494.0, 1.0]  episode_count: 1106 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 504 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 495.0, 1.0]  episode_count: 1108 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 505 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 496.0, 1.0]  episode_count: 1113 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 506 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 497.0, 1.0]  episode_count: 1114 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 507 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 498.0, 1.0]  episode_count: 1115 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
{"total_number_of_episodes": 1116, "number_of_timesteps": 23057, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 508 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 499.0, 1.0]  episode_count: 1116 q_vals: [-3.24, -3.009, -2.908, -4.546, -4.647, -3.044, -3.36, -2.869, 0.0, -4.17]
Step 509 8 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 1119 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 510 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 1119 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 511 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 1121 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 512 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 1122 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1126, "number_of_timesteps": 23311, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.019444444444444424, "biggest_recent_change": 1.700000000000001},
Step 513 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 1126 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 514 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 1128 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 515 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 1130 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 516 6 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 500.0, 0.0]  episode_count: 1133 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 517 7 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0, 0.0]  episode_count: 1134 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1138, "number_of_timesteps": 23599, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0188888888888889, "biggest_recent_change": 1.700000000000001},
Step 518 9 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 1138 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 519 0 visits [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 1142 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 520 1 visits [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 1143 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 521 2 visits [2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 1145 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 522 3 visits [2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 1146 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1148, "number_of_timesteps": 23774, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.018333333333333358, "biggest_recent_change": 1.700000000000001},
Step 523 4 visits [2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 1148 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 524 5 visits [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 1152 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 525 6 visits [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 500.0, 1.0]  episode_count: 1153 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 526 7 visits [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 500.0, 1.0]  episode_count: 1153 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 527 9 visits [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 1155 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1159, "number_of_timesteps": 24043, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.01722222222222223, "biggest_recent_change": 1.700000000000001},
Step 528 0 visits [3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 1159 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 529 1 visits [3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 1160 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 530 2 visits [3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 1163 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 531 3 visits [3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 1165 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 532 4 visits [3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 1167 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1170, "number_of_timesteps": 24259, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.01777777777777779, "biggest_recent_change": 1.700000000000001},
Step 533 5 visits [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 1170 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 534 6 visits [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 500.0, 2.0]  episode_count: 1171 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 535 7 visits [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 500.0, 2.0]  episode_count: 1173 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 536 9 visits [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 1174 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 537 0 visits [4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 1174 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 538 1 visits [4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 1178 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1180, "number_of_timesteps": 24525, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.01777777777777779, "biggest_recent_change": 1.700000000000001},
Step 539 2 visits [4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 1180 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 540 3 visits [4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 1182 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 541 4 visits [4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 1185 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 542 5 visits [4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 1187 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1191, "number_of_timesteps": 24778, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0188888888888889, "biggest_recent_change": 1.700000000000001},
Step 543 6 visits [4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 500.0, 3.0]  episode_count: 1191 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 544 7 visits [4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 500.0, 3.0]  episode_count: 1193 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 545 9 visits [4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 1193 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 546 0 visits [5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 1197 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 547 1 visits [5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 1197 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 548 2 visits [5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 1199 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1202, "number_of_timesteps": 25023, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.01777777777777779, "biggest_recent_change": 1.700000000000001},
Step 549 3 visits [5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 1202 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 550 4 visits [5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 1203 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 551 5 visits [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 1205 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 552 6 visits [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 500.0, 4.0]  episode_count: 1207 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 553 7 visits [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 500.0, 4.0]  episode_count: 1210 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 554 9 visits [5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 1211 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1214, "number_of_timesteps": 25270, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.016111111111111142, "biggest_recent_change": 1.700000000000001},
Step 555 0 visits [6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 1214 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 556 1 visits [6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 1217 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 557 2 visits [6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 1220 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 558 3 visits [6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 1222 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1224, "number_of_timesteps": 25489, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.14999999999999858},
Step 559 4 visits [6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 1224 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 560 5 visits [6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 1225 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 561 6 visits [6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 500.0, 5.0]  episode_count: 1228 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 562 7 visits [6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 500.0, 5.0]  episode_count: 1231 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 563 9 visits [6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 1233 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1235, "number_of_timesteps": 25698, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.14999999999999858},
Step 564 0 visits [7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 1235 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 565 1 visits [7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 1236 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 566 2 visits [7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 1238 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 567 3 visits [7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 1241 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 568 4 visits [7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 1244 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 569 5 visits [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 1244 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1247, "number_of_timesteps": 25974, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.14999999999999858},
Step 570 6 visits [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 500.0, 6.0]  episode_count: 1247 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 571 7 visits [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 500.0, 6.0]  episode_count: 1248 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 572 9 visits [7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 1249 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 573 0 visits [8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 1252 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 574 1 visits [8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 1254 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 575 2 visits [8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 1256 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1257, "number_of_timesteps": 26200, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14999999999999858},
Step 576 3 visits [8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 1257 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 577 4 visits [8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 1259 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 578 5 visits [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 1262 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 579 6 visits [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 500.0, 7.0]  episode_count: 1265 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 580 7 visits [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 500.0, 7.0]  episode_count: 1266 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1267, "number_of_timesteps": 26460, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 581 9 visits [8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 1267 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 582 0 visits [9.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 1270 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 583 1 visits [9.0, 9.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 1271 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 584 2 visits [9.0, 9.0, 9.0, 8.0, 8.0, 8.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 1273 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1278, "number_of_timesteps": 26679, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.14999999999999858},
Step 585 3 visits [9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 1278 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 586 4 visits [9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 1279 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 587 5 visits [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 1280 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 588 6 visits [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 500.0, 8.0]  episode_count: 1284 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 589 7 visits [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 500.0, 8.0]  episode_count: 1284 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 590 9 visits [9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 1285 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1291, "number_of_timesteps": 26964, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0027777777777777584, "biggest_recent_change": 0.14999999999999858},
Step 591 0 visits [10.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 1291 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 592 1 visits [10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 1293 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 593 2 visits [10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 1294 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 594 3 visits [10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 1295 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 595 4 visits [10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 1299 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 596 5 visits [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 1299 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1302, "number_of_timesteps": 27190, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.14999999999999858},
Step 597 6 visits [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 500.0, 9.0]  episode_count: 1302 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 598 7 visits [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 500.0, 9.0]  episode_count: 1305 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 599 9 visits [10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 1307 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 600 0 visits [11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 1308 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 601 1 visits [11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 1311 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 602 2 visits [11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 1311 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1314, "number_of_timesteps": 27465, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.09999999999999787},
Step 603 3 visits [11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 1314 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 604 4 visits [11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 1316 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 605 5 visits [11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 1318 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 606 6 visits [11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 500.0, 10.0]  episode_count: 1321 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 607 7 visits [11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 500.0, 10.0]  episode_count: 1322 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1326, "number_of_timesteps": 27724, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.09999999999999787},
Step 608 9 visits [11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 1326 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 609 0 visits [12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 1329 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 610 1 visits [12.0, 12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 1330 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 611 2 visits [12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 1330 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 612 3 visits [12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 1334 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 613 4 visits [12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 1334 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1337, "number_of_timesteps": 27943, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999787},
Step 614 5 visits [12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 1337 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 615 6 visits [12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 500.0, 11.0]  episode_count: 1339 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 616 7 visits [12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 500.0, 11.0]  episode_count: 1339 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 617 9 visits [12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 1342 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 618 0 visits [13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 1343 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 619 1 visits [13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 1345 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1347, "number_of_timesteps": 28191, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999787},
Step 620 2 visits [13.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 1347 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 621 3 visits [13.0, 13.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 1349 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 622 4 visits [13.0, 13.0, 13.0, 13.0, 13.0, 12.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 1353 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 623 5 visits [13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 1354 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1357, "number_of_timesteps": 28462, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
Step 624 6 visits [13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 12.0, 500.0, 12.0]  episode_count: 1357 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 625 7 visits [13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 500.0, 12.0]  episode_count: 1359 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 626 9 visits [13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 1362 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 627 0 visits [14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 1364 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 628 1 visits [14.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 1366 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1367, "number_of_timesteps": 28620, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.09999999999999787},
Step 629 2 visits [14.0, 14.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 1367 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 630 3 visits [14.0, 14.0, 14.0, 14.0, 13.0, 13.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 1369 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 631 4 visits [14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 1373 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1377, "number_of_timesteps": 28848, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
Step 632 5 visits [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 1377 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 633 6 visits [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 500.0, 13.0]  episode_count: 1378 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 634 7 visits [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 500.0, 13.0]  episode_count: 1379 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 635 9 visits [14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 1380 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 636 0 visits [15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 1384 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 637 1 visits [15.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 1386 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1388, "number_of_timesteps": 29086, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.15000000000000213},
Step 638 2 visits [15.0, 15.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 1388 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 639 3 visits [15.0, 15.0, 15.0, 15.0, 14.0, 14.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 1390 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 640 4 visits [15.0, 15.0, 15.0, 15.0, 15.0, 14.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 1392 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 641 5 visits [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 1394 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 642 6 visits [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 14.0, 500.0, 14.0]  episode_count: 1396 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1398, "number_of_timesteps": 29299, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.15000000000000213},
Step 643 7 visits [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 500.0, 14.0]  episode_count: 1398 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 644 9 visits [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 1401 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 645 0 visits [16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 1402 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 646 1 visits [16.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 1404 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1408, "number_of_timesteps": 29511, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000213},
Step 647 2 visits [16.0, 16.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 1408 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 648 3 visits [16.0, 16.0, 16.0, 16.0, 15.0, 15.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 1410 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 649 4 visits [16.0, 16.0, 16.0, 16.0, 16.0, 15.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 1413 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 650 5 visits [16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 1415 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1419, "number_of_timesteps": 29711, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.15000000000000213},
Step 651 6 visits [16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 15.0, 500.0, 15.0]  episode_count: 1419 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 652 7 visits [16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 500.0, 15.0]  episode_count: 1422 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 653 9 visits [16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 1424 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 654 0 visits [17.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 1426 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 655 1 visits [17.0, 17.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 1427 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 656 2 visits [17.0, 17.0, 17.0, 16.0, 16.0, 16.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 1428 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1431, "number_of_timesteps": 29908, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000213},
Step 657 3 visits [17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 1431 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 658 4 visits [17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 1432 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 659 5 visits [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 1434 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 660 6 visits [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 500.0, 16.0]  episode_count: 1436 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 661 7 visits [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 500.0, 16.0]  episode_count: 1437 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 662 9 visits [17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 1439 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1441, "number_of_timesteps": 30154, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.15000000000000213},
Step 663 0 visits [18.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 1441 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 664 1 visits [18.0, 18.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 1442 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 665 2 visits [18.0, 18.0, 18.0, 17.0, 17.0, 17.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 1445 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 666 3 visits [18.0, 18.0, 18.0, 18.0, 17.0, 17.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 1447 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 667 4 visits [18.0, 18.0, 18.0, 18.0, 18.0, 17.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 1448 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 668 5 visits [18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 1448 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1453, "number_of_timesteps": 30427, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000213},
Step 669 6 visits [18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 17.0, 500.0, 17.0]  episode_count: 1453 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 670 7 visits [18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 500.0, 17.0]  episode_count: 1456 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 671 9 visits [18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 1458 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 672 0 visits [19.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 1459 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 673 1 visits [19.0, 19.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 1461 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 674 2 visits [19.0, 19.0, 19.0, 18.0, 18.0, 18.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 1462 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1465, "number_of_timesteps": 30743, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.15000000000000213},
Step 675 3 visits [19.0, 19.0, 19.0, 19.0, 18.0, 18.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 1465 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 676 4 visits [19.0, 19.0, 19.0, 19.0, 19.0, 18.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 1469 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 677 5 visits [19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 1470 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 678 6 visits [19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 18.0, 500.0, 18.0]  episode_count: 1472 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 679 7 visits [19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 500.0, 18.0]  episode_count: 1473 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 680 9 visits [19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 1473 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1476, "number_of_timesteps": 30941, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.15000000000000213},
Step 681 0 visits [20.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 1476 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 682 1 visits [20.0, 20.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 1480 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 683 2 visits [20.0, 20.0, 20.0, 19.0, 19.0, 19.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 1480 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 684 3 visits [20.0, 20.0, 20.0, 20.0, 19.0, 19.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 1483 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1487, "number_of_timesteps": 31254, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
Step 685 4 visits [20.0, 20.0, 20.0, 20.0, 20.0, 19.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 1487 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 686 5 visits [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 1488 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 687 6 visits [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 19.0, 500.0, 19.0]  episode_count: 1491 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 688 7 visits [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 500.0, 19.0]  episode_count: 1491 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 689 9 visits [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 1493 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1498, "number_of_timesteps": 31476, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.003333333333333302, "biggest_recent_change": 0.10000000000000142},
Step 690 0 visits [21.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 1498 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 691 1 visits [21.0, 21.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 1500 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 692 2 visits [21.0, 21.0, 21.0, 20.0, 20.0, 20.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 1502 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 693 3 visits [21.0, 21.0, 21.0, 21.0, 20.0, 20.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 1505 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1509, "number_of_timesteps": 31666, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
Step 694 4 visits [21.0, 21.0, 21.0, 21.0, 21.0, 20.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 1509 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 695 5 visits [21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 1511 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 696 6 visits [21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 20.0, 500.0, 20.0]  episode_count: 1513 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 697 7 visits [21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 500.0, 20.0]  episode_count: 1515 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 698 9 visits [21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 1518 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1519, "number_of_timesteps": 31823, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
Step 699 0 visits [22.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 1519 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 700 1 visits [22.0, 22.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 1522 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 701 2 visits [22.0, 22.0, 22.0, 21.0, 21.0, 21.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 1526 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 702 3 visits [22.0, 22.0, 22.0, 22.0, 21.0, 21.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 1527 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1531, "number_of_timesteps": 32053, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
Step 703 4 visits [22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 1531 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 704 5 visits [22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 1533 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 705 6 visits [22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 500.0, 21.0]  episode_count: 1537 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 706 7 visits [22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 500.0, 21.0]  episode_count: 1538 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 707 9 visits [22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 1539 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1541, "number_of_timesteps": 32199, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
Step 708 0 visits [23.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 1541 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 709 1 visits [23.0, 23.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 1543 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 710 2 visits [23.0, 23.0, 23.0, 22.0, 22.0, 22.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 1543 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 711 3 visits [23.0, 23.0, 23.0, 23.0, 22.0, 22.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 1545 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 712 4 visits [23.0, 23.0, 23.0, 23.0, 23.0, 22.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 1549 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 713 5 visits [23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 1550 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1553, "number_of_timesteps": 32517, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
Step 714 6 visits [23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 22.0, 500.0, 22.0]  episode_count: 1553 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 715 7 visits [23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 500.0, 22.0]  episode_count: 1557 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 716 9 visits [23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 1557 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 717 0 visits [24.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 1557 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 718 1 visits [24.0, 24.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 1562 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1564, "number_of_timesteps": 32730, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999787},
Step 719 2 visits [24.0, 24.0, 24.0, 23.0, 23.0, 23.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 1564 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 720 3 visits [24.0, 24.0, 24.0, 24.0, 23.0, 23.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 1566 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 721 4 visits [24.0, 24.0, 24.0, 24.0, 24.0, 23.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 1568 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 722 5 visits [24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 1569 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 723 6 visits [24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 23.0, 500.0, 23.0]  episode_count: 1570 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 724 7 visits [24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 500.0, 23.0]  episode_count: 1572 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1575, "number_of_timesteps": 32975, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 725 9 visits [24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 1575 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 726 0 visits [25.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 1579 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 727 1 visits [25.0, 25.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 1581 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 728 2 visits [25.0, 25.0, 25.0, 24.0, 24.0, 24.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 1583 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 729 3 visits [25.0, 25.0, 25.0, 25.0, 24.0, 24.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 1583 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1586, "number_of_timesteps": 33201, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 730 4 visits [25.0, 25.0, 25.0, 25.0, 25.0, 24.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 1586 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 731 5 visits [25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 1587 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 732 6 visits [25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 24.0, 500.0, 24.0]  episode_count: 1590 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 733 7 visits [25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 500.0, 24.0]  episode_count: 1593 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 734 9 visits [25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 1593 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1596, "number_of_timesteps": 33469, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 735 0 visits [26.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 1596 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 736 1 visits [26.0, 26.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 1598 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 737 2 visits [26.0, 26.0, 26.0, 25.0, 25.0, 25.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 1599 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 738 3 visits [26.0, 26.0, 26.0, 26.0, 25.0, 25.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 1603 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 739 4 visits [26.0, 26.0, 26.0, 26.0, 26.0, 25.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 1604 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1607, "number_of_timesteps": 33714, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 740 5 visits [26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 1607 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 741 6 visits [26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 25.0, 500.0, 25.0]  episode_count: 1610 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 742 7 visits [26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 500.0, 25.0]  episode_count: 1611 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 743 9 visits [26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 1615 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1619, "number_of_timesteps": 33935, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 744 0 visits [27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 1619 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 745 1 visits [27.0, 27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 1619 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 746 2 visits [27.0, 27.0, 27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 1623 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 747 3 visits [27.0, 27.0, 27.0, 27.0, 26.0, 26.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 1624 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 748 4 visits [27.0, 27.0, 27.0, 27.0, 27.0, 26.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 1626 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1630, "number_of_timesteps": 34147, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 749 5 visits [27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 1630 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 750 6 visits [27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 26.0, 500.0, 26.0]  episode_count: 1632 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 751 7 visits [27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 500.0, 26.0]  episode_count: 1635 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 752 9 visits [27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 1636 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 753 0 visits [28.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 1636 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 754 1 visits [28.0, 28.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 1639 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1643, "number_of_timesteps": 34401, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 755 2 visits [28.0, 28.0, 28.0, 27.0, 27.0, 27.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 1643 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 756 3 visits [28.0, 28.0, 28.0, 28.0, 27.0, 27.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 1645 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 757 4 visits [28.0, 28.0, 28.0, 28.0, 28.0, 27.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 1646 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 758 5 visits [28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 1647 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 759 6 visits [28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 27.0, 500.0, 27.0]  episode_count: 1650 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 760 7 visits [28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 500.0, 27.0]  episode_count: 1651 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1653, "number_of_timesteps": 34655, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
Step 761 9 visits [28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 1653 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 762 0 visits [29.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 1654 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 763 1 visits [29.0, 29.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 1656 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 764 2 visits [29.0, 29.0, 29.0, 28.0, 28.0, 28.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 1657 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 765 3 visits [29.0, 29.0, 29.0, 29.0, 28.0, 28.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 1657 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 766 4 visits [29.0, 29.0, 29.0, 29.0, 29.0, 28.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 1660 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1663, "number_of_timesteps": 34891, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 767 5 visits [29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 1663 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 768 6 visits [29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 28.0, 500.0, 28.0]  episode_count: 1665 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 769 7 visits [29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 500.0, 28.0]  episode_count: 1667 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 770 9 visits [29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 1670 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 771 0 visits [30.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 1671 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 772 1 visits [30.0, 30.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 1672 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1675, "number_of_timesteps": 35163, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 773 2 visits [30.0, 30.0, 30.0, 29.0, 29.0, 29.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 1675 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 774 3 visits [30.0, 30.0, 30.0, 30.0, 29.0, 29.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 1678 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 775 4 visits [30.0, 30.0, 30.0, 30.0, 30.0, 29.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 1682 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 776 5 visits [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 1683 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1686, "number_of_timesteps": 35401, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
Step 777 6 visits [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 29.0, 500.0, 29.0]  episode_count: 1686 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 778 7 visits [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 500.0, 29.0]  episode_count: 1689 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 779 9 visits [30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 1689 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 780 0 visits [31.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 1691 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 781 1 visits [31.0, 31.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 1694 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 782 2 visits [31.0, 31.0, 31.0, 30.0, 30.0, 30.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 1694 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1696, "number_of_timesteps": 35630, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
Step 783 3 visits [31.0, 31.0, 31.0, 31.0, 30.0, 30.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 1696 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 784 4 visits [31.0, 31.0, 31.0, 31.0, 31.0, 30.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 1697 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 785 5 visits [31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 1701 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 786 6 visits [31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 30.0, 500.0, 30.0]  episode_count: 1702 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 787 7 visits [31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 500.0, 30.0]  episode_count: 1705 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1706, "number_of_timesteps": 35899, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
Step 788 9 visits [31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 1706 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 789 0 visits [32.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 1710 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 790 1 visits [32.0, 32.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 1711 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 791 2 visits [32.0, 32.0, 32.0, 31.0, 31.0, 31.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 1711 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 792 3 visits [32.0, 32.0, 32.0, 32.0, 31.0, 31.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 1715 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1717, "number_of_timesteps": 36123, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.15000000000000036},
Step 793 4 visits [32.0, 32.0, 32.0, 32.0, 32.0, 31.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 1717 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 794 5 visits [32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 1720 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 795 6 visits [32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 31.0, 500.0, 31.0]  episode_count: 1722 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 796 7 visits [32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 500.0, 31.0]  episode_count: 1723 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1728, "number_of_timesteps": 36326, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
Step 797 9 visits [32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 1728 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 798 0 visits [33.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 1728 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 799 1 visits [33.0, 33.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 1730 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 800 2 visits [33.0, 33.0, 33.0, 32.0, 32.0, 32.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 1734 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 801 3 visits [33.0, 33.0, 33.0, 33.0, 32.0, 32.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 1735 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 802 4 visits [33.0, 33.0, 33.0, 33.0, 33.0, 32.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 1737 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1741, "number_of_timesteps": 36594, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
Step 803 5 visits [33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 1741 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 804 6 visits [33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 32.0, 500.0, 32.0]  episode_count: 1744 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 805 7 visits [33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 500.0, 32.0]  episode_count: 1745 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 806 9 visits [33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 1748 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1751, "number_of_timesteps": 36791, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
Step 807 0 visits [34.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 1751 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 808 1 visits [34.0, 34.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 1752 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 809 2 visits [34.0, 34.0, 34.0, 33.0, 33.0, 33.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 1754 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 810 3 visits [34.0, 34.0, 34.0, 34.0, 33.0, 33.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 1756 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 811 4 visits [34.0, 34.0, 34.0, 34.0, 34.0, 33.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 1758 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 812 5 visits [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 1760 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1765, "number_of_timesteps": 37100, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
Step 813 6 visits [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 33.0, 500.0, 33.0]  episode_count: 1765 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 814 7 visits [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 500.0, 33.0]  episode_count: 1767 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 815 9 visits [34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 1768 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 816 0 visits [35.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 1769 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 817 1 visits [35.0, 35.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 1770 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 818 2 visits [35.0, 35.0, 35.0, 34.0, 34.0, 34.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 1773 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 819 3 visits [35.0, 35.0, 35.0, 35.0, 34.0, 34.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 1774 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1779, "number_of_timesteps": 37385, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
Step 820 4 visits [35.0, 35.0, 35.0, 35.0, 35.0, 34.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 1779 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 821 5 visits [35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 1780 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 822 6 visits [35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 34.0, 500.0, 34.0]  episode_count: 1782 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 823 7 visits [35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 500.0, 34.0]  episode_count: 1785 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 824 9 visits [35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 1787 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 825 0 visits [36.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 1788 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1791, "number_of_timesteps": 37642, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
Step 826 1 visits [36.0, 36.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 1791 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 827 2 visits [36.0, 36.0, 36.0, 35.0, 35.0, 35.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 1792 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 828 3 visits [36.0, 36.0, 36.0, 36.0, 35.0, 35.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 1793 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 829 4 visits [36.0, 36.0, 36.0, 36.0, 36.0, 35.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 1797 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 830 5 visits [36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 1797 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 831 6 visits [36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 35.0, 500.0, 35.0]  episode_count: 1797 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1801, "number_of_timesteps": 37865, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
Step 832 7 visits [36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 500.0, 35.0]  episode_count: 1801 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 833 9 visits [36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 1802 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 834 0 visits [37.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 1804 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 835 1 visits [37.0, 37.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 1807 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 836 2 visits [37.0, 37.0, 37.0, 36.0, 36.0, 36.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 1808 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1811, "number_of_timesteps": 38129, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
Step 837 3 visits [37.0, 37.0, 37.0, 37.0, 36.0, 36.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 1811 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 838 4 visits [37.0, 37.0, 37.0, 37.0, 37.0, 36.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 1813 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 839 5 visits [37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 1816 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 840 6 visits [37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 36.0, 500.0, 36.0]  episode_count: 1818 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 841 7 visits [37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 500.0, 36.0]  episode_count: 1819 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 842 9 visits [37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 1820 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1824, "number_of_timesteps": 38422, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
Step 843 0 visits [38.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 1824 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 844 1 visits [38.0, 38.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 1826 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 845 2 visits [38.0, 38.0, 38.0, 37.0, 37.0, 37.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 1827 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 846 3 visits [38.0, 38.0, 38.0, 38.0, 37.0, 37.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 1830 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 847 4 visits [38.0, 38.0, 38.0, 38.0, 38.0, 37.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 1830 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 848 5 visits [38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 1832 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 849 6 visits [38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 37.0, 500.0, 37.0]  episode_count: 1832 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1834, "number_of_timesteps": 38666, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
Step 850 7 visits [38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 500.0, 37.0]  episode_count: 1834 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 851 9 visits [38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 1836 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 852 0 visits [39.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 1840 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 853 1 visits [39.0, 39.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 1843 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1847, "number_of_timesteps": 38978, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
Step 854 2 visits [39.0, 39.0, 39.0, 38.0, 38.0, 38.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 1847 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 855 3 visits [39.0, 39.0, 39.0, 39.0, 38.0, 38.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 1848 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 856 4 visits [39.0, 39.0, 39.0, 39.0, 39.0, 38.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 1849 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 857 5 visits [39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 1850 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 858 6 visits [39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 38.0, 500.0, 38.0]  episode_count: 1852 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 859 7 visits [39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 500.0, 38.0]  episode_count: 1855 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 860 9 visits [39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 1855 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1857, "number_of_timesteps": 39215, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 861 0 visits [40.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 1857 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 862 1 visits [40.0, 40.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 1860 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 863 2 visits [40.0, 40.0, 40.0, 39.0, 39.0, 39.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 1862 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 864 3 visits [40.0, 40.0, 40.0, 40.0, 39.0, 39.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 1863 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 865 4 visits [40.0, 40.0, 40.0, 40.0, 40.0, 39.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 1864 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1867, "number_of_timesteps": 39418, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 866 5 visits [40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 1867 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 867 6 visits [40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 39.0, 500.0, 39.0]  episode_count: 1870 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 868 7 visits [40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 500.0, 39.0]  episode_count: 1872 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 869 9 visits [40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 1875 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1878, "number_of_timesteps": 39685, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 870 0 visits [41.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 1878 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 871 1 visits [41.0, 41.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 1879 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 872 2 visits [41.0, 41.0, 41.0, 40.0, 40.0, 40.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 1883 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 873 3 visits [41.0, 41.0, 41.0, 41.0, 40.0, 40.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 1884 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 874 4 visits [41.0, 41.0, 41.0, 41.0, 41.0, 40.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 1886 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 875 5 visits [41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 1886 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1891, "number_of_timesteps": 39925, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 876 6 visits [41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 40.0, 500.0, 40.0]  episode_count: 1891 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 877 7 visits [41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 500.0, 40.0]  episode_count: 1893 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 878 9 visits [41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 1894 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 879 0 visits [42.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 1895 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 880 1 visits [42.0, 42.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 1899 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 881 2 visits [42.0, 42.0, 42.0, 41.0, 41.0, 41.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 1899 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1904, "number_of_timesteps": 40248, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 882 3 visits [42.0, 42.0, 42.0, 42.0, 41.0, 41.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 1904 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 883 4 visits [42.0, 42.0, 42.0, 42.0, 42.0, 41.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 1905 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 884 5 visits [42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 1906 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 885 6 visits [42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 41.0, 500.0, 41.0]  episode_count: 1908 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 886 7 visits [42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 500.0, 41.0]  episode_count: 1911 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 887 9 visits [42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 1913 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1917, "number_of_timesteps": 40494, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 888 0 visits [43.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 1917 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 889 1 visits [43.0, 43.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 1917 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 890 2 visits [43.0, 43.0, 43.0, 42.0, 42.0, 42.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 1919 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 891 3 visits [43.0, 43.0, 43.0, 43.0, 42.0, 42.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 1922 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 892 4 visits [43.0, 43.0, 43.0, 43.0, 43.0, 42.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 1923 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 893 5 visits [43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 1924 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1927, "number_of_timesteps": 40724, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 894 6 visits [43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 42.0, 500.0, 42.0]  episode_count: 1927 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 895 7 visits [43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 500.0, 42.0]  episode_count: 1929 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 896 9 visits [43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 1930 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 897 0 visits [44.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 1931 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 898 1 visits [44.0, 44.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 1934 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 899 2 visits [44.0, 44.0, 44.0, 43.0, 43.0, 43.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 1935 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 900 3 visits [44.0, 44.0, 44.0, 44.0, 43.0, 43.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 1935 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1941, "number_of_timesteps": 41100, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 901 4 visits [44.0, 44.0, 44.0, 44.0, 44.0, 43.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 1941 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 902 5 visits [44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 1941 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 903 6 visits [44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 43.0, 500.0, 43.0]  episode_count: 1945 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 904 7 visits [44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 500.0, 43.0]  episode_count: 1947 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 905 9 visits [44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 1949 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 906 0 visits [45.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 1949 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1952, "number_of_timesteps": 41320, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 907 1 visits [45.0, 45.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 1952 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 908 2 visits [45.0, 45.0, 45.0, 44.0, 44.0, 44.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 1955 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 909 3 visits [45.0, 45.0, 45.0, 45.0, 44.0, 44.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 1958 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 910 4 visits [45.0, 45.0, 45.0, 45.0, 45.0, 44.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 1959 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 911 5 visits [45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 1961 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1965, "number_of_timesteps": 41578, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 912 6 visits [45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 44.0, 500.0, 44.0]  episode_count: 1965 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 913 7 visits [45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 500.0, 44.0]  episode_count: 1968 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 914 9 visits [45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 1969 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 915 0 visits [46.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 1970 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1975, "number_of_timesteps": 41775, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 916 1 visits [46.0, 46.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 1975 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 917 2 visits [46.0, 46.0, 46.0, 45.0, 45.0, 45.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 1976 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 918 3 visits [46.0, 46.0, 46.0, 46.0, 45.0, 45.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 1979 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 919 4 visits [46.0, 46.0, 46.0, 46.0, 46.0, 45.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 1979 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 920 5 visits [46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 1984 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1985, "number_of_timesteps": 41971, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 921 6 visits [46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 45.0, 500.0, 45.0]  episode_count: 1985 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 922 7 visits [46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 500.0, 45.0]  episode_count: 1986 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 923 9 visits [46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 1989 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 924 0 visits [47.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 1994 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 925 1 visits [47.0, 47.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 1994 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 926 2 visits [47.0, 47.0, 47.0, 46.0, 46.0, 46.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 1994 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 1998, "number_of_timesteps": 42219, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
Step 927 3 visits [47.0, 47.0, 47.0, 47.0, 46.0, 46.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 1998 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 928 4 visits [47.0, 47.0, 47.0, 47.0, 47.0, 46.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 2000 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 929 5 visits [47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 2001 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 930 6 visits [47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 46.0, 500.0, 46.0]  episode_count: 2004 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2008, "number_of_timesteps": 42416, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.09999999999999787},
Step 931 7 visits [47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 500.0, 46.0]  episode_count: 2008 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 932 9 visits [47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 2009 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 933 0 visits [48.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 2012 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 934 1 visits [48.0, 48.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 2013 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 935 2 visits [48.0, 48.0, 48.0, 47.0, 47.0, 47.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 2015 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2019, "number_of_timesteps": 42677, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999787},
Step 936 3 visits [48.0, 48.0, 48.0, 48.0, 47.0, 47.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 2019 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 937 4 visits [48.0, 48.0, 48.0, 48.0, 48.0, 47.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 2021 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 938 5 visits [48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 2023 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 939 6 visits [48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 47.0, 500.0, 47.0]  episode_count: 2023 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 940 7 visits [48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 500.0, 47.0]  episode_count: 2026 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2029, "number_of_timesteps": 42881, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999787},
Step 941 9 visits [48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 2029 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 942 0 visits [49.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 2031 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 943 1 visits [49.0, 49.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 2033 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 944 2 visits [49.0, 49.0, 49.0, 48.0, 48.0, 48.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 2034 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 945 3 visits [49.0, 49.0, 49.0, 49.0, 48.0, 48.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 2036 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2040, "number_of_timesteps": 43139, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999787},
Step 946 4 visits [49.0, 49.0, 49.0, 49.0, 49.0, 48.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 2040 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 947 5 visits [49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 2040 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 948 6 visits [49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 48.0, 500.0, 48.0]  episode_count: 2045 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 949 7 visits [49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 500.0, 48.0]  episode_count: 2047 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2050, "number_of_timesteps": 43332, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999787},
Step 950 9 visits [49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 2050 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 951 0 visits [50.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 2051 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 952 1 visits [50.0, 50.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 2056 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 953 2 visits [50.0, 50.0, 50.0, 49.0, 49.0, 49.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 2058 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2061, "number_of_timesteps": 43482, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999787},
Step 954 3 visits [50.0, 50.0, 50.0, 50.0, 49.0, 49.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 2061 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 955 4 visits [50.0, 50.0, 50.0, 50.0, 50.0, 49.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 2062 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 956 5 visits [50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 2064 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 957 6 visits [50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 49.0, 500.0, 49.0]  episode_count: 2067 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 958 7 visits [50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 500.0, 49.0]  episode_count: 2067 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 959 9 visits [50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 2069 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2071, "number_of_timesteps": 43679, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999787},
Step 960 0 visits [51.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 2071 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 961 1 visits [51.0, 51.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 2072 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 962 2 visits [51.0, 51.0, 51.0, 50.0, 50.0, 50.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 2076 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 963 3 visits [51.0, 51.0, 51.0, 51.0, 50.0, 50.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 2077 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 964 4 visits [51.0, 51.0, 51.0, 51.0, 51.0, 50.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 2077 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 965 5 visits [51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 2079 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2081, "number_of_timesteps": 43960, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.09999999999999787},
Step 966 6 visits [51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 50.0, 500.0, 50.0]  episode_count: 2081 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 967 7 visits [51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 500.0, 50.0]  episode_count: 2082 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 968 9 visits [51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 2084 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 969 0 visits [52.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 2087 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 970 1 visits [52.0, 52.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 2090 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2091, "number_of_timesteps": 44265, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
Step 971 2 visits [52.0, 52.0, 52.0, 51.0, 51.0, 51.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 2091 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 972 3 visits [52.0, 52.0, 52.0, 52.0, 51.0, 51.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 2092 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 973 4 visits [52.0, 52.0, 52.0, 52.0, 52.0, 51.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 2095 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 974 5 visits [52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 2097 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 975 6 visits [52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 51.0, 500.0, 51.0]  episode_count: 2099 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2102, "number_of_timesteps": 44491, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 976 7 visits [52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 500.0, 51.0]  episode_count: 2102 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 977 9 visits [52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 2108 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 978 0 visits [53.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 2109 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 979 1 visits [53.0, 53.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 2110 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2115, "number_of_timesteps": 44709, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.15000000000000213},
Step 980 2 visits [53.0, 53.0, 53.0, 52.0, 52.0, 52.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 2115 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 981 3 visits [53.0, 53.0, 53.0, 53.0, 52.0, 52.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 2115 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 982 4 visits [53.0, 53.0, 53.0, 53.0, 53.0, 52.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 2119 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 983 5 visits [53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 2119 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 984 6 visits [53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 52.0, 500.0, 52.0]  episode_count: 2123 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2126, "number_of_timesteps": 44913, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000213},
Step 985 7 visits [53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 500.0, 52.0]  episode_count: 2126 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 986 9 visits [53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 2128 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 987 0 visits [54.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 2131 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 988 1 visits [54.0, 54.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 2134 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2136, "number_of_timesteps": 45090, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.15000000000000213},
Step 989 2 visits [54.0, 54.0, 54.0, 53.0, 53.0, 53.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 2136 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 990 3 visits [54.0, 54.0, 54.0, 54.0, 53.0, 53.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 2137 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 991 4 visits [54.0, 54.0, 54.0, 54.0, 54.0, 53.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 2140 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 992 5 visits [54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 2142 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 993 6 visits [54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 53.0, 500.0, 53.0]  episode_count: 2144 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 994 7 visits [54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 500.0, 53.0]  episode_count: 2145 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2147, "number_of_timesteps": 45319, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000213},
Step 995 9 visits [54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 2147 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 996 0 visits [55.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 2152 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 997 1 visits [55.0, 55.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 2153 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 998 2 visits [55.0, 55.0, 55.0, 54.0, 54.0, 54.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 2154 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2160, "number_of_timesteps": 45561, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.15000000000000213},
Step 999 3 visits [55.0, 55.0, 55.0, 55.0, 54.0, 54.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 2160 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1000 4 visits [55.0, 55.0, 55.0, 55.0, 55.0, 54.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 2161 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1001 5 visits [55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 2161 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1002 6 visits [55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 54.0, 500.0, 54.0]  episode_count: 2164 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1003 7 visits [55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 500.0, 54.0]  episode_count: 2166 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1004 9 visits [55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 2168 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2170, "number_of_timesteps": 45752, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000213},
Step 1005 0 visits [56.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 2170 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1006 1 visits [56.0, 56.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 2171 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1007 2 visits [56.0, 56.0, 56.0, 55.0, 55.0, 55.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 2173 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1008 3 visits [56.0, 56.0, 56.0, 56.0, 55.0, 55.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 2174 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1009 4 visits [56.0, 56.0, 56.0, 56.0, 56.0, 55.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 2177 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2180, "number_of_timesteps": 46036, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000213},
Step 1010 5 visits [56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 2180 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1011 6 visits [56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 55.0, 500.0, 55.0]  episode_count: 2181 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1012 7 visits [56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 500.0, 55.0]  episode_count: 2183 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1013 9 visits [56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 2184 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1014 0 visits [57.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 2187 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1015 1 visits [57.0, 57.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 2189 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2192, "number_of_timesteps": 46305, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 1016 2 visits [57.0, 57.0, 57.0, 56.0, 56.0, 56.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 2192 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1017 3 visits [57.0, 57.0, 57.0, 57.0, 56.0, 56.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 2194 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1018 4 visits [57.0, 57.0, 57.0, 57.0, 57.0, 56.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 2196 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1019 5 visits [57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 2198 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1020 6 visits [57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 56.0, 500.0, 56.0]  episode_count: 2201 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2202, "number_of_timesteps": 46504, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000213},
Step 1021 7 visits [57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 500.0, 56.0]  episode_count: 2202 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1022 9 visits [57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 2203 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1023 0 visits [58.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 2207 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1024 1 visits [58.0, 58.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 2211 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1025 2 visits [58.0, 58.0, 58.0, 57.0, 57.0, 57.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 2211 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2213, "number_of_timesteps": 46742, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.14999999999999858},
Step 1026 3 visits [58.0, 58.0, 58.0, 58.0, 57.0, 57.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 2213 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1027 4 visits [58.0, 58.0, 58.0, 58.0, 58.0, 57.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 2217 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1028 5 visits [58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 2219 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1029 6 visits [58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 57.0, 500.0, 57.0]  episode_count: 2221 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2224, "number_of_timesteps": 46942, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14999999999999858},
Step 1030 7 visits [58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 500.0, 57.0]  episode_count: 2224 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1031 9 visits [58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 2224 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1032 0 visits [59.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 2229 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1033 1 visits [59.0, 59.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 2229 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1034 2 visits [59.0, 59.0, 59.0, 58.0, 58.0, 58.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 2230 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1035 3 visits [59.0, 59.0, 59.0, 59.0, 58.0, 58.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 2232 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2235, "number_of_timesteps": 47215, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.14999999999999858},
Step 1036 4 visits [59.0, 59.0, 59.0, 59.0, 59.0, 58.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 2235 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1037 5 visits [59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 2239 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1038 6 visits [59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 58.0, 500.0, 58.0]  episode_count: 2242 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1039 7 visits [59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 500.0, 58.0]  episode_count: 2244 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2245, "number_of_timesteps": 47403, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 1040 9 visits [59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 2245 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1041 0 visits [60.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 2250 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1042 1 visits [60.0, 60.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 2251 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1043 2 visits [60.0, 60.0, 60.0, 59.0, 59.0, 59.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 2252 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2255, "number_of_timesteps": 47574, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14999999999999858},
Step 1044 3 visits [60.0, 60.0, 60.0, 60.0, 59.0, 59.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 2255 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1045 4 visits [60.0, 60.0, 60.0, 60.0, 60.0, 59.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 2257 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1046 5 visits [60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 2261 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1047 6 visits [60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 59.0, 500.0, 59.0]  episode_count: 2264 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1048 7 visits [60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 500.0, 59.0]  episode_count: 2264 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2265, "number_of_timesteps": 47785, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 1049 9 visits [60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 2265 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1050 0 visits [61.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 2269 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1051 1 visits [61.0, 61.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 2271 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1052 2 visits [61.0, 61.0, 61.0, 60.0, 60.0, 60.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 2274 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2276, "number_of_timesteps": 47988, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.14999999999999858},
Step 1053 3 visits [61.0, 61.0, 61.0, 61.0, 60.0, 60.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 2276 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1054 4 visits [61.0, 61.0, 61.0, 61.0, 61.0, 60.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 2280 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1055 5 visits [61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 2282 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1056 6 visits [61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 60.0, 500.0, 60.0]  episode_count: 2284 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1057 7 visits [61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 500.0, 60.0]  episode_count: 2284 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2286, "number_of_timesteps": 48170, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
Step 1058 9 visits [61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 2286 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1059 0 visits [62.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 2289 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1060 1 visits [62.0, 62.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 2290 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1061 2 visits [62.0, 62.0, 62.0, 61.0, 61.0, 61.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 2291 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1062 3 visits [62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 2292 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2297, "number_of_timesteps": 48454, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
Step 1063 4 visits [62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 2297 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1064 5 visits [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 2297 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1065 6 visits [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 500.0, 61.0]  episode_count: 2300 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1066 7 visits [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 500.0, 61.0]  episode_count: 2302 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1067 9 visits [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 2304 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1068 0 visits [63.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 2306 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2307, "number_of_timesteps": 48662, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1069 1 visits [63.0, 63.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 2307 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1070 2 visits [63.0, 63.0, 63.0, 62.0, 62.0, 62.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 2308 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1071 3 visits [63.0, 63.0, 63.0, 63.0, 62.0, 62.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 2311 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1072 4 visits [63.0, 63.0, 63.0, 63.0, 63.0, 62.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 2315 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1073 5 visits [63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 2316 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2320, "number_of_timesteps": 48991, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1074 6 visits [63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 62.0, 500.0, 62.0]  episode_count: 2320 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1075 7 visits [63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 500.0, 62.0]  episode_count: 2321 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1076 9 visits [63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 2323 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1077 0 visits [64.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 2326 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2330, "number_of_timesteps": 49150, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1078 1 visits [64.0, 64.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 2330 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1079 2 visits [64.0, 64.0, 64.0, 63.0, 63.0, 63.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 2331 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1080 3 visits [64.0, 64.0, 64.0, 64.0, 63.0, 63.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 2333 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1081 4 visits [64.0, 64.0, 64.0, 64.0, 64.0, 63.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 2336 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1082 5 visits [64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 2338 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2343, "number_of_timesteps": 49401, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1083 6 visits [64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 63.0, 500.0, 63.0]  episode_count: 2343 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1084 7 visits [64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 500.0, 63.0]  episode_count: 2343 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1085 9 visits [64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 2344 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1086 0 visits [65.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 2348 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1087 1 visits [65.0, 65.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 2351 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1088 2 visits [65.0, 65.0, 65.0, 64.0, 64.0, 64.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 2352 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2354, "number_of_timesteps": 49622, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
Step 1089 3 visits [65.0, 65.0, 65.0, 65.0, 64.0, 64.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 2354 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1090 4 visits [65.0, 65.0, 65.0, 65.0, 65.0, 64.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 2356 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1091 5 visits [65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 2359 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1092 6 visits [65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 64.0, 500.0, 64.0]  episode_count: 2360 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2364, "number_of_timesteps": 49815, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
Step 1093 7 visits [65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 500.0, 64.0]  episode_count: 2364 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1094 9 visits [65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 2366 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1095 0 visits [66.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 2366 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1096 1 visits [66.0, 66.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 2370 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2375, "number_of_timesteps": 50063, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
Step 1097 2 visits [66.0, 66.0, 66.0, 65.0, 65.0, 65.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 2375 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1098 3 visits [66.0, 66.0, 66.0, 66.0, 65.0, 65.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 2375 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1099 4 visits [66.0, 66.0, 66.0, 66.0, 66.0, 65.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 2375 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1100 5 visits [66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 2379 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1101 6 visits [66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 65.0, 500.0, 65.0]  episode_count: 2382 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1102 7 visits [66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 500.0, 65.0]  episode_count: 2383 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2387, "number_of_timesteps": 50277, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
Step 1103 9 visits [66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 2387 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1104 0 visits [67.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 2388 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1105 1 visits [67.0, 67.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 2390 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1106 2 visits [67.0, 67.0, 67.0, 66.0, 66.0, 66.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 2392 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1107 3 visits [67.0, 67.0, 67.0, 67.0, 66.0, 66.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 2395 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2397, "number_of_timesteps": 50497, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
Step 1108 4 visits [67.0, 67.0, 67.0, 67.0, 67.0, 66.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 2397 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1109 5 visits [67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 2399 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1110 6 visits [67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 66.0, 500.0, 66.0]  episode_count: 2400 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1111 7 visits [67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 500.0, 66.0]  episode_count: 2404 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1112 9 visits [67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 2405 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2407, "number_of_timesteps": 50708, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
Step 1113 0 visits [68.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 2407 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1114 1 visits [68.0, 68.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 2411 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1115 2 visits [68.0, 68.0, 68.0, 67.0, 67.0, 67.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 2413 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1116 3 visits [68.0, 68.0, 68.0, 68.0, 67.0, 67.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 2414 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1117 4 visits [68.0, 68.0, 68.0, 68.0, 68.0, 67.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 2415 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2419, "number_of_timesteps": 50898, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
Step 1118 5 visits [68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 2419 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1119 6 visits [68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 67.0, 500.0, 67.0]  episode_count: 2423 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1120 7 visits [68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 500.0, 67.0]  episode_count: 2423 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1121 9 visits [68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 2426 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1122 0 visits [69.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 2426 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1123 1 visits [69.0, 69.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 2428 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2432, "number_of_timesteps": 51225, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
Step 1124 2 visits [69.0, 69.0, 69.0, 68.0, 68.0, 68.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 2432 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1125 3 visits [69.0, 69.0, 69.0, 69.0, 68.0, 68.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 2434 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1126 4 visits [69.0, 69.0, 69.0, 69.0, 69.0, 68.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 2434 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1127 5 visits [69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 2437 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1128 6 visits [69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 68.0, 500.0, 68.0]  episode_count: 2438 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1129 7 visits [69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 500.0, 68.0]  episode_count: 2441 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2445, "number_of_timesteps": 51515, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
Step 1130 9 visits [69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 2445 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1131 0 visits [70.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 2445 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1132 1 visits [70.0, 70.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 2446 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1133 2 visits [70.0, 70.0, 70.0, 69.0, 69.0, 69.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 2447 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1134 3 visits [70.0, 70.0, 70.0, 70.0, 69.0, 69.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 2451 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1135 4 visits [70.0, 70.0, 70.0, 70.0, 70.0, 69.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 2451 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2455, "number_of_timesteps": 51795, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1136 5 visits [70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 2455 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1137 6 visits [70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 69.0, 500.0, 69.0]  episode_count: 2458 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1138 7 visits [70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 500.0, 69.0]  episode_count: 2460 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1139 9 visits [70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 2463 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2466, "number_of_timesteps": 51987, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1140 0 visits [71.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 2466 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1141 1 visits [71.0, 71.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 2466 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1142 2 visits [71.0, 71.0, 71.0, 70.0, 70.0, 70.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 2467 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1143 3 visits [71.0, 71.0, 71.0, 71.0, 70.0, 70.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 2470 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1144 4 visits [71.0, 71.0, 71.0, 71.0, 71.0, 70.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 2472 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1145 5 visits [71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 2473 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2476, "number_of_timesteps": 52201, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1146 6 visits [71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 70.0, 500.0, 70.0]  episode_count: 2476 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1147 7 visits [71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 500.0, 70.0]  episode_count: 2479 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1148 9 visits [71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 2480 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1149 0 visits [72.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 2482 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1150 1 visits [72.0, 72.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 2483 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2487, "number_of_timesteps": 52443, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1151 2 visits [72.0, 72.0, 72.0, 71.0, 71.0, 71.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 2487 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1152 3 visits [72.0, 72.0, 72.0, 72.0, 71.0, 71.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 2489 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1153 4 visits [72.0, 72.0, 72.0, 72.0, 72.0, 71.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 2490 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1154 5 visits [72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 2491 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1155 6 visits [72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 71.0, 500.0, 71.0]  episode_count: 2494 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1156 7 visits [72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 500.0, 71.0]  episode_count: 2496 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2497, "number_of_timesteps": 52689, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1157 9 visits [72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 2497 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1158 0 visits [73.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 2498 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1159 1 visits [73.0, 73.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 2501 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1160 2 visits [73.0, 73.0, 73.0, 72.0, 72.0, 72.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 2503 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1161 3 visits [73.0, 73.0, 73.0, 73.0, 72.0, 72.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 2503 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1162 4 visits [73.0, 73.0, 73.0, 73.0, 73.0, 72.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 2506 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2509, "number_of_timesteps": 53005, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 1163 5 visits [73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 2509 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1164 6 visits [73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 72.0, 500.0, 72.0]  episode_count: 2513 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1165 7 visits [73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 500.0, 72.0]  episode_count: 2515 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2519, "number_of_timesteps": 53193, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 1166 9 visits [73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 2519 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1167 0 visits [74.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 2522 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1168 1 visits [74.0, 74.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 2522 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1169 2 visits [74.0, 74.0, 74.0, 73.0, 73.0, 73.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 2525 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2529, "number_of_timesteps": 53358, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 1170 3 visits [74.0, 74.0, 74.0, 74.0, 73.0, 73.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 2529 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1171 4 visits [74.0, 74.0, 74.0, 74.0, 74.0, 73.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 2530 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1172 5 visits [74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 2532 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1173 6 visits [74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 73.0, 500.0, 73.0]  episode_count: 2533 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1174 7 visits [74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 500.0, 73.0]  episode_count: 2536 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1175 9 visits [74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 2538 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1176 0 visits [75.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 2538 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2542, "number_of_timesteps": 53623, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 1177 1 visits [75.0, 75.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 2542 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1178 2 visits [75.0, 75.0, 75.0, 74.0, 74.0, 74.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 2545 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1179 3 visits [75.0, 75.0, 75.0, 75.0, 74.0, 74.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 2545 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1180 4 visits [75.0, 75.0, 75.0, 75.0, 75.0, 74.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 2545 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1181 5 visits [75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 2549 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1182 6 visits [75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 74.0, 500.0, 74.0]  episode_count: 2550 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2552, "number_of_timesteps": 53890, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 1183 7 visits [75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 500.0, 74.0]  episode_count: 2552 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1184 9 visits [75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 2557 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1185 0 visits [76.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 2559 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1186 1 visits [76.0, 76.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 2560 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1187 2 visits [76.0, 76.0, 76.0, 75.0, 75.0, 75.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 2561 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2566, "number_of_timesteps": 54161, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 1188 3 visits [76.0, 76.0, 76.0, 76.0, 75.0, 75.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 2566 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1189 4 visits [76.0, 76.0, 76.0, 76.0, 76.0, 75.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 2567 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1190 5 visits [76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 2568 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1191 6 visits [76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 75.0, 500.0, 75.0]  episode_count: 2573 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1192 7 visits [76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 500.0, 75.0]  episode_count: 2574 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1193 9 visits [76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 2575 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2580, "number_of_timesteps": 54438, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 1194 0 visits [77.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 2580 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1195 1 visits [77.0, 77.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 2582 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1196 2 visits [77.0, 77.0, 77.0, 76.0, 76.0, 76.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 2585 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1197 3 visits [77.0, 77.0, 77.0, 77.0, 76.0, 76.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 2588 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1198 4 visits [77.0, 77.0, 77.0, 77.0, 77.0, 76.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 2589 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2590, "number_of_timesteps": 54609, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 1199 5 visits [77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 2590 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1200 6 visits [77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 76.0, 500.0, 76.0]  episode_count: 2593 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1201 7 visits [77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 500.0, 76.0]  episode_count: 2597 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1202 9 visits [77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 2599 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2601, "number_of_timesteps": 54835, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 1203 0 visits [78.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 2601 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1204 1 visits [78.0, 78.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 2601 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1205 2 visits [78.0, 78.0, 78.0, 77.0, 77.0, 77.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 2603 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1206 3 visits [78.0, 78.0, 78.0, 78.0, 77.0, 77.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 2609 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2611, "number_of_timesteps": 55065, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1207 4 visits [78.0, 78.0, 78.0, 78.0, 78.0, 77.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 2611 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1208 5 visits [78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 2611 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1209 6 visits [78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 77.0, 500.0, 77.0]  episode_count: 2613 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1210 7 visits [78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 500.0, 77.0]  episode_count: 2620 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1211 9 visits [78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 2620 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2622, "number_of_timesteps": 55246, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1212 0 visits [79.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 2622 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1213 1 visits [79.0, 79.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 2625 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1214 2 visits [79.0, 79.0, 79.0, 78.0, 78.0, 78.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 2625 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1215 3 visits [79.0, 79.0, 79.0, 79.0, 78.0, 78.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 2628 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2633, "number_of_timesteps": 55463, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
Step 1216 4 visits [79.0, 79.0, 79.0, 79.0, 79.0, 78.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 2633 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1217 5 visits [79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 2634 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1218 6 visits [79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 78.0, 500.0, 78.0]  episode_count: 2634 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1219 7 visits [79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 500.0, 78.0]  episode_count: 2639 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1220 9 visits [79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 2642 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2643, "number_of_timesteps": 55663, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1221 0 visits [80.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 2643 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1222 1 visits [80.0, 80.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 2644 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1223 2 visits [80.0, 80.0, 80.0, 79.0, 79.0, 79.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 2646 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1224 3 visits [80.0, 80.0, 80.0, 80.0, 79.0, 79.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 2648 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1225 4 visits [80.0, 80.0, 80.0, 80.0, 80.0, 79.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 2650 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1226 5 visits [80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 2652 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2656, "number_of_timesteps": 55914, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
Step 1227 6 visits [80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 79.0, 500.0, 79.0]  episode_count: 2656 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1228 7 visits [80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 500.0, 79.0]  episode_count: 2657 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1229 9 visits [80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 2659 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1230 0 visits [81.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 2662 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1231 1 visits [81.0, 81.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 2664 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2667, "number_of_timesteps": 56173, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 1232 2 visits [81.0, 81.0, 81.0, 80.0, 80.0, 80.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 2667 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1233 3 visits [81.0, 81.0, 81.0, 81.0, 80.0, 80.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 2669 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1234 4 visits [81.0, 81.0, 81.0, 81.0, 81.0, 80.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 2672 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1235 5 visits [81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 2674 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1236 6 visits [81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 80.0, 500.0, 80.0]  episode_count: 2675 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2677, "number_of_timesteps": 56341, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
Step 1237 7 visits [81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 500.0, 80.0]  episode_count: 2677 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1238 9 visits [81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 2680 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1239 0 visits [82.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 2680 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1240 1 visits [82.0, 82.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 2683 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1241 2 visits [82.0, 82.0, 82.0, 81.0, 81.0, 81.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 2685 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1242 3 visits [82.0, 82.0, 82.0, 82.0, 81.0, 81.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 2686 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2689, "number_of_timesteps": 56643, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
Step 1243 4 visits [82.0, 82.0, 82.0, 82.0, 82.0, 81.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 2689 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1244 5 visits [82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 2691 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1245 6 visits [82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 81.0, 500.0, 81.0]  episode_count: 2694 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1246 7 visits [82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 500.0, 81.0]  episode_count: 2694 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1247 9 visits [82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 2698 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2700, "number_of_timesteps": 56858, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
Step 1248 0 visits [83.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 2700 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1249 1 visits [83.0, 83.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 2700 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1250 2 visits [83.0, 83.0, 83.0, 82.0, 82.0, 82.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 2704 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1251 3 visits [83.0, 83.0, 83.0, 83.0, 82.0, 82.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 2707 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1252 4 visits [83.0, 83.0, 83.0, 83.0, 83.0, 82.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 2708 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2710, "number_of_timesteps": 57086, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 1253 5 visits [83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 2710 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1254 6 visits [83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 82.0, 500.0, 82.0]  episode_count: 2713 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1255 7 visits [83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 500.0, 82.0]  episode_count: 2715 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1256 9 visits [83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 2716 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2720, "number_of_timesteps": 57300, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 1257 0 visits [84.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 2720 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1258 1 visits [84.0, 84.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 2723 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1259 2 visits [84.0, 84.0, 84.0, 83.0, 83.0, 83.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 2724 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1260 3 visits [84.0, 84.0, 84.0, 84.0, 83.0, 83.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 2727 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1261 4 visits [84.0, 84.0, 84.0, 84.0, 84.0, 83.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 2728 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1262 5 visits [84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 2729 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2733, "number_of_timesteps": 57556, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
Step 1263 6 visits [84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 83.0, 500.0, 83.0]  episode_count: 2733 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1264 7 visits [84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 500.0, 83.0]  episode_count: 2735 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1265 9 visits [84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 2736 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1266 0 visits [85.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 2739 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1267 1 visits [85.0, 85.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 2741 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1268 2 visits [85.0, 85.0, 85.0, 84.0, 84.0, 84.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 2742 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2743, "number_of_timesteps": 57746, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
Step 1269 3 visits [85.0, 85.0, 85.0, 85.0, 84.0, 84.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 2743 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1270 4 visits [85.0, 85.0, 85.0, 85.0, 85.0, 84.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 2745 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1271 5 visits [85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 2747 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1272 6 visits [85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 84.0, 500.0, 84.0]  episode_count: 2750 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1273 7 visits [85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 500.0, 84.0]  episode_count: 2752 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2756, "number_of_timesteps": 58100, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1274 9 visits [85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 2756 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1275 0 visits [86.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 2756 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1276 1 visits [86.0, 86.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 2758 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1277 2 visits [86.0, 86.0, 86.0, 85.0, 85.0, 85.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 2760 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1278 3 visits [86.0, 86.0, 86.0, 86.0, 85.0, 85.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 2763 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1279 4 visits [86.0, 86.0, 86.0, 86.0, 86.0, 85.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 2765 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1280 5 visits [86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 2765 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2767, "number_of_timesteps": 58316, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1281 6 visits [86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 85.0, 500.0, 85.0]  episode_count: 2767 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1282 7 visits [86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 500.0, 85.0]  episode_count: 2770 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1283 9 visits [86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 2773 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1284 0 visits [87.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 2773 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1285 1 visits [87.0, 87.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 2776 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2779, "number_of_timesteps": 58610, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1286 2 visits [87.0, 87.0, 87.0, 86.0, 86.0, 86.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 2779 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1287 3 visits [87.0, 87.0, 87.0, 87.0, 86.0, 86.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 2780 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1288 4 visits [87.0, 87.0, 87.0, 87.0, 87.0, 86.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 2782 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1289 5 visits [87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 2783 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1290 6 visits [87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 86.0, 500.0, 86.0]  episode_count: 2784 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1291 7 visits [87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 500.0, 86.0]  episode_count: 2786 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2789, "number_of_timesteps": 58868, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1292 9 visits [87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 2789 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1293 0 visits [88.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 2793 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1294 1 visits [88.0, 88.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 2794 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1295 2 visits [88.0, 88.0, 88.0, 87.0, 87.0, 87.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 2795 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1296 3 visits [88.0, 88.0, 88.0, 88.0, 87.0, 87.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 2797 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2799, "number_of_timesteps": 59075, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1297 4 visits [88.0, 88.0, 88.0, 88.0, 88.0, 87.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 2799 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1298 5 visits [88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 2800 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1299 6 visits [88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 87.0, 500.0, 87.0]  episode_count: 2803 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1300 7 visits [88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 500.0, 87.0]  episode_count: 2808 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2810, "number_of_timesteps": 59315, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1301 9 visits [88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 2810 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1302 0 visits [89.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 2812 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1303 1 visits [89.0, 89.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 2817 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1304 2 visits [89.0, 89.0, 89.0, 88.0, 88.0, 88.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 2817 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1305 3 visits [89.0, 89.0, 89.0, 89.0, 88.0, 88.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 2819 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2821, "number_of_timesteps": 59485, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1306 4 visits [89.0, 89.0, 89.0, 89.0, 89.0, 88.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 2821 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1307 5 visits [89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 2823 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1308 6 visits [89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 88.0, 500.0, 88.0]  episode_count: 2823 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1309 7 visits [89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 500.0, 88.0]  episode_count: 2826 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2831, "number_of_timesteps": 59737, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1310 9 visits [89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 2831 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1311 0 visits [90.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 2831 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1312 1 visits [90.0, 90.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 2833 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1313 2 visits [90.0, 90.0, 90.0, 89.0, 89.0, 89.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 2835 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1314 3 visits [90.0, 90.0, 90.0, 90.0, 89.0, 89.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 2837 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2841, "number_of_timesteps": 59913, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1315 4 visits [90.0, 90.0, 90.0, 90.0, 90.0, 89.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 2841 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1316 5 visits [90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 2841 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1317 6 visits [90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 89.0, 500.0, 89.0]  episode_count: 2843 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1318 7 visits [90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 500.0, 89.0]  episode_count: 2846 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1319 9 visits [90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 2848 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2851, "number_of_timesteps": 60131, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1320 0 visits [91.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 2851 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1321 1 visits [91.0, 91.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 2853 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1322 2 visits [91.0, 91.0, 91.0, 90.0, 90.0, 90.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 2854 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1323 3 visits [91.0, 91.0, 91.0, 91.0, 90.0, 90.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 2858 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1324 4 visits [91.0, 91.0, 91.0, 91.0, 91.0, 90.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 2860 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2861, "number_of_timesteps": 60309, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1325 5 visits [91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 2861 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1326 6 visits [91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 90.0, 500.0, 90.0]  episode_count: 2864 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1327 7 visits [91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 500.0, 90.0]  episode_count: 2865 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1328 9 visits [91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 2866 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1329 0 visits [92.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 2869 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2871, "number_of_timesteps": 60560, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1330 1 visits [92.0, 92.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 2871 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1331 2 visits [92.0, 92.0, 92.0, 91.0, 91.0, 91.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 2873 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1332 3 visits [92.0, 92.0, 92.0, 92.0, 91.0, 91.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 2875 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1333 4 visits [92.0, 92.0, 92.0, 92.0, 92.0, 91.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 2875 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1334 5 visits [92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 2880 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2882, "number_of_timesteps": 60825, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1335 6 visits [92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 91.0, 500.0, 91.0]  episode_count: 2882 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1336 7 visits [92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 500.0, 91.0]  episode_count: 2882 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1337 9 visits [92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 2887 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1338 0 visits [93.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 2890 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2892, "number_of_timesteps": 61019, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1339 1 visits [93.0, 93.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 2892 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1340 2 visits [93.0, 93.0, 93.0, 92.0, 92.0, 92.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 2896 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1341 3 visits [93.0, 93.0, 93.0, 93.0, 92.0, 92.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 2897 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1342 4 visits [93.0, 93.0, 93.0, 93.0, 93.0, 92.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 2900 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2903, "number_of_timesteps": 61199, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1343 5 visits [93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 2903 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1344 6 visits [93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 92.0, 500.0, 92.0]  episode_count: 2903 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1345 7 visits [93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 500.0, 92.0]  episode_count: 2906 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1346 9 visits [93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 2908 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1347 0 visits [94.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 2911 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2915, "number_of_timesteps": 61458, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1348 1 visits [94.0, 94.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 2915 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1349 2 visits [94.0, 94.0, 94.0, 93.0, 93.0, 93.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 2915 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1350 3 visits [94.0, 94.0, 94.0, 94.0, 93.0, 93.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 2915 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1351 4 visits [94.0, 94.0, 94.0, 94.0, 94.0, 93.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 2920 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1352 5 visits [94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 2924 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1353 6 visits [94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 93.0, 500.0, 93.0]  episode_count: 2924 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2925, "number_of_timesteps": 61651, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1354 7 visits [94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 500.0, 93.0]  episode_count: 2925 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1355 9 visits [94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 2929 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1356 0 visits [95.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 2932 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1357 1 visits [95.0, 95.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 2932 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2935, "number_of_timesteps": 61846, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1358 2 visits [95.0, 95.0, 95.0, 94.0, 94.0, 94.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 2935 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1359 3 visits [95.0, 95.0, 95.0, 95.0, 94.0, 94.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 2937 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1360 4 visits [95.0, 95.0, 95.0, 95.0, 95.0, 94.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 2939 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1361 5 visits [95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 2943 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1362 6 visits [95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 94.0, 500.0, 94.0]  episode_count: 2943 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2945, "number_of_timesteps": 62066, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1363 7 visits [95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 500.0, 94.0]  episode_count: 2945 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1364 9 visits [95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 2947 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1365 0 visits [96.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 2949 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1366 1 visits [96.0, 96.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 2950 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2955, "number_of_timesteps": 62285, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1367 2 visits [96.0, 96.0, 96.0, 95.0, 95.0, 95.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 2955 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1368 3 visits [96.0, 96.0, 96.0, 96.0, 95.0, 95.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 2955 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1369 4 visits [96.0, 96.0, 96.0, 96.0, 96.0, 95.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 2959 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1370 5 visits [96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 2961 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1371 6 visits [96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 95.0, 500.0, 95.0]  episode_count: 2962 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2965, "number_of_timesteps": 62507, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1372 7 visits [96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 500.0, 95.0]  episode_count: 2965 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1373 9 visits [96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 2966 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1374 0 visits [97.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 2968 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1375 1 visits [97.0, 97.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 2970 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1376 2 visits [97.0, 97.0, 97.0, 96.0, 96.0, 96.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 2972 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2975, "number_of_timesteps": 62720, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1377 3 visits [97.0, 97.0, 97.0, 97.0, 96.0, 96.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 2975 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1378 4 visits [97.0, 97.0, 97.0, 97.0, 97.0, 96.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 2978 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1379 5 visits [97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 2979 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1380 6 visits [97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 96.0, 500.0, 96.0]  episode_count: 2980 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1381 7 visits [97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 500.0, 96.0]  episode_count: 2981 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1382 9 visits [97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 2982 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2985, "number_of_timesteps": 62925, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1383 0 visits [98.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 2985 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1384 1 visits [98.0, 98.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 2988 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1385 2 visits [98.0, 98.0, 98.0, 97.0, 97.0, 97.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 2990 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1386 3 visits [98.0, 98.0, 98.0, 98.0, 97.0, 97.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 2992 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 2997, "number_of_timesteps": 63239, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1387 4 visits [98.0, 98.0, 98.0, 98.0, 98.0, 97.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 2997 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1388 5 visits [98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 2998 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1389 6 visits [98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 97.0, 500.0, 97.0]  episode_count: 2999 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1390 7 visits [98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 500.0, 97.0]  episode_count: 3001 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1391 9 visits [98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 3006 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1392 0 visits [99.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 3006 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3008, "number_of_timesteps": 63446, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1393 1 visits [99.0, 99.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 3008 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1394 2 visits [99.0, 99.0, 99.0, 98.0, 98.0, 98.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 3012 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1395 3 visits [99.0, 99.0, 99.0, 99.0, 98.0, 98.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 3013 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1396 4 visits [99.0, 99.0, 99.0, 99.0, 99.0, 98.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 3016 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1397 5 visits [99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 3017 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3018, "number_of_timesteps": 63645, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1398 6 visits [99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 98.0, 500.0, 98.0]  episode_count: 3018 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1399 7 visits [99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 500.0, 98.0]  episode_count: 3020 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1400 9 visits [99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 3023 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1401 0 visits [100.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 3026 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1402 1 visits [100.0, 100.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 3026 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3030, "number_of_timesteps": 63913, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1403 2 visits [100.0, 100.0, 100.0, 99.0, 99.0, 99.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 3030 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1404 3 visits [100.0, 100.0, 100.0, 100.0, 99.0, 99.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 3032 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1405 4 visits [100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 3037 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1406 5 visits [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 3038 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3040, "number_of_timesteps": 64104, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1407 6 visits [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 500.0, 99.0]  episode_count: 3040 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1408 7 visits [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 500.0, 99.0]  episode_count: 3043 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1409 9 visits [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 3046 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1410 0 visits [101.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 3048 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1411 1 visits [101.0, 101.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 3048 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3053, "number_of_timesteps": 64324, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 1412 2 visits [101.0, 101.0, 101.0, 100.0, 100.0, 100.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 3053 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1413 3 visits [101.0, 101.0, 101.0, 101.0, 100.0, 100.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 3056 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1414 4 visits [101.0, 101.0, 101.0, 101.0, 101.0, 100.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 3058 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1415 5 visits [101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 3060 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3063, "number_of_timesteps": 64514, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 1416 6 visits [101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 100.0, 500.0, 100.0]  episode_count: 3063 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1417 7 visits [101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 500.0, 100.0]  episode_count: 3065 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1418 9 visits [101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 3066 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1419 0 visits [102.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 3068 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1420 1 visits [102.0, 102.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 3071 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3073, "number_of_timesteps": 64720, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 1421 2 visits [102.0, 102.0, 102.0, 101.0, 101.0, 101.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 3073 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1422 3 visits [102.0, 102.0, 102.0, 102.0, 101.0, 101.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 3073 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1423 4 visits [102.0, 102.0, 102.0, 102.0, 102.0, 101.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 3077 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1424 5 visits [102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 3080 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1425 6 visits [102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 101.0, 500.0, 101.0]  episode_count: 3081 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3083, "number_of_timesteps": 64948, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 1426 7 visits [102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 500.0, 101.0]  episode_count: 3083 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1427 9 visits [102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 3084 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1428 0 visits [103.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 3085 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1429 1 visits [103.0, 103.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 3086 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1430 2 visits [103.0, 103.0, 103.0, 102.0, 102.0, 102.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 3089 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1431 3 visits [103.0, 103.0, 103.0, 103.0, 102.0, 102.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 3092 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3093, "number_of_timesteps": 65221, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 1432 4 visits [103.0, 103.0, 103.0, 103.0, 103.0, 102.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 3093 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1433 5 visits [103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 3097 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1434 6 visits [103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 102.0, 500.0, 102.0]  episode_count: 3099 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1435 7 visits [103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 500.0, 102.0]  episode_count: 3100 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1436 9 visits [103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 3100 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3104, "number_of_timesteps": 65411, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 1437 0 visits [104.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 3104 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1438 1 visits [104.0, 104.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 3107 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1439 2 visits [104.0, 104.0, 104.0, 103.0, 103.0, 103.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 3107 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1440 3 visits [104.0, 104.0, 104.0, 104.0, 103.0, 103.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 3109 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1441 4 visits [104.0, 104.0, 104.0, 104.0, 104.0, 103.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 3112 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3115, "number_of_timesteps": 65692, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 1442 5 visits [104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 3115 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1443 6 visits [104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 103.0, 500.0, 103.0]  episode_count: 3117 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1444 7 visits [104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 500.0, 103.0]  episode_count: 3118 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1445 9 visits [104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 3123 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1446 0 visits [105.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 3124 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3125, "number_of_timesteps": 65907, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 1447 1 visits [105.0, 105.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 3125 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1448 2 visits [105.0, 105.0, 105.0, 104.0, 104.0, 104.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 3129 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1449 3 visits [105.0, 105.0, 105.0, 105.0, 104.0, 104.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 3132 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1450 4 visits [105.0, 105.0, 105.0, 105.0, 105.0, 104.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 3133 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1451 5 visits [105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 3134 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3138, "number_of_timesteps": 66154, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 1452 6 visits [105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 104.0, 500.0, 104.0]  episode_count: 3138 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1453 7 visits [105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 500.0, 104.0]  episode_count: 3140 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1454 9 visits [105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 3141 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1455 0 visits [106.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 3142 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1456 1 visits [106.0, 106.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 3144 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1457 2 visits [106.0, 106.0, 106.0, 105.0, 105.0, 105.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 3144 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3150, "number_of_timesteps": 66463, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1458 3 visits [106.0, 106.0, 106.0, 106.0, 105.0, 105.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 3150 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1459 4 visits [106.0, 106.0, 106.0, 106.0, 106.0, 105.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 3152 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1460 5 visits [106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 3153 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1461 6 visits [106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 105.0, 500.0, 105.0]  episode_count: 3156 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1462 7 visits [106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 500.0, 105.0]  episode_count: 3157 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1463 9 visits [106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 3158 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3161, "number_of_timesteps": 66682, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1464 0 visits [107.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 3161 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1465 1 visits [107.0, 107.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 3163 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1466 2 visits [107.0, 107.0, 107.0, 106.0, 106.0, 106.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 3164 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1467 3 visits [107.0, 107.0, 107.0, 107.0, 106.0, 106.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 3165 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1468 4 visits [107.0, 107.0, 107.0, 107.0, 107.0, 106.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 3169 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3171, "number_of_timesteps": 66935, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1469 5 visits [107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 3171 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1470 6 visits [107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 106.0, 500.0, 106.0]  episode_count: 3172 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1471 7 visits [107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 500.0, 106.0]  episode_count: 3176 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1472 9 visits [107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 3177 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3181, "number_of_timesteps": 67131, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1473 0 visits [108.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 3181 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1474 1 visits [108.0, 108.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 3182 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1475 2 visits [108.0, 108.0, 108.0, 107.0, 107.0, 107.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 3182 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1476 3 visits [108.0, 108.0, 108.0, 108.0, 107.0, 107.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 3184 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1477 4 visits [108.0, 108.0, 108.0, 108.0, 108.0, 107.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 3187 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1478 5 visits [108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 3188 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1479 6 visits [108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 107.0, 500.0, 107.0]  episode_count: 3189 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3191, "number_of_timesteps": 67307, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1480 7 visits [108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 500.0, 107.0]  episode_count: 3191 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1481 9 visits [108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 3193 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1482 0 visits [109.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 3198 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1483 1 visits [109.0, 109.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 3199 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1484 2 visits [109.0, 109.0, 109.0, 108.0, 108.0, 108.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 3200 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3204, "number_of_timesteps": 67615, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1485 3 visits [109.0, 109.0, 109.0, 109.0, 108.0, 108.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 3204 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1486 4 visits [109.0, 109.0, 109.0, 109.0, 109.0, 108.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 3205 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1487 5 visits [109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 3207 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1488 6 visits [109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 108.0, 500.0, 108.0]  episode_count: 3208 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1489 7 visits [109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 500.0, 108.0]  episode_count: 3211 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3214, "number_of_timesteps": 67791, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1490 9 visits [109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 3214 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1491 0 visits [110.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 3218 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1492 1 visits [110.0, 110.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 3219 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1493 2 visits [110.0, 110.0, 110.0, 109.0, 109.0, 109.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 3220 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1494 3 visits [110.0, 110.0, 110.0, 110.0, 109.0, 109.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 3222 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3225, "number_of_timesteps": 68071, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1495 4 visits [110.0, 110.0, 110.0, 110.0, 110.0, 109.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 3225 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1496 5 visits [110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 3228 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1497 6 visits [110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 109.0, 500.0, 109.0]  episode_count: 3229 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1498 7 visits [110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 500.0, 109.0]  episode_count: 3231 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1499 9 visits [110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 3234 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1500 0 visits [111.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 3234 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3236, "number_of_timesteps": 68313, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1501 1 visits [111.0, 111.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 3236 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1502 2 visits [111.0, 111.0, 111.0, 110.0, 110.0, 110.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 3240 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1503 3 visits [111.0, 111.0, 111.0, 111.0, 110.0, 110.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 3244 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1504 4 visits [111.0, 111.0, 111.0, 111.0, 111.0, 110.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 3244 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1505 5 visits [111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 3245 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3249, "number_of_timesteps": 68569, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1506 6 visits [111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 110.0, 500.0, 110.0]  episode_count: 3249 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1507 7 visits [111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 500.0, 110.0]  episode_count: 3249 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1508 9 visits [111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 3250 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1509 0 visits [112.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 3254 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1510 1 visits [112.0, 112.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 3256 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1511 2 visits [112.0, 112.0, 112.0, 111.0, 111.0, 111.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 3258 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3259, "number_of_timesteps": 68803, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 1512 3 visits [112.0, 112.0, 112.0, 112.0, 111.0, 111.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 3259 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1513 4 visits [112.0, 112.0, 112.0, 112.0, 112.0, 111.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 3259 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1514 5 visits [112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 3262 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1515 6 visits [112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 111.0, 500.0, 111.0]  episode_count: 3264 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1516 7 visits [112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 500.0, 111.0]  episode_count: 3264 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1517 9 visits [112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 3267 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3269, "number_of_timesteps": 69113, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 1518 0 visits [113.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 3269 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1519 1 visits [113.0, 113.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 3273 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1520 2 visits [113.0, 113.0, 113.0, 112.0, 112.0, 112.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 3274 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1521 3 visits [113.0, 113.0, 113.0, 113.0, 112.0, 112.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 3276 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1522 4 visits [113.0, 113.0, 113.0, 113.0, 113.0, 112.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 3278 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3280, "number_of_timesteps": 69339, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 1523 5 visits [113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 3280 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1524 6 visits [113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 112.0, 500.0, 112.0]  episode_count: 3285 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1525 7 visits [113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 500.0, 112.0]  episode_count: 3287 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1526 9 visits [113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 3288 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3290, "number_of_timesteps": 69532, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 1527 0 visits [114.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 3290 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1528 1 visits [114.0, 114.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 3293 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1529 2 visits [114.0, 114.0, 114.0, 113.0, 113.0, 113.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 3295 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1530 3 visits [114.0, 114.0, 114.0, 114.0, 113.0, 113.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 3296 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1531 4 visits [114.0, 114.0, 114.0, 114.0, 114.0, 113.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 3297 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3302, "number_of_timesteps": 69746, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 1532 5 visits [114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 3302 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1533 6 visits [114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 113.0, 500.0, 113.0]  episode_count: 3305 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1534 7 visits [114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 500.0, 113.0]  episode_count: 3307 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1535 9 visits [114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 3309 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1536 0 visits [115.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 3311 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3316, "number_of_timesteps": 70039, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 1537 1 visits [115.0, 115.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 3316 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1538 2 visits [115.0, 115.0, 115.0, 114.0, 114.0, 114.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 3317 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1539 3 visits [115.0, 115.0, 115.0, 115.0, 114.0, 114.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 3321 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1540 4 visits [115.0, 115.0, 115.0, 115.0, 115.0, 114.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 3323 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3326, "number_of_timesteps": 70171, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 1541 5 visits [115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 3326 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1542 6 visits [115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 114.0, 500.0, 114.0]  episode_count: 3326 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1543 7 visits [115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 500.0, 114.0]  episode_count: 3331 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1544 9 visits [115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 3335 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1545 0 visits [116.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 3335 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3336, "number_of_timesteps": 70372, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 1546 1 visits [116.0, 116.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 3336 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1547 2 visits [116.0, 116.0, 116.0, 115.0, 115.0, 115.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 3339 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1548 3 visits [116.0, 116.0, 116.0, 116.0, 115.0, 115.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 3341 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1549 4 visits [116.0, 116.0, 116.0, 116.0, 116.0, 115.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 3344 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3347, "number_of_timesteps": 70607, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1550 5 visits [116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 3347 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1551 6 visits [116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 115.0, 500.0, 115.0]  episode_count: 3348 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1552 7 visits [116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 500.0, 115.0]  episode_count: 3350 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1553 9 visits [116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 3352 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1554 0 visits [117.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 3354 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3358, "number_of_timesteps": 70837, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1555 1 visits [117.0, 117.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 3358 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1556 2 visits [117.0, 117.0, 117.0, 116.0, 116.0, 116.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 3359 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1557 3 visits [117.0, 117.0, 117.0, 117.0, 116.0, 116.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 3362 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1558 4 visits [117.0, 117.0, 117.0, 117.0, 117.0, 116.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 3363 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1559 5 visits [117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 3364 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3369, "number_of_timesteps": 71030, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1560 6 visits [117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 116.0, 500.0, 116.0]  episode_count: 3369 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1561 7 visits [117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 500.0, 116.0]  episode_count: 3370 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1562 9 visits [117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 3371 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1563 0 visits [118.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 3373 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1564 1 visits [118.0, 118.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 3375 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3379, "number_of_timesteps": 71303, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1565 2 visits [118.0, 118.0, 118.0, 117.0, 117.0, 117.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 3379 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1566 3 visits [118.0, 118.0, 118.0, 118.0, 117.0, 117.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 3379 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1567 4 visits [118.0, 118.0, 118.0, 118.0, 118.0, 117.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 3379 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1568 5 visits [118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 3384 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1569 6 visits [118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 117.0, 500.0, 117.0]  episode_count: 3387 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1570 7 visits [118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 500.0, 117.0]  episode_count: 3387 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3389, "number_of_timesteps": 71481, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1571 9 visits [118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 3389 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1572 0 visits [119.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 3393 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1573 1 visits [119.0, 119.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 3393 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1574 2 visits [119.0, 119.0, 119.0, 118.0, 118.0, 118.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 3394 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1575 3 visits [119.0, 119.0, 119.0, 119.0, 118.0, 118.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 3398 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3400, "number_of_timesteps": 71775, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1576 4 visits [119.0, 119.0, 119.0, 119.0, 119.0, 118.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 3400 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1577 5 visits [119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 3402 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1578 6 visits [119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 118.0, 500.0, 118.0]  episode_count: 3404 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1579 7 visits [119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 500.0, 118.0]  episode_count: 3405 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1580 9 visits [119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 3408 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1581 0 visits [120.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 3409 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3412, "number_of_timesteps": 72026, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1582 1 visits [120.0, 120.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 3412 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1583 2 visits [120.0, 120.0, 120.0, 119.0, 119.0, 119.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 3413 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1584 3 visits [120.0, 120.0, 120.0, 120.0, 119.0, 119.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 3414 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1585 4 visits [120.0, 120.0, 120.0, 120.0, 120.0, 119.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 3417 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1586 5 visits [120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 3419 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3422, "number_of_timesteps": 72273, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 1587 6 visits [120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 119.0, 500.0, 119.0]  episode_count: 3422 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1588 7 visits [120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 500.0, 119.0]  episode_count: 3424 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1589 9 visits [120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 3426 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1590 0 visits [121.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 3428 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1591 1 visits [121.0, 121.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 3430 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1592 2 visits [121.0, 121.0, 121.0, 120.0, 120.0, 120.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 3430 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3432, "number_of_timesteps": 72495, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 1593 3 visits [121.0, 121.0, 121.0, 121.0, 120.0, 120.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 3432 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1594 4 visits [121.0, 121.0, 121.0, 121.0, 121.0, 120.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 3437 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1595 5 visits [121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 3438 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1596 6 visits [121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 120.0, 500.0, 120.0]  episode_count: 3440 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3442, "number_of_timesteps": 72719, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
Step 1597 7 visits [121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 500.0, 120.0]  episode_count: 3442 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1598 9 visits [121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 3442 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1599 0 visits [122.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 3445 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1600 1 visits [122.0, 122.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 3447 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1601 2 visits [122.0, 122.0, 122.0, 121.0, 121.0, 121.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 3451 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3453, "number_of_timesteps": 72983, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.14999999999999858},
Step 1602 3 visits [122.0, 122.0, 122.0, 122.0, 121.0, 121.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 3453 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1603 4 visits [122.0, 122.0, 122.0, 122.0, 122.0, 121.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 3454 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1604 5 visits [122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 3455 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1605 6 visits [122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 121.0, 500.0, 121.0]  episode_count: 3458 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1606 7 visits [122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 500.0, 121.0]  episode_count: 3461 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3463, "number_of_timesteps": 73178, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
Step 1607 9 visits [122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 3463 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1608 0 visits [123.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 3465 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1609 1 visits [123.0, 123.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 3467 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1610 2 visits [123.0, 123.0, 123.0, 122.0, 122.0, 122.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 3468 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1611 3 visits [123.0, 123.0, 123.0, 123.0, 122.0, 122.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 3472 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3475, "number_of_timesteps": 73447, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.14999999999999858},
Step 1612 4 visits [123.0, 123.0, 123.0, 123.0, 123.0, 122.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 3475 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1613 5 visits [123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 3475 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1614 6 visits [123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 122.0, 500.0, 122.0]  episode_count: 3478 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1615 7 visits [123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 500.0, 122.0]  episode_count: 3483 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3485, "number_of_timesteps": 73627, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.14999999999999858},
Step 1616 9 visits [123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 3485 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1617 0 visits [124.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 3486 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1618 1 visits [124.0, 124.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 3488 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1619 2 visits [124.0, 124.0, 124.0, 123.0, 123.0, 123.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 3490 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1620 3 visits [124.0, 124.0, 124.0, 124.0, 123.0, 123.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 3490 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1621 4 visits [124.0, 124.0, 124.0, 124.0, 124.0, 123.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 3492 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1622 5 visits [124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 3494 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3496, "number_of_timesteps": 73845, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 1623 6 visits [124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 123.0, 500.0, 123.0]  episode_count: 3496 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1624 7 visits [124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 500.0, 123.0]  episode_count: 3497 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1625 9 visits [124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 3499 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1626 0 visits [125.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 3501 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1627 1 visits [125.0, 125.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 3502 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1628 2 visits [125.0, 125.0, 125.0, 124.0, 124.0, 124.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 3503 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1629 3 visits [125.0, 125.0, 125.0, 125.0, 124.0, 124.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 3505 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3511, "number_of_timesteps": 74282, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.14999999999999858},
Step 1630 4 visits [125.0, 125.0, 125.0, 125.0, 125.0, 124.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 3511 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1631 5 visits [125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 3512 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1632 6 visits [125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 124.0, 500.0, 124.0]  episode_count: 3513 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1633 7 visits [125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 500.0, 124.0]  episode_count: 3518 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1634 9 visits [125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 3519 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3522, "number_of_timesteps": 74473, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.14999999999999858},
Step 1635 0 visits [126.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 3522 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1636 1 visits [126.0, 126.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 3525 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1637 2 visits [126.0, 126.0, 126.0, 125.0, 125.0, 125.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 3526 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1638 3 visits [126.0, 126.0, 126.0, 126.0, 125.0, 125.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 3528 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1639 4 visits [126.0, 126.0, 126.0, 126.0, 126.0, 125.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 3531 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3532, "number_of_timesteps": 74645, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 1640 5 visits [126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 3532 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1641 6 visits [126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 125.0, 500.0, 125.0]  episode_count: 3535 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1642 7 visits [126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 500.0, 125.0]  episode_count: 3535 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1643 9 visits [126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 3537 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1644 0 visits [127.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 3539 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1645 1 visits [127.0, 127.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 3541 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3546, "number_of_timesteps": 74972, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.14999999999999858},
Step 1646 2 visits [127.0, 127.0, 127.0, 126.0, 126.0, 126.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 3546 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1647 3 visits [127.0, 127.0, 127.0, 127.0, 126.0, 126.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 3550 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1648 4 visits [127.0, 127.0, 127.0, 127.0, 127.0, 126.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 3552 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1649 5 visits [127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 3553 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3557, "number_of_timesteps": 75169, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
Step 1650 6 visits [127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 126.0, 500.0, 126.0]  episode_count: 3557 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1651 7 visits [127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 500.0, 126.0]  episode_count: 3558 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1652 9 visits [127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 3560 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1653 0 visits [128.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 3562 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1654 1 visits [128.0, 128.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 3566 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3567, "number_of_timesteps": 75384, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
Step 1655 2 visits [128.0, 128.0, 128.0, 127.0, 127.0, 127.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 3567 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1656 3 visits [128.0, 128.0, 128.0, 128.0, 127.0, 127.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 3571 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1657 4 visits [128.0, 128.0, 128.0, 128.0, 128.0, 127.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 3573 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1658 5 visits [128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 3574 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1659 6 visits [128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 127.0, 500.0, 127.0]  episode_count: 3575 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3578, "number_of_timesteps": 75586, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14999999999999858},
Step 1660 7 visits [128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 500.0, 127.0]  episode_count: 3578 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1661 9 visits [128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 3580 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1662 0 visits [129.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 3583 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3588, "number_of_timesteps": 75793, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 1663 1 visits [129.0, 129.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 3588 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1664 2 visits [129.0, 129.0, 129.0, 128.0, 128.0, 128.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 3590 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1665 3 visits [129.0, 129.0, 129.0, 129.0, 128.0, 128.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 3591 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1666 4 visits [129.0, 129.0, 129.0, 129.0, 129.0, 128.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 3595 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1667 5 visits [129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 3597 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3603, "number_of_timesteps": 76023, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14999999999999858},
Step 1668 6 visits [129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 128.0, 500.0, 128.0]  episode_count: 3603 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1669 7 visits [129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 500.0, 128.0]  episode_count: 3603 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1670 9 visits [129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 3605 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1671 0 visits [130.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 3606 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1672 1 visits [130.0, 130.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 3609 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1673 2 visits [130.0, 130.0, 130.0, 129.0, 129.0, 129.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 3612 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3613, "number_of_timesteps": 76189, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
Step 1674 3 visits [130.0, 130.0, 130.0, 130.0, 129.0, 129.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 3613 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1675 4 visits [130.0, 130.0, 130.0, 130.0, 130.0, 129.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 3615 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1676 5 visits [130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 3616 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1677 6 visits [130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 129.0, 500.0, 129.0]  episode_count: 3617 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1678 7 visits [130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 500.0, 129.0]  episode_count: 3621 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3624, "number_of_timesteps": 76469, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
Step 1679 9 visits [130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 3624 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1680 0 visits [131.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 3624 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1681 1 visits [131.0, 131.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 3627 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1682 2 visits [131.0, 131.0, 131.0, 130.0, 130.0, 130.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 3629 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1683 3 visits [131.0, 131.0, 131.0, 131.0, 130.0, 130.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 3630 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1684 4 visits [131.0, 131.0, 131.0, 131.0, 131.0, 130.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 3632 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3635, "number_of_timesteps": 76733, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
Step 1685 5 visits [131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 3635 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1686 6 visits [131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 130.0, 500.0, 130.0]  episode_count: 3637 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1687 7 visits [131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 500.0, 130.0]  episode_count: 3638 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1688 9 visits [131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 3642 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1689 0 visits [132.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 3643 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3645, "number_of_timesteps": 76936, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.15000000000000036},
Step 1690 1 visits [132.0, 132.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 3645 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1691 2 visits [132.0, 132.0, 132.0, 131.0, 131.0, 131.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 3648 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1692 3 visits [132.0, 132.0, 132.0, 132.0, 131.0, 131.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 3648 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1693 4 visits [132.0, 132.0, 132.0, 132.0, 132.0, 131.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 3654 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3655, "number_of_timesteps": 77186, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.15000000000000036},
Step 1694 5 visits [132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 3655 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1695 6 visits [132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 131.0, 500.0, 131.0]  episode_count: 3657 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1696 7 visits [132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 500.0, 131.0]  episode_count: 3659 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1697 9 visits [132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 3661 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1698 0 visits [133.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 3662 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3666, "number_of_timesteps": 77368, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
Step 1699 1 visits [133.0, 133.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 3666 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1700 2 visits [133.0, 133.0, 133.0, 132.0, 132.0, 132.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 3668 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1701 3 visits [133.0, 133.0, 133.0, 133.0, 132.0, 132.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 3670 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1702 4 visits [133.0, 133.0, 133.0, 133.0, 133.0, 132.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 3674 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3678, "number_of_timesteps": 77636, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.15000000000000036},
Step 1703 5 visits [133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 3678 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1704 6 visits [133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 132.0, 500.0, 132.0]  episode_count: 3680 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1705 7 visits [133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 500.0, 132.0]  episode_count: 3681 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1706 9 visits [133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 3682 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1707 0 visits [134.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 3684 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1708 1 visits [134.0, 134.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 3685 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1709 2 visits [134.0, 134.0, 134.0, 133.0, 133.0, 133.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 3687 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3690, "number_of_timesteps": 77873, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 1710 3 visits [134.0, 134.0, 134.0, 134.0, 133.0, 133.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 3690 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1711 4 visits [134.0, 134.0, 134.0, 134.0, 134.0, 133.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 3692 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1712 5 visits [134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 3692 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1713 6 visits [134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 133.0, 500.0, 133.0]  episode_count: 3695 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1714 7 visits [134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 500.0, 133.0]  episode_count: 3698 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3701, "number_of_timesteps": 78174, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 1715 9 visits [134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 3701 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1716 0 visits [135.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 3702 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1717 1 visits [135.0, 135.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 3703 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1718 2 visits [135.0, 135.0, 135.0, 134.0, 134.0, 134.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 3704 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1719 3 visits [135.0, 135.0, 135.0, 135.0, 134.0, 134.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 3708 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3712, "number_of_timesteps": 78427, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1720 4 visits [135.0, 135.0, 135.0, 135.0, 135.0, 134.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 3712 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1721 5 visits [135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 3713 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1722 6 visits [135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 134.0, 500.0, 134.0]  episode_count: 3715 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1723 7 visits [135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 500.0, 134.0]  episode_count: 3717 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1724 9 visits [135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 3719 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1725 0 visits [136.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 3719 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3722, "number_of_timesteps": 78598, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 1726 1 visits [136.0, 136.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 3722 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1727 2 visits [136.0, 136.0, 136.0, 135.0, 135.0, 135.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 3726 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1728 3 visits [136.0, 136.0, 136.0, 136.0, 135.0, 135.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 3727 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1729 4 visits [136.0, 136.0, 136.0, 136.0, 136.0, 135.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 3729 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1730 5 visits [136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 3731 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3734, "number_of_timesteps": 78842, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 1731 6 visits [136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 135.0, 500.0, 135.0]  episode_count: 3734 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1732 7 visits [136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 500.0, 135.0]  episode_count: 3736 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1733 9 visits [136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 3738 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1734 0 visits [137.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 3739 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1735 1 visits [137.0, 137.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 3742 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3744, "number_of_timesteps": 79077, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 1736 2 visits [137.0, 137.0, 137.0, 136.0, 136.0, 136.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 3744 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1737 3 visits [137.0, 137.0, 137.0, 137.0, 136.0, 136.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 3747 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1738 4 visits [137.0, 137.0, 137.0, 137.0, 137.0, 136.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 3749 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1739 5 visits [137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 3751 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3755, "number_of_timesteps": 79303, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 1740 6 visits [137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 136.0, 500.0, 136.0]  episode_count: 3755 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1741 7 visits [137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 500.0, 136.0]  episode_count: 3756 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1742 9 visits [137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 3759 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1743 0 visits [138.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 3762 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3765, "number_of_timesteps": 79495, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1744 1 visits [138.0, 138.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 3765 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1745 2 visits [138.0, 138.0, 138.0, 137.0, 137.0, 137.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 3767 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1746 3 visits [138.0, 138.0, 138.0, 138.0, 137.0, 137.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 3768 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1747 4 visits [138.0, 138.0, 138.0, 138.0, 138.0, 137.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 3771 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1748 5 visits [138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 3773 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3775, "number_of_timesteps": 79663, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 1749 6 visits [138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 137.0, 500.0, 137.0]  episode_count: 3775 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1750 7 visits [138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 500.0, 137.0]  episode_count: 3776 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1751 9 visits [138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 3778 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1752 0 visits [139.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 3779 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1753 1 visits [139.0, 139.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 3782 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3785, "number_of_timesteps": 79929, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1754 2 visits [139.0, 139.0, 139.0, 138.0, 138.0, 138.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 3785 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1755 3 visits [139.0, 139.0, 139.0, 139.0, 138.0, 138.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 3785 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1756 4 visits [139.0, 139.0, 139.0, 139.0, 139.0, 138.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 3786 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1757 5 visits [139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 3791 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1758 6 visits [139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 138.0, 500.0, 138.0]  episode_count: 3792 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1759 7 visits [139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 500.0, 138.0]  episode_count: 3793 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3798, "number_of_timesteps": 80211, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1760 9 visits [139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 3798 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1761 0 visits [140.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 3799 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1762 1 visits [140.0, 140.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 3801 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1763 2 visits [140.0, 140.0, 140.0, 139.0, 139.0, 139.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 3802 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1764 3 visits [140.0, 140.0, 140.0, 140.0, 139.0, 139.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 3803 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1765 4 visits [140.0, 140.0, 140.0, 140.0, 140.0, 139.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 3805 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1766 5 visits [140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 3806 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3809, "number_of_timesteps": 80460, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1767 6 visits [140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 139.0, 500.0, 139.0]  episode_count: 3809 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1768 7 visits [140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 500.0, 139.0]  episode_count: 3811 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1769 9 visits [140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 3813 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1770 0 visits [141.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 3814 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1771 1 visits [141.0, 141.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 3818 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3820, "number_of_timesteps": 80709, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1772 2 visits [141.0, 141.0, 141.0, 140.0, 140.0, 140.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 3820 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1773 3 visits [141.0, 141.0, 141.0, 141.0, 140.0, 140.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 3824 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1774 4 visits [141.0, 141.0, 141.0, 141.0, 141.0, 140.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 3825 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1775 5 visits [141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 3825 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1776 6 visits [141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 140.0, 500.0, 140.0]  episode_count: 3828 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1777 7 visits [141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 500.0, 140.0]  episode_count: 3829 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3832, "number_of_timesteps": 80960, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1778 9 visits [141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 3832 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1779 0 visits [142.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 3833 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1780 1 visits [142.0, 142.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 3835 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1781 2 visits [142.0, 142.0, 142.0, 141.0, 141.0, 141.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 3837 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1782 3 visits [142.0, 142.0, 142.0, 142.0, 141.0, 141.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 3838 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3843, "number_of_timesteps": 81223, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1783 4 visits [142.0, 142.0, 142.0, 142.0, 142.0, 141.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 3843 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1784 5 visits [142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 3844 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1785 6 visits [142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 141.0, 500.0, 141.0]  episode_count: 3846 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1786 7 visits [142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 500.0, 141.0]  episode_count: 3848 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1787 9 visits [142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 3851 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3854, "number_of_timesteps": 81499, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1788 0 visits [143.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 3854 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1789 1 visits [143.0, 143.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 3854 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1790 2 visits [143.0, 143.0, 143.0, 142.0, 142.0, 142.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 3858 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1791 3 visits [143.0, 143.0, 143.0, 143.0, 142.0, 142.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 3862 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3864, "number_of_timesteps": 81686, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1792 4 visits [143.0, 143.0, 143.0, 143.0, 143.0, 142.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 3864 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1793 5 visits [143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 3866 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1794 6 visits [143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 142.0, 500.0, 142.0]  episode_count: 3867 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1795 7 visits [143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 500.0, 142.0]  episode_count: 3868 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1796 9 visits [143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 3871 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3875, "number_of_timesteps": 81899, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1797 0 visits [144.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 3875 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1798 1 visits [144.0, 144.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 3877 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1799 2 visits [144.0, 144.0, 144.0, 143.0, 143.0, 143.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 3877 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1800 3 visits [144.0, 144.0, 144.0, 144.0, 143.0, 143.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 3879 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1801 4 visits [144.0, 144.0, 144.0, 144.0, 144.0, 143.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 3884 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3885, "number_of_timesteps": 82135, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1802 5 visits [144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 3885 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1803 6 visits [144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 143.0, 500.0, 143.0]  episode_count: 3886 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1804 7 visits [144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 500.0, 143.0]  episode_count: 3888 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1805 9 visits [144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 3890 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1806 0 visits [145.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 3893 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3895, "number_of_timesteps": 82357, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1807 1 visits [145.0, 145.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 3895 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1808 2 visits [145.0, 145.0, 145.0, 144.0, 144.0, 144.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 3898 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1809 3 visits [145.0, 145.0, 145.0, 145.0, 144.0, 144.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 3899 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1810 4 visits [145.0, 145.0, 145.0, 145.0, 145.0, 144.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 3902 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1811 5 visits [145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 3904 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3906, "number_of_timesteps": 82561, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1812 6 visits [145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 144.0, 500.0, 144.0]  episode_count: 3906 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1813 7 visits [145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 500.0, 144.0]  episode_count: 3906 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1814 9 visits [145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 3909 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1815 0 visits [146.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 3911 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1816 1 visits [146.0, 146.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 3914 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3918, "number_of_timesteps": 82817, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1817 2 visits [146.0, 146.0, 146.0, 145.0, 145.0, 145.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 3918 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1818 3 visits [146.0, 146.0, 146.0, 146.0, 145.0, 145.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 3920 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1819 4 visits [146.0, 146.0, 146.0, 146.0, 146.0, 145.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 3921 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1820 5 visits [146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 3921 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1821 6 visits [146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 145.0, 500.0, 145.0]  episode_count: 3922 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1822 7 visits [146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 500.0, 145.0]  episode_count: 3925 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3928, "number_of_timesteps": 83048, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1823 9 visits [146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 3928 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1824 0 visits [147.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 3929 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1825 1 visits [147.0, 147.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 3933 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1826 2 visits [147.0, 147.0, 147.0, 146.0, 146.0, 146.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 3934 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1827 3 visits [147.0, 147.0, 147.0, 147.0, 146.0, 146.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 3936 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1828 4 visits [147.0, 147.0, 147.0, 147.0, 147.0, 146.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 3937 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3942, "number_of_timesteps": 83390, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1829 5 visits [147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 3942 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1830 6 visits [147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 146.0, 500.0, 146.0]  episode_count: 3944 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1831 7 visits [147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 500.0, 146.0]  episode_count: 3946 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1832 9 visits [147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 3947 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1833 0 visits [148.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 3950 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3954, "number_of_timesteps": 83587, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1834 1 visits [148.0, 148.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 3954 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1835 2 visits [148.0, 148.0, 148.0, 147.0, 147.0, 147.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 3956 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1836 3 visits [148.0, 148.0, 148.0, 148.0, 147.0, 147.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 3958 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1837 4 visits [148.0, 148.0, 148.0, 148.0, 148.0, 147.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 3960 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1838 5 visits [148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 3962 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3965, "number_of_timesteps": 83819, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1839 6 visits [148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 147.0, 500.0, 147.0]  episode_count: 3965 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1840 7 visits [148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 500.0, 147.0]  episode_count: 3966 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1841 9 visits [148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 3968 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1842 0 visits [149.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 3973 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3975, "number_of_timesteps": 83993, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1843 1 visits [149.0, 149.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 3975 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1844 2 visits [149.0, 149.0, 149.0, 148.0, 148.0, 148.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 3977 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1845 3 visits [149.0, 149.0, 149.0, 149.0, 148.0, 148.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 3982 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1846 4 visits [149.0, 149.0, 149.0, 149.0, 149.0, 148.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 3982 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1847 5 visits [149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 3983 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1848 6 visits [149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 148.0, 500.0, 148.0]  episode_count: 3984 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1849 7 visits [149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 500.0, 148.0]  episode_count: 3984 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3986, "number_of_timesteps": 84193, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1850 9 visits [149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 3986 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1851 0 visits [150.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 3990 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1852 1 visits [150.0, 150.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 3991 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1853 2 visits [150.0, 150.0, 150.0, 149.0, 149.0, 149.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 3992 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1854 3 visits [150.0, 150.0, 150.0, 150.0, 149.0, 149.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 3994 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 3996, "number_of_timesteps": 84462, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1855 4 visits [150.0, 150.0, 150.0, 150.0, 150.0, 149.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 3996 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1856 5 visits [150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 3998 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1857 6 visits [150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 149.0, 500.0, 149.0]  episode_count: 4002 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1858 7 visits [150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 500.0, 149.0]  episode_count: 4003 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4007, "number_of_timesteps": 84756, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1859 9 visits [150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 4007 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1860 0 visits [151.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 4009 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1861 1 visits [151.0, 151.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 4013 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1862 2 visits [151.0, 151.0, 151.0, 150.0, 150.0, 150.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 4015 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1863 3 visits [151.0, 151.0, 151.0, 151.0, 150.0, 150.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 4016 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4017, "number_of_timesteps": 84916, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1864 4 visits [151.0, 151.0, 151.0, 151.0, 151.0, 150.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 4017 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1865 5 visits [151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 4019 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1866 6 visits [151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 150.0, 500.0, 150.0]  episode_count: 4020 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1867 7 visits [151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 500.0, 150.0]  episode_count: 4020 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1868 9 visits [151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 4022 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1869 0 visits [152.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 4023 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1870 1 visits [152.0, 152.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 4025 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1871 2 visits [152.0, 152.0, 152.0, 151.0, 151.0, 151.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 4026 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4029, "number_of_timesteps": 85214, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1872 3 visits [152.0, 152.0, 152.0, 152.0, 151.0, 151.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 4029 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1873 4 visits [152.0, 152.0, 152.0, 152.0, 152.0, 151.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 4030 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1874 5 visits [152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 4034 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1875 6 visits [152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 151.0, 500.0, 151.0]  episode_count: 4035 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1876 7 visits [152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 500.0, 151.0]  episode_count: 4037 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1877 9 visits [152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 4038 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4040, "number_of_timesteps": 85537, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1878 0 visits [153.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 4040 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1879 1 visits [153.0, 153.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 4042 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1880 2 visits [153.0, 153.0, 153.0, 152.0, 152.0, 152.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 4043 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1881 3 visits [153.0, 153.0, 153.0, 153.0, 152.0, 152.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 4047 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1882 4 visits [153.0, 153.0, 153.0, 153.0, 153.0, 152.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 4049 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4053, "number_of_timesteps": 85892, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1883 5 visits [153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 4053 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1884 6 visits [153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 152.0, 500.0, 152.0]  episode_count: 4054 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1885 7 visits [153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 500.0, 152.0]  episode_count: 4056 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1886 9 visits [153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 4057 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1887 0 visits [154.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 4061 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4064, "number_of_timesteps": 86093, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1888 1 visits [154.0, 154.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 4064 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1889 2 visits [154.0, 154.0, 154.0, 153.0, 153.0, 153.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 4064 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1890 3 visits [154.0, 154.0, 154.0, 154.0, 153.0, 153.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 4068 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1891 4 visits [154.0, 154.0, 154.0, 154.0, 154.0, 153.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 4071 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1892 5 visits [154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 4072 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1893 6 visits [154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 153.0, 500.0, 153.0]  episode_count: 4072 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4077, "number_of_timesteps": 86337, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1894 7 visits [154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 500.0, 153.0]  episode_count: 4077 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1895 9 visits [154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 4079 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1896 0 visits [155.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 4082 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1897 1 visits [155.0, 155.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 4084 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1898 2 visits [155.0, 155.0, 155.0, 154.0, 154.0, 154.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 4085 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4088, "number_of_timesteps": 86556, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1899 3 visits [155.0, 155.0, 155.0, 155.0, 154.0, 154.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 4088 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1900 4 visits [155.0, 155.0, 155.0, 155.0, 155.0, 154.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 4090 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1901 5 visits [155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 4093 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1902 6 visits [155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 154.0, 500.0, 154.0]  episode_count: 4095 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4099, "number_of_timesteps": 86723, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1903 7 visits [155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 500.0, 154.0]  episode_count: 4099 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1904 9 visits [155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 4102 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1905 0 visits [156.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 4103 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1906 1 visits [156.0, 156.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 4107 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1907 2 visits [156.0, 156.0, 156.0, 155.0, 155.0, 155.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 4108 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4112, "number_of_timesteps": 86965, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1908 3 visits [156.0, 156.0, 156.0, 156.0, 155.0, 155.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 4112 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1909 4 visits [156.0, 156.0, 156.0, 156.0, 156.0, 155.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 4114 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1910 5 visits [156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 4116 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1911 6 visits [156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 155.0, 500.0, 155.0]  episode_count: 4120 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1912 7 visits [156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 500.0, 155.0]  episode_count: 4121 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4123, "number_of_timesteps": 87170, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1913 9 visits [156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 4123 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1914 0 visits [157.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 4128 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1915 1 visits [157.0, 157.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 4130 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1916 2 visits [157.0, 157.0, 157.0, 156.0, 156.0, 156.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 4131 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4134, "number_of_timesteps": 87367, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1917 3 visits [157.0, 157.0, 157.0, 157.0, 156.0, 156.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 4134 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1918 4 visits [157.0, 157.0, 157.0, 157.0, 157.0, 156.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 4135 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1919 5 visits [157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 4139 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1920 6 visits [157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 156.0, 500.0, 156.0]  episode_count: 4141 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4145, "number_of_timesteps": 87564, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1921 7 visits [157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 500.0, 156.0]  episode_count: 4145 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1922 9 visits [157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 4148 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1923 0 visits [158.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 4151 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1924 1 visits [158.0, 158.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 4152 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1925 2 visits [158.0, 158.0, 158.0, 157.0, 157.0, 157.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 4154 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4159, "number_of_timesteps": 87756, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1926 3 visits [158.0, 158.0, 158.0, 158.0, 157.0, 157.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 4159 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1927 4 visits [158.0, 158.0, 158.0, 158.0, 158.0, 157.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 4161 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1928 5 visits [158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 4162 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1929 6 visits [158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 157.0, 500.0, 157.0]  episode_count: 4166 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4169, "number_of_timesteps": 87941, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1930 7 visits [158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 500.0, 157.0]  episode_count: 4169 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1931 9 visits [158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 4172 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1932 0 visits [159.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 4177 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1933 1 visits [159.0, 159.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 4177 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1934 2 visits [159.0, 159.0, 159.0, 158.0, 158.0, 158.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 4178 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4179, "number_of_timesteps": 88116, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1935 3 visits [159.0, 159.0, 159.0, 159.0, 158.0, 158.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 4179 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1936 4 visits [159.0, 159.0, 159.0, 159.0, 159.0, 158.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 4184 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1937 5 visits [159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 4185 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1938 6 visits [159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 158.0, 500.0, 158.0]  episode_count: 4186 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4190, "number_of_timesteps": 88333, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1939 7 visits [159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 500.0, 158.0]  episode_count: 4190 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1940 9 visits [159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 4194 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1941 0 visits [160.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 4194 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1942 1 visits [160.0, 160.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 4197 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1943 2 visits [160.0, 160.0, 160.0, 159.0, 159.0, 159.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 4198 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4200, "number_of_timesteps": 88533, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1944 3 visits [160.0, 160.0, 160.0, 160.0, 159.0, 159.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 4200 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1945 4 visits [160.0, 160.0, 160.0, 160.0, 160.0, 159.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 4201 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1946 5 visits [160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 4206 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1947 6 visits [160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 159.0, 500.0, 159.0]  episode_count: 4208 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4210, "number_of_timesteps": 88773, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1948 7 visits [160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 500.0, 159.0]  episode_count: 4210 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1949 9 visits [160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 4210 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1950 0 visits [161.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 4214 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1951 1 visits [161.0, 161.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 4215 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1952 2 visits [161.0, 161.0, 161.0, 160.0, 160.0, 160.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 4217 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4220, "number_of_timesteps": 88940, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1953 3 visits [161.0, 161.0, 161.0, 161.0, 160.0, 160.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 4220 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1954 4 visits [161.0, 161.0, 161.0, 161.0, 161.0, 160.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 4222 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1955 5 visits [161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 4223 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1956 6 visits [161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 160.0, 500.0, 160.0]  episode_count: 4225 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1957 7 visits [161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 500.0, 160.0]  episode_count: 4228 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1958 9 visits [161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 4229 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4230, "number_of_timesteps": 89207, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1959 0 visits [162.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 4230 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1960 1 visits [162.0, 162.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 4233 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1961 2 visits [162.0, 162.0, 162.0, 161.0, 161.0, 161.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 4234 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1962 3 visits [162.0, 162.0, 162.0, 162.0, 161.0, 161.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 4236 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4240, "number_of_timesteps": 89466, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1963 4 visits [162.0, 162.0, 162.0, 162.0, 162.0, 161.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 4240 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1964 5 visits [162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 4242 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1965 6 visits [162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 161.0, 500.0, 161.0]  episode_count: 4244 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1966 7 visits [162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 500.0, 161.0]  episode_count: 4247 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4250, "number_of_timesteps": 89647, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1967 9 visits [162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 4250 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1968 0 visits [163.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 4253 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1969 1 visits [163.0, 163.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 4253 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1970 2 visits [163.0, 163.0, 163.0, 162.0, 162.0, 162.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 4257 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1971 3 visits [163.0, 163.0, 163.0, 163.0, 162.0, 162.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 4257 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1972 4 visits [163.0, 163.0, 163.0, 163.0, 163.0, 162.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 4259 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4260, "number_of_timesteps": 89830, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1973 5 visits [163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 4260 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1974 6 visits [163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 162.0, 500.0, 162.0]  episode_count: 4262 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1975 7 visits [163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 500.0, 162.0]  episode_count: 4266 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1976 9 visits [163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 4268 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4271, "number_of_timesteps": 90101, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1977 0 visits [164.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 4271 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1978 1 visits [164.0, 164.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 4273 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1979 2 visits [164.0, 164.0, 164.0, 163.0, 163.0, 163.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 4277 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1980 3 visits [164.0, 164.0, 164.0, 164.0, 163.0, 163.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 4279 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1981 4 visits [164.0, 164.0, 164.0, 164.0, 164.0, 163.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 4280 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4282, "number_of_timesteps": 90276, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1982 5 visits [164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 4282 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1983 6 visits [164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 163.0, 500.0, 163.0]  episode_count: 4285 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1984 7 visits [164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 500.0, 163.0]  episode_count: 4285 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1985 9 visits [164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 4286 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1986 0 visits [165.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 4287 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1987 1 visits [165.0, 165.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 4290 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4293, "number_of_timesteps": 90553, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1988 2 visits [165.0, 165.0, 165.0, 164.0, 164.0, 164.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 4293 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1989 3 visits [165.0, 165.0, 165.0, 165.0, 164.0, 164.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 4296 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1990 4 visits [165.0, 165.0, 165.0, 165.0, 165.0, 164.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 4297 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1991 5 visits [165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 4298 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1992 6 visits [165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 164.0, 500.0, 164.0]  episode_count: 4300 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4303, "number_of_timesteps": 90772, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1993 7 visits [165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 500.0, 164.0]  episode_count: 4303 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1994 9 visits [165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 4305 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1995 0 visits [166.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 4308 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1996 1 visits [166.0, 166.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 4310 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4315, "number_of_timesteps": 91019, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1997 2 visits [166.0, 166.0, 166.0, 165.0, 165.0, 165.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 4315 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1998 3 visits [166.0, 166.0, 166.0, 166.0, 165.0, 165.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 4317 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 1999 4 visits [166.0, 166.0, 166.0, 166.0, 166.0, 165.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 4319 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2000 5 visits [166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 4320 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2001 6 visits [166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 165.0, 500.0, 165.0]  episode_count: 4324 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4328, "number_of_timesteps": 91235, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2002 7 visits [166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 500.0, 165.0]  episode_count: 4328 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2003 9 visits [166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 4330 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2004 0 visits [167.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 4332 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2005 1 visits [167.0, 167.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 4334 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2006 2 visits [167.0, 167.0, 167.0, 166.0, 166.0, 166.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 4335 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4338, "number_of_timesteps": 91417, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2007 3 visits [167.0, 167.0, 167.0, 167.0, 166.0, 166.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 4338 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2008 4 visits [167.0, 167.0, 167.0, 167.0, 167.0, 166.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 4340 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2009 5 visits [167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 4343 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2010 6 visits [167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 166.0, 500.0, 166.0]  episode_count: 4345 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2011 7 visits [167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 500.0, 166.0]  episode_count: 4347 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4349, "number_of_timesteps": 91636, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2012 9 visits [167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 4349 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2013 0 visits [168.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 4351 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2014 1 visits [168.0, 168.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 4352 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2015 2 visits [168.0, 168.0, 168.0, 167.0, 167.0, 167.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 4354 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2016 3 visits [168.0, 168.0, 168.0, 168.0, 167.0, 167.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 4355 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2017 4 visits [168.0, 168.0, 168.0, 168.0, 168.0, 167.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 4357 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4360, "number_of_timesteps": 91885, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2018 5 visits [168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 4360 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2019 6 visits [168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 167.0, 500.0, 167.0]  episode_count: 4362 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2020 7 visits [168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 500.0, 167.0]  episode_count: 4362 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2021 9 visits [168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 4365 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2022 0 visits [169.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 4367 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2023 1 visits [169.0, 169.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 4369 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2024 2 visits [169.0, 169.0, 169.0, 168.0, 168.0, 168.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 4369 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4371, "number_of_timesteps": 92198, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2025 3 visits [169.0, 169.0, 169.0, 169.0, 168.0, 168.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 4371 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2026 4 visits [169.0, 169.0, 169.0, 169.0, 169.0, 168.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 4374 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2027 5 visits [169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 4376 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2028 6 visits [169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 168.0, 500.0, 168.0]  episode_count: 4377 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2029 7 visits [169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 500.0, 168.0]  episode_count: 4378 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4384, "number_of_timesteps": 92520, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2030 9 visits [169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 4384 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2031 0 visits [170.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 4385 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2032 1 visits [170.0, 170.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 4387 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2033 2 visits [170.0, 170.0, 170.0, 169.0, 169.0, 169.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 4389 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2034 3 visits [170.0, 170.0, 170.0, 170.0, 169.0, 169.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 4390 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4395, "number_of_timesteps": 92747, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2035 4 visits [170.0, 170.0, 170.0, 170.0, 170.0, 169.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 4395 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2036 5 visits [170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 4397 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2037 6 visits [170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 169.0, 500.0, 169.0]  episode_count: 4397 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2038 7 visits [170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 500.0, 169.0]  episode_count: 4398 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2039 9 visits [170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 4403 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4405, "number_of_timesteps": 92954, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2040 0 visits [171.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 4405 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2041 1 visits [171.0, 171.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 4406 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2042 2 visits [171.0, 171.0, 171.0, 170.0, 170.0, 170.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 4409 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2043 3 visits [171.0, 171.0, 171.0, 171.0, 170.0, 170.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 4411 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2044 4 visits [171.0, 171.0, 171.0, 171.0, 171.0, 170.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 4412 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4415, "number_of_timesteps": 93115, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2045 5 visits [171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 4415 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2046 6 visits [171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 170.0, 500.0, 170.0]  episode_count: 4418 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2047 7 visits [171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 500.0, 170.0]  episode_count: 4420 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2048 9 visits [171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 4421 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2049 0 visits [172.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 4423 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4428, "number_of_timesteps": 93389, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2050 1 visits [172.0, 172.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 4428 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2051 2 visits [172.0, 172.0, 172.0, 171.0, 171.0, 171.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 4429 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2052 3 visits [172.0, 172.0, 172.0, 172.0, 171.0, 171.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 4431 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2053 4 visits [172.0, 172.0, 172.0, 172.0, 172.0, 171.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 4435 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2054 5 visits [172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 4436 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2055 6 visits [172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 171.0, 500.0, 171.0]  episode_count: 4437 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4441, "number_of_timesteps": 93672, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2056 7 visits [172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 500.0, 171.0]  episode_count: 4441 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2057 9 visits [172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 4442 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2058 0 visits [173.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 4442 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2059 1 visits [173.0, 173.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 4444 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2060 2 visits [173.0, 173.0, 173.0, 172.0, 172.0, 172.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 4448 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2061 3 visits [173.0, 173.0, 173.0, 173.0, 172.0, 172.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 4450 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4454, "number_of_timesteps": 93971, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2062 4 visits [173.0, 173.0, 173.0, 173.0, 173.0, 172.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 4454 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2063 5 visits [173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 4455 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2064 6 visits [173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 172.0, 500.0, 172.0]  episode_count: 4460 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2065 7 visits [173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 500.0, 172.0]  episode_count: 4463 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4465, "number_of_timesteps": 94145, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2066 9 visits [173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 4465 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2067 0 visits [174.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 4468 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2068 1 visits [174.0, 174.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 4471 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2069 2 visits [174.0, 174.0, 174.0, 173.0, 173.0, 173.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 4472 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2070 3 visits [174.0, 174.0, 174.0, 174.0, 173.0, 173.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 4472 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4476, "number_of_timesteps": 94315, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2071 4 visits [174.0, 174.0, 174.0, 174.0, 174.0, 173.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 4476 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2072 5 visits [174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 4478 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2073 6 visits [174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 173.0, 500.0, 173.0]  episode_count: 4481 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2074 7 visits [174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 500.0, 173.0]  episode_count: 4481 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2075 9 visits [174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 4483 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4486, "number_of_timesteps": 94502, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2076 0 visits [175.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 4486 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2077 1 visits [175.0, 175.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 4488 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2078 2 visits [175.0, 175.0, 175.0, 174.0, 174.0, 174.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 4491 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2079 3 visits [175.0, 175.0, 175.0, 175.0, 174.0, 174.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 4494 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4498, "number_of_timesteps": 94808, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2080 4 visits [175.0, 175.0, 175.0, 175.0, 175.0, 174.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 4498 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2081 5 visits [175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 4498 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2082 6 visits [175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 174.0, 500.0, 174.0]  episode_count: 4501 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2083 7 visits [175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 500.0, 174.0]  episode_count: 4503 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2084 9 visits [175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 4505 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4509, "number_of_timesteps": 95012, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2085 0 visits [176.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 4509 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2086 1 visits [176.0, 176.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 4511 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2087 2 visits [176.0, 176.0, 176.0, 175.0, 175.0, 175.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 4515 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2088 3 visits [176.0, 176.0, 176.0, 176.0, 175.0, 175.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 4518 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4519, "number_of_timesteps": 95160, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2089 4 visits [176.0, 176.0, 176.0, 176.0, 176.0, 175.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 4519 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2090 5 visits [176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 4520 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2091 6 visits [176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 175.0, 500.0, 175.0]  episode_count: 4524 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2092 7 visits [176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 500.0, 175.0]  episode_count: 4526 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2093 9 visits [176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 4528 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4530, "number_of_timesteps": 95377, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2094 0 visits [177.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 4530 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2095 1 visits [177.0, 177.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 4533 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2096 2 visits [177.0, 177.0, 177.0, 176.0, 176.0, 176.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 4533 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2097 3 visits [177.0, 177.0, 177.0, 177.0, 176.0, 176.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 4535 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4540, "number_of_timesteps": 95604, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2098 4 visits [177.0, 177.0, 177.0, 177.0, 177.0, 176.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 4540 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2099 5 visits [177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 4542 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2100 6 visits [177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 176.0, 500.0, 176.0]  episode_count: 4545 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2101 7 visits [177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 500.0, 176.0]  episode_count: 4546 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4550, "number_of_timesteps": 95788, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2102 9 visits [177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 4550 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2103 0 visits [178.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 4552 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2104 1 visits [178.0, 178.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 4555 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2105 2 visits [178.0, 178.0, 178.0, 177.0, 177.0, 177.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 4557 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2106 3 visits [178.0, 178.0, 178.0, 178.0, 177.0, 177.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 4558 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4560, "number_of_timesteps": 95969, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2107 4 visits [178.0, 178.0, 178.0, 178.0, 178.0, 177.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 4560 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2108 5 visits [178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 4563 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2109 6 visits [178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 177.0, 500.0, 177.0]  episode_count: 4566 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2110 7 visits [178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 500.0, 177.0]  episode_count: 4568 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4570, "number_of_timesteps": 96181, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2111 9 visits [178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 4570 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2112 0 visits [179.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 4570 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2113 1 visits [179.0, 179.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 4572 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2114 2 visits [179.0, 179.0, 179.0, 178.0, 178.0, 178.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 4576 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2115 3 visits [179.0, 179.0, 179.0, 179.0, 178.0, 178.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 4577 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2116 4 visits [179.0, 179.0, 179.0, 179.0, 179.0, 178.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 4578 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2117 5 visits [179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 4579 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4581, "number_of_timesteps": 96437, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2118 6 visits [179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 178.0, 500.0, 178.0]  episode_count: 4581 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2119 7 visits [179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 500.0, 178.0]  episode_count: 4586 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2120 9 visits [179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 4586 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2121 0 visits [180.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 4587 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2122 1 visits [180.0, 180.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 4590 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4591, "number_of_timesteps": 96684, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2123 2 visits [180.0, 180.0, 180.0, 179.0, 179.0, 179.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 4591 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2124 3 visits [180.0, 180.0, 180.0, 180.0, 179.0, 179.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 4593 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2125 4 visits [180.0, 180.0, 180.0, 180.0, 180.0, 179.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 4596 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2126 5 visits [180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 4598 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2127 6 visits [180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 179.0, 500.0, 179.0]  episode_count: 4600 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4601, "number_of_timesteps": 96923, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
Step 2128 7 visits [180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 500.0, 179.0]  episode_count: 4601 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2129 9 visits [180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 4604 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2130 0 visits [181.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 4608 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4612, "number_of_timesteps": 97106, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
Step 2131 1 visits [181.0, 181.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 4612 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2132 2 visits [181.0, 181.0, 181.0, 180.0, 180.0, 180.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 4612 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2133 3 visits [181.0, 181.0, 181.0, 181.0, 180.0, 180.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 4615 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2134 4 visits [181.0, 181.0, 181.0, 181.0, 181.0, 180.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 4615 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2135 5 visits [181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 4618 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2136 6 visits [181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 180.0, 500.0, 180.0]  episode_count: 4621 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4622, "number_of_timesteps": 97334, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14999999999999858},
Step 2137 7 visits [181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 500.0, 180.0]  episode_count: 4622 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2138 9 visits [181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 4623 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2139 0 visits [182.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 4627 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2140 1 visits [182.0, 182.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 4630 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4632, "number_of_timesteps": 97563, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 2141 2 visits [182.0, 182.0, 182.0, 181.0, 181.0, 181.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 4632 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2142 3 visits [182.0, 182.0, 182.0, 182.0, 181.0, 181.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 4636 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2143 4 visits [182.0, 182.0, 182.0, 182.0, 182.0, 181.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 4637 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2144 5 visits [182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 4639 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2145 6 visits [182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 181.0, 500.0, 181.0]  episode_count: 4641 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2146 7 visits [182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 500.0, 181.0]  episode_count: 4641 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4644, "number_of_timesteps": 97766, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 2147 9 visits [182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 4644 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2148 0 visits [183.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 4645 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2149 1 visits [183.0, 183.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 4648 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2150 2 visits [183.0, 183.0, 183.0, 182.0, 182.0, 182.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 4649 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2151 3 visits [183.0, 183.0, 183.0, 183.0, 182.0, 182.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 4653 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4656, "number_of_timesteps": 98025, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 2152 4 visits [183.0, 183.0, 183.0, 183.0, 183.0, 182.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 4656 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2153 5 visits [183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 4658 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2154 6 visits [183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 182.0, 500.0, 182.0]  episode_count: 4659 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2155 7 visits [183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 500.0, 182.0]  episode_count: 4662 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4666, "number_of_timesteps": 98247, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 2156 9 visits [183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 4666 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2157 0 visits [184.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 4667 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2158 1 visits [184.0, 184.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 4670 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2159 2 visits [184.0, 184.0, 184.0, 183.0, 183.0, 183.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 4672 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2160 3 visits [184.0, 184.0, 184.0, 184.0, 183.0, 183.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 4675 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4677, "number_of_timesteps": 98442, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14999999999999858},
Step 2161 4 visits [184.0, 184.0, 184.0, 184.0, 184.0, 183.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 4677 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2162 5 visits [184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 4679 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2163 6 visits [184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 183.0, 500.0, 183.0]  episode_count: 4682 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2164 7 visits [184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 500.0, 183.0]  episode_count: 4686 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4688, "number_of_timesteps": 98663, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14999999999999858},
Step 2165 9 visits [184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 4688 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2166 0 visits [185.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 4689 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2167 1 visits [185.0, 185.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 4691 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2168 2 visits [185.0, 185.0, 185.0, 184.0, 184.0, 184.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 4695 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2169 3 visits [185.0, 185.0, 185.0, 185.0, 184.0, 184.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 4696 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4698, "number_of_timesteps": 98867, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.14999999999999858},
Step 2170 4 visits [185.0, 185.0, 185.0, 185.0, 185.0, 184.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 4698 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2171 5 visits [185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 4701 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2172 6 visits [185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 184.0, 500.0, 184.0]  episode_count: 4702 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2173 7 visits [185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 500.0, 184.0]  episode_count: 4703 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2174 9 visits [185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 4706 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4709, "number_of_timesteps": 99082, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.14999999999999858},
Step 2175 0 visits [186.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 4709 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2176 1 visits [186.0, 186.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 4712 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2177 2 visits [186.0, 186.0, 186.0, 185.0, 185.0, 185.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 4715 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2178 3 visits [186.0, 186.0, 186.0, 186.0, 185.0, 185.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 4717 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4720, "number_of_timesteps": 99296, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2179 4 visits [186.0, 186.0, 186.0, 186.0, 186.0, 185.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 4720 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2180 5 visits [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 4722 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2181 6 visits [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 185.0, 500.0, 185.0]  episode_count: 4724 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2182 7 visits [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 500.0, 185.0]  episode_count: 4729 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4730, "number_of_timesteps": 99464, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2183 9 visits [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 4730 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2184 0 visits [187.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 4732 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2185 1 visits [187.0, 187.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 4736 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2186 2 visits [187.0, 187.0, 187.0, 186.0, 186.0, 186.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 4736 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2187 3 visits [187.0, 187.0, 187.0, 187.0, 186.0, 186.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 4737 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4740, "number_of_timesteps": 99630, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2188 4 visits [187.0, 187.0, 187.0, 187.0, 187.0, 186.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 4740 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2189 5 visits [187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 4742 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2190 6 visits [187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 186.0, 500.0, 186.0]  episode_count: 4743 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2191 7 visits [187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 500.0, 186.0]  episode_count: 4744 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2192 9 visits [187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 4746 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2193 0 visits [188.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 4749 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2194 1 visits [188.0, 188.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 4749 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4752, "number_of_timesteps": 99950, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2195 2 visits [188.0, 188.0, 188.0, 187.0, 187.0, 187.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 4752 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2196 3 visits [188.0, 188.0, 188.0, 188.0, 187.0, 187.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 4756 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2197 4 visits [188.0, 188.0, 188.0, 188.0, 188.0, 187.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 4757 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2198 5 visits [188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 4760 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2199 6 visits [188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 187.0, 500.0, 187.0]  episode_count: 4761 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4762, "number_of_timesteps": 100184, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2200 7 visits [188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 500.0, 187.0]  episode_count: 4762 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2201 9 visits [188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 4767 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2202 0 visits [189.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 4767 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2203 1 visits [189.0, 189.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 4771 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4772, "number_of_timesteps": 100393, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
Step 2204 2 visits [189.0, 189.0, 189.0, 188.0, 188.0, 188.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 4772 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2205 3 visits [189.0, 189.0, 189.0, 189.0, 188.0, 188.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 4773 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2206 4 visits [189.0, 189.0, 189.0, 189.0, 189.0, 188.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 4778 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2207 5 visits [189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 4778 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2208 6 visits [189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 188.0, 500.0, 188.0]  episode_count: 4780 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2209 7 visits [189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 500.0, 188.0]  episode_count: 4781 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4783, "number_of_timesteps": 100622, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
Step 2210 9 visits [189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 4783 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2211 0 visits [190.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 4785 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2212 1 visits [190.0, 190.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 4786 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2213 2 visits [190.0, 190.0, 190.0, 189.0, 189.0, 189.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 4787 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2214 3 visits [190.0, 190.0, 190.0, 190.0, 189.0, 189.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 4790 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2215 4 visits [190.0, 190.0, 190.0, 190.0, 190.0, 189.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 4792 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4794, "number_of_timesteps": 100893, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
Step 2216 5 visits [190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 4794 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2217 6 visits [190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 189.0, 500.0, 189.0]  episode_count: 4795 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2218 7 visits [190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 500.0, 189.0]  episode_count: 4798 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2219 9 visits [190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 4799 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4805, "number_of_timesteps": 101191, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
Step 2220 0 visits [191.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 4805 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2221 1 visits [191.0, 191.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 4805 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2222 2 visits [191.0, 191.0, 191.0, 190.0, 190.0, 190.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 4810 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2223 3 visits [191.0, 191.0, 191.0, 191.0, 190.0, 190.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 4810 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2224 4 visits [191.0, 191.0, 191.0, 191.0, 191.0, 190.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 4812 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4816, "number_of_timesteps": 101361, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.15000000000000036},
Step 2225 5 visits [191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 4816 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2226 6 visits [191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 190.0, 500.0, 190.0]  episode_count: 4816 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2227 7 visits [191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 500.0, 190.0]  episode_count: 4816 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2228 9 visits [191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 4821 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2229 0 visits [192.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 4822 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2230 1 visits [192.0, 192.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 4823 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2231 2 visits [192.0, 192.0, 192.0, 191.0, 191.0, 191.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 4825 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4826, "number_of_timesteps": 101636, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
Step 2232 3 visits [192.0, 192.0, 192.0, 192.0, 191.0, 191.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 4826 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2233 4 visits [192.0, 192.0, 192.0, 192.0, 192.0, 191.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 4830 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2234 5 visits [192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 4832 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2235 6 visits [192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 191.0, 500.0, 191.0]  episode_count: 4832 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2236 7 visits [192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 500.0, 191.0]  episode_count: 4833 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2237 9 visits [192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 4835 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4839, "number_of_timesteps": 101963, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
Step 2238 0 visits [193.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 4839 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2239 1 visits [193.0, 193.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 4840 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2240 2 visits [193.0, 193.0, 193.0, 192.0, 192.0, 192.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 4842 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2241 3 visits [193.0, 193.0, 193.0, 193.0, 192.0, 192.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 4846 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2242 4 visits [193.0, 193.0, 193.0, 193.0, 193.0, 192.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 4848 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4849, "number_of_timesteps": 102169, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
Step 2243 5 visits [193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 4849 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2244 6 visits [193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 192.0, 500.0, 192.0]  episode_count: 4852 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2245 7 visits [193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 500.0, 192.0]  episode_count: 4855 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2246 9 visits [193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 4857 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4860, "number_of_timesteps": 102366, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
Step 2247 0 visits [194.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 4860 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2248 1 visits [194.0, 194.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 4864 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2249 2 visits [194.0, 194.0, 194.0, 193.0, 193.0, 193.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 4866 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2250 3 visits [194.0, 194.0, 194.0, 194.0, 193.0, 193.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 4868 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4870, "number_of_timesteps": 102547, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 2251 4 visits [194.0, 194.0, 194.0, 194.0, 194.0, 193.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 4870 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2252 5 visits [194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 4873 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2253 6 visits [194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 193.0, 500.0, 193.0]  episode_count: 4876 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2254 7 visits [194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 500.0, 193.0]  episode_count: 4877 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2255 9 visits [194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 4879 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4883, "number_of_timesteps": 102799, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 2256 0 visits [195.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 4883 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2257 1 visits [195.0, 195.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 4884 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2258 2 visits [195.0, 195.0, 195.0, 194.0, 194.0, 194.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 4887 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2259 3 visits [195.0, 195.0, 195.0, 195.0, 194.0, 194.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 4887 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2260 4 visits [195.0, 195.0, 195.0, 195.0, 195.0, 194.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 4892 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4895, "number_of_timesteps": 103040, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2261 5 visits [195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 4895 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2262 6 visits [195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 194.0, 500.0, 194.0]  episode_count: 4898 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2263 7 visits [195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 500.0, 194.0]  episode_count: 4900 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2264 9 visits [195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 4901 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4905, "number_of_timesteps": 103203, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 2265 0 visits [196.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 4905 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2266 1 visits [196.0, 196.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 4906 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2267 2 visits [196.0, 196.0, 196.0, 195.0, 195.0, 195.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 4908 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2268 3 visits [196.0, 196.0, 196.0, 196.0, 195.0, 195.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 4910 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2269 4 visits [196.0, 196.0, 196.0, 196.0, 196.0, 195.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 4912 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4915, "number_of_timesteps": 103421, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
Step 2270 5 visits [196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 4915 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2271 6 visits [196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 195.0, 500.0, 195.0]  episode_count: 4916 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2272 7 visits [196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 500.0, 195.0]  episode_count: 4920 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2273 9 visits [196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 4921 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2274 0 visits [197.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 4922 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2275 1 visits [197.0, 197.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 4922 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4927, "number_of_timesteps": 103644, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 2276 2 visits [197.0, 197.0, 197.0, 196.0, 196.0, 196.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 4927 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2277 3 visits [197.0, 197.0, 197.0, 197.0, 196.0, 196.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 4929 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2278 4 visits [197.0, 197.0, 197.0, 197.0, 197.0, 196.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 4931 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2279 5 visits [197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 4931 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2280 6 visits [197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 196.0, 500.0, 196.0]  episode_count: 4934 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2281 7 visits [197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 500.0, 196.0]  episode_count: 4936 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4939, "number_of_timesteps": 103920, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2282 9 visits [197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 4939 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2283 0 visits [198.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 4941 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2284 1 visits [198.0, 198.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 4943 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2285 2 visits [198.0, 198.0, 198.0, 197.0, 197.0, 197.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 4946 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2286 3 visits [198.0, 198.0, 198.0, 198.0, 197.0, 197.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 4946 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2287 4 visits [198.0, 198.0, 198.0, 198.0, 198.0, 197.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 4948 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4951, "number_of_timesteps": 104220, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2288 5 visits [198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 4951 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2289 6 visits [198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 197.0, 500.0, 197.0]  episode_count: 4951 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2290 7 visits [198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 500.0, 197.0]  episode_count: 4954 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2291 9 visits [198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 4956 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2292 0 visits [199.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 4957 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2293 1 visits [199.0, 199.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 4959 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4962, "number_of_timesteps": 104458, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2294 2 visits [199.0, 199.0, 199.0, 198.0, 198.0, 198.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 4962 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2295 3 visits [199.0, 199.0, 199.0, 199.0, 198.0, 198.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 4966 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2296 4 visits [199.0, 199.0, 199.0, 199.0, 199.0, 198.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 4967 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2297 5 visits [199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 4968 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4972, "number_of_timesteps": 104683, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2298 6 visits [199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 198.0, 500.0, 198.0]  episode_count: 4972 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2299 7 visits [199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 500.0, 198.0]  episode_count: 4973 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2300 9 visits [199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 4975 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2301 0 visits [200.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 4977 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2302 1 visits [200.0, 200.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 4980 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2303 2 visits [200.0, 200.0, 200.0, 199.0, 199.0, 199.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 4981 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4983, "number_of_timesteps": 104913, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2304 3 visits [200.0, 200.0, 200.0, 200.0, 199.0, 199.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 4983 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2305 4 visits [200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 4987 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2306 5 visits [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 4989 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2307 6 visits [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 500.0, 199.0]  episode_count: 4989 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 4995, "number_of_timesteps": 105185, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2308 7 visits [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 500.0, 199.0]  episode_count: 4995 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2309 9 visits [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 4997 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2310 0 visits [201.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 4997 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2311 1 visits [201.0, 201.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 5002 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5006, "number_of_timesteps": 105371, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2312 2 visits [201.0, 201.0, 201.0, 200.0, 200.0, 200.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 5006 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2313 3 visits [201.0, 201.0, 201.0, 201.0, 200.0, 200.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 5007 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2314 4 visits [201.0, 201.0, 201.0, 201.0, 201.0, 200.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 5009 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2315 5 visits [201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 5012 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2316 6 visits [201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 200.0, 500.0, 200.0]  episode_count: 5014 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5016, "number_of_timesteps": 105535, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2317 7 visits [201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 500.0, 200.0]  episode_count: 5016 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2318 9 visits [201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 5017 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2319 0 visits [202.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 5020 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2320 1 visits [202.0, 202.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 5022 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2321 2 visits [202.0, 202.0, 202.0, 201.0, 201.0, 201.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 5023 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2322 3 visits [202.0, 202.0, 202.0, 202.0, 201.0, 201.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 5025 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5027, "number_of_timesteps": 105800, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2323 4 visits [202.0, 202.0, 202.0, 202.0, 202.0, 201.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 5027 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2324 5 visits [202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 5029 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2325 6 visits [202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 201.0, 500.0, 201.0]  episode_count: 5031 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2326 7 visits [202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 500.0, 201.0]  episode_count: 5032 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2327 9 visits [202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 5035 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5037, "number_of_timesteps": 106031, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2328 0 visits [203.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 5037 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2329 1 visits [203.0, 203.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 5038 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2330 2 visits [203.0, 203.0, 203.0, 202.0, 202.0, 202.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 5041 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2331 3 visits [203.0, 203.0, 203.0, 203.0, 202.0, 202.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 5045 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2332 4 visits [203.0, 203.0, 203.0, 203.0, 203.0, 202.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 5046 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5048, "number_of_timesteps": 106281, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2333 5 visits [203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 5048 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2334 6 visits [203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 202.0, 500.0, 202.0]  episode_count: 5050 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2335 7 visits [203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 500.0, 202.0]  episode_count: 5052 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2336 9 visits [203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 5056 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2337 0 visits [204.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 5056 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5058, "number_of_timesteps": 106501, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2338 1 visits [204.0, 204.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 5058 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2339 2 visits [204.0, 204.0, 204.0, 203.0, 203.0, 203.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 5061 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2340 3 visits [204.0, 204.0, 204.0, 204.0, 203.0, 203.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 5063 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2341 4 visits [204.0, 204.0, 204.0, 204.0, 204.0, 203.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 5065 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2342 5 visits [204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 5066 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5070, "number_of_timesteps": 106743, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2343 6 visits [204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 203.0, 500.0, 203.0]  episode_count: 5070 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2344 7 visits [204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 500.0, 203.0]  episode_count: 5074 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2345 9 visits [204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 5075 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2346 0 visits [205.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 5077 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5080, "number_of_timesteps": 106926, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2347 1 visits [205.0, 205.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 5080 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2348 2 visits [205.0, 205.0, 205.0, 204.0, 204.0, 204.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 5083 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2349 3 visits [205.0, 205.0, 205.0, 205.0, 204.0, 204.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 5084 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2350 4 visits [205.0, 205.0, 205.0, 205.0, 205.0, 204.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 5086 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2351 5 visits [205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 5089 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5091, "number_of_timesteps": 107149, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2352 6 visits [205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 204.0, 500.0, 204.0]  episode_count: 5091 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2353 7 visits [205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 500.0, 204.0]  episode_count: 5093 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2354 9 visits [205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 5095 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2355 0 visits [206.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 5098 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5101, "number_of_timesteps": 107350, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2356 1 visits [206.0, 206.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 5101 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2357 2 visits [206.0, 206.0, 206.0, 205.0, 205.0, 205.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 5104 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2358 3 visits [206.0, 206.0, 206.0, 206.0, 205.0, 205.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 5104 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2359 4 visits [206.0, 206.0, 206.0, 206.0, 206.0, 205.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 5105 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2360 5 visits [206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 5107 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5111, "number_of_timesteps": 107563, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2361 6 visits [206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 205.0, 500.0, 205.0]  episode_count: 5111 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2362 7 visits [206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 500.0, 205.0]  episode_count: 5111 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2363 9 visits [206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 5113 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2364 0 visits [207.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 5118 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2365 1 visits [207.0, 207.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 5119 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2366 2 visits [207.0, 207.0, 207.0, 206.0, 206.0, 206.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 5120 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5122, "number_of_timesteps": 107818, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2367 3 visits [207.0, 207.0, 207.0, 207.0, 206.0, 206.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 5122 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2368 4 visits [207.0, 207.0, 207.0, 207.0, 207.0, 206.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 5124 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2369 5 visits [207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 5124 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2370 6 visits [207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 206.0, 500.0, 206.0]  episode_count: 5126 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2371 7 visits [207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 500.0, 206.0]  episode_count: 5129 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5132, "number_of_timesteps": 108045, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2372 9 visits [207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 5132 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2373 0 visits [208.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 5134 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2374 1 visits [208.0, 208.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 5135 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2375 2 visits [208.0, 208.0, 208.0, 207.0, 207.0, 207.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 5139 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2376 3 visits [208.0, 208.0, 208.0, 208.0, 207.0, 207.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 5141 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5143, "number_of_timesteps": 108238, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2377 4 visits [208.0, 208.0, 208.0, 208.0, 208.0, 207.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 5143 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2378 5 visits [208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 5147 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2379 6 visits [208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 207.0, 500.0, 207.0]  episode_count: 5150 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2380 7 visits [208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 500.0, 207.0]  episode_count: 5152 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5153, "number_of_timesteps": 108452, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2381 9 visits [208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 5153 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2382 0 visits [209.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 5157 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2383 1 visits [209.0, 209.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 5160 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2384 2 visits [209.0, 209.0, 209.0, 208.0, 208.0, 208.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 5162 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5163, "number_of_timesteps": 108636, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2385 3 visits [209.0, 209.0, 209.0, 209.0, 208.0, 208.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 5163 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2386 4 visits [209.0, 209.0, 209.0, 209.0, 209.0, 208.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 5166 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2387 5 visits [209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 5168 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2388 6 visits [209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 208.0, 500.0, 208.0]  episode_count: 5170 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2389 7 visits [209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 500.0, 208.0]  episode_count: 5171 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5174, "number_of_timesteps": 108812, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2390 9 visits [209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 5174 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2391 0 visits [210.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 5176 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2392 1 visits [210.0, 210.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 5179 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2393 2 visits [210.0, 210.0, 210.0, 209.0, 209.0, 209.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 5181 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2394 3 visits [210.0, 210.0, 210.0, 210.0, 209.0, 209.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 5182 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5184, "number_of_timesteps": 109049, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2395 4 visits [210.0, 210.0, 210.0, 210.0, 210.0, 209.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 5184 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2396 5 visits [210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 5185 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2397 6 visits [210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 209.0, 500.0, 209.0]  episode_count: 5187 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2398 7 visits [210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 500.0, 209.0]  episode_count: 5191 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2399 9 visits [210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 5193 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5195, "number_of_timesteps": 109316, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2400 0 visits [211.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 5195 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2401 1 visits [211.0, 211.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 5195 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2402 2 visits [211.0, 211.0, 211.0, 210.0, 210.0, 210.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 5196 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2403 3 visits [211.0, 211.0, 211.0, 211.0, 210.0, 210.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 5200 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2404 4 visits [211.0, 211.0, 211.0, 211.0, 211.0, 210.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 5202 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2405 5 visits [211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 5202 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2406 6 visits [211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 210.0, 500.0, 210.0]  episode_count: 5204 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5210, "number_of_timesteps": 109654, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2407 7 visits [211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 500.0, 210.0]  episode_count: 5210 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2408 9 visits [211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 5211 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2409 0 visits [212.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 5213 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2410 1 visits [212.0, 212.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 5215 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5220, "number_of_timesteps": 109859, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2411 2 visits [212.0, 212.0, 212.0, 211.0, 211.0, 211.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 5220 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2412 3 visits [212.0, 212.0, 212.0, 212.0, 211.0, 211.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 5221 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2413 4 visits [212.0, 212.0, 212.0, 212.0, 212.0, 211.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 5222 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2414 5 visits [212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 5222 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2415 6 visits [212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 211.0, 500.0, 211.0]  episode_count: 5224 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2416 7 visits [212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 500.0, 211.0]  episode_count: 5228 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2417 9 visits [212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 5229 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5231, "number_of_timesteps": 110099, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2418 0 visits [213.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 5231 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2419 1 visits [213.0, 213.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 5234 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2420 2 visits [213.0, 213.0, 213.0, 212.0, 212.0, 212.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 5234 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2421 3 visits [213.0, 213.0, 213.0, 213.0, 212.0, 212.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 5238 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2422 4 visits [213.0, 213.0, 213.0, 213.0, 213.0, 212.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 5240 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5242, "number_of_timesteps": 110336, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2423 5 visits [213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 5242 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2424 6 visits [213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 212.0, 500.0, 212.0]  episode_count: 5243 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2425 7 visits [213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 500.0, 212.0]  episode_count: 5246 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2426 9 visits [213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 5249 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2427 0 visits [214.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 5249 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5252, "number_of_timesteps": 110554, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2428 1 visits [214.0, 214.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 5252 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2429 2 visits [214.0, 214.0, 214.0, 213.0, 213.0, 213.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 5255 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2430 3 visits [214.0, 214.0, 214.0, 214.0, 213.0, 213.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 5259 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2431 4 visits [214.0, 214.0, 214.0, 214.0, 214.0, 213.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 5260 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2432 5 visits [214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 5261 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5263, "number_of_timesteps": 110759, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2433 6 visits [214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 213.0, 500.0, 213.0]  episode_count: 5263 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2434 7 visits [214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 500.0, 213.0]  episode_count: 5268 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2435 9 visits [214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 5269 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2436 0 visits [215.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 5271 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5273, "number_of_timesteps": 111004, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2437 1 visits [215.0, 215.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 5273 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2438 2 visits [215.0, 215.0, 215.0, 214.0, 214.0, 214.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 5278 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2439 3 visits [215.0, 215.0, 215.0, 215.0, 214.0, 214.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 5279 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2440 4 visits [215.0, 215.0, 215.0, 215.0, 215.0, 214.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 5281 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5285, "number_of_timesteps": 111187, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2441 5 visits [215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 5285 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2442 6 visits [215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 214.0, 500.0, 214.0]  episode_count: 5286 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2443 7 visits [215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 500.0, 214.0]  episode_count: 5290 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2444 9 visits [215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 5292 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2445 0 visits [216.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 5293 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5295, "number_of_timesteps": 111341, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2446 1 visits [216.0, 216.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 5295 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2447 2 visits [216.0, 216.0, 216.0, 215.0, 215.0, 215.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 5299 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2448 3 visits [216.0, 216.0, 216.0, 216.0, 215.0, 215.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 5301 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2449 4 visits [216.0, 216.0, 216.0, 216.0, 216.0, 215.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 5303 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2450 5 visits [216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 5303 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5305, "number_of_timesteps": 111576, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2451 6 visits [216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 215.0, 500.0, 215.0]  episode_count: 5305 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2452 7 visits [216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 500.0, 215.0]  episode_count: 5309 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2453 9 visits [216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 5310 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2454 0 visits [217.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 5312 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2455 1 visits [217.0, 217.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 5313 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5317, "number_of_timesteps": 111844, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2456 2 visits [217.0, 217.0, 217.0, 216.0, 216.0, 216.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 5317 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2457 3 visits [217.0, 217.0, 217.0, 217.0, 216.0, 216.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 5318 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2458 4 visits [217.0, 217.0, 217.0, 217.0, 217.0, 216.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 5320 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2459 5 visits [217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 5323 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2460 6 visits [217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 216.0, 500.0, 216.0]  episode_count: 5326 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5328, "number_of_timesteps": 112095, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2461 7 visits [217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 500.0, 216.0]  episode_count: 5328 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2462 9 visits [217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 5330 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2463 0 visits [218.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 5332 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2464 1 visits [218.0, 218.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 5336 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5338, "number_of_timesteps": 112274, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2465 2 visits [218.0, 218.0, 218.0, 217.0, 217.0, 217.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 5338 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2466 3 visits [218.0, 218.0, 218.0, 218.0, 217.0, 217.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 5340 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2467 4 visits [218.0, 218.0, 218.0, 218.0, 218.0, 217.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 5342 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2468 5 visits [218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 5345 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2469 6 visits [218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 217.0, 500.0, 217.0]  episode_count: 5346 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5349, "number_of_timesteps": 112486, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2470 7 visits [218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 500.0, 217.0]  episode_count: 5349 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2471 9 visits [218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 5351 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2472 0 visits [219.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 5352 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2473 1 visits [219.0, 219.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 5356 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2474 2 visits [219.0, 219.0, 219.0, 218.0, 218.0, 218.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 5357 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5361, "number_of_timesteps": 112725, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2475 3 visits [219.0, 219.0, 219.0, 219.0, 218.0, 218.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 5361 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2476 4 visits [219.0, 219.0, 219.0, 219.0, 219.0, 218.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 5363 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2477 5 visits [219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 5366 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2478 6 visits [219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 218.0, 500.0, 218.0]  episode_count: 5369 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5371, "number_of_timesteps": 112918, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2479 7 visits [219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 500.0, 218.0]  episode_count: 5371 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2480 9 visits [219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 5374 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2481 0 visits [220.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 5377 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2482 1 visits [220.0, 220.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 5378 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5381, "number_of_timesteps": 113079, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2483 2 visits [220.0, 220.0, 220.0, 219.0, 219.0, 219.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 5381 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2484 3 visits [220.0, 220.0, 220.0, 220.0, 219.0, 219.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 5382 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2485 4 visits [220.0, 220.0, 220.0, 220.0, 220.0, 219.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 5385 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2486 5 visits [220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 5389 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2487 6 visits [220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 219.0, 500.0, 219.0]  episode_count: 5390 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5391, "number_of_timesteps": 113271, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2488 7 visits [220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 500.0, 219.0]  episode_count: 5391 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2489 9 visits [220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 5394 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2490 0 visits [221.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 5397 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2491 1 visits [221.0, 221.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 5398 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2492 2 visits [221.0, 221.0, 221.0, 220.0, 220.0, 220.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 5399 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5404, "number_of_timesteps": 113541, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2493 3 visits [221.0, 221.0, 221.0, 221.0, 220.0, 220.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 5404 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2494 4 visits [221.0, 221.0, 221.0, 221.0, 221.0, 220.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 5405 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2495 5 visits [221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 5407 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2496 6 visits [221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 220.0, 500.0, 220.0]  episode_count: 5409 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2497 7 visits [221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 500.0, 220.0]  episode_count: 5410 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2498 9 visits [221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 5412 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5415, "number_of_timesteps": 113799, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2499 0 visits [222.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 5415 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2500 1 visits [222.0, 222.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 5417 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2501 2 visits [222.0, 222.0, 222.0, 221.0, 221.0, 221.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 5420 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2502 3 visits [222.0, 222.0, 222.0, 222.0, 221.0, 221.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 5424 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5426, "number_of_timesteps": 114029, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2503 4 visits [222.0, 222.0, 222.0, 222.0, 222.0, 221.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 5426 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2504 5 visits [222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 5428 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2505 6 visits [222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 221.0, 500.0, 221.0]  episode_count: 5433 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2506 7 visits [222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 500.0, 221.0]  episode_count: 5434 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5437, "number_of_timesteps": 114189, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2507 9 visits [222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 5437 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2508 0 visits [223.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 5439 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2509 1 visits [223.0, 223.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 5439 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2510 2 visits [223.0, 223.0, 223.0, 222.0, 222.0, 222.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 5444 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2511 3 visits [223.0, 223.0, 223.0, 223.0, 222.0, 222.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 5445 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5447, "number_of_timesteps": 114405, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2512 4 visits [223.0, 223.0, 223.0, 223.0, 223.0, 222.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 5447 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2513 5 visits [223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 5451 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2514 6 visits [223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 222.0, 500.0, 222.0]  episode_count: 5452 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2515 7 visits [223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 500.0, 222.0]  episode_count: 5453 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2516 9 visits [223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 5456 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5458, "number_of_timesteps": 114613, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2517 0 visits [224.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 5458 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2518 1 visits [224.0, 224.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 5460 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2519 2 visits [224.0, 224.0, 224.0, 223.0, 223.0, 223.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 5461 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2520 3 visits [224.0, 224.0, 224.0, 224.0, 223.0, 223.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 5464 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2521 4 visits [224.0, 224.0, 224.0, 224.0, 224.0, 223.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 5467 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5470, "number_of_timesteps": 114880, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2522 5 visits [224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 5470 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2523 6 visits [224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 223.0, 500.0, 223.0]  episode_count: 5474 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2524 7 visits [224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 500.0, 223.0]  episode_count: 5476 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2525 9 visits [224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 5477 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2526 0 visits [225.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 5478 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2527 1 visits [225.0, 225.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 5478 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5482, "number_of_timesteps": 115090, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2528 2 visits [225.0, 225.0, 225.0, 224.0, 224.0, 224.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 5482 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2529 3 visits [225.0, 225.0, 225.0, 225.0, 224.0, 224.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 5485 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2530 4 visits [225.0, 225.0, 225.0, 225.0, 225.0, 224.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 5486 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2531 5 visits [225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 5488 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2532 6 visits [225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 224.0, 500.0, 224.0]  episode_count: 5490 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2533 7 visits [225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 500.0, 224.0]  episode_count: 5490 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2534 9 visits [225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 5491 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5494, "number_of_timesteps": 115407, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2535 0 visits [226.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 5494 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2536 1 visits [226.0, 226.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 5497 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2537 2 visits [226.0, 226.0, 226.0, 225.0, 225.0, 225.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 5499 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2538 3 visits [226.0, 226.0, 226.0, 226.0, 225.0, 225.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 5502 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5504, "number_of_timesteps": 115637, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2539 4 visits [226.0, 226.0, 226.0, 226.0, 226.0, 225.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 5504 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2540 5 visits [226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 5507 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2541 6 visits [226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 225.0, 500.0, 225.0]  episode_count: 5509 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2542 7 visits [226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 500.0, 225.0]  episode_count: 5511 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5514, "number_of_timesteps": 115820, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2543 9 visits [226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 5514 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2544 0 visits [227.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 5515 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2545 1 visits [227.0, 227.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 5517 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2546 2 visits [227.0, 227.0, 227.0, 226.0, 226.0, 226.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 5520 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2547 3 visits [227.0, 227.0, 227.0, 227.0, 226.0, 226.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 5523 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5525, "number_of_timesteps": 116059, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2548 4 visits [227.0, 227.0, 227.0, 227.0, 227.0, 226.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 5525 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2549 5 visits [227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 5526 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2550 6 visits [227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 226.0, 500.0, 226.0]  episode_count: 5528 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2551 7 visits [227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 500.0, 226.0]  episode_count: 5531 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2552 9 visits [227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 5532 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5536, "number_of_timesteps": 116288, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2553 0 visits [228.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 5536 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2554 1 visits [228.0, 228.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 5538 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2555 2 visits [228.0, 228.0, 228.0, 227.0, 227.0, 227.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 5541 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2556 3 visits [228.0, 228.0, 228.0, 228.0, 227.0, 227.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 5542 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2557 4 visits [228.0, 228.0, 228.0, 228.0, 228.0, 227.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 5544 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5547, "number_of_timesteps": 116496, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2558 5 visits [228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 5547 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2559 6 visits [228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 227.0, 500.0, 227.0]  episode_count: 5550 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2560 7 visits [228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 500.0, 227.0]  episode_count: 5554 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2561 9 visits [228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 5556 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5558, "number_of_timesteps": 116695, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2562 0 visits [229.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 5558 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2563 1 visits [229.0, 229.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 5561 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2564 2 visits [229.0, 229.0, 229.0, 228.0, 228.0, 228.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 5562 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2565 3 visits [229.0, 229.0, 229.0, 229.0, 228.0, 228.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 5564 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2566 4 visits [229.0, 229.0, 229.0, 229.0, 229.0, 228.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 5565 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5569, "number_of_timesteps": 116878, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2567 5 visits [229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 5569 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2568 6 visits [229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 228.0, 500.0, 228.0]  episode_count: 5573 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2569 7 visits [229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 500.0, 228.0]  episode_count: 5574 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2570 9 visits [229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 5576 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2571 0 visits [230.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 5577 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5580, "number_of_timesteps": 117106, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2572 1 visits [230.0, 230.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 5580 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2573 2 visits [230.0, 230.0, 230.0, 229.0, 229.0, 229.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 5581 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2574 3 visits [230.0, 230.0, 230.0, 230.0, 229.0, 229.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 5583 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2575 4 visits [230.0, 230.0, 230.0, 230.0, 230.0, 229.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 5586 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2576 5 visits [230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 5587 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2577 6 visits [230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 229.0, 500.0, 229.0]  episode_count: 5589 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5590, "number_of_timesteps": 117306, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2578 7 visits [230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 500.0, 229.0]  episode_count: 5590 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2579 9 visits [230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 5594 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2580 0 visits [231.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 5596 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2581 1 visits [231.0, 231.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 5597 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5600, "number_of_timesteps": 117516, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2582 2 visits [231.0, 231.0, 231.0, 230.0, 230.0, 230.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 5600 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2583 3 visits [231.0, 231.0, 231.0, 231.0, 230.0, 230.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 5602 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2584 4 visits [231.0, 231.0, 231.0, 231.0, 231.0, 230.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 5604 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2585 5 visits [231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 5608 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5610, "number_of_timesteps": 117773, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2586 6 visits [231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 230.0, 500.0, 230.0]  episode_count: 5610 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2587 7 visits [231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 500.0, 230.0]  episode_count: 5611 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2588 9 visits [231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 5615 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2589 0 visits [232.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 5616 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2590 1 visits [232.0, 232.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 5617 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5621, "number_of_timesteps": 117991, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2591 2 visits [232.0, 232.0, 232.0, 231.0, 231.0, 231.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 5621 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2592 3 visits [232.0, 232.0, 232.0, 232.0, 231.0, 231.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 5622 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2593 4 visits [232.0, 232.0, 232.0, 232.0, 232.0, 231.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 5623 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2594 5 visits [232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 5625 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2595 6 visits [232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 231.0, 500.0, 231.0]  episode_count: 5626 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2596 7 visits [232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 500.0, 231.0]  episode_count: 5627 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2597 9 visits [232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 5630 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5634, "number_of_timesteps": 118327, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2598 0 visits [233.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 5634 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2599 1 visits [233.0, 233.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 5635 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2600 2 visits [233.0, 233.0, 233.0, 232.0, 232.0, 232.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 5638 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2601 3 visits [233.0, 233.0, 233.0, 233.0, 232.0, 232.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 5640 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2602 4 visits [233.0, 233.0, 233.0, 233.0, 233.0, 232.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 5641 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2603 5 visits [233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 5642 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5645, "number_of_timesteps": 118556, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 2604 6 visits [233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 232.0, 500.0, 232.0]  episode_count: 5645 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2605 7 visits [233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 500.0, 232.0]  episode_count: 5648 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2606 9 visits [233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 5652 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2607 0 visits [234.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 5653 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5655, "number_of_timesteps": 118768, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 2608 1 visits [234.0, 234.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 5655 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2609 2 visits [234.0, 234.0, 234.0, 233.0, 233.0, 233.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 5658 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2610 3 visits [234.0, 234.0, 234.0, 234.0, 233.0, 233.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 5660 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2611 4 visits [234.0, 234.0, 234.0, 234.0, 234.0, 233.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 5661 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2612 5 visits [234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 5662 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2613 6 visits [234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 233.0, 500.0, 233.0]  episode_count: 5664 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5667, "number_of_timesteps": 119032, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2614 7 visits [234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 500.0, 233.0]  episode_count: 5667 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2615 9 visits [234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 5669 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2616 0 visits [235.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 5671 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2617 1 visits [235.0, 235.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 5674 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5677, "number_of_timesteps": 119247, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 2618 2 visits [235.0, 235.0, 235.0, 234.0, 234.0, 234.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 5677 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2619 3 visits [235.0, 235.0, 235.0, 235.0, 234.0, 234.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 5681 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2620 4 visits [235.0, 235.0, 235.0, 235.0, 235.0, 234.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 5682 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2621 5 visits [235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 5684 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5689, "number_of_timesteps": 119431, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2622 6 visits [235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 234.0, 500.0, 234.0]  episode_count: 5689 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2623 7 visits [235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 500.0, 234.0]  episode_count: 5690 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2624 9 visits [235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 5692 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2625 0 visits [236.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 5694 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2626 1 visits [236.0, 236.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 5697 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5700, "number_of_timesteps": 119643, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 2627 2 visits [236.0, 236.0, 236.0, 235.0, 235.0, 235.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 5700 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2628 3 visits [236.0, 236.0, 236.0, 236.0, 235.0, 235.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 5703 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2629 4 visits [236.0, 236.0, 236.0, 236.0, 236.0, 235.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 5704 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2630 5 visits [236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 5705 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2631 6 visits [236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 235.0, 500.0, 235.0]  episode_count: 5706 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2632 7 visits [236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 500.0, 235.0]  episode_count: 5709 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5712, "number_of_timesteps": 119881, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 2633 9 visits [236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 5712 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2634 0 visits [237.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 5715 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2635 1 visits [237.0, 237.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 5717 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2636 2 visits [237.0, 237.0, 237.0, 236.0, 236.0, 236.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 5719 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5723, "number_of_timesteps": 120065, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 2637 3 visits [237.0, 237.0, 237.0, 237.0, 236.0, 236.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 5723 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2638 4 visits [237.0, 237.0, 237.0, 237.0, 237.0, 236.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 5726 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2639 5 visits [237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 5726 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2640 6 visits [237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 236.0, 500.0, 236.0]  episode_count: 5729 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2641 7 visits [237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 500.0, 236.0]  episode_count: 5729 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5734, "number_of_timesteps": 120306, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 2642 9 visits [237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 5734 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2643 0 visits [238.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 5735 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2644 1 visits [238.0, 238.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 5739 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2645 2 visits [238.0, 238.0, 238.0, 237.0, 237.0, 237.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 5741 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2646 3 visits [238.0, 238.0, 238.0, 238.0, 237.0, 237.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 5743 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5744, "number_of_timesteps": 120506, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2647 4 visits [238.0, 238.0, 238.0, 238.0, 238.0, 237.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 5744 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2648 5 visits [238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 5748 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2649 6 visits [238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 237.0, 500.0, 237.0]  episode_count: 5751 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2650 7 visits [238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 500.0, 237.0]  episode_count: 5753 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5756, "number_of_timesteps": 120723, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 2651 9 visits [238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 5756 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2652 0 visits [239.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 5759 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2653 1 visits [239.0, 239.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 5760 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2654 2 visits [239.0, 239.0, 239.0, 238.0, 238.0, 238.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 5762 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5766, "number_of_timesteps": 120887, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 2655 3 visits [239.0, 239.0, 239.0, 239.0, 238.0, 238.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 5766 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2656 4 visits [239.0, 239.0, 239.0, 239.0, 239.0, 238.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 5767 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2657 5 visits [239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 5768 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2658 6 visits [239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 238.0, 500.0, 238.0]  episode_count: 5770 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2659 7 visits [239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 500.0, 238.0]  episode_count: 5775 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2660 9 visits [239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 5775 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5779, "number_of_timesteps": 121149, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 2661 0 visits [240.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 5779 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2662 1 visits [240.0, 240.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 5781 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2663 2 visits [240.0, 240.0, 240.0, 239.0, 239.0, 239.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 5782 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2664 3 visits [240.0, 240.0, 240.0, 240.0, 239.0, 239.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 5785 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2665 4 visits [240.0, 240.0, 240.0, 240.0, 240.0, 239.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 5788 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5789, "number_of_timesteps": 121363, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 2666 5 visits [240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 5789 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2667 6 visits [240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 239.0, 500.0, 239.0]  episode_count: 5790 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2668 7 visits [240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 500.0, 239.0]  episode_count: 5793 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2669 9 visits [240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 5794 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2670 0 visits [241.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 5797 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5799, "number_of_timesteps": 121597, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2671 1 visits [241.0, 241.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 5799 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2672 2 visits [241.0, 241.0, 241.0, 240.0, 240.0, 240.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 5800 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2673 3 visits [241.0, 241.0, 241.0, 241.0, 240.0, 240.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 5804 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2674 4 visits [241.0, 241.0, 241.0, 241.0, 241.0, 240.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 5804 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2675 5 visits [241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 5805 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5809, "number_of_timesteps": 121807, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2676 6 visits [241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 240.0, 500.0, 240.0]  episode_count: 5809 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2677 7 visits [241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 500.0, 240.0]  episode_count: 5812 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2678 9 visits [241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 5814 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2679 0 visits [242.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 5815 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5819, "number_of_timesteps": 122032, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2680 1 visits [242.0, 242.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 5819 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2681 2 visits [242.0, 242.0, 242.0, 241.0, 241.0, 241.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 5820 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2682 3 visits [242.0, 242.0, 242.0, 242.0, 241.0, 241.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 5823 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2683 4 visits [242.0, 242.0, 242.0, 242.0, 242.0, 241.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 5825 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2684 5 visits [242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 5826 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5829, "number_of_timesteps": 122222, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2685 6 visits [242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 241.0, 500.0, 241.0]  episode_count: 5829 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2686 7 visits [242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 500.0, 241.0]  episode_count: 5829 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2687 9 visits [242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 5831 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2688 0 visits [243.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 5833 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2689 1 visits [243.0, 243.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 5835 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2690 2 visits [243.0, 243.0, 243.0, 242.0, 242.0, 242.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 5837 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2691 3 visits [243.0, 243.0, 243.0, 243.0, 242.0, 242.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 5838 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5842, "number_of_timesteps": 122591, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2692 4 visits [243.0, 243.0, 243.0, 243.0, 243.0, 242.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 5842 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2693 5 visits [243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 5843 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2694 6 visits [243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 242.0, 500.0, 242.0]  episode_count: 5845 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2695 7 visits [243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 500.0, 242.0]  episode_count: 5848 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2696 9 visits [243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 5850 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5853, "number_of_timesteps": 122824, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2697 0 visits [244.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 5853 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2698 1 visits [244.0, 244.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 5856 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2699 2 visits [244.0, 244.0, 244.0, 243.0, 243.0, 243.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 5856 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2700 3 visits [244.0, 244.0, 244.0, 244.0, 243.0, 243.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 5860 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2701 4 visits [244.0, 244.0, 244.0, 244.0, 244.0, 243.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 5862 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5863, "number_of_timesteps": 123003, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2702 5 visits [244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 5863 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2703 6 visits [244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 243.0, 500.0, 243.0]  episode_count: 5867 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2704 7 visits [244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 500.0, 243.0]  episode_count: 5868 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2705 9 visits [244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 5869 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2706 0 visits [245.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 5871 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5876, "number_of_timesteps": 123255, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2707 1 visits [245.0, 245.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 5876 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2708 2 visits [245.0, 245.0, 245.0, 244.0, 244.0, 244.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 5878 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2709 3 visits [245.0, 245.0, 245.0, 245.0, 244.0, 244.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 5878 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2710 4 visits [245.0, 245.0, 245.0, 245.0, 245.0, 244.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 5882 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2711 5 visits [245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 5883 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2712 6 visits [245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 244.0, 500.0, 244.0]  episode_count: 5885 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5887, "number_of_timesteps": 123518, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2713 7 visits [245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 500.0, 244.0]  episode_count: 5887 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2714 9 visits [245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 5891 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2715 0 visits [246.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 5892 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2716 1 visits [246.0, 246.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 5893 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2717 2 visits [246.0, 246.0, 246.0, 245.0, 245.0, 245.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 5894 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2718 3 visits [246.0, 246.0, 246.0, 246.0, 245.0, 245.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 5896 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5899, "number_of_timesteps": 123794, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2719 4 visits [246.0, 246.0, 246.0, 246.0, 246.0, 245.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 5899 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2720 5 visits [246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 5901 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2721 6 visits [246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 245.0, 500.0, 245.0]  episode_count: 5902 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2722 7 visits [246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 500.0, 245.0]  episode_count: 5905 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2723 9 visits [246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 5906 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5909, "number_of_timesteps": 124035, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2724 0 visits [247.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 5909 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2725 1 visits [247.0, 247.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 5912 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2726 2 visits [247.0, 247.0, 247.0, 246.0, 246.0, 246.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 5915 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2727 3 visits [247.0, 247.0, 247.0, 247.0, 246.0, 246.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 5915 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2728 4 visits [247.0, 247.0, 247.0, 247.0, 247.0, 246.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 5918 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5919, "number_of_timesteps": 124206, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2729 5 visits [247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 5919 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2730 6 visits [247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 246.0, 500.0, 246.0]  episode_count: 5922 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2731 7 visits [247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 500.0, 246.0]  episode_count: 5924 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2732 9 visits [247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 5925 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2733 0 visits [248.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 5927 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5931, "number_of_timesteps": 124485, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2734 1 visits [248.0, 248.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 5931 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2735 2 visits [248.0, 248.0, 248.0, 247.0, 247.0, 247.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 5932 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2736 3 visits [248.0, 248.0, 248.0, 248.0, 247.0, 247.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 5933 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2737 4 visits [248.0, 248.0, 248.0, 248.0, 248.0, 247.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 5936 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2738 5 visits [248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 5938 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2739 6 visits [248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 247.0, 500.0, 247.0]  episode_count: 5939 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2740 7 visits [248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 500.0, 247.0]  episode_count: 5940 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5941, "number_of_timesteps": 124708, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2741 9 visits [248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 5941 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2742 0 visits [249.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 5942 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2743 1 visits [249.0, 249.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 5944 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2744 2 visits [249.0, 249.0, 249.0, 248.0, 248.0, 248.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 5947 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2745 3 visits [249.0, 249.0, 249.0, 249.0, 248.0, 248.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 5948 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2746 4 visits [249.0, 249.0, 249.0, 249.0, 249.0, 248.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 5950 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5954, "number_of_timesteps": 125093, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2747 5 visits [249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 5954 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2748 6 visits [249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 248.0, 500.0, 248.0]  episode_count: 5955 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2749 7 visits [249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 500.0, 248.0]  episode_count: 5959 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2750 9 visits [249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 5959 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2751 0 visits [250.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 5963 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5964, "number_of_timesteps": 125295, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2752 1 visits [250.0, 250.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 5964 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2753 2 visits [250.0, 250.0, 250.0, 249.0, 249.0, 249.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 5966 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2754 3 visits [250.0, 250.0, 250.0, 250.0, 249.0, 249.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 5968 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2755 4 visits [250.0, 250.0, 250.0, 250.0, 250.0, 249.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 5971 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2756 5 visits [250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 5972 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2757 6 visits [250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 249.0, 500.0, 249.0]  episode_count: 5972 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5974, "number_of_timesteps": 125474, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2758 7 visits [250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 500.0, 249.0]  episode_count: 5974 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2759 9 visits [250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 5977 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2760 0 visits [251.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 5979 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2761 1 visits [251.0, 251.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 5980 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2762 2 visits [251.0, 251.0, 251.0, 250.0, 250.0, 250.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 5982 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5984, "number_of_timesteps": 125785, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2763 3 visits [251.0, 251.0, 251.0, 251.0, 250.0, 250.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 5984 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2764 4 visits [251.0, 251.0, 251.0, 251.0, 251.0, 250.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 5984 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2765 5 visits [251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 5985 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2766 6 visits [251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 250.0, 500.0, 250.0]  episode_count: 5991 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2767 7 visits [251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 500.0, 250.0]  episode_count: 5992 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2768 9 visits [251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 5992 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 5995, "number_of_timesteps": 126052, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2769 0 visits [252.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 5995 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2770 1 visits [252.0, 252.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 5999 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2771 2 visits [252.0, 252.0, 252.0, 251.0, 251.0, 251.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 6001 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2772 3 visits [252.0, 252.0, 252.0, 252.0, 251.0, 251.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 6003 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2773 4 visits [252.0, 252.0, 252.0, 252.0, 252.0, 251.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 6004 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6009, "number_of_timesteps": 126311, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2774 5 visits [252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 6009 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2775 6 visits [252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 251.0, 500.0, 251.0]  episode_count: 6010 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2776 7 visits [252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 500.0, 251.0]  episode_count: 6011 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2777 9 visits [252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 6013 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2778 0 visits [253.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 6015 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2779 1 visits [253.0, 253.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 6018 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6020, "number_of_timesteps": 126565, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2780 2 visits [253.0, 253.0, 253.0, 252.0, 252.0, 252.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 6020 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2781 3 visits [253.0, 253.0, 253.0, 253.0, 252.0, 252.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 6022 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2782 4 visits [253.0, 253.0, 253.0, 253.0, 253.0, 252.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 6023 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2783 5 visits [253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 6026 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6031, "number_of_timesteps": 126822, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2784 6 visits [253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 252.0, 500.0, 252.0]  episode_count: 6031 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2785 7 visits [253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 500.0, 252.0]  episode_count: 6032 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2786 9 visits [253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 6034 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2787 0 visits [254.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 6035 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2788 1 visits [254.0, 254.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 6037 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2789 2 visits [254.0, 254.0, 254.0, 253.0, 253.0, 253.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 6040 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2790 3 visits [254.0, 254.0, 254.0, 254.0, 253.0, 253.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 6040 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6046, "number_of_timesteps": 127144, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2791 4 visits [254.0, 254.0, 254.0, 254.0, 254.0, 253.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 6046 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2792 5 visits [254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 6047 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2793 6 visits [254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 253.0, 500.0, 253.0]  episode_count: 6048 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2794 7 visits [254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 500.0, 253.0]  episode_count: 6051 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2795 9 visits [254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 6052 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2796 0 visits [255.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 6052 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2797 1 visits [255.0, 255.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 6054 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6057, "number_of_timesteps": 127348, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2798 2 visits [255.0, 255.0, 255.0, 254.0, 254.0, 254.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 6057 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2799 3 visits [255.0, 255.0, 255.0, 255.0, 254.0, 254.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 6060 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2800 4 visits [255.0, 255.0, 255.0, 255.0, 255.0, 254.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 6064 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2801 5 visits [255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 6066 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6067, "number_of_timesteps": 127584, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2802 6 visits [255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 254.0, 500.0, 254.0]  episode_count: 6067 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2803 7 visits [255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 500.0, 254.0]  episode_count: 6069 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2804 9 visits [255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 6070 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2805 0 visits [256.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 6071 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2806 1 visits [256.0, 256.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 6076 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6077, "number_of_timesteps": 127800, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2807 2 visits [256.0, 256.0, 256.0, 255.0, 255.0, 255.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 6077 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2808 3 visits [256.0, 256.0, 256.0, 256.0, 255.0, 255.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 6078 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2809 4 visits [256.0, 256.0, 256.0, 256.0, 256.0, 255.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 6079 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2810 5 visits [256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 6080 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2811 6 visits [256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 255.0, 500.0, 255.0]  episode_count: 6083 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2812 7 visits [256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 500.0, 255.0]  episode_count: 6085 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6087, "number_of_timesteps": 128053, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2813 9 visits [256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 6087 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2814 0 visits [257.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 6088 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2815 1 visits [257.0, 257.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 6092 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2816 2 visits [257.0, 257.0, 257.0, 256.0, 256.0, 256.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 6095 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6098, "number_of_timesteps": 128298, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2817 3 visits [257.0, 257.0, 257.0, 257.0, 256.0, 256.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 6098 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2818 4 visits [257.0, 257.0, 257.0, 257.0, 257.0, 256.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 6099 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2819 5 visits [257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 6104 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2820 6 visits [257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 256.0, 500.0, 256.0]  episode_count: 6105 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6108, "number_of_timesteps": 128502, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2821 7 visits [257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 500.0, 256.0]  episode_count: 6108 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2822 9 visits [257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 6109 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2823 0 visits [258.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 6112 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2824 1 visits [258.0, 258.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 6114 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6120, "number_of_timesteps": 128745, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2825 2 visits [258.0, 258.0, 258.0, 257.0, 257.0, 257.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 6120 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2826 3 visits [258.0, 258.0, 258.0, 258.0, 257.0, 257.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 6120 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2827 4 visits [258.0, 258.0, 258.0, 258.0, 258.0, 257.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 6121 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2828 5 visits [258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 6126 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2829 6 visits [258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 257.0, 500.0, 257.0]  episode_count: 6128 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2830 7 visits [258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 500.0, 257.0]  episode_count: 6129 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6132, "number_of_timesteps": 128944, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2831 9 visits [258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 6132 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2832 0 visits [259.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 6133 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2833 1 visits [259.0, 259.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 6137 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2834 2 visits [259.0, 259.0, 259.0, 258.0, 258.0, 258.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 6138 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2835 3 visits [259.0, 259.0, 259.0, 259.0, 258.0, 258.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 6140 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6144, "number_of_timesteps": 129190, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2836 4 visits [259.0, 259.0, 259.0, 259.0, 259.0, 258.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 6144 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2837 5 visits [259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 6144 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2838 6 visits [259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 258.0, 500.0, 258.0]  episode_count: 6148 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2839 7 visits [259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 500.0, 258.0]  episode_count: 6149 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2840 9 visits [259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 6151 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2841 0 visits [260.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 6151 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2842 1 visits [260.0, 260.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 6153 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6156, "number_of_timesteps": 129480, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2843 2 visits [260.0, 260.0, 260.0, 259.0, 259.0, 259.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 6156 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2844 3 visits [260.0, 260.0, 260.0, 260.0, 259.0, 259.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 6161 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2845 4 visits [260.0, 260.0, 260.0, 260.0, 260.0, 259.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 6161 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2846 5 visits [260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 6162 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2847 6 visits [260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 259.0, 500.0, 259.0]  episode_count: 6164 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2848 7 visits [260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 500.0, 259.0]  episode_count: 6164 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6167, "number_of_timesteps": 129716, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2849 9 visits [260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 6167 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2850 0 visits [261.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 6169 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2851 1 visits [261.0, 261.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 6172 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2852 2 visits [261.0, 261.0, 261.0, 260.0, 260.0, 260.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 6175 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2853 3 visits [261.0, 261.0, 261.0, 261.0, 260.0, 260.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 6176 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6178, "number_of_timesteps": 130006, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2854 4 visits [261.0, 261.0, 261.0, 261.0, 261.0, 260.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 6178 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2855 5 visits [261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 6181 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2856 6 visits [261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 260.0, 500.0, 260.0]  episode_count: 6182 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2857 7 visits [261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 500.0, 260.0]  episode_count: 6184 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2858 9 visits [261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 6186 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2859 0 visits [262.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 6187 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6192, "number_of_timesteps": 130291, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2860 1 visits [262.0, 262.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 6192 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2861 2 visits [262.0, 262.0, 262.0, 261.0, 261.0, 261.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 6193 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2862 3 visits [262.0, 262.0, 262.0, 262.0, 261.0, 261.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 6196 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2863 4 visits [262.0, 262.0, 262.0, 262.0, 262.0, 261.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 6198 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2864 5 visits [262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 6199 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6204, "number_of_timesteps": 130528, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2865 6 visits [262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 261.0, 500.0, 261.0]  episode_count: 6204 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2866 7 visits [262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 500.0, 261.0]  episode_count: 6207 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2867 9 visits [262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 6208 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2868 0 visits [263.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 6210 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2869 1 visits [263.0, 263.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 6212 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6215, "number_of_timesteps": 130739, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2870 2 visits [263.0, 263.0, 263.0, 262.0, 262.0, 262.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 6215 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2871 3 visits [263.0, 263.0, 263.0, 263.0, 262.0, 262.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 6216 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2872 4 visits [263.0, 263.0, 263.0, 263.0, 263.0, 262.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 6218 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2873 5 visits [263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 6221 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2874 6 visits [263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 262.0, 500.0, 262.0]  episode_count: 6224 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6226, "number_of_timesteps": 130960, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2875 7 visits [263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 500.0, 262.0]  episode_count: 6226 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2876 9 visits [263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 6228 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2877 0 visits [264.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 6230 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2878 1 visits [264.0, 264.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 6232 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2879 2 visits [264.0, 264.0, 264.0, 263.0, 263.0, 263.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 6235 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6237, "number_of_timesteps": 131203, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2880 3 visits [264.0, 264.0, 264.0, 264.0, 263.0, 263.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 6237 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2881 4 visits [264.0, 264.0, 264.0, 264.0, 264.0, 263.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 6239 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2882 5 visits [264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 6241 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2883 6 visits [264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 263.0, 500.0, 263.0]  episode_count: 6244 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6247, "number_of_timesteps": 131407, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2884 7 visits [264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 500.0, 263.0]  episode_count: 6247 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2885 9 visits [264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 6249 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2886 0 visits [265.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 6249 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2887 1 visits [265.0, 265.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 6253 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2888 2 visits [265.0, 265.0, 265.0, 264.0, 264.0, 264.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 6254 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6257, "number_of_timesteps": 131593, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2889 3 visits [265.0, 265.0, 265.0, 265.0, 264.0, 264.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 6257 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2890 4 visits [265.0, 265.0, 265.0, 265.0, 265.0, 264.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 6259 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2891 5 visits [265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 6263 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2892 6 visits [265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 264.0, 500.0, 264.0]  episode_count: 6265 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6267, "number_of_timesteps": 131761, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2893 7 visits [265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 500.0, 264.0]  episode_count: 6267 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2894 9 visits [265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 6271 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2895 0 visits [266.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 6275 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2896 1 visits [266.0, 266.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 6275 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6278, "number_of_timesteps": 131977, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2897 2 visits [266.0, 266.0, 266.0, 265.0, 265.0, 265.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 6278 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2898 3 visits [266.0, 266.0, 266.0, 266.0, 265.0, 265.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 6281 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2899 4 visits [266.0, 266.0, 266.0, 266.0, 266.0, 265.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 6283 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2900 5 visits [266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 6283 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2901 6 visits [266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 265.0, 500.0, 265.0]  episode_count: 6286 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6288, "number_of_timesteps": 132158, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2902 7 visits [266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 500.0, 265.0]  episode_count: 6288 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2903 9 visits [266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 6290 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2904 0 visits [267.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 6293 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2905 1 visits [267.0, 267.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 6294 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2906 2 visits [267.0, 267.0, 267.0, 266.0, 266.0, 266.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 6295 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2907 3 visits [267.0, 267.0, 267.0, 267.0, 266.0, 266.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 6297 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6301, "number_of_timesteps": 132458, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2908 4 visits [267.0, 267.0, 267.0, 267.0, 267.0, 266.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 6301 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2909 5 visits [267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 6303 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2910 6 visits [267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 266.0, 500.0, 266.0]  episode_count: 6304 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2911 7 visits [267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 500.0, 266.0]  episode_count: 6308 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6312, "number_of_timesteps": 132690, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2912 9 visits [267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 6312 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2913 0 visits [268.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 6313 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2914 1 visits [268.0, 268.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 6316 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2915 2 visits [268.0, 268.0, 268.0, 267.0, 267.0, 267.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 6320 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6323, "number_of_timesteps": 132848, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2916 3 visits [268.0, 268.0, 268.0, 268.0, 267.0, 267.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 6323 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2917 4 visits [268.0, 268.0, 268.0, 268.0, 268.0, 267.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 6325 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2918 5 visits [268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 6326 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2919 6 visits [268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 267.0, 500.0, 267.0]  episode_count: 6327 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2920 7 visits [268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 500.0, 267.0]  episode_count: 6330 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6333, "number_of_timesteps": 133037, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2921 9 visits [268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 6333 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2922 0 visits [269.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 6336 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2923 1 visits [269.0, 269.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 6337 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2924 2 visits [269.0, 269.0, 269.0, 268.0, 268.0, 268.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 6338 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2925 3 visits [269.0, 269.0, 269.0, 269.0, 268.0, 268.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 6342 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6344, "number_of_timesteps": 133247, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2926 4 visits [269.0, 269.0, 269.0, 269.0, 269.0, 268.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 6344 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2927 5 visits [269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 6345 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2928 6 visits [269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 268.0, 500.0, 268.0]  episode_count: 6347 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2929 7 visits [269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 500.0, 268.0]  episode_count: 6350 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2930 9 visits [269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 6353 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6354, "number_of_timesteps": 133480, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2931 0 visits [270.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 6354 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2932 1 visits [270.0, 270.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 6356 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2933 2 visits [270.0, 270.0, 270.0, 269.0, 269.0, 269.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 6360 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2934 3 visits [270.0, 270.0, 270.0, 270.0, 269.0, 269.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 6361 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2935 4 visits [270.0, 270.0, 270.0, 270.0, 270.0, 269.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 6363 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6365, "number_of_timesteps": 133684, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2936 5 visits [270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 6365 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2937 6 visits [270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 269.0, 500.0, 269.0]  episode_count: 6369 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2938 7 visits [270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 500.0, 269.0]  episode_count: 6371 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2939 9 visits [270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 6371 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6375, "number_of_timesteps": 133908, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2940 0 visits [271.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 6375 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2941 1 visits [271.0, 271.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 6377 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2942 2 visits [271.0, 271.0, 271.0, 270.0, 270.0, 270.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 6378 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2943 3 visits [271.0, 271.0, 271.0, 271.0, 270.0, 270.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 6380 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2944 4 visits [271.0, 271.0, 271.0, 271.0, 271.0, 270.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 6382 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2945 5 visits [271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 6382 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6385, "number_of_timesteps": 134139, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 2946 6 visits [271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 270.0, 500.0, 270.0]  episode_count: 6385 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2947 7 visits [271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 500.0, 270.0]  episode_count: 6388 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2948 9 visits [271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 6388 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2949 0 visits [272.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 6388 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2950 1 visits [272.0, 272.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 6390 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2951 2 visits [272.0, 272.0, 272.0, 271.0, 271.0, 271.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 6391 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2952 3 visits [272.0, 272.0, 272.0, 272.0, 271.0, 271.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 6393 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6395, "number_of_timesteps": 134376, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2953 4 visits [272.0, 272.0, 272.0, 272.0, 272.0, 271.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 6395 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2954 5 visits [272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 6396 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2955 6 visits [272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 271.0, 500.0, 271.0]  episode_count: 6399 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2956 7 visits [272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 500.0, 271.0]  episode_count: 6401 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2957 9 visits [272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 6403 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6407, "number_of_timesteps": 134776, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2958 0 visits [273.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 6407 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2959 1 visits [273.0, 273.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 6410 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2960 2 visits [273.0, 273.0, 273.0, 272.0, 272.0, 272.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 6412 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2961 3 visits [273.0, 273.0, 273.0, 273.0, 272.0, 272.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 6413 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6417, "number_of_timesteps": 134936, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2962 4 visits [273.0, 273.0, 273.0, 273.0, 273.0, 272.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 6417 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2963 5 visits [273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 6420 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2964 6 visits [273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 272.0, 500.0, 272.0]  episode_count: 6424 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2965 7 visits [273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 500.0, 272.0]  episode_count: 6425 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6429, "number_of_timesteps": 135131, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2966 9 visits [273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 6429 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2967 0 visits [274.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 6430 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2968 1 visits [274.0, 274.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 6431 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2969 2 visits [274.0, 274.0, 274.0, 273.0, 273.0, 273.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 6433 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2970 3 visits [274.0, 274.0, 274.0, 274.0, 273.0, 273.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 6434 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2971 4 visits [274.0, 274.0, 274.0, 274.0, 274.0, 273.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 6437 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6439, "number_of_timesteps": 135340, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2972 5 visits [274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 6439 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2973 6 visits [274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 273.0, 500.0, 273.0]  episode_count: 6442 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2974 7 visits [274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 500.0, 273.0]  episode_count: 6444 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2975 9 visits [274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 6448 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6451, "number_of_timesteps": 135596, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 2976 0 visits [275.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 6451 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2977 1 visits [275.0, 275.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 6452 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2978 2 visits [275.0, 275.0, 275.0, 274.0, 274.0, 274.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 6454 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2979 3 visits [275.0, 275.0, 275.0, 275.0, 274.0, 274.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 6457 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2980 4 visits [275.0, 275.0, 275.0, 275.0, 275.0, 274.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 6457 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2981 5 visits [275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 6459 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6462, "number_of_timesteps": 135798, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2982 6 visits [275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 274.0, 500.0, 274.0]  episode_count: 6462 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2983 7 visits [275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 500.0, 274.0]  episode_count: 6463 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2984 9 visits [275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 6464 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2985 0 visits [276.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 6467 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2986 1 visits [276.0, 276.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 6470 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2987 2 visits [276.0, 276.0, 276.0, 275.0, 275.0, 275.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 6471 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6473, "number_of_timesteps": 136086, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 2988 3 visits [276.0, 276.0, 276.0, 276.0, 275.0, 275.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 6473 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2989 4 visits [276.0, 276.0, 276.0, 276.0, 276.0, 275.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 6476 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2990 5 visits [276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 6477 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2991 6 visits [276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 275.0, 500.0, 275.0]  episode_count: 6479 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6483, "number_of_timesteps": 136296, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 2992 7 visits [276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 500.0, 275.0]  episode_count: 6483 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2993 9 visits [276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 6483 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2994 0 visits [277.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 6484 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2995 1 visits [277.0, 277.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 6488 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2996 2 visits [277.0, 277.0, 277.0, 276.0, 276.0, 276.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 6490 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6493, "number_of_timesteps": 136553, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 2997 3 visits [277.0, 277.0, 277.0, 277.0, 276.0, 276.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 6493 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2998 4 visits [277.0, 277.0, 277.0, 277.0, 277.0, 276.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 6495 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 2999 5 visits [277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 6497 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3000 6 visits [277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 276.0, 500.0, 276.0]  episode_count: 6498 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3001 7 visits [277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 500.0, 276.0]  episode_count: 6501 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6506, "number_of_timesteps": 136782, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3002 9 visits [277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 6506 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3003 0 visits [278.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 6507 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3004 1 visits [278.0, 278.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 6510 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3005 2 visits [278.0, 278.0, 278.0, 277.0, 277.0, 277.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 6515 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3006 3 visits [278.0, 278.0, 278.0, 278.0, 277.0, 277.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 6515 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6518, "number_of_timesteps": 136977, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3007 4 visits [278.0, 278.0, 278.0, 278.0, 278.0, 277.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 6518 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3008 5 visits [278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 6521 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3009 6 visits [278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 277.0, 500.0, 277.0]  episode_count: 6521 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3010 7 visits [278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 500.0, 277.0]  episode_count: 6524 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3011 9 visits [278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 6527 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6529, "number_of_timesteps": 137197, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3012 0 visits [279.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 6529 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3013 1 visits [279.0, 279.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 6532 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3014 2 visits [279.0, 279.0, 279.0, 278.0, 278.0, 278.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 6535 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3015 3 visits [279.0, 279.0, 279.0, 279.0, 278.0, 278.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 6535 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3016 4 visits [279.0, 279.0, 279.0, 279.0, 279.0, 278.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 6537 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6540, "number_of_timesteps": 137377, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3017 5 visits [279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 6540 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3018 6 visits [279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 278.0, 500.0, 278.0]  episode_count: 6542 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3019 7 visits [279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 500.0, 278.0]  episode_count: 6544 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3020 9 visits [279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 6546 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3021 0 visits [280.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 6549 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6550, "number_of_timesteps": 137604, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3022 1 visits [280.0, 280.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 6550 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3023 2 visits [280.0, 280.0, 280.0, 279.0, 279.0, 279.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 6553 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3024 3 visits [280.0, 280.0, 280.0, 280.0, 279.0, 279.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 6555 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3025 4 visits [280.0, 280.0, 280.0, 280.0, 280.0, 279.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 6558 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3026 5 visits [280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 6558 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6562, "number_of_timesteps": 137847, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3027 6 visits [280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 279.0, 500.0, 279.0]  episode_count: 6562 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3028 7 visits [280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 500.0, 279.0]  episode_count: 6564 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3029 9 visits [280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 6566 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3030 0 visits [281.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 6566 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3031 1 visits [281.0, 281.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 6570 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6574, "number_of_timesteps": 138109, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3032 2 visits [281.0, 281.0, 281.0, 280.0, 280.0, 280.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 6574 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3033 3 visits [281.0, 281.0, 281.0, 281.0, 280.0, 280.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 6575 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3034 4 visits [281.0, 281.0, 281.0, 281.0, 281.0, 280.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 6579 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3035 5 visits [281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 6579 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3036 6 visits [281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 280.0, 500.0, 280.0]  episode_count: 6581 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3037 7 visits [281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 500.0, 280.0]  episode_count: 6583 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6585, "number_of_timesteps": 138326, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3038 9 visits [281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 6585 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3039 0 visits [282.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 6587 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3040 1 visits [282.0, 282.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 6589 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3041 2 visits [282.0, 282.0, 282.0, 281.0, 281.0, 281.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 6589 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3042 3 visits [282.0, 282.0, 282.0, 282.0, 281.0, 281.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 6591 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3043 4 visits [282.0, 282.0, 282.0, 282.0, 282.0, 281.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 6593 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6595, "number_of_timesteps": 138584, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3044 5 visits [282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 6595 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3045 6 visits [282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 281.0, 500.0, 281.0]  episode_count: 6596 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3046 7 visits [282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 500.0, 281.0]  episode_count: 6599 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3047 9 visits [282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 6601 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6607, "number_of_timesteps": 138876, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3048 0 visits [283.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 6607 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3049 1 visits [283.0, 283.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 6608 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3050 2 visits [283.0, 283.0, 283.0, 282.0, 282.0, 282.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 6611 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3051 3 visits [283.0, 283.0, 283.0, 283.0, 282.0, 282.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 6613 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3052 4 visits [283.0, 283.0, 283.0, 283.0, 283.0, 282.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 6613 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6617, "number_of_timesteps": 139039, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3053 5 visits [283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 6617 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3054 6 visits [283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 282.0, 500.0, 282.0]  episode_count: 6617 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3055 7 visits [283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 500.0, 282.0]  episode_count: 6619 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3056 9 visits [283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 6624 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3057 0 visits [284.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 6625 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3058 1 visits [284.0, 284.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 6625 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6629, "number_of_timesteps": 139303, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3059 2 visits [284.0, 284.0, 284.0, 283.0, 283.0, 283.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 6629 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3060 3 visits [284.0, 284.0, 284.0, 284.0, 283.0, 283.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 6632 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3061 4 visits [284.0, 284.0, 284.0, 284.0, 284.0, 283.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 6633 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3062 5 visits [284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 6633 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3063 6 visits [284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 283.0, 500.0, 283.0]  episode_count: 6636 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6639, "number_of_timesteps": 139535, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3064 7 visits [284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 500.0, 283.0]  episode_count: 6639 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3065 9 visits [284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 6642 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3066 0 visits [285.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 6645 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3067 1 visits [285.0, 285.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 6645 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3068 2 visits [285.0, 285.0, 285.0, 284.0, 284.0, 284.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 6647 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3069 3 visits [285.0, 285.0, 285.0, 285.0, 284.0, 284.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 6648 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6653, "number_of_timesteps": 139821, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
Step 3070 4 visits [285.0, 285.0, 285.0, 285.0, 285.0, 284.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 6653 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3071 5 visits [285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 6654 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3072 6 visits [285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 284.0, 500.0, 284.0]  episode_count: 6655 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3073 7 visits [285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 500.0, 284.0]  episode_count: 6658 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3074 9 visits [285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 6660 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3075 0 visits [286.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 6662 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6665, "number_of_timesteps": 140087, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
Step 3076 1 visits [286.0, 286.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 6665 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3077 2 visits [286.0, 286.0, 286.0, 285.0, 285.0, 285.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 6668 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3078 3 visits [286.0, 286.0, 286.0, 286.0, 285.0, 285.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 6669 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3079 4 visits [286.0, 286.0, 286.0, 286.0, 286.0, 285.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 6671 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6675, "number_of_timesteps": 140299, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 3080 5 visits [286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 6675 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3081 6 visits [286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 285.0, 500.0, 285.0]  episode_count: 6678 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3082 7 visits [286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 500.0, 285.0]  episode_count: 6678 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3083 9 visits [286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 6682 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6686, "number_of_timesteps": 140520, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
Step 3084 0 visits [287.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 6686 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3085 1 visits [287.0, 287.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 6687 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3086 2 visits [287.0, 287.0, 287.0, 286.0, 286.0, 286.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 6691 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3087 3 visits [287.0, 287.0, 287.0, 287.0, 286.0, 286.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 6694 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3088 4 visits [287.0, 287.0, 287.0, 287.0, 287.0, 286.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 6695 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6698, "number_of_timesteps": 140688, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3089 5 visits [287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 6698 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3090 6 visits [287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 286.0, 500.0, 286.0]  episode_count: 6698 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3091 7 visits [287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 500.0, 286.0]  episode_count: 6701 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3092 9 visits [287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 6703 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3093 0 visits [288.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 6704 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3094 1 visits [288.0, 288.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 6707 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6710, "number_of_timesteps": 140952, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3095 2 visits [288.0, 288.0, 288.0, 287.0, 287.0, 287.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 6710 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3096 3 visits [288.0, 288.0, 288.0, 288.0, 287.0, 287.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 6712 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3097 4 visits [288.0, 288.0, 288.0, 288.0, 288.0, 287.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 6714 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3098 5 visits [288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 6717 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6720, "number_of_timesteps": 141177, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3099 6 visits [288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 287.0, 500.0, 287.0]  episode_count: 6720 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3100 7 visits [288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 500.0, 287.0]  episode_count: 6722 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3101 9 visits [288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 6725 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3102 0 visits [289.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 6728 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3103 1 visits [289.0, 289.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 6728 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3104 2 visits [289.0, 289.0, 289.0, 288.0, 288.0, 288.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 6729 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6733, "number_of_timesteps": 141383, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3105 3 visits [289.0, 289.0, 289.0, 289.0, 288.0, 288.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 6733 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3106 4 visits [289.0, 289.0, 289.0, 289.0, 289.0, 288.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 6737 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3107 5 visits [289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 6738 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3108 6 visits [289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 288.0, 500.0, 288.0]  episode_count: 6740 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6744, "number_of_timesteps": 141626, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3109 7 visits [289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 500.0, 288.0]  episode_count: 6744 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3110 9 visits [289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 6745 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3111 0 visits [290.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 6747 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3112 1 visits [290.0, 290.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 6751 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3113 2 visits [290.0, 290.0, 290.0, 289.0, 289.0, 289.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 6753 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6757, "number_of_timesteps": 141876, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
Step 3114 3 visits [290.0, 290.0, 290.0, 290.0, 289.0, 289.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 6757 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3115 4 visits [290.0, 290.0, 290.0, 290.0, 290.0, 289.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 6757 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3116 5 visits [290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 6762 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3117 6 visits [290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 289.0, 500.0, 289.0]  episode_count: 6763 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3118 7 visits [290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 500.0, 289.0]  episode_count: 6766 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6767, "number_of_timesteps": 142035, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0027777777777777584, "biggest_recent_change": 0.09999999999999964},
Step 3119 9 visits [290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 6767 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3120 0 visits [291.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 6770 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3121 1 visits [291.0, 291.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 6773 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3122 2 visits [291.0, 291.0, 291.0, 290.0, 290.0, 290.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 6775 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3123 3 visits [291.0, 291.0, 291.0, 291.0, 290.0, 290.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 6776 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6779, "number_of_timesteps": 142289, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
Step 3124 4 visits [291.0, 291.0, 291.0, 291.0, 291.0, 290.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 6779 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3125 5 visits [291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 6781 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3126 6 visits [291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 290.0, 500.0, 290.0]  episode_count: 6785 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3127 7 visits [291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 500.0, 290.0]  episode_count: 6787 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3128 9 visits [291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 6788 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6789, "number_of_timesteps": 142448, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0027777777777777584, "biggest_recent_change": 0.09999999999999964},
Step 3129 0 visits [292.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 6789 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3130 1 visits [292.0, 292.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 6792 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3131 2 visits [292.0, 292.0, 292.0, 291.0, 291.0, 291.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 6794 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3132 3 visits [292.0, 292.0, 292.0, 292.0, 291.0, 291.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 6797 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3133 4 visits [292.0, 292.0, 292.0, 292.0, 292.0, 291.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 6798 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6801, "number_of_timesteps": 142747, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 3134 5 visits [292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 6801 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3135 6 visits [292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 291.0, 500.0, 291.0]  episode_count: 6803 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3136 7 visits [292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 500.0, 291.0]  episode_count: 6804 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3137 9 visits [292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 6807 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3138 0 visits [293.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 6808 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3139 1 visits [293.0, 293.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 6809 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6812, "number_of_timesteps": 142994, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 3140 2 visits [293.0, 293.0, 293.0, 292.0, 292.0, 292.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 6812 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3141 3 visits [293.0, 293.0, 293.0, 293.0, 292.0, 292.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 6816 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3142 4 visits [293.0, 293.0, 293.0, 293.0, 293.0, 292.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 6817 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3143 5 visits [293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 6819 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6822, "number_of_timesteps": 143205, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 3144 6 visits [293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 292.0, 500.0, 292.0]  episode_count: 6822 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3145 7 visits [293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 500.0, 292.0]  episode_count: 6824 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3146 9 visits [293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 6824 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3147 0 visits [294.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 6828 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3148 1 visits [294.0, 294.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 6831 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3149 2 visits [294.0, 294.0, 294.0, 293.0, 293.0, 293.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 6831 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6834, "number_of_timesteps": 143413, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 3150 3 visits [294.0, 294.0, 294.0, 294.0, 293.0, 293.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 6834 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3151 4 visits [294.0, 294.0, 294.0, 294.0, 294.0, 293.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 6836 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3152 5 visits [294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 6838 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3153 6 visits [294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 293.0, 500.0, 293.0]  episode_count: 6839 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3154 7 visits [294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 500.0, 293.0]  episode_count: 6843 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6844, "number_of_timesteps": 143687, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3155 9 visits [294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 6844 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3156 0 visits [295.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 6848 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3157 1 visits [295.0, 295.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 6851 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3158 2 visits [295.0, 295.0, 295.0, 294.0, 294.0, 294.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 6852 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6855, "number_of_timesteps": 143891, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3159 3 visits [295.0, 295.0, 295.0, 295.0, 294.0, 294.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 6855 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3160 4 visits [295.0, 295.0, 295.0, 295.0, 295.0, 294.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 6856 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3161 5 visits [295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 6857 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3162 6 visits [295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 294.0, 500.0, 294.0]  episode_count: 6860 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3163 7 visits [295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 500.0, 294.0]  episode_count: 6863 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3164 9 visits [295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 6864 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6868, "number_of_timesteps": 144153, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3165 0 visits [296.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 6868 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3166 1 visits [296.0, 296.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 6870 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3167 2 visits [296.0, 296.0, 296.0, 295.0, 295.0, 295.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 6872 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3168 3 visits [296.0, 296.0, 296.0, 296.0, 295.0, 295.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 6874 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3169 4 visits [296.0, 296.0, 296.0, 296.0, 296.0, 295.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 6877 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6880, "number_of_timesteps": 144379, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3170 5 visits [296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 6880 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3171 6 visits [296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 295.0, 500.0, 295.0]  episode_count: 6881 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3172 7 visits [296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 500.0, 295.0]  episode_count: 6884 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3173 9 visits [296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 6886 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3174 0 visits [297.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 6889 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6892, "number_of_timesteps": 144629, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3175 1 visits [297.0, 297.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 6892 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3176 2 visits [297.0, 297.0, 297.0, 296.0, 296.0, 296.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 6894 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3177 3 visits [297.0, 297.0, 297.0, 297.0, 296.0, 296.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 6894 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3178 4 visits [297.0, 297.0, 297.0, 297.0, 297.0, 296.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 6897 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3179 5 visits [297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 6901 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6902, "number_of_timesteps": 144815, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3180 6 visits [297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 296.0, 500.0, 296.0]  episode_count: 6902 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3181 7 visits [297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 500.0, 296.0]  episode_count: 6903 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3182 9 visits [297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 6907 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3183 0 visits [298.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 6909 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3184 1 visits [298.0, 298.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 6911 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6915, "number_of_timesteps": 145106, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3185 2 visits [298.0, 298.0, 298.0, 297.0, 297.0, 297.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 6915 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3186 3 visits [298.0, 298.0, 298.0, 298.0, 297.0, 297.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 6916 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3187 4 visits [298.0, 298.0, 298.0, 298.0, 298.0, 297.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 6920 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3188 5 visits [298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 6922 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3189 6 visits [298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 297.0, 500.0, 297.0]  episode_count: 6923 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6927, "number_of_timesteps": 145302, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3190 7 visits [298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 500.0, 297.0]  episode_count: 6927 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3191 9 visits [298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 6929 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3192 0 visits [299.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 6930 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3193 1 visits [299.0, 299.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 6933 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3194 2 visits [299.0, 299.0, 299.0, 298.0, 298.0, 298.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 6933 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6938, "number_of_timesteps": 145512, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3195 3 visits [299.0, 299.0, 299.0, 299.0, 298.0, 298.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 6938 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3196 4 visits [299.0, 299.0, 299.0, 299.0, 299.0, 298.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 6938 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3197 5 visits [299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 6939 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3198 6 visits [299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 298.0, 500.0, 298.0]  episode_count: 6942 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3199 7 visits [299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 500.0, 298.0]  episode_count: 6945 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3200 9 visits [299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 6946 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3201 0 visits [300.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 6947 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3202 1 visits [300.0, 300.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 6947 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6950, "number_of_timesteps": 145815, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3203 2 visits [300.0, 300.0, 300.0, 299.0, 299.0, 299.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 6950 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3204 3 visits [300.0, 300.0, 300.0, 300.0, 299.0, 299.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 6953 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3205 4 visits [300.0, 300.0, 300.0, 300.0, 300.0, 299.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 6953 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3206 5 visits [300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 6955 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3207 6 visits [300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 299.0, 500.0, 299.0]  episode_count: 6958 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6960, "number_of_timesteps": 146111, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3208 7 visits [300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 500.0, 299.0]  episode_count: 6960 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3209 9 visits [300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 6961 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3210 0 visits [301.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 6965 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3211 1 visits [301.0, 301.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 6968 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3212 2 visits [301.0, 301.0, 301.0, 300.0, 300.0, 300.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 6968 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6970, "number_of_timesteps": 146339, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3213 3 visits [301.0, 301.0, 301.0, 301.0, 300.0, 300.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 6970 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3214 4 visits [301.0, 301.0, 301.0, 301.0, 301.0, 300.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 6971 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3215 5 visits [301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 6975 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3216 6 visits [301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 300.0, 500.0, 300.0]  episode_count: 6977 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3217 7 visits [301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 500.0, 300.0]  episode_count: 6979 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6981, "number_of_timesteps": 146572, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3218 9 visits [301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 6981 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3219 0 visits [302.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 6983 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3220 1 visits [302.0, 302.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 6984 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3221 2 visits [302.0, 302.0, 302.0, 301.0, 301.0, 301.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 6985 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3222 3 visits [302.0, 302.0, 302.0, 302.0, 301.0, 301.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 6987 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3223 4 visits [302.0, 302.0, 302.0, 302.0, 302.0, 301.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 6988 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 6992, "number_of_timesteps": 146860, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3224 5 visits [302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 6992 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3225 6 visits [302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 301.0, 500.0, 301.0]  episode_count: 6995 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3226 7 visits [302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 500.0, 301.0]  episode_count: 6996 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3227 9 visits [302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 6999 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7002, "number_of_timesteps": 147079, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3228 0 visits [303.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 7002 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3229 1 visits [303.0, 303.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 7005 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3230 2 visits [303.0, 303.0, 303.0, 302.0, 302.0, 302.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 7006 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3231 3 visits [303.0, 303.0, 303.0, 303.0, 302.0, 302.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 7007 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3232 4 visits [303.0, 303.0, 303.0, 303.0, 303.0, 302.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 7008 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3233 5 visits [303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 7009 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7013, "number_of_timesteps": 147290, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3234 6 visits [303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 302.0, 500.0, 302.0]  episode_count: 7013 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3235 7 visits [303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 500.0, 302.0]  episode_count: 7014 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3236 9 visits [303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 7015 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3237 0 visits [304.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 7018 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3238 1 visits [304.0, 304.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 7021 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7023, "number_of_timesteps": 147572, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3239 2 visits [304.0, 304.0, 304.0, 303.0, 303.0, 303.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 7023 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3240 3 visits [304.0, 304.0, 304.0, 304.0, 303.0, 303.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 7024 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3241 4 visits [304.0, 304.0, 304.0, 304.0, 304.0, 303.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 7025 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3242 5 visits [304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 7026 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3243 6 visits [304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 303.0, 500.0, 303.0]  episode_count: 7027 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3244 7 visits [304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 500.0, 303.0]  episode_count: 7030 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3245 9 visits [304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 7032 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7034, "number_of_timesteps": 147886, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3246 0 visits [305.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 7034 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3247 1 visits [305.0, 305.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 7038 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3248 2 visits [305.0, 305.0, 305.0, 304.0, 304.0, 304.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 7038 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3249 3 visits [305.0, 305.0, 305.0, 305.0, 304.0, 304.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 7040 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7045, "number_of_timesteps": 148091, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3250 4 visits [305.0, 305.0, 305.0, 305.0, 305.0, 304.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 7045 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3251 5 visits [305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 7047 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3252 6 visits [305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 304.0, 500.0, 304.0]  episode_count: 7047 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3253 7 visits [305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 500.0, 304.0]  episode_count: 7048 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3254 9 visits [305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 7050 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3255 0 visits [306.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 7052 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7056, "number_of_timesteps": 148342, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3256 1 visits [306.0, 306.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 7056 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3257 2 visits [306.0, 306.0, 306.0, 305.0, 305.0, 305.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 7056 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3258 3 visits [306.0, 306.0, 306.0, 306.0, 305.0, 305.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 7058 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3259 4 visits [306.0, 306.0, 306.0, 306.0, 306.0, 305.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 7060 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3260 5 visits [306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 7062 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3261 6 visits [306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 305.0, 500.0, 305.0]  episode_count: 7064 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7068, "number_of_timesteps": 148564, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3262 7 visits [306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 500.0, 305.0]  episode_count: 7068 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3263 9 visits [306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 7068 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3264 0 visits [307.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 7069 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3265 1 visits [307.0, 307.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 7071 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3266 2 visits [307.0, 307.0, 307.0, 306.0, 306.0, 306.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 7074 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3267 3 visits [307.0, 307.0, 307.0, 307.0, 306.0, 306.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 7076 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7079, "number_of_timesteps": 148912, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3268 4 visits [307.0, 307.0, 307.0, 307.0, 307.0, 306.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 7079 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3269 5 visits [307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 7080 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3270 6 visits [307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 306.0, 500.0, 306.0]  episode_count: 7082 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3271 7 visits [307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 500.0, 306.0]  episode_count: 7084 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3272 9 visits [307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 7087 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7090, "number_of_timesteps": 149150, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 3273 0 visits [308.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 7090 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3274 1 visits [308.0, 308.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 7092 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3275 2 visits [308.0, 308.0, 308.0, 307.0, 307.0, 307.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 7092 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3276 3 visits [308.0, 308.0, 308.0, 308.0, 307.0, 307.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 7099 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3277 4 visits [308.0, 308.0, 308.0, 308.0, 308.0, 307.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 7099 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3278 5 visits [308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 7099 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7101, "number_of_timesteps": 149341, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3279 6 visits [308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 307.0, 500.0, 307.0]  episode_count: 7101 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3280 7 visits [308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 500.0, 307.0]  episode_count: 7105 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3281 9 visits [308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 7108 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3282 0 visits [309.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 7110 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7111, "number_of_timesteps": 149565, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3283 1 visits [309.0, 309.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 7111 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3284 2 visits [309.0, 309.0, 309.0, 308.0, 308.0, 308.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 7114 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3285 3 visits [309.0, 309.0, 309.0, 309.0, 308.0, 308.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 7117 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3286 4 visits [309.0, 309.0, 309.0, 309.0, 309.0, 308.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 7119 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3287 5 visits [309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 7120 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7123, "number_of_timesteps": 149800, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3288 6 visits [309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 308.0, 500.0, 308.0]  episode_count: 7123 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3289 7 visits [309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 500.0, 308.0]  episode_count: 7124 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3290 9 visits [309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 7126 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3291 0 visits [310.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 7127 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3292 1 visits [310.0, 310.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 7130 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3293 2 visits [310.0, 310.0, 310.0, 309.0, 309.0, 309.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 7131 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3294 3 visits [310.0, 310.0, 310.0, 310.0, 309.0, 309.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 7131 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7133, "number_of_timesteps": 150051, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3295 4 visits [310.0, 310.0, 310.0, 310.0, 310.0, 309.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 7133 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3296 5 visits [310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 7135 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3297 6 visits [310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 309.0, 500.0, 309.0]  episode_count: 7135 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3298 7 visits [310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 500.0, 309.0]  episode_count: 7138 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3299 9 visits [310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 7141 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7143, "number_of_timesteps": 150360, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3300 0 visits [311.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 7143 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3301 1 visits [311.0, 311.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 7144 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3302 2 visits [311.0, 311.0, 311.0, 310.0, 310.0, 310.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 7146 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3303 3 visits [311.0, 311.0, 311.0, 311.0, 310.0, 310.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 7152 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7153, "number_of_timesteps": 150565, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3304 4 visits [311.0, 311.0, 311.0, 311.0, 311.0, 310.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 7153 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3305 5 visits [311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 7153 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3306 6 visits [311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 310.0, 500.0, 310.0]  episode_count: 7155 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3307 7 visits [311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 500.0, 310.0]  episode_count: 7156 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3308 9 visits [311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 7156 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3309 0 visits [312.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 7161 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3310 1 visits [312.0, 312.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 7162 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7164, "number_of_timesteps": 150801, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3311 2 visits [312.0, 312.0, 312.0, 311.0, 311.0, 311.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 7164 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3312 3 visits [312.0, 312.0, 312.0, 312.0, 311.0, 311.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 7166 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3313 4 visits [312.0, 312.0, 312.0, 312.0, 312.0, 311.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 7168 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3314 5 visits [312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 7170 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3315 6 visits [312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 311.0, 500.0, 311.0]  episode_count: 7173 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7174, "number_of_timesteps": 151086, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3316 7 visits [312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 500.0, 311.0]  episode_count: 7174 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3317 9 visits [312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 7177 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3318 0 visits [313.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 7180 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3319 1 visits [313.0, 313.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 7182 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7184, "number_of_timesteps": 151293, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3320 2 visits [313.0, 313.0, 313.0, 312.0, 312.0, 312.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 7184 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3321 3 visits [313.0, 313.0, 313.0, 313.0, 312.0, 312.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 7187 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3322 4 visits [313.0, 313.0, 313.0, 313.0, 313.0, 312.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 7189 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3323 5 visits [313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 7191 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3324 6 visits [313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 312.0, 500.0, 312.0]  episode_count: 7191 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3325 7 visits [313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 500.0, 312.0]  episode_count: 7193 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7195, "number_of_timesteps": 151481, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3326 9 visits [313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 7195 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3327 0 visits [314.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 7195 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3328 1 visits [314.0, 314.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 7198 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3329 2 visits [314.0, 314.0, 314.0, 313.0, 313.0, 313.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 7201 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3330 3 visits [314.0, 314.0, 314.0, 314.0, 313.0, 313.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 7204 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7208, "number_of_timesteps": 151839, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3331 4 visits [314.0, 314.0, 314.0, 314.0, 314.0, 313.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 7208 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3332 5 visits [314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 7210 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3333 6 visits [314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 313.0, 500.0, 313.0]  episode_count: 7210 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3334 7 visits [314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 500.0, 313.0]  episode_count: 7213 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3335 9 visits [314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 7214 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3336 0 visits [315.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 7217 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3337 1 visits [315.0, 315.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 7217 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7219, "number_of_timesteps": 152038, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3338 2 visits [315.0, 315.0, 315.0, 314.0, 314.0, 314.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 7219 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3339 3 visits [315.0, 315.0, 315.0, 315.0, 314.0, 314.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 7221 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3340 4 visits [315.0, 315.0, 315.0, 315.0, 315.0, 314.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 7224 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3341 5 visits [315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 7225 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3342 6 visits [315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 314.0, 500.0, 314.0]  episode_count: 7226 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3343 7 visits [315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 500.0, 314.0]  episode_count: 7228 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7229, "number_of_timesteps": 152302, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3344 9 visits [315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 7229 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3345 0 visits [316.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 7231 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3346 1 visits [316.0, 316.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 7232 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3347 2 visits [316.0, 316.0, 316.0, 315.0, 315.0, 315.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 7235 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3348 3 visits [316.0, 316.0, 316.0, 316.0, 315.0, 315.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 7236 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3349 4 visits [316.0, 316.0, 316.0, 316.0, 316.0, 315.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 7237 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7240, "number_of_timesteps": 152584, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3350 5 visits [316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 7240 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3351 6 visits [316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 315.0, 500.0, 315.0]  episode_count: 7242 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3352 7 visits [316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 500.0, 315.0]  episode_count: 7243 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3353 9 visits [316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 7246 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3354 0 visits [317.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 7247 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7250, "number_of_timesteps": 152883, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3355 1 visits [317.0, 317.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 7250 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3356 2 visits [317.0, 317.0, 317.0, 316.0, 316.0, 316.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 7251 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3357 3 visits [317.0, 317.0, 317.0, 317.0, 316.0, 316.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 7256 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3358 4 visits [317.0, 317.0, 317.0, 317.0, 317.0, 316.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 7259 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7261, "number_of_timesteps": 153081, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3359 5 visits [317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 7261 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3360 6 visits [317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 316.0, 500.0, 316.0]  episode_count: 7262 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3361 7 visits [317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 500.0, 316.0]  episode_count: 7264 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3362 9 visits [317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 7266 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3363 0 visits [318.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 7269 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7271, "number_of_timesteps": 153293, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3364 1 visits [318.0, 318.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 7271 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3365 2 visits [318.0, 318.0, 318.0, 317.0, 317.0, 317.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 7274 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3366 3 visits [318.0, 318.0, 318.0, 318.0, 317.0, 317.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 7277 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3367 4 visits [318.0, 318.0, 318.0, 318.0, 318.0, 317.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 7277 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3368 5 visits [318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 7278 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7282, "number_of_timesteps": 153511, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 3369 6 visits [318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 317.0, 500.0, 317.0]  episode_count: 7282 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3370 7 visits [318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 500.0, 317.0]  episode_count: 7282 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3371 9 visits [318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 7285 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3372 0 visits [319.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 7286 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3373 1 visits [319.0, 319.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 7289 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3374 2 visits [319.0, 319.0, 319.0, 318.0, 318.0, 318.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 7290 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7292, "number_of_timesteps": 153766, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 3375 3 visits [319.0, 319.0, 319.0, 319.0, 318.0, 318.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 7292 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3376 4 visits [319.0, 319.0, 319.0, 319.0, 319.0, 318.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 7294 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3377 5 visits [319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 7297 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3378 6 visits [319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 318.0, 500.0, 318.0]  episode_count: 7298 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3379 7 visits [319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 500.0, 318.0]  episode_count: 7299 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7302, "number_of_timesteps": 153986, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 3380 9 visits [319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 7302 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3381 0 visits [320.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 7302 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3382 1 visits [320.0, 320.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 7306 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3383 2 visits [320.0, 320.0, 320.0, 319.0, 319.0, 319.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 7307 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3384 3 visits [320.0, 320.0, 320.0, 320.0, 319.0, 319.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 7308 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7312, "number_of_timesteps": 154245, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 3385 4 visits [320.0, 320.0, 320.0, 320.0, 320.0, 319.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 7312 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3386 5 visits [320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 7314 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3387 6 visits [320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 319.0, 500.0, 319.0]  episode_count: 7316 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3388 7 visits [320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 500.0, 319.0]  episode_count: 7319 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3389 9 visits [320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 7320 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7323, "number_of_timesteps": 154486, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 3390 0 visits [321.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 7323 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3391 1 visits [321.0, 321.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 7325 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3392 2 visits [321.0, 321.0, 321.0, 320.0, 320.0, 320.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 7327 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3393 3 visits [321.0, 321.0, 321.0, 321.0, 320.0, 320.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 7329 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3394 4 visits [321.0, 321.0, 321.0, 321.0, 321.0, 320.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 7330 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3395 5 visits [321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 7331 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7338, "number_of_timesteps": 154788, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 3396 6 visits [321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 320.0, 500.0, 320.0]  episode_count: 7338 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3397 7 visits [321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 500.0, 320.0]  episode_count: 7340 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3398 9 visits [321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 7340 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3399 0 visits [322.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 7341 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7348, "number_of_timesteps": 155010, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 3400 1 visits [322.0, 322.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 7348 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3401 2 visits [322.0, 322.0, 322.0, 321.0, 321.0, 321.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 7349 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3402 3 visits [322.0, 322.0, 322.0, 322.0, 321.0, 321.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 7350 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3403 4 visits [322.0, 322.0, 322.0, 322.0, 322.0, 321.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 7351 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3404 5 visits [322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 7355 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3405 6 visits [322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 321.0, 500.0, 321.0]  episode_count: 7356 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3406 7 visits [322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 500.0, 321.0]  episode_count: 7357 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7361, "number_of_timesteps": 155252, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 3407 9 visits [322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 7361 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3408 0 visits [323.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 7363 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3409 1 visits [323.0, 323.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 7365 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3410 2 visits [323.0, 323.0, 323.0, 322.0, 322.0, 322.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 7368 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7371, "number_of_timesteps": 155455, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 3411 3 visits [323.0, 323.0, 323.0, 323.0, 322.0, 322.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 7371 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3412 4 visits [323.0, 323.0, 323.0, 323.0, 323.0, 322.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 7372 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3413 5 visits [323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 7374 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3414 6 visits [323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 322.0, 500.0, 322.0]  episode_count: 7376 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3415 7 visits [323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 500.0, 322.0]  episode_count: 7379 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7381, "number_of_timesteps": 155632, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 3416 9 visits [323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 7381 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3417 0 visits [324.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 7383 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3418 1 visits [324.0, 324.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 7385 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3419 2 visits [324.0, 324.0, 324.0, 323.0, 323.0, 323.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 7388 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7391, "number_of_timesteps": 155895, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3420 3 visits [324.0, 324.0, 324.0, 324.0, 323.0, 323.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 7391 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3421 4 visits [324.0, 324.0, 324.0, 324.0, 324.0, 323.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 7393 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3422 5 visits [324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 7396 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3423 6 visits [324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 323.0, 500.0, 323.0]  episode_count: 7398 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3424 7 visits [324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 500.0, 323.0]  episode_count: 7400 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7401, "number_of_timesteps": 156042, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3425 9 visits [324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 7401 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3426 0 visits [325.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 7401 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3427 1 visits [325.0, 325.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 7403 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3428 2 visits [325.0, 325.0, 325.0, 324.0, 324.0, 324.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 7409 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3429 3 visits [325.0, 325.0, 325.0, 325.0, 324.0, 324.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 7409 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3430 4 visits [325.0, 325.0, 325.0, 325.0, 325.0, 324.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 7410 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7415, "number_of_timesteps": 156354, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3431 5 visits [325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 7415 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3432 6 visits [325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 324.0, 500.0, 324.0]  episode_count: 7416 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3433 7 visits [325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 500.0, 324.0]  episode_count: 7416 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3434 9 visits [325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 7419 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3435 0 visits [326.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 7423 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3436 1 visits [326.0, 326.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 7423 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3437 2 visits [326.0, 326.0, 326.0, 325.0, 325.0, 325.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 7424 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7426, "number_of_timesteps": 156637, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3438 3 visits [326.0, 326.0, 326.0, 326.0, 325.0, 325.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 7426 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3439 4 visits [326.0, 326.0, 326.0, 326.0, 326.0, 325.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 7428 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3440 5 visits [326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 7432 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3441 6 visits [326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 325.0, 500.0, 325.0]  episode_count: 7434 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3442 7 visits [326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 500.0, 325.0]  episode_count: 7435 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7438, "number_of_timesteps": 156909, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3443 9 visits [326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 7438 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3444 0 visits [327.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 7440 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3445 1 visits [327.0, 327.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 7442 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3446 2 visits [327.0, 327.0, 327.0, 326.0, 326.0, 326.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 7443 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3447 3 visits [327.0, 327.0, 327.0, 327.0, 326.0, 326.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 7444 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3448 4 visits [327.0, 327.0, 327.0, 327.0, 327.0, 326.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 7447 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7450, "number_of_timesteps": 157197, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3449 5 visits [327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 7450 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3450 6 visits [327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 326.0, 500.0, 326.0]  episode_count: 7451 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3451 7 visits [327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 500.0, 326.0]  episode_count: 7454 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3452 9 visits [327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 7457 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7460, "number_of_timesteps": 157416, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3453 0 visits [328.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 7460 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3454 1 visits [328.0, 328.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 7460 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3455 2 visits [328.0, 328.0, 328.0, 327.0, 327.0, 327.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 7465 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3456 3 visits [328.0, 328.0, 328.0, 328.0, 327.0, 327.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 7466 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3457 4 visits [328.0, 328.0, 328.0, 328.0, 328.0, 327.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 7467 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7471, "number_of_timesteps": 157614, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3458 5 visits [328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 7471 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3459 6 visits [328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 327.0, 500.0, 327.0]  episode_count: 7471 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3460 7 visits [328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 500.0, 327.0]  episode_count: 7475 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3461 9 visits [328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 7477 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3462 0 visits [329.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 7478 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7481, "number_of_timesteps": 157815, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3463 1 visits [329.0, 329.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 7481 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3464 2 visits [329.0, 329.0, 329.0, 328.0, 328.0, 328.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 7483 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3465 3 visits [329.0, 329.0, 329.0, 329.0, 328.0, 328.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 7485 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3466 4 visits [329.0, 329.0, 329.0, 329.0, 329.0, 328.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 7487 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3467 5 visits [329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 7487 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3468 6 visits [329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 328.0, 500.0, 328.0]  episode_count: 7490 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7491, "number_of_timesteps": 158015, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3469 7 visits [329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 500.0, 328.0]  episode_count: 7491 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3470 9 visits [329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 7491 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3471 0 visits [330.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 7497 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3472 1 visits [330.0, 330.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 7498 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7502, "number_of_timesteps": 158292, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3473 2 visits [330.0, 330.0, 330.0, 329.0, 329.0, 329.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 7502 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3474 3 visits [330.0, 330.0, 330.0, 330.0, 329.0, 329.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 7504 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3475 4 visits [330.0, 330.0, 330.0, 330.0, 330.0, 329.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 7506 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3476 5 visits [330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 7507 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3477 6 visits [330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 329.0, 500.0, 329.0]  episode_count: 7511 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7512, "number_of_timesteps": 158480, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 3478 7 visits [330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 500.0, 329.0]  episode_count: 7512 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3479 9 visits [330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 7514 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3480 0 visits [331.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 7518 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7522, "number_of_timesteps": 158699, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.09999999999999964},
Step 3481 1 visits [331.0, 331.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 7522 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3482 2 visits [331.0, 331.0, 331.0, 330.0, 330.0, 330.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 7522 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3483 3 visits [331.0, 331.0, 331.0, 331.0, 330.0, 330.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 7524 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3484 4 visits [331.0, 331.0, 331.0, 331.0, 331.0, 330.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 7525 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3485 5 visits [331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 7527 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3486 6 visits [331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 330.0, 500.0, 330.0]  episode_count: 7527 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3487 7 visits [331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 500.0, 330.0]  episode_count: 7530 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7532, "number_of_timesteps": 158892, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 3488 9 visits [331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 7532 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3489 0 visits [332.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 7535 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3490 1 visits [332.0, 332.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 7537 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3491 2 visits [332.0, 332.0, 332.0, 331.0, 331.0, 331.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 7539 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7543, "number_of_timesteps": 159196, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.09999999999999964},
Step 3492 3 visits [332.0, 332.0, 332.0, 332.0, 331.0, 331.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 7543 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3493 4 visits [332.0, 332.0, 332.0, 332.0, 332.0, 331.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 7545 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3494 5 visits [332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 7547 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3495 6 visits [332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 331.0, 500.0, 331.0]  episode_count: 7548 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3496 7 visits [332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 500.0, 331.0]  episode_count: 7552 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7555, "number_of_timesteps": 159393, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 3497 9 visits [332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 7555 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3498 0 visits [333.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 7556 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3499 1 visits [333.0, 333.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 7560 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3500 2 visits [333.0, 333.0, 333.0, 332.0, 332.0, 332.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 7563 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3501 3 visits [333.0, 333.0, 333.0, 333.0, 332.0, 332.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 7563 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7565, "number_of_timesteps": 159598, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 3502 4 visits [333.0, 333.0, 333.0, 333.0, 333.0, 332.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 7565 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3503 5 visits [333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 7568 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3504 6 visits [333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 332.0, 500.0, 332.0]  episode_count: 7568 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3505 7 visits [333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 500.0, 332.0]  episode_count: 7571 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7575, "number_of_timesteps": 159820, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 3506 9 visits [333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 7575 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3507 0 visits [334.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 7576 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3508 1 visits [334.0, 334.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 7577 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3509 2 visits [334.0, 334.0, 334.0, 333.0, 333.0, 333.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 7578 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3510 3 visits [334.0, 334.0, 334.0, 334.0, 333.0, 333.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 7580 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3511 4 visits [334.0, 334.0, 334.0, 334.0, 334.0, 333.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 7583 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7587, "number_of_timesteps": 160118, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 3512 5 visits [334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 7587 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3513 6 visits [334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 333.0, 500.0, 333.0]  episode_count: 7588 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3514 7 visits [334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 500.0, 333.0]  episode_count: 7589 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3515 9 visits [334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 7592 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3516 0 visits [335.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 7593 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3517 1 visits [335.0, 335.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 7596 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7598, "number_of_timesteps": 160318, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.09999999999999964},
Step 3518 2 visits [335.0, 335.0, 335.0, 334.0, 334.0, 334.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 7598 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3519 3 visits [335.0, 335.0, 335.0, 335.0, 334.0, 334.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 7602 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3520 4 visits [335.0, 335.0, 335.0, 335.0, 335.0, 334.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 7603 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3521 5 visits [335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 7606 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7608, "number_of_timesteps": 160514, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 3522 6 visits [335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 334.0, 500.0, 334.0]  episode_count: 7608 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3523 7 visits [335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 500.0, 334.0]  episode_count: 7611 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3524 9 visits [335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 7613 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3525 0 visits [336.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 7614 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3526 1 visits [336.0, 336.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 7615 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3527 2 visits [336.0, 336.0, 336.0, 335.0, 335.0, 335.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 7617 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7618, "number_of_timesteps": 160721, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 3528 3 visits [336.0, 336.0, 336.0, 336.0, 335.0, 335.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 7618 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3529 4 visits [336.0, 336.0, 336.0, 336.0, 336.0, 335.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 7622 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3530 5 visits [336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 7624 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3531 6 visits [336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 335.0, 500.0, 335.0]  episode_count: 7626 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7630, "number_of_timesteps": 160982, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 3532 7 visits [336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 500.0, 335.0]  episode_count: 7630 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3533 9 visits [336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 7631 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3534 0 visits [337.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 7633 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3535 1 visits [337.0, 337.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 7635 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3536 2 visits [337.0, 337.0, 337.0, 336.0, 336.0, 336.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 7638 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3537 3 visits [337.0, 337.0, 337.0, 337.0, 336.0, 336.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 7639 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7643, "number_of_timesteps": 161250, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3538 4 visits [337.0, 337.0, 337.0, 337.0, 337.0, 336.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 7643 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3539 5 visits [337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 7643 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3540 6 visits [337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 336.0, 500.0, 336.0]  episode_count: 7644 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3541 7 visits [337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 500.0, 336.0]  episode_count: 7647 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3542 9 visits [337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 7647 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3543 0 visits [338.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 7650 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3544 1 visits [338.0, 338.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 7651 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3545 2 visits [338.0, 338.0, 338.0, 337.0, 337.0, 337.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 7652 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7658, "number_of_timesteps": 161576, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3546 3 visits [338.0, 338.0, 338.0, 338.0, 337.0, 337.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 7658 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3547 4 visits [338.0, 338.0, 338.0, 338.0, 338.0, 337.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 7659 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3548 5 visits [338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 7662 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3549 6 visits [338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 337.0, 500.0, 337.0]  episode_count: 7663 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3550 7 visits [338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 500.0, 337.0]  episode_count: 7664 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7668, "number_of_timesteps": 161829, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3551 9 visits [338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 7668 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3552 0 visits [339.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 7669 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3553 1 visits [339.0, 339.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 7671 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3554 2 visits [339.0, 339.0, 339.0, 338.0, 338.0, 338.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 7673 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3555 3 visits [339.0, 339.0, 339.0, 339.0, 338.0, 338.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 7676 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7678, "number_of_timesteps": 162071, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3556 4 visits [339.0, 339.0, 339.0, 339.0, 339.0, 338.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 7678 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3557 5 visits [339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 7681 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3558 6 visits [339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 338.0, 500.0, 338.0]  episode_count: 7683 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3559 7 visits [339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 500.0, 338.0]  episode_count: 7685 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3560 9 visits [339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 7687 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7690, "number_of_timesteps": 162262, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 3561 0 visits [340.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 7690 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3562 1 visits [340.0, 340.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 7692 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3563 2 visits [340.0, 340.0, 340.0, 339.0, 339.0, 339.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 7694 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3564 3 visits [340.0, 340.0, 340.0, 340.0, 339.0, 339.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 7698 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7700, "number_of_timesteps": 162476, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 3565 4 visits [340.0, 340.0, 340.0, 340.0, 340.0, 339.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 7700 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3566 5 visits [340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 7702 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3567 6 visits [340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 339.0, 500.0, 339.0]  episode_count: 7706 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3568 7 visits [340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 500.0, 339.0]  episode_count: 7708 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7710, "number_of_timesteps": 162669, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 3569 9 visits [340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 7710 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3570 0 visits [341.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 7712 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3571 1 visits [341.0, 341.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 7715 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3572 2 visits [341.0, 341.0, 341.0, 340.0, 340.0, 340.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 7717 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3573 3 visits [341.0, 341.0, 341.0, 341.0, 340.0, 340.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 7719 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7721, "number_of_timesteps": 162832, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3574 4 visits [341.0, 341.0, 341.0, 341.0, 341.0, 340.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 7721 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3575 5 visits [341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 7722 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3576 6 visits [341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 340.0, 500.0, 340.0]  episode_count: 7724 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3577 7 visits [341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 500.0, 340.0]  episode_count: 7726 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3578 9 visits [341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 7730 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7732, "number_of_timesteps": 163077, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3579 0 visits [342.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 7732 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3580 1 visits [342.0, 342.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 7736 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3581 2 visits [342.0, 342.0, 342.0, 341.0, 341.0, 341.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 7738 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3582 3 visits [342.0, 342.0, 342.0, 342.0, 341.0, 341.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 7740 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7743, "number_of_timesteps": 163282, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3583 4 visits [342.0, 342.0, 342.0, 342.0, 342.0, 341.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 7743 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3584 5 visits [342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 7744 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3585 6 visits [342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 341.0, 500.0, 341.0]  episode_count: 7747 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3586 7 visits [342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 500.0, 341.0]  episode_count: 7749 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3587 9 visits [342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 7751 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3588 0 visits [343.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 7751 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7753, "number_of_timesteps": 163494, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3589 1 visits [343.0, 343.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 7753 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3590 2 visits [343.0, 343.0, 343.0, 342.0, 342.0, 342.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 7756 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3591 3 visits [343.0, 343.0, 343.0, 343.0, 342.0, 342.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 7758 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3592 4 visits [343.0, 343.0, 343.0, 343.0, 343.0, 342.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 7758 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3593 5 visits [343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 7761 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7764, "number_of_timesteps": 163749, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3594 6 visits [343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 342.0, 500.0, 342.0]  episode_count: 7764 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3595 7 visits [343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 500.0, 342.0]  episode_count: 7766 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3596 9 visits [343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 7769 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3597 0 visits [344.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 7771 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3598 1 visits [344.0, 344.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 7772 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7775, "number_of_timesteps": 163989, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3599 2 visits [344.0, 344.0, 344.0, 343.0, 343.0, 343.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 7775 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3600 3 visits [344.0, 344.0, 344.0, 344.0, 343.0, 343.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 7778 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3601 4 visits [344.0, 344.0, 344.0, 344.0, 344.0, 343.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 7780 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3602 5 visits [344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 7784 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7785, "number_of_timesteps": 164195, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3603 6 visits [344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 343.0, 500.0, 343.0]  episode_count: 7785 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3604 7 visits [344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 500.0, 343.0]  episode_count: 7789 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3605 9 visits [344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 7792 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3606 0 visits [345.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 7793 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7795, "number_of_timesteps": 164349, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3607 1 visits [345.0, 345.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 7795 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3608 2 visits [345.0, 345.0, 345.0, 344.0, 344.0, 344.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 7797 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3609 3 visits [345.0, 345.0, 345.0, 345.0, 344.0, 344.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 7798 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3610 4 visits [345.0, 345.0, 345.0, 345.0, 345.0, 344.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 7801 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7805, "number_of_timesteps": 164552, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 3611 5 visits [345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 7805 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3612 6 visits [345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 344.0, 500.0, 344.0]  episode_count: 7805 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3613 7 visits [345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 500.0, 344.0]  episode_count: 7807 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3614 9 visits [345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 7809 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3615 0 visits [346.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 7813 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3616 1 visits [346.0, 346.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 7814 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7815, "number_of_timesteps": 164725, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 3617 2 visits [346.0, 346.0, 346.0, 345.0, 345.0, 345.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 7815 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3618 3 visits [346.0, 346.0, 346.0, 346.0, 345.0, 345.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 7818 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3619 4 visits [346.0, 346.0, 346.0, 346.0, 346.0, 345.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 7821 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3620 5 visits [346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 7823 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3621 6 visits [346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 345.0, 500.0, 345.0]  episode_count: 7824 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7825, "number_of_timesteps": 164890, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 3622 7 visits [346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 500.0, 345.0]  episode_count: 7825 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3623 9 visits [346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 7831 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3624 0 visits [347.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 7832 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3625 1 visits [347.0, 347.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 7832 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3626 2 visits [347.0, 347.0, 347.0, 346.0, 346.0, 346.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 7834 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7837, "number_of_timesteps": 165235, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 3627 3 visits [347.0, 347.0, 347.0, 347.0, 346.0, 346.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 7837 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3628 4 visits [347.0, 347.0, 347.0, 347.0, 347.0, 346.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 7840 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3629 5 visits [347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 7840 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3630 6 visits [347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 346.0, 500.0, 346.0]  episode_count: 7842 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3631 7 visits [347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 500.0, 346.0]  episode_count: 7843 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7847, "number_of_timesteps": 165478, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.20000000000000107},
Step 3632 9 visits [347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 7847 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3633 0 visits [348.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 7849 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3634 1 visits [348.0, 348.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 7852 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3635 2 visits [348.0, 348.0, 348.0, 347.0, 347.0, 347.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 7853 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3636 3 visits [348.0, 348.0, 348.0, 348.0, 347.0, 347.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 7856 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7859, "number_of_timesteps": 165735, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.20000000000000107},
Step 3637 4 visits [348.0, 348.0, 348.0, 348.0, 348.0, 347.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 7859 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3638 5 visits [348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 7860 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3639 6 visits [348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 347.0, 500.0, 347.0]  episode_count: 7862 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3640 7 visits [348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 500.0, 347.0]  episode_count: 7864 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3641 9 visits [348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 7866 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7871, "number_of_timesteps": 165968, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.20000000000000107},
Step 3642 0 visits [349.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 7871 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3643 1 visits [349.0, 349.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 7874 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3644 2 visits [349.0, 349.0, 349.0, 348.0, 348.0, 348.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 7876 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3645 3 visits [349.0, 349.0, 349.0, 349.0, 348.0, 348.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 7876 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3646 4 visits [349.0, 349.0, 349.0, 349.0, 349.0, 348.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 7879 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3647 5 visits [349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 7880 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7883, "number_of_timesteps": 166211, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.20000000000000107},
Step 3648 6 visits [349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 348.0, 500.0, 348.0]  episode_count: 7883 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3649 7 visits [349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 500.0, 348.0]  episode_count: 7884 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3650 9 visits [349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 7887 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3651 0 visits [350.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 7889 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3652 1 visits [350.0, 350.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 7890 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3653 2 visits [350.0, 350.0, 350.0, 349.0, 349.0, 349.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 7892 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7895, "number_of_timesteps": 166443, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.20000000000000107},
Step 3654 3 visits [350.0, 350.0, 350.0, 350.0, 349.0, 349.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 7895 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3655 4 visits [350.0, 350.0, 350.0, 350.0, 350.0, 349.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 7898 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3656 5 visits [350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 7900 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3657 6 visits [350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 349.0, 500.0, 349.0]  episode_count: 7901 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3658 7 visits [350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 500.0, 349.0]  episode_count: 7904 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7905, "number_of_timesteps": 166683, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.20000000000000107},
Step 3659 9 visits [350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 7905 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3660 0 visits [351.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 7907 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3661 1 visits [351.0, 351.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 7909 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3662 2 visits [351.0, 351.0, 351.0, 350.0, 350.0, 350.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 7912 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3663 3 visits [351.0, 351.0, 351.0, 351.0, 350.0, 350.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 7914 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7916, "number_of_timesteps": 166962, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.20000000000000107},
Step 3664 4 visits [351.0, 351.0, 351.0, 351.0, 351.0, 350.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 7916 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3665 5 visits [351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 7921 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3666 6 visits [351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 350.0, 500.0, 350.0]  episode_count: 7924 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3667 7 visits [351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 500.0, 350.0]  episode_count: 7925 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7928, "number_of_timesteps": 167140, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.20000000000000107},
Step 3668 9 visits [351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 7928 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3669 0 visits [352.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 7929 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3670 1 visits [352.0, 352.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 7932 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3671 2 visits [352.0, 352.0, 352.0, 351.0, 351.0, 351.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 7934 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3672 3 visits [352.0, 352.0, 352.0, 352.0, 351.0, 351.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 7936 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3673 4 visits [352.0, 352.0, 352.0, 352.0, 352.0, 351.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 7936 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7940, "number_of_timesteps": 167362, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.20000000000000107},
Step 3674 5 visits [352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 7940 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3675 6 visits [352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 351.0, 500.0, 351.0]  episode_count: 7942 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3676 7 visits [352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 500.0, 351.0]  episode_count: 7947 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3677 9 visits [352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 7949 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7953, "number_of_timesteps": 167633, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.0027777777777777974, "biggest_recent_change": 0.09999999999999964},
Step 3678 0 visits [353.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 7953 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3679 1 visits [353.0, 353.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 7956 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3680 2 visits [353.0, 353.0, 353.0, 352.0, 352.0, 352.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 7958 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3681 3 visits [353.0, 353.0, 353.0, 353.0, 352.0, 352.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 7960 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3682 4 visits [353.0, 353.0, 353.0, 353.0, 353.0, 352.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 7962 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7964, "number_of_timesteps": 167786, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 3683 5 visits [353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 7964 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3684 6 visits [353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 352.0, 500.0, 352.0]  episode_count: 7969 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3685 7 visits [353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 500.0, 352.0]  episode_count: 7972 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3686 9 visits [353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 7973 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7977, "number_of_timesteps": 168018, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 3687 0 visits [354.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 7977 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3688 1 visits [354.0, 354.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 7978 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3689 2 visits [354.0, 354.0, 354.0, 353.0, 353.0, 353.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 7980 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3690 3 visits [354.0, 354.0, 354.0, 354.0, 353.0, 353.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 7983 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3691 4 visits [354.0, 354.0, 354.0, 354.0, 354.0, 353.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 7985 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7987, "number_of_timesteps": 168181, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 3692 5 visits [354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 7987 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3693 6 visits [354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 353.0, 500.0, 353.0]  episode_count: 7990 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3694 7 visits [354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 500.0, 353.0]  episode_count: 7991 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3695 9 visits [354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 7994 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 7997, "number_of_timesteps": 168376, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3696 0 visits [355.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 7997 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3697 1 visits [355.0, 355.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 7998 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3698 2 visits [355.0, 355.0, 355.0, 354.0, 354.0, 354.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 7999 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3699 3 visits [355.0, 355.0, 355.0, 355.0, 354.0, 354.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 8003 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3700 4 visits [355.0, 355.0, 355.0, 355.0, 355.0, 354.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 8006 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8007, "number_of_timesteps": 168618, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3701 5 visits [355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 8007 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3702 6 visits [355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 354.0, 500.0, 354.0]  episode_count: 8009 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3703 7 visits [355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 500.0, 354.0]  episode_count: 8012 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3704 9 visits [355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 8012 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3705 0 visits [356.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 8015 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8017, "number_of_timesteps": 168785, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3706 1 visits [356.0, 356.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 8017 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3707 2 visits [356.0, 356.0, 356.0, 355.0, 355.0, 355.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 8019 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3708 3 visits [356.0, 356.0, 356.0, 356.0, 355.0, 355.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 8020 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3709 4 visits [356.0, 356.0, 356.0, 356.0, 356.0, 355.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 8023 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3710 5 visits [356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 8025 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8029, "number_of_timesteps": 169068, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3711 6 visits [356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 355.0, 500.0, 355.0]  episode_count: 8029 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3712 7 visits [356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 500.0, 355.0]  episode_count: 8029 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3713 9 visits [356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 8029 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3714 0 visits [357.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 8034 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3715 1 visits [357.0, 357.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 8036 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3716 2 visits [357.0, 357.0, 357.0, 356.0, 356.0, 356.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 8038 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8041, "number_of_timesteps": 169371, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 3717 3 visits [357.0, 357.0, 357.0, 357.0, 356.0, 356.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 8041 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3718 4 visits [357.0, 357.0, 357.0, 357.0, 357.0, 356.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 8042 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3719 5 visits [357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 8044 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3720 6 visits [357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 356.0, 500.0, 356.0]  episode_count: 8047 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3721 7 visits [357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 500.0, 356.0]  episode_count: 8049 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8052, "number_of_timesteps": 169581, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3722 9 visits [357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 8052 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3723 0 visits [358.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 8053 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3724 1 visits [358.0, 358.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 8053 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3725 2 visits [358.0, 358.0, 358.0, 357.0, 357.0, 357.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 8055 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3726 3 visits [358.0, 358.0, 358.0, 358.0, 357.0, 357.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 8061 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8062, "number_of_timesteps": 169831, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3727 4 visits [358.0, 358.0, 358.0, 358.0, 358.0, 357.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 8062 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3728 5 visits [358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 8064 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3729 6 visits [358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 357.0, 500.0, 357.0]  episode_count: 8065 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3730 7 visits [358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 500.0, 357.0]  episode_count: 8069 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8072, "number_of_timesteps": 170006, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3731 9 visits [358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 8072 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3732 0 visits [359.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 8074 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3733 1 visits [359.0, 359.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 8076 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3734 2 visits [359.0, 359.0, 359.0, 358.0, 358.0, 358.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 8078 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8083, "number_of_timesteps": 170210, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3735 3 visits [359.0, 359.0, 359.0, 359.0, 358.0, 358.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 8083 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3736 4 visits [359.0, 359.0, 359.0, 359.0, 359.0, 358.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 8084 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3737 5 visits [359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 8086 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3738 6 visits [359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 358.0, 500.0, 358.0]  episode_count: 8089 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3739 7 visits [359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 500.0, 358.0]  episode_count: 8090 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3740 9 visits [359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 8091 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8093, "number_of_timesteps": 170387, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3741 0 visits [360.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 8093 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3742 1 visits [360.0, 360.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 8095 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3743 2 visits [360.0, 360.0, 360.0, 359.0, 359.0, 359.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 8098 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3744 3 visits [360.0, 360.0, 360.0, 360.0, 359.0, 359.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 8101 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3745 4 visits [360.0, 360.0, 360.0, 360.0, 360.0, 359.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 8102 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8106, "number_of_timesteps": 170682, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3746 5 visits [360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 8106 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3747 6 visits [360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 359.0, 500.0, 359.0]  episode_count: 8108 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3748 7 visits [360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 500.0, 359.0]  episode_count: 8110 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3749 9 visits [360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 8113 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3750 0 visits [361.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 8113 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8116, "number_of_timesteps": 170879, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 3751 1 visits [361.0, 361.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 8116 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3752 2 visits [361.0, 361.0, 361.0, 360.0, 360.0, 360.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 8119 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3753 3 visits [361.0, 361.0, 361.0, 361.0, 360.0, 360.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 8120 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3754 4 visits [361.0, 361.0, 361.0, 361.0, 361.0, 360.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 8122 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3755 5 visits [361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 8125 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8128, "number_of_timesteps": 171144, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3756 6 visits [361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 360.0, 500.0, 360.0]  episode_count: 8128 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3757 7 visits [361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 500.0, 360.0]  episode_count: 8130 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3758 9 visits [361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 8133 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3759 0 visits [362.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 8135 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8138, "number_of_timesteps": 171305, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3760 1 visits [362.0, 362.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 8138 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3761 2 visits [362.0, 362.0, 362.0, 361.0, 361.0, 361.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 8139 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3762 3 visits [362.0, 362.0, 362.0, 362.0, 361.0, 361.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 8139 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3763 4 visits [362.0, 362.0, 362.0, 362.0, 362.0, 361.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 8145 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8148, "number_of_timesteps": 171530, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3764 5 visits [362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 8148 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3765 6 visits [362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 361.0, 500.0, 361.0]  episode_count: 8148 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3766 7 visits [362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 500.0, 361.0]  episode_count: 8150 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3767 9 visits [362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 8153 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3768 0 visits [363.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 8155 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3769 1 visits [363.0, 363.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 8157 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8158, "number_of_timesteps": 171734, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 3770 2 visits [363.0, 363.0, 363.0, 362.0, 362.0, 362.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 8158 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3771 3 visits [363.0, 363.0, 363.0, 363.0, 362.0, 362.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 8159 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3772 4 visits [363.0, 363.0, 363.0, 363.0, 363.0, 362.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 8160 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3773 5 visits [363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 8164 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3774 6 visits [363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 362.0, 500.0, 362.0]  episode_count: 8165 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3775 7 visits [363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 500.0, 362.0]  episode_count: 8165 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3776 9 visits [363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 8167 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8172, "number_of_timesteps": 172098, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 3777 0 visits [364.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 8172 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3778 1 visits [364.0, 364.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 8174 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3779 2 visits [364.0, 364.0, 364.0, 363.0, 363.0, 363.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 8176 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3780 3 visits [364.0, 364.0, 364.0, 364.0, 363.0, 363.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 8178 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3781 4 visits [364.0, 364.0, 364.0, 364.0, 364.0, 363.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 8181 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8185, "number_of_timesteps": 172349, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 3782 5 visits [364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 8185 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3783 6 visits [364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 363.0, 500.0, 363.0]  episode_count: 8186 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3784 7 visits [364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 500.0, 363.0]  episode_count: 8187 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3785 9 visits [364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 8191 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3786 0 visits [365.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 8192 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3787 1 visits [365.0, 365.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 8193 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8195, "number_of_timesteps": 172542, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 3788 2 visits [365.0, 365.0, 365.0, 364.0, 364.0, 364.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 8195 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3789 3 visits [365.0, 365.0, 365.0, 365.0, 364.0, 364.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 8198 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3790 4 visits [365.0, 365.0, 365.0, 365.0, 365.0, 364.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 8200 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3791 5 visits [365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 8204 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8206, "number_of_timesteps": 172759, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 3792 6 visits [365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 364.0, 500.0, 364.0]  episode_count: 8206 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3793 7 visits [365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 500.0, 364.0]  episode_count: 8207 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3794 9 visits [365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 8210 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3795 0 visits [366.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 8212 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3796 1 visits [366.0, 366.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 8214 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8218, "number_of_timesteps": 172999, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 3797 2 visits [366.0, 366.0, 366.0, 365.0, 365.0, 365.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 8218 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3798 3 visits [366.0, 366.0, 366.0, 366.0, 365.0, 365.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 8221 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3799 4 visits [366.0, 366.0, 366.0, 366.0, 366.0, 365.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 8222 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3800 5 visits [366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 8226 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8230, "number_of_timesteps": 173213, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 3801 6 visits [366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 365.0, 500.0, 365.0]  episode_count: 8230 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3802 7 visits [366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 500.0, 365.0]  episode_count: 8231 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3803 9 visits [366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 8233 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3804 0 visits [367.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 8235 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3805 1 visits [367.0, 367.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 8237 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3806 2 visits [367.0, 367.0, 367.0, 366.0, 366.0, 366.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 8239 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8242, "number_of_timesteps": 173449, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
Step 3807 3 visits [367.0, 367.0, 367.0, 367.0, 366.0, 366.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 8242 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3808 4 visits [367.0, 367.0, 367.0, 367.0, 367.0, 366.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 8243 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3809 5 visits [367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 8244 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3810 6 visits [367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 366.0, 500.0, 366.0]  episode_count: 8248 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8252, "number_of_timesteps": 173668, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 3811 7 visits [367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 500.0, 366.0]  episode_count: 8252 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3812 9 visits [367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 8252 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3813 0 visits [368.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 8256 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3814 1 visits [368.0, 368.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 8260 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8262, "number_of_timesteps": 173834, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 3815 2 visits [368.0, 368.0, 368.0, 367.0, 367.0, 367.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 8262 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3816 3 visits [368.0, 368.0, 368.0, 368.0, 367.0, 367.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 8263 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3817 4 visits [368.0, 368.0, 368.0, 368.0, 368.0, 367.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 8266 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3818 5 visits [368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 8269 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8272, "number_of_timesteps": 174012, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 3819 6 visits [368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 367.0, 500.0, 367.0]  episode_count: 8272 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3820 7 visits [368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 500.0, 367.0]  episode_count: 8272 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3821 9 visits [368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 8272 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3822 0 visits [369.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 8273 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3823 1 visits [369.0, 369.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 8274 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3824 2 visits [369.0, 369.0, 369.0, 368.0, 368.0, 368.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 8276 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3825 3 visits [369.0, 369.0, 369.0, 369.0, 368.0, 368.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 8279 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8282, "number_of_timesteps": 174268, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
Step 3826 4 visits [369.0, 369.0, 369.0, 369.0, 369.0, 368.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 8282 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3827 5 visits [369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 8283 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3828 6 visits [369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 368.0, 500.0, 368.0]  episode_count: 8287 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3829 7 visits [369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 500.0, 368.0]  episode_count: 8288 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8293, "number_of_timesteps": 174537, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000213},
Step 3830 9 visits [369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 8293 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3831 0 visits [370.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 8295 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3832 1 visits [370.0, 370.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 8296 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3833 2 visits [370.0, 370.0, 370.0, 369.0, 369.0, 369.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 8298 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3834 3 visits [370.0, 370.0, 370.0, 370.0, 369.0, 369.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 8302 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8304, "number_of_timesteps": 174748, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 3835 4 visits [370.0, 370.0, 370.0, 370.0, 370.0, 369.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 8304 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3836 5 visits [370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 8305 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3837 6 visits [370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 369.0, 500.0, 369.0]  episode_count: 8307 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3838 7 visits [370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 500.0, 369.0]  episode_count: 8310 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3839 9 visits [370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 8311 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8314, "number_of_timesteps": 174950, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 3840 0 visits [371.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 8314 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3841 1 visits [371.0, 371.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 8318 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3842 2 visits [371.0, 371.0, 371.0, 370.0, 370.0, 370.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 8319 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3843 3 visits [371.0, 371.0, 371.0, 371.0, 370.0, 370.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 8321 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3844 4 visits [371.0, 371.0, 371.0, 371.0, 371.0, 370.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 8321 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3845 5 visits [371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 8323 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8324, "number_of_timesteps": 175147, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 3846 6 visits [371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 370.0, 500.0, 370.0]  episode_count: 8324 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3847 7 visits [371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 500.0, 370.0]  episode_count: 8325 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3848 9 visits [371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 8327 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3849 0 visits [372.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 8329 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3850 1 visits [372.0, 372.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 8332 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3851 2 visits [372.0, 372.0, 372.0, 371.0, 371.0, 371.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 8333 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8334, "number_of_timesteps": 175461, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 3852 3 visits [372.0, 372.0, 372.0, 372.0, 371.0, 371.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 8334 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3853 4 visits [372.0, 372.0, 372.0, 372.0, 372.0, 371.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 8339 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3854 5 visits [372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 8341 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3855 6 visits [372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 371.0, 500.0, 371.0]  episode_count: 8342 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8344, "number_of_timesteps": 175667, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.15000000000000213},
Step 3856 7 visits [372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 500.0, 371.0]  episode_count: 8344 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3857 9 visits [372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 8346 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3858 0 visits [373.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 8348 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3859 1 visits [373.0, 373.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 8352 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3860 2 visits [373.0, 373.0, 373.0, 372.0, 372.0, 372.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 8353 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8355, "number_of_timesteps": 175893, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000213},
Step 3861 3 visits [373.0, 373.0, 373.0, 373.0, 372.0, 372.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 8355 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3862 4 visits [373.0, 373.0, 373.0, 373.0, 373.0, 372.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 8357 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3863 5 visits [373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 8360 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3864 6 visits [373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 372.0, 500.0, 372.0]  episode_count: 8363 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8365, "number_of_timesteps": 176063, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 3865 7 visits [373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 500.0, 372.0]  episode_count: 8365 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3866 9 visits [373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 8368 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3867 0 visits [374.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 8370 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3868 1 visits [374.0, 374.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 8374 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8375, "number_of_timesteps": 176277, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000213},
Step 3869 2 visits [374.0, 374.0, 374.0, 373.0, 373.0, 373.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 8375 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3870 3 visits [374.0, 374.0, 374.0, 374.0, 373.0, 373.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 8378 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3871 4 visits [374.0, 374.0, 374.0, 374.0, 374.0, 373.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 8380 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3872 5 visits [374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 8380 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3873 6 visits [374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 373.0, 500.0, 373.0]  episode_count: 8382 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8386, "number_of_timesteps": 176507, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 3874 7 visits [374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 500.0, 373.0]  episode_count: 8386 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3875 9 visits [374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 8388 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3876 0 visits [375.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 8388 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3877 1 visits [375.0, 375.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 8393 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8396, "number_of_timesteps": 176729, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 3878 2 visits [375.0, 375.0, 375.0, 374.0, 374.0, 374.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 8396 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3879 3 visits [375.0, 375.0, 375.0, 375.0, 374.0, 374.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 8399 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3880 4 visits [375.0, 375.0, 375.0, 375.0, 375.0, 374.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 8401 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3881 5 visits [375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 8403 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8407, "number_of_timesteps": 176906, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3882 6 visits [375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 374.0, 500.0, 374.0]  episode_count: 8407 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3883 7 visits [375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 500.0, 374.0]  episode_count: 8409 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3884 9 visits [375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 8412 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3885 0 visits [376.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 8413 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3886 1 visits [376.0, 376.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 8416 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8417, "number_of_timesteps": 177076, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 3887 2 visits [376.0, 376.0, 376.0, 375.0, 375.0, 375.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 8417 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3888 3 visits [376.0, 376.0, 376.0, 376.0, 375.0, 375.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 8420 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3889 4 visits [376.0, 376.0, 376.0, 376.0, 376.0, 375.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 8422 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3890 5 visits [376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 8423 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3891 6 visits [376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 375.0, 500.0, 375.0]  episode_count: 8426 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8427, "number_of_timesteps": 177289, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 3892 7 visits [376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 500.0, 375.0]  episode_count: 8427 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3893 9 visits [376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 8429 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3894 0 visits [377.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 8432 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3895 1 visits [377.0, 377.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 8434 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3896 2 visits [377.0, 377.0, 377.0, 376.0, 376.0, 376.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 8435 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8438, "number_of_timesteps": 177504, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.09999999999999964},
Step 3897 3 visits [377.0, 377.0, 377.0, 377.0, 376.0, 376.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 8438 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3898 4 visits [377.0, 377.0, 377.0, 377.0, 377.0, 376.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 8440 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3899 5 visits [377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 8442 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3900 6 visits [377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 376.0, 500.0, 376.0]  episode_count: 8442 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8448, "number_of_timesteps": 177786, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 3901 7 visits [377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 500.0, 376.0]  episode_count: 8448 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3902 9 visits [377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 8450 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3903 0 visits [378.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 8451 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3904 1 visits [378.0, 378.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 8453 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3905 2 visits [378.0, 378.0, 378.0, 377.0, 377.0, 377.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 8455 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3906 3 visits [378.0, 378.0, 378.0, 378.0, 377.0, 377.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 8457 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8458, "number_of_timesteps": 177968, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 3907 4 visits [378.0, 378.0, 378.0, 378.0, 378.0, 377.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 8458 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3908 5 visits [378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 8463 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3909 6 visits [378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 377.0, 500.0, 377.0]  episode_count: 8465 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3910 7 visits [378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 500.0, 377.0]  episode_count: 8466 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8469, "number_of_timesteps": 178182, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 3911 9 visits [378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 8469 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3912 0 visits [379.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 8474 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3913 1 visits [379.0, 379.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 8474 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3914 2 visits [379.0, 379.0, 379.0, 378.0, 378.0, 378.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 8474 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3915 3 visits [379.0, 379.0, 379.0, 379.0, 378.0, 378.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 8476 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3916 4 visits [379.0, 379.0, 379.0, 379.0, 379.0, 378.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 8477 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8479, "number_of_timesteps": 178418, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 3917 5 visits [379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 8479 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3918 6 visits [379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 378.0, 500.0, 378.0]  episode_count: 8481 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3919 7 visits [379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 500.0, 378.0]  episode_count: 8483 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3920 9 visits [379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 8485 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3921 0 visits [380.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 8487 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8490, "number_of_timesteps": 178694, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 3922 1 visits [380.0, 380.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 8490 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3923 2 visits [380.0, 380.0, 380.0, 379.0, 379.0, 379.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 8492 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3924 3 visits [380.0, 380.0, 380.0, 380.0, 379.0, 379.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 8493 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3925 4 visits [380.0, 380.0, 380.0, 380.0, 380.0, 379.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 8496 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3926 5 visits [380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 8499 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8501, "number_of_timesteps": 178954, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 3927 6 visits [380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 379.0, 500.0, 379.0]  episode_count: 8501 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3928 7 visits [380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 500.0, 379.0]  episode_count: 8502 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3929 9 visits [380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 8503 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3930 0 visits [381.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 8504 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3931 1 visits [381.0, 381.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 8508 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8512, "number_of_timesteps": 179175, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 3932 2 visits [381.0, 381.0, 381.0, 380.0, 380.0, 380.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 8512 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3933 3 visits [381.0, 381.0, 381.0, 381.0, 380.0, 380.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 8513 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3934 4 visits [381.0, 381.0, 381.0, 381.0, 381.0, 380.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 8516 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3935 5 visits [381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 8520 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3936 6 visits [381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 380.0, 500.0, 380.0]  episode_count: 8521 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8523, "number_of_timesteps": 179378, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 3937 7 visits [381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 500.0, 380.0]  episode_count: 8523 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3938 9 visits [381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 8526 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3939 0 visits [382.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 8530 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3940 1 visits [382.0, 382.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 8531 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8534, "number_of_timesteps": 179580, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 3941 2 visits [382.0, 382.0, 382.0, 381.0, 381.0, 381.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 8534 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3942 3 visits [382.0, 382.0, 382.0, 382.0, 381.0, 381.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 8536 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3943 4 visits [382.0, 382.0, 382.0, 382.0, 382.0, 381.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 8538 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3944 5 visits [382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 8541 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3945 6 visits [382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 381.0, 500.0, 381.0]  episode_count: 8542 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8546, "number_of_timesteps": 179806, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 3946 7 visits [382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 500.0, 381.0]  episode_count: 8546 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3947 9 visits [382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 8548 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3948 0 visits [383.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 8550 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3949 1 visits [383.0, 383.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 8551 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3950 2 visits [383.0, 383.0, 383.0, 382.0, 382.0, 382.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 8554 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3951 3 visits [383.0, 383.0, 383.0, 383.0, 382.0, 382.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 8554 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8557, "number_of_timesteps": 180025, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 3952 4 visits [383.0, 383.0, 383.0, 383.0, 383.0, 382.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 8557 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3953 5 visits [383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 8558 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3954 6 visits [383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 382.0, 500.0, 382.0]  episode_count: 8560 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3955 7 visits [383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 500.0, 382.0]  episode_count: 8563 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3956 9 visits [383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 8566 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8568, "number_of_timesteps": 180305, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 3957 0 visits [384.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 8568 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3958 1 visits [384.0, 384.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 8569 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3959 2 visits [384.0, 384.0, 384.0, 383.0, 383.0, 383.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 8572 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3960 3 visits [384.0, 384.0, 384.0, 384.0, 383.0, 383.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 8575 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3961 4 visits [384.0, 384.0, 384.0, 384.0, 384.0, 383.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 8576 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8578, "number_of_timesteps": 180489, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 3962 5 visits [384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 8578 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3963 6 visits [384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 383.0, 500.0, 383.0]  episode_count: 8579 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3964 7 visits [384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 500.0, 383.0]  episode_count: 8583 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3965 9 visits [384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 8585 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3966 0 visits [385.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 8586 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3967 1 visits [385.0, 385.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 8587 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8592, "number_of_timesteps": 180813, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 3968 2 visits [385.0, 385.0, 385.0, 384.0, 384.0, 384.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 8592 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3969 3 visits [385.0, 385.0, 385.0, 385.0, 384.0, 384.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 8594 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3970 4 visits [385.0, 385.0, 385.0, 385.0, 385.0, 384.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 8595 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3971 5 visits [385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 8597 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8602, "number_of_timesteps": 181017, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
Step 3972 6 visits [385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 384.0, 500.0, 384.0]  episode_count: 8602 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3973 7 visits [385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 500.0, 384.0]  episode_count: 8603 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3974 9 visits [385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 8605 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3975 0 visits [386.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 8608 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8612, "number_of_timesteps": 181208, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 3976 1 visits [386.0, 386.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 8612 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3977 2 visits [386.0, 386.0, 386.0, 385.0, 385.0, 385.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 8613 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3978 3 visits [386.0, 386.0, 386.0, 386.0, 385.0, 385.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 8614 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3979 4 visits [386.0, 386.0, 386.0, 386.0, 386.0, 385.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 8615 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3980 5 visits [386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 8618 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3981 6 visits [386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 385.0, 500.0, 385.0]  episode_count: 8621 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8622, "number_of_timesteps": 181394, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 3982 7 visits [386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 500.0, 385.0]  episode_count: 8622 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3983 9 visits [386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 8624 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3984 0 visits [387.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 8628 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3985 1 visits [387.0, 387.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 8631 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3986 2 visits [387.0, 387.0, 387.0, 386.0, 386.0, 386.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 8631 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3987 3 visits [387.0, 387.0, 387.0, 387.0, 386.0, 386.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 8631 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8636, "number_of_timesteps": 181717, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 3988 4 visits [387.0, 387.0, 387.0, 387.0, 387.0, 386.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 8636 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3989 5 visits [387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 8639 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3990 6 visits [387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 386.0, 500.0, 386.0]  episode_count: 8640 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3991 7 visits [387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 500.0, 386.0]  episode_count: 8643 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3992 9 visits [387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 8645 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8647, "number_of_timesteps": 181938, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 3993 0 visits [388.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 8647 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3994 1 visits [388.0, 388.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 8652 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3995 2 visits [388.0, 388.0, 388.0, 387.0, 387.0, 387.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 8653 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3996 3 visits [388.0, 388.0, 388.0, 388.0, 387.0, 387.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 8655 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8658, "number_of_timesteps": 182113, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 3997 4 visits [388.0, 388.0, 388.0, 388.0, 388.0, 387.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 8658 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3998 5 visits [388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 8659 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 3999 6 visits [388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 387.0, 500.0, 387.0]  episode_count: 8660 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4000 7 visits [388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 500.0, 387.0]  episode_count: 8662 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4001 9 visits [388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 8665 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8668, "number_of_timesteps": 182358, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 4002 0 visits [389.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 8668 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4003 1 visits [389.0, 389.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 8669 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4004 2 visits [389.0, 389.0, 389.0, 388.0, 388.0, 388.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 8670 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4005 3 visits [389.0, 389.0, 389.0, 389.0, 388.0, 388.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 8673 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4006 4 visits [389.0, 389.0, 389.0, 389.0, 389.0, 388.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 8674 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4007 5 visits [389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 8677 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8680, "number_of_timesteps": 182639, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 4008 6 visits [389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 388.0, 500.0, 388.0]  episode_count: 8680 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4009 7 visits [389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 500.0, 388.0]  episode_count: 8681 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4010 9 visits [389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 8683 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4011 0 visits [390.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 8686 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4012 1 visits [390.0, 390.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 8687 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4013 2 visits [390.0, 390.0, 390.0, 389.0, 389.0, 389.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 8687 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8691, "number_of_timesteps": 182870, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 4014 3 visits [390.0, 390.0, 390.0, 390.0, 389.0, 389.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 8691 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4015 4 visits [390.0, 390.0, 390.0, 390.0, 390.0, 389.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 8691 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4016 5 visits [390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 8692 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4017 6 visits [390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 389.0, 500.0, 389.0]  episode_count: 8695 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4018 7 visits [390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 500.0, 389.0]  episode_count: 8699 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4019 9 visits [390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 8700 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8702, "number_of_timesteps": 183155, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 4020 0 visits [391.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 8702 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4021 1 visits [391.0, 391.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 8704 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4022 2 visits [391.0, 391.0, 391.0, 390.0, 390.0, 390.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 8706 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4023 3 visits [391.0, 391.0, 391.0, 391.0, 390.0, 390.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 8707 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4024 4 visits [391.0, 391.0, 391.0, 391.0, 391.0, 390.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 8711 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8712, "number_of_timesteps": 183337, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 4025 5 visits [391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 8712 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4026 6 visits [391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 390.0, 500.0, 390.0]  episode_count: 8716 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4027 7 visits [391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 500.0, 390.0]  episode_count: 8716 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4028 9 visits [391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 8717 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4029 0 visits [392.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 8721 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8722, "number_of_timesteps": 183572, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 4030 1 visits [392.0, 392.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 8722 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4031 2 visits [392.0, 392.0, 392.0, 391.0, 391.0, 391.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 8725 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4032 3 visits [392.0, 392.0, 392.0, 392.0, 391.0, 391.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 8728 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4033 4 visits [392.0, 392.0, 392.0, 392.0, 392.0, 391.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 8730 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4034 5 visits [392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 8731 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8733, "number_of_timesteps": 183814, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
Step 4035 6 visits [392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 391.0, 500.0, 391.0]  episode_count: 8733 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4036 7 visits [392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 500.0, 391.0]  episode_count: 8735 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4037 9 visits [392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 8737 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4038 0 visits [393.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 8738 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4039 1 visits [393.0, 393.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 8742 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4040 2 visits [393.0, 393.0, 393.0, 392.0, 392.0, 392.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 8742 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8744, "number_of_timesteps": 184086, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
Step 4041 3 visits [393.0, 393.0, 393.0, 393.0, 392.0, 392.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 8744 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4042 4 visits [393.0, 393.0, 393.0, 393.0, 393.0, 392.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 8746 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4043 5 visits [393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 8749 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4044 6 visits [393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 392.0, 500.0, 392.0]  episode_count: 8751 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4045 7 visits [393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 500.0, 392.0]  episode_count: 8752 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8755, "number_of_timesteps": 184356, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
Step 4046 9 visits [393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 8755 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4047 0 visits [394.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 8756 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4048 1 visits [394.0, 394.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 8758 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4049 2 visits [394.0, 394.0, 394.0, 393.0, 393.0, 393.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 8760 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4050 3 visits [394.0, 394.0, 394.0, 394.0, 393.0, 393.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 8763 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8765, "number_of_timesteps": 184598, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4051 4 visits [394.0, 394.0, 394.0, 394.0, 394.0, 393.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 8765 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4052 5 visits [394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 8766 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4053 6 visits [394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 393.0, 500.0, 393.0]  episode_count: 8769 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4054 7 visits [394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 500.0, 393.0]  episode_count: 8770 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4055 9 visits [394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 8772 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4056 0 visits [395.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 8772 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8775, "number_of_timesteps": 184862, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4057 1 visits [395.0, 395.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 8775 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4058 2 visits [395.0, 395.0, 395.0, 394.0, 394.0, 394.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 8779 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4059 3 visits [395.0, 395.0, 395.0, 395.0, 394.0, 394.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 8780 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4060 4 visits [395.0, 395.0, 395.0, 395.0, 395.0, 394.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 8782 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4061 5 visits [395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 8784 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8787, "number_of_timesteps": 185094, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4062 6 visits [395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 394.0, 500.0, 394.0]  episode_count: 8787 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4063 7 visits [395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 500.0, 394.0]  episode_count: 8789 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4064 9 visits [395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 8791 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4065 0 visits [396.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 8792 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4066 1 visits [396.0, 396.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 8796 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8797, "number_of_timesteps": 185346, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 4067 2 visits [396.0, 396.0, 396.0, 395.0, 395.0, 395.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 8797 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4068 3 visits [396.0, 396.0, 396.0, 396.0, 395.0, 395.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 8797 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4069 4 visits [396.0, 396.0, 396.0, 396.0, 396.0, 395.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 8799 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4070 5 visits [396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 8802 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4071 6 visits [396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 395.0, 500.0, 395.0]  episode_count: 8804 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8807, "number_of_timesteps": 185595, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4072 7 visits [396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 500.0, 395.0]  episode_count: 8807 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4073 9 visits [396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 8810 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4074 0 visits [397.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 8811 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4075 1 visits [397.0, 397.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 8816 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8818, "number_of_timesteps": 185789, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 4076 2 visits [397.0, 397.0, 397.0, 396.0, 396.0, 396.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 8818 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4077 3 visits [397.0, 397.0, 397.0, 397.0, 396.0, 396.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 8820 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4078 4 visits [397.0, 397.0, 397.0, 397.0, 397.0, 396.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 8823 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4079 5 visits [397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 8823 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4080 6 visits [397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 396.0, 500.0, 396.0]  episode_count: 8825 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8828, "number_of_timesteps": 185968, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 4081 7 visits [397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 500.0, 396.0]  episode_count: 8828 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4082 9 visits [397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 8830 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4083 0 visits [398.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 8831 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4084 1 visits [398.0, 398.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 8834 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8839, "number_of_timesteps": 186217, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 4085 2 visits [398.0, 398.0, 398.0, 397.0, 397.0, 397.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 8839 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4086 3 visits [398.0, 398.0, 398.0, 398.0, 397.0, 397.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 8840 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4087 4 visits [398.0, 398.0, 398.0, 398.0, 398.0, 397.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 8842 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4088 5 visits [398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 8846 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4089 6 visits [398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 397.0, 500.0, 397.0]  episode_count: 8847 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8850, "number_of_timesteps": 186402, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 4090 7 visits [398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 500.0, 397.0]  episode_count: 8850 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4091 9 visits [398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 8850 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4092 0 visits [399.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 8853 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4093 1 visits [399.0, 399.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 8857 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4094 2 visits [399.0, 399.0, 399.0, 398.0, 398.0, 398.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 8857 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8861, "number_of_timesteps": 186636, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 4095 3 visits [399.0, 399.0, 399.0, 399.0, 398.0, 398.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 8861 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4096 4 visits [399.0, 399.0, 399.0, 399.0, 399.0, 398.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 8866 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4097 5 visits [399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 8867 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4098 6 visits [399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 398.0, 500.0, 398.0]  episode_count: 8868 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8872, "number_of_timesteps": 186815, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 4099 7 visits [399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 500.0, 398.0]  episode_count: 8872 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4100 9 visits [399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 8875 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4101 0 visits [400.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 8876 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4102 1 visits [400.0, 400.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 8879 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4103 2 visits [400.0, 400.0, 400.0, 399.0, 399.0, 399.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 8881 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8882, "number_of_timesteps": 186994, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
Step 4104 3 visits [400.0, 400.0, 400.0, 400.0, 399.0, 399.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 8882 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4105 4 visits [400.0, 400.0, 400.0, 400.0, 400.0, 399.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 8885 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4106 5 visits [400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 8887 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4107 6 visits [400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 399.0, 500.0, 399.0]  episode_count: 8889 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8892, "number_of_timesteps": 187236, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 4108 7 visits [400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 500.0, 399.0]  episode_count: 8892 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4109 9 visits [400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 8896 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4110 0 visits [401.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 8898 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4111 1 visits [401.0, 401.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 8898 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4112 2 visits [401.0, 401.0, 401.0, 400.0, 400.0, 400.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 8900 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8903, "number_of_timesteps": 187412, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 4113 3 visits [401.0, 401.0, 401.0, 401.0, 400.0, 400.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 8903 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4114 4 visits [401.0, 401.0, 401.0, 401.0, 401.0, 400.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 8906 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4115 5 visits [401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 8907 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4116 6 visits [401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 400.0, 500.0, 400.0]  episode_count: 8908 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8914, "number_of_timesteps": 187666, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 4117 7 visits [401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 500.0, 400.0]  episode_count: 8914 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4118 9 visits [401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 8916 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4119 0 visits [402.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 8918 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4120 1 visits [402.0, 402.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 8922 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4121 2 visits [402.0, 402.0, 402.0, 401.0, 401.0, 401.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 8923 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8926, "number_of_timesteps": 187867, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 4122 3 visits [402.0, 402.0, 402.0, 402.0, 401.0, 401.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 8926 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4123 4 visits [402.0, 402.0, 402.0, 402.0, 402.0, 401.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 8929 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4124 5 visits [402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 8929 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4125 6 visits [402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 401.0, 500.0, 401.0]  episode_count: 8931 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4126 7 visits [402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 500.0, 401.0]  episode_count: 8932 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4127 9 visits [402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 8935 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8937, "number_of_timesteps": 188069, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 4128 0 visits [403.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 8937 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4129 1 visits [403.0, 403.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 8938 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4130 2 visits [403.0, 403.0, 403.0, 402.0, 402.0, 402.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 8940 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4131 3 visits [403.0, 403.0, 403.0, 403.0, 402.0, 402.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 8945 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8948, "number_of_timesteps": 188356, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 4132 4 visits [403.0, 403.0, 403.0, 403.0, 403.0, 402.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 8948 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4133 5 visits [403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 8948 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4134 6 visits [403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 402.0, 500.0, 402.0]  episode_count: 8949 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4135 7 visits [403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 500.0, 402.0]  episode_count: 8955 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8958, "number_of_timesteps": 188535, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 4136 9 visits [403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 8958 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4137 0 visits [404.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 8958 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4138 1 visits [404.0, 404.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 8963 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4139 2 visits [404.0, 404.0, 404.0, 403.0, 403.0, 403.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 8967 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8968, "number_of_timesteps": 188683, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 4140 3 visits [404.0, 404.0, 404.0, 404.0, 403.0, 403.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 8968 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4141 4 visits [404.0, 404.0, 404.0, 404.0, 404.0, 403.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 8969 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4142 5 visits [404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 8972 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4143 6 visits [404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 403.0, 500.0, 403.0]  episode_count: 8973 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4144 7 visits [404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 500.0, 403.0]  episode_count: 8973 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4145 9 visits [404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 8976 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8978, "number_of_timesteps": 188894, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 4146 0 visits [405.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 8978 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4147 1 visits [405.0, 405.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 8978 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4148 2 visits [405.0, 405.0, 405.0, 404.0, 404.0, 404.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 8980 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4149 3 visits [405.0, 405.0, 405.0, 405.0, 404.0, 404.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 8982 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4150 4 visits [405.0, 405.0, 405.0, 405.0, 405.0, 404.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 8984 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8988, "number_of_timesteps": 189192, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 4151 5 visits [405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 8988 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4152 6 visits [405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 404.0, 500.0, 404.0]  episode_count: 8990 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4153 7 visits [405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 500.0, 404.0]  episode_count: 8993 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4154 9 visits [405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 8993 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4155 0 visits [406.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 8996 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4156 1 visits [406.0, 406.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 8997 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 8998, "number_of_timesteps": 189382, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 4157 2 visits [406.0, 406.0, 406.0, 405.0, 405.0, 405.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 8998 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4158 3 visits [406.0, 406.0, 406.0, 406.0, 405.0, 405.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 8999 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4159 4 visits [406.0, 406.0, 406.0, 406.0, 406.0, 405.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 9003 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4160 5 visits [406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 9003 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4161 6 visits [406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 405.0, 500.0, 405.0]  episode_count: 9006 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4162 7 visits [406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 500.0, 405.0]  episode_count: 9007 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9009, "number_of_timesteps": 189700, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 4163 9 visits [406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 9009 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4164 0 visits [407.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 9011 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4165 1 visits [407.0, 407.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 9014 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4166 2 visits [407.0, 407.0, 407.0, 406.0, 406.0, 406.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 9015 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4167 3 visits [407.0, 407.0, 407.0, 407.0, 406.0, 406.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 9018 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9021, "number_of_timesteps": 189975, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 4168 4 visits [407.0, 407.0, 407.0, 407.0, 407.0, 406.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 9021 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4169 5 visits [407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 9022 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4170 6 visits [407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 406.0, 500.0, 406.0]  episode_count: 9026 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4171 7 visits [407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 500.0, 406.0]  episode_count: 9029 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4172 9 visits [407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 9030 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9033, "number_of_timesteps": 190190, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4173 0 visits [408.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 9033 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4174 1 visits [408.0, 408.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 9034 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4175 2 visits [408.0, 408.0, 408.0, 407.0, 407.0, 407.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 9038 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4176 3 visits [408.0, 408.0, 408.0, 408.0, 407.0, 407.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 9042 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9043, "number_of_timesteps": 190373, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4177 4 visits [408.0, 408.0, 408.0, 408.0, 408.0, 407.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 9043 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4178 5 visits [408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 9044 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4179 6 visits [408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 407.0, 500.0, 407.0]  episode_count: 9047 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4180 7 visits [408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 500.0, 407.0]  episode_count: 9049 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4181 9 visits [408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 9051 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4182 0 visits [409.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 9052 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9054, "number_of_timesteps": 190552, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4183 1 visits [409.0, 409.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 9054 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4184 2 visits [409.0, 409.0, 409.0, 408.0, 408.0, 408.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 9058 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4185 3 visits [409.0, 409.0, 409.0, 409.0, 408.0, 408.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 9058 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4186 4 visits [409.0, 409.0, 409.0, 409.0, 409.0, 408.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 9060 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4187 5 visits [409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 9060 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9064, "number_of_timesteps": 190859, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4188 6 visits [409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 408.0, 500.0, 408.0]  episode_count: 9064 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4189 7 visits [409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 500.0, 408.0]  episode_count: 9066 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4190 9 visits [409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 9067 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4191 0 visits [410.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 9068 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4192 1 visits [410.0, 410.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 9069 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4193 2 visits [410.0, 410.0, 410.0, 409.0, 409.0, 409.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 9071 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9074, "number_of_timesteps": 191079, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 4194 3 visits [410.0, 410.0, 410.0, 410.0, 409.0, 409.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 9074 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4195 4 visits [410.0, 410.0, 410.0, 410.0, 410.0, 409.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 9077 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4196 5 visits [410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 9080 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4197 6 visits [410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 409.0, 500.0, 409.0]  episode_count: 9081 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9084, "number_of_timesteps": 191310, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 4198 7 visits [410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 500.0, 409.0]  episode_count: 9084 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4199 9 visits [410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 9087 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4200 0 visits [411.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 9089 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4201 1 visits [411.0, 411.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 9092 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9094, "number_of_timesteps": 191510, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 4202 2 visits [411.0, 411.0, 411.0, 410.0, 410.0, 410.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 9094 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4203 3 visits [411.0, 411.0, 411.0, 411.0, 410.0, 410.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 9096 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4204 4 visits [411.0, 411.0, 411.0, 411.0, 411.0, 410.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 9100 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4205 5 visits [411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 9102 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9105, "number_of_timesteps": 191698, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 4206 6 visits [411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 410.0, 500.0, 410.0]  episode_count: 9105 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4207 7 visits [411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 500.0, 410.0]  episode_count: 9107 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4208 9 visits [411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 9109 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4209 0 visits [412.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 9111 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4210 1 visits [412.0, 412.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 9114 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9116, "number_of_timesteps": 191897, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 4211 2 visits [412.0, 412.0, 412.0, 411.0, 411.0, 411.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 9116 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4212 3 visits [412.0, 412.0, 412.0, 412.0, 411.0, 411.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 9118 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4213 4 visits [412.0, 412.0, 412.0, 412.0, 412.0, 411.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 9122 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4214 5 visits [412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 9123 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4215 6 visits [412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 411.0, 500.0, 411.0]  episode_count: 9124 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9126, "number_of_timesteps": 192106, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
Step 4216 7 visits [412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 500.0, 411.0]  episode_count: 9126 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4217 9 visits [412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 9128 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4218 0 visits [413.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 9131 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4219 1 visits [413.0, 413.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 9134 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9136, "number_of_timesteps": 192316, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.10000000000000142},
Step 4220 2 visits [413.0, 413.0, 413.0, 412.0, 412.0, 412.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 9136 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4221 3 visits [413.0, 413.0, 413.0, 413.0, 412.0, 412.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 9138 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4222 4 visits [413.0, 413.0, 413.0, 413.0, 413.0, 412.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 9139 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4223 5 visits [413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 9141 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4224 6 visits [413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 412.0, 500.0, 412.0]  episode_count: 9143 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4225 7 visits [413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 500.0, 412.0]  episode_count: 9145 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9146, "number_of_timesteps": 192506, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 4226 9 visits [413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 9146 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4227 0 visits [414.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 9149 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4228 1 visits [414.0, 414.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 9149 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4229 2 visits [414.0, 414.0, 414.0, 413.0, 413.0, 413.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 9151 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4230 3 visits [414.0, 414.0, 414.0, 414.0, 413.0, 413.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 9155 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9158, "number_of_timesteps": 192832, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.10000000000000142},
Step 4231 4 visits [414.0, 414.0, 414.0, 414.0, 414.0, 413.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 9158 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4232 5 visits [414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 9161 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4233 6 visits [414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 413.0, 500.0, 413.0]  episode_count: 9162 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4234 7 visits [414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 500.0, 413.0]  episode_count: 9163 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4235 9 visits [414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 9166 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9168, "number_of_timesteps": 193013, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 4236 0 visits [415.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 9168 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4237 1 visits [415.0, 415.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 9170 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4238 2 visits [415.0, 415.0, 415.0, 414.0, 414.0, 414.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 9172 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4239 3 visits [415.0, 415.0, 415.0, 415.0, 414.0, 414.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 9174 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4240 4 visits [415.0, 415.0, 415.0, 415.0, 415.0, 414.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 9174 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4241 5 visits [415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 9177 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9181, "number_of_timesteps": 193338, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 4242 6 visits [415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 414.0, 500.0, 414.0]  episode_count: 9181 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4243 7 visits [415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 500.0, 414.0]  episode_count: 9183 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4244 9 visits [415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 9184 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4245 0 visits [416.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 9185 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4246 1 visits [416.0, 416.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 9188 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4247 2 visits [416.0, 416.0, 416.0, 415.0, 415.0, 415.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 9190 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9193, "number_of_timesteps": 193596, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
Step 4248 3 visits [416.0, 416.0, 416.0, 416.0, 415.0, 415.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 9193 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4249 4 visits [416.0, 416.0, 416.0, 416.0, 416.0, 415.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 9195 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4250 5 visits [416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 9197 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4251 6 visits [416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 415.0, 500.0, 415.0]  episode_count: 9199 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4252 7 visits [416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 500.0, 415.0]  episode_count: 9201 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4253 9 visits [416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 9201 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9204, "number_of_timesteps": 193813, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4254 0 visits [417.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 9204 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4255 1 visits [417.0, 417.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 9207 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4256 2 visits [417.0, 417.0, 417.0, 416.0, 416.0, 416.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 9209 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4257 3 visits [417.0, 417.0, 417.0, 417.0, 416.0, 416.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 9212 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9215, "number_of_timesteps": 194080, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4258 4 visits [417.0, 417.0, 417.0, 417.0, 417.0, 416.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 9215 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4259 5 visits [417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 9215 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4260 6 visits [417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 416.0, 500.0, 416.0]  episode_count: 9219 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4261 7 visits [417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 500.0, 416.0]  episode_count: 9221 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4262 9 visits [417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 9221 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9227, "number_of_timesteps": 194305, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4263 0 visits [418.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 9227 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4264 1 visits [418.0, 418.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 9228 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4265 2 visits [418.0, 418.0, 418.0, 417.0, 417.0, 417.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 9228 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4266 3 visits [418.0, 418.0, 418.0, 418.0, 417.0, 417.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 9232 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4267 4 visits [418.0, 418.0, 418.0, 418.0, 418.0, 417.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 9232 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4268 5 visits [418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 9235 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4269 6 visits [418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 417.0, 500.0, 417.0]  episode_count: 9236 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9239, "number_of_timesteps": 194540, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 4270 7 visits [418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 500.0, 417.0]  episode_count: 9239 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4271 9 visits [418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 9241 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4272 0 visits [419.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 9243 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4273 1 visits [419.0, 419.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 9246 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9250, "number_of_timesteps": 194826, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 4274 2 visits [419.0, 419.0, 419.0, 418.0, 418.0, 418.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 9250 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4275 3 visits [419.0, 419.0, 419.0, 419.0, 418.0, 418.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 9251 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4276 4 visits [419.0, 419.0, 419.0, 419.0, 419.0, 418.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 9254 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4277 5 visits [419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 9256 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4278 6 visits [419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 418.0, 500.0, 418.0]  episode_count: 9258 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9260, "number_of_timesteps": 194987, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 4279 7 visits [419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 500.0, 418.0]  episode_count: 9260 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4280 9 visits [419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 9261 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4281 0 visits [420.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 9265 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4282 1 visits [420.0, 420.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 9266 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4283 2 visits [420.0, 420.0, 420.0, 419.0, 419.0, 419.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 9268 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9270, "number_of_timesteps": 195197, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 4284 3 visits [420.0, 420.0, 420.0, 420.0, 419.0, 419.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 9270 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4285 4 visits [420.0, 420.0, 420.0, 420.0, 420.0, 419.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 9271 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4286 5 visits [420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 9276 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4287 6 visits [420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 419.0, 500.0, 419.0]  episode_count: 9277 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9280, "number_of_timesteps": 195435, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 4288 7 visits [420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 500.0, 419.0]  episode_count: 9280 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4289 9 visits [420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 9283 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4290 0 visits [421.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 9284 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4291 1 visits [421.0, 421.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 9287 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4292 2 visits [421.0, 421.0, 421.0, 420.0, 420.0, 420.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 9289 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9291, "number_of_timesteps": 195640, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4293 3 visits [421.0, 421.0, 421.0, 421.0, 420.0, 420.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 9291 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4294 4 visits [421.0, 421.0, 421.0, 421.0, 421.0, 420.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 9294 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4295 5 visits [421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 9295 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4296 6 visits [421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 420.0, 500.0, 420.0]  episode_count: 9296 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4297 7 visits [421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 500.0, 420.0]  episode_count: 9298 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9301, "number_of_timesteps": 195876, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4298 9 visits [421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 9301 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4299 0 visits [422.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 9304 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4300 1 visits [422.0, 422.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 9305 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4301 2 visits [422.0, 422.0, 422.0, 421.0, 421.0, 421.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 9307 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9311, "number_of_timesteps": 196090, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4302 3 visits [422.0, 422.0, 422.0, 422.0, 421.0, 421.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 9311 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4303 4 visits [422.0, 422.0, 422.0, 422.0, 422.0, 421.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 9314 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4304 5 visits [422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 9314 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4305 6 visits [422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 421.0, 500.0, 421.0]  episode_count: 9316 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4306 7 visits [422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 500.0, 421.0]  episode_count: 9317 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4307 9 visits [422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 9320 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9321, "number_of_timesteps": 196293, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4308 0 visits [423.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 9321 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4309 1 visits [423.0, 423.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 9324 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4310 2 visits [423.0, 423.0, 423.0, 422.0, 422.0, 422.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 9326 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4311 3 visits [423.0, 423.0, 423.0, 423.0, 422.0, 422.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 9329 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9331, "number_of_timesteps": 196496, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4312 4 visits [423.0, 423.0, 423.0, 423.0, 423.0, 422.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 9331 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4313 5 visits [423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 9336 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4314 6 visits [423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 422.0, 500.0, 422.0]  episode_count: 9336 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4315 7 visits [423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 500.0, 422.0]  episode_count: 9337 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4316 9 visits [423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 9340 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4317 0 visits [424.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 9340 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9343, "number_of_timesteps": 196746, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4318 1 visits [424.0, 424.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 9343 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4319 2 visits [424.0, 424.0, 424.0, 423.0, 423.0, 423.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 9347 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4320 3 visits [424.0, 424.0, 424.0, 424.0, 423.0, 423.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 9349 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4321 4 visits [424.0, 424.0, 424.0, 424.0, 424.0, 423.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 9350 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9354, "number_of_timesteps": 196973, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4322 5 visits [424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 9354 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4323 6 visits [424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 423.0, 500.0, 423.0]  episode_count: 9356 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4324 7 visits [424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 500.0, 423.0]  episode_count: 9359 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4325 9 visits [424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 9359 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4326 0 visits [425.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 9362 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4327 1 visits [425.0, 425.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 9363 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9364, "number_of_timesteps": 197177, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4328 2 visits [425.0, 425.0, 425.0, 424.0, 424.0, 424.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 9364 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4329 3 visits [425.0, 425.0, 425.0, 425.0, 424.0, 424.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 9366 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4330 4 visits [425.0, 425.0, 425.0, 425.0, 425.0, 424.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 9368 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4331 5 visits [425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 9372 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4332 6 visits [425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 424.0, 500.0, 424.0]  episode_count: 9373 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9374, "number_of_timesteps": 197424, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4333 7 visits [425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 500.0, 424.0]  episode_count: 9374 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4334 9 visits [425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 9379 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4335 0 visits [426.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 9381 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9384, "number_of_timesteps": 197603, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4336 1 visits [426.0, 426.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 9384 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4337 2 visits [426.0, 426.0, 426.0, 425.0, 425.0, 425.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 9386 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4338 3 visits [426.0, 426.0, 426.0, 426.0, 425.0, 425.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 9388 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4339 4 visits [426.0, 426.0, 426.0, 426.0, 426.0, 425.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 9392 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4340 5 visits [426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 9393 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9396, "number_of_timesteps": 197815, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4341 6 visits [426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 425.0, 500.0, 425.0]  episode_count: 9396 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4342 7 visits [426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 500.0, 425.0]  episode_count: 9400 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4343 9 visits [426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 9403 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4344 0 visits [427.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 9403 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9407, "number_of_timesteps": 198010, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4345 1 visits [427.0, 427.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 9407 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4346 2 visits [427.0, 427.0, 427.0, 426.0, 426.0, 426.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 9411 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4347 3 visits [427.0, 427.0, 427.0, 427.0, 426.0, 426.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 9411 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4348 4 visits [427.0, 427.0, 427.0, 427.0, 427.0, 426.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 9412 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4349 5 visits [427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 9415 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9417, "number_of_timesteps": 198218, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4350 6 visits [427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 426.0, 500.0, 426.0]  episode_count: 9417 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4351 7 visits [427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 500.0, 426.0]  episode_count: 9422 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4352 9 visits [427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 9423 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4353 0 visits [428.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 9426 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9430, "number_of_timesteps": 198443, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4354 1 visits [428.0, 428.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 9430 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4355 2 visits [428.0, 428.0, 428.0, 427.0, 427.0, 427.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 9433 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4356 3 visits [428.0, 428.0, 428.0, 428.0, 427.0, 427.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 9435 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4357 4 visits [428.0, 428.0, 428.0, 428.0, 428.0, 427.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 9436 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4358 5 visits [428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 9439 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9440, "number_of_timesteps": 198592, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4359 6 visits [428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 427.0, 500.0, 427.0]  episode_count: 9440 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4360 7 visits [428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 500.0, 427.0]  episode_count: 9442 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4361 9 visits [428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 9445 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4362 0 visits [429.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 9448 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4363 1 visits [429.0, 429.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 9449 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9451, "number_of_timesteps": 198822, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4364 2 visits [429.0, 429.0, 429.0, 428.0, 428.0, 428.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 9451 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4365 3 visits [429.0, 429.0, 429.0, 429.0, 428.0, 428.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 9455 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4366 4 visits [429.0, 429.0, 429.0, 429.0, 429.0, 428.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 9457 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4367 5 visits [429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 9458 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4368 6 visits [429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 428.0, 500.0, 428.0]  episode_count: 9460 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9464, "number_of_timesteps": 199061, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4369 7 visits [429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 500.0, 428.0]  episode_count: 9464 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4370 9 visits [429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 9464 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4371 0 visits [430.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 9465 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4372 1 visits [430.0, 430.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 9468 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4373 2 visits [430.0, 430.0, 430.0, 429.0, 429.0, 429.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 9469 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4374 3 visits [430.0, 430.0, 430.0, 430.0, 429.0, 429.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 9471 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4375 4 visits [430.0, 430.0, 430.0, 430.0, 430.0, 429.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 9473 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9474, "number_of_timesteps": 199374, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4376 5 visits [430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 9474 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4377 6 visits [430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 429.0, 500.0, 429.0]  episode_count: 9477 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4378 7 visits [430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 500.0, 429.0]  episode_count: 9477 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4379 9 visits [430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 9479 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4380 0 visits [431.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 9482 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9485, "number_of_timesteps": 199635, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4381 1 visits [431.0, 431.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 9485 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4382 2 visits [431.0, 431.0, 431.0, 430.0, 430.0, 430.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 9488 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4383 3 visits [431.0, 431.0, 431.0, 431.0, 430.0, 430.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 9490 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4384 4 visits [431.0, 431.0, 431.0, 431.0, 431.0, 430.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 9491 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9495, "number_of_timesteps": 199876, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4385 5 visits [431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 9495 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4386 6 visits [431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 430.0, 500.0, 430.0]  episode_count: 9496 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4387 7 visits [431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 500.0, 430.0]  episode_count: 9497 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4388 9 visits [431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 9502 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4389 0 visits [432.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 9504 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9505, "number_of_timesteps": 200054, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4390 1 visits [432.0, 432.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 9505 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4391 2 visits [432.0, 432.0, 432.0, 431.0, 431.0, 431.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 9506 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4392 3 visits [432.0, 432.0, 432.0, 432.0, 431.0, 431.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 9508 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4393 4 visits [432.0, 432.0, 432.0, 432.0, 432.0, 431.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 9509 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4394 5 visits [432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 9511 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4395 6 visits [432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 431.0, 500.0, 431.0]  episode_count: 9513 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9515, "number_of_timesteps": 200288, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4396 7 visits [432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 500.0, 431.0]  episode_count: 9515 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4397 9 visits [432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 9517 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4398 0 visits [433.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 9519 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4399 1 visits [433.0, 433.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 9521 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9525, "number_of_timesteps": 200509, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4400 2 visits [433.0, 433.0, 433.0, 432.0, 432.0, 432.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 9525 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4401 3 visits [433.0, 433.0, 433.0, 433.0, 432.0, 432.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 9527 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4402 4 visits [433.0, 433.0, 433.0, 433.0, 433.0, 432.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 9529 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4403 5 visits [433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 9533 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4404 6 visits [433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 432.0, 500.0, 432.0]  episode_count: 9534 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9536, "number_of_timesteps": 200762, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4405 7 visits [433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 500.0, 432.0]  episode_count: 9536 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4406 9 visits [433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 9540 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4407 0 visits [434.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 9544 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4408 1 visits [434.0, 434.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 9545 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9548, "number_of_timesteps": 200976, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4409 2 visits [434.0, 434.0, 434.0, 433.0, 433.0, 433.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 9548 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4410 3 visits [434.0, 434.0, 434.0, 434.0, 433.0, 433.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 9551 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4411 4 visits [434.0, 434.0, 434.0, 434.0, 434.0, 433.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 9554 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4412 5 visits [434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 9555 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9558, "number_of_timesteps": 201156, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4413 6 visits [434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 433.0, 500.0, 433.0]  episode_count: 9558 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4414 7 visits [434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 500.0, 433.0]  episode_count: 9559 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4415 9 visits [434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 9563 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4416 0 visits [435.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 9563 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4417 1 visits [435.0, 435.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 9567 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9571, "number_of_timesteps": 201402, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4418 2 visits [435.0, 435.0, 435.0, 434.0, 434.0, 434.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 9571 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4419 3 visits [435.0, 435.0, 435.0, 435.0, 434.0, 434.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 9572 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4420 4 visits [435.0, 435.0, 435.0, 435.0, 435.0, 434.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 9574 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4421 5 visits [435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 9577 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4422 6 visits [435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 434.0, 500.0, 434.0]  episode_count: 9578 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9581, "number_of_timesteps": 201584, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4423 7 visits [435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 500.0, 434.0]  episode_count: 9581 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4424 9 visits [435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 9583 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4425 0 visits [436.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 9584 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4426 1 visits [436.0, 436.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 9585 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4427 2 visits [436.0, 436.0, 436.0, 435.0, 435.0, 435.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 9587 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9591, "number_of_timesteps": 201828, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4428 3 visits [436.0, 436.0, 436.0, 436.0, 435.0, 435.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 9591 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4429 4 visits [436.0, 436.0, 436.0, 436.0, 436.0, 435.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 9593 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4430 5 visits [436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 9594 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4431 6 visits [436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 435.0, 500.0, 435.0]  episode_count: 9597 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9601, "number_of_timesteps": 202056, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4432 7 visits [436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 500.0, 435.0]  episode_count: 9601 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4433 9 visits [436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 9602 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4434 0 visits [437.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 9604 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4435 1 visits [437.0, 437.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 9605 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4436 2 visits [437.0, 437.0, 437.0, 436.0, 436.0, 436.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 9609 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4437 3 visits [437.0, 437.0, 437.0, 437.0, 436.0, 436.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 9610 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9611, "number_of_timesteps": 202229, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4438 4 visits [437.0, 437.0, 437.0, 437.0, 437.0, 436.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 9611 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4439 5 visits [437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 9616 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4440 6 visits [437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 436.0, 500.0, 436.0]  episode_count: 9617 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4441 7 visits [437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 500.0, 436.0]  episode_count: 9619 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9621, "number_of_timesteps": 202426, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4442 9 visits [437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 9621 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4443 0 visits [438.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 9625 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4444 1 visits [438.0, 438.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 9627 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4445 2 visits [438.0, 438.0, 438.0, 437.0, 437.0, 437.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 9628 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4446 3 visits [438.0, 438.0, 438.0, 438.0, 437.0, 437.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 9629 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9631, "number_of_timesteps": 202651, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4447 4 visits [438.0, 438.0, 438.0, 438.0, 438.0, 437.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 9631 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4448 5 visits [438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 9633 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4449 6 visits [438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 437.0, 500.0, 437.0]  episode_count: 9636 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4450 7 visits [438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 500.0, 437.0]  episode_count: 9640 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9642, "number_of_timesteps": 202919, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4451 9 visits [438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 9642 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4452 0 visits [439.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 9644 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4453 1 visits [439.0, 439.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 9646 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4454 2 visits [439.0, 439.0, 439.0, 438.0, 438.0, 438.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 9649 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4455 3 visits [439.0, 439.0, 439.0, 439.0, 438.0, 438.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 9651 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4456 4 visits [439.0, 439.0, 439.0, 439.0, 439.0, 438.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 9651 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9655, "number_of_timesteps": 203161, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4457 5 visits [439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 9655 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4458 6 visits [439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 438.0, 500.0, 438.0]  episode_count: 9657 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4459 7 visits [439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 500.0, 438.0]  episode_count: 9661 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4460 9 visits [439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 9663 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9665, "number_of_timesteps": 203328, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4461 0 visits [440.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 9665 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4462 1 visits [440.0, 440.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 9668 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4463 2 visits [440.0, 440.0, 440.0, 439.0, 439.0, 439.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 9669 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4464 3 visits [440.0, 440.0, 440.0, 440.0, 439.0, 439.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 9672 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9675, "number_of_timesteps": 203533, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4465 4 visits [440.0, 440.0, 440.0, 440.0, 440.0, 439.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 9675 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4466 5 visits [440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 9677 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4467 6 visits [440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 439.0, 500.0, 439.0]  episode_count: 9679 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4468 7 visits [440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 500.0, 439.0]  episode_count: 9681 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4469 9 visits [440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 9684 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9686, "number_of_timesteps": 203744, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4470 0 visits [441.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 9686 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4471 1 visits [441.0, 441.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 9687 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4472 2 visits [441.0, 441.0, 441.0, 440.0, 440.0, 440.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 9691 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4473 3 visits [441.0, 441.0, 441.0, 441.0, 440.0, 440.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 9695 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9697, "number_of_timesteps": 203960, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4474 4 visits [441.0, 441.0, 441.0, 441.0, 441.0, 440.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 9697 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4475 5 visits [441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 9699 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4476 6 visits [441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 440.0, 500.0, 440.0]  episode_count: 9702 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4477 7 visits [441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 500.0, 440.0]  episode_count: 9702 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4478 9 visits [441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 9703 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4479 0 visits [442.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 9704 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9709, "number_of_timesteps": 204195, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4480 1 visits [442.0, 442.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 9709 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4481 2 visits [442.0, 442.0, 442.0, 441.0, 441.0, 441.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 9711 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4482 3 visits [442.0, 442.0, 442.0, 442.0, 441.0, 441.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 9713 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4483 4 visits [442.0, 442.0, 442.0, 442.0, 442.0, 441.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 9714 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4484 5 visits [442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 9716 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4485 6 visits [442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 441.0, 500.0, 441.0]  episode_count: 9717 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9719, "number_of_timesteps": 204413, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4486 7 visits [442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 500.0, 441.0]  episode_count: 9719 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4487 9 visits [442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 9721 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4488 0 visits [443.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 9723 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4489 1 visits [443.0, 443.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 9724 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4490 2 visits [443.0, 443.0, 443.0, 442.0, 442.0, 442.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 9727 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9729, "number_of_timesteps": 204680, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4491 3 visits [443.0, 443.0, 443.0, 443.0, 442.0, 442.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 9729 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4492 4 visits [443.0, 443.0, 443.0, 443.0, 443.0, 442.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 9733 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4493 5 visits [443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 9733 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4494 6 visits [443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 442.0, 500.0, 442.0]  episode_count: 9735 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4495 7 visits [443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 500.0, 442.0]  episode_count: 9736 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9739, "number_of_timesteps": 204905, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 4496 9 visits [443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 9739 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4497 0 visits [444.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 9742 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4498 1 visits [444.0, 444.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 9742 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4499 2 visits [444.0, 444.0, 444.0, 443.0, 443.0, 443.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 9742 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4500 3 visits [444.0, 444.0, 444.0, 444.0, 443.0, 443.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 9746 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4501 4 visits [444.0, 444.0, 444.0, 444.0, 444.0, 443.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 9748 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9750, "number_of_timesteps": 205176, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 4502 5 visits [444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 9750 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4503 6 visits [444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 443.0, 500.0, 443.0]  episode_count: 9752 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4504 7 visits [444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 500.0, 443.0]  episode_count: 9755 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4505 9 visits [444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 9758 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9760, "number_of_timesteps": 205333, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4506 0 visits [445.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 9760 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4507 1 visits [445.0, 445.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 9762 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4508 2 visits [445.0, 445.0, 445.0, 444.0, 444.0, 444.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 9764 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9770, "number_of_timesteps": 205585, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4509 3 visits [445.0, 445.0, 445.0, 445.0, 444.0, 444.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 9770 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4510 4 visits [445.0, 445.0, 445.0, 445.0, 445.0, 444.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 9770 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4511 5 visits [445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 9771 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4512 6 visits [445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 444.0, 500.0, 444.0]  episode_count: 9774 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4513 7 visits [445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 500.0, 444.0]  episode_count: 9775 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4514 9 visits [445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 9776 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4515 0 visits [446.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 9779 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9784, "number_of_timesteps": 205882, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4516 1 visits [446.0, 446.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 9784 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4517 2 visits [446.0, 446.0, 446.0, 445.0, 445.0, 445.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 9785 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4518 3 visits [446.0, 446.0, 446.0, 446.0, 445.0, 445.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 9785 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4519 4 visits [446.0, 446.0, 446.0, 446.0, 446.0, 445.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 9788 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4520 5 visits [446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 9791 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9795, "number_of_timesteps": 206112, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 4521 6 visits [446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 445.0, 500.0, 445.0]  episode_count: 9795 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4522 7 visits [446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 500.0, 445.0]  episode_count: 9796 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4523 9 visits [446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 9799 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4524 0 visits [447.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 9801 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4525 1 visits [447.0, 447.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 9804 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9805, "number_of_timesteps": 206307, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4526 2 visits [447.0, 447.0, 447.0, 446.0, 446.0, 446.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 9805 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4527 3 visits [447.0, 447.0, 447.0, 447.0, 446.0, 446.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 9806 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4528 4 visits [447.0, 447.0, 447.0, 447.0, 447.0, 446.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 9809 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4529 5 visits [447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 9811 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4530 6 visits [447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 446.0, 500.0, 446.0]  episode_count: 9813 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9816, "number_of_timesteps": 206531, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4531 7 visits [447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 500.0, 446.0]  episode_count: 9816 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4532 9 visits [447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 9820 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4533 0 visits [448.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 9820 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4534 1 visits [448.0, 448.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 9822 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4535 2 visits [448.0, 448.0, 448.0, 447.0, 447.0, 447.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 9824 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9827, "number_of_timesteps": 206753, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4536 3 visits [448.0, 448.0, 448.0, 448.0, 447.0, 447.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 9827 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4537 4 visits [448.0, 448.0, 448.0, 448.0, 448.0, 447.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 9828 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4538 5 visits [448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 9830 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4539 6 visits [448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 447.0, 500.0, 447.0]  episode_count: 9834 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4540 7 visits [448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 500.0, 447.0]  episode_count: 9836 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9837, "number_of_timesteps": 206976, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4541 9 visits [448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 9837 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4542 0 visits [449.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 9841 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4543 1 visits [449.0, 449.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 9844 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4544 2 visits [449.0, 449.0, 449.0, 448.0, 448.0, 448.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 9845 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9849, "number_of_timesteps": 207174, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4545 3 visits [449.0, 449.0, 449.0, 449.0, 448.0, 448.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 9849 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4546 4 visits [449.0, 449.0, 449.0, 449.0, 449.0, 448.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 9850 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4547 5 visits [449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 9854 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4548 6 visits [449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 448.0, 500.0, 448.0]  episode_count: 9855 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4549 7 visits [449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 500.0, 448.0]  episode_count: 9857 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9860, "number_of_timesteps": 207395, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4550 9 visits [449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 9860 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4551 0 visits [450.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 9863 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4552 1 visits [450.0, 450.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 9865 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4553 2 visits [450.0, 450.0, 450.0, 449.0, 449.0, 449.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 9865 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4554 3 visits [450.0, 450.0, 450.0, 450.0, 449.0, 449.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 9868 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9871, "number_of_timesteps": 207619, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4555 4 visits [450.0, 450.0, 450.0, 450.0, 450.0, 449.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 9871 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4556 5 visits [450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 9873 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4557 6 visits [450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 449.0, 500.0, 449.0]  episode_count: 9873 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4558 7 visits [450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 500.0, 449.0]  episode_count: 9875 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4559 9 visits [450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 9877 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4560 0 visits [451.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 9878 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9881, "number_of_timesteps": 207853, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4561 1 visits [451.0, 451.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 9881 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4562 2 visits [451.0, 451.0, 451.0, 450.0, 450.0, 450.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 9883 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4563 3 visits [451.0, 451.0, 451.0, 451.0, 450.0, 450.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 9886 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4564 4 visits [451.0, 451.0, 451.0, 451.0, 451.0, 450.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 9887 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4565 5 visits [451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 9888 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9891, "number_of_timesteps": 208088, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4566 6 visits [451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 450.0, 500.0, 450.0]  episode_count: 9891 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4567 7 visits [451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 500.0, 450.0]  episode_count: 9893 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4568 9 visits [451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 9895 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4569 0 visits [452.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 9895 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4570 1 visits [452.0, 452.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 9898 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4571 2 visits [452.0, 452.0, 452.0, 451.0, 451.0, 451.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 9900 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9903, "number_of_timesteps": 208383, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4572 3 visits [452.0, 452.0, 452.0, 452.0, 451.0, 451.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 9903 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4573 4 visits [452.0, 452.0, 452.0, 452.0, 452.0, 451.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 9905 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4574 5 visits [452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 9908 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4575 6 visits [452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 451.0, 500.0, 451.0]  episode_count: 9909 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4576 7 visits [452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 500.0, 451.0]  episode_count: 9910 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4577 9 visits [452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 9912 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9915, "number_of_timesteps": 208661, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4578 0 visits [453.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 9915 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4579 1 visits [453.0, 453.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 9919 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4580 2 visits [453.0, 453.0, 453.0, 452.0, 452.0, 452.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 9919 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4581 3 visits [453.0, 453.0, 453.0, 453.0, 452.0, 452.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 9921 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4582 4 visits [453.0, 453.0, 453.0, 453.0, 453.0, 452.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 9924 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4583 5 visits [453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 9924 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9928, "number_of_timesteps": 208938, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4584 6 visits [453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 452.0, 500.0, 452.0]  episode_count: 9928 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4585 7 visits [453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 500.0, 452.0]  episode_count: 9930 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4586 9 visits [453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 9930 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4587 0 visits [454.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 9937 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9938, "number_of_timesteps": 209134, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4588 1 visits [454.0, 454.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 9938 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4589 2 visits [454.0, 454.0, 454.0, 453.0, 453.0, 453.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 9940 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4590 3 visits [454.0, 454.0, 454.0, 454.0, 453.0, 453.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 9945 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4591 4 visits [454.0, 454.0, 454.0, 454.0, 454.0, 453.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 9946 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4592 5 visits [454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 9946 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9949, "number_of_timesteps": 209325, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4593 6 visits [454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 453.0, 500.0, 453.0]  episode_count: 9949 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4594 7 visits [454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 500.0, 453.0]  episode_count: 9951 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4595 9 visits [454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 9953 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4596 0 visits [455.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 9954 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4597 1 visits [455.0, 455.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 9958 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9959, "number_of_timesteps": 209506, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4598 2 visits [455.0, 455.0, 455.0, 454.0, 454.0, 454.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 9959 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4599 3 visits [455.0, 455.0, 455.0, 455.0, 454.0, 454.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 9960 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4600 4 visits [455.0, 455.0, 455.0, 455.0, 455.0, 454.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 9963 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4601 5 visits [455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 9965 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4602 6 visits [455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 454.0, 500.0, 454.0]  episode_count: 9966 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9969, "number_of_timesteps": 209785, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4603 7 visits [455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 500.0, 454.0]  episode_count: 9969 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4604 9 visits [455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 9970 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4605 0 visits [456.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 9974 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4606 1 visits [456.0, 456.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 9976 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4607 2 visits [456.0, 456.0, 456.0, 455.0, 455.0, 455.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 9976 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4608 3 visits [456.0, 456.0, 456.0, 456.0, 455.0, 455.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 9977 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9980, "number_of_timesteps": 210027, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4609 4 visits [456.0, 456.0, 456.0, 456.0, 456.0, 455.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 9980 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4610 5 visits [456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 9982 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4611 6 visits [456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 455.0, 500.0, 455.0]  episode_count: 9986 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4612 7 visits [456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 500.0, 455.0]  episode_count: 9987 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 9990, "number_of_timesteps": 210263, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4613 9 visits [456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 9990 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4614 0 visits [457.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 9992 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4615 1 visits [457.0, 457.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 9992 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4616 2 visits [457.0, 457.0, 457.0, 456.0, 456.0, 456.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 9995 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4617 3 visits [457.0, 457.0, 457.0, 457.0, 456.0, 456.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 9996 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4618 4 visits [457.0, 457.0, 457.0, 457.0, 457.0, 456.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 9998 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10002, "number_of_timesteps": 210548, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4619 5 visits [457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 10002 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4620 6 visits [457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 456.0, 500.0, 456.0]  episode_count: 10003 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4621 7 visits [457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 500.0, 456.0]  episode_count: 10007 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4622 9 visits [457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 10011 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4623 0 visits [458.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 10011 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10015, "number_of_timesteps": 210789, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4624 1 visits [458.0, 458.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 10015 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4625 2 visits [458.0, 458.0, 458.0, 457.0, 457.0, 457.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 10016 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4626 3 visits [458.0, 458.0, 458.0, 458.0, 457.0, 457.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 10020 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4627 4 visits [458.0, 458.0, 458.0, 458.0, 458.0, 457.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 10023 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10026, "number_of_timesteps": 210969, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4628 5 visits [458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 10026 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4629 6 visits [458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 457.0, 500.0, 457.0]  episode_count: 10028 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4630 7 visits [458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 500.0, 457.0]  episode_count: 10028 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4631 9 visits [458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 10033 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4632 0 visits [459.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 10034 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4633 1 visits [459.0, 459.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 10034 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4634 2 visits [459.0, 459.0, 459.0, 458.0, 458.0, 458.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 10035 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10038, "number_of_timesteps": 211163, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4635 3 visits [459.0, 459.0, 459.0, 459.0, 458.0, 458.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 10038 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4636 4 visits [459.0, 459.0, 459.0, 459.0, 459.0, 458.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 10040 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4637 5 visits [459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 10042 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4638 6 visits [459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 458.0, 500.0, 458.0]  episode_count: 10044 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10048, "number_of_timesteps": 211464, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4639 7 visits [459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 500.0, 458.0]  episode_count: 10048 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4640 9 visits [459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 10050 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4641 0 visits [460.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 10051 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4642 1 visits [460.0, 460.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 10054 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4643 2 visits [460.0, 460.0, 460.0, 459.0, 459.0, 459.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 10056 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10058, "number_of_timesteps": 211691, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4644 3 visits [460.0, 460.0, 460.0, 460.0, 459.0, 459.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 10058 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4645 4 visits [460.0, 460.0, 460.0, 460.0, 460.0, 459.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 10062 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4646 5 visits [460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 10062 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4647 6 visits [460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 459.0, 500.0, 459.0]  episode_count: 10066 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4648 7 visits [460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 500.0, 459.0]  episode_count: 10067 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10069, "number_of_timesteps": 211899, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4649 9 visits [460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 10069 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4650 0 visits [461.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 10071 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4651 1 visits [461.0, 461.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 10073 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4652 2 visits [461.0, 461.0, 461.0, 460.0, 460.0, 460.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 10077 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4653 3 visits [461.0, 461.0, 461.0, 461.0, 460.0, 460.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 10078 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10082, "number_of_timesteps": 212183, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4654 4 visits [461.0, 461.0, 461.0, 461.0, 461.0, 460.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 10082 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4655 5 visits [461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 10084 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4656 6 visits [461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 460.0, 500.0, 460.0]  episode_count: 10087 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4657 7 visits [461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 500.0, 460.0]  episode_count: 10089 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4658 9 visits [461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 10090 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10094, "number_of_timesteps": 212388, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4659 0 visits [462.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 10094 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4660 1 visits [462.0, 462.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 10096 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4661 2 visits [462.0, 462.0, 462.0, 461.0, 461.0, 461.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 10099 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4662 3 visits [462.0, 462.0, 462.0, 462.0, 461.0, 461.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 10101 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4663 4 visits [462.0, 462.0, 462.0, 462.0, 462.0, 461.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 10103 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10105, "number_of_timesteps": 212578, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4664 5 visits [462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 10105 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4665 6 visits [462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 461.0, 500.0, 461.0]  episode_count: 10109 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4666 7 visits [462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 500.0, 461.0]  episode_count: 10111 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4667 9 visits [462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 10114 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10116, "number_of_timesteps": 212789, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4668 0 visits [463.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 10116 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4669 1 visits [463.0, 463.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 10116 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4670 2 visits [463.0, 463.0, 463.0, 462.0, 462.0, 462.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 10122 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4671 3 visits [463.0, 463.0, 463.0, 463.0, 462.0, 462.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 10125 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10126, "number_of_timesteps": 212975, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4672 4 visits [463.0, 463.0, 463.0, 463.0, 463.0, 462.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 10126 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4673 5 visits [463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 10129 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4674 6 visits [463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 462.0, 500.0, 462.0]  episode_count: 10131 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4675 7 visits [463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 500.0, 462.0]  episode_count: 10133 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4676 9 visits [463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 10134 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10136, "number_of_timesteps": 213134, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4677 0 visits [464.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 10136 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4678 1 visits [464.0, 464.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 10136 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4679 2 visits [464.0, 464.0, 464.0, 463.0, 463.0, 463.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 10138 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4680 3 visits [464.0, 464.0, 464.0, 464.0, 463.0, 463.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 10141 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4681 4 visits [464.0, 464.0, 464.0, 464.0, 464.0, 463.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 10142 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4682 5 visits [464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 10145 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10148, "number_of_timesteps": 213438, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4683 6 visits [464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 463.0, 500.0, 463.0]  episode_count: 10148 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4684 7 visits [464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 500.0, 463.0]  episode_count: 10151 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4685 9 visits [464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 10152 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4686 0 visits [465.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 10156 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10158, "number_of_timesteps": 213639, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4687 1 visits [465.0, 465.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 10158 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4688 2 visits [465.0, 465.0, 465.0, 464.0, 464.0, 464.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 10158 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4689 3 visits [465.0, 465.0, 465.0, 465.0, 464.0, 464.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 10161 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4690 4 visits [465.0, 465.0, 465.0, 465.0, 465.0, 464.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 10161 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4691 5 visits [465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 10165 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4692 6 visits [465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 464.0, 500.0, 464.0]  episode_count: 10167 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10168, "number_of_timesteps": 213897, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4693 7 visits [465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 500.0, 464.0]  episode_count: 10168 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4694 9 visits [465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 10171 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4695 0 visits [466.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 10174 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4696 1 visits [466.0, 466.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 10175 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4697 2 visits [466.0, 466.0, 466.0, 465.0, 465.0, 465.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 10176 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10181, "number_of_timesteps": 214180, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4698 3 visits [466.0, 466.0, 466.0, 466.0, 465.0, 465.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 10181 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4699 4 visits [466.0, 466.0, 466.0, 466.0, 466.0, 465.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 10183 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4700 5 visits [466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 10186 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4701 6 visits [466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 465.0, 500.0, 465.0]  episode_count: 10189 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10191, "number_of_timesteps": 214351, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4702 7 visits [466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 500.0, 465.0]  episode_count: 10191 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4703 9 visits [466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 10192 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4704 0 visits [467.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 10194 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4705 1 visits [467.0, 467.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 10197 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4706 2 visits [467.0, 467.0, 467.0, 466.0, 466.0, 466.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 10198 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10201, "number_of_timesteps": 214550, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4707 3 visits [467.0, 467.0, 467.0, 467.0, 466.0, 466.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 10201 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4708 4 visits [467.0, 467.0, 467.0, 467.0, 467.0, 466.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 10202 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4709 5 visits [467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 10205 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4710 6 visits [467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 466.0, 500.0, 466.0]  episode_count: 10207 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4711 7 visits [467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 500.0, 466.0]  episode_count: 10208 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10211, "number_of_timesteps": 214716, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4712 9 visits [467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 10211 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4713 0 visits [468.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 10213 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4714 1 visits [468.0, 468.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 10215 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4715 2 visits [468.0, 468.0, 468.0, 467.0, 467.0, 467.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 10219 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10221, "number_of_timesteps": 214930, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4716 3 visits [468.0, 468.0, 468.0, 468.0, 467.0, 467.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 10221 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4717 4 visits [468.0, 468.0, 468.0, 468.0, 468.0, 467.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 10223 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4718 5 visits [468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 10224 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4719 6 visits [468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 467.0, 500.0, 467.0]  episode_count: 10228 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10231, "number_of_timesteps": 215160, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4720 7 visits [468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 500.0, 467.0]  episode_count: 10231 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4721 9 visits [468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 10234 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4722 0 visits [469.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 10234 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4723 1 visits [469.0, 469.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 10238 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4724 2 visits [469.0, 469.0, 469.0, 468.0, 468.0, 468.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 10240 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10242, "number_of_timesteps": 215348, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4725 3 visits [469.0, 469.0, 469.0, 469.0, 468.0, 468.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 10242 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4726 4 visits [469.0, 469.0, 469.0, 469.0, 469.0, 468.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 10243 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4727 5 visits [469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 10246 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4728 6 visits [469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 468.0, 500.0, 468.0]  episode_count: 10247 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4729 7 visits [469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 500.0, 468.0]  episode_count: 10248 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4730 9 visits [469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 10251 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10253, "number_of_timesteps": 215564, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4731 0 visits [470.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 10253 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4732 1 visits [470.0, 470.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 10255 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4733 2 visits [470.0, 470.0, 470.0, 469.0, 469.0, 469.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 10260 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4734 3 visits [470.0, 470.0, 470.0, 470.0, 469.0, 469.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 10261 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10264, "number_of_timesteps": 215809, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4735 4 visits [470.0, 470.0, 470.0, 470.0, 470.0, 469.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 10264 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4736 5 visits [470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 10266 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4737 6 visits [470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 469.0, 500.0, 469.0]  episode_count: 10268 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4738 7 visits [470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 500.0, 469.0]  episode_count: 10268 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4739 9 visits [470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 10272 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10276, "number_of_timesteps": 216055, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4740 0 visits [471.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 10276 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4741 1 visits [471.0, 471.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 10277 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4742 2 visits [471.0, 471.0, 471.0, 470.0, 470.0, 470.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 10279 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4743 3 visits [471.0, 471.0, 471.0, 471.0, 470.0, 470.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 10280 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4744 4 visits [471.0, 471.0, 471.0, 471.0, 471.0, 470.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 10283 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10287, "number_of_timesteps": 216283, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4745 5 visits [471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 10287 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4746 6 visits [471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 470.0, 500.0, 470.0]  episode_count: 10287 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4747 7 visits [471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 500.0, 470.0]  episode_count: 10290 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4748 9 visits [471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 10294 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10297, "number_of_timesteps": 216469, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4749 0 visits [472.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 10297 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4750 1 visits [472.0, 472.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 10297 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4751 2 visits [472.0, 472.0, 472.0, 471.0, 471.0, 471.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 10300 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4752 3 visits [472.0, 472.0, 472.0, 472.0, 471.0, 471.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 10302 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10307, "number_of_timesteps": 216665, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4753 4 visits [472.0, 472.0, 472.0, 472.0, 472.0, 471.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 10307 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4754 5 visits [472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 10308 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4755 6 visits [472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 471.0, 500.0, 471.0]  episode_count: 10309 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4756 7 visits [472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 500.0, 471.0]  episode_count: 10312 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4757 9 visits [472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 10313 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4758 0 visits [473.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 10316 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10319, "number_of_timesteps": 216907, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4759 1 visits [473.0, 473.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 10319 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4760 2 visits [473.0, 473.0, 473.0, 472.0, 472.0, 472.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 10323 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4761 3 visits [473.0, 473.0, 473.0, 473.0, 472.0, 472.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 10326 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4762 4 visits [473.0, 473.0, 473.0, 473.0, 473.0, 472.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 10326 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4763 5 visits [473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 10328 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10330, "number_of_timesteps": 217084, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4764 6 visits [473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 472.0, 500.0, 472.0]  episode_count: 10330 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4765 7 visits [473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 500.0, 472.0]  episode_count: 10332 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4766 9 visits [473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 10333 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4767 0 visits [474.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 10334 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4768 1 visits [474.0, 474.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 10336 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4769 2 visits [474.0, 474.0, 474.0, 473.0, 473.0, 473.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 10339 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10344, "number_of_timesteps": 217464, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4770 3 visits [474.0, 474.0, 474.0, 474.0, 473.0, 473.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 10344 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4771 4 visits [474.0, 474.0, 474.0, 474.0, 474.0, 473.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 10345 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4772 5 visits [474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 10345 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4773 6 visits [474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 473.0, 500.0, 473.0]  episode_count: 10352 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4774 7 visits [474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 500.0, 473.0]  episode_count: 10352 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4775 9 visits [474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 10352 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10355, "number_of_timesteps": 217651, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4776 0 visits [475.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 10355 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4777 1 visits [475.0, 475.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 10358 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4778 2 visits [475.0, 475.0, 475.0, 474.0, 474.0, 474.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 10361 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4779 3 visits [475.0, 475.0, 475.0, 475.0, 474.0, 474.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 10362 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4780 4 visits [475.0, 475.0, 475.0, 475.0, 475.0, 474.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 10362 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4781 5 visits [475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 10364 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10370, "number_of_timesteps": 218001, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4782 6 visits [475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 474.0, 500.0, 474.0]  episode_count: 10370 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4783 7 visits [475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 500.0, 474.0]  episode_count: 10372 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4784 9 visits [475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 10375 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4785 0 visits [476.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 10378 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10382, "number_of_timesteps": 218189, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4786 1 visits [476.0, 476.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 10382 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4787 2 visits [476.0, 476.0, 476.0, 475.0, 475.0, 475.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 10383 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4788 3 visits [476.0, 476.0, 476.0, 476.0, 475.0, 475.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 10384 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4789 4 visits [476.0, 476.0, 476.0, 476.0, 476.0, 475.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 10388 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4790 5 visits [476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 10390 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4791 6 visits [476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 475.0, 500.0, 475.0]  episode_count: 10391 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10396, "number_of_timesteps": 218424, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4792 7 visits [476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 500.0, 475.0]  episode_count: 10396 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4793 9 visits [476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 10400 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4794 0 visits [477.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 10401 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4795 1 visits [477.0, 477.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 10401 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4796 2 visits [477.0, 477.0, 477.0, 476.0, 476.0, 476.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 10404 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10410, "number_of_timesteps": 218694, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4797 3 visits [477.0, 477.0, 477.0, 477.0, 476.0, 476.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 10410 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4798 4 visits [477.0, 477.0, 477.0, 477.0, 477.0, 476.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 10411 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4799 5 visits [477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 10411 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4800 6 visits [477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 476.0, 500.0, 476.0]  episode_count: 10413 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4801 7 visits [477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 500.0, 476.0]  episode_count: 10416 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4802 9 visits [477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 10418 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4803 0 visits [478.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 10419 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10422, "number_of_timesteps": 218921, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4804 1 visits [478.0, 478.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 10422 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4805 2 visits [478.0, 478.0, 478.0, 477.0, 477.0, 477.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 10424 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4806 3 visits [478.0, 478.0, 478.0, 478.0, 477.0, 477.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 10425 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4807 4 visits [478.0, 478.0, 478.0, 478.0, 478.0, 477.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 10427 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4808 5 visits [478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 10430 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4809 6 visits [478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 477.0, 500.0, 477.0]  episode_count: 10431 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10432, "number_of_timesteps": 219144, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4810 7 visits [478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 500.0, 477.0]  episode_count: 10432 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4811 9 visits [478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 10436 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4812 0 visits [479.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 10436 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4813 1 visits [479.0, 479.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 10437 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4814 2 visits [479.0, 479.0, 479.0, 478.0, 478.0, 478.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 10440 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10443, "number_of_timesteps": 219433, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4815 3 visits [479.0, 479.0, 479.0, 479.0, 478.0, 478.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 10443 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4816 4 visits [479.0, 479.0, 479.0, 479.0, 479.0, 478.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 10443 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4817 5 visits [479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 10446 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4818 6 visits [479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 478.0, 500.0, 478.0]  episode_count: 10446 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4819 7 visits [479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 500.0, 478.0]  episode_count: 10451 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10453, "number_of_timesteps": 219718, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4820 9 visits [479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 10453 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4821 0 visits [480.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 10454 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4822 1 visits [480.0, 480.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 10456 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4823 2 visits [480.0, 480.0, 480.0, 479.0, 479.0, 479.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 10457 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4824 3 visits [480.0, 480.0, 480.0, 480.0, 479.0, 479.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 10458 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4825 4 visits [480.0, 480.0, 480.0, 480.0, 480.0, 479.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 10460 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10464, "number_of_timesteps": 219997, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4826 5 visits [480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 10464 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4827 6 visits [480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 479.0, 500.0, 479.0]  episode_count: 10466 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4828 7 visits [480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 500.0, 479.0]  episode_count: 10469 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4829 9 visits [480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 10470 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4830 0 visits [481.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 10472 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10475, "number_of_timesteps": 220220, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4831 1 visits [481.0, 481.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 10475 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4832 2 visits [481.0, 481.0, 481.0, 480.0, 480.0, 480.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 10477 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4833 3 visits [481.0, 481.0, 481.0, 481.0, 480.0, 480.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 10479 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4834 4 visits [481.0, 481.0, 481.0, 481.0, 481.0, 480.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 10481 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4835 5 visits [481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 10482 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10485, "number_of_timesteps": 220405, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4836 6 visits [481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 480.0, 500.0, 480.0]  episode_count: 10485 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4837 7 visits [481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 500.0, 480.0]  episode_count: 10487 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4838 9 visits [481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 10487 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4839 0 visits [482.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 10489 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4840 1 visits [482.0, 482.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 10491 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4841 2 visits [482.0, 482.0, 482.0, 481.0, 481.0, 481.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 10493 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10497, "number_of_timesteps": 220705, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4842 3 visits [482.0, 482.0, 482.0, 482.0, 481.0, 481.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 10497 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4843 4 visits [482.0, 482.0, 482.0, 482.0, 482.0, 481.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 10499 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4844 5 visits [482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 10501 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4845 6 visits [482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 481.0, 500.0, 481.0]  episode_count: 10503 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4846 7 visits [482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 500.0, 481.0]  episode_count: 10505 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10507, "number_of_timesteps": 220914, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4847 9 visits [482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 10507 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4848 0 visits [483.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 10509 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4849 1 visits [483.0, 483.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 10512 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4850 2 visits [483.0, 483.0, 483.0, 482.0, 482.0, 482.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 10513 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10517, "number_of_timesteps": 221131, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4851 3 visits [483.0, 483.0, 483.0, 483.0, 482.0, 482.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 10517 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4852 4 visits [483.0, 483.0, 483.0, 483.0, 483.0, 482.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 10518 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4853 5 visits [483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 10519 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4854 6 visits [483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 482.0, 500.0, 482.0]  episode_count: 10523 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4855 7 visits [483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 500.0, 482.0]  episode_count: 10525 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10527, "number_of_timesteps": 221336, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4856 9 visits [483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 10527 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4857 0 visits [484.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 10530 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4858 1 visits [484.0, 484.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 10530 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4859 2 visits [484.0, 484.0, 484.0, 483.0, 483.0, 483.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 10532 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4860 3 visits [484.0, 484.0, 484.0, 484.0, 483.0, 483.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 10535 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10537, "number_of_timesteps": 221538, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4861 4 visits [484.0, 484.0, 484.0, 484.0, 484.0, 483.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 10537 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4862 5 visits [484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 10540 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4863 6 visits [484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 483.0, 500.0, 483.0]  episode_count: 10541 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4864 7 visits [484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 500.0, 483.0]  episode_count: 10543 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4865 9 visits [484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 10545 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10548, "number_of_timesteps": 221787, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4866 0 visits [485.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 10548 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4867 1 visits [485.0, 485.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 10551 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4868 2 visits [485.0, 485.0, 485.0, 484.0, 484.0, 484.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 10554 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4869 3 visits [485.0, 485.0, 485.0, 485.0, 484.0, 484.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 10555 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4870 4 visits [485.0, 485.0, 485.0, 485.0, 485.0, 484.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 10556 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10559, "number_of_timesteps": 221959, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4871 5 visits [485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 10559 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4872 6 visits [485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 484.0, 500.0, 484.0]  episode_count: 10563 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4873 7 visits [485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 500.0, 484.0]  episode_count: 10566 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10569, "number_of_timesteps": 222163, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4874 9 visits [485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 10569 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4875 0 visits [486.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 10571 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4876 1 visits [486.0, 486.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 10575 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4877 2 visits [486.0, 486.0, 486.0, 485.0, 485.0, 485.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 10577 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4878 3 visits [486.0, 486.0, 486.0, 486.0, 485.0, 485.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 10578 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10580, "number_of_timesteps": 222361, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4879 4 visits [486.0, 486.0, 486.0, 486.0, 486.0, 485.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 10580 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4880 5 visits [486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 10582 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4881 6 visits [486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 485.0, 500.0, 485.0]  episode_count: 10585 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4882 7 visits [486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 500.0, 485.0]  episode_count: 10587 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4883 9 visits [486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 10589 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4884 0 visits [487.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 10589 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10590, "number_of_timesteps": 222543, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4885 1 visits [487.0, 487.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 10590 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4886 2 visits [487.0, 487.0, 487.0, 486.0, 486.0, 486.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 10596 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4887 3 visits [487.0, 487.0, 487.0, 487.0, 486.0, 486.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 10599 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10600, "number_of_timesteps": 222799, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 4888 4 visits [487.0, 487.0, 487.0, 487.0, 487.0, 486.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 10600 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4889 5 visits [487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 10602 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4890 6 visits [487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 486.0, 500.0, 486.0]  episode_count: 10605 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4891 7 visits [487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 500.0, 486.0]  episode_count: 10607 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10610, "number_of_timesteps": 222970, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4892 9 visits [487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 10610 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4893 0 visits [488.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 10611 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4894 1 visits [488.0, 488.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 10612 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4895 2 visits [488.0, 488.0, 488.0, 487.0, 487.0, 487.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 10615 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4896 3 visits [488.0, 488.0, 488.0, 488.0, 487.0, 487.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 10617 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4897 4 visits [488.0, 488.0, 488.0, 488.0, 488.0, 487.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 10617 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4898 5 visits [488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 10618 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10623, "number_of_timesteps": 223285, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4899 6 visits [488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 487.0, 500.0, 487.0]  episode_count: 10623 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4900 7 visits [488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 500.0, 487.0]  episode_count: 10624 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4901 9 visits [488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 10625 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4902 0 visits [489.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 10626 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4903 1 visits [489.0, 489.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 10629 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4904 2 visits [489.0, 489.0, 489.0, 488.0, 488.0, 488.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 10630 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4905 3 visits [489.0, 489.0, 489.0, 489.0, 488.0, 488.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 10630 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10634, "number_of_timesteps": 223583, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 4906 4 visits [489.0, 489.0, 489.0, 489.0, 489.0, 488.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 10634 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4907 5 visits [489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 10636 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4908 6 visits [489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 488.0, 500.0, 488.0]  episode_count: 10637 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4909 7 visits [489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 500.0, 488.0]  episode_count: 10638 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10644, "number_of_timesteps": 223798, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 4910 9 visits [489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 10644 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4911 0 visits [490.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 10645 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4912 1 visits [490.0, 490.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 10645 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4913 2 visits [490.0, 490.0, 490.0, 489.0, 489.0, 489.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 10648 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4914 3 visits [490.0, 490.0, 490.0, 490.0, 489.0, 489.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 10651 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10654, "number_of_timesteps": 224035, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 4915 4 visits [490.0, 490.0, 490.0, 490.0, 490.0, 489.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 10654 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4916 5 visits [490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 10655 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4917 6 visits [490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 489.0, 500.0, 489.0]  episode_count: 10658 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4918 7 visits [490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 500.0, 489.0]  episode_count: 10661 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4919 9 visits [490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 10663 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10665, "number_of_timesteps": 224244, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 4920 0 visits [491.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 10665 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4921 1 visits [491.0, 491.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 10667 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4922 2 visits [491.0, 491.0, 491.0, 490.0, 490.0, 490.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 10670 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4923 3 visits [491.0, 491.0, 491.0, 491.0, 490.0, 490.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 10672 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4924 4 visits [491.0, 491.0, 491.0, 491.0, 491.0, 490.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 10673 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10676, "number_of_timesteps": 224472, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 4925 5 visits [491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 10676 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4926 6 visits [491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 490.0, 500.0, 490.0]  episode_count: 10678 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4927 7 visits [491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 500.0, 490.0]  episode_count: 10679 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4928 9 visits [491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 10681 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4929 0 visits [492.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 10684 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10687, "number_of_timesteps": 224730, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4930 1 visits [492.0, 492.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 10687 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4931 2 visits [492.0, 492.0, 492.0, 491.0, 491.0, 491.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 10688 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4932 3 visits [492.0, 492.0, 492.0, 492.0, 491.0, 491.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 10690 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4933 4 visits [492.0, 492.0, 492.0, 492.0, 492.0, 491.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 10692 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4934 5 visits [492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 10696 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10698, "number_of_timesteps": 224922, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4935 6 visits [492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 491.0, 500.0, 491.0]  episode_count: 10698 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4936 7 visits [492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 500.0, 491.0]  episode_count: 10700 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4937 9 visits [492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 10703 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4938 0 visits [493.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 10706 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10708, "number_of_timesteps": 225149, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4939 1 visits [493.0, 493.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 10708 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4940 2 visits [493.0, 493.0, 493.0, 492.0, 492.0, 492.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 10711 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4941 3 visits [493.0, 493.0, 493.0, 493.0, 492.0, 492.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 10715 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4942 4 visits [493.0, 493.0, 493.0, 493.0, 493.0, 492.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 10717 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10719, "number_of_timesteps": 225331, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 4943 5 visits [493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 10719 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4944 6 visits [493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 492.0, 500.0, 492.0]  episode_count: 10720 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4945 7 visits [493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 500.0, 492.0]  episode_count: 10723 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4946 9 visits [493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 10724 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4947 0 visits [494.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 10725 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4948 1 visits [494.0, 494.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 10727 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10730, "number_of_timesteps": 225543, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4949 2 visits [494.0, 494.0, 494.0, 493.0, 493.0, 493.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 10730 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4950 3 visits [494.0, 494.0, 494.0, 494.0, 493.0, 493.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 10732 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4951 4 visits [494.0, 494.0, 494.0, 494.0, 494.0, 493.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 10732 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4952 5 visits [494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 10734 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4953 6 visits [494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 493.0, 500.0, 493.0]  episode_count: 10735 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4954 7 visits [494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 500.0, 493.0]  episode_count: 10738 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10740, "number_of_timesteps": 225827, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 4955 9 visits [494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 10740 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4956 0 visits [495.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 10744 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4957 1 visits [495.0, 495.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 10745 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4958 2 visits [495.0, 495.0, 495.0, 494.0, 494.0, 494.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 10746 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4959 3 visits [495.0, 495.0, 495.0, 495.0, 494.0, 494.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 10749 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10752, "number_of_timesteps": 226069, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4960 4 visits [495.0, 495.0, 495.0, 495.0, 495.0, 494.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 10752 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4961 5 visits [495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 10754 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4962 6 visits [495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 494.0, 500.0, 494.0]  episode_count: 10754 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4963 7 visits [495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 500.0, 494.0]  episode_count: 10756 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4964 9 visits [495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 10759 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10762, "number_of_timesteps": 226278, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4965 0 visits [496.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 10762 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4966 1 visits [496.0, 496.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 10765 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4967 2 visits [496.0, 496.0, 496.0, 495.0, 495.0, 495.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 10765 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4968 3 visits [496.0, 496.0, 496.0, 496.0, 495.0, 495.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 10768 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10772, "number_of_timesteps": 226530, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4969 4 visits [496.0, 496.0, 496.0, 496.0, 496.0, 495.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 10772 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4970 5 visits [496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 10773 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4971 6 visits [496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 495.0, 500.0, 495.0]  episode_count: 10775 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4972 7 visits [496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 500.0, 495.0]  episode_count: 10778 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4973 9 visits [496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 10780 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10782, "number_of_timesteps": 226734, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4974 0 visits [497.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 10782 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4975 1 visits [497.0, 497.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 10784 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4976 2 visits [497.0, 497.0, 497.0, 496.0, 496.0, 496.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 10787 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4977 3 visits [497.0, 497.0, 497.0, 497.0, 496.0, 496.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 10788 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4978 4 visits [497.0, 497.0, 497.0, 497.0, 497.0, 496.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 10789 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4979 5 visits [497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 10790 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10794, "number_of_timesteps": 226990, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4980 6 visits [497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 496.0, 500.0, 496.0]  episode_count: 10794 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4981 7 visits [497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 500.0, 496.0]  episode_count: 10795 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4982 9 visits [497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 10797 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4983 0 visits [498.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 10799 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10804, "number_of_timesteps": 227206, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 4984 1 visits [498.0, 498.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 10804 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4985 2 visits [498.0, 498.0, 498.0, 497.0, 497.0, 497.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 10806 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4986 3 visits [498.0, 498.0, 498.0, 498.0, 497.0, 497.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 10807 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4987 4 visits [498.0, 498.0, 498.0, 498.0, 498.0, 497.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 10810 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4988 5 visits [498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 10813 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10814, "number_of_timesteps": 227392, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 4989 6 visits [498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 497.0, 500.0, 497.0]  episode_count: 10814 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4990 7 visits [498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 500.0, 497.0]  episode_count: 10818 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4991 9 visits [498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 10819 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4992 0 visits [499.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 10822 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10827, "number_of_timesteps": 227645, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4993 1 visits [499.0, 499.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 10827 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4994 2 visits [499.0, 499.0, 499.0, 498.0, 498.0, 498.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 10827 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4995 3 visits [499.0, 499.0, 499.0, 499.0, 498.0, 498.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 10829 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4996 4 visits [499.0, 499.0, 499.0, 499.0, 499.0, 498.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 10832 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4997 5 visits [499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 10833 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 4998 6 visits [499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 498.0, 500.0, 498.0]  episode_count: 10835 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10837, "number_of_timesteps": 227844, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 4999 7 visits [499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 500.0, 498.0]  episode_count: 10837 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5000 9 visits [499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 500.0, 499.0]  episode_count: 10837 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5001 0 visits [500.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 10841 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5002 1 visits [500.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 10843 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5003 2 visits [500.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 10845 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10848, "number_of_timesteps": 228067, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 1.8000000000000007},
Step 5004 3 visits [500.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 10848 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5005 4 visits [500.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 10849 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5006 5 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 10849 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5007 6 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 500.0, 0.0]  episode_count: 10854 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5008 7 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0, 0.0]  episode_count: 10855 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5009 9 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 10857 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10860, "number_of_timesteps": 228324, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 1.8000000000000007},
Step 5010 1 visits [500.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 10860 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5011 2 visits [500.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 10862 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5012 3 visits [500.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 10865 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5013 4 visits [500.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 10867 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5014 5 visits [500.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 500.0, 1.0]  episode_count: 10867 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5015 6 visits [500.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 500.0, 1.0]  episode_count: 10868 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5016 7 visits [500.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 500.0, 1.0]  episode_count: 10869 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10871, "number_of_timesteps": 228556, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.019444444444444445, "biggest_recent_change": 1.8000000000000007},
Step 5017 9 visits [500.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 10871 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5018 1 visits [500.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 10876 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5019 2 visits [500.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 10876 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5020 3 visits [500.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 10880 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5021 4 visits [500.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 10880 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10881, "number_of_timesteps": 228879, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.8000000000000007},
Step 5022 5 visits [500.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 500.0, 2.0]  episode_count: 10881 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5023 6 visits [500.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 500.0, 2.0]  episode_count: 10886 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5024 7 visits [500.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 500.0, 2.0]  episode_count: 10887 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5025 9 visits [500.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 10890 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10893, "number_of_timesteps": 229151, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 1.8000000000000007},
Step 5026 1 visits [500.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 10893 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5027 2 visits [500.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 10896 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5028 3 visits [500.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 10897 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5029 4 visits [500.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 10901 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10904, "number_of_timesteps": 229332, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.021111111111111136, "biggest_recent_change": 1.8000000000000007},
Step 5030 5 visits [500.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 500.0, 3.0]  episode_count: 10904 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5031 6 visits [500.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 500.0, 3.0]  episode_count: 10905 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5032 7 visits [500.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 500.0, 3.0]  episode_count: 10908 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5033 9 visits [500.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 10910 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5034 1 visits [500.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 10913 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10915, "number_of_timesteps": 229508, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.021111111111111136, "biggest_recent_change": 1.8000000000000007},
Step 5035 2 visits [500.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 10915 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5036 3 visits [500.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 10915 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5037 4 visits [500.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 10918 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5038 5 visits [500.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 4.0, 500.0, 4.0]  episode_count: 10922 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5039 6 visits [500.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.0, 500.0, 4.0]  episode_count: 10923 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10925, "number_of_timesteps": 229752, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.021111111111111136, "biggest_recent_change": 1.8000000000000007},
Step 5040 7 visits [500.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 500.0, 4.0]  episode_count: 10925 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5041 9 visits [500.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 10927 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5042 1 visits [500.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 10929 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5043 2 visits [500.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 10932 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10935, "number_of_timesteps": 229936, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.021111111111111136, "biggest_recent_change": 1.8000000000000007},
Step 5044 3 visits [500.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 10935 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5045 4 visits [500.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 10938 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5046 5 visits [500.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 5.0, 500.0, 5.0]  episode_count: 10939 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5047 6 visits [500.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.0, 500.0, 5.0]  episode_count: 10943 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5048 7 visits [500.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 500.0, 5.0]  episode_count: 10944 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10946, "number_of_timesteps": 230154, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 5049 9 visits [500.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 10946 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5050 1 visits [500.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 10948 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5051 2 visits [500.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 10951 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5052 3 visits [500.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 10955 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10956, "number_of_timesteps": 230353, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 5053 4 visits [500.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 10956 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5054 5 visits [500.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 500.0, 6.0]  episode_count: 10957 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5055 6 visits [500.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 6.0, 500.0, 6.0]  episode_count: 10961 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5056 7 visits [500.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 500.0, 6.0]  episode_count: 10965 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10967, "number_of_timesteps": 230561, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 5057 9 visits [500.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 10967 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5058 1 visits [500.0, 8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 10970 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5059 2 visits [500.0, 8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 10971 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5060 3 visits [500.0, 8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 10972 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5061 4 visits [500.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 10976 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10978, "number_of_timesteps": 230740, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 5062 5 visits [500.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 7.0, 500.0, 7.0]  episode_count: 10978 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5063 6 visits [500.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 500.0, 7.0]  episode_count: 10979 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5064 7 visits [500.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 500.0, 7.0]  episode_count: 10980 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5065 9 visits [500.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 10981 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5066 1 visits [500.0, 9.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 10985 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5067 2 visits [500.0, 9.0, 9.0, 8.0, 8.0, 8.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 10986 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10988, "number_of_timesteps": 230973, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 5068 3 visits [500.0, 9.0, 9.0, 9.0, 8.0, 8.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 10988 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5069 4 visits [500.0, 9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 10989 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5070 5 visits [500.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 500.0, 8.0]  episode_count: 10991 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5071 6 visits [500.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 8.0, 500.0, 8.0]  episode_count: 10995 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 10998, "number_of_timesteps": 231255, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5072 7 visits [500.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 500.0, 8.0]  episode_count: 10998 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5073 9 visits [500.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 10998 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5074 1 visits [500.0, 10.0, 9.0, 9.0, 9.0, 9.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 11002 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5075 2 visits [500.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 11004 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5076 3 visits [500.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 11005 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5077 4 visits [500.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 11006 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11008, "number_of_timesteps": 231448, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5078 5 visits [500.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 9.0, 500.0, 9.0]  episode_count: 11008 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5079 6 visits [500.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 500.0, 9.0]  episode_count: 11012 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5080 7 visits [500.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 500.0, 9.0]  episode_count: 11012 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5081 9 visits [500.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 11015 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11018, "number_of_timesteps": 231692, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5082 1 visits [500.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 11018 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5083 2 visits [500.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 11018 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5084 3 visits [500.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 11020 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5085 4 visits [500.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 11023 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5086 5 visits [500.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 10.0, 500.0, 10.0]  episode_count: 11025 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5087 6 visits [500.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 10.0, 500.0, 10.0]  episode_count: 11026 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5088 7 visits [500.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 500.0, 10.0]  episode_count: 11026 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11031, "number_of_timesteps": 232001, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5089 9 visits [500.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 11031 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5090 1 visits [500.0, 12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 11032 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5091 2 visits [500.0, 12.0, 12.0, 11.0, 11.0, 11.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 11035 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5092 3 visits [500.0, 12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 11037 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5093 4 visits [500.0, 12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 11038 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11041, "number_of_timesteps": 232227, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5094 5 visits [500.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 11.0, 500.0, 11.0]  episode_count: 11041 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5095 6 visits [500.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 11.0, 500.0, 11.0]  episode_count: 11044 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5096 7 visits [500.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 500.0, 11.0]  episode_count: 11044 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5097 9 visits [500.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 11048 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11051, "number_of_timesteps": 232411, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 5098 1 visits [500.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 11051 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5099 2 visits [500.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 11053 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5100 3 visits [500.0, 13.0, 13.0, 13.0, 12.0, 12.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 11054 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5101 4 visits [500.0, 13.0, 13.0, 13.0, 13.0, 12.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 11057 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5102 5 visits [500.0, 13.0, 13.0, 13.0, 13.0, 13.0, 12.0, 12.0, 500.0, 12.0]  episode_count: 11058 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5103 6 visits [500.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 12.0, 500.0, 12.0]  episode_count: 11059 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11064, "number_of_timesteps": 232713, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 5104 7 visits [500.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 500.0, 12.0]  episode_count: 11064 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5105 9 visits [500.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 11064 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5106 1 visits [500.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 11067 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5107 2 visits [500.0, 14.0, 14.0, 13.0, 13.0, 13.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 11071 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5108 3 visits [500.0, 14.0, 14.0, 14.0, 13.0, 13.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 11073 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11075, "number_of_timesteps": 232918, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 5109 4 visits [500.0, 14.0, 14.0, 14.0, 14.0, 13.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 11075 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5110 5 visits [500.0, 14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 13.0, 500.0, 13.0]  episode_count: 11076 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5111 6 visits [500.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 13.0, 500.0, 13.0]  episode_count: 11080 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5112 7 visits [500.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 500.0, 13.0]  episode_count: 11082 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11085, "number_of_timesteps": 233108, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 5113 9 visits [500.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 11085 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5114 1 visits [500.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 11086 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5115 2 visits [500.0, 15.0, 15.0, 14.0, 14.0, 14.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 11089 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5116 3 visits [500.0, 15.0, 15.0, 15.0, 14.0, 14.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 11093 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5117 4 visits [500.0, 15.0, 15.0, 15.0, 15.0, 14.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 11094 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11097, "number_of_timesteps": 233353, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 5118 5 visits [500.0, 15.0, 15.0, 15.0, 15.0, 15.0, 14.0, 14.0, 500.0, 14.0]  episode_count: 11097 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5119 6 visits [500.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 14.0, 500.0, 14.0]  episode_count: 11100 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5120 7 visits [500.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 500.0, 14.0]  episode_count: 11102 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5121 9 visits [500.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 11104 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5122 1 visits [500.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 11104 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5123 2 visits [500.0, 16.0, 16.0, 15.0, 15.0, 15.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 11106 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11107, "number_of_timesteps": 233540, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 5124 3 visits [500.0, 16.0, 16.0, 16.0, 15.0, 15.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 11107 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5125 4 visits [500.0, 16.0, 16.0, 16.0, 16.0, 15.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 11112 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5126 5 visits [500.0, 16.0, 16.0, 16.0, 16.0, 16.0, 15.0, 15.0, 500.0, 15.0]  episode_count: 11113 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5127 6 visits [500.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 15.0, 500.0, 15.0]  episode_count: 11114 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11117, "number_of_timesteps": 233755, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 5128 7 visits [500.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 500.0, 15.0]  episode_count: 11117 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5129 9 visits [500.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 11118 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5130 1 visits [500.0, 17.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 11120 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5131 2 visits [500.0, 17.0, 17.0, 16.0, 16.0, 16.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 11125 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11127, "number_of_timesteps": 234006, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 5132 3 visits [500.0, 17.0, 17.0, 17.0, 16.0, 16.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 11127 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5133 4 visits [500.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 11129 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5134 5 visits [500.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 16.0, 500.0, 16.0]  episode_count: 11131 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5135 6 visits [500.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 16.0, 500.0, 16.0]  episode_count: 11135 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5136 7 visits [500.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 500.0, 16.0]  episode_count: 11136 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11140, "number_of_timesteps": 234229, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 5137 9 visits [500.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 11140 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5138 1 visits [500.0, 18.0, 17.0, 17.0, 17.0, 17.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 11144 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5139 2 visits [500.0, 18.0, 18.0, 17.0, 17.0, 17.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 11144 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5140 3 visits [500.0, 18.0, 18.0, 18.0, 17.0, 17.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 11146 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11150, "number_of_timesteps": 234370, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 5141 4 visits [500.0, 18.0, 18.0, 18.0, 18.0, 17.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 11150 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5142 5 visits [500.0, 18.0, 18.0, 18.0, 18.0, 18.0, 17.0, 17.0, 500.0, 17.0]  episode_count: 11152 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5143 6 visits [500.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 17.0, 500.0, 17.0]  episode_count: 11153 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5144 7 visits [500.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 500.0, 17.0]  episode_count: 11154 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5145 9 visits [500.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 11157 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5146 1 visits [500.0, 19.0, 18.0, 18.0, 18.0, 18.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 11159 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11163, "number_of_timesteps": 234650, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 5147 2 visits [500.0, 19.0, 19.0, 18.0, 18.0, 18.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 11163 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5148 3 visits [500.0, 19.0, 19.0, 19.0, 18.0, 18.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 11164 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5149 4 visits [500.0, 19.0, 19.0, 19.0, 19.0, 18.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 11166 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5150 5 visits [500.0, 19.0, 19.0, 19.0, 19.0, 19.0, 18.0, 18.0, 500.0, 18.0]  episode_count: 11169 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11173, "number_of_timesteps": 234864, "per_episode_reward": 14.05, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
Step 5151 6 visits [500.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 18.0, 500.0, 18.0]  episode_count: 11173 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5152 7 visits [500.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 500.0, 18.0]  episode_count: 11175 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5153 9 visits [500.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 11178 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5154 1 visits [500.0, 20.0, 19.0, 19.0, 19.0, 19.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 11179 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5155 2 visits [500.0, 20.0, 20.0, 19.0, 19.0, 19.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 11181 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11183, "number_of_timesteps": 235005, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 5156 3 visits [500.0, 20.0, 20.0, 20.0, 19.0, 19.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 11183 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5157 4 visits [500.0, 20.0, 20.0, 20.0, 20.0, 19.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 11183 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5158 5 visits [500.0, 20.0, 20.0, 20.0, 20.0, 20.0, 19.0, 19.0, 500.0, 19.0]  episode_count: 11185 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5159 6 visits [500.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 19.0, 500.0, 19.0]  episode_count: 11188 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5160 7 visits [500.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 500.0, 19.0]  episode_count: 11190 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5161 9 visits [500.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 11191 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11195, "number_of_timesteps": 235336, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 5162 1 visits [500.0, 21.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 11195 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5163 2 visits [500.0, 21.0, 21.0, 20.0, 20.0, 20.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 11197 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5164 3 visits [500.0, 21.0, 21.0, 21.0, 20.0, 20.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 11198 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5165 4 visits [500.0, 21.0, 21.0, 21.0, 21.0, 20.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 11202 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5166 5 visits [500.0, 21.0, 21.0, 21.0, 21.0, 21.0, 20.0, 20.0, 500.0, 20.0]  episode_count: 11203 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11205, "number_of_timesteps": 235515, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 5167 6 visits [500.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 20.0, 500.0, 20.0]  episode_count: 11205 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5168 7 visits [500.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 500.0, 20.0]  episode_count: 11206 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5169 9 visits [500.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 11211 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5170 1 visits [500.0, 22.0, 21.0, 21.0, 21.0, 21.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 11212 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5171 2 visits [500.0, 22.0, 22.0, 21.0, 21.0, 21.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 11213 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11216, "number_of_timesteps": 235770, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 5172 3 visits [500.0, 22.0, 22.0, 22.0, 21.0, 21.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 11216 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5173 4 visits [500.0, 22.0, 22.0, 22.0, 22.0, 21.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 11217 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5174 5 visits [500.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 21.0, 500.0, 21.0]  episode_count: 11219 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5175 6 visits [500.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 21.0, 500.0, 21.0]  episode_count: 11221 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5176 7 visits [500.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 500.0, 21.0]  episode_count: 11223 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11226, "number_of_timesteps": 235978, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 5177 9 visits [500.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 11226 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5178 1 visits [500.0, 23.0, 22.0, 22.0, 22.0, 22.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 11230 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5179 2 visits [500.0, 23.0, 23.0, 22.0, 22.0, 22.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 11233 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5180 3 visits [500.0, 23.0, 23.0, 23.0, 22.0, 22.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 11233 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11237, "number_of_timesteps": 236210, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 5181 4 visits [500.0, 23.0, 23.0, 23.0, 23.0, 22.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 11237 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5182 5 visits [500.0, 23.0, 23.0, 23.0, 23.0, 23.0, 22.0, 22.0, 500.0, 22.0]  episode_count: 11239 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5183 6 visits [500.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 22.0, 500.0, 22.0]  episode_count: 11242 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5184 7 visits [500.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 500.0, 22.0]  episode_count: 11243 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5185 9 visits [500.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 11246 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11248, "number_of_timesteps": 236403, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 5186 1 visits [500.0, 24.0, 23.0, 23.0, 23.0, 23.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 11248 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5187 2 visits [500.0, 24.0, 24.0, 23.0, 23.0, 23.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 11250 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5188 3 visits [500.0, 24.0, 24.0, 24.0, 23.0, 23.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 11253 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5189 4 visits [500.0, 24.0, 24.0, 24.0, 24.0, 23.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 11256 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11260, "number_of_timesteps": 236647, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 5190 5 visits [500.0, 24.0, 24.0, 24.0, 24.0, 24.0, 23.0, 23.0, 500.0, 23.0]  episode_count: 11260 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5191 6 visits [500.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 23.0, 500.0, 23.0]  episode_count: 11260 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5192 7 visits [500.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 500.0, 23.0]  episode_count: 11264 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5193 9 visits [500.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 11267 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5194 1 visits [500.0, 25.0, 24.0, 24.0, 24.0, 24.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 11269 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11271, "number_of_timesteps": 236833, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 5195 2 visits [500.0, 25.0, 25.0, 24.0, 24.0, 24.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 11271 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5196 3 visits [500.0, 25.0, 25.0, 25.0, 24.0, 24.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 11274 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5197 4 visits [500.0, 25.0, 25.0, 25.0, 25.0, 24.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 11276 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11281, "number_of_timesteps": 236988, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5198 5 visits [500.0, 25.0, 25.0, 25.0, 25.0, 25.0, 24.0, 24.0, 500.0, 24.0]  episode_count: 11281 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5199 6 visits [500.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 24.0, 500.0, 24.0]  episode_count: 11282 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5200 7 visits [500.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 500.0, 24.0]  episode_count: 11282 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5201 9 visits [500.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 11285 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5202 1 visits [500.0, 26.0, 25.0, 25.0, 25.0, 25.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 11288 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5203 2 visits [500.0, 26.0, 26.0, 25.0, 25.0, 25.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 11290 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5204 3 visits [500.0, 26.0, 26.0, 26.0, 25.0, 25.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 11290 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11292, "number_of_timesteps": 237219, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5205 4 visits [500.0, 26.0, 26.0, 26.0, 26.0, 25.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 11292 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5206 5 visits [500.0, 26.0, 26.0, 26.0, 26.0, 26.0, 25.0, 25.0, 500.0, 25.0]  episode_count: 11296 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5207 6 visits [500.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 25.0, 500.0, 25.0]  episode_count: 11298 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5208 7 visits [500.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 500.0, 25.0]  episode_count: 11301 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11304, "number_of_timesteps": 237482, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5209 9 visits [500.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 11304 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5210 1 visits [500.0, 27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 11307 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5211 2 visits [500.0, 27.0, 27.0, 26.0, 26.0, 26.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 11309 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5212 3 visits [500.0, 27.0, 27.0, 27.0, 26.0, 26.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 11310 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11316, "number_of_timesteps": 237672, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5213 4 visits [500.0, 27.0, 27.0, 27.0, 27.0, 26.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 11316 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5214 5 visits [500.0, 27.0, 27.0, 27.0, 27.0, 27.0, 26.0, 26.0, 500.0, 26.0]  episode_count: 11317 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5215 6 visits [500.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 26.0, 500.0, 26.0]  episode_count: 11320 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5216 7 visits [500.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 500.0, 26.0]  episode_count: 11323 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5217 9 visits [500.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 11325 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11326, "number_of_timesteps": 237855, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5218 1 visits [500.0, 28.0, 27.0, 27.0, 27.0, 27.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 11326 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5219 2 visits [500.0, 28.0, 28.0, 27.0, 27.0, 27.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 11327 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5220 3 visits [500.0, 28.0, 28.0, 28.0, 27.0, 27.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 11330 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5221 4 visits [500.0, 28.0, 28.0, 28.0, 28.0, 27.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 11331 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5222 5 visits [500.0, 28.0, 28.0, 28.0, 28.0, 28.0, 27.0, 27.0, 500.0, 27.0]  episode_count: 11333 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11337, "number_of_timesteps": 238123, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5223 6 visits [500.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 27.0, 500.0, 27.0]  episode_count: 11337 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5224 7 visits [500.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 500.0, 27.0]  episode_count: 11339 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5225 9 visits [500.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 11339 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5226 1 visits [500.0, 29.0, 28.0, 28.0, 28.0, 28.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 11343 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5227 2 visits [500.0, 29.0, 29.0, 28.0, 28.0, 28.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 11346 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11347, "number_of_timesteps": 238312, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5228 3 visits [500.0, 29.0, 29.0, 29.0, 28.0, 28.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 11347 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5229 4 visits [500.0, 29.0, 29.0, 29.0, 29.0, 28.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 11348 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5230 5 visits [500.0, 29.0, 29.0, 29.0, 29.0, 29.0, 28.0, 28.0, 500.0, 28.0]  episode_count: 11353 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5231 6 visits [500.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 28.0, 500.0, 28.0]  episode_count: 11355 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11359, "number_of_timesteps": 238557, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5232 7 visits [500.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 500.0, 28.0]  episode_count: 11359 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5233 9 visits [500.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 11361 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5234 1 visits [500.0, 30.0, 29.0, 29.0, 29.0, 29.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 11363 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5235 2 visits [500.0, 30.0, 30.0, 29.0, 29.0, 29.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 11367 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11370, "number_of_timesteps": 238716, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5236 3 visits [500.0, 30.0, 30.0, 30.0, 29.0, 29.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 11370 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5237 4 visits [500.0, 30.0, 30.0, 30.0, 30.0, 29.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 11372 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5238 5 visits [500.0, 30.0, 30.0, 30.0, 30.0, 30.0, 29.0, 29.0, 500.0, 29.0]  episode_count: 11376 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5239 6 visits [500.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 29.0, 500.0, 29.0]  episode_count: 11379 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5240 7 visits [500.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 500.0, 29.0]  episode_count: 11379 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11382, "number_of_timesteps": 238896, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5241 9 visits [500.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 11382 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5242 1 visits [500.0, 31.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 11385 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5243 2 visits [500.0, 31.0, 31.0, 30.0, 30.0, 30.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 11387 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5244 3 visits [500.0, 31.0, 31.0, 31.0, 30.0, 30.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 11390 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5245 4 visits [500.0, 31.0, 31.0, 31.0, 31.0, 30.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 11391 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11393, "number_of_timesteps": 239123, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5246 5 visits [500.0, 31.0, 31.0, 31.0, 31.0, 31.0, 30.0, 30.0, 500.0, 30.0]  episode_count: 11393 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5247 6 visits [500.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 30.0, 500.0, 30.0]  episode_count: 11396 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5248 7 visits [500.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 500.0, 30.0]  episode_count: 11397 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5249 9 visits [500.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 11398 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5250 1 visits [500.0, 32.0, 31.0, 31.0, 31.0, 31.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 11400 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11403, "number_of_timesteps": 239308, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5251 2 visits [500.0, 32.0, 32.0, 31.0, 31.0, 31.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 11403 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5252 3 visits [500.0, 32.0, 32.0, 32.0, 31.0, 31.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 11405 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5253 4 visits [500.0, 32.0, 32.0, 32.0, 32.0, 31.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 11405 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5254 5 visits [500.0, 32.0, 32.0, 32.0, 32.0, 32.0, 31.0, 31.0, 500.0, 31.0]  episode_count: 11408 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5255 6 visits [500.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 31.0, 500.0, 31.0]  episode_count: 11411 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11413, "number_of_timesteps": 239585, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5256 7 visits [500.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 500.0, 31.0]  episode_count: 11413 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5257 9 visits [500.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 11416 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5258 1 visits [500.0, 33.0, 32.0, 32.0, 32.0, 32.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 11418 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5259 2 visits [500.0, 33.0, 33.0, 32.0, 32.0, 32.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 11420 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5260 3 visits [500.0, 33.0, 33.0, 33.0, 32.0, 32.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 11422 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11426, "number_of_timesteps": 239838, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5261 4 visits [500.0, 33.0, 33.0, 33.0, 33.0, 32.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 11426 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5262 5 visits [500.0, 33.0, 33.0, 33.0, 33.0, 33.0, 32.0, 32.0, 500.0, 32.0]  episode_count: 11429 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5263 6 visits [500.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 32.0, 500.0, 32.0]  episode_count: 11430 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5264 7 visits [500.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 500.0, 32.0]  episode_count: 11433 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5265 9 visits [500.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 11435 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11437, "number_of_timesteps": 240039, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5266 1 visits [500.0, 34.0, 33.0, 33.0, 33.0, 33.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 11437 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5267 2 visits [500.0, 34.0, 34.0, 33.0, 33.0, 33.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 11440 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5268 3 visits [500.0, 34.0, 34.0, 34.0, 33.0, 33.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 11442 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5269 4 visits [500.0, 34.0, 34.0, 34.0, 34.0, 33.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 11443 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5270 5 visits [500.0, 34.0, 34.0, 34.0, 34.0, 34.0, 33.0, 33.0, 500.0, 33.0]  episode_count: 11443 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11448, "number_of_timesteps": 240245, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5271 6 visits [500.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 33.0, 500.0, 33.0]  episode_count: 11448 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5272 7 visits [500.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 500.0, 33.0]  episode_count: 11452 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5273 9 visits [500.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 11452 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5274 1 visits [500.0, 35.0, 34.0, 34.0, 34.0, 34.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 11456 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11459, "number_of_timesteps": 240486, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5275 2 visits [500.0, 35.0, 35.0, 34.0, 34.0, 34.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 11459 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5276 3 visits [500.0, 35.0, 35.0, 35.0, 34.0, 34.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 11459 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5277 4 visits [500.0, 35.0, 35.0, 35.0, 35.0, 34.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 11461 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5278 5 visits [500.0, 35.0, 35.0, 35.0, 35.0, 35.0, 34.0, 34.0, 500.0, 34.0]  episode_count: 11465 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5279 6 visits [500.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 34.0, 500.0, 34.0]  episode_count: 11466 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5280 7 visits [500.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 500.0, 34.0]  episode_count: 11467 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11469, "number_of_timesteps": 240640, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5281 9 visits [500.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 11469 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5282 1 visits [500.0, 36.0, 35.0, 35.0, 35.0, 35.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 11472 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5283 2 visits [500.0, 36.0, 36.0, 35.0, 35.0, 35.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 11473 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5284 3 visits [500.0, 36.0, 36.0, 36.0, 35.0, 35.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 11476 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5285 4 visits [500.0, 36.0, 36.0, 36.0, 36.0, 35.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 11477 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11481, "number_of_timesteps": 240971, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5286 5 visits [500.0, 36.0, 36.0, 36.0, 36.0, 36.0, 35.0, 35.0, 500.0, 35.0]  episode_count: 11481 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5287 6 visits [500.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 35.0, 500.0, 35.0]  episode_count: 11483 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5288 7 visits [500.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 500.0, 35.0]  episode_count: 11485 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5289 9 visits [500.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 11485 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5290 1 visits [500.0, 37.0, 36.0, 36.0, 36.0, 36.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 11488 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11491, "number_of_timesteps": 241176, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 5291 2 visits [500.0, 37.0, 37.0, 36.0, 36.0, 36.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 11491 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5292 3 visits [500.0, 37.0, 37.0, 37.0, 36.0, 36.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 11493 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5293 4 visits [500.0, 37.0, 37.0, 37.0, 37.0, 36.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 11496 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5294 5 visits [500.0, 37.0, 37.0, 37.0, 37.0, 37.0, 36.0, 36.0, 500.0, 36.0]  episode_count: 11496 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5295 6 visits [500.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 36.0, 500.0, 36.0]  episode_count: 11499 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11502, "number_of_timesteps": 241377, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 5296 7 visits [500.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 500.0, 36.0]  episode_count: 11502 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5297 9 visits [500.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 11504 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5298 1 visits [500.0, 38.0, 37.0, 37.0, 37.0, 37.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 11507 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5299 2 visits [500.0, 38.0, 38.0, 37.0, 37.0, 37.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 11508 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5300 3 visits [500.0, 38.0, 38.0, 38.0, 37.0, 37.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 11510 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11512, "number_of_timesteps": 241618, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 5301 4 visits [500.0, 38.0, 38.0, 38.0, 38.0, 37.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 11512 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5302 5 visits [500.0, 38.0, 38.0, 38.0, 38.0, 38.0, 37.0, 37.0, 500.0, 37.0]  episode_count: 11513 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5303 6 visits [500.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 37.0, 500.0, 37.0]  episode_count: 11517 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5304 7 visits [500.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 500.0, 37.0]  episode_count: 11517 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5305 9 visits [500.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 11518 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11522, "number_of_timesteps": 241844, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 5306 1 visits [500.0, 39.0, 38.0, 38.0, 38.0, 38.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 11522 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5307 2 visits [500.0, 39.0, 39.0, 38.0, 38.0, 38.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 11522 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5308 3 visits [500.0, 39.0, 39.0, 39.0, 38.0, 38.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 11526 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5309 4 visits [500.0, 39.0, 39.0, 39.0, 39.0, 38.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 11530 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5310 5 visits [500.0, 39.0, 39.0, 39.0, 39.0, 39.0, 38.0, 38.0, 500.0, 38.0]  episode_count: 11531 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11533, "number_of_timesteps": 242090, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 5311 6 visits [500.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 38.0, 500.0, 38.0]  episode_count: 11533 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5312 7 visits [500.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 500.0, 38.0]  episode_count: 11538 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5313 9 visits [500.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 11539 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5314 1 visits [500.0, 40.0, 39.0, 39.0, 39.0, 39.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 11540 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11543, "number_of_timesteps": 242239, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 5315 2 visits [500.0, 40.0, 40.0, 39.0, 39.0, 39.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 11543 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5316 3 visits [500.0, 40.0, 40.0, 40.0, 39.0, 39.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 11546 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5317 4 visits [500.0, 40.0, 40.0, 40.0, 40.0, 39.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 11548 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5318 5 visits [500.0, 40.0, 40.0, 40.0, 40.0, 40.0, 39.0, 39.0, 500.0, 39.0]  episode_count: 11550 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11553, "number_of_timesteps": 242449, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 5319 6 visits [500.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 39.0, 500.0, 39.0]  episode_count: 11553 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5320 7 visits [500.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 500.0, 39.0]  episode_count: 11556 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5321 9 visits [500.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 11559 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5322 1 visits [500.0, 41.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 11561 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5323 2 visits [500.0, 41.0, 41.0, 40.0, 40.0, 40.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 11561 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5324 3 visits [500.0, 41.0, 41.0, 41.0, 40.0, 40.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 11562 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11565, "number_of_timesteps": 242672, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 5325 4 visits [500.0, 41.0, 41.0, 41.0, 41.0, 40.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 11565 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5326 5 visits [500.0, 41.0, 41.0, 41.0, 41.0, 41.0, 40.0, 40.0, 500.0, 40.0]  episode_count: 11567 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5327 6 visits [500.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 40.0, 500.0, 40.0]  episode_count: 11568 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5328 7 visits [500.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 500.0, 40.0]  episode_count: 11571 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5329 9 visits [500.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 11572 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5330 1 visits [500.0, 42.0, 41.0, 41.0, 41.0, 41.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 11574 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11576, "number_of_timesteps": 242975, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 5331 2 visits [500.0, 42.0, 42.0, 41.0, 41.0, 41.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 11576 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5332 3 visits [500.0, 42.0, 42.0, 42.0, 41.0, 41.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 11579 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5333 4 visits [500.0, 42.0, 42.0, 42.0, 42.0, 41.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 11581 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5334 5 visits [500.0, 42.0, 42.0, 42.0, 42.0, 42.0, 41.0, 41.0, 500.0, 41.0]  episode_count: 11583 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5335 6 visits [500.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 41.0, 500.0, 41.0]  episode_count: 11585 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11590, "number_of_timesteps": 243278, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 5336 7 visits [500.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 500.0, 41.0]  episode_count: 11590 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5337 9 visits [500.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 11590 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5338 1 visits [500.0, 43.0, 42.0, 42.0, 42.0, 42.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 11590 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5339 2 visits [500.0, 43.0, 43.0, 42.0, 42.0, 42.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 11593 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5340 3 visits [500.0, 43.0, 43.0, 43.0, 42.0, 42.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 11597 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5341 4 visits [500.0, 43.0, 43.0, 43.0, 43.0, 42.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 11598 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11600, "number_of_timesteps": 243480, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5342 5 visits [500.0, 43.0, 43.0, 43.0, 43.0, 43.0, 42.0, 42.0, 500.0, 42.0]  episode_count: 11600 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5343 6 visits [500.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 42.0, 500.0, 42.0]  episode_count: 11600 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5344 7 visits [500.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 500.0, 42.0]  episode_count: 11602 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5345 9 visits [500.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 11605 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5346 1 visits [500.0, 44.0, 43.0, 43.0, 43.0, 43.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 11609 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11611, "number_of_timesteps": 243748, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5347 2 visits [500.0, 44.0, 44.0, 43.0, 43.0, 43.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 11611 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5348 3 visits [500.0, 44.0, 44.0, 44.0, 43.0, 43.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 11614 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5349 4 visits [500.0, 44.0, 44.0, 44.0, 44.0, 43.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 11616 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5350 5 visits [500.0, 44.0, 44.0, 44.0, 44.0, 44.0, 43.0, 43.0, 500.0, 43.0]  episode_count: 11617 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5351 6 visits [500.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 43.0, 500.0, 43.0]  episode_count: 11619 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11621, "number_of_timesteps": 243925, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5352 7 visits [500.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 500.0, 43.0]  episode_count: 11621 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5353 9 visits [500.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 11624 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5354 1 visits [500.0, 45.0, 44.0, 44.0, 44.0, 44.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 11626 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5355 2 visits [500.0, 45.0, 45.0, 44.0, 44.0, 44.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 11627 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5356 3 visits [500.0, 45.0, 45.0, 45.0, 44.0, 44.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 11629 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11631, "number_of_timesteps": 244162, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5357 4 visits [500.0, 45.0, 45.0, 45.0, 45.0, 44.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 11631 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5358 5 visits [500.0, 45.0, 45.0, 45.0, 45.0, 45.0, 44.0, 44.0, 500.0, 44.0]  episode_count: 11632 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5359 6 visits [500.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 44.0, 500.0, 44.0]  episode_count: 11636 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5360 7 visits [500.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 500.0, 44.0]  episode_count: 11637 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5361 9 visits [500.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 11639 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11644, "number_of_timesteps": 244430, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5362 1 visits [500.0, 46.0, 45.0, 45.0, 45.0, 45.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 11644 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5363 2 visits [500.0, 46.0, 46.0, 45.0, 45.0, 45.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 11647 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5364 3 visits [500.0, 46.0, 46.0, 46.0, 45.0, 45.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 11650 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5365 4 visits [500.0, 46.0, 46.0, 46.0, 46.0, 45.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 11651 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5366 5 visits [500.0, 46.0, 46.0, 46.0, 46.0, 46.0, 45.0, 45.0, 500.0, 45.0]  episode_count: 11652 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11654, "number_of_timesteps": 244600, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5367 6 visits [500.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 45.0, 500.0, 45.0]  episode_count: 11654 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5368 7 visits [500.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 500.0, 45.0]  episode_count: 11656 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5369 9 visits [500.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 11659 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5370 1 visits [500.0, 47.0, 46.0, 46.0, 46.0, 46.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 11661 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5371 2 visits [500.0, 47.0, 47.0, 46.0, 46.0, 46.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 11662 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11665, "number_of_timesteps": 244843, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5372 3 visits [500.0, 47.0, 47.0, 47.0, 46.0, 46.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 11665 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5373 4 visits [500.0, 47.0, 47.0, 47.0, 47.0, 46.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 11666 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5374 5 visits [500.0, 47.0, 47.0, 47.0, 47.0, 47.0, 46.0, 46.0, 500.0, 46.0]  episode_count: 11669 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5375 6 visits [500.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 46.0, 500.0, 46.0]  episode_count: 11671 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5376 7 visits [500.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 500.0, 46.0]  episode_count: 11672 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5377 9 visits [500.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 11674 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11676, "number_of_timesteps": 245109, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5378 1 visits [500.0, 48.0, 47.0, 47.0, 47.0, 47.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 11676 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5379 2 visits [500.0, 48.0, 48.0, 47.0, 47.0, 47.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 11678 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5380 3 visits [500.0, 48.0, 48.0, 48.0, 47.0, 47.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 11680 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5381 4 visits [500.0, 48.0, 48.0, 48.0, 48.0, 47.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 11683 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5382 5 visits [500.0, 48.0, 48.0, 48.0, 48.0, 48.0, 47.0, 47.0, 500.0, 47.0]  episode_count: 11685 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11688, "number_of_timesteps": 245397, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5383 6 visits [500.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 47.0, 500.0, 47.0]  episode_count: 11688 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5384 7 visits [500.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 500.0, 47.0]  episode_count: 11692 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5385 9 visits [500.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 11695 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5386 1 visits [500.0, 49.0, 48.0, 48.0, 48.0, 48.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 11695 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11699, "number_of_timesteps": 245549, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5387 2 visits [500.0, 49.0, 49.0, 48.0, 48.0, 48.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 11699 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5388 3 visits [500.0, 49.0, 49.0, 49.0, 48.0, 48.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 11701 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5389 4 visits [500.0, 49.0, 49.0, 49.0, 49.0, 48.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 11702 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5390 5 visits [500.0, 49.0, 49.0, 49.0, 49.0, 49.0, 48.0, 48.0, 500.0, 48.0]  episode_count: 11705 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5391 6 visits [500.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 48.0, 500.0, 48.0]  episode_count: 11707 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11709, "number_of_timesteps": 245717, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5392 7 visits [500.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 500.0, 48.0]  episode_count: 11709 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5393 9 visits [500.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 11711 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5394 1 visits [500.0, 50.0, 49.0, 49.0, 49.0, 49.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 11715 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5395 2 visits [500.0, 50.0, 50.0, 49.0, 49.0, 49.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 11715 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5396 3 visits [500.0, 50.0, 50.0, 50.0, 49.0, 49.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 11717 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11723, "number_of_timesteps": 246024, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5397 4 visits [500.0, 50.0, 50.0, 50.0, 50.0, 49.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 11723 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5398 5 visits [500.0, 50.0, 50.0, 50.0, 50.0, 50.0, 49.0, 49.0, 500.0, 49.0]  episode_count: 11723 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5399 6 visits [500.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 49.0, 500.0, 49.0]  episode_count: 11725 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5400 7 visits [500.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 500.0, 49.0]  episode_count: 11730 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5401 9 visits [500.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 11732 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11733, "number_of_timesteps": 246209, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5402 1 visits [500.0, 51.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 11733 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5403 2 visits [500.0, 51.0, 51.0, 50.0, 50.0, 50.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 11736 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5404 3 visits [500.0, 51.0, 51.0, 51.0, 50.0, 50.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 11738 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5405 4 visits [500.0, 51.0, 51.0, 51.0, 51.0, 50.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 11741 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5406 5 visits [500.0, 51.0, 51.0, 51.0, 51.0, 51.0, 50.0, 50.0, 500.0, 50.0]  episode_count: 11742 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11746, "number_of_timesteps": 246449, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5407 6 visits [500.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 50.0, 500.0, 50.0]  episode_count: 11746 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5408 7 visits [500.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 500.0, 50.0]  episode_count: 11747 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5409 9 visits [500.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 11748 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5410 1 visits [500.0, 52.0, 51.0, 51.0, 51.0, 51.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 11753 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5411 2 visits [500.0, 52.0, 52.0, 51.0, 51.0, 51.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 11754 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11756, "number_of_timesteps": 246678, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5412 3 visits [500.0, 52.0, 52.0, 52.0, 51.0, 51.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 11756 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5413 4 visits [500.0, 52.0, 52.0, 52.0, 52.0, 51.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 11759 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5414 5 visits [500.0, 52.0, 52.0, 52.0, 52.0, 52.0, 51.0, 51.0, 500.0, 51.0]  episode_count: 11762 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5415 6 visits [500.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 51.0, 500.0, 51.0]  episode_count: 11764 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11768, "number_of_timesteps": 246892, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5416 7 visits [500.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 500.0, 51.0]  episode_count: 11768 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5417 9 visits [500.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 11769 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5418 1 visits [500.0, 53.0, 52.0, 52.0, 52.0, 52.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 11772 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5419 2 visits [500.0, 53.0, 53.0, 52.0, 52.0, 52.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 11774 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11778, "number_of_timesteps": 247071, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5420 3 visits [500.0, 53.0, 53.0, 53.0, 52.0, 52.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 11778 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5421 4 visits [500.0, 53.0, 53.0, 53.0, 53.0, 52.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 11780 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5422 5 visits [500.0, 53.0, 53.0, 53.0, 53.0, 53.0, 52.0, 52.0, 500.0, 52.0]  episode_count: 11781 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5423 6 visits [500.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 52.0, 500.0, 52.0]  episode_count: 11783 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11788, "number_of_timesteps": 247245, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5424 7 visits [500.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 500.0, 52.0]  episode_count: 11788 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5425 9 visits [500.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 11788 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5426 1 visits [500.0, 54.0, 53.0, 53.0, 53.0, 53.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 11789 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5427 2 visits [500.0, 54.0, 54.0, 53.0, 53.0, 53.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 11790 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5428 3 visits [500.0, 54.0, 54.0, 54.0, 53.0, 53.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 11793 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5429 4 visits [500.0, 54.0, 54.0, 54.0, 54.0, 53.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 11794 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5430 5 visits [500.0, 54.0, 54.0, 54.0, 54.0, 54.0, 53.0, 53.0, 500.0, 53.0]  episode_count: 11795 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11800, "number_of_timesteps": 247552, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5431 6 visits [500.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 53.0, 500.0, 53.0]  episode_count: 11800 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5432 7 visits [500.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 500.0, 53.0]  episode_count: 11801 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5433 9 visits [500.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 11802 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5434 1 visits [500.0, 55.0, 54.0, 54.0, 54.0, 54.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 11806 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5435 2 visits [500.0, 55.0, 55.0, 54.0, 54.0, 54.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 11808 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11812, "number_of_timesteps": 247837, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5436 3 visits [500.0, 55.0, 55.0, 55.0, 54.0, 54.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 11812 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5437 4 visits [500.0, 55.0, 55.0, 55.0, 55.0, 54.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 11813 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5438 5 visits [500.0, 55.0, 55.0, 55.0, 55.0, 55.0, 54.0, 54.0, 500.0, 54.0]  episode_count: 11815 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5439 6 visits [500.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 54.0, 500.0, 54.0]  episode_count: 11817 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5440 7 visits [500.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 500.0, 54.0]  episode_count: 11818 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11823, "number_of_timesteps": 248043, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5441 9 visits [500.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 11823 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5442 1 visits [500.0, 56.0, 55.0, 55.0, 55.0, 55.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 11824 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5443 2 visits [500.0, 56.0, 56.0, 55.0, 55.0, 55.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 11828 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5444 3 visits [500.0, 56.0, 56.0, 56.0, 55.0, 55.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 11829 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5445 4 visits [500.0, 56.0, 56.0, 56.0, 56.0, 55.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 11831 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11834, "number_of_timesteps": 248244, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5446 5 visits [500.0, 56.0, 56.0, 56.0, 56.0, 56.0, 55.0, 55.0, 500.0, 55.0]  episode_count: 11834 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5447 6 visits [500.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 55.0, 500.0, 55.0]  episode_count: 11836 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5448 7 visits [500.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 500.0, 55.0]  episode_count: 11839 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5449 9 visits [500.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 11839 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5450 1 visits [500.0, 57.0, 56.0, 56.0, 56.0, 56.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 11842 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11845, "number_of_timesteps": 248479, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5451 2 visits [500.0, 57.0, 57.0, 56.0, 56.0, 56.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 11845 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5452 3 visits [500.0, 57.0, 57.0, 57.0, 56.0, 56.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 11846 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5453 4 visits [500.0, 57.0, 57.0, 57.0, 57.0, 56.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 11849 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5454 5 visits [500.0, 57.0, 57.0, 57.0, 57.0, 57.0, 56.0, 56.0, 500.0, 56.0]  episode_count: 11851 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5455 6 visits [500.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 56.0, 500.0, 56.0]  episode_count: 11852 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5456 7 visits [500.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 500.0, 56.0]  episode_count: 11853 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11857, "number_of_timesteps": 248780, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5457 9 visits [500.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 11857 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5458 1 visits [500.0, 58.0, 57.0, 57.0, 57.0, 57.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 11859 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5459 2 visits [500.0, 58.0, 58.0, 57.0, 57.0, 57.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 11862 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5460 3 visits [500.0, 58.0, 58.0, 58.0, 57.0, 57.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 11864 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5461 4 visits [500.0, 58.0, 58.0, 58.0, 58.0, 57.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 11866 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11868, "number_of_timesteps": 248989, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5462 5 visits [500.0, 58.0, 58.0, 58.0, 58.0, 58.0, 57.0, 57.0, 500.0, 57.0]  episode_count: 11868 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5463 6 visits [500.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 57.0, 500.0, 57.0]  episode_count: 11869 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5464 7 visits [500.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 500.0, 57.0]  episode_count: 11870 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5465 9 visits [500.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 11872 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5466 1 visits [500.0, 59.0, 58.0, 58.0, 58.0, 58.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 11873 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11878, "number_of_timesteps": 249228, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5467 2 visits [500.0, 59.0, 59.0, 58.0, 58.0, 58.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 11878 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5468 3 visits [500.0, 59.0, 59.0, 59.0, 58.0, 58.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 11879 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5469 4 visits [500.0, 59.0, 59.0, 59.0, 59.0, 58.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 11881 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5470 5 visits [500.0, 59.0, 59.0, 59.0, 59.0, 59.0, 58.0, 58.0, 500.0, 58.0]  episode_count: 11882 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5471 6 visits [500.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 58.0, 500.0, 58.0]  episode_count: 11884 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11888, "number_of_timesteps": 249473, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5472 7 visits [500.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 500.0, 58.0]  episode_count: 11888 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5473 9 visits [500.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 11888 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5474 1 visits [500.0, 60.0, 59.0, 59.0, 59.0, 59.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 11890 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5475 2 visits [500.0, 60.0, 60.0, 59.0, 59.0, 59.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 11892 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5476 3 visits [500.0, 60.0, 60.0, 60.0, 59.0, 59.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 11894 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5477 4 visits [500.0, 60.0, 60.0, 60.0, 60.0, 59.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 11895 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5478 5 visits [500.0, 60.0, 60.0, 60.0, 60.0, 60.0, 59.0, 59.0, 500.0, 59.0]  episode_count: 11897 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11898, "number_of_timesteps": 249702, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5479 6 visits [500.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 59.0, 500.0, 59.0]  episode_count: 11898 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5480 7 visits [500.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 500.0, 59.0]  episode_count: 11902 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5481 9 visits [500.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 11905 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5482 1 visits [500.0, 61.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 11905 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5483 2 visits [500.0, 61.0, 61.0, 60.0, 60.0, 60.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 11907 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11909, "number_of_timesteps": 249986, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5484 3 visits [500.0, 61.0, 61.0, 61.0, 60.0, 60.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 11909 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5485 4 visits [500.0, 61.0, 61.0, 61.0, 61.0, 60.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 11912 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5486 5 visits [500.0, 61.0, 61.0, 61.0, 61.0, 61.0, 60.0, 60.0, 500.0, 60.0]  episode_count: 11913 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5487 6 visits [500.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 60.0, 500.0, 60.0]  episode_count: 11917 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11919, "number_of_timesteps": 250190, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5488 7 visits [500.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 500.0, 60.0]  episode_count: 11919 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5489 9 visits [500.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 11920 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5490 1 visits [500.0, 62.0, 61.0, 61.0, 61.0, 61.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 11921 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5491 2 visits [500.0, 62.0, 62.0, 61.0, 61.0, 61.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 11924 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5492 3 visits [500.0, 62.0, 62.0, 62.0, 61.0, 61.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 11925 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5493 4 visits [500.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 11927 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11932, "number_of_timesteps": 250460, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5494 5 visits [500.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 500.0, 61.0]  episode_count: 11932 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5495 6 visits [500.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 500.0, 61.0]  episode_count: 11933 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5496 7 visits [500.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 500.0, 61.0]  episode_count: 11934 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5497 9 visits [500.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 11936 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5498 1 visits [500.0, 63.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 11938 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11942, "number_of_timesteps": 250702, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5499 2 visits [500.0, 63.0, 63.0, 62.0, 62.0, 62.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 11942 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5500 3 visits [500.0, 63.0, 63.0, 63.0, 62.0, 62.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 11944 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5501 4 visits [500.0, 63.0, 63.0, 63.0, 63.0, 62.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 11947 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5502 5 visits [500.0, 63.0, 63.0, 63.0, 63.0, 63.0, 62.0, 62.0, 500.0, 62.0]  episode_count: 11949 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5503 6 visits [500.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 62.0, 500.0, 62.0]  episode_count: 11951 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11953, "number_of_timesteps": 250906, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5504 7 visits [500.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 500.0, 62.0]  episode_count: 11953 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5505 9 visits [500.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 11954 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5506 1 visits [500.0, 64.0, 63.0, 63.0, 63.0, 63.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 11956 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5507 2 visits [500.0, 64.0, 64.0, 63.0, 63.0, 63.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 11961 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11963, "number_of_timesteps": 251100, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5508 3 visits [500.0, 64.0, 64.0, 64.0, 63.0, 63.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 11963 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5509 4 visits [500.0, 64.0, 64.0, 64.0, 64.0, 63.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 11963 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5510 5 visits [500.0, 64.0, 64.0, 64.0, 64.0, 64.0, 63.0, 63.0, 500.0, 63.0]  episode_count: 11966 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5511 6 visits [500.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 63.0, 500.0, 63.0]  episode_count: 11970 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5512 7 visits [500.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 500.0, 63.0]  episode_count: 11972 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11975, "number_of_timesteps": 251331, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5513 9 visits [500.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 11975 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5514 1 visits [500.0, 65.0, 64.0, 64.0, 64.0, 64.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 11976 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5515 2 visits [500.0, 65.0, 65.0, 64.0, 64.0, 64.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 11979 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5516 3 visits [500.0, 65.0, 65.0, 65.0, 64.0, 64.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 11982 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5517 4 visits [500.0, 65.0, 65.0, 65.0, 65.0, 64.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 11984 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11987, "number_of_timesteps": 251572, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5518 5 visits [500.0, 65.0, 65.0, 65.0, 65.0, 65.0, 64.0, 64.0, 500.0, 64.0]  episode_count: 11987 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5519 6 visits [500.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 64.0, 500.0, 64.0]  episode_count: 11990 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5520 7 visits [500.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 500.0, 64.0]  episode_count: 11991 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5521 9 visits [500.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 11994 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 11997, "number_of_timesteps": 251743, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5522 1 visits [500.0, 66.0, 65.0, 65.0, 65.0, 65.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 11997 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5523 2 visits [500.0, 66.0, 66.0, 65.0, 65.0, 65.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 11999 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5524 3 visits [500.0, 66.0, 66.0, 66.0, 65.0, 65.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 12001 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5525 4 visits [500.0, 66.0, 66.0, 66.0, 66.0, 65.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 12003 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5526 5 visits [500.0, 66.0, 66.0, 66.0, 66.0, 66.0, 65.0, 65.0, 500.0, 65.0]  episode_count: 12005 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12007, "number_of_timesteps": 251948, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5527 6 visits [500.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 65.0, 500.0, 65.0]  episode_count: 12007 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5528 7 visits [500.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 500.0, 65.0]  episode_count: 12011 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5529 9 visits [500.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 12014 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12017, "number_of_timesteps": 252123, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5530 1 visits [500.0, 67.0, 66.0, 66.0, 66.0, 66.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 12017 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5531 2 visits [500.0, 67.0, 67.0, 66.0, 66.0, 66.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 12019 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5532 3 visits [500.0, 67.0, 67.0, 67.0, 66.0, 66.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 12019 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5533 4 visits [500.0, 67.0, 67.0, 67.0, 67.0, 66.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 12020 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5534 5 visits [500.0, 67.0, 67.0, 67.0, 67.0, 67.0, 66.0, 66.0, 500.0, 66.0]  episode_count: 12024 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5535 6 visits [500.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 66.0, 500.0, 66.0]  episode_count: 12026 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5536 7 visits [500.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 500.0, 66.0]  episode_count: 12026 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12029, "number_of_timesteps": 252331, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5537 9 visits [500.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 12029 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5538 1 visits [500.0, 68.0, 67.0, 67.0, 67.0, 67.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 12032 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5539 2 visits [500.0, 68.0, 68.0, 67.0, 67.0, 67.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 12034 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5540 3 visits [500.0, 68.0, 68.0, 68.0, 67.0, 67.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 12034 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12039, "number_of_timesteps": 252621, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5541 4 visits [500.0, 68.0, 68.0, 68.0, 68.0, 67.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 12039 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5542 5 visits [500.0, 68.0, 68.0, 68.0, 68.0, 68.0, 67.0, 67.0, 500.0, 67.0]  episode_count: 12040 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5543 6 visits [500.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 67.0, 500.0, 67.0]  episode_count: 12043 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5544 7 visits [500.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 500.0, 67.0]  episode_count: 12046 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5545 9 visits [500.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 12047 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5546 1 visits [500.0, 69.0, 68.0, 68.0, 68.0, 68.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 12048 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12051, "number_of_timesteps": 252829, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5547 2 visits [500.0, 69.0, 69.0, 68.0, 68.0, 68.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 12051 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5548 3 visits [500.0, 69.0, 69.0, 69.0, 68.0, 68.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 12051 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5549 4 visits [500.0, 69.0, 69.0, 69.0, 69.0, 68.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 12053 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5550 5 visits [500.0, 69.0, 69.0, 69.0, 69.0, 69.0, 68.0, 68.0, 500.0, 68.0]  episode_count: 12058 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5551 6 visits [500.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 68.0, 500.0, 68.0]  episode_count: 12060 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12062, "number_of_timesteps": 253103, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5552 7 visits [500.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 500.0, 68.0]  episode_count: 12062 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5553 9 visits [500.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 12065 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5554 1 visits [500.0, 70.0, 69.0, 69.0, 69.0, 69.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 12067 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5555 2 visits [500.0, 70.0, 70.0, 69.0, 69.0, 69.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 12067 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5556 3 visits [500.0, 70.0, 70.0, 70.0, 69.0, 69.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 12069 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5557 4 visits [500.0, 70.0, 70.0, 70.0, 70.0, 69.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 12071 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12073, "number_of_timesteps": 253359, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5558 5 visits [500.0, 70.0, 70.0, 70.0, 70.0, 70.0, 69.0, 69.0, 500.0, 69.0]  episode_count: 12073 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5559 6 visits [500.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 69.0, 500.0, 69.0]  episode_count: 12076 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5560 7 visits [500.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 500.0, 69.0]  episode_count: 12079 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5561 9 visits [500.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 12080 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5562 1 visits [500.0, 71.0, 70.0, 70.0, 70.0, 70.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 12082 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12083, "number_of_timesteps": 253579, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5563 2 visits [500.0, 71.0, 71.0, 70.0, 70.0, 70.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 12083 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5564 3 visits [500.0, 71.0, 71.0, 71.0, 70.0, 70.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 12086 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5565 4 visits [500.0, 71.0, 71.0, 71.0, 71.0, 70.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 12088 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5566 5 visits [500.0, 71.0, 71.0, 71.0, 71.0, 71.0, 70.0, 70.0, 500.0, 70.0]  episode_count: 12089 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12094, "number_of_timesteps": 253821, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5567 6 visits [500.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 70.0, 500.0, 70.0]  episode_count: 12094 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5568 7 visits [500.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 500.0, 70.0]  episode_count: 12098 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5569 9 visits [500.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 12098 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5570 1 visits [500.0, 72.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 12101 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5571 2 visits [500.0, 72.0, 72.0, 71.0, 71.0, 71.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 12103 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12104, "number_of_timesteps": 253989, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5572 3 visits [500.0, 72.0, 72.0, 72.0, 71.0, 71.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 12104 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5573 4 visits [500.0, 72.0, 72.0, 72.0, 72.0, 71.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 12107 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5574 5 visits [500.0, 72.0, 72.0, 72.0, 72.0, 72.0, 71.0, 71.0, 500.0, 71.0]  episode_count: 12109 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5575 6 visits [500.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 71.0, 500.0, 71.0]  episode_count: 12112 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12114, "number_of_timesteps": 254208, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5576 7 visits [500.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 500.0, 71.0]  episode_count: 12114 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5577 9 visits [500.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 12117 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5578 1 visits [500.0, 73.0, 72.0, 72.0, 72.0, 72.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 12119 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5579 2 visits [500.0, 73.0, 73.0, 72.0, 72.0, 72.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 12121 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5580 3 visits [500.0, 73.0, 73.0, 73.0, 72.0, 72.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 12122 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12125, "number_of_timesteps": 254400, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5581 4 visits [500.0, 73.0, 73.0, 73.0, 73.0, 72.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 12125 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5582 5 visits [500.0, 73.0, 73.0, 73.0, 73.0, 73.0, 72.0, 72.0, 500.0, 72.0]  episode_count: 12128 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5583 6 visits [500.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 72.0, 500.0, 72.0]  episode_count: 12130 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5584 7 visits [500.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 500.0, 72.0]  episode_count: 12132 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12136, "number_of_timesteps": 254598, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5585 9 visits [500.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 12136 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5586 1 visits [500.0, 74.0, 73.0, 73.0, 73.0, 73.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 12139 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5587 2 visits [500.0, 74.0, 74.0, 73.0, 73.0, 73.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 12142 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5588 3 visits [500.0, 74.0, 74.0, 74.0, 73.0, 73.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 12145 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12149, "number_of_timesteps": 254819, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5589 4 visits [500.0, 74.0, 74.0, 74.0, 74.0, 73.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 12149 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5590 5 visits [500.0, 74.0, 74.0, 74.0, 74.0, 74.0, 73.0, 73.0, 500.0, 73.0]  episode_count: 12149 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5591 6 visits [500.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 73.0, 500.0, 73.0]  episode_count: 12153 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5592 7 visits [500.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 500.0, 73.0]  episode_count: 12154 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5593 9 visits [500.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 12156 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5594 1 visits [500.0, 75.0, 74.0, 74.0, 74.0, 74.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 12158 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12161, "number_of_timesteps": 255034, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5595 2 visits [500.0, 75.0, 75.0, 74.0, 74.0, 74.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 12161 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5596 3 visits [500.0, 75.0, 75.0, 75.0, 74.0, 74.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 12164 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5597 4 visits [500.0, 75.0, 75.0, 75.0, 75.0, 74.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 12167 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5598 5 visits [500.0, 75.0, 75.0, 75.0, 75.0, 75.0, 74.0, 74.0, 500.0, 74.0]  episode_count: 12167 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5599 6 visits [500.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 74.0, 500.0, 74.0]  episode_count: 12169 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12172, "number_of_timesteps": 255253, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5600 7 visits [500.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 500.0, 74.0]  episode_count: 12172 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5601 9 visits [500.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 12175 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5602 1 visits [500.0, 76.0, 75.0, 75.0, 75.0, 75.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 12178 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5603 2 visits [500.0, 76.0, 76.0, 75.0, 75.0, 75.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 12178 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12183, "number_of_timesteps": 255480, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5604 3 visits [500.0, 76.0, 76.0, 76.0, 75.0, 75.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 12183 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5605 4 visits [500.0, 76.0, 76.0, 76.0, 76.0, 75.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 12185 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5606 5 visits [500.0, 76.0, 76.0, 76.0, 76.0, 76.0, 75.0, 75.0, 500.0, 75.0]  episode_count: 12186 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5607 6 visits [500.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 75.0, 500.0, 75.0]  episode_count: 12189 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5608 7 visits [500.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 500.0, 75.0]  episode_count: 12191 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12194, "number_of_timesteps": 255692, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5609 9 visits [500.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 12194 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5610 1 visits [500.0, 77.0, 76.0, 76.0, 76.0, 76.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 12197 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5611 2 visits [500.0, 77.0, 77.0, 76.0, 76.0, 76.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 12198 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5612 3 visits [500.0, 77.0, 77.0, 77.0, 76.0, 76.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 12202 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5613 4 visits [500.0, 77.0, 77.0, 77.0, 77.0, 76.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 12202 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12204, "number_of_timesteps": 255845, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5614 5 visits [500.0, 77.0, 77.0, 77.0, 77.0, 77.0, 76.0, 76.0, 500.0, 76.0]  episode_count: 12204 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5615 6 visits [500.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 76.0, 500.0, 76.0]  episode_count: 12206 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5616 7 visits [500.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 500.0, 76.0]  episode_count: 12209 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5617 9 visits [500.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 12211 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12215, "number_of_timesteps": 256133, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5618 1 visits [500.0, 78.0, 77.0, 77.0, 77.0, 77.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 12215 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5619 2 visits [500.0, 78.0, 78.0, 77.0, 77.0, 77.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 12218 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5620 3 visits [500.0, 78.0, 78.0, 78.0, 77.0, 77.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 12219 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5621 4 visits [500.0, 78.0, 78.0, 78.0, 78.0, 77.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 12221 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12226, "number_of_timesteps": 256307, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5622 5 visits [500.0, 78.0, 78.0, 78.0, 78.0, 78.0, 77.0, 77.0, 500.0, 77.0]  episode_count: 12226 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5623 6 visits [500.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 77.0, 500.0, 77.0]  episode_count: 12227 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5624 7 visits [500.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 500.0, 77.0]  episode_count: 12230 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5625 9 visits [500.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 12234 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12236, "number_of_timesteps": 256480, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5626 1 visits [500.0, 79.0, 78.0, 78.0, 78.0, 78.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 12236 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5627 2 visits [500.0, 79.0, 79.0, 78.0, 78.0, 78.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 12238 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5628 3 visits [500.0, 79.0, 79.0, 79.0, 78.0, 78.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 12239 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5629 4 visits [500.0, 79.0, 79.0, 79.0, 79.0, 78.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 12240 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5630 5 visits [500.0, 79.0, 79.0, 79.0, 79.0, 79.0, 78.0, 78.0, 500.0, 78.0]  episode_count: 12241 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5631 6 visits [500.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 78.0, 500.0, 78.0]  episode_count: 12242 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5632 7 visits [500.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 500.0, 78.0]  episode_count: 12245 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5633 9 visits [500.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 12245 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12248, "number_of_timesteps": 256745, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5634 1 visits [500.0, 80.0, 79.0, 79.0, 79.0, 79.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 12248 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5635 2 visits [500.0, 80.0, 80.0, 79.0, 79.0, 79.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 12250 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5636 3 visits [500.0, 80.0, 80.0, 80.0, 79.0, 79.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 12252 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5637 4 visits [500.0, 80.0, 80.0, 80.0, 80.0, 79.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 12255 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5638 5 visits [500.0, 80.0, 80.0, 80.0, 80.0, 80.0, 79.0, 79.0, 500.0, 79.0]  episode_count: 12257 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12259, "number_of_timesteps": 257014, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5639 6 visits [500.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 79.0, 500.0, 79.0]  episode_count: 12259 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5640 7 visits [500.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 500.0, 79.0]  episode_count: 12261 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5641 9 visits [500.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 12263 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5642 1 visits [500.0, 81.0, 80.0, 80.0, 80.0, 80.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 12264 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5643 2 visits [500.0, 81.0, 81.0, 80.0, 80.0, 80.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 12267 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12269, "number_of_timesteps": 257254, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5644 3 visits [500.0, 81.0, 81.0, 81.0, 80.0, 80.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 12269 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5645 4 visits [500.0, 81.0, 81.0, 81.0, 81.0, 80.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 12272 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5646 5 visits [500.0, 81.0, 81.0, 81.0, 81.0, 81.0, 80.0, 80.0, 500.0, 80.0]  episode_count: 12273 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5647 6 visits [500.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 80.0, 500.0, 80.0]  episode_count: 12275 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5648 7 visits [500.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 500.0, 80.0]  episode_count: 12277 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12280, "number_of_timesteps": 257508, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5649 9 visits [500.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 12280 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5650 1 visits [500.0, 82.0, 81.0, 81.0, 81.0, 81.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 12280 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5651 2 visits [500.0, 82.0, 82.0, 81.0, 81.0, 81.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 12283 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5652 3 visits [500.0, 82.0, 82.0, 82.0, 81.0, 81.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 12284 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5653 4 visits [500.0, 82.0, 82.0, 82.0, 82.0, 81.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 12287 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12290, "number_of_timesteps": 257730, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5654 5 visits [500.0, 82.0, 82.0, 82.0, 82.0, 82.0, 81.0, 81.0, 500.0, 81.0]  episode_count: 12290 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5655 6 visits [500.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 81.0, 500.0, 81.0]  episode_count: 12291 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5656 7 visits [500.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 500.0, 81.0]  episode_count: 12293 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5657 9 visits [500.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 12295 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5658 1 visits [500.0, 83.0, 82.0, 82.0, 82.0, 82.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 12299 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12301, "number_of_timesteps": 257972, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5659 2 visits [500.0, 83.0, 83.0, 82.0, 82.0, 82.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 12301 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5660 3 visits [500.0, 83.0, 83.0, 83.0, 82.0, 82.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 12301 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5661 4 visits [500.0, 83.0, 83.0, 83.0, 83.0, 82.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 12304 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5662 5 visits [500.0, 83.0, 83.0, 83.0, 83.0, 83.0, 82.0, 82.0, 500.0, 82.0]  episode_count: 12306 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5663 6 visits [500.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 82.0, 500.0, 82.0]  episode_count: 12306 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12311, "number_of_timesteps": 258231, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5664 7 visits [500.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 500.0, 82.0]  episode_count: 12311 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5665 9 visits [500.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 12311 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5666 1 visits [500.0, 84.0, 83.0, 83.0, 83.0, 83.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 12314 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5667 2 visits [500.0, 84.0, 84.0, 83.0, 83.0, 83.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 12314 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5668 3 visits [500.0, 84.0, 84.0, 84.0, 83.0, 83.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 12318 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5669 4 visits [500.0, 84.0, 84.0, 84.0, 84.0, 83.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 12318 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5670 5 visits [500.0, 84.0, 84.0, 84.0, 84.0, 84.0, 83.0, 83.0, 500.0, 83.0]  episode_count: 12319 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12326, "number_of_timesteps": 258573, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5671 6 visits [500.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 83.0, 500.0, 83.0]  episode_count: 12326 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5672 7 visits [500.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 500.0, 83.0]  episode_count: 12326 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5673 9 visits [500.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 12327 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5674 1 visits [500.0, 85.0, 84.0, 84.0, 84.0, 84.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 12330 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5675 2 visits [500.0, 85.0, 85.0, 84.0, 84.0, 84.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 12334 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5676 3 visits [500.0, 85.0, 85.0, 85.0, 84.0, 84.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 12335 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12338, "number_of_timesteps": 258815, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5677 4 visits [500.0, 85.0, 85.0, 85.0, 85.0, 84.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 12338 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5678 5 visits [500.0, 85.0, 85.0, 85.0, 85.0, 85.0, 84.0, 84.0, 500.0, 84.0]  episode_count: 12341 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5679 6 visits [500.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 84.0, 500.0, 84.0]  episode_count: 12343 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5680 7 visits [500.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 500.0, 84.0]  episode_count: 12345 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12348, "number_of_timesteps": 258975, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5681 9 visits [500.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 12348 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5682 1 visits [500.0, 86.0, 85.0, 85.0, 85.0, 85.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 12352 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5683 2 visits [500.0, 86.0, 86.0, 85.0, 85.0, 85.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 12353 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5684 3 visits [500.0, 86.0, 86.0, 86.0, 85.0, 85.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 12355 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12359, "number_of_timesteps": 259184, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5685 4 visits [500.0, 86.0, 86.0, 86.0, 86.0, 85.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 12359 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5686 5 visits [500.0, 86.0, 86.0, 86.0, 86.0, 86.0, 85.0, 85.0, 500.0, 85.0]  episode_count: 12362 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5687 6 visits [500.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 85.0, 500.0, 85.0]  episode_count: 12363 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5688 7 visits [500.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 500.0, 85.0]  episode_count: 12365 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5689 9 visits [500.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 12368 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12371, "number_of_timesteps": 259420, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5690 1 visits [500.0, 87.0, 86.0, 86.0, 86.0, 86.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 12371 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5691 2 visits [500.0, 87.0, 87.0, 86.0, 86.0, 86.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 12373 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5692 3 visits [500.0, 87.0, 87.0, 87.0, 86.0, 86.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 12374 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5693 4 visits [500.0, 87.0, 87.0, 87.0, 87.0, 86.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 12375 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5694 5 visits [500.0, 87.0, 87.0, 87.0, 87.0, 87.0, 86.0, 86.0, 500.0, 86.0]  episode_count: 12379 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12382, "number_of_timesteps": 259647, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5695 6 visits [500.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 86.0, 500.0, 86.0]  episode_count: 12382 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5696 7 visits [500.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 500.0, 86.0]  episode_count: 12383 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5697 9 visits [500.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 12386 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5698 1 visits [500.0, 88.0, 87.0, 87.0, 87.0, 87.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 12388 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5699 2 visits [500.0, 88.0, 88.0, 87.0, 87.0, 87.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 12390 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12393, "number_of_timesteps": 259868, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5700 3 visits [500.0, 88.0, 88.0, 88.0, 87.0, 87.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 12393 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5701 4 visits [500.0, 88.0, 88.0, 88.0, 88.0, 87.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 12395 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5702 5 visits [500.0, 88.0, 88.0, 88.0, 88.0, 88.0, 87.0, 87.0, 500.0, 87.0]  episode_count: 12397 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5703 6 visits [500.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 87.0, 500.0, 87.0]  episode_count: 12401 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12403, "number_of_timesteps": 260052, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5704 7 visits [500.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 500.0, 87.0]  episode_count: 12403 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5705 9 visits [500.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 12403 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5706 1 visits [500.0, 89.0, 88.0, 88.0, 88.0, 88.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 12406 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5707 2 visits [500.0, 89.0, 89.0, 88.0, 88.0, 88.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 12410 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12413, "number_of_timesteps": 260208, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5708 3 visits [500.0, 89.0, 89.0, 89.0, 88.0, 88.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 12413 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5709 4 visits [500.0, 89.0, 89.0, 89.0, 89.0, 88.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 12415 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5710 5 visits [500.0, 89.0, 89.0, 89.0, 89.0, 89.0, 88.0, 88.0, 500.0, 88.0]  episode_count: 12416 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5711 6 visits [500.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 88.0, 500.0, 88.0]  episode_count: 12417 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5712 7 visits [500.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 500.0, 88.0]  episode_count: 12420 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5713 9 visits [500.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 12422 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12424, "number_of_timesteps": 260439, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5714 1 visits [500.0, 90.0, 89.0, 89.0, 89.0, 89.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 12424 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5715 2 visits [500.0, 90.0, 90.0, 89.0, 89.0, 89.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 12425 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5716 3 visits [500.0, 90.0, 90.0, 90.0, 89.0, 89.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 12429 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5717 4 visits [500.0, 90.0, 90.0, 90.0, 90.0, 89.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 12429 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5718 5 visits [500.0, 90.0, 90.0, 90.0, 90.0, 90.0, 89.0, 89.0, 500.0, 89.0]  episode_count: 12432 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12437, "number_of_timesteps": 260771, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5719 6 visits [500.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 89.0, 500.0, 89.0]  episode_count: 12437 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5720 7 visits [500.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 500.0, 89.0]  episode_count: 12437 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5721 9 visits [500.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 12440 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5722 1 visits [500.0, 91.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 12443 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5723 2 visits [500.0, 91.0, 91.0, 90.0, 90.0, 90.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 12443 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5724 3 visits [500.0, 91.0, 91.0, 91.0, 90.0, 90.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 12444 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12449, "number_of_timesteps": 260968, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5725 4 visits [500.0, 91.0, 91.0, 91.0, 91.0, 90.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 12449 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5726 5 visits [500.0, 91.0, 91.0, 91.0, 91.0, 91.0, 90.0, 90.0, 500.0, 90.0]  episode_count: 12449 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5727 6 visits [500.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 90.0, 500.0, 90.0]  episode_count: 12452 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5728 7 visits [500.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 500.0, 90.0]  episode_count: 12454 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5729 9 visits [500.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 12456 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5730 1 visits [500.0, 92.0, 91.0, 91.0, 91.0, 91.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 12457 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12461, "number_of_timesteps": 261249, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5731 2 visits [500.0, 92.0, 92.0, 91.0, 91.0, 91.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 12461 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5732 3 visits [500.0, 92.0, 92.0, 92.0, 91.0, 91.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 12461 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5733 4 visits [500.0, 92.0, 92.0, 92.0, 92.0, 91.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 12464 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5734 5 visits [500.0, 92.0, 92.0, 92.0, 92.0, 92.0, 91.0, 91.0, 500.0, 91.0]  episode_count: 12465 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5735 6 visits [500.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 91.0, 500.0, 91.0]  episode_count: 12466 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5736 7 visits [500.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 500.0, 91.0]  episode_count: 12468 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12471, "number_of_timesteps": 261489, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5737 9 visits [500.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 12471 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5738 1 visits [500.0, 93.0, 92.0, 92.0, 92.0, 92.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 12472 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5739 2 visits [500.0, 93.0, 93.0, 92.0, 92.0, 92.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 12474 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5740 3 visits [500.0, 93.0, 93.0, 93.0, 92.0, 92.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 12477 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5741 4 visits [500.0, 93.0, 93.0, 93.0, 93.0, 92.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 12480 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12482, "number_of_timesteps": 261768, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5742 5 visits [500.0, 93.0, 93.0, 93.0, 93.0, 93.0, 92.0, 92.0, 500.0, 92.0]  episode_count: 12482 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5743 6 visits [500.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 92.0, 500.0, 92.0]  episode_count: 12486 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5744 7 visits [500.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 500.0, 92.0]  episode_count: 12490 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5745 9 visits [500.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 12491 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12494, "number_of_timesteps": 261956, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5746 1 visits [500.0, 94.0, 93.0, 93.0, 93.0, 93.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 12494 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5747 2 visits [500.0, 94.0, 94.0, 93.0, 93.0, 93.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 12495 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5748 3 visits [500.0, 94.0, 94.0, 94.0, 93.0, 93.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 12496 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5749 4 visits [500.0, 94.0, 94.0, 94.0, 94.0, 93.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 12499 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12504, "number_of_timesteps": 262164, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5750 5 visits [500.0, 94.0, 94.0, 94.0, 94.0, 94.0, 93.0, 93.0, 500.0, 93.0]  episode_count: 12504 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5751 6 visits [500.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 93.0, 500.0, 93.0]  episode_count: 12505 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5752 7 visits [500.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 500.0, 93.0]  episode_count: 12505 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5753 9 visits [500.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 12508 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5754 1 visits [500.0, 95.0, 94.0, 94.0, 94.0, 94.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 12512 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5755 2 visits [500.0, 95.0, 95.0, 94.0, 94.0, 94.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 12513 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12515, "number_of_timesteps": 262373, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5756 3 visits [500.0, 95.0, 95.0, 95.0, 94.0, 94.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 12515 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5757 4 visits [500.0, 95.0, 95.0, 95.0, 95.0, 94.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 12519 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5758 5 visits [500.0, 95.0, 95.0, 95.0, 95.0, 95.0, 94.0, 94.0, 500.0, 94.0]  episode_count: 12522 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5759 6 visits [500.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 94.0, 500.0, 94.0]  episode_count: 12523 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5760 7 visits [500.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 500.0, 94.0]  episode_count: 12524 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12526, "number_of_timesteps": 262596, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5761 9 visits [500.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 12526 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5762 1 visits [500.0, 96.0, 95.0, 95.0, 95.0, 95.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 12529 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5763 2 visits [500.0, 96.0, 96.0, 95.0, 95.0, 95.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 12530 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5764 3 visits [500.0, 96.0, 96.0, 96.0, 95.0, 95.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 12530 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5765 4 visits [500.0, 96.0, 96.0, 96.0, 96.0, 95.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 12534 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5766 5 visits [500.0, 96.0, 96.0, 96.0, 96.0, 96.0, 95.0, 95.0, 500.0, 95.0]  episode_count: 12535 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12537, "number_of_timesteps": 262879, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5767 6 visits [500.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 95.0, 500.0, 95.0]  episode_count: 12537 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5768 7 visits [500.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 500.0, 95.0]  episode_count: 12540 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5769 9 visits [500.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 12542 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5770 1 visits [500.0, 97.0, 96.0, 96.0, 96.0, 96.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 12542 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5771 2 visits [500.0, 97.0, 97.0, 96.0, 96.0, 96.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 12544 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12548, "number_of_timesteps": 263144, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5772 3 visits [500.0, 97.0, 97.0, 97.0, 96.0, 96.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 12548 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5773 4 visits [500.0, 97.0, 97.0, 97.0, 97.0, 96.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 12550 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5774 5 visits [500.0, 97.0, 97.0, 97.0, 97.0, 97.0, 96.0, 96.0, 500.0, 96.0]  episode_count: 12550 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5775 6 visits [500.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 96.0, 500.0, 96.0]  episode_count: 12552 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5776 7 visits [500.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 500.0, 96.0]  episode_count: 12555 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12558, "number_of_timesteps": 263343, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5777 9 visits [500.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 12558 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5778 1 visits [500.0, 98.0, 97.0, 97.0, 97.0, 97.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 12558 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5779 2 visits [500.0, 98.0, 98.0, 97.0, 97.0, 97.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 12561 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5780 3 visits [500.0, 98.0, 98.0, 98.0, 97.0, 97.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 12563 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5781 4 visits [500.0, 98.0, 98.0, 98.0, 98.0, 97.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 12565 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12568, "number_of_timesteps": 263579, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5782 5 visits [500.0, 98.0, 98.0, 98.0, 98.0, 98.0, 97.0, 97.0, 500.0, 97.0]  episode_count: 12568 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5783 6 visits [500.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 97.0, 500.0, 97.0]  episode_count: 12569 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5784 7 visits [500.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 500.0, 97.0]  episode_count: 12571 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5785 9 visits [500.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 12575 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5786 1 visits [500.0, 99.0, 98.0, 98.0, 98.0, 98.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 12576 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12578, "number_of_timesteps": 263827, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5787 2 visits [500.0, 99.0, 99.0, 98.0, 98.0, 98.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 12578 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5788 3 visits [500.0, 99.0, 99.0, 99.0, 98.0, 98.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 12583 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5789 4 visits [500.0, 99.0, 99.0, 99.0, 99.0, 98.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 12585 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5790 5 visits [500.0, 99.0, 99.0, 99.0, 99.0, 99.0, 98.0, 98.0, 500.0, 98.0]  episode_count: 12587 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12590, "number_of_timesteps": 264038, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5791 6 visits [500.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 98.0, 500.0, 98.0]  episode_count: 12590 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5792 7 visits [500.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 500.0, 98.0]  episode_count: 12590 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5793 9 visits [500.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 12593 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5794 1 visits [500.0, 100.0, 99.0, 99.0, 99.0, 99.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 12594 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5795 2 visits [500.0, 100.0, 100.0, 99.0, 99.0, 99.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 12598 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5796 3 visits [500.0, 100.0, 100.0, 100.0, 99.0, 99.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 12599 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12600, "number_of_timesteps": 264254, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5797 4 visits [500.0, 100.0, 100.0, 100.0, 100.0, 99.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 12600 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5798 5 visits [500.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 99.0, 500.0, 99.0]  episode_count: 12603 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5799 6 visits [500.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 99.0, 500.0, 99.0]  episode_count: 12606 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5800 7 visits [500.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 500.0, 99.0]  episode_count: 12606 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5801 9 visits [500.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 12609 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12612, "number_of_timesteps": 264509, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5802 1 visits [500.0, 101.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 12612 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5803 2 visits [500.0, 101.0, 101.0, 100.0, 100.0, 100.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 12614 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5804 3 visits [500.0, 101.0, 101.0, 101.0, 100.0, 100.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 12614 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5805 4 visits [500.0, 101.0, 101.0, 101.0, 101.0, 100.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 12616 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5806 5 visits [500.0, 101.0, 101.0, 101.0, 101.0, 101.0, 100.0, 100.0, 500.0, 100.0]  episode_count: 12617 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5807 6 visits [500.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 100.0, 500.0, 100.0]  episode_count: 12621 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12624, "number_of_timesteps": 264788, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5808 7 visits [500.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 500.0, 100.0]  episode_count: 12624 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5809 9 visits [500.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 12626 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5810 1 visits [500.0, 102.0, 101.0, 101.0, 101.0, 101.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 12629 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5811 2 visits [500.0, 102.0, 102.0, 101.0, 101.0, 101.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 12631 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5812 3 visits [500.0, 102.0, 102.0, 102.0, 101.0, 101.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 12632 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5813 4 visits [500.0, 102.0, 102.0, 102.0, 102.0, 101.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 12632 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12634, "number_of_timesteps": 264985, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5814 5 visits [500.0, 102.0, 102.0, 102.0, 102.0, 102.0, 101.0, 101.0, 500.0, 101.0]  episode_count: 12634 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5815 6 visits [500.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 101.0, 500.0, 101.0]  episode_count: 12637 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5816 7 visits [500.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 500.0, 101.0]  episode_count: 12640 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5817 9 visits [500.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 12641 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12644, "number_of_timesteps": 265245, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5818 1 visits [500.0, 103.0, 102.0, 102.0, 102.0, 102.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 12644 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5819 2 visits [500.0, 103.0, 103.0, 102.0, 102.0, 102.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 12647 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5820 3 visits [500.0, 103.0, 103.0, 103.0, 102.0, 102.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 12648 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5821 4 visits [500.0, 103.0, 103.0, 103.0, 103.0, 102.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 12651 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12655, "number_of_timesteps": 265437, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5822 5 visits [500.0, 103.0, 103.0, 103.0, 103.0, 103.0, 102.0, 102.0, 500.0, 102.0]  episode_count: 12655 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5823 6 visits [500.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 102.0, 500.0, 102.0]  episode_count: 12655 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5824 7 visits [500.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 500.0, 102.0]  episode_count: 12656 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5825 9 visits [500.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 12660 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5826 1 visits [500.0, 104.0, 103.0, 103.0, 103.0, 103.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 12663 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5827 2 visits [500.0, 104.0, 104.0, 103.0, 103.0, 103.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 12664 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12665, "number_of_timesteps": 265641, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5828 3 visits [500.0, 104.0, 104.0, 104.0, 103.0, 103.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 12665 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5829 4 visits [500.0, 104.0, 104.0, 104.0, 104.0, 103.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 12669 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5830 5 visits [500.0, 104.0, 104.0, 104.0, 104.0, 104.0, 103.0, 103.0, 500.0, 103.0]  episode_count: 12672 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5831 6 visits [500.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 103.0, 500.0, 103.0]  episode_count: 12672 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5832 7 visits [500.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 500.0, 103.0]  episode_count: 12674 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12678, "number_of_timesteps": 265911, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5833 9 visits [500.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 12678 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5834 1 visits [500.0, 105.0, 104.0, 104.0, 104.0, 104.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 12682 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5835 2 visits [500.0, 105.0, 105.0, 104.0, 104.0, 104.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 12683 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5836 3 visits [500.0, 105.0, 105.0, 105.0, 104.0, 104.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 12687 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12689, "number_of_timesteps": 266115, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5837 4 visits [500.0, 105.0, 105.0, 105.0, 105.0, 104.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 12689 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5838 5 visits [500.0, 105.0, 105.0, 105.0, 105.0, 105.0, 104.0, 104.0, 500.0, 104.0]  episode_count: 12690 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5839 6 visits [500.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 104.0, 500.0, 104.0]  episode_count: 12693 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5840 7 visits [500.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 500.0, 104.0]  episode_count: 12694 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5841 9 visits [500.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 12697 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12701, "number_of_timesteps": 266338, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5842 1 visits [500.0, 106.0, 105.0, 105.0, 105.0, 105.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 12701 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5843 2 visits [500.0, 106.0, 106.0, 105.0, 105.0, 105.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 12703 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5844 3 visits [500.0, 106.0, 106.0, 106.0, 105.0, 105.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 12706 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5845 4 visits [500.0, 106.0, 106.0, 106.0, 106.0, 105.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 12710 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5846 5 visits [500.0, 106.0, 106.0, 106.0, 106.0, 106.0, 105.0, 105.0, 500.0, 105.0]  episode_count: 12710 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12712, "number_of_timesteps": 266509, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5847 6 visits [500.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 105.0, 500.0, 105.0]  episode_count: 12712 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5848 7 visits [500.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 500.0, 105.0]  episode_count: 12715 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5849 9 visits [500.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 12717 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5850 1 visits [500.0, 107.0, 106.0, 106.0, 106.0, 106.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 12717 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5851 2 visits [500.0, 107.0, 107.0, 106.0, 106.0, 106.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 12721 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12723, "number_of_timesteps": 266691, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5852 3 visits [500.0, 107.0, 107.0, 107.0, 106.0, 106.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 12723 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5853 4 visits [500.0, 107.0, 107.0, 107.0, 107.0, 106.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 12727 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5854 5 visits [500.0, 107.0, 107.0, 107.0, 107.0, 107.0, 106.0, 106.0, 500.0, 106.0]  episode_count: 12729 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12734, "number_of_timesteps": 266944, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5855 6 visits [500.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 106.0, 500.0, 106.0]  episode_count: 12734 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5856 7 visits [500.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 500.0, 106.0]  episode_count: 12735 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5857 9 visits [500.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 12735 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5858 1 visits [500.0, 108.0, 107.0, 107.0, 107.0, 107.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 12737 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5859 2 visits [500.0, 108.0, 108.0, 107.0, 107.0, 107.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 12741 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5860 3 visits [500.0, 108.0, 108.0, 108.0, 107.0, 107.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 12742 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5861 4 visits [500.0, 108.0, 108.0, 108.0, 108.0, 107.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 12743 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12747, "number_of_timesteps": 267240, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5862 5 visits [500.0, 108.0, 108.0, 108.0, 108.0, 108.0, 107.0, 107.0, 500.0, 107.0]  episode_count: 12747 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5863 6 visits [500.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 107.0, 500.0, 107.0]  episode_count: 12750 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5864 7 visits [500.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 500.0, 107.0]  episode_count: 12752 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5865 9 visits [500.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 12755 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12757, "number_of_timesteps": 267413, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5866 1 visits [500.0, 109.0, 108.0, 108.0, 108.0, 108.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 12757 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5867 2 visits [500.0, 109.0, 109.0, 108.0, 108.0, 108.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 12758 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5868 3 visits [500.0, 109.0, 109.0, 109.0, 108.0, 108.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 12761 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5869 4 visits [500.0, 109.0, 109.0, 109.0, 109.0, 108.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 12765 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12767, "number_of_timesteps": 267609, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5870 5 visits [500.0, 109.0, 109.0, 109.0, 109.0, 109.0, 108.0, 108.0, 500.0, 108.0]  episode_count: 12767 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5871 6 visits [500.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 108.0, 500.0, 108.0]  episode_count: 12769 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5872 7 visits [500.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 500.0, 108.0]  episode_count: 12771 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5873 9 visits [500.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 12773 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5874 1 visits [500.0, 110.0, 109.0, 109.0, 109.0, 109.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 12775 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5875 2 visits [500.0, 110.0, 110.0, 109.0, 109.0, 109.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 12776 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5876 3 visits [500.0, 110.0, 110.0, 110.0, 109.0, 109.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 12776 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12779, "number_of_timesteps": 267832, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5877 4 visits [500.0, 110.0, 110.0, 110.0, 110.0, 109.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 12779 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5878 5 visits [500.0, 110.0, 110.0, 110.0, 110.0, 110.0, 109.0, 109.0, 500.0, 109.0]  episode_count: 12781 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5879 6 visits [500.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 109.0, 500.0, 109.0]  episode_count: 12781 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5880 7 visits [500.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 500.0, 109.0]  episode_count: 12785 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5881 9 visits [500.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 12785 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5882 1 visits [500.0, 111.0, 110.0, 110.0, 110.0, 110.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 12788 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12790, "number_of_timesteps": 268135, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5883 2 visits [500.0, 111.0, 111.0, 110.0, 110.0, 110.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 12790 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5884 3 visits [500.0, 111.0, 111.0, 111.0, 110.0, 110.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 12792 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5885 4 visits [500.0, 111.0, 111.0, 111.0, 111.0, 110.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 12795 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5886 5 visits [500.0, 111.0, 111.0, 111.0, 111.0, 111.0, 110.0, 110.0, 500.0, 110.0]  episode_count: 12798 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5887 6 visits [500.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 110.0, 500.0, 110.0]  episode_count: 12799 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12801, "number_of_timesteps": 268390, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5888 7 visits [500.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 500.0, 110.0]  episode_count: 12801 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5889 9 visits [500.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 12803 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5890 1 visits [500.0, 112.0, 111.0, 111.0, 111.0, 111.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 12807 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5891 2 visits [500.0, 112.0, 112.0, 111.0, 111.0, 111.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 12809 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12813, "number_of_timesteps": 268612, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5892 3 visits [500.0, 112.0, 112.0, 112.0, 111.0, 111.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 12813 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5893 4 visits [500.0, 112.0, 112.0, 112.0, 112.0, 111.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 12814 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5894 5 visits [500.0, 112.0, 112.0, 112.0, 112.0, 112.0, 111.0, 111.0, 500.0, 111.0]  episode_count: 12815 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5895 6 visits [500.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 111.0, 500.0, 111.0]  episode_count: 12819 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5896 7 visits [500.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 500.0, 111.0]  episode_count: 12821 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12823, "number_of_timesteps": 268804, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5897 9 visits [500.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 12823 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5898 1 visits [500.0, 113.0, 112.0, 112.0, 112.0, 112.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 12823 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5899 2 visits [500.0, 113.0, 113.0, 112.0, 112.0, 112.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 12825 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5900 3 visits [500.0, 113.0, 113.0, 113.0, 112.0, 112.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 12827 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5901 4 visits [500.0, 113.0, 113.0, 113.0, 113.0, 112.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 12828 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5902 5 visits [500.0, 113.0, 113.0, 113.0, 113.0, 113.0, 112.0, 112.0, 500.0, 112.0]  episode_count: 12831 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5903 6 visits [500.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 112.0, 500.0, 112.0]  episode_count: 12832 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12833, "number_of_timesteps": 269049, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5904 7 visits [500.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 500.0, 112.0]  episode_count: 12833 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5905 9 visits [500.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 12837 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5906 1 visits [500.0, 114.0, 113.0, 113.0, 113.0, 113.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 12840 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5907 2 visits [500.0, 114.0, 114.0, 113.0, 113.0, 113.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 12840 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12843, "number_of_timesteps": 269258, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5908 3 visits [500.0, 114.0, 114.0, 114.0, 113.0, 113.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 12843 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5909 4 visits [500.0, 114.0, 114.0, 114.0, 114.0, 113.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 12847 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5910 5 visits [500.0, 114.0, 114.0, 114.0, 114.0, 114.0, 113.0, 113.0, 500.0, 113.0]  episode_count: 12848 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5911 6 visits [500.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 113.0, 500.0, 113.0]  episode_count: 12848 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5912 7 visits [500.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 500.0, 113.0]  episode_count: 12852 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12855, "number_of_timesteps": 269481, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5913 9 visits [500.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 12855 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5914 1 visits [500.0, 115.0, 114.0, 114.0, 114.0, 114.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 12857 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5915 2 visits [500.0, 115.0, 115.0, 114.0, 114.0, 114.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 12858 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5916 3 visits [500.0, 115.0, 115.0, 115.0, 114.0, 114.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 12859 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5917 4 visits [500.0, 115.0, 115.0, 115.0, 115.0, 114.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 12862 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5918 5 visits [500.0, 115.0, 115.0, 115.0, 115.0, 115.0, 114.0, 114.0, 500.0, 114.0]  episode_count: 12863 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12867, "number_of_timesteps": 269838, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5919 6 visits [500.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 114.0, 500.0, 114.0]  episode_count: 12867 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5920 7 visits [500.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 500.0, 114.0]  episode_count: 12870 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5921 9 visits [500.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 12871 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5922 1 visits [500.0, 116.0, 115.0, 115.0, 115.0, 115.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 12875 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12877, "number_of_timesteps": 270046, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5923 2 visits [500.0, 116.0, 116.0, 115.0, 115.0, 115.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 12877 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5924 3 visits [500.0, 116.0, 116.0, 116.0, 115.0, 115.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 12879 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5925 4 visits [500.0, 116.0, 116.0, 116.0, 116.0, 115.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 12880 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5926 5 visits [500.0, 116.0, 116.0, 116.0, 116.0, 116.0, 115.0, 115.0, 500.0, 115.0]  episode_count: 12881 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5927 6 visits [500.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 115.0, 500.0, 115.0]  episode_count: 12884 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5928 7 visits [500.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 500.0, 115.0]  episode_count: 12886 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12888, "number_of_timesteps": 270286, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5929 9 visits [500.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 12888 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5930 1 visits [500.0, 117.0, 116.0, 116.0, 116.0, 116.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 12890 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5931 2 visits [500.0, 117.0, 117.0, 116.0, 116.0, 116.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 12892 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5932 3 visits [500.0, 117.0, 117.0, 117.0, 116.0, 116.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 12894 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5933 4 visits [500.0, 117.0, 117.0, 117.0, 117.0, 116.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 12896 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5934 5 visits [500.0, 117.0, 117.0, 117.0, 117.0, 117.0, 116.0, 116.0, 500.0, 116.0]  episode_count: 12897 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12901, "number_of_timesteps": 270564, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5935 6 visits [500.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 116.0, 500.0, 116.0]  episode_count: 12901 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5936 7 visits [500.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 500.0, 116.0]  episode_count: 12902 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5937 9 visits [500.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 12905 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5938 1 visits [500.0, 118.0, 117.0, 117.0, 117.0, 117.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 12908 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5939 2 visits [500.0, 118.0, 118.0, 117.0, 117.0, 117.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 12910 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12912, "number_of_timesteps": 270756, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5940 3 visits [500.0, 118.0, 118.0, 118.0, 117.0, 117.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 12912 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5941 4 visits [500.0, 118.0, 118.0, 118.0, 118.0, 117.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 12915 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5942 5 visits [500.0, 118.0, 118.0, 118.0, 118.0, 118.0, 117.0, 117.0, 500.0, 117.0]  episode_count: 12917 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5943 6 visits [500.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 117.0, 500.0, 117.0]  episode_count: 12918 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5944 7 visits [500.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 500.0, 117.0]  episode_count: 12920 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12924, "number_of_timesteps": 271041, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5945 9 visits [500.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 12924 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5946 1 visits [500.0, 119.0, 118.0, 118.0, 118.0, 118.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 12926 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5947 2 visits [500.0, 119.0, 119.0, 118.0, 118.0, 118.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 12927 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5948 3 visits [500.0, 119.0, 119.0, 119.0, 118.0, 118.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 12929 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5949 4 visits [500.0, 119.0, 119.0, 119.0, 119.0, 118.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 12932 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5950 5 visits [500.0, 119.0, 119.0, 119.0, 119.0, 119.0, 118.0, 118.0, 500.0, 118.0]  episode_count: 12933 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12936, "number_of_timesteps": 271293, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5951 6 visits [500.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 118.0, 500.0, 118.0]  episode_count: 12936 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5952 7 visits [500.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 500.0, 118.0]  episode_count: 12939 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5953 9 visits [500.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 12939 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5954 1 visits [500.0, 120.0, 119.0, 119.0, 119.0, 119.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 12943 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5955 2 visits [500.0, 120.0, 120.0, 119.0, 119.0, 119.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 12944 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5956 3 visits [500.0, 120.0, 120.0, 120.0, 119.0, 119.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 12945 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12949, "number_of_timesteps": 271580, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5957 4 visits [500.0, 120.0, 120.0, 120.0, 120.0, 119.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 12949 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5958 5 visits [500.0, 120.0, 120.0, 120.0, 120.0, 120.0, 119.0, 119.0, 500.0, 119.0]  episode_count: 12951 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5959 6 visits [500.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 119.0, 500.0, 119.0]  episode_count: 12952 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5960 7 visits [500.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 500.0, 119.0]  episode_count: 12956 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5961 9 visits [500.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 12958 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12960, "number_of_timesteps": 271774, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5962 1 visits [500.0, 121.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 12960 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5963 2 visits [500.0, 121.0, 121.0, 120.0, 120.0, 120.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 12963 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5964 3 visits [500.0, 121.0, 121.0, 121.0, 120.0, 120.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 12964 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5965 4 visits [500.0, 121.0, 121.0, 121.0, 121.0, 120.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 12966 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5966 5 visits [500.0, 121.0, 121.0, 121.0, 121.0, 121.0, 120.0, 120.0, 500.0, 120.0]  episode_count: 12967 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12971, "number_of_timesteps": 272021, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5967 6 visits [500.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 120.0, 500.0, 120.0]  episode_count: 12971 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5968 7 visits [500.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 500.0, 120.0]  episode_count: 12972 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5969 9 visits [500.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 12973 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5970 1 visits [500.0, 122.0, 121.0, 121.0, 121.0, 121.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 12976 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5971 2 visits [500.0, 122.0, 122.0, 121.0, 121.0, 121.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 12976 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5972 3 visits [500.0, 122.0, 122.0, 122.0, 121.0, 121.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 12977 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12982, "number_of_timesteps": 272305, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5973 4 visits [500.0, 122.0, 122.0, 122.0, 122.0, 121.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 12982 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5974 5 visits [500.0, 122.0, 122.0, 122.0, 122.0, 122.0, 121.0, 121.0, 500.0, 121.0]  episode_count: 12983 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5975 6 visits [500.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 121.0, 500.0, 121.0]  episode_count: 12985 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5976 7 visits [500.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 500.0, 121.0]  episode_count: 12986 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5977 9 visits [500.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 12989 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 12993, "number_of_timesteps": 272564, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5978 1 visits [500.0, 123.0, 122.0, 122.0, 122.0, 122.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 12993 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5979 2 visits [500.0, 123.0, 123.0, 122.0, 122.0, 122.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 12994 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5980 3 visits [500.0, 123.0, 123.0, 123.0, 122.0, 122.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 12999 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5981 4 visits [500.0, 123.0, 123.0, 123.0, 123.0, 122.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 13002 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13003, "number_of_timesteps": 272736, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5982 5 visits [500.0, 123.0, 123.0, 123.0, 123.0, 123.0, 122.0, 122.0, 500.0, 122.0]  episode_count: 13003 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5983 6 visits [500.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 122.0, 500.0, 122.0]  episode_count: 13007 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5984 7 visits [500.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 500.0, 122.0]  episode_count: 13009 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5985 9 visits [500.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 13010 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13013, "number_of_timesteps": 272893, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5986 1 visits [500.0, 124.0, 123.0, 123.0, 123.0, 123.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 13013 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5987 2 visits [500.0, 124.0, 124.0, 123.0, 123.0, 123.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 13017 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5988 3 visits [500.0, 124.0, 124.0, 124.0, 123.0, 123.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 13019 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5989 4 visits [500.0, 124.0, 124.0, 124.0, 124.0, 123.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 13022 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13023, "number_of_timesteps": 273064, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5990 5 visits [500.0, 124.0, 124.0, 124.0, 124.0, 124.0, 123.0, 123.0, 500.0, 123.0]  episode_count: 13023 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5991 6 visits [500.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 123.0, 500.0, 123.0]  episode_count: 13024 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5992 7 visits [500.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 500.0, 123.0]  episode_count: 13027 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5993 9 visits [500.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 13031 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5994 1 visits [500.0, 125.0, 124.0, 124.0, 124.0, 124.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 13032 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13033, "number_of_timesteps": 273266, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5995 2 visits [500.0, 125.0, 125.0, 124.0, 124.0, 124.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 13033 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5996 3 visits [500.0, 125.0, 125.0, 125.0, 124.0, 124.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 13037 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5997 4 visits [500.0, 125.0, 125.0, 125.0, 125.0, 124.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 13038 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 5998 5 visits [500.0, 125.0, 125.0, 125.0, 125.0, 125.0, 124.0, 124.0, 500.0, 124.0]  episode_count: 13041 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13043, "number_of_timesteps": 273473, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 5999 6 visits [500.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 124.0, 500.0, 124.0]  episode_count: 13043 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6000 7 visits [500.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 500.0, 124.0]  episode_count: 13045 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6001 9 visits [500.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 13046 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6002 1 visits [500.0, 126.0, 125.0, 125.0, 125.0, 125.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 13048 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6003 2 visits [500.0, 126.0, 126.0, 125.0, 125.0, 125.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 13049 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6004 3 visits [500.0, 126.0, 126.0, 126.0, 125.0, 125.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 13051 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13053, "number_of_timesteps": 273708, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6005 4 visits [500.0, 126.0, 126.0, 126.0, 126.0, 125.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 13053 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6006 5 visits [500.0, 126.0, 126.0, 126.0, 126.0, 126.0, 125.0, 125.0, 500.0, 125.0]  episode_count: 13056 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6007 6 visits [500.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 125.0, 500.0, 125.0]  episode_count: 13057 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6008 7 visits [500.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 500.0, 125.0]  episode_count: 13059 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6009 9 visits [500.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 13062 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13065, "number_of_timesteps": 274008, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6010 1 visits [500.0, 127.0, 126.0, 126.0, 126.0, 126.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 13065 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6011 2 visits [500.0, 127.0, 127.0, 126.0, 126.0, 126.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 13068 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6012 3 visits [500.0, 127.0, 127.0, 127.0, 126.0, 126.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 13069 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6013 4 visits [500.0, 127.0, 127.0, 127.0, 127.0, 126.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 13071 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6014 5 visits [500.0, 127.0, 127.0, 127.0, 127.0, 127.0, 126.0, 126.0, 500.0, 126.0]  episode_count: 13074 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13076, "number_of_timesteps": 274235, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6015 6 visits [500.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 126.0, 500.0, 126.0]  episode_count: 13076 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6016 7 visits [500.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 500.0, 126.0]  episode_count: 13077 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6017 9 visits [500.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 13079 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6018 1 visits [500.0, 128.0, 127.0, 127.0, 127.0, 127.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 13083 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6019 2 visits [500.0, 128.0, 128.0, 127.0, 127.0, 127.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 13085 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13087, "number_of_timesteps": 274462, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6020 3 visits [500.0, 128.0, 128.0, 128.0, 127.0, 127.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 13087 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6021 4 visits [500.0, 128.0, 128.0, 128.0, 128.0, 127.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 13090 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6022 5 visits [500.0, 128.0, 128.0, 128.0, 128.0, 128.0, 127.0, 127.0, 500.0, 127.0]  episode_count: 13091 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6023 6 visits [500.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 127.0, 500.0, 127.0]  episode_count: 13092 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6024 7 visits [500.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 500.0, 127.0]  episode_count: 13092 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6025 9 visits [500.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 13095 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13099, "number_of_timesteps": 274751, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6026 1 visits [500.0, 129.0, 128.0, 128.0, 128.0, 128.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 13099 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6027 2 visits [500.0, 129.0, 129.0, 128.0, 128.0, 128.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 13100 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6028 3 visits [500.0, 129.0, 129.0, 129.0, 128.0, 128.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 13101 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6029 4 visits [500.0, 129.0, 129.0, 129.0, 129.0, 128.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 13103 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6030 5 visits [500.0, 129.0, 129.0, 129.0, 129.0, 129.0, 128.0, 128.0, 500.0, 128.0]  episode_count: 13105 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6031 6 visits [500.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 128.0, 500.0, 128.0]  episode_count: 13106 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13109, "number_of_timesteps": 274979, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6032 7 visits [500.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 500.0, 128.0]  episode_count: 13109 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6033 9 visits [500.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 13110 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6034 1 visits [500.0, 130.0, 129.0, 129.0, 129.0, 129.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 13113 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6035 2 visits [500.0, 130.0, 130.0, 129.0, 129.0, 129.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 13115 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6036 3 visits [500.0, 130.0, 130.0, 130.0, 129.0, 129.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 13115 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6037 4 visits [500.0, 130.0, 130.0, 130.0, 130.0, 129.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 13116 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13119, "number_of_timesteps": 275245, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6038 5 visits [500.0, 130.0, 130.0, 130.0, 130.0, 130.0, 129.0, 129.0, 500.0, 129.0]  episode_count: 13119 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6039 6 visits [500.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 129.0, 500.0, 129.0]  episode_count: 13123 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6040 7 visits [500.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 500.0, 129.0]  episode_count: 13125 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6041 9 visits [500.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 13126 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13131, "number_of_timesteps": 275500, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6042 1 visits [500.0, 131.0, 130.0, 130.0, 130.0, 130.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 13131 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6043 2 visits [500.0, 131.0, 131.0, 130.0, 130.0, 130.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 13133 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6044 3 visits [500.0, 131.0, 131.0, 131.0, 130.0, 130.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 13134 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6045 4 visits [500.0, 131.0, 131.0, 131.0, 131.0, 130.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 13137 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6046 5 visits [500.0, 131.0, 131.0, 131.0, 131.0, 131.0, 130.0, 130.0, 500.0, 130.0]  episode_count: 13139 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13141, "number_of_timesteps": 275709, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6047 6 visits [500.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 130.0, 500.0, 130.0]  episode_count: 13141 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6048 7 visits [500.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 500.0, 130.0]  episode_count: 13143 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6049 9 visits [500.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 13145 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6050 1 visits [500.0, 132.0, 131.0, 131.0, 131.0, 131.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 13148 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6051 2 visits [500.0, 132.0, 132.0, 131.0, 131.0, 131.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 13149 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13153, "number_of_timesteps": 275958, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6052 3 visits [500.0, 132.0, 132.0, 132.0, 131.0, 131.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 13153 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6053 4 visits [500.0, 132.0, 132.0, 132.0, 132.0, 131.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 13156 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6054 5 visits [500.0, 132.0, 132.0, 132.0, 132.0, 132.0, 131.0, 131.0, 500.0, 131.0]  episode_count: 13159 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6055 6 visits [500.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 131.0, 500.0, 131.0]  episode_count: 13161 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6056 7 visits [500.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 500.0, 131.0]  episode_count: 13162 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13168, "number_of_timesteps": 276206, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6057 9 visits [500.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 13168 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6058 1 visits [500.0, 133.0, 132.0, 132.0, 132.0, 132.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 13169 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6059 2 visits [500.0, 133.0, 133.0, 132.0, 132.0, 132.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 13170 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6060 3 visits [500.0, 133.0, 133.0, 133.0, 132.0, 132.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 13173 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6061 4 visits [500.0, 133.0, 133.0, 133.0, 133.0, 132.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 13175 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6062 5 visits [500.0, 133.0, 133.0, 133.0, 133.0, 133.0, 132.0, 132.0, 500.0, 132.0]  episode_count: 13176 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13179, "number_of_timesteps": 276441, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6063 6 visits [500.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 132.0, 500.0, 132.0]  episode_count: 13179 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6064 7 visits [500.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 500.0, 132.0]  episode_count: 13181 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6065 9 visits [500.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 13183 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6066 1 visits [500.0, 134.0, 133.0, 133.0, 133.0, 133.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 13184 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6067 2 visits [500.0, 134.0, 134.0, 133.0, 133.0, 133.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 13185 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6068 3 visits [500.0, 134.0, 134.0, 134.0, 133.0, 133.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 13187 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13191, "number_of_timesteps": 276687, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6069 4 visits [500.0, 134.0, 134.0, 134.0, 134.0, 133.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 13191 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6070 5 visits [500.0, 134.0, 134.0, 134.0, 134.0, 134.0, 133.0, 133.0, 500.0, 133.0]  episode_count: 13192 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6071 6 visits [500.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 133.0, 500.0, 133.0]  episode_count: 13195 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6072 7 visits [500.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 500.0, 133.0]  episode_count: 13196 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13201, "number_of_timesteps": 276943, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 6073 9 visits [500.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 13201 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6074 1 visits [500.0, 135.0, 134.0, 134.0, 134.0, 134.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 13203 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6075 2 visits [500.0, 135.0, 135.0, 134.0, 134.0, 134.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 13203 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6076 3 visits [500.0, 135.0, 135.0, 135.0, 134.0, 134.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 13206 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6077 4 visits [500.0, 135.0, 135.0, 135.0, 135.0, 134.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 13210 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13211, "number_of_timesteps": 277115, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 6078 5 visits [500.0, 135.0, 135.0, 135.0, 135.0, 135.0, 134.0, 134.0, 500.0, 134.0]  episode_count: 13211 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6079 6 visits [500.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 134.0, 500.0, 134.0]  episode_count: 13212 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6080 7 visits [500.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 500.0, 134.0]  episode_count: 13214 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6081 9 visits [500.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 13218 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6082 1 visits [500.0, 136.0, 135.0, 135.0, 135.0, 135.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 13219 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6083 2 visits [500.0, 136.0, 136.0, 135.0, 135.0, 135.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 13219 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13221, "number_of_timesteps": 277329, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6084 3 visits [500.0, 136.0, 136.0, 136.0, 135.0, 135.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 13221 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6085 4 visits [500.0, 136.0, 136.0, 136.0, 136.0, 135.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 13224 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6086 5 visits [500.0, 136.0, 136.0, 136.0, 136.0, 136.0, 135.0, 135.0, 500.0, 135.0]  episode_count: 13225 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6087 6 visits [500.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 135.0, 500.0, 135.0]  episode_count: 13227 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13231, "number_of_timesteps": 277573, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6088 7 visits [500.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 500.0, 135.0]  episode_count: 13231 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6089 9 visits [500.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 13232 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6090 1 visits [500.0, 137.0, 136.0, 136.0, 136.0, 136.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 13234 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6091 2 visits [500.0, 137.0, 137.0, 136.0, 136.0, 136.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 13237 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13242, "number_of_timesteps": 277832, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6092 3 visits [500.0, 137.0, 137.0, 137.0, 136.0, 136.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 13242 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6093 4 visits [500.0, 137.0, 137.0, 137.0, 137.0, 136.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 13244 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6094 5 visits [500.0, 137.0, 137.0, 137.0, 137.0, 137.0, 136.0, 136.0, 500.0, 136.0]  episode_count: 13246 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6095 6 visits [500.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 136.0, 500.0, 136.0]  episode_count: 13247 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6096 7 visits [500.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 500.0, 136.0]  episode_count: 13251 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13253, "number_of_timesteps": 278011, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6097 9 visits [500.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 13253 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6098 1 visits [500.0, 138.0, 137.0, 137.0, 137.0, 137.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 13256 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6099 2 visits [500.0, 138.0, 138.0, 137.0, 137.0, 137.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 13257 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6100 3 visits [500.0, 138.0, 138.0, 138.0, 137.0, 137.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 13259 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13263, "number_of_timesteps": 278179, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6101 4 visits [500.0, 138.0, 138.0, 138.0, 138.0, 137.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 13263 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6102 5 visits [500.0, 138.0, 138.0, 138.0, 138.0, 138.0, 137.0, 137.0, 500.0, 137.0]  episode_count: 13265 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6103 6 visits [500.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 137.0, 500.0, 137.0]  episode_count: 13266 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6104 7 visits [500.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 500.0, 137.0]  episode_count: 13270 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13274, "number_of_timesteps": 278397, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6105 9 visits [500.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 13274 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6106 1 visits [500.0, 139.0, 138.0, 138.0, 138.0, 138.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 13274 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6107 2 visits [500.0, 139.0, 139.0, 138.0, 138.0, 138.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 13274 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6108 3 visits [500.0, 139.0, 139.0, 139.0, 138.0, 138.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 13278 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6109 4 visits [500.0, 139.0, 139.0, 139.0, 139.0, 138.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 13281 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6110 5 visits [500.0, 139.0, 139.0, 139.0, 139.0, 139.0, 138.0, 138.0, 500.0, 138.0]  episode_count: 13282 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6111 6 visits [500.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 138.0, 500.0, 138.0]  episode_count: 13283 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13286, "number_of_timesteps": 278647, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6112 7 visits [500.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 500.0, 138.0]  episode_count: 13286 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6113 9 visits [500.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 13289 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6114 1 visits [500.0, 140.0, 139.0, 139.0, 139.0, 139.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 13291 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6115 2 visits [500.0, 140.0, 140.0, 139.0, 139.0, 139.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 13295 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13297, "number_of_timesteps": 278882, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 6116 3 visits [500.0, 140.0, 140.0, 140.0, 139.0, 139.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 13297 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6117 4 visits [500.0, 140.0, 140.0, 140.0, 140.0, 139.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 13299 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6118 5 visits [500.0, 140.0, 140.0, 140.0, 140.0, 140.0, 139.0, 139.0, 500.0, 139.0]  episode_count: 13300 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6119 6 visits [500.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 139.0, 500.0, 139.0]  episode_count: 13303 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13307, "number_of_timesteps": 279049, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 6120 7 visits [500.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 500.0, 139.0]  episode_count: 13307 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6121 9 visits [500.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 13310 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6122 1 visits [500.0, 141.0, 140.0, 140.0, 140.0, 140.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 13311 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6123 2 visits [500.0, 141.0, 141.0, 140.0, 140.0, 140.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 13313 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6124 3 visits [500.0, 141.0, 141.0, 141.0, 140.0, 140.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 13314 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13317, "number_of_timesteps": 279218, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6125 4 visits [500.0, 141.0, 141.0, 141.0, 141.0, 140.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 13317 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6126 5 visits [500.0, 141.0, 141.0, 141.0, 141.0, 141.0, 140.0, 140.0, 500.0, 140.0]  episode_count: 13317 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6127 6 visits [500.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 140.0, 500.0, 140.0]  episode_count: 13323 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6128 7 visits [500.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 500.0, 140.0]  episode_count: 13324 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6129 9 visits [500.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 13325 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13329, "number_of_timesteps": 279509, "per_episode_reward": 14.05, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 6130 1 visits [500.0, 142.0, 141.0, 141.0, 141.0, 141.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 13329 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6131 2 visits [500.0, 142.0, 142.0, 141.0, 141.0, 141.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 13332 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6132 3 visits [500.0, 142.0, 142.0, 142.0, 141.0, 141.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 13334 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6133 4 visits [500.0, 142.0, 142.0, 142.0, 142.0, 141.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 13336 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13339, "number_of_timesteps": 279679, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6134 5 visits [500.0, 142.0, 142.0, 142.0, 142.0, 142.0, 141.0, 141.0, 500.0, 141.0]  episode_count: 13339 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6135 6 visits [500.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 141.0, 500.0, 141.0]  episode_count: 13342 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6136 7 visits [500.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 500.0, 141.0]  episode_count: 13344 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6137 9 visits [500.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 13346 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13350, "number_of_timesteps": 279896, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6138 1 visits [500.0, 143.0, 142.0, 142.0, 142.0, 142.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 13350 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6139 2 visits [500.0, 143.0, 143.0, 142.0, 142.0, 142.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 13350 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6140 3 visits [500.0, 143.0, 143.0, 143.0, 142.0, 142.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 13351 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6141 4 visits [500.0, 143.0, 143.0, 143.0, 143.0, 142.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 13353 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6142 5 visits [500.0, 143.0, 143.0, 143.0, 143.0, 143.0, 142.0, 142.0, 500.0, 142.0]  episode_count: 13354 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6143 6 visits [500.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 142.0, 500.0, 142.0]  episode_count: 13358 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13360, "number_of_timesteps": 280120, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6144 7 visits [500.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 500.0, 142.0]  episode_count: 13360 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6145 9 visits [500.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 13361 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6146 1 visits [500.0, 144.0, 143.0, 143.0, 143.0, 143.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 13362 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6147 2 visits [500.0, 144.0, 144.0, 143.0, 143.0, 143.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 13366 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6148 3 visits [500.0, 144.0, 144.0, 144.0, 143.0, 143.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 13368 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13370, "number_of_timesteps": 280370, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6149 4 visits [500.0, 144.0, 144.0, 144.0, 144.0, 143.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 13370 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6150 5 visits [500.0, 144.0, 144.0, 144.0, 144.0, 144.0, 143.0, 143.0, 500.0, 143.0]  episode_count: 13371 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6151 6 visits [500.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 143.0, 500.0, 143.0]  episode_count: 13375 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6152 7 visits [500.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 500.0, 143.0]  episode_count: 13377 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6153 9 visits [500.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 13379 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13381, "number_of_timesteps": 280584, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6154 1 visits [500.0, 145.0, 144.0, 144.0, 144.0, 144.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 13381 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6155 2 visits [500.0, 145.0, 145.0, 144.0, 144.0, 144.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 13384 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6156 3 visits [500.0, 145.0, 145.0, 145.0, 144.0, 144.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 13385 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6157 4 visits [500.0, 145.0, 145.0, 145.0, 145.0, 144.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 13389 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13391, "number_of_timesteps": 280797, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6158 5 visits [500.0, 145.0, 145.0, 145.0, 145.0, 145.0, 144.0, 144.0, 500.0, 144.0]  episode_count: 13391 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6159 6 visits [500.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 144.0, 500.0, 144.0]  episode_count: 13393 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6160 7 visits [500.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 500.0, 144.0]  episode_count: 13394 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6161 9 visits [500.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 13398 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6162 1 visits [500.0, 146.0, 145.0, 145.0, 145.0, 145.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 13400 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13401, "number_of_timesteps": 280992, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6163 2 visits [500.0, 146.0, 146.0, 145.0, 145.0, 145.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 13401 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6164 3 visits [500.0, 146.0, 146.0, 146.0, 145.0, 145.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 13403 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6165 4 visits [500.0, 146.0, 146.0, 146.0, 146.0, 145.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 13405 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6166 5 visits [500.0, 146.0, 146.0, 146.0, 146.0, 146.0, 145.0, 145.0, 500.0, 145.0]  episode_count: 13406 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6167 6 visits [500.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 145.0, 500.0, 145.0]  episode_count: 13410 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13412, "number_of_timesteps": 281224, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6168 7 visits [500.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 500.0, 145.0]  episode_count: 13412 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6169 9 visits [500.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 13413 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6170 1 visits [500.0, 147.0, 146.0, 146.0, 146.0, 146.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 13417 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6171 2 visits [500.0, 147.0, 147.0, 146.0, 146.0, 146.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 13420 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6172 3 visits [500.0, 147.0, 147.0, 147.0, 146.0, 146.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 13421 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13424, "number_of_timesteps": 281465, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 6173 4 visits [500.0, 147.0, 147.0, 147.0, 147.0, 146.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 13424 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6174 5 visits [500.0, 147.0, 147.0, 147.0, 147.0, 147.0, 146.0, 146.0, 500.0, 146.0]  episode_count: 13428 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6175 6 visits [500.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 146.0, 500.0, 146.0]  episode_count: 13430 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6176 7 visits [500.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 500.0, 146.0]  episode_count: 13430 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6177 9 visits [500.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 13433 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13436, "number_of_timesteps": 281681, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6178 1 visits [500.0, 148.0, 147.0, 147.0, 147.0, 147.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 13436 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6179 2 visits [500.0, 148.0, 148.0, 147.0, 147.0, 147.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 13439 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6180 3 visits [500.0, 148.0, 148.0, 148.0, 147.0, 147.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 13444 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13446, "number_of_timesteps": 281857, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6181 4 visits [500.0, 148.0, 148.0, 148.0, 148.0, 147.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 13446 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6182 5 visits [500.0, 148.0, 148.0, 148.0, 148.0, 148.0, 147.0, 147.0, 500.0, 147.0]  episode_count: 13447 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6183 6 visits [500.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 147.0, 500.0, 147.0]  episode_count: 13449 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6184 7 visits [500.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 500.0, 147.0]  episode_count: 13451 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13456, "number_of_timesteps": 282032, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6185 9 visits [500.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 13456 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6186 1 visits [500.0, 149.0, 148.0, 148.0, 148.0, 148.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 13458 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6187 2 visits [500.0, 149.0, 149.0, 148.0, 148.0, 148.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 13460 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6188 3 visits [500.0, 149.0, 149.0, 149.0, 148.0, 148.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 13463 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6189 4 visits [500.0, 149.0, 149.0, 149.0, 149.0, 148.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 13464 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13466, "number_of_timesteps": 282200, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6190 5 visits [500.0, 149.0, 149.0, 149.0, 149.0, 149.0, 148.0, 148.0, 500.0, 148.0]  episode_count: 13466 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6191 6 visits [500.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 148.0, 500.0, 148.0]  episode_count: 13468 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6192 7 visits [500.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 500.0, 148.0]  episode_count: 13470 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6193 9 visits [500.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 13473 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6194 1 visits [500.0, 150.0, 149.0, 149.0, 149.0, 149.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 13475 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13478, "number_of_timesteps": 282443, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6195 2 visits [500.0, 150.0, 150.0, 149.0, 149.0, 149.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 13478 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6196 3 visits [500.0, 150.0, 150.0, 150.0, 149.0, 149.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 13480 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6197 4 visits [500.0, 150.0, 150.0, 150.0, 150.0, 149.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 13481 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6198 5 visits [500.0, 150.0, 150.0, 150.0, 150.0, 150.0, 149.0, 149.0, 500.0, 149.0]  episode_count: 13486 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6199 6 visits [500.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 149.0, 500.0, 149.0]  episode_count: 13487 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13488, "number_of_timesteps": 282650, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6200 7 visits [500.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 500.0, 149.0]  episode_count: 13488 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6201 9 visits [500.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 13493 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6202 1 visits [500.0, 151.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 13494 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6203 2 visits [500.0, 151.0, 151.0, 150.0, 150.0, 150.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 13495 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6204 3 visits [500.0, 151.0, 151.0, 151.0, 150.0, 150.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 13497 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13499, "number_of_timesteps": 282879, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6205 4 visits [500.0, 151.0, 151.0, 151.0, 151.0, 150.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 13499 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6206 5 visits [500.0, 151.0, 151.0, 151.0, 151.0, 151.0, 150.0, 150.0, 500.0, 150.0]  episode_count: 13503 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6207 6 visits [500.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 150.0, 500.0, 150.0]  episode_count: 13505 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6208 7 visits [500.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 500.0, 150.0]  episode_count: 13505 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6209 9 visits [500.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 13508 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13510, "number_of_timesteps": 283117, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6210 1 visits [500.0, 152.0, 151.0, 151.0, 151.0, 151.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 13510 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6211 2 visits [500.0, 152.0, 152.0, 151.0, 151.0, 151.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 13513 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6212 3 visits [500.0, 152.0, 152.0, 152.0, 151.0, 151.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 13515 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6213 4 visits [500.0, 152.0, 152.0, 152.0, 152.0, 151.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 13518 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13520, "number_of_timesteps": 283312, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6214 5 visits [500.0, 152.0, 152.0, 152.0, 152.0, 152.0, 151.0, 151.0, 500.0, 151.0]  episode_count: 13520 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6215 6 visits [500.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 151.0, 500.0, 151.0]  episode_count: 13522 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6216 7 visits [500.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 500.0, 151.0]  episode_count: 13526 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6217 9 visits [500.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 13526 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6218 1 visits [500.0, 153.0, 152.0, 152.0, 152.0, 152.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 13529 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13531, "number_of_timesteps": 283518, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6219 2 visits [500.0, 153.0, 153.0, 152.0, 152.0, 152.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 13531 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6220 3 visits [500.0, 153.0, 153.0, 153.0, 152.0, 152.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 13534 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6221 4 visits [500.0, 153.0, 153.0, 153.0, 153.0, 152.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 13535 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6222 5 visits [500.0, 153.0, 153.0, 153.0, 153.0, 153.0, 152.0, 152.0, 500.0, 152.0]  episode_count: 13536 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6223 6 visits [500.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 152.0, 500.0, 152.0]  episode_count: 13540 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13543, "number_of_timesteps": 283805, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6224 7 visits [500.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 500.0, 152.0]  episode_count: 13543 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6225 9 visits [500.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 13546 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6226 1 visits [500.0, 154.0, 153.0, 153.0, 153.0, 153.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 13547 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6227 2 visits [500.0, 154.0, 154.0, 153.0, 153.0, 153.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 13548 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6228 3 visits [500.0, 154.0, 154.0, 154.0, 153.0, 153.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 13552 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13553, "number_of_timesteps": 283984, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6229 4 visits [500.0, 154.0, 154.0, 154.0, 154.0, 153.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 13553 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6230 5 visits [500.0, 154.0, 154.0, 154.0, 154.0, 154.0, 153.0, 153.0, 500.0, 153.0]  episode_count: 13556 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6231 6 visits [500.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 153.0, 500.0, 153.0]  episode_count: 13557 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6232 7 visits [500.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 500.0, 153.0]  episode_count: 13559 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6233 9 visits [500.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 13560 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13563, "number_of_timesteps": 284201, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6234 1 visits [500.0, 155.0, 154.0, 154.0, 154.0, 154.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 13563 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6235 2 visits [500.0, 155.0, 155.0, 154.0, 154.0, 154.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 13568 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6236 3 visits [500.0, 155.0, 155.0, 155.0, 154.0, 154.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 13569 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6237 4 visits [500.0, 155.0, 155.0, 155.0, 155.0, 154.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 13571 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13573, "number_of_timesteps": 284398, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6238 5 visits [500.0, 155.0, 155.0, 155.0, 155.0, 155.0, 154.0, 154.0, 500.0, 154.0]  episode_count: 13573 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6239 6 visits [500.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 154.0, 500.0, 154.0]  episode_count: 13575 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6240 7 visits [500.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 500.0, 154.0]  episode_count: 13578 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6241 9 visits [500.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 13579 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6242 1 visits [500.0, 156.0, 155.0, 155.0, 155.0, 155.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 13580 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13583, "number_of_timesteps": 284601, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6243 2 visits [500.0, 156.0, 156.0, 155.0, 155.0, 155.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 13583 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6244 3 visits [500.0, 156.0, 156.0, 156.0, 155.0, 155.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 13586 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6245 4 visits [500.0, 156.0, 156.0, 156.0, 156.0, 155.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 13588 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6246 5 visits [500.0, 156.0, 156.0, 156.0, 156.0, 156.0, 155.0, 155.0, 500.0, 155.0]  episode_count: 13588 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6247 6 visits [500.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 155.0, 500.0, 155.0]  episode_count: 13590 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13594, "number_of_timesteps": 284838, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6248 7 visits [500.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 500.0, 155.0]  episode_count: 13594 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6249 9 visits [500.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 13596 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6250 1 visits [500.0, 157.0, 156.0, 156.0, 156.0, 156.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 13597 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6251 2 visits [500.0, 157.0, 157.0, 156.0, 156.0, 156.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 13600 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6252 3 visits [500.0, 157.0, 157.0, 157.0, 156.0, 156.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 13603 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13606, "number_of_timesteps": 285117, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6253 4 visits [500.0, 157.0, 157.0, 157.0, 157.0, 156.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 13606 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6254 5 visits [500.0, 157.0, 157.0, 157.0, 157.0, 157.0, 156.0, 156.0, 500.0, 156.0]  episode_count: 13607 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6255 6 visits [500.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 156.0, 500.0, 156.0]  episode_count: 13608 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6256 7 visits [500.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 500.0, 156.0]  episode_count: 13610 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6257 9 visits [500.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 13614 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6258 1 visits [500.0, 158.0, 157.0, 157.0, 157.0, 157.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 13615 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13618, "number_of_timesteps": 285385, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6259 2 visits [500.0, 158.0, 158.0, 157.0, 157.0, 157.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 13618 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6260 3 visits [500.0, 158.0, 158.0, 158.0, 157.0, 157.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 13619 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6261 4 visits [500.0, 158.0, 158.0, 158.0, 158.0, 157.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 13621 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6262 5 visits [500.0, 158.0, 158.0, 158.0, 158.0, 158.0, 157.0, 157.0, 500.0, 157.0]  episode_count: 13623 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6263 6 visits [500.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 157.0, 500.0, 157.0]  episode_count: 13626 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13629, "number_of_timesteps": 285622, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6264 7 visits [500.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 500.0, 157.0]  episode_count: 13629 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6265 9 visits [500.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 13629 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6266 1 visits [500.0, 159.0, 158.0, 158.0, 158.0, 158.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 13629 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6267 2 visits [500.0, 159.0, 159.0, 158.0, 158.0, 158.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 13632 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6268 3 visits [500.0, 159.0, 159.0, 159.0, 158.0, 158.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 13635 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6269 4 visits [500.0, 159.0, 159.0, 159.0, 159.0, 158.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 13637 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13640, "number_of_timesteps": 285917, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6270 5 visits [500.0, 159.0, 159.0, 159.0, 159.0, 159.0, 158.0, 158.0, 500.0, 158.0]  episode_count: 13640 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6271 6 visits [500.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 158.0, 500.0, 158.0]  episode_count: 13644 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6272 7 visits [500.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 500.0, 158.0]  episode_count: 13644 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6273 9 visits [500.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 13645 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6274 1 visits [500.0, 160.0, 159.0, 159.0, 159.0, 159.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 13648 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13650, "number_of_timesteps": 286103, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6275 2 visits [500.0, 160.0, 160.0, 159.0, 159.0, 159.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 13650 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6276 3 visits [500.0, 160.0, 160.0, 160.0, 159.0, 159.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 13652 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6277 4 visits [500.0, 160.0, 160.0, 160.0, 160.0, 159.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 13655 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6278 5 visits [500.0, 160.0, 160.0, 160.0, 160.0, 160.0, 159.0, 159.0, 500.0, 159.0]  episode_count: 13658 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6279 6 visits [500.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 159.0, 500.0, 159.0]  episode_count: 13659 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13662, "number_of_timesteps": 286362, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6280 7 visits [500.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 500.0, 159.0]  episode_count: 13662 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6281 9 visits [500.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 13663 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6282 1 visits [500.0, 161.0, 160.0, 160.0, 160.0, 160.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 13669 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6283 2 visits [500.0, 161.0, 161.0, 160.0, 160.0, 160.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 13670 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6284 3 visits [500.0, 161.0, 161.0, 161.0, 160.0, 160.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 13671 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13674, "number_of_timesteps": 286569, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6285 4 visits [500.0, 161.0, 161.0, 161.0, 161.0, 160.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 13674 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6286 5 visits [500.0, 161.0, 161.0, 161.0, 161.0, 161.0, 160.0, 160.0, 500.0, 160.0]  episode_count: 13676 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6287 6 visits [500.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 160.0, 500.0, 160.0]  episode_count: 13679 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6288 7 visits [500.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 500.0, 160.0]  episode_count: 13681 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6289 9 visits [500.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 13683 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13685, "number_of_timesteps": 286746, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6290 1 visits [500.0, 162.0, 161.0, 161.0, 161.0, 161.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 13685 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6291 2 visits [500.0, 162.0, 162.0, 161.0, 161.0, 161.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 13687 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6292 3 visits [500.0, 162.0, 162.0, 162.0, 161.0, 161.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 13690 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6293 4 visits [500.0, 162.0, 162.0, 162.0, 162.0, 161.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 13692 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6294 5 visits [500.0, 162.0, 162.0, 162.0, 162.0, 162.0, 161.0, 161.0, 500.0, 161.0]  episode_count: 13694 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13695, "number_of_timesteps": 287002, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6295 6 visits [500.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 161.0, 500.0, 161.0]  episode_count: 13695 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6296 7 visits [500.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 500.0, 161.0]  episode_count: 13700 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6297 9 visits [500.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 13702 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6298 1 visits [500.0, 163.0, 162.0, 162.0, 162.0, 162.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 13703 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6299 2 visits [500.0, 163.0, 163.0, 162.0, 162.0, 162.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 13704 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13705, "number_of_timesteps": 287202, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6300 3 visits [500.0, 163.0, 163.0, 163.0, 162.0, 162.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 13705 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6301 4 visits [500.0, 163.0, 163.0, 163.0, 163.0, 162.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 13707 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6302 5 visits [500.0, 163.0, 163.0, 163.0, 163.0, 163.0, 162.0, 162.0, 500.0, 162.0]  episode_count: 13710 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6303 6 visits [500.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 162.0, 500.0, 162.0]  episode_count: 13711 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6304 7 visits [500.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 500.0, 162.0]  episode_count: 13714 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13715, "number_of_timesteps": 287447, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6305 9 visits [500.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 13715 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6306 1 visits [500.0, 164.0, 163.0, 163.0, 163.0, 163.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 13716 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6307 2 visits [500.0, 164.0, 164.0, 163.0, 163.0, 163.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 13720 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6308 3 visits [500.0, 164.0, 164.0, 164.0, 163.0, 163.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 13722 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6309 4 visits [500.0, 164.0, 164.0, 164.0, 164.0, 163.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 13722 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6310 5 visits [500.0, 164.0, 164.0, 164.0, 164.0, 164.0, 163.0, 163.0, 500.0, 163.0]  episode_count: 13722 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13725, "number_of_timesteps": 287643, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6311 6 visits [500.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 163.0, 500.0, 163.0]  episode_count: 13725 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6312 7 visits [500.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 500.0, 163.0]  episode_count: 13727 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6313 9 visits [500.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 13728 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6314 1 visits [500.0, 165.0, 164.0, 164.0, 164.0, 164.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 13733 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6315 2 visits [500.0, 165.0, 165.0, 164.0, 164.0, 164.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 13734 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13737, "number_of_timesteps": 287937, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6316 3 visits [500.0, 165.0, 165.0, 165.0, 164.0, 164.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 13737 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6317 4 visits [500.0, 165.0, 165.0, 165.0, 165.0, 164.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 13740 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6318 5 visits [500.0, 165.0, 165.0, 165.0, 165.0, 165.0, 164.0, 164.0, 500.0, 164.0]  episode_count: 13741 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6319 6 visits [500.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 164.0, 500.0, 164.0]  episode_count: 13745 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6320 7 visits [500.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 500.0, 164.0]  episode_count: 13746 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13748, "number_of_timesteps": 288177, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6321 9 visits [500.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 13748 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6322 1 visits [500.0, 166.0, 165.0, 165.0, 165.0, 165.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 13750 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6323 2 visits [500.0, 166.0, 166.0, 165.0, 165.0, 165.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 13753 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6324 3 visits [500.0, 166.0, 166.0, 166.0, 165.0, 165.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 13757 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13758, "number_of_timesteps": 288383, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6325 4 visits [500.0, 166.0, 166.0, 166.0, 166.0, 165.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 13758 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6326 5 visits [500.0, 166.0, 166.0, 166.0, 166.0, 166.0, 165.0, 165.0, 500.0, 165.0]  episode_count: 13761 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6327 6 visits [500.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 165.0, 500.0, 165.0]  episode_count: 13763 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6328 7 visits [500.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 500.0, 165.0]  episode_count: 13766 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13768, "number_of_timesteps": 288587, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6329 9 visits [500.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 13768 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6330 1 visits [500.0, 167.0, 166.0, 166.0, 166.0, 166.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 13770 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6331 2 visits [500.0, 167.0, 167.0, 166.0, 166.0, 166.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 13775 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6332 3 visits [500.0, 167.0, 167.0, 167.0, 166.0, 166.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 13776 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6333 4 visits [500.0, 167.0, 167.0, 167.0, 167.0, 166.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 13777 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13779, "number_of_timesteps": 288772, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6334 5 visits [500.0, 167.0, 167.0, 167.0, 167.0, 167.0, 166.0, 166.0, 500.0, 166.0]  episode_count: 13779 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6335 6 visits [500.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 166.0, 500.0, 166.0]  episode_count: 13782 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6336 7 visits [500.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 500.0, 166.0]  episode_count: 13782 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6337 9 visits [500.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 13786 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6338 1 visits [500.0, 168.0, 167.0, 167.0, 167.0, 167.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 13787 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6339 2 visits [500.0, 168.0, 168.0, 167.0, 167.0, 167.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 13788 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13792, "number_of_timesteps": 289087, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6340 3 visits [500.0, 168.0, 168.0, 168.0, 167.0, 167.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 13792 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6341 4 visits [500.0, 168.0, 168.0, 168.0, 168.0, 167.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 13795 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6342 5 visits [500.0, 168.0, 168.0, 168.0, 168.0, 168.0, 167.0, 167.0, 500.0, 167.0]  episode_count: 13797 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6343 6 visits [500.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 167.0, 500.0, 167.0]  episode_count: 13797 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13802, "number_of_timesteps": 289280, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6344 7 visits [500.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 500.0, 167.0]  episode_count: 13802 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6345 9 visits [500.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 13802 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6346 1 visits [500.0, 169.0, 168.0, 168.0, 168.0, 168.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 13807 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6347 2 visits [500.0, 169.0, 169.0, 168.0, 168.0, 168.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 13809 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13812, "number_of_timesteps": 289444, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6348 3 visits [500.0, 169.0, 169.0, 169.0, 168.0, 168.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 13812 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6349 4 visits [500.0, 169.0, 169.0, 169.0, 169.0, 168.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 13815 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6350 5 visits [500.0, 169.0, 169.0, 169.0, 169.0, 169.0, 168.0, 168.0, 500.0, 168.0]  episode_count: 13818 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6351 6 visits [500.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 168.0, 500.0, 168.0]  episode_count: 13819 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6352 7 visits [500.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 500.0, 168.0]  episode_count: 13820 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13823, "number_of_timesteps": 289653, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6353 9 visits [500.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 13823 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6354 1 visits [500.0, 170.0, 169.0, 169.0, 169.0, 169.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 13824 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6355 2 visits [500.0, 170.0, 170.0, 169.0, 169.0, 169.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 13827 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6356 3 visits [500.0, 170.0, 170.0, 170.0, 169.0, 169.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 13828 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6357 4 visits [500.0, 170.0, 170.0, 170.0, 170.0, 169.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 13829 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13833, "number_of_timesteps": 289889, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6358 5 visits [500.0, 170.0, 170.0, 170.0, 170.0, 170.0, 169.0, 169.0, 500.0, 169.0]  episode_count: 13833 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6359 6 visits [500.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 169.0, 500.0, 169.0]  episode_count: 13836 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6360 7 visits [500.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 500.0, 169.0]  episode_count: 13837 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6361 9 visits [500.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 13840 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6362 1 visits [500.0, 171.0, 170.0, 170.0, 170.0, 170.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 13842 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13844, "number_of_timesteps": 290110, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6363 2 visits [500.0, 171.0, 171.0, 170.0, 170.0, 170.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 13844 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6364 3 visits [500.0, 171.0, 171.0, 171.0, 170.0, 170.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 13846 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6365 4 visits [500.0, 171.0, 171.0, 171.0, 171.0, 170.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 13848 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6366 5 visits [500.0, 171.0, 171.0, 171.0, 171.0, 171.0, 170.0, 170.0, 500.0, 170.0]  episode_count: 13850 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6367 6 visits [500.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 170.0, 500.0, 170.0]  episode_count: 13853 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13854, "number_of_timesteps": 290309, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6368 7 visits [500.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 500.0, 170.0]  episode_count: 13854 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6369 9 visits [500.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 13858 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6370 1 visits [500.0, 172.0, 171.0, 171.0, 171.0, 171.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 13859 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6371 2 visits [500.0, 172.0, 172.0, 171.0, 171.0, 171.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 13861 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13865, "number_of_timesteps": 290535, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6372 3 visits [500.0, 172.0, 172.0, 172.0, 171.0, 171.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 13865 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6373 4 visits [500.0, 172.0, 172.0, 172.0, 172.0, 171.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 13866 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6374 5 visits [500.0, 172.0, 172.0, 172.0, 172.0, 172.0, 171.0, 171.0, 500.0, 171.0]  episode_count: 13868 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6375 6 visits [500.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 171.0, 500.0, 171.0]  episode_count: 13873 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6376 7 visits [500.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 500.0, 171.0]  episode_count: 13873 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6377 9 visits [500.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 13874 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13875, "number_of_timesteps": 290717, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6378 1 visits [500.0, 173.0, 172.0, 172.0, 172.0, 172.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 13875 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6379 2 visits [500.0, 173.0, 173.0, 172.0, 172.0, 172.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 13878 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6380 3 visits [500.0, 173.0, 173.0, 173.0, 172.0, 172.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 13879 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6381 4 visits [500.0, 173.0, 173.0, 173.0, 173.0, 172.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 13883 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13886, "number_of_timesteps": 290998, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6382 5 visits [500.0, 173.0, 173.0, 173.0, 173.0, 173.0, 172.0, 172.0, 500.0, 172.0]  episode_count: 13886 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6383 6 visits [500.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 172.0, 500.0, 172.0]  episode_count: 13887 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6384 7 visits [500.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 500.0, 172.0]  episode_count: 13889 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6385 9 visits [500.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 13893 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6386 1 visits [500.0, 174.0, 173.0, 173.0, 173.0, 173.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 13895 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6387 2 visits [500.0, 174.0, 174.0, 173.0, 173.0, 173.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 13895 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13899, "number_of_timesteps": 291240, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6388 3 visits [500.0, 174.0, 174.0, 174.0, 173.0, 173.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 13899 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6389 4 visits [500.0, 174.0, 174.0, 174.0, 174.0, 173.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 13901 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6390 5 visits [500.0, 174.0, 174.0, 174.0, 174.0, 174.0, 173.0, 173.0, 500.0, 173.0]  episode_count: 13901 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6391 6 visits [500.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 173.0, 500.0, 173.0]  episode_count: 13906 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6392 7 visits [500.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 500.0, 173.0]  episode_count: 13908 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13909, "number_of_timesteps": 291465, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6393 9 visits [500.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 13909 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6394 1 visits [500.0, 175.0, 174.0, 174.0, 174.0, 174.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 13911 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6395 2 visits [500.0, 175.0, 175.0, 174.0, 174.0, 174.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 13914 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6396 3 visits [500.0, 175.0, 175.0, 175.0, 174.0, 174.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 13917 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13919, "number_of_timesteps": 291680, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6397 4 visits [500.0, 175.0, 175.0, 175.0, 175.0, 174.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 13919 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6398 5 visits [500.0, 175.0, 175.0, 175.0, 175.0, 175.0, 174.0, 174.0, 500.0, 174.0]  episode_count: 13922 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6399 6 visits [500.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 174.0, 500.0, 174.0]  episode_count: 13926 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6400 7 visits [500.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 500.0, 174.0]  episode_count: 13927 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6401 9 visits [500.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 13928 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13930, "number_of_timesteps": 291884, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6402 1 visits [500.0, 176.0, 175.0, 175.0, 175.0, 175.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 13930 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6403 2 visits [500.0, 176.0, 176.0, 175.0, 175.0, 175.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 13933 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6404 3 visits [500.0, 176.0, 176.0, 176.0, 175.0, 175.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 13936 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6405 4 visits [500.0, 176.0, 176.0, 176.0, 176.0, 175.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 13939 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13941, "number_of_timesteps": 292070, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6406 5 visits [500.0, 176.0, 176.0, 176.0, 176.0, 176.0, 175.0, 175.0, 500.0, 175.0]  episode_count: 13941 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6407 6 visits [500.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 175.0, 500.0, 175.0]  episode_count: 13943 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6408 7 visits [500.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 500.0, 175.0]  episode_count: 13946 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6409 9 visits [500.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 13948 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6410 1 visits [500.0, 177.0, 176.0, 176.0, 176.0, 176.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 13949 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6411 2 visits [500.0, 177.0, 177.0, 176.0, 176.0, 176.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 13950 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13952, "number_of_timesteps": 292284, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6412 3 visits [500.0, 177.0, 177.0, 177.0, 176.0, 176.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 13952 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6413 4 visits [500.0, 177.0, 177.0, 177.0, 177.0, 176.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 13956 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6414 5 visits [500.0, 177.0, 177.0, 177.0, 177.0, 177.0, 176.0, 176.0, 500.0, 176.0]  episode_count: 13957 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6415 6 visits [500.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 176.0, 500.0, 176.0]  episode_count: 13960 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13965, "number_of_timesteps": 292574, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6416 7 visits [500.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 500.0, 176.0]  episode_count: 13965 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6417 9 visits [500.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 13965 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6418 1 visits [500.0, 178.0, 177.0, 177.0, 177.0, 177.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 13967 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6419 2 visits [500.0, 178.0, 178.0, 177.0, 177.0, 177.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 13971 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6420 3 visits [500.0, 178.0, 178.0, 178.0, 177.0, 177.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 13972 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6421 4 visits [500.0, 178.0, 178.0, 178.0, 178.0, 177.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 13974 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13979, "number_of_timesteps": 292850, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6422 5 visits [500.0, 178.0, 178.0, 178.0, 178.0, 178.0, 177.0, 177.0, 500.0, 177.0]  episode_count: 13979 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6423 6 visits [500.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 177.0, 500.0, 177.0]  episode_count: 13979 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6424 7 visits [500.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 500.0, 177.0]  episode_count: 13980 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6425 9 visits [500.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 13984 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6426 1 visits [500.0, 179.0, 178.0, 178.0, 178.0, 178.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 13987 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6427 2 visits [500.0, 179.0, 179.0, 178.0, 178.0, 178.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 13988 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 13991, "number_of_timesteps": 293054, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6428 3 visits [500.0, 179.0, 179.0, 179.0, 178.0, 178.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 13991 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6429 4 visits [500.0, 179.0, 179.0, 179.0, 179.0, 178.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 13993 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6430 5 visits [500.0, 179.0, 179.0, 179.0, 179.0, 179.0, 178.0, 178.0, 500.0, 178.0]  episode_count: 13993 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6431 6 visits [500.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 178.0, 500.0, 178.0]  episode_count: 13995 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6432 7 visits [500.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 500.0, 178.0]  episode_count: 13998 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6433 9 visits [500.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 14000 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14002, "number_of_timesteps": 293332, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6434 1 visits [500.0, 180.0, 179.0, 179.0, 179.0, 179.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 14002 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6435 2 visits [500.0, 180.0, 180.0, 179.0, 179.0, 179.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 14003 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6436 3 visits [500.0, 180.0, 180.0, 180.0, 179.0, 179.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 14003 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6437 4 visits [500.0, 180.0, 180.0, 180.0, 180.0, 179.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 14006 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6438 5 visits [500.0, 180.0, 180.0, 180.0, 180.0, 180.0, 179.0, 179.0, 500.0, 179.0]  episode_count: 14009 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6439 6 visits [500.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 179.0, 500.0, 179.0]  episode_count: 14011 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14015, "number_of_timesteps": 293632, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6440 7 visits [500.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 500.0, 179.0]  episode_count: 14015 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6441 9 visits [500.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 14017 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6442 1 visits [500.0, 181.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 14020 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6443 2 visits [500.0, 181.0, 181.0, 180.0, 180.0, 180.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 14021 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14025, "number_of_timesteps": 293809, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6444 3 visits [500.0, 181.0, 181.0, 181.0, 180.0, 180.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 14025 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6445 4 visits [500.0, 181.0, 181.0, 181.0, 181.0, 180.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 14025 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6446 5 visits [500.0, 181.0, 181.0, 181.0, 181.0, 181.0, 180.0, 180.0, 500.0, 180.0]  episode_count: 14029 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6447 6 visits [500.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 180.0, 500.0, 180.0]  episode_count: 14031 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6448 7 visits [500.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 500.0, 180.0]  episode_count: 14032 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6449 9 visits [500.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 14034 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6450 1 visits [500.0, 182.0, 181.0, 181.0, 181.0, 181.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 14034 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14038, "number_of_timesteps": 294062, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6451 2 visits [500.0, 182.0, 182.0, 181.0, 181.0, 181.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 14038 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6452 3 visits [500.0, 182.0, 182.0, 182.0, 181.0, 181.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 14041 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6453 4 visits [500.0, 182.0, 182.0, 182.0, 182.0, 181.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 14042 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6454 5 visits [500.0, 182.0, 182.0, 182.0, 182.0, 182.0, 181.0, 181.0, 500.0, 181.0]  episode_count: 14045 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14048, "number_of_timesteps": 294301, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6455 6 visits [500.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 181.0, 500.0, 181.0]  episode_count: 14048 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6456 7 visits [500.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 500.0, 181.0]  episode_count: 14050 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6457 9 visits [500.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 14050 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6458 1 visits [500.0, 183.0, 182.0, 182.0, 182.0, 182.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 14054 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14058, "number_of_timesteps": 294509, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6459 2 visits [500.0, 183.0, 183.0, 182.0, 182.0, 182.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 14058 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6460 3 visits [500.0, 183.0, 183.0, 183.0, 182.0, 182.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 14060 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6461 4 visits [500.0, 183.0, 183.0, 183.0, 183.0, 182.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 14062 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6462 5 visits [500.0, 183.0, 183.0, 183.0, 183.0, 183.0, 182.0, 182.0, 500.0, 182.0]  episode_count: 14063 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6463 6 visits [500.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 182.0, 500.0, 182.0]  episode_count: 14064 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14068, "number_of_timesteps": 294697, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6464 7 visits [500.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 500.0, 182.0]  episode_count: 14068 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6465 9 visits [500.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 14071 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6466 1 visits [500.0, 184.0, 183.0, 183.0, 183.0, 183.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 14072 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6467 2 visits [500.0, 184.0, 184.0, 183.0, 183.0, 183.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 14072 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6468 3 visits [500.0, 184.0, 184.0, 184.0, 183.0, 183.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 14075 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6469 4 visits [500.0, 184.0, 184.0, 184.0, 184.0, 183.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 14076 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14078, "number_of_timesteps": 294928, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6470 5 visits [500.0, 184.0, 184.0, 184.0, 184.0, 184.0, 183.0, 183.0, 500.0, 183.0]  episode_count: 14078 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6471 6 visits [500.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 183.0, 500.0, 183.0]  episode_count: 14078 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6472 7 visits [500.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 500.0, 183.0]  episode_count: 14082 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6473 9 visits [500.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 14085 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6474 1 visits [500.0, 185.0, 184.0, 184.0, 184.0, 184.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 14087 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14090, "number_of_timesteps": 295224, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6475 2 visits [500.0, 185.0, 185.0, 184.0, 184.0, 184.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 14090 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6476 3 visits [500.0, 185.0, 185.0, 185.0, 184.0, 184.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 14091 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6477 4 visits [500.0, 185.0, 185.0, 185.0, 185.0, 184.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 14093 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6478 5 visits [500.0, 185.0, 185.0, 185.0, 185.0, 185.0, 184.0, 184.0, 500.0, 184.0]  episode_count: 14094 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6479 6 visits [500.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 184.0, 500.0, 184.0]  episode_count: 14096 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14100, "number_of_timesteps": 295427, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6480 7 visits [500.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 500.0, 184.0]  episode_count: 14100 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6481 9 visits [500.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 14102 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6482 1 visits [500.0, 186.0, 185.0, 185.0, 185.0, 185.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 14104 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6483 2 visits [500.0, 186.0, 186.0, 185.0, 185.0, 185.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 14108 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6484 3 visits [500.0, 186.0, 186.0, 186.0, 185.0, 185.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 14108 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14112, "number_of_timesteps": 295676, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6485 4 visits [500.0, 186.0, 186.0, 186.0, 186.0, 185.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 14112 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6486 5 visits [500.0, 186.0, 186.0, 186.0, 186.0, 186.0, 185.0, 185.0, 500.0, 185.0]  episode_count: 14116 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6487 6 visits [500.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 185.0, 500.0, 185.0]  episode_count: 14119 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6488 7 visits [500.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 500.0, 185.0]  episode_count: 14120 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14122, "number_of_timesteps": 295820, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6489 9 visits [500.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 14122 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6490 1 visits [500.0, 187.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 14127 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6491 2 visits [500.0, 187.0, 187.0, 186.0, 186.0, 186.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 14127 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6492 3 visits [500.0, 187.0, 187.0, 187.0, 186.0, 186.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 14128 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14133, "number_of_timesteps": 296042, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6493 4 visits [500.0, 187.0, 187.0, 187.0, 187.0, 186.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 14133 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6494 5 visits [500.0, 187.0, 187.0, 187.0, 187.0, 187.0, 186.0, 186.0, 500.0, 186.0]  episode_count: 14134 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6495 6 visits [500.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 186.0, 500.0, 186.0]  episode_count: 14136 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6496 7 visits [500.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 500.0, 186.0]  episode_count: 14138 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6497 9 visits [500.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 14140 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6498 1 visits [500.0, 188.0, 187.0, 187.0, 187.0, 187.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 14141 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14146, "number_of_timesteps": 296278, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6499 2 visits [500.0, 188.0, 188.0, 187.0, 187.0, 187.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 14146 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6500 3 visits [500.0, 188.0, 188.0, 188.0, 187.0, 187.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 14148 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6501 4 visits [500.0, 188.0, 188.0, 188.0, 188.0, 187.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 14148 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6502 5 visits [500.0, 188.0, 188.0, 188.0, 188.0, 188.0, 187.0, 187.0, 500.0, 187.0]  episode_count: 14151 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6503 6 visits [500.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 187.0, 500.0, 187.0]  episode_count: 14154 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6504 7 visits [500.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 500.0, 187.0]  episode_count: 14154 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14156, "number_of_timesteps": 296509, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6505 9 visits [500.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 14156 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6506 1 visits [500.0, 189.0, 188.0, 188.0, 188.0, 188.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 14160 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6507 2 visits [500.0, 189.0, 189.0, 188.0, 188.0, 188.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 14161 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6508 3 visits [500.0, 189.0, 189.0, 189.0, 188.0, 188.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 14163 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6509 4 visits [500.0, 189.0, 189.0, 189.0, 189.0, 188.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 14163 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14166, "number_of_timesteps": 296731, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6510 5 visits [500.0, 189.0, 189.0, 189.0, 189.0, 189.0, 188.0, 188.0, 500.0, 188.0]  episode_count: 14166 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6511 6 visits [500.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 188.0, 500.0, 188.0]  episode_count: 14170 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6512 7 visits [500.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 500.0, 188.0]  episode_count: 14174 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6513 9 visits [500.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 14174 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6514 1 visits [500.0, 190.0, 189.0, 189.0, 189.0, 189.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 14174 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14177, "number_of_timesteps": 296980, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6515 2 visits [500.0, 190.0, 190.0, 189.0, 189.0, 189.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 14177 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6516 3 visits [500.0, 190.0, 190.0, 190.0, 189.0, 189.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 14177 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6517 4 visits [500.0, 190.0, 190.0, 190.0, 190.0, 189.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 14182 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6518 5 visits [500.0, 190.0, 190.0, 190.0, 190.0, 190.0, 189.0, 189.0, 500.0, 189.0]  episode_count: 14184 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6519 6 visits [500.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 189.0, 500.0, 189.0]  episode_count: 14185 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14187, "number_of_timesteps": 297227, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6520 7 visits [500.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 500.0, 189.0]  episode_count: 14187 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6521 9 visits [500.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 14188 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6522 1 visits [500.0, 191.0, 190.0, 190.0, 190.0, 190.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 14190 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6523 2 visits [500.0, 191.0, 191.0, 190.0, 190.0, 190.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 14191 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6524 3 visits [500.0, 191.0, 191.0, 191.0, 190.0, 190.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 14193 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6525 4 visits [500.0, 191.0, 191.0, 191.0, 191.0, 190.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 14195 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14197, "number_of_timesteps": 297471, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6526 5 visits [500.0, 191.0, 191.0, 191.0, 191.0, 191.0, 190.0, 190.0, 500.0, 190.0]  episode_count: 14197 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6527 6 visits [500.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 190.0, 500.0, 190.0]  episode_count: 14199 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6528 7 visits [500.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 500.0, 190.0]  episode_count: 14203 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6529 9 visits [500.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 14204 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6530 1 visits [500.0, 192.0, 191.0, 191.0, 191.0, 191.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 14206 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14209, "number_of_timesteps": 297698, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6531 2 visits [500.0, 192.0, 192.0, 191.0, 191.0, 191.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 14209 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6532 3 visits [500.0, 192.0, 192.0, 192.0, 191.0, 191.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 14209 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6533 4 visits [500.0, 192.0, 192.0, 192.0, 192.0, 191.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 14210 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6534 5 visits [500.0, 192.0, 192.0, 192.0, 192.0, 192.0, 191.0, 191.0, 500.0, 191.0]  episode_count: 14213 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6535 6 visits [500.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 191.0, 500.0, 191.0]  episode_count: 14215 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6536 7 visits [500.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 500.0, 191.0]  episode_count: 14216 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14221, "number_of_timesteps": 298028, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6537 9 visits [500.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 14221 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6538 1 visits [500.0, 193.0, 192.0, 192.0, 192.0, 192.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 14221 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6539 2 visits [500.0, 193.0, 193.0, 192.0, 192.0, 192.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 14225 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6540 3 visits [500.0, 193.0, 193.0, 193.0, 192.0, 192.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 14226 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6541 4 visits [500.0, 193.0, 193.0, 193.0, 193.0, 192.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 14229 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14232, "number_of_timesteps": 298232, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6542 5 visits [500.0, 193.0, 193.0, 193.0, 193.0, 193.0, 192.0, 192.0, 500.0, 192.0]  episode_count: 14232 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6543 6 visits [500.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 192.0, 500.0, 192.0]  episode_count: 14234 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6544 7 visits [500.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 500.0, 192.0]  episode_count: 14236 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6545 9 visits [500.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 14241 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14242, "number_of_timesteps": 298399, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6546 1 visits [500.0, 194.0, 193.0, 193.0, 193.0, 193.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 14242 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6547 2 visits [500.0, 194.0, 194.0, 193.0, 193.0, 193.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 14244 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6548 3 visits [500.0, 194.0, 194.0, 194.0, 193.0, 193.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 14246 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6549 4 visits [500.0, 194.0, 194.0, 194.0, 194.0, 193.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 14246 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6550 5 visits [500.0, 194.0, 194.0, 194.0, 194.0, 194.0, 193.0, 193.0, 500.0, 193.0]  episode_count: 14247 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6551 6 visits [500.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 193.0, 500.0, 193.0]  episode_count: 14250 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14252, "number_of_timesteps": 298677, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6552 7 visits [500.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 500.0, 193.0]  episode_count: 14252 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6553 9 visits [500.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 14254 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6554 1 visits [500.0, 195.0, 194.0, 194.0, 194.0, 194.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 14257 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6555 2 visits [500.0, 195.0, 195.0, 194.0, 194.0, 194.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 14260 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6556 3 visits [500.0, 195.0, 195.0, 195.0, 194.0, 194.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 14261 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14262, "number_of_timesteps": 298893, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6557 4 visits [500.0, 195.0, 195.0, 195.0, 195.0, 194.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 14262 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6558 5 visits [500.0, 195.0, 195.0, 195.0, 195.0, 195.0, 194.0, 194.0, 500.0, 194.0]  episode_count: 14265 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6559 6 visits [500.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 194.0, 500.0, 194.0]  episode_count: 14267 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14272, "number_of_timesteps": 299112, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6560 7 visits [500.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 500.0, 194.0]  episode_count: 14272 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6561 9 visits [500.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 14273 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6562 1 visits [500.0, 196.0, 195.0, 195.0, 195.0, 195.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 14273 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6563 2 visits [500.0, 196.0, 196.0, 195.0, 195.0, 195.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 14276 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6564 3 visits [500.0, 196.0, 196.0, 196.0, 195.0, 195.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 14277 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6565 4 visits [500.0, 196.0, 196.0, 196.0, 196.0, 195.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 14281 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14283, "number_of_timesteps": 299322, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6566 5 visits [500.0, 196.0, 196.0, 196.0, 196.0, 196.0, 195.0, 195.0, 500.0, 195.0]  episode_count: 14283 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6567 6 visits [500.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 195.0, 500.0, 195.0]  episode_count: 14286 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6568 7 visits [500.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 500.0, 195.0]  episode_count: 14286 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6569 9 visits [500.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 14289 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6570 1 visits [500.0, 197.0, 196.0, 196.0, 196.0, 196.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 14292 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14293, "number_of_timesteps": 299561, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6571 2 visits [500.0, 197.0, 197.0, 196.0, 196.0, 196.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 14293 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6572 3 visits [500.0, 197.0, 197.0, 197.0, 196.0, 196.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 14296 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6573 4 visits [500.0, 197.0, 197.0, 197.0, 197.0, 196.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 14297 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6574 5 visits [500.0, 197.0, 197.0, 197.0, 197.0, 197.0, 196.0, 196.0, 500.0, 196.0]  episode_count: 14301 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6575 6 visits [500.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 196.0, 500.0, 196.0]  episode_count: 14302 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14304, "number_of_timesteps": 299788, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6576 7 visits [500.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 500.0, 196.0]  episode_count: 14304 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6577 9 visits [500.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 14305 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6578 1 visits [500.0, 198.0, 197.0, 197.0, 197.0, 197.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 14308 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6579 2 visits [500.0, 198.0, 198.0, 197.0, 197.0, 197.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 14312 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6580 3 visits [500.0, 198.0, 198.0, 198.0, 197.0, 197.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 14313 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14314, "number_of_timesteps": 299977, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6581 4 visits [500.0, 198.0, 198.0, 198.0, 198.0, 197.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 14314 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6582 5 visits [500.0, 198.0, 198.0, 198.0, 198.0, 198.0, 197.0, 197.0, 500.0, 197.0]  episode_count: 14318 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6583 6 visits [500.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 197.0, 500.0, 197.0]  episode_count: 14320 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6584 7 visits [500.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 500.0, 197.0]  episode_count: 14322 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6585 9 visits [500.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 14323 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6586 1 visits [500.0, 199.0, 198.0, 198.0, 198.0, 198.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 14323 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14325, "number_of_timesteps": 300203, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6587 2 visits [500.0, 199.0, 199.0, 198.0, 198.0, 198.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 14325 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6588 3 visits [500.0, 199.0, 199.0, 199.0, 198.0, 198.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 14329 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6589 4 visits [500.0, 199.0, 199.0, 199.0, 199.0, 198.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 14330 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6590 5 visits [500.0, 199.0, 199.0, 199.0, 199.0, 199.0, 198.0, 198.0, 500.0, 198.0]  episode_count: 14331 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6591 6 visits [500.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 198.0, 500.0, 198.0]  episode_count: 14332 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14336, "number_of_timesteps": 300459, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6592 7 visits [500.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 500.0, 198.0]  episode_count: 14336 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6593 9 visits [500.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 14337 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6594 1 visits [500.0, 200.0, 199.0, 199.0, 199.0, 199.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 14339 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6595 2 visits [500.0, 200.0, 200.0, 199.0, 199.0, 199.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 14341 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6596 3 visits [500.0, 200.0, 200.0, 200.0, 199.0, 199.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 14343 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6597 4 visits [500.0, 200.0, 200.0, 200.0, 200.0, 199.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 14344 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14346, "number_of_timesteps": 300758, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6598 5 visits [500.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 199.0, 500.0, 199.0]  episode_count: 14346 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6599 6 visits [500.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 199.0, 500.0, 199.0]  episode_count: 14347 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6600 7 visits [500.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 500.0, 199.0]  episode_count: 14351 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6601 9 visits [500.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 14353 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14356, "number_of_timesteps": 301004, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6602 1 visits [500.0, 201.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 14356 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6603 2 visits [500.0, 201.0, 201.0, 200.0, 200.0, 200.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 14359 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6604 3 visits [500.0, 201.0, 201.0, 201.0, 200.0, 200.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 14359 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6605 4 visits [500.0, 201.0, 201.0, 201.0, 201.0, 200.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 14360 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6606 5 visits [500.0, 201.0, 201.0, 201.0, 201.0, 201.0, 200.0, 200.0, 500.0, 200.0]  episode_count: 14365 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14366, "number_of_timesteps": 301174, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6607 6 visits [500.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 200.0, 500.0, 200.0]  episode_count: 14366 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6608 7 visits [500.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 500.0, 200.0]  episode_count: 14368 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6609 9 visits [500.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 14370 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6610 1 visits [500.0, 202.0, 201.0, 201.0, 201.0, 201.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 14374 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6611 2 visits [500.0, 202.0, 202.0, 201.0, 201.0, 201.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 14375 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14377, "number_of_timesteps": 301426, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6612 3 visits [500.0, 202.0, 202.0, 202.0, 201.0, 201.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 14377 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6613 4 visits [500.0, 202.0, 202.0, 202.0, 202.0, 201.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 14377 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6614 5 visits [500.0, 202.0, 202.0, 202.0, 202.0, 202.0, 201.0, 201.0, 500.0, 201.0]  episode_count: 14381 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6615 6 visits [500.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 201.0, 500.0, 201.0]  episode_count: 14383 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6616 7 visits [500.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 500.0, 201.0]  episode_count: 14385 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14388, "number_of_timesteps": 301630, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6617 9 visits [500.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 14388 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6618 1 visits [500.0, 203.0, 202.0, 202.0, 202.0, 202.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 14390 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6619 2 visits [500.0, 203.0, 203.0, 202.0, 202.0, 202.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 14393 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6620 3 visits [500.0, 203.0, 203.0, 203.0, 202.0, 202.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 14396 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6621 4 visits [500.0, 203.0, 203.0, 203.0, 203.0, 202.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 14397 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14398, "number_of_timesteps": 301845, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6622 5 visits [500.0, 203.0, 203.0, 203.0, 203.0, 203.0, 202.0, 202.0, 500.0, 202.0]  episode_count: 14398 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6623 6 visits [500.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 202.0, 500.0, 202.0]  episode_count: 14402 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6624 7 visits [500.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 500.0, 202.0]  episode_count: 14406 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6625 9 visits [500.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 14406 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14409, "number_of_timesteps": 302061, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6626 1 visits [500.0, 204.0, 203.0, 203.0, 203.0, 203.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 14409 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6627 2 visits [500.0, 204.0, 204.0, 203.0, 203.0, 203.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 14411 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6628 3 visits [500.0, 204.0, 204.0, 204.0, 203.0, 203.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 14412 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6629 4 visits [500.0, 204.0, 204.0, 204.0, 204.0, 203.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 14416 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6630 5 visits [500.0, 204.0, 204.0, 204.0, 204.0, 204.0, 203.0, 203.0, 500.0, 203.0]  episode_count: 14418 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6631 6 visits [500.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 203.0, 500.0, 203.0]  episode_count: 14418 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14421, "number_of_timesteps": 302279, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6632 7 visits [500.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 500.0, 203.0]  episode_count: 14421 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6633 9 visits [500.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 14423 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6634 1 visits [500.0, 205.0, 204.0, 204.0, 204.0, 204.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 14426 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6635 2 visits [500.0, 205.0, 205.0, 204.0, 204.0, 204.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 14428 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6636 3 visits [500.0, 205.0, 205.0, 205.0, 204.0, 204.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 14428 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14431, "number_of_timesteps": 302519, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6637 4 visits [500.0, 205.0, 205.0, 205.0, 205.0, 204.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 14431 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6638 5 visits [500.0, 205.0, 205.0, 205.0, 205.0, 205.0, 204.0, 204.0, 500.0, 204.0]  episode_count: 14434 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6639 6 visits [500.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 204.0, 500.0, 204.0]  episode_count: 14436 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6640 7 visits [500.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 500.0, 204.0]  episode_count: 14440 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6641 9 visits [500.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 14440 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14441, "number_of_timesteps": 302774, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6642 1 visits [500.0, 206.0, 205.0, 205.0, 205.0, 205.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 14441 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6643 2 visits [500.0, 206.0, 206.0, 205.0, 205.0, 205.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 14444 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6644 3 visits [500.0, 206.0, 206.0, 206.0, 205.0, 205.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 14447 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6645 4 visits [500.0, 206.0, 206.0, 206.0, 206.0, 205.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 14448 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6646 5 visits [500.0, 206.0, 206.0, 206.0, 206.0, 206.0, 205.0, 205.0, 500.0, 205.0]  episode_count: 14449 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14451, "number_of_timesteps": 302969, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6647 6 visits [500.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 205.0, 500.0, 205.0]  episode_count: 14451 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6648 7 visits [500.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 500.0, 205.0]  episode_count: 14453 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6649 9 visits [500.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 14455 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6650 1 visits [500.0, 207.0, 206.0, 206.0, 206.0, 206.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 14457 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6651 2 visits [500.0, 207.0, 207.0, 206.0, 206.0, 206.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 14460 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14463, "number_of_timesteps": 303280, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6652 3 visits [500.0, 207.0, 207.0, 207.0, 206.0, 206.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 14463 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6653 4 visits [500.0, 207.0, 207.0, 207.0, 207.0, 206.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 14464 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6654 5 visits [500.0, 207.0, 207.0, 207.0, 207.0, 207.0, 206.0, 206.0, 500.0, 206.0]  episode_count: 14469 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6655 6 visits [500.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 206.0, 500.0, 206.0]  episode_count: 14471 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14474, "number_of_timesteps": 303475, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6656 7 visits [500.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 500.0, 206.0]  episode_count: 14474 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6657 9 visits [500.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 14477 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6658 1 visits [500.0, 208.0, 207.0, 207.0, 207.0, 207.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 14479 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6659 2 visits [500.0, 208.0, 208.0, 207.0, 207.0, 207.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 14480 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6660 3 visits [500.0, 208.0, 208.0, 208.0, 207.0, 207.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 14480 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6661 4 visits [500.0, 208.0, 208.0, 208.0, 208.0, 207.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 14482 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14485, "number_of_timesteps": 303681, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6662 5 visits [500.0, 208.0, 208.0, 208.0, 208.0, 208.0, 207.0, 207.0, 500.0, 207.0]  episode_count: 14485 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6663 6 visits [500.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 207.0, 500.0, 207.0]  episode_count: 14487 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6664 7 visits [500.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 500.0, 207.0]  episode_count: 14489 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6665 9 visits [500.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 14492 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14495, "number_of_timesteps": 303919, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6666 1 visits [500.0, 209.0, 208.0, 208.0, 208.0, 208.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 14495 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6667 2 visits [500.0, 209.0, 209.0, 208.0, 208.0, 208.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 14496 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6668 3 visits [500.0, 209.0, 209.0, 209.0, 208.0, 208.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 14497 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6669 4 visits [500.0, 209.0, 209.0, 209.0, 209.0, 208.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 14500 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6670 5 visits [500.0, 209.0, 209.0, 209.0, 209.0, 209.0, 208.0, 208.0, 500.0, 208.0]  episode_count: 14503 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6671 6 visits [500.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 208.0, 500.0, 208.0]  episode_count: 14504 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14505, "number_of_timesteps": 304114, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6672 7 visits [500.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 500.0, 208.0]  episode_count: 14505 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6673 9 visits [500.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 14509 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6674 1 visits [500.0, 210.0, 209.0, 209.0, 209.0, 209.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 14512 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6675 2 visits [500.0, 210.0, 210.0, 209.0, 209.0, 209.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 14513 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6676 3 visits [500.0, 210.0, 210.0, 210.0, 209.0, 209.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 14514 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14518, "number_of_timesteps": 304395, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6677 4 visits [500.0, 210.0, 210.0, 210.0, 210.0, 209.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 14518 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6678 5 visits [500.0, 210.0, 210.0, 210.0, 210.0, 210.0, 209.0, 209.0, 500.0, 209.0]  episode_count: 14521 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6679 6 visits [500.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 209.0, 500.0, 209.0]  episode_count: 14521 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6680 7 visits [500.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 500.0, 209.0]  episode_count: 14525 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14528, "number_of_timesteps": 304567, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6681 9 visits [500.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 14528 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6682 1 visits [500.0, 211.0, 210.0, 210.0, 210.0, 210.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 14530 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6683 2 visits [500.0, 211.0, 211.0, 210.0, 210.0, 210.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 14532 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6684 3 visits [500.0, 211.0, 211.0, 211.0, 210.0, 210.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 14535 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14538, "number_of_timesteps": 304797, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 6685 4 visits [500.0, 211.0, 211.0, 211.0, 211.0, 210.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 14538 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6686 5 visits [500.0, 211.0, 211.0, 211.0, 211.0, 211.0, 210.0, 210.0, 500.0, 210.0]  episode_count: 14540 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6687 6 visits [500.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 210.0, 500.0, 210.0]  episode_count: 14540 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6688 7 visits [500.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 500.0, 210.0]  episode_count: 14544 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6689 9 visits [500.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 14546 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14548, "number_of_timesteps": 304996, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6690 1 visits [500.0, 212.0, 211.0, 211.0, 211.0, 211.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 14548 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6691 2 visits [500.0, 212.0, 212.0, 211.0, 211.0, 211.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 14550 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6692 3 visits [500.0, 212.0, 212.0, 212.0, 211.0, 211.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 14551 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6693 4 visits [500.0, 212.0, 212.0, 212.0, 212.0, 211.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 14553 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14558, "number_of_timesteps": 305210, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6694 5 visits [500.0, 212.0, 212.0, 212.0, 212.0, 212.0, 211.0, 211.0, 500.0, 211.0]  episode_count: 14558 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6695 6 visits [500.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 211.0, 500.0, 211.0]  episode_count: 14558 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6696 7 visits [500.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 500.0, 211.0]  episode_count: 14559 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6697 9 visits [500.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 14563 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6698 1 visits [500.0, 213.0, 212.0, 212.0, 212.0, 212.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 14566 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14568, "number_of_timesteps": 305414, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6699 2 visits [500.0, 213.0, 213.0, 212.0, 212.0, 212.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 14568 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6700 3 visits [500.0, 213.0, 213.0, 213.0, 212.0, 212.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 14570 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6701 4 visits [500.0, 213.0, 213.0, 213.0, 213.0, 212.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 14571 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6702 5 visits [500.0, 213.0, 213.0, 213.0, 213.0, 213.0, 212.0, 212.0, 500.0, 212.0]  episode_count: 14573 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6703 6 visits [500.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 212.0, 500.0, 212.0]  episode_count: 14575 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6704 7 visits [500.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 500.0, 212.0]  episode_count: 14576 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14579, "number_of_timesteps": 305651, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6705 9 visits [500.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 14579 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6706 1 visits [500.0, 214.0, 213.0, 213.0, 213.0, 213.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 14582 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6707 2 visits [500.0, 214.0, 214.0, 213.0, 213.0, 213.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 14583 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6708 3 visits [500.0, 214.0, 214.0, 214.0, 213.0, 213.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 14585 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6709 4 visits [500.0, 214.0, 214.0, 214.0, 214.0, 213.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 14588 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14590, "number_of_timesteps": 305905, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6710 5 visits [500.0, 214.0, 214.0, 214.0, 214.0, 214.0, 213.0, 213.0, 500.0, 213.0]  episode_count: 14590 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6711 6 visits [500.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 213.0, 500.0, 213.0]  episode_count: 14593 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6712 7 visits [500.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 500.0, 213.0]  episode_count: 14597 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14600, "number_of_timesteps": 306063, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6713 9 visits [500.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 14600 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6714 1 visits [500.0, 215.0, 214.0, 214.0, 214.0, 214.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 14602 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6715 2 visits [500.0, 215.0, 215.0, 214.0, 214.0, 214.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 14602 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6716 3 visits [500.0, 215.0, 215.0, 215.0, 214.0, 214.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 14602 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6717 4 visits [500.0, 215.0, 215.0, 215.0, 215.0, 214.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 14606 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6718 5 visits [500.0, 215.0, 215.0, 215.0, 215.0, 215.0, 214.0, 214.0, 500.0, 214.0]  episode_count: 14609 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14611, "number_of_timesteps": 306303, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6719 6 visits [500.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 214.0, 500.0, 214.0]  episode_count: 14611 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6720 7 visits [500.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 500.0, 214.0]  episode_count: 14615 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6721 9 visits [500.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 14615 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6722 1 visits [500.0, 216.0, 215.0, 215.0, 215.0, 215.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 14618 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14621, "number_of_timesteps": 306509, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6723 2 visits [500.0, 216.0, 216.0, 215.0, 215.0, 215.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 14621 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6724 3 visits [500.0, 216.0, 216.0, 216.0, 215.0, 215.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 14621 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6725 4 visits [500.0, 216.0, 216.0, 216.0, 216.0, 215.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 14623 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6726 5 visits [500.0, 216.0, 216.0, 216.0, 216.0, 216.0, 215.0, 215.0, 500.0, 215.0]  episode_count: 14625 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6727 6 visits [500.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 215.0, 500.0, 215.0]  episode_count: 14629 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6728 7 visits [500.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 500.0, 215.0]  episode_count: 14630 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14632, "number_of_timesteps": 306745, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 6729 9 visits [500.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 14632 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6730 1 visits [500.0, 217.0, 216.0, 216.0, 216.0, 216.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 14637 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6731 2 visits [500.0, 217.0, 217.0, 216.0, 216.0, 216.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 14637 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6732 3 visits [500.0, 217.0, 217.0, 217.0, 216.0, 216.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 14638 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6733 4 visits [500.0, 217.0, 217.0, 217.0, 217.0, 216.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 14641 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14642, "number_of_timesteps": 306943, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6734 5 visits [500.0, 217.0, 217.0, 217.0, 217.0, 217.0, 216.0, 216.0, 500.0, 216.0]  episode_count: 14642 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6735 6 visits [500.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 216.0, 500.0, 216.0]  episode_count: 14644 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6736 7 visits [500.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 500.0, 216.0]  episode_count: 14648 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6737 9 visits [500.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 14650 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14653, "number_of_timesteps": 307218, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6738 1 visits [500.0, 218.0, 217.0, 217.0, 217.0, 217.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 14653 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6739 2 visits [500.0, 218.0, 218.0, 217.0, 217.0, 217.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 14656 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6740 3 visits [500.0, 218.0, 218.0, 218.0, 217.0, 217.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 14657 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6741 4 visits [500.0, 218.0, 218.0, 218.0, 218.0, 217.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 14658 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6742 5 visits [500.0, 218.0, 218.0, 218.0, 218.0, 218.0, 217.0, 217.0, 500.0, 217.0]  episode_count: 14659 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14663, "number_of_timesteps": 307392, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6743 6 visits [500.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 217.0, 500.0, 217.0]  episode_count: 14663 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6744 7 visits [500.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 500.0, 217.0]  episode_count: 14667 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6745 9 visits [500.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 14667 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6746 1 visits [500.0, 219.0, 218.0, 218.0, 218.0, 218.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 14669 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6747 2 visits [500.0, 219.0, 219.0, 218.0, 218.0, 218.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 14672 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14673, "number_of_timesteps": 307602, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6748 3 visits [500.0, 219.0, 219.0, 219.0, 218.0, 218.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 14673 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6749 4 visits [500.0, 219.0, 219.0, 219.0, 219.0, 218.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 14675 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6750 5 visits [500.0, 219.0, 219.0, 219.0, 219.0, 219.0, 218.0, 218.0, 500.0, 218.0]  episode_count: 14676 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6751 6 visits [500.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 218.0, 500.0, 218.0]  episode_count: 14679 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6752 7 visits [500.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 500.0, 218.0]  episode_count: 14681 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14684, "number_of_timesteps": 307869, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6753 9 visits [500.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 14684 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6754 1 visits [500.0, 220.0, 219.0, 219.0, 219.0, 219.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 14685 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6755 2 visits [500.0, 220.0, 220.0, 219.0, 219.0, 219.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 14688 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6756 3 visits [500.0, 220.0, 220.0, 220.0, 219.0, 219.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 14689 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6757 4 visits [500.0, 220.0, 220.0, 220.0, 220.0, 219.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 14692 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14694, "number_of_timesteps": 308091, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6758 5 visits [500.0, 220.0, 220.0, 220.0, 220.0, 220.0, 219.0, 219.0, 500.0, 219.0]  episode_count: 14694 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6759 6 visits [500.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 219.0, 500.0, 219.0]  episode_count: 14695 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6760 7 visits [500.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 500.0, 219.0]  episode_count: 14696 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6761 9 visits [500.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 14700 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6762 1 visits [500.0, 221.0, 220.0, 220.0, 220.0, 220.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 14701 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6763 2 visits [500.0, 221.0, 221.0, 220.0, 220.0, 220.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 14703 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14704, "number_of_timesteps": 308331, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6764 3 visits [500.0, 221.0, 221.0, 221.0, 220.0, 220.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 14704 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6765 4 visits [500.0, 221.0, 221.0, 221.0, 221.0, 220.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 14707 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6766 5 visits [500.0, 221.0, 221.0, 221.0, 221.0, 221.0, 220.0, 220.0, 500.0, 220.0]  episode_count: 14710 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6767 6 visits [500.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 220.0, 500.0, 220.0]  episode_count: 14713 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14715, "number_of_timesteps": 308582, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6768 7 visits [500.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 500.0, 220.0]  episode_count: 14715 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6769 9 visits [500.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 14718 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6770 1 visits [500.0, 222.0, 221.0, 221.0, 221.0, 221.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 14722 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6771 2 visits [500.0, 222.0, 222.0, 221.0, 221.0, 221.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 14722 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6772 3 visits [500.0, 222.0, 222.0, 222.0, 221.0, 221.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 14722 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14727, "number_of_timesteps": 308790, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6773 4 visits [500.0, 222.0, 222.0, 222.0, 222.0, 221.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 14727 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6774 5 visits [500.0, 222.0, 222.0, 222.0, 222.0, 222.0, 221.0, 221.0, 500.0, 221.0]  episode_count: 14728 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6775 6 visits [500.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 221.0, 500.0, 221.0]  episode_count: 14730 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6776 7 visits [500.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 500.0, 221.0]  episode_count: 14734 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6777 9 visits [500.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 14735 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14738, "number_of_timesteps": 309015, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6778 1 visits [500.0, 223.0, 222.0, 222.0, 222.0, 222.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 14738 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6779 2 visits [500.0, 223.0, 223.0, 222.0, 222.0, 222.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 14742 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6780 3 visits [500.0, 223.0, 223.0, 223.0, 222.0, 222.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 14744 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6781 4 visits [500.0, 223.0, 223.0, 223.0, 223.0, 222.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 14747 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14750, "number_of_timesteps": 309218, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6782 5 visits [500.0, 223.0, 223.0, 223.0, 223.0, 223.0, 222.0, 222.0, 500.0, 222.0]  episode_count: 14750 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6783 6 visits [500.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 222.0, 500.0, 222.0]  episode_count: 14754 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6784 7 visits [500.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 500.0, 222.0]  episode_count: 14754 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6785 9 visits [500.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 14755 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14760, "number_of_timesteps": 309384, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6786 1 visits [500.0, 224.0, 223.0, 223.0, 223.0, 223.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 14760 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6787 2 visits [500.0, 224.0, 224.0, 223.0, 223.0, 223.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 14762 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6788 3 visits [500.0, 224.0, 224.0, 224.0, 223.0, 223.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 14762 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6789 4 visits [500.0, 224.0, 224.0, 224.0, 224.0, 223.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 14765 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6790 5 visits [500.0, 224.0, 224.0, 224.0, 224.0, 224.0, 223.0, 223.0, 500.0, 223.0]  episode_count: 14769 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14770, "number_of_timesteps": 309558, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6791 6 visits [500.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 223.0, 500.0, 223.0]  episode_count: 14770 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6792 7 visits [500.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 500.0, 223.0]  episode_count: 14774 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6793 9 visits [500.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 14776 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6794 1 visits [500.0, 225.0, 224.0, 224.0, 224.0, 224.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 14778 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14782, "number_of_timesteps": 309816, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6795 2 visits [500.0, 225.0, 225.0, 224.0, 224.0, 224.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 14782 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6796 3 visits [500.0, 225.0, 225.0, 225.0, 224.0, 224.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 14784 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6797 4 visits [500.0, 225.0, 225.0, 225.0, 225.0, 224.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 14785 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6798 5 visits [500.0, 225.0, 225.0, 225.0, 225.0, 225.0, 224.0, 224.0, 500.0, 224.0]  episode_count: 14786 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6799 6 visits [500.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 224.0, 500.0, 224.0]  episode_count: 14788 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6800 7 visits [500.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 500.0, 224.0]  episode_count: 14791 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14793, "number_of_timesteps": 310028, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6801 9 visits [500.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 14793 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6802 1 visits [500.0, 226.0, 225.0, 225.0, 225.0, 225.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 14794 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6803 2 visits [500.0, 226.0, 226.0, 225.0, 225.0, 225.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 14796 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6804 3 visits [500.0, 226.0, 226.0, 226.0, 225.0, 225.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 14797 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6805 4 visits [500.0, 226.0, 226.0, 226.0, 226.0, 225.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 14798 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6806 5 visits [500.0, 226.0, 226.0, 226.0, 226.0, 226.0, 225.0, 225.0, 500.0, 225.0]  episode_count: 14800 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14804, "number_of_timesteps": 310334, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6807 6 visits [500.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 225.0, 500.0, 225.0]  episode_count: 14804 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6808 7 visits [500.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 500.0, 225.0]  episode_count: 14806 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6809 9 visits [500.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 14809 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6810 1 visits [500.0, 227.0, 226.0, 226.0, 226.0, 226.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 14810 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6811 2 visits [500.0, 227.0, 227.0, 226.0, 226.0, 226.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 14811 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14815, "number_of_timesteps": 310569, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6812 3 visits [500.0, 227.0, 227.0, 227.0, 226.0, 226.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 14815 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6813 4 visits [500.0, 227.0, 227.0, 227.0, 227.0, 226.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 14816 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6814 5 visits [500.0, 227.0, 227.0, 227.0, 227.0, 227.0, 226.0, 226.0, 500.0, 226.0]  episode_count: 14819 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6815 6 visits [500.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 226.0, 500.0, 226.0]  episode_count: 14820 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6816 7 visits [500.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 500.0, 226.0]  episode_count: 14824 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14826, "number_of_timesteps": 310811, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6817 9 visits [500.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 14826 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6818 1 visits [500.0, 228.0, 227.0, 227.0, 227.0, 227.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 14827 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6819 2 visits [500.0, 228.0, 228.0, 227.0, 227.0, 227.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 14827 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6820 3 visits [500.0, 228.0, 228.0, 228.0, 227.0, 227.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 14829 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6821 4 visits [500.0, 228.0, 228.0, 228.0, 228.0, 227.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 14833 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6822 5 visits [500.0, 228.0, 228.0, 228.0, 228.0, 228.0, 227.0, 227.0, 500.0, 227.0]  episode_count: 14833 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6823 6 visits [500.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 227.0, 500.0, 227.0]  episode_count: 14834 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14837, "number_of_timesteps": 311072, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6824 7 visits [500.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 500.0, 227.0]  episode_count: 14837 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6825 9 visits [500.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 14841 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6826 1 visits [500.0, 229.0, 228.0, 228.0, 228.0, 228.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 14843 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6827 2 visits [500.0, 229.0, 229.0, 228.0, 228.0, 228.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 14845 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14848, "number_of_timesteps": 311329, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6828 3 visits [500.0, 229.0, 229.0, 229.0, 228.0, 228.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 14848 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6829 4 visits [500.0, 229.0, 229.0, 229.0, 229.0, 228.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 14849 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6830 5 visits [500.0, 229.0, 229.0, 229.0, 229.0, 229.0, 228.0, 228.0, 500.0, 228.0]  episode_count: 14852 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6831 6 visits [500.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 228.0, 500.0, 228.0]  episode_count: 14854 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6832 7 visits [500.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 500.0, 228.0]  episode_count: 14856 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6833 9 visits [500.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 14857 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14859, "number_of_timesteps": 311515, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6834 1 visits [500.0, 230.0, 229.0, 229.0, 229.0, 229.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 14859 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6835 2 visits [500.0, 230.0, 230.0, 229.0, 229.0, 229.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 14860 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6836 3 visits [500.0, 230.0, 230.0, 230.0, 229.0, 229.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 14863 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6837 4 visits [500.0, 230.0, 230.0, 230.0, 230.0, 229.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 14866 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14869, "number_of_timesteps": 311800, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6838 5 visits [500.0, 230.0, 230.0, 230.0, 230.0, 230.0, 229.0, 229.0, 500.0, 229.0]  episode_count: 14869 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6839 6 visits [500.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 229.0, 500.0, 229.0]  episode_count: 14869 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6840 7 visits [500.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 500.0, 229.0]  episode_count: 14874 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6841 9 visits [500.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 14876 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6842 1 visits [500.0, 231.0, 230.0, 230.0, 230.0, 230.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 14877 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6843 2 visits [500.0, 231.0, 231.0, 230.0, 230.0, 230.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 14878 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14881, "number_of_timesteps": 312022, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6844 3 visits [500.0, 231.0, 231.0, 231.0, 230.0, 230.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 14881 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6845 4 visits [500.0, 231.0, 231.0, 231.0, 231.0, 230.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 14883 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6846 5 visits [500.0, 231.0, 231.0, 231.0, 231.0, 231.0, 230.0, 230.0, 500.0, 230.0]  episode_count: 14887 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6847 6 visits [500.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 230.0, 500.0, 230.0]  episode_count: 14889 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14891, "number_of_timesteps": 312203, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6848 7 visits [500.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 500.0, 230.0]  episode_count: 14891 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6849 9 visits [500.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 14892 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6850 1 visits [500.0, 232.0, 231.0, 231.0, 231.0, 231.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 14895 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6851 2 visits [500.0, 232.0, 232.0, 231.0, 231.0, 231.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 14895 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14901, "number_of_timesteps": 312412, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6852 3 visits [500.0, 232.0, 232.0, 232.0, 231.0, 231.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 14901 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6853 4 visits [500.0, 232.0, 232.0, 232.0, 232.0, 231.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 14902 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6854 5 visits [500.0, 232.0, 232.0, 232.0, 232.0, 232.0, 231.0, 231.0, 500.0, 231.0]  episode_count: 14902 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6855 6 visits [500.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 231.0, 500.0, 231.0]  episode_count: 14904 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6856 7 visits [500.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 500.0, 231.0]  episode_count: 14905 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6857 9 visits [500.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 14907 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6858 1 visits [500.0, 233.0, 232.0, 232.0, 232.0, 232.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 14910 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14911, "number_of_timesteps": 312639, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6859 2 visits [500.0, 233.0, 233.0, 232.0, 232.0, 232.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 14911 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6860 3 visits [500.0, 233.0, 233.0, 233.0, 232.0, 232.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 14914 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6861 4 visits [500.0, 233.0, 233.0, 233.0, 233.0, 232.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 14916 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6862 5 visits [500.0, 233.0, 233.0, 233.0, 233.0, 233.0, 232.0, 232.0, 500.0, 232.0]  episode_count: 14917 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14921, "number_of_timesteps": 312868, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6863 6 visits [500.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 232.0, 500.0, 232.0]  episode_count: 14921 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6864 7 visits [500.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 500.0, 232.0]  episode_count: 14921 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6865 9 visits [500.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 14923 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6866 1 visits [500.0, 234.0, 233.0, 233.0, 233.0, 233.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 14925 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6867 2 visits [500.0, 234.0, 234.0, 233.0, 233.0, 233.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 14930 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14932, "number_of_timesteps": 313173, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6868 3 visits [500.0, 234.0, 234.0, 234.0, 233.0, 233.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 14932 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6869 4 visits [500.0, 234.0, 234.0, 234.0, 234.0, 233.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 14932 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6870 5 visits [500.0, 234.0, 234.0, 234.0, 234.0, 234.0, 233.0, 233.0, 500.0, 233.0]  episode_count: 14933 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6871 6 visits [500.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 233.0, 500.0, 233.0]  episode_count: 14938 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6872 7 visits [500.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 500.0, 233.0]  episode_count: 14941 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14943, "number_of_timesteps": 313393, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6873 9 visits [500.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 14943 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6874 1 visits [500.0, 235.0, 234.0, 234.0, 234.0, 234.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 14946 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6875 2 visits [500.0, 235.0, 235.0, 234.0, 234.0, 234.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 14947 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6876 3 visits [500.0, 235.0, 235.0, 235.0, 234.0, 234.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 14950 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6877 4 visits [500.0, 235.0, 235.0, 235.0, 235.0, 234.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 14952 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14953, "number_of_timesteps": 313553, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6878 5 visits [500.0, 235.0, 235.0, 235.0, 235.0, 235.0, 234.0, 234.0, 500.0, 234.0]  episode_count: 14953 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6879 6 visits [500.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 234.0, 500.0, 234.0]  episode_count: 14955 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6880 7 visits [500.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 500.0, 234.0]  episode_count: 14959 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14963, "number_of_timesteps": 313775, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6881 9 visits [500.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 14963 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6882 1 visits [500.0, 236.0, 235.0, 235.0, 235.0, 235.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 14965 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6883 2 visits [500.0, 236.0, 236.0, 235.0, 235.0, 235.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 14966 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6884 3 visits [500.0, 236.0, 236.0, 236.0, 235.0, 235.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 14970 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6885 4 visits [500.0, 236.0, 236.0, 236.0, 236.0, 235.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 14971 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14974, "number_of_timesteps": 313971, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6886 5 visits [500.0, 236.0, 236.0, 236.0, 236.0, 236.0, 235.0, 235.0, 500.0, 235.0]  episode_count: 14974 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6887 6 visits [500.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 235.0, 500.0, 235.0]  episode_count: 14976 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6888 7 visits [500.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 500.0, 235.0]  episode_count: 14978 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6889 9 visits [500.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 14980 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14985, "number_of_timesteps": 314164, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6890 1 visits [500.0, 237.0, 236.0, 236.0, 236.0, 236.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 14985 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6891 2 visits [500.0, 237.0, 237.0, 236.0, 236.0, 236.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 14987 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6892 3 visits [500.0, 237.0, 237.0, 237.0, 236.0, 236.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 14988 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6893 4 visits [500.0, 237.0, 237.0, 237.0, 237.0, 236.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 14991 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 14995, "number_of_timesteps": 314316, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6894 5 visits [500.0, 237.0, 237.0, 237.0, 237.0, 237.0, 236.0, 236.0, 500.0, 236.0]  episode_count: 14995 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6895 6 visits [500.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 236.0, 500.0, 236.0]  episode_count: 14999 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6896 7 visits [500.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 500.0, 236.0]  episode_count: 14999 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6897 9 visits [500.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 15002 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6898 1 visits [500.0, 238.0, 237.0, 237.0, 237.0, 237.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 15003 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15005, "number_of_timesteps": 314524, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6899 2 visits [500.0, 238.0, 238.0, 237.0, 237.0, 237.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 15005 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6900 3 visits [500.0, 238.0, 238.0, 238.0, 237.0, 237.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 15008 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6901 4 visits [500.0, 238.0, 238.0, 238.0, 238.0, 237.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 15012 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6902 5 visits [500.0, 238.0, 238.0, 238.0, 238.0, 238.0, 237.0, 237.0, 500.0, 237.0]  episode_count: 15013 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15015, "number_of_timesteps": 314723, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6903 6 visits [500.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 237.0, 500.0, 237.0]  episode_count: 15015 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6904 7 visits [500.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 500.0, 237.0]  episode_count: 15019 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6905 9 visits [500.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 15022 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6906 1 visits [500.0, 239.0, 238.0, 238.0, 238.0, 238.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 15022 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15025, "number_of_timesteps": 314892, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6907 2 visits [500.0, 239.0, 239.0, 238.0, 238.0, 238.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 15025 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6908 3 visits [500.0, 239.0, 239.0, 239.0, 238.0, 238.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 15027 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6909 4 visits [500.0, 239.0, 239.0, 239.0, 239.0, 238.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 15028 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6910 5 visits [500.0, 239.0, 239.0, 239.0, 239.0, 239.0, 238.0, 238.0, 500.0, 238.0]  episode_count: 15032 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6911 6 visits [500.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 238.0, 500.0, 238.0]  episode_count: 15033 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15035, "number_of_timesteps": 315104, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6912 7 visits [500.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 500.0, 238.0]  episode_count: 15035 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6913 9 visits [500.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 15037 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6914 1 visits [500.0, 240.0, 239.0, 239.0, 239.0, 239.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 15039 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6915 2 visits [500.0, 240.0, 240.0, 239.0, 239.0, 239.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 15040 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6916 3 visits [500.0, 240.0, 240.0, 240.0, 239.0, 239.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 15042 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6917 4 visits [500.0, 240.0, 240.0, 240.0, 240.0, 239.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 15043 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15045, "number_of_timesteps": 315346, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6918 5 visits [500.0, 240.0, 240.0, 240.0, 240.0, 240.0, 239.0, 239.0, 500.0, 239.0]  episode_count: 15045 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6919 6 visits [500.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 239.0, 500.0, 239.0]  episode_count: 15047 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6920 7 visits [500.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 500.0, 239.0]  episode_count: 15049 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6921 9 visits [500.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 15052 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6922 1 visits [500.0, 241.0, 240.0, 240.0, 240.0, 240.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 15053 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15056, "number_of_timesteps": 315588, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 6923 2 visits [500.0, 241.0, 241.0, 240.0, 240.0, 240.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 15056 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6924 3 visits [500.0, 241.0, 241.0, 241.0, 240.0, 240.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 15059 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6925 4 visits [500.0, 241.0, 241.0, 241.0, 241.0, 240.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 15060 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6926 5 visits [500.0, 241.0, 241.0, 241.0, 241.0, 241.0, 240.0, 240.0, 500.0, 240.0]  episode_count: 15062 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15066, "number_of_timesteps": 315804, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 6927 6 visits [500.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 240.0, 500.0, 240.0]  episode_count: 15066 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6928 7 visits [500.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 500.0, 240.0]  episode_count: 15066 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6929 9 visits [500.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 15071 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6930 1 visits [500.0, 242.0, 241.0, 241.0, 241.0, 241.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 15073 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6931 2 visits [500.0, 242.0, 242.0, 241.0, 241.0, 241.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 15073 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6932 3 visits [500.0, 242.0, 242.0, 242.0, 241.0, 241.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 15075 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15078, "number_of_timesteps": 316072, "per_episode_reward": 14.05, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 6933 4 visits [500.0, 242.0, 242.0, 242.0, 242.0, 241.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 15078 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6934 5 visits [500.0, 242.0, 242.0, 242.0, 242.0, 242.0, 241.0, 241.0, 500.0, 241.0]  episode_count: 15081 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6935 6 visits [500.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 241.0, 500.0, 241.0]  episode_count: 15084 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6936 7 visits [500.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 500.0, 241.0]  episode_count: 15085 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6937 9 visits [500.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 15087 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15088, "number_of_timesteps": 316276, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 6938 1 visits [500.0, 243.0, 242.0, 242.0, 242.0, 242.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 15088 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6939 2 visits [500.0, 243.0, 243.0, 242.0, 242.0, 242.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 15091 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6940 3 visits [500.0, 243.0, 243.0, 243.0, 242.0, 242.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 15095 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6941 4 visits [500.0, 243.0, 243.0, 243.0, 243.0, 242.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 15096 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6942 5 visits [500.0, 243.0, 243.0, 243.0, 243.0, 243.0, 242.0, 242.0, 500.0, 242.0]  episode_count: 15096 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15100, "number_of_timesteps": 316542, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 6943 6 visits [500.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 242.0, 500.0, 242.0]  episode_count: 15100 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6944 7 visits [500.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 500.0, 242.0]  episode_count: 15101 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6945 9 visits [500.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 15104 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6946 1 visits [500.0, 244.0, 243.0, 243.0, 243.0, 243.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 15106 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6947 2 visits [500.0, 244.0, 244.0, 243.0, 243.0, 243.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 15108 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15110, "number_of_timesteps": 316766, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 6948 3 visits [500.0, 244.0, 244.0, 244.0, 243.0, 243.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 15110 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6949 4 visits [500.0, 244.0, 244.0, 244.0, 244.0, 243.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 15112 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6950 5 visits [500.0, 244.0, 244.0, 244.0, 244.0, 244.0, 243.0, 243.0, 500.0, 243.0]  episode_count: 15116 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6951 6 visits [500.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 243.0, 500.0, 243.0]  episode_count: 15118 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6952 7 visits [500.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 500.0, 243.0]  episode_count: 15118 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15120, "number_of_timesteps": 316991, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 6953 9 visits [500.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 15120 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6954 1 visits [500.0, 245.0, 244.0, 244.0, 244.0, 244.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 15122 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6955 2 visits [500.0, 245.0, 245.0, 244.0, 244.0, 244.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 15124 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6956 3 visits [500.0, 245.0, 245.0, 245.0, 244.0, 244.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 15127 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6957 4 visits [500.0, 245.0, 245.0, 245.0, 245.0, 244.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 15128 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15132, "number_of_timesteps": 317272, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 6958 5 visits [500.0, 245.0, 245.0, 245.0, 245.0, 245.0, 244.0, 244.0, 500.0, 244.0]  episode_count: 15132 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6959 6 visits [500.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 244.0, 500.0, 244.0]  episode_count: 15133 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6960 7 visits [500.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 500.0, 244.0]  episode_count: 15136 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6961 9 visits [500.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 15138 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6962 1 visits [500.0, 246.0, 245.0, 245.0, 245.0, 245.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 15140 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15144, "number_of_timesteps": 317504, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 6963 2 visits [500.0, 246.0, 246.0, 245.0, 245.0, 245.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 15144 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6964 3 visits [500.0, 246.0, 246.0, 246.0, 245.0, 245.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 15146 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6965 4 visits [500.0, 246.0, 246.0, 246.0, 246.0, 245.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 15147 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6966 5 visits [500.0, 246.0, 246.0, 246.0, 246.0, 246.0, 245.0, 245.0, 500.0, 245.0]  episode_count: 15150 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6967 6 visits [500.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 245.0, 500.0, 245.0]  episode_count: 15152 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15155, "number_of_timesteps": 317692, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6968 7 visits [500.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 500.0, 245.0]  episode_count: 15155 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6969 9 visits [500.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 15159 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6970 1 visits [500.0, 247.0, 246.0, 246.0, 246.0, 246.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 15159 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6971 2 visits [500.0, 247.0, 247.0, 246.0, 246.0, 246.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 15162 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6972 3 visits [500.0, 247.0, 247.0, 247.0, 246.0, 246.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 15164 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15168, "number_of_timesteps": 317949, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 6973 4 visits [500.0, 247.0, 247.0, 247.0, 247.0, 246.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 15168 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6974 5 visits [500.0, 247.0, 247.0, 247.0, 247.0, 247.0, 246.0, 246.0, 500.0, 246.0]  episode_count: 15169 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6975 6 visits [500.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 246.0, 500.0, 246.0]  episode_count: 15170 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6976 7 visits [500.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 500.0, 246.0]  episode_count: 15172 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6977 9 visits [500.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 15175 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6978 1 visits [500.0, 248.0, 247.0, 247.0, 247.0, 247.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 15176 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15178, "number_of_timesteps": 318145, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 6979 2 visits [500.0, 248.0, 248.0, 247.0, 247.0, 247.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 15178 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6980 3 visits [500.0, 248.0, 248.0, 248.0, 247.0, 247.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 15180 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6981 4 visits [500.0, 248.0, 248.0, 248.0, 248.0, 247.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 15182 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6982 5 visits [500.0, 248.0, 248.0, 248.0, 248.0, 248.0, 247.0, 247.0, 500.0, 247.0]  episode_count: 15183 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6983 6 visits [500.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 247.0, 500.0, 247.0]  episode_count: 15186 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15188, "number_of_timesteps": 318395, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6984 7 visits [500.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 500.0, 247.0]  episode_count: 15188 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6985 9 visits [500.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 15190 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6986 1 visits [500.0, 249.0, 248.0, 248.0, 248.0, 248.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 15193 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6987 2 visits [500.0, 249.0, 249.0, 248.0, 248.0, 248.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 15196 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15199, "number_of_timesteps": 318653, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6988 3 visits [500.0, 249.0, 249.0, 249.0, 248.0, 248.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 15199 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6989 4 visits [500.0, 249.0, 249.0, 249.0, 249.0, 248.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 15199 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6990 5 visits [500.0, 249.0, 249.0, 249.0, 249.0, 249.0, 248.0, 248.0, 500.0, 248.0]  episode_count: 15201 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6991 6 visits [500.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 248.0, 500.0, 248.0]  episode_count: 15203 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6992 7 visits [500.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 500.0, 248.0]  episode_count: 15204 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6993 9 visits [500.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 15207 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15209, "number_of_timesteps": 318856, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6994 1 visits [500.0, 250.0, 249.0, 249.0, 249.0, 249.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 15209 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6995 2 visits [500.0, 250.0, 250.0, 249.0, 249.0, 249.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 15210 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6996 3 visits [500.0, 250.0, 250.0, 250.0, 249.0, 249.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 15213 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6997 4 visits [500.0, 250.0, 250.0, 250.0, 250.0, 249.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 15217 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 6998 5 visits [500.0, 250.0, 250.0, 250.0, 250.0, 250.0, 249.0, 249.0, 500.0, 249.0]  episode_count: 15218 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15220, "number_of_timesteps": 319123, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 6999 6 visits [500.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 249.0, 500.0, 249.0]  episode_count: 15220 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7000 7 visits [500.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 500.0, 249.0]  episode_count: 15221 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7001 9 visits [500.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 15223 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7002 1 visits [500.0, 251.0, 250.0, 250.0, 250.0, 250.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 15224 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7003 2 visits [500.0, 251.0, 251.0, 250.0, 250.0, 250.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 15226 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7004 3 visits [500.0, 251.0, 251.0, 251.0, 250.0, 250.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 15226 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7005 4 visits [500.0, 251.0, 251.0, 251.0, 251.0, 250.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 15229 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15231, "number_of_timesteps": 319398, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7006 5 visits [500.0, 251.0, 251.0, 251.0, 251.0, 251.0, 250.0, 250.0, 500.0, 250.0]  episode_count: 15231 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7007 6 visits [500.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 250.0, 500.0, 250.0]  episode_count: 15234 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7008 7 visits [500.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 500.0, 250.0]  episode_count: 15235 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7009 9 visits [500.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 15236 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7010 1 visits [500.0, 252.0, 251.0, 251.0, 251.0, 251.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 15240 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15243, "number_of_timesteps": 319679, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7011 2 visits [500.0, 252.0, 252.0, 251.0, 251.0, 251.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 15243 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7012 3 visits [500.0, 252.0, 252.0, 252.0, 251.0, 251.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 15243 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7013 4 visits [500.0, 252.0, 252.0, 252.0, 252.0, 251.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 15247 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7014 5 visits [500.0, 252.0, 252.0, 252.0, 252.0, 252.0, 251.0, 251.0, 500.0, 251.0]  episode_count: 15249 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7015 6 visits [500.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 251.0, 500.0, 251.0]  episode_count: 15252 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15253, "number_of_timesteps": 319908, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7016 7 visits [500.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 500.0, 251.0]  episode_count: 15253 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7017 9 visits [500.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 15256 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7018 1 visits [500.0, 253.0, 252.0, 252.0, 252.0, 252.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 15259 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7019 2 visits [500.0, 253.0, 253.0, 252.0, 252.0, 252.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 15259 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7020 3 visits [500.0, 253.0, 253.0, 253.0, 252.0, 252.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 15262 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15265, "number_of_timesteps": 320110, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7021 4 visits [500.0, 253.0, 253.0, 253.0, 253.0, 252.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 15265 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7022 5 visits [500.0, 253.0, 253.0, 253.0, 253.0, 253.0, 252.0, 252.0, 500.0, 252.0]  episode_count: 15267 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7023 6 visits [500.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 252.0, 500.0, 252.0]  episode_count: 15268 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7024 7 visits [500.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 500.0, 252.0]  episode_count: 15270 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7025 9 visits [500.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 15270 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7026 1 visits [500.0, 254.0, 253.0, 253.0, 253.0, 253.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 15274 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15276, "number_of_timesteps": 320330, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7027 2 visits [500.0, 254.0, 254.0, 253.0, 253.0, 253.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 15276 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7028 3 visits [500.0, 254.0, 254.0, 254.0, 253.0, 253.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 15277 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7029 4 visits [500.0, 254.0, 254.0, 254.0, 254.0, 253.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 15279 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7030 5 visits [500.0, 254.0, 254.0, 254.0, 254.0, 254.0, 253.0, 253.0, 500.0, 253.0]  episode_count: 15280 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7031 6 visits [500.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 253.0, 500.0, 253.0]  episode_count: 15284 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7032 7 visits [500.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 500.0, 253.0]  episode_count: 15284 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15287, "number_of_timesteps": 320677, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7033 9 visits [500.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 15287 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7034 1 visits [500.0, 255.0, 254.0, 254.0, 254.0, 254.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 15291 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7035 2 visits [500.0, 255.0, 255.0, 254.0, 254.0, 254.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 15292 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7036 3 visits [500.0, 255.0, 255.0, 255.0, 254.0, 254.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 15293 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7037 4 visits [500.0, 255.0, 255.0, 255.0, 255.0, 254.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 15296 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15299, "number_of_timesteps": 320906, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7038 5 visits [500.0, 255.0, 255.0, 255.0, 255.0, 255.0, 254.0, 254.0, 500.0, 254.0]  episode_count: 15299 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7039 6 visits [500.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 254.0, 500.0, 254.0]  episode_count: 15299 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7040 7 visits [500.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 500.0, 254.0]  episode_count: 15302 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7041 9 visits [500.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 15304 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7042 1 visits [500.0, 256.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 15306 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7043 2 visits [500.0, 256.0, 256.0, 255.0, 255.0, 255.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 15308 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15310, "number_of_timesteps": 321149, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7044 3 visits [500.0, 256.0, 256.0, 256.0, 255.0, 255.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 15310 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7045 4 visits [500.0, 256.0, 256.0, 256.0, 256.0, 255.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 15313 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7046 5 visits [500.0, 256.0, 256.0, 256.0, 256.0, 256.0, 255.0, 255.0, 500.0, 255.0]  episode_count: 15315 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7047 6 visits [500.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 255.0, 500.0, 255.0]  episode_count: 15317 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15320, "number_of_timesteps": 321379, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7048 7 visits [500.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 500.0, 255.0]  episode_count: 15320 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7049 9 visits [500.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 15323 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7050 1 visits [500.0, 257.0, 256.0, 256.0, 256.0, 256.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 15325 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7051 2 visits [500.0, 257.0, 257.0, 256.0, 256.0, 256.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 15327 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15330, "number_of_timesteps": 321557, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7052 3 visits [500.0, 257.0, 257.0, 257.0, 256.0, 256.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 15330 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7053 4 visits [500.0, 257.0, 257.0, 257.0, 257.0, 256.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 15331 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7054 5 visits [500.0, 257.0, 257.0, 257.0, 257.0, 257.0, 256.0, 256.0, 500.0, 256.0]  episode_count: 15334 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7055 6 visits [500.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 256.0, 500.0, 256.0]  episode_count: 15336 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7056 7 visits [500.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 500.0, 256.0]  episode_count: 15339 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15340, "number_of_timesteps": 321724, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7057 9 visits [500.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 15340 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7058 1 visits [500.0, 258.0, 257.0, 257.0, 257.0, 257.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 15344 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7059 2 visits [500.0, 258.0, 258.0, 257.0, 257.0, 257.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 15345 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7060 3 visits [500.0, 258.0, 258.0, 258.0, 257.0, 257.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 15349 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7061 4 visits [500.0, 258.0, 258.0, 258.0, 258.0, 257.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 15349 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15350, "number_of_timesteps": 321928, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7062 5 visits [500.0, 258.0, 258.0, 258.0, 258.0, 258.0, 257.0, 257.0, 500.0, 257.0]  episode_count: 15350 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7063 6 visits [500.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 257.0, 500.0, 257.0]  episode_count: 15353 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7064 7 visits [500.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 500.0, 257.0]  episode_count: 15354 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7065 9 visits [500.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 15356 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15360, "number_of_timesteps": 322156, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7066 1 visits [500.0, 259.0, 258.0, 258.0, 258.0, 258.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 15360 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7067 2 visits [500.0, 259.0, 259.0, 258.0, 258.0, 258.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 15363 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7068 3 visits [500.0, 259.0, 259.0, 259.0, 258.0, 258.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 15363 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7069 4 visits [500.0, 259.0, 259.0, 259.0, 259.0, 258.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 15366 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15370, "number_of_timesteps": 322391, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7070 5 visits [500.0, 259.0, 259.0, 259.0, 259.0, 259.0, 258.0, 258.0, 500.0, 258.0]  episode_count: 15370 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7071 6 visits [500.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 258.0, 500.0, 258.0]  episode_count: 15372 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7072 7 visits [500.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 500.0, 258.0]  episode_count: 15373 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7073 9 visits [500.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 15374 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7074 1 visits [500.0, 260.0, 259.0, 259.0, 259.0, 259.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 15375 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7075 2 visits [500.0, 260.0, 260.0, 259.0, 259.0, 259.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 15379 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15382, "number_of_timesteps": 322666, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7076 3 visits [500.0, 260.0, 260.0, 260.0, 259.0, 259.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 15382 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7077 4 visits [500.0, 260.0, 260.0, 260.0, 260.0, 259.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 15383 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7078 5 visits [500.0, 260.0, 260.0, 260.0, 260.0, 260.0, 259.0, 259.0, 500.0, 259.0]  episode_count: 15387 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7079 6 visits [500.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 259.0, 500.0, 259.0]  episode_count: 15388 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7080 7 visits [500.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 500.0, 259.0]  episode_count: 15391 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15394, "number_of_timesteps": 322868, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7081 9 visits [500.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 15394 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7082 1 visits [500.0, 261.0, 260.0, 260.0, 260.0, 260.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 15396 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7083 2 visits [500.0, 261.0, 261.0, 260.0, 260.0, 260.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 15396 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7084 3 visits [500.0, 261.0, 261.0, 261.0, 260.0, 260.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 15400 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7085 4 visits [500.0, 261.0, 261.0, 261.0, 261.0, 260.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 15402 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15404, "number_of_timesteps": 323096, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7086 5 visits [500.0, 261.0, 261.0, 261.0, 261.0, 261.0, 260.0, 260.0, 500.0, 260.0]  episode_count: 15404 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7087 6 visits [500.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 260.0, 500.0, 260.0]  episode_count: 15407 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7088 7 visits [500.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 500.0, 260.0]  episode_count: 15410 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7089 9 visits [500.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 15413 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15414, "number_of_timesteps": 323287, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7090 1 visits [500.0, 262.0, 261.0, 261.0, 261.0, 261.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 15414 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7091 2 visits [500.0, 262.0, 262.0, 261.0, 261.0, 261.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 15417 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7092 3 visits [500.0, 262.0, 262.0, 262.0, 261.0, 261.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 15419 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7093 4 visits [500.0, 262.0, 262.0, 262.0, 262.0, 261.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 15421 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7094 5 visits [500.0, 262.0, 262.0, 262.0, 262.0, 262.0, 261.0, 261.0, 500.0, 261.0]  episode_count: 15423 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15424, "number_of_timesteps": 323463, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7095 6 visits [500.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 261.0, 500.0, 261.0]  episode_count: 15424 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7096 7 visits [500.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 500.0, 261.0]  episode_count: 15426 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7097 9 visits [500.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 15427 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7098 1 visits [500.0, 263.0, 262.0, 262.0, 262.0, 262.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 15429 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7099 2 visits [500.0, 263.0, 263.0, 262.0, 262.0, 262.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 15432 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15436, "number_of_timesteps": 323762, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7100 3 visits [500.0, 263.0, 263.0, 263.0, 262.0, 262.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 15436 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7101 4 visits [500.0, 263.0, 263.0, 263.0, 263.0, 262.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 15438 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7102 5 visits [500.0, 263.0, 263.0, 263.0, 263.0, 263.0, 262.0, 262.0, 500.0, 262.0]  episode_count: 15441 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7103 6 visits [500.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 262.0, 500.0, 262.0]  episode_count: 15442 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15446, "number_of_timesteps": 323935, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7104 7 visits [500.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 500.0, 262.0]  episode_count: 15446 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7105 9 visits [500.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 15449 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7106 1 visits [500.0, 264.0, 263.0, 263.0, 263.0, 263.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 15449 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7107 2 visits [500.0, 264.0, 264.0, 263.0, 263.0, 263.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 15453 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7108 3 visits [500.0, 264.0, 264.0, 264.0, 263.0, 263.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 15454 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15457, "number_of_timesteps": 324139, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7109 4 visits [500.0, 264.0, 264.0, 264.0, 264.0, 263.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 15457 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7110 5 visits [500.0, 264.0, 264.0, 264.0, 264.0, 264.0, 263.0, 263.0, 500.0, 263.0]  episode_count: 15459 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7111 6 visits [500.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 263.0, 500.0, 263.0]  episode_count: 15460 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7112 7 visits [500.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 500.0, 263.0]  episode_count: 15461 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7113 9 visits [500.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 15462 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7114 1 visits [500.0, 265.0, 264.0, 264.0, 264.0, 264.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 15463 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7115 2 visits [500.0, 265.0, 265.0, 264.0, 264.0, 264.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 15466 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15469, "number_of_timesteps": 324451, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7116 3 visits [500.0, 265.0, 265.0, 265.0, 264.0, 264.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 15469 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7117 4 visits [500.0, 265.0, 265.0, 265.0, 265.0, 264.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 15472 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7118 5 visits [500.0, 265.0, 265.0, 265.0, 265.0, 265.0, 264.0, 264.0, 500.0, 264.0]  episode_count: 15475 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7119 6 visits [500.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 264.0, 500.0, 264.0]  episode_count: 15477 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7120 7 visits [500.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 500.0, 264.0]  episode_count: 15477 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15480, "number_of_timesteps": 324665, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7121 9 visits [500.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 15480 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7122 1 visits [500.0, 266.0, 265.0, 265.0, 265.0, 265.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 15482 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7123 2 visits [500.0, 266.0, 266.0, 265.0, 265.0, 265.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 15484 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7124 3 visits [500.0, 266.0, 266.0, 266.0, 265.0, 265.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 15485 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7125 4 visits [500.0, 266.0, 266.0, 266.0, 266.0, 265.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 15488 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15490, "number_of_timesteps": 324895, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7126 5 visits [500.0, 266.0, 266.0, 266.0, 266.0, 266.0, 265.0, 265.0, 500.0, 265.0]  episode_count: 15490 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7127 6 visits [500.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 265.0, 500.0, 265.0]  episode_count: 15493 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7128 7 visits [500.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 500.0, 265.0]  episode_count: 15494 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7129 9 visits [500.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 15495 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7130 1 visits [500.0, 267.0, 266.0, 266.0, 266.0, 266.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 15499 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15500, "number_of_timesteps": 325126, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7131 2 visits [500.0, 267.0, 267.0, 266.0, 266.0, 266.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 15500 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7132 3 visits [500.0, 267.0, 267.0, 267.0, 266.0, 266.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 15502 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7133 4 visits [500.0, 267.0, 267.0, 267.0, 267.0, 266.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 15504 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7134 5 visits [500.0, 267.0, 267.0, 267.0, 267.0, 267.0, 266.0, 266.0, 500.0, 266.0]  episode_count: 15506 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7135 6 visits [500.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 266.0, 500.0, 266.0]  episode_count: 15509 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7136 7 visits [500.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 500.0, 266.0]  episode_count: 15509 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15512, "number_of_timesteps": 325412, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7137 9 visits [500.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 15512 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7138 1 visits [500.0, 268.0, 267.0, 267.0, 267.0, 267.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 15514 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7139 2 visits [500.0, 268.0, 268.0, 267.0, 267.0, 267.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 15518 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7140 3 visits [500.0, 268.0, 268.0, 268.0, 267.0, 267.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 15519 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15523, "number_of_timesteps": 325612, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7141 4 visits [500.0, 268.0, 268.0, 268.0, 268.0, 267.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 15523 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7142 5 visits [500.0, 268.0, 268.0, 268.0, 268.0, 268.0, 267.0, 267.0, 500.0, 267.0]  episode_count: 15525 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7143 6 visits [500.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 267.0, 500.0, 267.0]  episode_count: 15526 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7144 7 visits [500.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 500.0, 267.0]  episode_count: 15528 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15533, "number_of_timesteps": 325811, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7145 9 visits [500.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 15533 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7146 1 visits [500.0, 269.0, 268.0, 268.0, 268.0, 268.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 15535 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7147 2 visits [500.0, 269.0, 269.0, 268.0, 268.0, 268.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 15538 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7148 3 visits [500.0, 269.0, 269.0, 269.0, 268.0, 268.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 15539 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7149 4 visits [500.0, 269.0, 269.0, 269.0, 269.0, 268.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 15540 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7150 5 visits [500.0, 269.0, 269.0, 269.0, 269.0, 269.0, 268.0, 268.0, 500.0, 268.0]  episode_count: 15540 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15545, "number_of_timesteps": 326033, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7151 6 visits [500.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 268.0, 500.0, 268.0]  episode_count: 15545 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7152 7 visits [500.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 500.0, 268.0]  episode_count: 15548 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7153 9 visits [500.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 15549 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7154 1 visits [500.0, 270.0, 269.0, 269.0, 269.0, 269.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 15552 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15555, "number_of_timesteps": 326232, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7155 2 visits [500.0, 270.0, 270.0, 269.0, 269.0, 269.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 15555 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7156 3 visits [500.0, 270.0, 270.0, 270.0, 269.0, 269.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 15557 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7157 4 visits [500.0, 270.0, 270.0, 270.0, 270.0, 269.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 15561 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7158 5 visits [500.0, 270.0, 270.0, 270.0, 270.0, 270.0, 269.0, 269.0, 500.0, 269.0]  episode_count: 15563 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7159 6 visits [500.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 269.0, 500.0, 269.0]  episode_count: 15564 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15567, "number_of_timesteps": 326448, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7160 7 visits [500.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 500.0, 269.0]  episode_count: 15567 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7161 9 visits [500.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 15568 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7162 1 visits [500.0, 271.0, 270.0, 270.0, 270.0, 270.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 15569 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7163 2 visits [500.0, 271.0, 271.0, 270.0, 270.0, 270.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 15571 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7164 3 visits [500.0, 271.0, 271.0, 271.0, 270.0, 270.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 15575 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15577, "number_of_timesteps": 326680, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7165 4 visits [500.0, 271.0, 271.0, 271.0, 271.0, 270.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 15577 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7166 5 visits [500.0, 271.0, 271.0, 271.0, 271.0, 271.0, 270.0, 270.0, 500.0, 270.0]  episode_count: 15580 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7167 6 visits [500.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 270.0, 500.0, 270.0]  episode_count: 15582 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7168 7 visits [500.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 500.0, 270.0]  episode_count: 15583 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7169 9 visits [500.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 15586 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15589, "number_of_timesteps": 326906, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7170 1 visits [500.0, 272.0, 271.0, 271.0, 271.0, 271.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 15589 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7171 2 visits [500.0, 272.0, 272.0, 271.0, 271.0, 271.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 15590 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7172 3 visits [500.0, 272.0, 272.0, 272.0, 271.0, 271.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 15592 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7173 4 visits [500.0, 272.0, 272.0, 272.0, 272.0, 271.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 15596 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7174 5 visits [500.0, 272.0, 272.0, 272.0, 272.0, 272.0, 271.0, 271.0, 500.0, 271.0]  episode_count: 15598 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15600, "number_of_timesteps": 327128, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7175 6 visits [500.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 271.0, 500.0, 271.0]  episode_count: 15600 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7176 7 visits [500.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 500.0, 271.0]  episode_count: 15603 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7177 9 visits [500.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 15605 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7178 1 visits [500.0, 273.0, 272.0, 272.0, 272.0, 272.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 15605 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7179 2 visits [500.0, 273.0, 273.0, 272.0, 272.0, 272.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 15609 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15611, "number_of_timesteps": 327341, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7180 3 visits [500.0, 273.0, 273.0, 273.0, 272.0, 272.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 15611 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7181 4 visits [500.0, 273.0, 273.0, 273.0, 273.0, 272.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 15613 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7182 5 visits [500.0, 273.0, 273.0, 273.0, 273.0, 273.0, 272.0, 272.0, 500.0, 272.0]  episode_count: 15616 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7183 6 visits [500.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 272.0, 500.0, 272.0]  episode_count: 15617 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7184 7 visits [500.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 500.0, 272.0]  episode_count: 15620 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15622, "number_of_timesteps": 327569, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7185 9 visits [500.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 15622 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7186 1 visits [500.0, 274.0, 273.0, 273.0, 273.0, 273.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 15624 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7187 2 visits [500.0, 274.0, 274.0, 273.0, 273.0, 273.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 15625 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7188 3 visits [500.0, 274.0, 274.0, 274.0, 273.0, 273.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 15630 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15633, "number_of_timesteps": 327793, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7189 4 visits [500.0, 274.0, 274.0, 274.0, 274.0, 273.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 15633 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7190 5 visits [500.0, 274.0, 274.0, 274.0, 274.0, 274.0, 273.0, 273.0, 500.0, 273.0]  episode_count: 15635 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7191 6 visits [500.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 273.0, 500.0, 273.0]  episode_count: 15638 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7192 7 visits [500.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 500.0, 273.0]  episode_count: 15640 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15644, "number_of_timesteps": 327953, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7193 9 visits [500.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 15644 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7194 1 visits [500.0, 275.0, 274.0, 274.0, 274.0, 274.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 15645 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7195 2 visits [500.0, 275.0, 275.0, 274.0, 274.0, 274.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 15648 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7196 3 visits [500.0, 275.0, 275.0, 275.0, 274.0, 274.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 15651 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7197 4 visits [500.0, 275.0, 275.0, 275.0, 275.0, 274.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 15652 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15654, "number_of_timesteps": 328141, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7198 5 visits [500.0, 275.0, 275.0, 275.0, 275.0, 275.0, 274.0, 274.0, 500.0, 274.0]  episode_count: 15654 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7199 6 visits [500.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 274.0, 500.0, 274.0]  episode_count: 15655 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7200 7 visits [500.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 500.0, 274.0]  episode_count: 15657 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7201 9 visits [500.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 15663 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15664, "number_of_timesteps": 328369, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7202 1 visits [500.0, 276.0, 275.0, 275.0, 275.0, 275.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 15664 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7203 2 visits [500.0, 276.0, 276.0, 275.0, 275.0, 275.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 15667 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7204 3 visits [500.0, 276.0, 276.0, 276.0, 275.0, 275.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 15668 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7205 4 visits [500.0, 276.0, 276.0, 276.0, 276.0, 275.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 15670 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7206 5 visits [500.0, 276.0, 276.0, 276.0, 276.0, 276.0, 275.0, 275.0, 500.0, 275.0]  episode_count: 15671 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15674, "number_of_timesteps": 328535, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7207 6 visits [500.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 275.0, 500.0, 275.0]  episode_count: 15674 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7208 7 visits [500.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 500.0, 275.0]  episode_count: 15675 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7209 9 visits [500.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 15679 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7210 1 visits [500.0, 277.0, 276.0, 276.0, 276.0, 276.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 15681 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15685, "number_of_timesteps": 328778, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7211 2 visits [500.0, 277.0, 277.0, 276.0, 276.0, 276.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 15685 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7212 3 visits [500.0, 277.0, 277.0, 277.0, 276.0, 276.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 15687 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7213 4 visits [500.0, 277.0, 277.0, 277.0, 277.0, 276.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 15688 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7214 5 visits [500.0, 277.0, 277.0, 277.0, 277.0, 277.0, 276.0, 276.0, 500.0, 276.0]  episode_count: 15692 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15695, "number_of_timesteps": 328948, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7215 6 visits [500.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 276.0, 500.0, 276.0]  episode_count: 15695 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7216 7 visits [500.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 500.0, 276.0]  episode_count: 15696 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7217 9 visits [500.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 15698 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7218 1 visits [500.0, 278.0, 277.0, 277.0, 277.0, 277.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 15701 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7219 2 visits [500.0, 278.0, 278.0, 277.0, 277.0, 277.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 15704 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15705, "number_of_timesteps": 329131, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7220 3 visits [500.0, 278.0, 278.0, 278.0, 277.0, 277.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 15705 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7221 4 visits [500.0, 278.0, 278.0, 278.0, 278.0, 277.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 15709 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7222 5 visits [500.0, 278.0, 278.0, 278.0, 278.0, 278.0, 277.0, 277.0, 500.0, 277.0]  episode_count: 15710 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7223 6 visits [500.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 277.0, 500.0, 277.0]  episode_count: 15713 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15717, "number_of_timesteps": 329356, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7224 7 visits [500.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 500.0, 277.0]  episode_count: 15717 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7225 9 visits [500.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 15718 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7226 1 visits [500.0, 279.0, 278.0, 278.0, 278.0, 278.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 15721 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7227 2 visits [500.0, 279.0, 279.0, 278.0, 278.0, 278.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 15724 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7228 3 visits [500.0, 279.0, 279.0, 279.0, 278.0, 278.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 15726 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15727, "number_of_timesteps": 329525, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7229 4 visits [500.0, 279.0, 279.0, 279.0, 279.0, 278.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 15727 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7230 5 visits [500.0, 279.0, 279.0, 279.0, 279.0, 279.0, 278.0, 278.0, 500.0, 278.0]  episode_count: 15729 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7231 6 visits [500.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 278.0, 500.0, 278.0]  episode_count: 15733 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7232 7 visits [500.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 500.0, 278.0]  episode_count: 15734 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7233 9 visits [500.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 15735 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15739, "number_of_timesteps": 329749, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7234 1 visits [500.0, 280.0, 279.0, 279.0, 279.0, 279.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 15739 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7235 2 visits [500.0, 280.0, 280.0, 279.0, 279.0, 279.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 15740 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7236 3 visits [500.0, 280.0, 280.0, 280.0, 279.0, 279.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 15741 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7237 4 visits [500.0, 280.0, 280.0, 280.0, 280.0, 279.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 15745 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7238 5 visits [500.0, 280.0, 280.0, 280.0, 280.0, 280.0, 279.0, 279.0, 500.0, 279.0]  episode_count: 15745 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7239 6 visits [500.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 279.0, 500.0, 279.0]  episode_count: 15747 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7240 7 visits [500.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 500.0, 279.0]  episode_count: 15748 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7241 9 visits [500.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 15748 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15751, "number_of_timesteps": 330065, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7242 1 visits [500.0, 281.0, 280.0, 280.0, 280.0, 280.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 15751 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7243 2 visits [500.0, 281.0, 281.0, 280.0, 280.0, 280.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 15753 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7244 3 visits [500.0, 281.0, 281.0, 281.0, 280.0, 280.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 15755 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7245 4 visits [500.0, 281.0, 281.0, 281.0, 281.0, 280.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 15756 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7246 5 visits [500.0, 281.0, 281.0, 281.0, 281.0, 281.0, 280.0, 280.0, 500.0, 280.0]  episode_count: 15756 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7247 6 visits [500.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 280.0, 500.0, 280.0]  episode_count: 15760 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15762, "number_of_timesteps": 330344, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 7248 7 visits [500.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 500.0, 280.0]  episode_count: 15762 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7249 9 visits [500.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 15763 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7250 1 visits [500.0, 282.0, 281.0, 281.0, 281.0, 281.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 15766 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7251 2 visits [500.0, 282.0, 282.0, 281.0, 281.0, 281.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 15769 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7252 3 visits [500.0, 282.0, 282.0, 282.0, 281.0, 281.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 15769 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15772, "number_of_timesteps": 330630, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 7253 4 visits [500.0, 282.0, 282.0, 282.0, 282.0, 281.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 15772 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7254 5 visits [500.0, 282.0, 282.0, 282.0, 282.0, 282.0, 281.0, 281.0, 500.0, 281.0]  episode_count: 15775 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7255 6 visits [500.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 281.0, 500.0, 281.0]  episode_count: 15778 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7256 7 visits [500.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 500.0, 281.0]  episode_count: 15780 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15782, "number_of_timesteps": 330827, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 7257 9 visits [500.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 15782 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7258 1 visits [500.0, 283.0, 282.0, 282.0, 282.0, 282.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 15785 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7259 2 visits [500.0, 283.0, 283.0, 282.0, 282.0, 282.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 15786 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7260 3 visits [500.0, 283.0, 283.0, 283.0, 282.0, 282.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 15789 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7261 4 visits [500.0, 283.0, 283.0, 283.0, 283.0, 282.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 15789 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15793, "number_of_timesteps": 331077, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 7262 5 visits [500.0, 283.0, 283.0, 283.0, 283.0, 283.0, 282.0, 282.0, 500.0, 282.0]  episode_count: 15793 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7263 6 visits [500.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 282.0, 500.0, 282.0]  episode_count: 15797 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7264 7 visits [500.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 500.0, 282.0]  episode_count: 15799 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7265 9 visits [500.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 15800 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7266 1 visits [500.0, 284.0, 283.0, 283.0, 283.0, 283.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 15802 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15806, "number_of_timesteps": 331312, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 7267 2 visits [500.0, 284.0, 284.0, 283.0, 283.0, 283.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 15806 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7268 3 visits [500.0, 284.0, 284.0, 284.0, 283.0, 283.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 15808 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7269 4 visits [500.0, 284.0, 284.0, 284.0, 284.0, 283.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 15808 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7270 5 visits [500.0, 284.0, 284.0, 284.0, 284.0, 284.0, 283.0, 283.0, 500.0, 283.0]  episode_count: 15811 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7271 6 visits [500.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 283.0, 500.0, 283.0]  episode_count: 15815 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15817, "number_of_timesteps": 331533, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 7272 7 visits [500.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 500.0, 283.0]  episode_count: 15817 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7273 9 visits [500.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 15819 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7274 1 visits [500.0, 285.0, 284.0, 284.0, 284.0, 284.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 15820 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7275 2 visits [500.0, 285.0, 285.0, 284.0, 284.0, 284.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 15822 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7276 3 visits [500.0, 285.0, 285.0, 285.0, 284.0, 284.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 15825 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15827, "number_of_timesteps": 331751, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 7277 4 visits [500.0, 285.0, 285.0, 285.0, 285.0, 284.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 15827 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7278 5 visits [500.0, 285.0, 285.0, 285.0, 285.0, 285.0, 284.0, 284.0, 500.0, 284.0]  episode_count: 15827 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7279 6 visits [500.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 284.0, 500.0, 284.0]  episode_count: 15832 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7280 7 visits [500.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 500.0, 284.0]  episode_count: 15834 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7281 9 visits [500.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 15835 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15839, "number_of_timesteps": 331978, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7282 1 visits [500.0, 286.0, 285.0, 285.0, 285.0, 285.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 15839 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7283 2 visits [500.0, 286.0, 286.0, 285.0, 285.0, 285.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 15841 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7284 3 visits [500.0, 286.0, 286.0, 286.0, 285.0, 285.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 15843 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7285 4 visits [500.0, 286.0, 286.0, 286.0, 286.0, 285.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 15846 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7286 5 visits [500.0, 286.0, 286.0, 286.0, 286.0, 286.0, 285.0, 285.0, 500.0, 285.0]  episode_count: 15848 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15850, "number_of_timesteps": 332210, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 7287 6 visits [500.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 285.0, 500.0, 285.0]  episode_count: 15850 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7288 7 visits [500.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 500.0, 285.0]  episode_count: 15850 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7289 9 visits [500.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 15853 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7290 1 visits [500.0, 287.0, 286.0, 286.0, 286.0, 286.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 15853 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7291 2 visits [500.0, 287.0, 287.0, 286.0, 286.0, 286.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 15855 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15860, "number_of_timesteps": 332449, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 7292 3 visits [500.0, 287.0, 287.0, 287.0, 286.0, 286.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 15860 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7293 4 visits [500.0, 287.0, 287.0, 287.0, 287.0, 286.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 15862 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7294 5 visits [500.0, 287.0, 287.0, 287.0, 287.0, 287.0, 286.0, 286.0, 500.0, 286.0]  episode_count: 15863 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7295 6 visits [500.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 286.0, 500.0, 286.0]  episode_count: 15866 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7296 7 visits [500.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 500.0, 286.0]  episode_count: 15868 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15870, "number_of_timesteps": 332677, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 7297 9 visits [500.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 15870 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7298 1 visits [500.0, 288.0, 287.0, 287.0, 287.0, 287.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 15872 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7299 2 visits [500.0, 288.0, 288.0, 287.0, 287.0, 287.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 15873 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7300 3 visits [500.0, 288.0, 288.0, 288.0, 287.0, 287.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 15874 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7301 4 visits [500.0, 288.0, 288.0, 288.0, 288.0, 287.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 15875 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7302 5 visits [500.0, 288.0, 288.0, 288.0, 288.0, 288.0, 287.0, 287.0, 500.0, 287.0]  episode_count: 15877 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7303 6 visits [500.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 287.0, 500.0, 287.0]  episode_count: 15877 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7304 7 visits [500.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 500.0, 287.0]  episode_count: 15878 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7305 9 visits [500.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 15879 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15883, "number_of_timesteps": 333026, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7306 1 visits [500.0, 289.0, 288.0, 288.0, 288.0, 288.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 15883 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7307 2 visits [500.0, 289.0, 289.0, 288.0, 288.0, 288.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 15884 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7308 3 visits [500.0, 289.0, 289.0, 289.0, 288.0, 288.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 15886 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7309 4 visits [500.0, 289.0, 289.0, 289.0, 289.0, 288.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 15890 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7310 5 visits [500.0, 289.0, 289.0, 289.0, 289.0, 289.0, 288.0, 288.0, 500.0, 288.0]  episode_count: 15891 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15893, "number_of_timesteps": 333336, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 7311 6 visits [500.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 288.0, 500.0, 288.0]  episode_count: 15893 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7312 7 visits [500.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 500.0, 288.0]  episode_count: 15894 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7313 9 visits [500.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 15897 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7314 1 visits [500.0, 290.0, 289.0, 289.0, 289.0, 289.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 15897 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7315 2 visits [500.0, 290.0, 290.0, 289.0, 289.0, 289.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 15899 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15903, "number_of_timesteps": 333550, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 7316 3 visits [500.0, 290.0, 290.0, 290.0, 289.0, 289.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 15903 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7317 4 visits [500.0, 290.0, 290.0, 290.0, 290.0, 289.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 15904 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7318 5 visits [500.0, 290.0, 290.0, 290.0, 290.0, 290.0, 289.0, 289.0, 500.0, 289.0]  episode_count: 15906 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7319 6 visits [500.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 289.0, 500.0, 289.0]  episode_count: 15910 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7320 7 visits [500.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 500.0, 289.0]  episode_count: 15911 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7321 9 visits [500.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 15912 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15916, "number_of_timesteps": 333846, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 7322 1 visits [500.0, 291.0, 290.0, 290.0, 290.0, 290.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 15916 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7323 2 visits [500.0, 291.0, 291.0, 290.0, 290.0, 290.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 15918 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7324 3 visits [500.0, 291.0, 291.0, 291.0, 290.0, 290.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 15920 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7325 4 visits [500.0, 291.0, 291.0, 291.0, 291.0, 290.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 15922 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7326 5 visits [500.0, 291.0, 291.0, 291.0, 291.0, 291.0, 290.0, 290.0, 500.0, 290.0]  episode_count: 15923 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15927, "number_of_timesteps": 334072, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 7327 6 visits [500.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 290.0, 500.0, 290.0]  episode_count: 15927 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7328 7 visits [500.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 500.0, 290.0]  episode_count: 15928 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7329 9 visits [500.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 15928 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7330 1 visits [500.0, 292.0, 291.0, 291.0, 291.0, 291.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 15934 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7331 2 visits [500.0, 292.0, 292.0, 291.0, 291.0, 291.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 15935 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7332 3 visits [500.0, 292.0, 292.0, 292.0, 291.0, 291.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 15936 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15939, "number_of_timesteps": 334320, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 7333 4 visits [500.0, 292.0, 292.0, 292.0, 292.0, 291.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 15939 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7334 5 visits [500.0, 292.0, 292.0, 292.0, 292.0, 292.0, 291.0, 291.0, 500.0, 291.0]  episode_count: 15940 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7335 6 visits [500.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 291.0, 500.0, 291.0]  episode_count: 15943 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7336 7 visits [500.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 500.0, 291.0]  episode_count: 15944 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7337 9 visits [500.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 15946 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15949, "number_of_timesteps": 334580, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 7338 1 visits [500.0, 293.0, 292.0, 292.0, 292.0, 292.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 15949 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7339 2 visits [500.0, 293.0, 293.0, 292.0, 292.0, 292.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 15951 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7340 3 visits [500.0, 293.0, 293.0, 293.0, 292.0, 292.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 15953 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7341 4 visits [500.0, 293.0, 293.0, 293.0, 293.0, 292.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 15954 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7342 5 visits [500.0, 293.0, 293.0, 293.0, 293.0, 293.0, 292.0, 292.0, 500.0, 292.0]  episode_count: 15957 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15960, "number_of_timesteps": 334804, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 7343 6 visits [500.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 292.0, 500.0, 292.0]  episode_count: 15960 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7344 7 visits [500.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 500.0, 292.0]  episode_count: 15962 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7345 9 visits [500.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 15962 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7346 1 visits [500.0, 294.0, 293.0, 293.0, 293.0, 293.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 15965 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15970, "number_of_timesteps": 334997, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 7347 2 visits [500.0, 294.0, 294.0, 293.0, 293.0, 293.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 15970 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7348 3 visits [500.0, 294.0, 294.0, 294.0, 293.0, 293.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 15971 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7349 4 visits [500.0, 294.0, 294.0, 294.0, 294.0, 293.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 15974 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7350 5 visits [500.0, 294.0, 294.0, 294.0, 294.0, 294.0, 293.0, 293.0, 500.0, 293.0]  episode_count: 15975 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7351 6 visits [500.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 293.0, 500.0, 293.0]  episode_count: 15976 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7352 7 visits [500.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 500.0, 293.0]  episode_count: 15977 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7353 9 visits [500.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 15979 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15982, "number_of_timesteps": 335269, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 7354 1 visits [500.0, 295.0, 294.0, 294.0, 294.0, 294.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 15982 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7355 2 visits [500.0, 295.0, 295.0, 294.0, 294.0, 294.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 15983 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7356 3 visits [500.0, 295.0, 295.0, 295.0, 294.0, 294.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 15984 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7357 4 visits [500.0, 295.0, 295.0, 295.0, 295.0, 294.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 15986 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7358 5 visits [500.0, 295.0, 295.0, 295.0, 295.0, 295.0, 294.0, 294.0, 500.0, 294.0]  episode_count: 15987 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7359 6 visits [500.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 294.0, 500.0, 294.0]  episode_count: 15989 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7360 7 visits [500.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 500.0, 294.0]  episode_count: 15989 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7361 9 visits [500.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 15990 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 15994, "number_of_timesteps": 335593, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 7362 1 visits [500.0, 296.0, 295.0, 295.0, 295.0, 295.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 15994 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7363 2 visits [500.0, 296.0, 296.0, 295.0, 295.0, 295.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 15995 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7364 3 visits [500.0, 296.0, 296.0, 296.0, 295.0, 295.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 15997 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7365 4 visits [500.0, 296.0, 296.0, 296.0, 296.0, 295.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 16001 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7366 5 visits [500.0, 296.0, 296.0, 296.0, 296.0, 296.0, 295.0, 295.0, 500.0, 295.0]  episode_count: 16001 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7367 6 visits [500.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 295.0, 500.0, 295.0]  episode_count: 16001 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7368 7 visits [500.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 500.0, 295.0]  episode_count: 16003 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16008, "number_of_timesteps": 336002, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 7369 9 visits [500.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 16008 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7370 1 visits [500.0, 297.0, 296.0, 296.0, 296.0, 296.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 16009 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7371 2 visits [500.0, 297.0, 297.0, 296.0, 296.0, 296.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 16011 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7372 3 visits [500.0, 297.0, 297.0, 297.0, 296.0, 296.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 16013 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7373 4 visits [500.0, 297.0, 297.0, 297.0, 297.0, 296.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 16016 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7374 5 visits [500.0, 297.0, 297.0, 297.0, 297.0, 297.0, 296.0, 296.0, 500.0, 296.0]  episode_count: 16017 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16018, "number_of_timesteps": 336203, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
Step 7375 6 visits [500.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 296.0, 500.0, 296.0]  episode_count: 16018 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7376 7 visits [500.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 500.0, 296.0]  episode_count: 16021 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7377 9 visits [500.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 16024 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7378 1 visits [500.0, 298.0, 297.0, 297.0, 297.0, 297.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 16026 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16028, "number_of_timesteps": 336446, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 7379 2 visits [500.0, 298.0, 298.0, 297.0, 297.0, 297.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 16028 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7380 3 visits [500.0, 298.0, 298.0, 298.0, 297.0, 297.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 16030 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7381 4 visits [500.0, 298.0, 298.0, 298.0, 298.0, 297.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 16033 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7382 5 visits [500.0, 298.0, 298.0, 298.0, 298.0, 298.0, 297.0, 297.0, 500.0, 297.0]  episode_count: 16035 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7383 6 visits [500.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 297.0, 500.0, 297.0]  episode_count: 16036 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16039, "number_of_timesteps": 336662, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7384 7 visits [500.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 500.0, 297.0]  episode_count: 16039 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7385 9 visits [500.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 16042 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7386 1 visits [500.0, 299.0, 298.0, 298.0, 298.0, 298.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 16043 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7387 2 visits [500.0, 299.0, 299.0, 298.0, 298.0, 298.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 16043 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7388 3 visits [500.0, 299.0, 299.0, 299.0, 298.0, 298.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 16044 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7389 4 visits [500.0, 299.0, 299.0, 299.0, 299.0, 298.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 16047 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16049, "number_of_timesteps": 336915, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7390 5 visits [500.0, 299.0, 299.0, 299.0, 299.0, 299.0, 298.0, 298.0, 500.0, 298.0]  episode_count: 16049 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7391 6 visits [500.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 298.0, 500.0, 298.0]  episode_count: 16050 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7392 7 visits [500.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 500.0, 298.0]  episode_count: 16051 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7393 9 visits [500.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 16056 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7394 1 visits [500.0, 300.0, 299.0, 299.0, 299.0, 299.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 16057 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7395 2 visits [500.0, 300.0, 300.0, 299.0, 299.0, 299.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 16058 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16060, "number_of_timesteps": 337153, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7396 3 visits [500.0, 300.0, 300.0, 300.0, 299.0, 299.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 16060 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7397 4 visits [500.0, 300.0, 300.0, 300.0, 300.0, 299.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 16063 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7398 5 visits [500.0, 300.0, 300.0, 300.0, 300.0, 300.0, 299.0, 299.0, 500.0, 299.0]  episode_count: 16063 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7399 6 visits [500.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 299.0, 500.0, 299.0]  episode_count: 16067 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7400 7 visits [500.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 500.0, 299.0]  episode_count: 16069 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16070, "number_of_timesteps": 337454, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 7401 9 visits [500.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 16070 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7402 1 visits [500.0, 301.0, 300.0, 300.0, 300.0, 300.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 16074 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7403 2 visits [500.0, 301.0, 301.0, 300.0, 300.0, 300.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 16077 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7404 3 visits [500.0, 301.0, 301.0, 301.0, 300.0, 300.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 16078 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16081, "number_of_timesteps": 337652, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7405 4 visits [500.0, 301.0, 301.0, 301.0, 301.0, 300.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 16081 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7406 5 visits [500.0, 301.0, 301.0, 301.0, 301.0, 301.0, 300.0, 300.0, 500.0, 300.0]  episode_count: 16084 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7407 6 visits [500.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 300.0, 500.0, 300.0]  episode_count: 16085 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7408 7 visits [500.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 500.0, 300.0]  episode_count: 16088 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16093, "number_of_timesteps": 337878, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 7409 9 visits [500.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 16093 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7410 1 visits [500.0, 302.0, 301.0, 301.0, 301.0, 301.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 16094 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7411 2 visits [500.0, 302.0, 302.0, 301.0, 301.0, 301.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 16094 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7412 3 visits [500.0, 302.0, 302.0, 302.0, 301.0, 301.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 16099 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7413 4 visits [500.0, 302.0, 302.0, 302.0, 302.0, 301.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 16101 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7414 5 visits [500.0, 302.0, 302.0, 302.0, 302.0, 302.0, 301.0, 301.0, 500.0, 301.0]  episode_count: 16102 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16104, "number_of_timesteps": 338058, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 7415 6 visits [500.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 301.0, 500.0, 301.0]  episode_count: 16104 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7416 7 visits [500.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 500.0, 301.0]  episode_count: 16104 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7417 9 visits [500.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 16107 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7418 1 visits [500.0, 303.0, 302.0, 302.0, 302.0, 302.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 16111 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7419 2 visits [500.0, 303.0, 303.0, 302.0, 302.0, 302.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 16112 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16115, "number_of_timesteps": 338334, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 7420 3 visits [500.0, 303.0, 303.0, 303.0, 302.0, 302.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 16115 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7421 4 visits [500.0, 303.0, 303.0, 303.0, 303.0, 302.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 16117 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7422 5 visits [500.0, 303.0, 303.0, 303.0, 303.0, 303.0, 302.0, 302.0, 500.0, 302.0]  episode_count: 16119 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7423 6 visits [500.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 302.0, 500.0, 302.0]  episode_count: 16120 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7424 7 visits [500.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 500.0, 302.0]  episode_count: 16124 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16125, "number_of_timesteps": 338528, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 7425 9 visits [500.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 16125 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7426 1 visits [500.0, 304.0, 303.0, 303.0, 303.0, 303.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 16126 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7427 2 visits [500.0, 304.0, 304.0, 303.0, 303.0, 303.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 16131 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7428 3 visits [500.0, 304.0, 304.0, 304.0, 303.0, 303.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 16134 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16135, "number_of_timesteps": 338761, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 7429 4 visits [500.0, 304.0, 304.0, 304.0, 304.0, 303.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 16135 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7430 5 visits [500.0, 304.0, 304.0, 304.0, 304.0, 304.0, 303.0, 303.0, 500.0, 303.0]  episode_count: 16135 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7431 6 visits [500.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 303.0, 500.0, 303.0]  episode_count: 16136 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7432 7 visits [500.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 500.0, 303.0]  episode_count: 16140 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7433 9 visits [500.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 16141 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16145, "number_of_timesteps": 338975, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 7434 1 visits [500.0, 305.0, 304.0, 304.0, 304.0, 304.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 16145 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7435 2 visits [500.0, 305.0, 305.0, 304.0, 304.0, 304.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 16147 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7436 3 visits [500.0, 305.0, 305.0, 305.0, 304.0, 304.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 16147 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7437 4 visits [500.0, 305.0, 305.0, 305.0, 305.0, 304.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 16151 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7438 5 visits [500.0, 305.0, 305.0, 305.0, 305.0, 305.0, 304.0, 304.0, 500.0, 304.0]  episode_count: 16153 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7439 6 visits [500.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 304.0, 500.0, 304.0]  episode_count: 16154 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16155, "number_of_timesteps": 339178, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 7440 7 visits [500.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 500.0, 304.0]  episode_count: 16155 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7441 9 visits [500.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 16157 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7442 1 visits [500.0, 306.0, 305.0, 305.0, 305.0, 305.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 16158 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7443 2 visits [500.0, 306.0, 306.0, 305.0, 305.0, 305.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 16161 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7444 3 visits [500.0, 306.0, 306.0, 306.0, 305.0, 305.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 16164 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16167, "number_of_timesteps": 339510, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 7445 4 visits [500.0, 306.0, 306.0, 306.0, 306.0, 305.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 16167 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7446 5 visits [500.0, 306.0, 306.0, 306.0, 306.0, 306.0, 305.0, 305.0, 500.0, 305.0]  episode_count: 16170 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7447 6 visits [500.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 305.0, 500.0, 305.0]  episode_count: 16172 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7448 7 visits [500.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 500.0, 305.0]  episode_count: 16173 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7449 9 visits [500.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 16175 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16178, "number_of_timesteps": 339689, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7450 1 visits [500.0, 307.0, 306.0, 306.0, 306.0, 306.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 16178 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7451 2 visits [500.0, 307.0, 307.0, 306.0, 306.0, 306.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 16179 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7452 3 visits [500.0, 307.0, 307.0, 307.0, 306.0, 306.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 16182 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7453 4 visits [500.0, 307.0, 307.0, 307.0, 307.0, 306.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 16185 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7454 5 visits [500.0, 307.0, 307.0, 307.0, 307.0, 307.0, 306.0, 306.0, 500.0, 306.0]  episode_count: 16185 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16188, "number_of_timesteps": 339876, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7455 6 visits [500.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 306.0, 500.0, 306.0]  episode_count: 16188 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7456 7 visits [500.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 500.0, 306.0]  episode_count: 16193 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7457 9 visits [500.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 16194 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7458 1 visits [500.0, 308.0, 307.0, 307.0, 307.0, 307.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 16196 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7459 2 visits [500.0, 308.0, 308.0, 307.0, 307.0, 307.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 16197 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16199, "number_of_timesteps": 340115, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7460 3 visits [500.0, 308.0, 308.0, 308.0, 307.0, 307.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 16199 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7461 4 visits [500.0, 308.0, 308.0, 308.0, 308.0, 307.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 16200 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7462 5 visits [500.0, 308.0, 308.0, 308.0, 308.0, 308.0, 307.0, 307.0, 500.0, 307.0]  episode_count: 16202 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7463 6 visits [500.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 307.0, 500.0, 307.0]  episode_count: 16204 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7464 7 visits [500.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 500.0, 307.0]  episode_count: 16206 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7465 9 visits [500.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 16207 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16209, "number_of_timesteps": 340354, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7466 1 visits [500.0, 309.0, 308.0, 308.0, 308.0, 308.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 16209 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7467 2 visits [500.0, 309.0, 309.0, 308.0, 308.0, 308.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 16211 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7468 3 visits [500.0, 309.0, 309.0, 309.0, 308.0, 308.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 16214 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7469 4 visits [500.0, 309.0, 309.0, 309.0, 309.0, 308.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 16217 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16219, "number_of_timesteps": 340624, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7470 5 visits [500.0, 309.0, 309.0, 309.0, 309.0, 309.0, 308.0, 308.0, 500.0, 308.0]  episode_count: 16219 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7471 6 visits [500.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 308.0, 500.0, 308.0]  episode_count: 16222 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7472 7 visits [500.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 500.0, 308.0]  episode_count: 16223 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7473 9 visits [500.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 16225 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7474 1 visits [500.0, 310.0, 309.0, 309.0, 309.0, 309.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 16228 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16229, "number_of_timesteps": 340823, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7475 2 visits [500.0, 310.0, 310.0, 309.0, 309.0, 309.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 16229 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7476 3 visits [500.0, 310.0, 310.0, 310.0, 309.0, 309.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 16232 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7477 4 visits [500.0, 310.0, 310.0, 310.0, 310.0, 309.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 16234 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7478 5 visits [500.0, 310.0, 310.0, 310.0, 310.0, 310.0, 309.0, 309.0, 500.0, 309.0]  episode_count: 16236 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16239, "number_of_timesteps": 341045, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7479 6 visits [500.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 309.0, 500.0, 309.0]  episode_count: 16239 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7480 7 visits [500.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 500.0, 309.0]  episode_count: 16240 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7481 9 visits [500.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 16242 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7482 1 visits [500.0, 311.0, 310.0, 310.0, 310.0, 310.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 16248 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7483 2 visits [500.0, 311.0, 311.0, 310.0, 310.0, 310.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 16248 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16250, "number_of_timesteps": 341248, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7484 3 visits [500.0, 311.0, 311.0, 311.0, 310.0, 310.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 16250 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7485 4 visits [500.0, 311.0, 311.0, 311.0, 311.0, 310.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 16251 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7486 5 visits [500.0, 311.0, 311.0, 311.0, 311.0, 311.0, 310.0, 310.0, 500.0, 310.0]  episode_count: 16254 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7487 6 visits [500.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 310.0, 500.0, 310.0]  episode_count: 16255 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7488 7 visits [500.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 500.0, 310.0]  episode_count: 16257 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16260, "number_of_timesteps": 341442, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7489 9 visits [500.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 16260 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7490 1 visits [500.0, 312.0, 311.0, 311.0, 311.0, 311.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 16261 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7491 2 visits [500.0, 312.0, 312.0, 311.0, 311.0, 311.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 16264 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7492 3 visits [500.0, 312.0, 312.0, 312.0, 311.0, 311.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 16266 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7493 4 visits [500.0, 312.0, 312.0, 312.0, 312.0, 311.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 16267 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7494 5 visits [500.0, 312.0, 312.0, 312.0, 312.0, 312.0, 311.0, 311.0, 500.0, 311.0]  episode_count: 16267 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16270, "number_of_timesteps": 341675, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7495 6 visits [500.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 311.0, 500.0, 311.0]  episode_count: 16270 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7496 7 visits [500.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 500.0, 311.0]  episode_count: 16275 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7497 9 visits [500.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 16276 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7498 1 visits [500.0, 313.0, 312.0, 312.0, 312.0, 312.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 16277 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16280, "number_of_timesteps": 341917, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7499 2 visits [500.0, 313.0, 313.0, 312.0, 312.0, 312.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 16280 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7500 3 visits [500.0, 313.0, 313.0, 313.0, 312.0, 312.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 16281 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7501 4 visits [500.0, 313.0, 313.0, 313.0, 313.0, 312.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 16281 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7502 5 visits [500.0, 313.0, 313.0, 313.0, 313.0, 313.0, 312.0, 312.0, 500.0, 312.0]  episode_count: 16282 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7503 6 visits [500.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 312.0, 500.0, 312.0]  episode_count: 16287 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7504 7 visits [500.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 500.0, 312.0]  episode_count: 16287 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7505 9 visits [500.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 16289 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16291, "number_of_timesteps": 342235, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7506 1 visits [500.0, 314.0, 313.0, 313.0, 313.0, 313.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 16291 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7507 2 visits [500.0, 314.0, 314.0, 313.0, 313.0, 313.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 16292 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7508 3 visits [500.0, 314.0, 314.0, 314.0, 313.0, 313.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 16296 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7509 4 visits [500.0, 314.0, 314.0, 314.0, 314.0, 313.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 16298 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7510 5 visits [500.0, 314.0, 314.0, 314.0, 314.0, 314.0, 313.0, 313.0, 500.0, 313.0]  episode_count: 16300 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16303, "number_of_timesteps": 342498, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7511 6 visits [500.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 313.0, 500.0, 313.0]  episode_count: 16303 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7512 7 visits [500.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 500.0, 313.0]  episode_count: 16306 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7513 9 visits [500.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 16308 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7514 1 visits [500.0, 315.0, 314.0, 314.0, 314.0, 314.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 16310 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7515 2 visits [500.0, 315.0, 315.0, 314.0, 314.0, 314.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 16312 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16313, "number_of_timesteps": 342630, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7516 3 visits [500.0, 315.0, 315.0, 315.0, 314.0, 314.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 16313 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7517 4 visits [500.0, 315.0, 315.0, 315.0, 315.0, 314.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 16315 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7518 5 visits [500.0, 315.0, 315.0, 315.0, 315.0, 315.0, 314.0, 314.0, 500.0, 314.0]  episode_count: 16318 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7519 6 visits [500.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 314.0, 500.0, 314.0]  episode_count: 16320 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7520 7 visits [500.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 500.0, 314.0]  episode_count: 16321 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16325, "number_of_timesteps": 342960, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7521 9 visits [500.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 16325 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7522 1 visits [500.0, 316.0, 315.0, 315.0, 315.0, 315.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 16328 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7523 2 visits [500.0, 316.0, 316.0, 315.0, 315.0, 315.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 16329 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7524 3 visits [500.0, 316.0, 316.0, 316.0, 315.0, 315.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 16330 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7525 4 visits [500.0, 316.0, 316.0, 316.0, 316.0, 315.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 16332 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16337, "number_of_timesteps": 343187, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7526 5 visits [500.0, 316.0, 316.0, 316.0, 316.0, 316.0, 315.0, 315.0, 500.0, 315.0]  episode_count: 16337 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7527 6 visits [500.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 315.0, 500.0, 315.0]  episode_count: 16339 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7528 7 visits [500.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 500.0, 315.0]  episode_count: 16340 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7529 9 visits [500.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 16343 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7530 1 visits [500.0, 317.0, 316.0, 316.0, 316.0, 316.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 16346 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16349, "number_of_timesteps": 343445, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7531 2 visits [500.0, 317.0, 317.0, 316.0, 316.0, 316.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 16349 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7532 3 visits [500.0, 317.0, 317.0, 317.0, 316.0, 316.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 16349 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7533 4 visits [500.0, 317.0, 317.0, 317.0, 317.0, 316.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 16351 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7534 5 visits [500.0, 317.0, 317.0, 317.0, 317.0, 317.0, 316.0, 316.0, 500.0, 316.0]  episode_count: 16355 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7535 6 visits [500.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 316.0, 500.0, 316.0]  episode_count: 16358 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16361, "number_of_timesteps": 343680, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7536 7 visits [500.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 500.0, 316.0]  episode_count: 16361 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7537 9 visits [500.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 16363 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7538 1 visits [500.0, 318.0, 317.0, 317.0, 317.0, 317.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 16364 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7539 2 visits [500.0, 318.0, 318.0, 317.0, 317.0, 317.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 16367 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7540 3 visits [500.0, 318.0, 318.0, 318.0, 317.0, 317.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 16368 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7541 4 visits [500.0, 318.0, 318.0, 318.0, 318.0, 317.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 16370 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16374, "number_of_timesteps": 343936, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7542 5 visits [500.0, 318.0, 318.0, 318.0, 318.0, 318.0, 317.0, 317.0, 500.0, 317.0]  episode_count: 16374 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7543 6 visits [500.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 317.0, 500.0, 317.0]  episode_count: 16375 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7544 7 visits [500.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 500.0, 317.0]  episode_count: 16376 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7545 9 visits [500.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 16377 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7546 1 visits [500.0, 319.0, 318.0, 318.0, 318.0, 318.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 16378 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7547 2 visits [500.0, 319.0, 319.0, 318.0, 318.0, 318.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 16382 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16385, "number_of_timesteps": 344172, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7548 3 visits [500.0, 319.0, 319.0, 319.0, 318.0, 318.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 16385 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7549 4 visits [500.0, 319.0, 319.0, 319.0, 319.0, 318.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 16386 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7550 5 visits [500.0, 319.0, 319.0, 319.0, 319.0, 319.0, 318.0, 318.0, 500.0, 318.0]  episode_count: 16390 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7551 6 visits [500.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 318.0, 500.0, 318.0]  episode_count: 16393 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7552 7 visits [500.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 500.0, 318.0]  episode_count: 16394 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16395, "number_of_timesteps": 344391, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7553 9 visits [500.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 16395 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7554 1 visits [500.0, 320.0, 319.0, 319.0, 319.0, 319.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 16398 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7555 2 visits [500.0, 320.0, 320.0, 319.0, 319.0, 319.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 16400 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16405, "number_of_timesteps": 344606, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7556 3 visits [500.0, 320.0, 320.0, 320.0, 319.0, 319.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 16405 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7557 4 visits [500.0, 320.0, 320.0, 320.0, 320.0, 319.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 16405 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7558 5 visits [500.0, 320.0, 320.0, 320.0, 320.0, 320.0, 319.0, 319.0, 500.0, 319.0]  episode_count: 16407 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7559 6 visits [500.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 319.0, 500.0, 319.0]  episode_count: 16411 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7560 7 visits [500.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 500.0, 319.0]  episode_count: 16413 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16416, "number_of_timesteps": 344806, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7561 9 visits [500.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 16416 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7562 1 visits [500.0, 321.0, 320.0, 320.0, 320.0, 320.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 16418 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7563 2 visits [500.0, 321.0, 321.0, 320.0, 320.0, 320.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 16421 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7564 3 visits [500.0, 321.0, 321.0, 321.0, 320.0, 320.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 16423 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16426, "number_of_timesteps": 344959, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7565 4 visits [500.0, 321.0, 321.0, 321.0, 321.0, 320.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 16426 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7566 5 visits [500.0, 321.0, 321.0, 321.0, 321.0, 321.0, 320.0, 320.0, 500.0, 320.0]  episode_count: 16429 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7567 6 visits [500.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 320.0, 500.0, 320.0]  episode_count: 16430 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7568 7 visits [500.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 500.0, 320.0]  episode_count: 16434 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16436, "number_of_timesteps": 345147, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7569 9 visits [500.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 16436 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7570 1 visits [500.0, 322.0, 321.0, 321.0, 321.0, 321.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 16438 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7571 2 visits [500.0, 322.0, 322.0, 321.0, 321.0, 321.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 16439 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7572 3 visits [500.0, 322.0, 322.0, 322.0, 321.0, 321.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 16441 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7573 4 visits [500.0, 322.0, 322.0, 322.0, 322.0, 321.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 16443 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7574 5 visits [500.0, 322.0, 322.0, 322.0, 322.0, 322.0, 321.0, 321.0, 500.0, 321.0]  episode_count: 16444 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16449, "number_of_timesteps": 345433, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7575 6 visits [500.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 321.0, 500.0, 321.0]  episode_count: 16449 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7576 7 visits [500.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 500.0, 321.0]  episode_count: 16452 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7577 9 visits [500.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 16454 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7578 1 visits [500.0, 323.0, 322.0, 322.0, 322.0, 322.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 16455 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7579 2 visits [500.0, 323.0, 323.0, 322.0, 322.0, 322.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 16456 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16460, "number_of_timesteps": 345625, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7580 3 visits [500.0, 323.0, 323.0, 323.0, 322.0, 322.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 16460 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7581 4 visits [500.0, 323.0, 323.0, 323.0, 323.0, 322.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 16462 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7582 5 visits [500.0, 323.0, 323.0, 323.0, 323.0, 323.0, 322.0, 322.0, 500.0, 322.0]  episode_count: 16465 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7583 6 visits [500.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 322.0, 500.0, 322.0]  episode_count: 16466 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7584 7 visits [500.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 500.0, 322.0]  episode_count: 16467 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16470, "number_of_timesteps": 345851, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7585 9 visits [500.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 16470 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7586 1 visits [500.0, 324.0, 323.0, 323.0, 323.0, 323.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 16475 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7587 2 visits [500.0, 324.0, 324.0, 323.0, 323.0, 323.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 16477 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7588 3 visits [500.0, 324.0, 324.0, 324.0, 323.0, 323.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 16479 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16480, "number_of_timesteps": 346032, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7589 4 visits [500.0, 324.0, 324.0, 324.0, 324.0, 323.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 16480 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7590 5 visits [500.0, 324.0, 324.0, 324.0, 324.0, 324.0, 323.0, 323.0, 500.0, 323.0]  episode_count: 16481 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7591 6 visits [500.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 323.0, 500.0, 323.0]  episode_count: 16484 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7592 7 visits [500.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 500.0, 323.0]  episode_count: 16487 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7593 9 visits [500.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 16489 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16491, "number_of_timesteps": 346260, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7594 1 visits [500.0, 325.0, 324.0, 324.0, 324.0, 324.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 16491 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7595 2 visits [500.0, 325.0, 325.0, 324.0, 324.0, 324.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 16493 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7596 3 visits [500.0, 325.0, 325.0, 325.0, 324.0, 324.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 16497 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7597 4 visits [500.0, 325.0, 325.0, 325.0, 325.0, 324.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 16497 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7598 5 visits [500.0, 325.0, 325.0, 325.0, 325.0, 325.0, 324.0, 324.0, 500.0, 324.0]  episode_count: 16499 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7599 6 visits [500.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 324.0, 500.0, 324.0]  episode_count: 16499 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16501, "number_of_timesteps": 346482, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7600 7 visits [500.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 500.0, 324.0]  episode_count: 16501 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7601 9 visits [500.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 16504 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7602 1 visits [500.0, 326.0, 325.0, 325.0, 325.0, 325.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 16507 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7603 2 visits [500.0, 326.0, 326.0, 325.0, 325.0, 325.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 16507 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7604 3 visits [500.0, 326.0, 326.0, 326.0, 325.0, 325.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 16508 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16511, "number_of_timesteps": 346736, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7605 4 visits [500.0, 326.0, 326.0, 326.0, 326.0, 325.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 16511 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7606 5 visits [500.0, 326.0, 326.0, 326.0, 326.0, 326.0, 325.0, 325.0, 500.0, 325.0]  episode_count: 16515 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7607 6 visits [500.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 325.0, 500.0, 325.0]  episode_count: 16515 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7608 7 visits [500.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 500.0, 325.0]  episode_count: 16517 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16521, "number_of_timesteps": 346987, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7609 9 visits [500.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 16521 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7610 1 visits [500.0, 327.0, 326.0, 326.0, 326.0, 326.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 16522 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7611 2 visits [500.0, 327.0, 327.0, 326.0, 326.0, 326.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 16524 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7612 3 visits [500.0, 327.0, 327.0, 327.0, 326.0, 326.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 16528 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7613 4 visits [500.0, 327.0, 327.0, 327.0, 327.0, 326.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 16530 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16533, "number_of_timesteps": 347231, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7614 5 visits [500.0, 327.0, 327.0, 327.0, 327.0, 327.0, 326.0, 326.0, 500.0, 326.0]  episode_count: 16533 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7615 6 visits [500.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 326.0, 500.0, 326.0]  episode_count: 16533 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7616 7 visits [500.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 500.0, 326.0]  episode_count: 16535 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7617 9 visits [500.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 16538 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7618 1 visits [500.0, 328.0, 327.0, 327.0, 327.0, 327.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 16539 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7619 2 visits [500.0, 328.0, 328.0, 327.0, 327.0, 327.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 16540 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16544, "number_of_timesteps": 347482, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7620 3 visits [500.0, 328.0, 328.0, 328.0, 327.0, 327.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 16544 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7621 4 visits [500.0, 328.0, 328.0, 328.0, 328.0, 327.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 16545 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7622 5 visits [500.0, 328.0, 328.0, 328.0, 328.0, 328.0, 327.0, 327.0, 500.0, 327.0]  episode_count: 16548 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7623 6 visits [500.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 327.0, 500.0, 327.0]  episode_count: 16550 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7624 7 visits [500.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 500.0, 327.0]  episode_count: 16551 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7625 9 visits [500.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 16553 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16556, "number_of_timesteps": 347732, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7626 1 visits [500.0, 329.0, 328.0, 328.0, 328.0, 328.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 16556 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7627 2 visits [500.0, 329.0, 329.0, 328.0, 328.0, 328.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 16559 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7628 3 visits [500.0, 329.0, 329.0, 329.0, 328.0, 328.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 16561 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7629 4 visits [500.0, 329.0, 329.0, 329.0, 329.0, 328.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 16564 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16567, "number_of_timesteps": 347961, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7630 5 visits [500.0, 329.0, 329.0, 329.0, 329.0, 329.0, 328.0, 328.0, 500.0, 328.0]  episode_count: 16567 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7631 6 visits [500.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 328.0, 500.0, 328.0]  episode_count: 16568 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7632 7 visits [500.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 500.0, 328.0]  episode_count: 16569 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7633 9 visits [500.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 16572 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7634 1 visits [500.0, 330.0, 329.0, 329.0, 329.0, 329.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 16573 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7635 2 visits [500.0, 330.0, 330.0, 329.0, 329.0, 329.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 16576 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16580, "number_of_timesteps": 348219, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7636 3 visits [500.0, 330.0, 330.0, 330.0, 329.0, 329.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 16580 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7637 4 visits [500.0, 330.0, 330.0, 330.0, 330.0, 329.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 16580 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7638 5 visits [500.0, 330.0, 330.0, 330.0, 330.0, 330.0, 329.0, 329.0, 500.0, 329.0]  episode_count: 16582 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7639 6 visits [500.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 329.0, 500.0, 329.0]  episode_count: 16587 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7640 7 visits [500.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 500.0, 329.0]  episode_count: 16589 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7641 9 visits [500.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 16589 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16595, "number_of_timesteps": 348513, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7642 1 visits [500.0, 331.0, 330.0, 330.0, 330.0, 330.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 16595 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7643 2 visits [500.0, 331.0, 331.0, 330.0, 330.0, 330.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 16596 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7644 3 visits [500.0, 331.0, 331.0, 331.0, 330.0, 330.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 16598 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7645 4 visits [500.0, 331.0, 331.0, 331.0, 331.0, 330.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 16602 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7646 5 visits [500.0, 331.0, 331.0, 331.0, 331.0, 331.0, 330.0, 330.0, 500.0, 330.0]  episode_count: 16603 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16605, "number_of_timesteps": 348663, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7647 6 visits [500.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 330.0, 500.0, 330.0]  episode_count: 16605 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7648 7 visits [500.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 500.0, 330.0]  episode_count: 16608 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7649 9 visits [500.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 16610 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7650 1 visits [500.0, 332.0, 331.0, 331.0, 331.0, 331.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 16612 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7651 2 visits [500.0, 332.0, 332.0, 331.0, 331.0, 331.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 16613 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7652 3 visits [500.0, 332.0, 332.0, 332.0, 331.0, 331.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 16614 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16618, "number_of_timesteps": 348964, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7653 4 visits [500.0, 332.0, 332.0, 332.0, 332.0, 331.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 16618 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7654 5 visits [500.0, 332.0, 332.0, 332.0, 332.0, 332.0, 331.0, 331.0, 500.0, 331.0]  episode_count: 16621 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7655 6 visits [500.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 331.0, 500.0, 331.0]  episode_count: 16623 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7656 7 visits [500.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 500.0, 331.0]  episode_count: 16625 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7657 9 visits [500.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 16627 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16630, "number_of_timesteps": 349180, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7658 1 visits [500.0, 333.0, 332.0, 332.0, 332.0, 332.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 16630 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7659 2 visits [500.0, 333.0, 333.0, 332.0, 332.0, 332.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 16630 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7660 3 visits [500.0, 333.0, 333.0, 333.0, 332.0, 332.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 16633 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7661 4 visits [500.0, 333.0, 333.0, 333.0, 333.0, 332.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 16636 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7662 5 visits [500.0, 333.0, 333.0, 333.0, 333.0, 333.0, 332.0, 332.0, 500.0, 332.0]  episode_count: 16639 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16640, "number_of_timesteps": 349397, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7663 6 visits [500.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 332.0, 500.0, 332.0]  episode_count: 16640 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7664 7 visits [500.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 500.0, 332.0]  episode_count: 16642 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7665 9 visits [500.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 16642 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7666 1 visits [500.0, 334.0, 333.0, 333.0, 333.0, 333.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 16645 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16650, "number_of_timesteps": 349592, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7667 2 visits [500.0, 334.0, 334.0, 333.0, 333.0, 333.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 16650 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7668 3 visits [500.0, 334.0, 334.0, 334.0, 333.0, 333.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 16651 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7669 4 visits [500.0, 334.0, 334.0, 334.0, 334.0, 333.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 16652 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7670 5 visits [500.0, 334.0, 334.0, 334.0, 334.0, 334.0, 333.0, 333.0, 500.0, 333.0]  episode_count: 16654 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7671 6 visits [500.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 333.0, 500.0, 333.0]  episode_count: 16659 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16661, "number_of_timesteps": 349851, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7672 7 visits [500.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 500.0, 333.0]  episode_count: 16661 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7673 9 visits [500.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 16663 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7674 1 visits [500.0, 335.0, 334.0, 334.0, 334.0, 334.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 16665 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7675 2 visits [500.0, 335.0, 335.0, 334.0, 334.0, 334.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 16667 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7676 3 visits [500.0, 335.0, 335.0, 335.0, 334.0, 334.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 16667 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7677 4 visits [500.0, 335.0, 335.0, 335.0, 335.0, 334.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 16668 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16673, "number_of_timesteps": 350052, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7678 5 visits [500.0, 335.0, 335.0, 335.0, 335.0, 335.0, 334.0, 334.0, 500.0, 334.0]  episode_count: 16673 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7679 6 visits [500.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 334.0, 500.0, 334.0]  episode_count: 16675 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7680 7 visits [500.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 500.0, 334.0]  episode_count: 16677 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7681 9 visits [500.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 16679 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7682 1 visits [500.0, 336.0, 335.0, 335.0, 335.0, 335.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 16680 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16683, "number_of_timesteps": 350303, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7683 2 visits [500.0, 336.0, 336.0, 335.0, 335.0, 335.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 16683 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7684 3 visits [500.0, 336.0, 336.0, 336.0, 335.0, 335.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 16687 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7685 4 visits [500.0, 336.0, 336.0, 336.0, 336.0, 335.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 16688 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7686 5 visits [500.0, 336.0, 336.0, 336.0, 336.0, 336.0, 335.0, 335.0, 500.0, 335.0]  episode_count: 16692 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16693, "number_of_timesteps": 350512, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7687 6 visits [500.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 335.0, 500.0, 335.0]  episode_count: 16693 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7688 7 visits [500.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 500.0, 335.0]  episode_count: 16696 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7689 9 visits [500.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 16699 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7690 1 visits [500.0, 337.0, 336.0, 336.0, 336.0, 336.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 16699 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7691 2 visits [500.0, 337.0, 337.0, 336.0, 336.0, 336.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 16700 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16704, "number_of_timesteps": 350685, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7692 3 visits [500.0, 337.0, 337.0, 337.0, 336.0, 336.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 16704 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7693 4 visits [500.0, 337.0, 337.0, 337.0, 337.0, 336.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 16704 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7694 5 visits [500.0, 337.0, 337.0, 337.0, 337.0, 337.0, 336.0, 336.0, 500.0, 336.0]  episode_count: 16705 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7695 6 visits [500.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 336.0, 500.0, 336.0]  episode_count: 16710 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7696 7 visits [500.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 500.0, 336.0]  episode_count: 16712 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16715, "number_of_timesteps": 350964, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7697 9 visits [500.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 16715 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7698 1 visits [500.0, 338.0, 337.0, 337.0, 337.0, 337.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 16717 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7699 2 visits [500.0, 338.0, 338.0, 337.0, 337.0, 337.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 16718 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7700 3 visits [500.0, 338.0, 338.0, 338.0, 337.0, 337.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 16723 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7701 4 visits [500.0, 338.0, 338.0, 338.0, 338.0, 337.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 16724 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16729, "number_of_timesteps": 351229, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7702 5 visits [500.0, 338.0, 338.0, 338.0, 338.0, 338.0, 337.0, 337.0, 500.0, 337.0]  episode_count: 16729 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7703 6 visits [500.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 337.0, 500.0, 337.0]  episode_count: 16733 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7704 7 visits [500.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 500.0, 337.0]  episode_count: 16733 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7705 9 visits [500.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 16736 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16739, "number_of_timesteps": 351366, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7706 1 visits [500.0, 339.0, 338.0, 338.0, 338.0, 338.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 16739 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7707 2 visits [500.0, 339.0, 339.0, 338.0, 338.0, 338.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 16741 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7708 3 visits [500.0, 339.0, 339.0, 339.0, 338.0, 338.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 16742 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7709 4 visits [500.0, 339.0, 339.0, 339.0, 339.0, 338.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 16747 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7710 5 visits [500.0, 339.0, 339.0, 339.0, 339.0, 339.0, 338.0, 338.0, 500.0, 338.0]  episode_count: 16747 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7711 6 visits [500.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 338.0, 500.0, 338.0]  episode_count: 16748 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16751, "number_of_timesteps": 351613, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7712 7 visits [500.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 500.0, 338.0]  episode_count: 16751 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7713 9 visits [500.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 16753 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7714 1 visits [500.0, 340.0, 339.0, 339.0, 339.0, 339.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 16755 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7715 2 visits [500.0, 340.0, 340.0, 339.0, 339.0, 339.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 16760 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16761, "number_of_timesteps": 351828, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7716 3 visits [500.0, 340.0, 340.0, 340.0, 339.0, 339.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 16761 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7717 4 visits [500.0, 340.0, 340.0, 340.0, 340.0, 339.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 16762 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7718 5 visits [500.0, 340.0, 340.0, 340.0, 340.0, 340.0, 339.0, 339.0, 500.0, 339.0]  episode_count: 16765 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7719 6 visits [500.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 339.0, 500.0, 339.0]  episode_count: 16765 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7720 7 visits [500.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 500.0, 339.0]  episode_count: 16768 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16773, "number_of_timesteps": 352075, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7721 9 visits [500.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 16773 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7722 1 visits [500.0, 341.0, 340.0, 340.0, 340.0, 340.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 16774 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7723 2 visits [500.0, 341.0, 341.0, 340.0, 340.0, 340.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 16775 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7724 3 visits [500.0, 341.0, 341.0, 341.0, 340.0, 340.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 16777 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7725 4 visits [500.0, 341.0, 341.0, 341.0, 341.0, 340.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 16777 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7726 5 visits [500.0, 341.0, 341.0, 341.0, 341.0, 341.0, 340.0, 340.0, 500.0, 340.0]  episode_count: 16781 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16785, "number_of_timesteps": 352329, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7727 6 visits [500.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 340.0, 500.0, 340.0]  episode_count: 16785 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7728 7 visits [500.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 500.0, 340.0]  episode_count: 16786 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7729 9 visits [500.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 16787 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7730 1 visits [500.0, 342.0, 341.0, 341.0, 341.0, 341.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 16790 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7731 2 visits [500.0, 342.0, 342.0, 341.0, 341.0, 341.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 16792 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7732 3 visits [500.0, 342.0, 342.0, 342.0, 341.0, 341.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 16794 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16795, "number_of_timesteps": 352498, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7733 4 visits [500.0, 342.0, 342.0, 342.0, 342.0, 341.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 16795 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7734 5 visits [500.0, 342.0, 342.0, 342.0, 342.0, 342.0, 341.0, 341.0, 500.0, 341.0]  episode_count: 16799 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7735 6 visits [500.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 341.0, 500.0, 341.0]  episode_count: 16802 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7736 7 visits [500.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 500.0, 341.0]  episode_count: 16803 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16805, "number_of_timesteps": 352731, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7737 9 visits [500.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 16805 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7738 1 visits [500.0, 343.0, 342.0, 342.0, 342.0, 342.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 16808 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7739 2 visits [500.0, 343.0, 343.0, 342.0, 342.0, 342.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 16810 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7740 3 visits [500.0, 343.0, 343.0, 343.0, 342.0, 342.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 16811 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7741 4 visits [500.0, 343.0, 343.0, 343.0, 343.0, 342.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 16813 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16815, "number_of_timesteps": 352936, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7742 5 visits [500.0, 343.0, 343.0, 343.0, 343.0, 343.0, 342.0, 342.0, 500.0, 342.0]  episode_count: 16815 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7743 6 visits [500.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 342.0, 500.0, 342.0]  episode_count: 16816 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7744 7 visits [500.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 500.0, 342.0]  episode_count: 16818 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7745 9 visits [500.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 16818 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7746 1 visits [500.0, 344.0, 343.0, 343.0, 343.0, 343.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 16820 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7747 2 visits [500.0, 344.0, 344.0, 343.0, 343.0, 343.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 16821 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7748 3 visits [500.0, 344.0, 344.0, 344.0, 343.0, 343.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 16823 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16825, "number_of_timesteps": 353210, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7749 4 visits [500.0, 344.0, 344.0, 344.0, 344.0, 343.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 16825 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7750 5 visits [500.0, 344.0, 344.0, 344.0, 344.0, 344.0, 343.0, 343.0, 500.0, 343.0]  episode_count: 16827 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7751 6 visits [500.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 343.0, 500.0, 343.0]  episode_count: 16828 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7752 7 visits [500.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 500.0, 343.0]  episode_count: 16830 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7753 9 visits [500.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 16832 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7754 1 visits [500.0, 345.0, 344.0, 344.0, 344.0, 344.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 16833 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16836, "number_of_timesteps": 353557, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7755 2 visits [500.0, 345.0, 345.0, 344.0, 344.0, 344.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 16836 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7756 3 visits [500.0, 345.0, 345.0, 345.0, 344.0, 344.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 16840 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7757 4 visits [500.0, 345.0, 345.0, 345.0, 345.0, 344.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 16841 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7758 5 visits [500.0, 345.0, 345.0, 345.0, 345.0, 345.0, 344.0, 344.0, 500.0, 344.0]  episode_count: 16842 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16847, "number_of_timesteps": 353782, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7759 6 visits [500.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 344.0, 500.0, 344.0]  episode_count: 16847 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7760 7 visits [500.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 500.0, 344.0]  episode_count: 16849 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7761 9 visits [500.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 16850 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7762 1 visits [500.0, 346.0, 345.0, 345.0, 345.0, 345.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 16853 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7763 2 visits [500.0, 346.0, 346.0, 345.0, 345.0, 345.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 16855 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16857, "number_of_timesteps": 353973, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7764 3 visits [500.0, 346.0, 346.0, 346.0, 345.0, 345.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 16857 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7765 4 visits [500.0, 346.0, 346.0, 346.0, 346.0, 345.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 16859 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7766 5 visits [500.0, 346.0, 346.0, 346.0, 346.0, 346.0, 345.0, 345.0, 500.0, 345.0]  episode_count: 16860 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7767 6 visits [500.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 345.0, 500.0, 345.0]  episode_count: 16866 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16867, "number_of_timesteps": 354154, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 7768 7 visits [500.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 500.0, 345.0]  episode_count: 16867 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7769 9 visits [500.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 16870 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7770 1 visits [500.0, 347.0, 346.0, 346.0, 346.0, 346.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 16872 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7771 2 visits [500.0, 347.0, 347.0, 346.0, 346.0, 346.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 16873 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7772 3 visits [500.0, 347.0, 347.0, 347.0, 346.0, 346.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 16876 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16879, "number_of_timesteps": 354390, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7773 4 visits [500.0, 347.0, 347.0, 347.0, 347.0, 346.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 16879 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7774 5 visits [500.0, 347.0, 347.0, 347.0, 347.0, 347.0, 346.0, 346.0, 500.0, 346.0]  episode_count: 16881 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7775 6 visits [500.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 346.0, 500.0, 346.0]  episode_count: 16882 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7776 7 visits [500.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 500.0, 346.0]  episode_count: 16883 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7777 9 visits [500.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 16886 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7778 1 visits [500.0, 348.0, 347.0, 347.0, 347.0, 347.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 16887 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7779 2 visits [500.0, 348.0, 348.0, 347.0, 347.0, 347.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 16888 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16890, "number_of_timesteps": 354643, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7780 3 visits [500.0, 348.0, 348.0, 348.0, 347.0, 347.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 16890 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7781 4 visits [500.0, 348.0, 348.0, 348.0, 348.0, 347.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 16896 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7782 5 visits [500.0, 348.0, 348.0, 348.0, 348.0, 348.0, 347.0, 347.0, 500.0, 347.0]  episode_count: 16897 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7783 6 visits [500.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 347.0, 500.0, 347.0]  episode_count: 16899 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16900, "number_of_timesteps": 354871, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7784 7 visits [500.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 500.0, 347.0]  episode_count: 16900 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7785 9 visits [500.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 16903 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7786 1 visits [500.0, 349.0, 348.0, 348.0, 348.0, 348.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 16907 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16910, "number_of_timesteps": 355042, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7787 2 visits [500.0, 349.0, 349.0, 348.0, 348.0, 348.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 16910 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7788 3 visits [500.0, 349.0, 349.0, 349.0, 348.0, 348.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 16911 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7789 4 visits [500.0, 349.0, 349.0, 349.0, 349.0, 348.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 16913 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7790 5 visits [500.0, 349.0, 349.0, 349.0, 349.0, 349.0, 348.0, 348.0, 500.0, 348.0]  episode_count: 16915 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7791 6 visits [500.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 348.0, 500.0, 348.0]  episode_count: 16915 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7792 7 visits [500.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 500.0, 348.0]  episode_count: 16919 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16924, "number_of_timesteps": 355352, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7793 9 visits [500.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 16924 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7794 1 visits [500.0, 350.0, 349.0, 349.0, 349.0, 349.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 16925 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7795 2 visits [500.0, 350.0, 350.0, 349.0, 349.0, 349.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 16925 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7796 3 visits [500.0, 350.0, 350.0, 350.0, 349.0, 349.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 16928 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7797 4 visits [500.0, 350.0, 350.0, 350.0, 350.0, 349.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 16931 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16935, "number_of_timesteps": 355559, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7798 5 visits [500.0, 350.0, 350.0, 350.0, 350.0, 350.0, 349.0, 349.0, 500.0, 349.0]  episode_count: 16935 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7799 6 visits [500.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 349.0, 500.0, 349.0]  episode_count: 16938 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7800 7 visits [500.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 500.0, 349.0]  episode_count: 16940 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7801 9 visits [500.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 16944 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16945, "number_of_timesteps": 355714, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7802 1 visits [500.0, 351.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 16945 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7803 2 visits [500.0, 351.0, 351.0, 350.0, 350.0, 350.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 16948 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7804 3 visits [500.0, 351.0, 351.0, 351.0, 350.0, 350.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 16951 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7805 4 visits [500.0, 351.0, 351.0, 351.0, 351.0, 350.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 16954 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16955, "number_of_timesteps": 355882, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7806 5 visits [500.0, 351.0, 351.0, 351.0, 351.0, 351.0, 350.0, 350.0, 500.0, 350.0]  episode_count: 16955 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7807 6 visits [500.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 350.0, 500.0, 350.0]  episode_count: 16958 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7808 7 visits [500.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 500.0, 350.0]  episode_count: 16959 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7809 9 visits [500.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 16960 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16965, "number_of_timesteps": 356083, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7810 1 visits [500.0, 352.0, 351.0, 351.0, 351.0, 351.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 16965 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7811 2 visits [500.0, 352.0, 352.0, 351.0, 351.0, 351.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 16967 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7812 3 visits [500.0, 352.0, 352.0, 352.0, 351.0, 351.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 16968 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7813 4 visits [500.0, 352.0, 352.0, 352.0, 352.0, 351.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 16971 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7814 5 visits [500.0, 352.0, 352.0, 352.0, 352.0, 352.0, 351.0, 351.0, 500.0, 351.0]  episode_count: 16974 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16976, "number_of_timesteps": 356266, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7815 6 visits [500.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 351.0, 500.0, 351.0]  episode_count: 16976 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7816 7 visits [500.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 500.0, 351.0]  episode_count: 16976 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7817 9 visits [500.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 16977 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7818 1 visits [500.0, 353.0, 352.0, 352.0, 352.0, 352.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 16983 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16987, "number_of_timesteps": 356534, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7819 2 visits [500.0, 353.0, 353.0, 352.0, 352.0, 352.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 16987 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7820 3 visits [500.0, 353.0, 353.0, 353.0, 352.0, 352.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 16987 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7821 4 visits [500.0, 353.0, 353.0, 353.0, 353.0, 352.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 16987 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7822 5 visits [500.0, 353.0, 353.0, 353.0, 353.0, 353.0, 352.0, 352.0, 500.0, 352.0]  episode_count: 16990 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7823 6 visits [500.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 352.0, 500.0, 352.0]  episode_count: 16992 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7824 7 visits [500.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 500.0, 352.0]  episode_count: 16993 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7825 9 visits [500.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 16995 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 16998, "number_of_timesteps": 356764, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7826 1 visits [500.0, 354.0, 353.0, 353.0, 353.0, 353.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 16998 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7827 2 visits [500.0, 354.0, 354.0, 353.0, 353.0, 353.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 17001 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7828 3 visits [500.0, 354.0, 354.0, 354.0, 353.0, 353.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 17002 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7829 4 visits [500.0, 354.0, 354.0, 354.0, 354.0, 353.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 17003 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17008, "number_of_timesteps": 356991, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7830 5 visits [500.0, 354.0, 354.0, 354.0, 354.0, 354.0, 353.0, 353.0, 500.0, 353.0]  episode_count: 17008 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7831 6 visits [500.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 353.0, 500.0, 353.0]  episode_count: 17010 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7832 7 visits [500.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 500.0, 353.0]  episode_count: 17010 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7833 9 visits [500.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 17012 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7834 1 visits [500.0, 355.0, 354.0, 354.0, 354.0, 354.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 17013 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7835 2 visits [500.0, 355.0, 355.0, 354.0, 354.0, 354.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 17015 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7836 3 visits [500.0, 355.0, 355.0, 355.0, 354.0, 354.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 17017 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17018, "number_of_timesteps": 357211, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7837 4 visits [500.0, 355.0, 355.0, 355.0, 355.0, 354.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 17018 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7838 5 visits [500.0, 355.0, 355.0, 355.0, 355.0, 355.0, 354.0, 354.0, 500.0, 354.0]  episode_count: 17021 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7839 6 visits [500.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 354.0, 500.0, 354.0]  episode_count: 17023 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7840 7 visits [500.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 500.0, 354.0]  episode_count: 17025 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7841 9 visits [500.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 17026 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17028, "number_of_timesteps": 357484, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7842 1 visits [500.0, 356.0, 355.0, 355.0, 355.0, 355.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 17028 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7843 2 visits [500.0, 356.0, 356.0, 355.0, 355.0, 355.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 17031 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7844 3 visits [500.0, 356.0, 356.0, 356.0, 355.0, 355.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 17034 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7845 4 visits [500.0, 356.0, 356.0, 356.0, 356.0, 355.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 17034 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17039, "number_of_timesteps": 357721, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7846 5 visits [500.0, 356.0, 356.0, 356.0, 356.0, 356.0, 355.0, 355.0, 500.0, 355.0]  episode_count: 17039 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7847 6 visits [500.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 355.0, 500.0, 355.0]  episode_count: 17040 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7848 7 visits [500.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 500.0, 355.0]  episode_count: 17044 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7849 9 visits [500.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 17045 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7850 1 visits [500.0, 357.0, 356.0, 356.0, 356.0, 356.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 17047 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17050, "number_of_timesteps": 357943, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7851 2 visits [500.0, 357.0, 357.0, 356.0, 356.0, 356.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 17050 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7852 3 visits [500.0, 357.0, 357.0, 357.0, 356.0, 356.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 17055 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7853 4 visits [500.0, 357.0, 357.0, 357.0, 357.0, 356.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 17055 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7854 5 visits [500.0, 357.0, 357.0, 357.0, 357.0, 357.0, 356.0, 356.0, 500.0, 356.0]  episode_count: 17055 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17060, "number_of_timesteps": 358136, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7855 6 visits [500.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 356.0, 500.0, 356.0]  episode_count: 17060 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7856 7 visits [500.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 500.0, 356.0]  episode_count: 17061 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7857 9 visits [500.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 17062 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7858 1 visits [500.0, 358.0, 357.0, 357.0, 357.0, 357.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 17066 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7859 2 visits [500.0, 358.0, 358.0, 357.0, 357.0, 357.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 17068 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17070, "number_of_timesteps": 358356, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7860 3 visits [500.0, 358.0, 358.0, 358.0, 357.0, 357.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 17070 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7861 4 visits [500.0, 358.0, 358.0, 358.0, 358.0, 357.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 17074 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7862 5 visits [500.0, 358.0, 358.0, 358.0, 358.0, 358.0, 357.0, 357.0, 500.0, 357.0]  episode_count: 17075 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7863 6 visits [500.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 357.0, 500.0, 357.0]  episode_count: 17076 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17081, "number_of_timesteps": 358556, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7864 7 visits [500.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 500.0, 357.0]  episode_count: 17081 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7865 9 visits [500.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 17082 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7866 1 visits [500.0, 359.0, 358.0, 358.0, 358.0, 358.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 17083 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7867 2 visits [500.0, 359.0, 359.0, 358.0, 358.0, 358.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 17086 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7868 3 visits [500.0, 359.0, 359.0, 359.0, 358.0, 358.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 17089 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7869 4 visits [500.0, 359.0, 359.0, 359.0, 359.0, 358.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 17089 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17092, "number_of_timesteps": 358808, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7870 5 visits [500.0, 359.0, 359.0, 359.0, 359.0, 359.0, 358.0, 358.0, 500.0, 358.0]  episode_count: 17092 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7871 6 visits [500.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 358.0, 500.0, 358.0]  episode_count: 17094 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7872 7 visits [500.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 500.0, 358.0]  episode_count: 17095 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7873 9 visits [500.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 17098 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7874 1 visits [500.0, 360.0, 359.0, 359.0, 359.0, 359.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 17098 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7875 2 visits [500.0, 360.0, 360.0, 359.0, 359.0, 359.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 17099 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17102, "number_of_timesteps": 359010, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7876 3 visits [500.0, 360.0, 360.0, 360.0, 359.0, 359.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 17102 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7877 4 visits [500.0, 360.0, 360.0, 360.0, 360.0, 359.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 17105 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7878 5 visits [500.0, 360.0, 360.0, 360.0, 360.0, 360.0, 359.0, 359.0, 500.0, 359.0]  episode_count: 17107 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7879 6 visits [500.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 359.0, 500.0, 359.0]  episode_count: 17107 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7880 7 visits [500.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 500.0, 359.0]  episode_count: 17109 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17112, "number_of_timesteps": 359272, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7881 9 visits [500.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 17112 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7882 1 visits [500.0, 361.0, 360.0, 360.0, 360.0, 360.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 17115 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7883 2 visits [500.0, 361.0, 361.0, 360.0, 360.0, 360.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 17115 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7884 3 visits [500.0, 361.0, 361.0, 361.0, 360.0, 360.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 17119 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17123, "number_of_timesteps": 359545, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7885 4 visits [500.0, 361.0, 361.0, 361.0, 361.0, 360.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 17123 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7886 5 visits [500.0, 361.0, 361.0, 361.0, 361.0, 361.0, 360.0, 360.0, 500.0, 360.0]  episode_count: 17123 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7887 6 visits [500.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 360.0, 500.0, 360.0]  episode_count: 17125 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7888 7 visits [500.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 500.0, 360.0]  episode_count: 17128 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7889 9 visits [500.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 17130 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7890 1 visits [500.0, 362.0, 361.0, 361.0, 361.0, 361.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 17132 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17134, "number_of_timesteps": 359776, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7891 2 visits [500.0, 362.0, 362.0, 361.0, 361.0, 361.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 17134 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7892 3 visits [500.0, 362.0, 362.0, 362.0, 361.0, 361.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 17135 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7893 4 visits [500.0, 362.0, 362.0, 362.0, 362.0, 361.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 17137 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7894 5 visits [500.0, 362.0, 362.0, 362.0, 362.0, 362.0, 361.0, 361.0, 500.0, 361.0]  episode_count: 17138 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7895 6 visits [500.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 361.0, 500.0, 361.0]  episode_count: 17141 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17144, "number_of_timesteps": 360006, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7896 7 visits [500.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 500.0, 361.0]  episode_count: 17144 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7897 9 visits [500.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 17146 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7898 1 visits [500.0, 363.0, 362.0, 362.0, 362.0, 362.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 17152 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17154, "number_of_timesteps": 360193, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 7899 2 visits [500.0, 363.0, 363.0, 362.0, 362.0, 362.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 17154 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7900 3 visits [500.0, 363.0, 363.0, 363.0, 362.0, 362.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 17154 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7901 4 visits [500.0, 363.0, 363.0, 363.0, 363.0, 362.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 17158 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7902 5 visits [500.0, 363.0, 363.0, 363.0, 363.0, 363.0, 362.0, 362.0, 500.0, 362.0]  episode_count: 17159 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7903 6 visits [500.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 362.0, 500.0, 362.0]  episode_count: 17161 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17165, "number_of_timesteps": 360395, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 7904 7 visits [500.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 500.0, 362.0]  episode_count: 17165 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7905 9 visits [500.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 17166 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7906 1 visits [500.0, 364.0, 363.0, 363.0, 363.0, 363.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 17168 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7907 2 visits [500.0, 364.0, 364.0, 363.0, 363.0, 363.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 17172 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7908 3 visits [500.0, 364.0, 364.0, 364.0, 363.0, 363.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 17173 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17175, "number_of_timesteps": 360603, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 7909 4 visits [500.0, 364.0, 364.0, 364.0, 364.0, 363.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 17175 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7910 5 visits [500.0, 364.0, 364.0, 364.0, 364.0, 364.0, 363.0, 363.0, 500.0, 363.0]  episode_count: 17179 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7911 6 visits [500.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 363.0, 500.0, 363.0]  episode_count: 17181 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7912 7 visits [500.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 500.0, 363.0]  episode_count: 17184 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17186, "number_of_timesteps": 360787, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 7913 9 visits [500.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 17186 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7914 1 visits [500.0, 365.0, 364.0, 364.0, 364.0, 364.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 17188 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7915 2 visits [500.0, 365.0, 365.0, 364.0, 364.0, 364.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 17190 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7916 3 visits [500.0, 365.0, 365.0, 365.0, 364.0, 364.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 17194 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17196, "number_of_timesteps": 361008, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7917 4 visits [500.0, 365.0, 365.0, 365.0, 365.0, 364.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 17196 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7918 5 visits [500.0, 365.0, 365.0, 365.0, 365.0, 365.0, 364.0, 364.0, 500.0, 364.0]  episode_count: 17199 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7919 6 visits [500.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 364.0, 500.0, 364.0]  episode_count: 17202 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7920 7 visits [500.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 500.0, 364.0]  episode_count: 17205 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17207, "number_of_timesteps": 361169, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7921 9 visits [500.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 17207 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7922 1 visits [500.0, 366.0, 365.0, 365.0, 365.0, 365.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 17210 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7923 2 visits [500.0, 366.0, 366.0, 365.0, 365.0, 365.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 17211 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7924 3 visits [500.0, 366.0, 366.0, 366.0, 365.0, 365.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 17213 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17218, "number_of_timesteps": 361382, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7925 4 visits [500.0, 366.0, 366.0, 366.0, 366.0, 365.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 17218 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7926 5 visits [500.0, 366.0, 366.0, 366.0, 366.0, 366.0, 365.0, 365.0, 500.0, 365.0]  episode_count: 17218 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7927 6 visits [500.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 365.0, 500.0, 365.0]  episode_count: 17221 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7928 7 visits [500.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 500.0, 365.0]  episode_count: 17223 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7929 9 visits [500.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 17226 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17230, "number_of_timesteps": 361598, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7930 1 visits [500.0, 367.0, 366.0, 366.0, 366.0, 366.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 17230 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7931 2 visits [500.0, 367.0, 367.0, 366.0, 366.0, 366.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 17231 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7932 3 visits [500.0, 367.0, 367.0, 367.0, 366.0, 366.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 17233 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7933 4 visits [500.0, 367.0, 367.0, 367.0, 367.0, 366.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 17235 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7934 5 visits [500.0, 367.0, 367.0, 367.0, 367.0, 367.0, 366.0, 366.0, 500.0, 366.0]  episode_count: 17236 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7935 6 visits [500.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 366.0, 500.0, 366.0]  episode_count: 17237 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17241, "number_of_timesteps": 361849, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7936 7 visits [500.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 500.0, 366.0]  episode_count: 17241 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7937 9 visits [500.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 17243 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7938 1 visits [500.0, 368.0, 367.0, 367.0, 367.0, 367.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 17246 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7939 2 visits [500.0, 368.0, 368.0, 367.0, 367.0, 367.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 17248 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17251, "number_of_timesteps": 362070, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7940 3 visits [500.0, 368.0, 368.0, 368.0, 367.0, 367.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 17251 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7941 4 visits [500.0, 368.0, 368.0, 368.0, 368.0, 367.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 17253 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7942 5 visits [500.0, 368.0, 368.0, 368.0, 368.0, 368.0, 367.0, 367.0, 500.0, 367.0]  episode_count: 17253 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7943 6 visits [500.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 367.0, 500.0, 367.0]  episode_count: 17257 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7944 7 visits [500.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 500.0, 367.0]  episode_count: 17259 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17261, "number_of_timesteps": 362276, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 7945 9 visits [500.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 17261 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7946 1 visits [500.0, 369.0, 368.0, 368.0, 368.0, 368.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 17266 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7947 2 visits [500.0, 369.0, 369.0, 368.0, 368.0, 368.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 17269 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17273, "number_of_timesteps": 362471, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 7948 3 visits [500.0, 369.0, 369.0, 369.0, 368.0, 368.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 17273 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7949 4 visits [500.0, 369.0, 369.0, 369.0, 369.0, 368.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 17274 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7950 5 visits [500.0, 369.0, 369.0, 369.0, 369.0, 369.0, 368.0, 368.0, 500.0, 368.0]  episode_count: 17275 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7951 6 visits [500.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 368.0, 500.0, 368.0]  episode_count: 17278 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7952 7 visits [500.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 500.0, 368.0]  episode_count: 17281 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17283, "number_of_timesteps": 362648, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 7953 9 visits [500.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 17283 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7954 1 visits [500.0, 370.0, 369.0, 369.0, 369.0, 369.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 17284 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7955 2 visits [500.0, 370.0, 370.0, 369.0, 369.0, 369.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 17288 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7956 3 visits [500.0, 370.0, 370.0, 370.0, 369.0, 369.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 17290 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7957 4 visits [500.0, 370.0, 370.0, 370.0, 370.0, 369.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 17291 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17293, "number_of_timesteps": 362855, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7958 5 visits [500.0, 370.0, 370.0, 370.0, 370.0, 370.0, 369.0, 369.0, 500.0, 369.0]  episode_count: 17293 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7959 6 visits [500.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 369.0, 500.0, 369.0]  episode_count: 17297 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7960 7 visits [500.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 500.0, 369.0]  episode_count: 17299 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7961 9 visits [500.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 17300 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7962 1 visits [500.0, 371.0, 370.0, 370.0, 370.0, 370.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 17301 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17305, "number_of_timesteps": 363109, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 7963 2 visits [500.0, 371.0, 371.0, 370.0, 370.0, 370.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 17305 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7964 3 visits [500.0, 371.0, 371.0, 371.0, 370.0, 370.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 17306 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7965 4 visits [500.0, 371.0, 371.0, 371.0, 371.0, 370.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 17307 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7966 5 visits [500.0, 371.0, 371.0, 371.0, 371.0, 371.0, 370.0, 370.0, 500.0, 370.0]  episode_count: 17310 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7967 6 visits [500.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 370.0, 500.0, 370.0]  episode_count: 17312 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17316, "number_of_timesteps": 363336, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 7968 7 visits [500.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 500.0, 370.0]  episode_count: 17316 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7969 9 visits [500.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 17318 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7970 1 visits [500.0, 372.0, 371.0, 371.0, 371.0, 371.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 17320 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7971 2 visits [500.0, 372.0, 372.0, 371.0, 371.0, 371.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 17321 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7972 3 visits [500.0, 372.0, 372.0, 372.0, 371.0, 371.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 17324 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7973 4 visits [500.0, 372.0, 372.0, 372.0, 372.0, 371.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 17325 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17326, "number_of_timesteps": 363515, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 7974 5 visits [500.0, 372.0, 372.0, 372.0, 372.0, 372.0, 371.0, 371.0, 500.0, 371.0]  episode_count: 17326 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7975 6 visits [500.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 371.0, 500.0, 371.0]  episode_count: 17328 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7976 7 visits [500.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 500.0, 371.0]  episode_count: 17332 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7977 9 visits [500.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 17333 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7978 1 visits [500.0, 373.0, 372.0, 372.0, 372.0, 372.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 17335 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17338, "number_of_timesteps": 363774, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 7979 2 visits [500.0, 373.0, 373.0, 372.0, 372.0, 372.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 17338 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7980 3 visits [500.0, 373.0, 373.0, 373.0, 372.0, 372.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 17339 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7981 4 visits [500.0, 373.0, 373.0, 373.0, 373.0, 372.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 17340 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7982 5 visits [500.0, 373.0, 373.0, 373.0, 373.0, 373.0, 372.0, 372.0, 500.0, 372.0]  episode_count: 17341 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7983 6 visits [500.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 372.0, 500.0, 372.0]  episode_count: 17347 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17348, "number_of_timesteps": 364085, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 7984 7 visits [500.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 500.0, 372.0]  episode_count: 17348 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7985 9 visits [500.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 17348 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7986 1 visits [500.0, 374.0, 373.0, 373.0, 373.0, 373.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 17349 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7987 2 visits [500.0, 374.0, 374.0, 373.0, 373.0, 373.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 17352 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7988 3 visits [500.0, 374.0, 374.0, 374.0, 373.0, 373.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 17354 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7989 4 visits [500.0, 374.0, 374.0, 374.0, 374.0, 373.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 17354 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7990 5 visits [500.0, 374.0, 374.0, 374.0, 374.0, 374.0, 373.0, 373.0, 500.0, 373.0]  episode_count: 17357 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17360, "number_of_timesteps": 364391, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 7991 6 visits [500.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 373.0, 500.0, 373.0]  episode_count: 17360 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7992 7 visits [500.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 500.0, 373.0]  episode_count: 17364 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7993 9 visits [500.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 17365 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7994 1 visits [500.0, 375.0, 374.0, 374.0, 374.0, 374.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 17367 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17370, "number_of_timesteps": 364589, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 7995 2 visits [500.0, 375.0, 375.0, 374.0, 374.0, 374.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 17370 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7996 3 visits [500.0, 375.0, 375.0, 375.0, 374.0, 374.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 17373 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7997 4 visits [500.0, 375.0, 375.0, 375.0, 375.0, 374.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 17375 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7998 5 visits [500.0, 375.0, 375.0, 375.0, 375.0, 375.0, 374.0, 374.0, 500.0, 374.0]  episode_count: 17375 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 7999 6 visits [500.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 374.0, 500.0, 374.0]  episode_count: 17377 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17380, "number_of_timesteps": 364800, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 8000 7 visits [500.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 500.0, 374.0]  episode_count: 17380 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8001 9 visits [500.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 17382 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8002 1 visits [500.0, 376.0, 375.0, 375.0, 375.0, 375.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 17383 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8003 2 visits [500.0, 376.0, 376.0, 375.0, 375.0, 375.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 17383 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8004 3 visits [500.0, 376.0, 376.0, 376.0, 375.0, 375.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 17386 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8005 4 visits [500.0, 376.0, 376.0, 376.0, 376.0, 375.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 17389 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17391, "number_of_timesteps": 365032, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 8006 5 visits [500.0, 376.0, 376.0, 376.0, 376.0, 376.0, 375.0, 375.0, 500.0, 375.0]  episode_count: 17391 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8007 6 visits [500.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 375.0, 500.0, 375.0]  episode_count: 17392 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8008 7 visits [500.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 500.0, 375.0]  episode_count: 17395 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8009 9 visits [500.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 17396 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8010 1 visits [500.0, 377.0, 376.0, 376.0, 376.0, 376.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 17398 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17402, "number_of_timesteps": 365352, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 8011 2 visits [500.0, 377.0, 377.0, 376.0, 376.0, 376.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 17402 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8012 3 visits [500.0, 377.0, 377.0, 377.0, 376.0, 376.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 17404 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8013 4 visits [500.0, 377.0, 377.0, 377.0, 377.0, 376.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 17405 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8014 5 visits [500.0, 377.0, 377.0, 377.0, 377.0, 377.0, 376.0, 376.0, 500.0, 376.0]  episode_count: 17407 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8015 6 visits [500.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 376.0, 500.0, 376.0]  episode_count: 17408 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17412, "number_of_timesteps": 365569, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8016 7 visits [500.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 500.0, 376.0]  episode_count: 17412 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8017 9 visits [500.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 17414 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8018 1 visits [500.0, 378.0, 377.0, 377.0, 377.0, 377.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 17417 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8019 2 visits [500.0, 378.0, 378.0, 377.0, 377.0, 377.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 17418 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8020 3 visits [500.0, 378.0, 378.0, 378.0, 377.0, 377.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 17418 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17422, "number_of_timesteps": 365798, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8021 4 visits [500.0, 378.0, 378.0, 378.0, 378.0, 377.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 17422 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8022 5 visits [500.0, 378.0, 378.0, 378.0, 378.0, 378.0, 377.0, 377.0, 500.0, 377.0]  episode_count: 17424 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8023 6 visits [500.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 377.0, 500.0, 377.0]  episode_count: 17425 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8024 7 visits [500.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 500.0, 377.0]  episode_count: 17425 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8025 9 visits [500.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 17431 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17432, "number_of_timesteps": 366042, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8026 1 visits [500.0, 379.0, 378.0, 378.0, 378.0, 378.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 17432 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8027 2 visits [500.0, 379.0, 379.0, 378.0, 378.0, 378.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 17434 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8028 3 visits [500.0, 379.0, 379.0, 379.0, 378.0, 378.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 17436 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8029 4 visits [500.0, 379.0, 379.0, 379.0, 379.0, 378.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 17439 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8030 5 visits [500.0, 379.0, 379.0, 379.0, 379.0, 379.0, 378.0, 378.0, 500.0, 378.0]  episode_count: 17441 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17443, "number_of_timesteps": 366230, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 8031 6 visits [500.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 378.0, 500.0, 378.0]  episode_count: 17443 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8032 7 visits [500.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 500.0, 378.0]  episode_count: 17444 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8033 9 visits [500.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 17446 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8034 1 visits [500.0, 380.0, 379.0, 379.0, 379.0, 379.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 17447 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8035 2 visits [500.0, 380.0, 380.0, 379.0, 379.0, 379.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 17451 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17453, "number_of_timesteps": 366490, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8036 3 visits [500.0, 380.0, 380.0, 380.0, 379.0, 379.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 17453 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8037 4 visits [500.0, 380.0, 380.0, 380.0, 380.0, 379.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 17454 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8038 5 visits [500.0, 380.0, 380.0, 380.0, 380.0, 380.0, 379.0, 379.0, 500.0, 379.0]  episode_count: 17456 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8039 6 visits [500.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 379.0, 500.0, 379.0]  episode_count: 17457 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8040 7 visits [500.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 500.0, 379.0]  episode_count: 17461 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8041 9 visits [500.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 17462 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17464, "number_of_timesteps": 366756, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8042 1 visits [500.0, 381.0, 380.0, 380.0, 380.0, 380.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 17464 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8043 2 visits [500.0, 381.0, 381.0, 380.0, 380.0, 380.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 17467 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8044 3 visits [500.0, 381.0, 381.0, 381.0, 380.0, 380.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 17469 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8045 4 visits [500.0, 381.0, 381.0, 381.0, 381.0, 380.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 17470 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17474, "number_of_timesteps": 366970, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8046 5 visits [500.0, 381.0, 381.0, 381.0, 381.0, 381.0, 380.0, 380.0, 500.0, 380.0]  episode_count: 17474 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8047 6 visits [500.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 380.0, 500.0, 380.0]  episode_count: 17476 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8048 7 visits [500.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 500.0, 380.0]  episode_count: 17477 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8049 9 visits [500.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 17479 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8050 1 visits [500.0, 382.0, 381.0, 381.0, 381.0, 381.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 17479 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8051 2 visits [500.0, 382.0, 382.0, 381.0, 381.0, 381.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 17481 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17486, "number_of_timesteps": 367259, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8052 3 visits [500.0, 382.0, 382.0, 382.0, 381.0, 381.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 17486 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8053 4 visits [500.0, 382.0, 382.0, 382.0, 382.0, 381.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 17486 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8054 5 visits [500.0, 382.0, 382.0, 382.0, 382.0, 382.0, 381.0, 381.0, 500.0, 381.0]  episode_count: 17490 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8055 6 visits [500.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 381.0, 500.0, 381.0]  episode_count: 17492 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8056 7 visits [500.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 500.0, 381.0]  episode_count: 17493 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8057 9 visits [500.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 17495 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17496, "number_of_timesteps": 367460, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8058 1 visits [500.0, 383.0, 382.0, 382.0, 382.0, 382.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 17496 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8059 2 visits [500.0, 383.0, 383.0, 382.0, 382.0, 382.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 17500 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8060 3 visits [500.0, 383.0, 383.0, 383.0, 382.0, 382.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 17501 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8061 4 visits [500.0, 383.0, 383.0, 383.0, 383.0, 382.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 17503 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17507, "number_of_timesteps": 367688, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8062 5 visits [500.0, 383.0, 383.0, 383.0, 383.0, 383.0, 382.0, 382.0, 500.0, 382.0]  episode_count: 17507 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8063 6 visits [500.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 382.0, 500.0, 382.0]  episode_count: 17509 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8064 7 visits [500.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 500.0, 382.0]  episode_count: 17509 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8065 9 visits [500.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 17512 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8066 1 visits [500.0, 384.0, 383.0, 383.0, 383.0, 383.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 17514 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8067 2 visits [500.0, 384.0, 384.0, 383.0, 383.0, 383.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 17515 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17517, "number_of_timesteps": 367915, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8068 3 visits [500.0, 384.0, 384.0, 384.0, 383.0, 383.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 17517 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8069 4 visits [500.0, 384.0, 384.0, 384.0, 384.0, 383.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 17519 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8070 5 visits [500.0, 384.0, 384.0, 384.0, 384.0, 384.0, 383.0, 383.0, 500.0, 383.0]  episode_count: 17522 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8071 6 visits [500.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 383.0, 500.0, 383.0]  episode_count: 17524 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17527, "number_of_timesteps": 368127, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8072 7 visits [500.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 500.0, 383.0]  episode_count: 17527 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8073 9 visits [500.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 17528 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8074 1 visits [500.0, 385.0, 384.0, 384.0, 384.0, 384.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 17530 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8075 2 visits [500.0, 385.0, 385.0, 384.0, 384.0, 384.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 17531 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8076 3 visits [500.0, 385.0, 385.0, 385.0, 384.0, 384.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 17534 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8077 4 visits [500.0, 385.0, 385.0, 385.0, 385.0, 384.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 17536 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17537, "number_of_timesteps": 368381, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 8078 5 visits [500.0, 385.0, 385.0, 385.0, 385.0, 385.0, 384.0, 384.0, 500.0, 384.0]  episode_count: 17537 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8079 6 visits [500.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 384.0, 500.0, 384.0]  episode_count: 17542 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8080 7 visits [500.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 500.0, 384.0]  episode_count: 17543 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8081 9 visits [500.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 17545 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17547, "number_of_timesteps": 368582, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8082 1 visits [500.0, 386.0, 385.0, 385.0, 385.0, 385.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 17547 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8083 2 visits [500.0, 386.0, 386.0, 385.0, 385.0, 385.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 17547 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8084 3 visits [500.0, 386.0, 386.0, 386.0, 385.0, 385.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 17552 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8085 4 visits [500.0, 386.0, 386.0, 386.0, 386.0, 385.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 17554 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8086 5 visits [500.0, 386.0, 386.0, 386.0, 386.0, 386.0, 385.0, 385.0, 500.0, 385.0]  episode_count: 17554 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8087 6 visits [500.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 385.0, 500.0, 385.0]  episode_count: 17556 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17559, "number_of_timesteps": 368842, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8088 7 visits [500.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 500.0, 385.0]  episode_count: 17559 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8089 9 visits [500.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 17561 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8090 1 visits [500.0, 387.0, 386.0, 386.0, 386.0, 386.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 17566 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8091 2 visits [500.0, 387.0, 387.0, 386.0, 386.0, 386.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 17566 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8092 3 visits [500.0, 387.0, 387.0, 387.0, 386.0, 386.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 17568 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17571, "number_of_timesteps": 369059, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8093 4 visits [500.0, 387.0, 387.0, 387.0, 387.0, 386.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 17571 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8094 5 visits [500.0, 387.0, 387.0, 387.0, 387.0, 387.0, 386.0, 386.0, 500.0, 386.0]  episode_count: 17573 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8095 6 visits [500.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 386.0, 500.0, 386.0]  episode_count: 17574 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8096 7 visits [500.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 500.0, 386.0]  episode_count: 17576 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8097 9 visits [500.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 17578 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8098 1 visits [500.0, 388.0, 387.0, 387.0, 387.0, 387.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 17580 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17583, "number_of_timesteps": 369366, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8099 2 visits [500.0, 388.0, 388.0, 387.0, 387.0, 387.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 17583 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8100 3 visits [500.0, 388.0, 388.0, 388.0, 387.0, 387.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 17584 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8101 4 visits [500.0, 388.0, 388.0, 388.0, 388.0, 387.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 17586 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8102 5 visits [500.0, 388.0, 388.0, 388.0, 388.0, 388.0, 387.0, 387.0, 500.0, 387.0]  episode_count: 17586 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8103 6 visits [500.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 387.0, 500.0, 387.0]  episode_count: 17590 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17593, "number_of_timesteps": 369614, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8104 7 visits [500.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 500.0, 387.0]  episode_count: 17593 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8105 9 visits [500.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 17594 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8106 1 visits [500.0, 389.0, 388.0, 388.0, 388.0, 388.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 17595 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8107 2 visits [500.0, 389.0, 389.0, 388.0, 388.0, 388.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 17599 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8108 3 visits [500.0, 389.0, 389.0, 389.0, 388.0, 388.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 17600 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8109 4 visits [500.0, 389.0, 389.0, 389.0, 389.0, 388.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 17602 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17603, "number_of_timesteps": 369838, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8110 5 visits [500.0, 389.0, 389.0, 389.0, 389.0, 389.0, 388.0, 388.0, 500.0, 388.0]  episode_count: 17603 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8111 6 visits [500.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 388.0, 500.0, 388.0]  episode_count: 17604 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8112 7 visits [500.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 500.0, 388.0]  episode_count: 17609 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8113 9 visits [500.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 17609 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8114 1 visits [500.0, 390.0, 389.0, 389.0, 389.0, 389.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 17612 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17615, "number_of_timesteps": 370086, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8115 2 visits [500.0, 390.0, 390.0, 389.0, 389.0, 389.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 17615 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8116 3 visits [500.0, 390.0, 390.0, 390.0, 389.0, 389.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 17617 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8117 4 visits [500.0, 390.0, 390.0, 390.0, 390.0, 389.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 17619 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8118 5 visits [500.0, 390.0, 390.0, 390.0, 390.0, 390.0, 389.0, 389.0, 500.0, 389.0]  episode_count: 17621 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8119 6 visits [500.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 389.0, 500.0, 389.0]  episode_count: 17624 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17627, "number_of_timesteps": 370371, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8120 7 visits [500.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 500.0, 389.0]  episode_count: 17627 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8121 9 visits [500.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 17630 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8122 1 visits [500.0, 391.0, 390.0, 390.0, 390.0, 390.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 17632 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8123 2 visits [500.0, 391.0, 391.0, 390.0, 390.0, 390.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 17635 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17638, "number_of_timesteps": 370542, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8124 3 visits [500.0, 391.0, 391.0, 391.0, 390.0, 390.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 17638 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8125 4 visits [500.0, 391.0, 391.0, 391.0, 391.0, 390.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 17639 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8126 5 visits [500.0, 391.0, 391.0, 391.0, 391.0, 391.0, 390.0, 390.0, 500.0, 390.0]  episode_count: 17640 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8127 6 visits [500.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 390.0, 500.0, 390.0]  episode_count: 17642 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8128 7 visits [500.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 500.0, 390.0]  episode_count: 17646 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17648, "number_of_timesteps": 370779, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8129 9 visits [500.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 17648 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8130 1 visits [500.0, 392.0, 391.0, 391.0, 391.0, 391.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 17650 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8131 2 visits [500.0, 392.0, 392.0, 391.0, 391.0, 391.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 17652 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8132 3 visits [500.0, 392.0, 392.0, 392.0, 391.0, 391.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 17652 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8133 4 visits [500.0, 392.0, 392.0, 392.0, 392.0, 391.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 17656 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8134 5 visits [500.0, 392.0, 392.0, 392.0, 392.0, 392.0, 391.0, 391.0, 500.0, 391.0]  episode_count: 17657 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17658, "number_of_timesteps": 370978, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8135 6 visits [500.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 391.0, 500.0, 391.0]  episode_count: 17658 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8136 7 visits [500.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 500.0, 391.0]  episode_count: 17661 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8137 9 visits [500.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 17663 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8138 1 visits [500.0, 393.0, 392.0, 392.0, 392.0, 392.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 17665 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17668, "number_of_timesteps": 371221, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8139 2 visits [500.0, 393.0, 393.0, 392.0, 392.0, 392.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 17668 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8140 3 visits [500.0, 393.0, 393.0, 393.0, 392.0, 392.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 17669 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8141 4 visits [500.0, 393.0, 393.0, 393.0, 393.0, 392.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 17671 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8142 5 visits [500.0, 393.0, 393.0, 393.0, 393.0, 393.0, 392.0, 392.0, 500.0, 392.0]  episode_count: 17675 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8143 6 visits [500.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 392.0, 500.0, 392.0]  episode_count: 17676 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17679, "number_of_timesteps": 371437, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8144 7 visits [500.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 500.0, 392.0]  episode_count: 17679 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8145 9 visits [500.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 17680 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8146 1 visits [500.0, 394.0, 393.0, 393.0, 393.0, 393.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 17682 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8147 2 visits [500.0, 394.0, 394.0, 393.0, 393.0, 393.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 17685 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8148 3 visits [500.0, 394.0, 394.0, 394.0, 393.0, 393.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 17686 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8149 4 visits [500.0, 394.0, 394.0, 394.0, 394.0, 393.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 17688 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17690, "number_of_timesteps": 371671, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8150 5 visits [500.0, 394.0, 394.0, 394.0, 394.0, 394.0, 393.0, 393.0, 500.0, 393.0]  episode_count: 17690 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8151 6 visits [500.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 393.0, 500.0, 393.0]  episode_count: 17692 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8152 7 visits [500.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 500.0, 393.0]  episode_count: 17694 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8153 9 visits [500.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 17695 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8154 1 visits [500.0, 395.0, 394.0, 394.0, 394.0, 394.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 17698 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17701, "number_of_timesteps": 371954, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8155 2 visits [500.0, 395.0, 395.0, 394.0, 394.0, 394.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 17701 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8156 3 visits [500.0, 395.0, 395.0, 395.0, 394.0, 394.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 17703 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8157 4 visits [500.0, 395.0, 395.0, 395.0, 395.0, 394.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 17704 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8158 5 visits [500.0, 395.0, 395.0, 395.0, 395.0, 395.0, 394.0, 394.0, 500.0, 394.0]  episode_count: 17706 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8159 6 visits [500.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 394.0, 500.0, 394.0]  episode_count: 17709 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8160 7 visits [500.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 500.0, 394.0]  episode_count: 17710 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17712, "number_of_timesteps": 372174, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8161 9 visits [500.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 17712 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8162 1 visits [500.0, 396.0, 395.0, 395.0, 395.0, 395.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 17714 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8163 2 visits [500.0, 396.0, 396.0, 395.0, 395.0, 395.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 17715 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8164 3 visits [500.0, 396.0, 396.0, 396.0, 395.0, 395.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 17719 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8165 4 visits [500.0, 396.0, 396.0, 396.0, 396.0, 395.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 17720 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8166 5 visits [500.0, 396.0, 396.0, 396.0, 396.0, 396.0, 395.0, 395.0, 500.0, 395.0]  episode_count: 17721 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8167 6 visits [500.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 395.0, 500.0, 395.0]  episode_count: 17721 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17725, "number_of_timesteps": 372482, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8168 7 visits [500.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 500.0, 395.0]  episode_count: 17725 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8169 9 visits [500.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 17728 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8170 1 visits [500.0, 397.0, 396.0, 396.0, 396.0, 396.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 17729 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8171 2 visits [500.0, 397.0, 397.0, 396.0, 396.0, 396.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 17731 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8172 3 visits [500.0, 397.0, 397.0, 397.0, 396.0, 396.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 17734 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17735, "number_of_timesteps": 372730, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8173 4 visits [500.0, 397.0, 397.0, 397.0, 397.0, 396.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 17735 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8174 5 visits [500.0, 397.0, 397.0, 397.0, 397.0, 397.0, 396.0, 396.0, 500.0, 396.0]  episode_count: 17736 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8175 6 visits [500.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 396.0, 500.0, 396.0]  episode_count: 17738 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8176 7 visits [500.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 500.0, 396.0]  episode_count: 17741 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8177 9 visits [500.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 17742 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8178 1 visits [500.0, 398.0, 397.0, 397.0, 397.0, 397.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 17744 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17746, "number_of_timesteps": 373024, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8179 2 visits [500.0, 398.0, 398.0, 397.0, 397.0, 397.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 17746 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8180 3 visits [500.0, 398.0, 398.0, 398.0, 397.0, 397.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 17749 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8181 4 visits [500.0, 398.0, 398.0, 398.0, 398.0, 397.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 17750 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8182 5 visits [500.0, 398.0, 398.0, 398.0, 398.0, 398.0, 397.0, 397.0, 500.0, 397.0]  episode_count: 17752 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8183 6 visits [500.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 397.0, 500.0, 397.0]  episode_count: 17755 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17758, "number_of_timesteps": 373302, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8184 7 visits [500.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 500.0, 397.0]  episode_count: 17758 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8185 9 visits [500.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 17761 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8186 1 visits [500.0, 399.0, 398.0, 398.0, 398.0, 398.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 17764 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8187 2 visits [500.0, 399.0, 399.0, 398.0, 398.0, 398.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 17765 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17768, "number_of_timesteps": 373460, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8188 3 visits [500.0, 399.0, 399.0, 399.0, 398.0, 398.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 17768 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8189 4 visits [500.0, 399.0, 399.0, 399.0, 399.0, 398.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 17771 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8190 5 visits [500.0, 399.0, 399.0, 399.0, 399.0, 399.0, 398.0, 398.0, 500.0, 398.0]  episode_count: 17773 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8191 6 visits [500.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 398.0, 500.0, 398.0]  episode_count: 17774 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17779, "number_of_timesteps": 373653, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8192 7 visits [500.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 500.0, 398.0]  episode_count: 17779 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8193 9 visits [500.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 17779 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8194 1 visits [500.0, 400.0, 399.0, 399.0, 399.0, 399.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 17780 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8195 2 visits [500.0, 400.0, 400.0, 399.0, 399.0, 399.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 17783 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8196 3 visits [500.0, 400.0, 400.0, 400.0, 399.0, 399.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 17787 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8197 4 visits [500.0, 400.0, 400.0, 400.0, 400.0, 399.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 17787 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17790, "number_of_timesteps": 373882, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8198 5 visits [500.0, 400.0, 400.0, 400.0, 400.0, 400.0, 399.0, 399.0, 500.0, 399.0]  episode_count: 17790 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8199 6 visits [500.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 399.0, 500.0, 399.0]  episode_count: 17793 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8200 7 visits [500.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 500.0, 399.0]  episode_count: 17796 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8201 9 visits [500.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 17798 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17801, "number_of_timesteps": 374103, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8202 1 visits [500.0, 401.0, 400.0, 400.0, 400.0, 400.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 17801 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8203 2 visits [500.0, 401.0, 401.0, 400.0, 400.0, 400.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 17804 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8204 3 visits [500.0, 401.0, 401.0, 401.0, 400.0, 400.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 17805 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8205 4 visits [500.0, 401.0, 401.0, 401.0, 401.0, 400.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 17808 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8206 5 visits [500.0, 401.0, 401.0, 401.0, 401.0, 401.0, 400.0, 400.0, 500.0, 400.0]  episode_count: 17810 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17812, "number_of_timesteps": 374301, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8207 6 visits [500.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 400.0, 500.0, 400.0]  episode_count: 17812 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8208 7 visits [500.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 500.0, 400.0]  episode_count: 17814 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8209 9 visits [500.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 17816 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8210 1 visits [500.0, 402.0, 401.0, 401.0, 401.0, 401.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 17819 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17822, "number_of_timesteps": 374508, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8211 2 visits [500.0, 402.0, 402.0, 401.0, 401.0, 401.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 17822 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8212 3 visits [500.0, 402.0, 402.0, 402.0, 401.0, 401.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 17825 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8213 4 visits [500.0, 402.0, 402.0, 402.0, 402.0, 401.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 17826 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8214 5 visits [500.0, 402.0, 402.0, 402.0, 402.0, 402.0, 401.0, 401.0, 500.0, 401.0]  episode_count: 17828 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8215 6 visits [500.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 401.0, 500.0, 401.0]  episode_count: 17829 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8216 7 visits [500.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 500.0, 401.0]  episode_count: 17830 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17832, "number_of_timesteps": 374715, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8217 9 visits [500.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 17832 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8218 1 visits [500.0, 403.0, 402.0, 402.0, 402.0, 402.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 17837 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8219 2 visits [500.0, 403.0, 403.0, 402.0, 402.0, 402.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 17840 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8220 3 visits [500.0, 403.0, 403.0, 403.0, 402.0, 402.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 17841 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17844, "number_of_timesteps": 374961, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8221 4 visits [500.0, 403.0, 403.0, 403.0, 403.0, 402.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 17844 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8222 5 visits [500.0, 403.0, 403.0, 403.0, 403.0, 403.0, 402.0, 402.0, 500.0, 402.0]  episode_count: 17849 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8223 6 visits [500.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 402.0, 500.0, 402.0]  episode_count: 17849 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8224 7 visits [500.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 500.0, 402.0]  episode_count: 17850 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17854, "number_of_timesteps": 375105, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8225 9 visits [500.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 17854 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8226 1 visits [500.0, 404.0, 403.0, 403.0, 403.0, 403.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 17855 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8227 2 visits [500.0, 404.0, 404.0, 403.0, 403.0, 403.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 17856 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8228 3 visits [500.0, 404.0, 404.0, 404.0, 403.0, 403.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 17858 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8229 4 visits [500.0, 404.0, 404.0, 404.0, 404.0, 403.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 17861 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8230 5 visits [500.0, 404.0, 404.0, 404.0, 404.0, 404.0, 403.0, 403.0, 500.0, 403.0]  episode_count: 17863 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17864, "number_of_timesteps": 375384, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8231 6 visits [500.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 403.0, 500.0, 403.0]  episode_count: 17864 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8232 7 visits [500.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 500.0, 403.0]  episode_count: 17866 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8233 9 visits [500.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 17870 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8234 1 visits [500.0, 405.0, 404.0, 404.0, 404.0, 404.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 17872 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17874, "number_of_timesteps": 375600, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8235 2 visits [500.0, 405.0, 405.0, 404.0, 404.0, 404.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 17874 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8236 3 visits [500.0, 405.0, 405.0, 405.0, 404.0, 404.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 17876 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8237 4 visits [500.0, 405.0, 405.0, 405.0, 405.0, 404.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 17879 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8238 5 visits [500.0, 405.0, 405.0, 405.0, 405.0, 405.0, 404.0, 404.0, 500.0, 404.0]  episode_count: 17880 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8239 6 visits [500.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 404.0, 500.0, 404.0]  episode_count: 17883 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17884, "number_of_timesteps": 375790, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8240 7 visits [500.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 500.0, 404.0]  episode_count: 17884 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8241 9 visits [500.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 17887 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8242 1 visits [500.0, 406.0, 405.0, 405.0, 405.0, 405.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 17890 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8243 2 visits [500.0, 406.0, 406.0, 405.0, 405.0, 405.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 17890 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8244 3 visits [500.0, 406.0, 406.0, 406.0, 405.0, 405.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 17893 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17894, "number_of_timesteps": 376002, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8245 4 visits [500.0, 406.0, 406.0, 406.0, 406.0, 405.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 17894 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8246 5 visits [500.0, 406.0, 406.0, 406.0, 406.0, 406.0, 405.0, 405.0, 500.0, 405.0]  episode_count: 17896 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8247 6 visits [500.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 405.0, 500.0, 405.0]  episode_count: 17899 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8248 7 visits [500.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 500.0, 405.0]  episode_count: 17902 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8249 9 visits [500.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 17903 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17907, "number_of_timesteps": 376288, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8250 1 visits [500.0, 407.0, 406.0, 406.0, 406.0, 406.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 17907 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8251 2 visits [500.0, 407.0, 407.0, 406.0, 406.0, 406.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 17910 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8252 3 visits [500.0, 407.0, 407.0, 407.0, 406.0, 406.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 17911 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8253 4 visits [500.0, 407.0, 407.0, 407.0, 407.0, 406.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 17913 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8254 5 visits [500.0, 407.0, 407.0, 407.0, 407.0, 407.0, 406.0, 406.0, 500.0, 406.0]  episode_count: 17915 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17918, "number_of_timesteps": 376503, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8255 6 visits [500.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 406.0, 500.0, 406.0]  episode_count: 17918 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8256 7 visits [500.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 500.0, 406.0]  episode_count: 17921 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8257 9 visits [500.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 17922 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8258 1 visits [500.0, 408.0, 407.0, 407.0, 407.0, 407.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 17925 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8259 2 visits [500.0, 408.0, 408.0, 407.0, 407.0, 407.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 17925 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17931, "number_of_timesteps": 376755, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8260 3 visits [500.0, 408.0, 408.0, 408.0, 407.0, 407.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 17931 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8261 4 visits [500.0, 408.0, 408.0, 408.0, 408.0, 407.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 17932 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8262 5 visits [500.0, 408.0, 408.0, 408.0, 408.0, 408.0, 407.0, 407.0, 500.0, 407.0]  episode_count: 17933 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8263 6 visits [500.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 407.0, 500.0, 407.0]  episode_count: 17934 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8264 7 visits [500.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 500.0, 407.0]  episode_count: 17939 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17942, "number_of_timesteps": 376996, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8265 9 visits [500.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 17942 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8266 1 visits [500.0, 409.0, 408.0, 408.0, 408.0, 408.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 17943 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8267 2 visits [500.0, 409.0, 409.0, 408.0, 408.0, 408.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 17944 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8268 3 visits [500.0, 409.0, 409.0, 409.0, 408.0, 408.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 17947 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8269 4 visits [500.0, 409.0, 409.0, 409.0, 409.0, 408.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 17948 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8270 5 visits [500.0, 409.0, 409.0, 409.0, 409.0, 409.0, 408.0, 408.0, 500.0, 408.0]  episode_count: 17949 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17953, "number_of_timesteps": 377176, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8271 6 visits [500.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 408.0, 500.0, 408.0]  episode_count: 17953 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8272 7 visits [500.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 500.0, 408.0]  episode_count: 17953 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8273 9 visits [500.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 17954 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8274 1 visits [500.0, 410.0, 409.0, 409.0, 409.0, 409.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 17959 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8275 2 visits [500.0, 410.0, 410.0, 409.0, 409.0, 409.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 17961 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17963, "number_of_timesteps": 377470, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8276 3 visits [500.0, 410.0, 410.0, 410.0, 409.0, 409.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 17963 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8277 4 visits [500.0, 410.0, 410.0, 410.0, 410.0, 409.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 17965 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8278 5 visits [500.0, 410.0, 410.0, 410.0, 410.0, 410.0, 409.0, 409.0, 500.0, 409.0]  episode_count: 17967 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8279 6 visits [500.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 409.0, 500.0, 409.0]  episode_count: 17971 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8280 7 visits [500.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 500.0, 409.0]  episode_count: 17971 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17975, "number_of_timesteps": 377686, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8281 9 visits [500.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 17975 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8282 1 visits [500.0, 411.0, 410.0, 410.0, 410.0, 410.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 17977 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8283 2 visits [500.0, 411.0, 411.0, 410.0, 410.0, 410.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 17980 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8284 3 visits [500.0, 411.0, 411.0, 411.0, 410.0, 410.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 17982 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17985, "number_of_timesteps": 377890, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8285 4 visits [500.0, 411.0, 411.0, 411.0, 411.0, 410.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 17985 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8286 5 visits [500.0, 411.0, 411.0, 411.0, 411.0, 411.0, 410.0, 410.0, 500.0, 410.0]  episode_count: 17987 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8287 6 visits [500.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 410.0, 500.0, 410.0]  episode_count: 17990 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8288 7 visits [500.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 500.0, 410.0]  episode_count: 17993 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 17995, "number_of_timesteps": 378070, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8289 9 visits [500.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 17995 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8290 1 visits [500.0, 412.0, 411.0, 411.0, 411.0, 411.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 17998 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8291 2 visits [500.0, 412.0, 412.0, 411.0, 411.0, 411.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 17999 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8292 3 visits [500.0, 412.0, 412.0, 412.0, 411.0, 411.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 18001 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8293 4 visits [500.0, 412.0, 412.0, 412.0, 412.0, 411.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 18004 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18006, "number_of_timesteps": 378284, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8294 5 visits [500.0, 412.0, 412.0, 412.0, 412.0, 412.0, 411.0, 411.0, 500.0, 411.0]  episode_count: 18006 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8295 6 visits [500.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 411.0, 500.0, 411.0]  episode_count: 18007 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8296 7 visits [500.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 500.0, 411.0]  episode_count: 18007 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8297 9 visits [500.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 18012 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8298 1 visits [500.0, 413.0, 412.0, 412.0, 412.0, 412.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 18015 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18016, "number_of_timesteps": 378511, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8299 2 visits [500.0, 413.0, 413.0, 412.0, 412.0, 412.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 18016 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8300 3 visits [500.0, 413.0, 413.0, 413.0, 412.0, 412.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 18018 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8301 4 visits [500.0, 413.0, 413.0, 413.0, 413.0, 412.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 18018 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8302 5 visits [500.0, 413.0, 413.0, 413.0, 413.0, 413.0, 412.0, 412.0, 500.0, 412.0]  episode_count: 18022 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8303 6 visits [500.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 412.0, 500.0, 412.0]  episode_count: 18023 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8304 7 visits [500.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 500.0, 412.0]  episode_count: 18025 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18027, "number_of_timesteps": 378716, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8305 9 visits [500.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 18027 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8306 1 visits [500.0, 414.0, 413.0, 413.0, 413.0, 413.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 18031 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8307 2 visits [500.0, 414.0, 414.0, 413.0, 413.0, 413.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 18031 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8308 3 visits [500.0, 414.0, 414.0, 414.0, 413.0, 413.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 18032 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8309 4 visits [500.0, 414.0, 414.0, 414.0, 414.0, 413.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 18034 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18038, "number_of_timesteps": 378974, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8310 5 visits [500.0, 414.0, 414.0, 414.0, 414.0, 414.0, 413.0, 413.0, 500.0, 413.0]  episode_count: 18038 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8311 6 visits [500.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 413.0, 500.0, 413.0]  episode_count: 18039 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8312 7 visits [500.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 500.0, 413.0]  episode_count: 18040 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8313 9 visits [500.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 18043 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8314 1 visits [500.0, 415.0, 414.0, 414.0, 414.0, 414.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 18046 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8315 2 visits [500.0, 415.0, 415.0, 414.0, 414.0, 414.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 18047 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18051, "number_of_timesteps": 379275, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8316 3 visits [500.0, 415.0, 415.0, 415.0, 414.0, 414.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 18051 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8317 4 visits [500.0, 415.0, 415.0, 415.0, 415.0, 414.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 18054 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8318 5 visits [500.0, 415.0, 415.0, 415.0, 415.0, 415.0, 414.0, 414.0, 500.0, 414.0]  episode_count: 18056 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8319 6 visits [500.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 414.0, 500.0, 414.0]  episode_count: 18060 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8320 7 visits [500.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 500.0, 414.0]  episode_count: 18060 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18061, "number_of_timesteps": 379472, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8321 9 visits [500.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 18061 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8322 1 visits [500.0, 416.0, 415.0, 415.0, 415.0, 415.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 18066 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8323 2 visits [500.0, 416.0, 416.0, 415.0, 415.0, 415.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 18067 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8324 3 visits [500.0, 416.0, 416.0, 416.0, 415.0, 415.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 18069 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18073, "number_of_timesteps": 379681, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8325 4 visits [500.0, 416.0, 416.0, 416.0, 416.0, 415.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 18073 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8326 5 visits [500.0, 416.0, 416.0, 416.0, 416.0, 416.0, 415.0, 415.0, 500.0, 415.0]  episode_count: 18074 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8327 6 visits [500.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 415.0, 500.0, 415.0]  episode_count: 18075 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8328 7 visits [500.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 500.0, 415.0]  episode_count: 18078 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8329 9 visits [500.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 18080 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18084, "number_of_timesteps": 379945, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8330 1 visits [500.0, 417.0, 416.0, 416.0, 416.0, 416.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 18084 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8331 2 visits [500.0, 417.0, 417.0, 416.0, 416.0, 416.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 18086 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8332 3 visits [500.0, 417.0, 417.0, 417.0, 416.0, 416.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 18086 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8333 4 visits [500.0, 417.0, 417.0, 417.0, 417.0, 416.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 18087 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8334 5 visits [500.0, 417.0, 417.0, 417.0, 417.0, 417.0, 416.0, 416.0, 500.0, 416.0]  episode_count: 18089 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8335 6 visits [500.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 416.0, 500.0, 416.0]  episode_count: 18093 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18096, "number_of_timesteps": 380233, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8336 7 visits [500.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 500.0, 416.0]  episode_count: 18096 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8337 9 visits [500.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 18097 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8338 1 visits [500.0, 418.0, 417.0, 417.0, 417.0, 417.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 18099 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8339 2 visits [500.0, 418.0, 418.0, 417.0, 417.0, 417.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 18101 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8340 3 visits [500.0, 418.0, 418.0, 418.0, 417.0, 417.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 18105 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18107, "number_of_timesteps": 380416, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8341 4 visits [500.0, 418.0, 418.0, 418.0, 418.0, 417.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 18107 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8342 5 visits [500.0, 418.0, 418.0, 418.0, 418.0, 418.0, 417.0, 417.0, 500.0, 417.0]  episode_count: 18108 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8343 6 visits [500.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 417.0, 500.0, 417.0]  episode_count: 18110 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8344 7 visits [500.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 500.0, 417.0]  episode_count: 18113 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8345 9 visits [500.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 18116 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18117, "number_of_timesteps": 380628, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8346 1 visits [500.0, 419.0, 418.0, 418.0, 418.0, 418.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 18117 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8347 2 visits [500.0, 419.0, 419.0, 418.0, 418.0, 418.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 18117 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8348 3 visits [500.0, 419.0, 419.0, 419.0, 418.0, 418.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 18120 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8349 4 visits [500.0, 419.0, 419.0, 419.0, 419.0, 418.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 18123 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8350 5 visits [500.0, 419.0, 419.0, 419.0, 419.0, 419.0, 418.0, 418.0, 500.0, 418.0]  episode_count: 18126 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18128, "number_of_timesteps": 380885, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8351 6 visits [500.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 418.0, 500.0, 418.0]  episode_count: 18128 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8352 7 visits [500.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 500.0, 418.0]  episode_count: 18129 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8353 9 visits [500.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 18131 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8354 1 visits [500.0, 420.0, 419.0, 419.0, 419.0, 419.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 18132 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8355 2 visits [500.0, 420.0, 420.0, 419.0, 419.0, 419.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 18134 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8356 3 visits [500.0, 420.0, 420.0, 420.0, 419.0, 419.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 18137 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18141, "number_of_timesteps": 381178, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8357 4 visits [500.0, 420.0, 420.0, 420.0, 420.0, 419.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 18141 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8358 5 visits [500.0, 420.0, 420.0, 420.0, 420.0, 420.0, 419.0, 419.0, 500.0, 419.0]  episode_count: 18143 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8359 6 visits [500.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 419.0, 500.0, 419.0]  episode_count: 18144 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8360 7 visits [500.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 500.0, 419.0]  episode_count: 18148 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18152, "number_of_timesteps": 381365, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8361 9 visits [500.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 18152 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8362 1 visits [500.0, 421.0, 420.0, 420.0, 420.0, 420.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 18152 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8363 2 visits [500.0, 421.0, 421.0, 420.0, 420.0, 420.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 18155 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8364 3 visits [500.0, 421.0, 421.0, 421.0, 420.0, 420.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 18157 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8365 4 visits [500.0, 421.0, 421.0, 421.0, 421.0, 420.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 18158 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18162, "number_of_timesteps": 381546, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8366 5 visits [500.0, 421.0, 421.0, 421.0, 421.0, 421.0, 420.0, 420.0, 500.0, 420.0]  episode_count: 18162 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8367 6 visits [500.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 420.0, 500.0, 420.0]  episode_count: 18163 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8368 7 visits [500.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 500.0, 420.0]  episode_count: 18166 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8369 9 visits [500.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 18168 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8370 1 visits [500.0, 422.0, 421.0, 421.0, 421.0, 421.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 18171 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18173, "number_of_timesteps": 381769, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8371 2 visits [500.0, 422.0, 422.0, 421.0, 421.0, 421.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 18173 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8372 3 visits [500.0, 422.0, 422.0, 422.0, 421.0, 421.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 18175 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8373 4 visits [500.0, 422.0, 422.0, 422.0, 422.0, 421.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 18179 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8374 5 visits [500.0, 422.0, 422.0, 422.0, 422.0, 422.0, 421.0, 421.0, 500.0, 421.0]  episode_count: 18180 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8375 6 visits [500.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 421.0, 500.0, 421.0]  episode_count: 18182 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18184, "number_of_timesteps": 381996, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8376 7 visits [500.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 500.0, 421.0]  episode_count: 18184 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8377 9 visits [500.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 18186 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8378 1 visits [500.0, 423.0, 422.0, 422.0, 422.0, 422.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 18187 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8379 2 visits [500.0, 423.0, 423.0, 422.0, 422.0, 422.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 18189 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8380 3 visits [500.0, 423.0, 423.0, 423.0, 422.0, 422.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 18193 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18194, "number_of_timesteps": 382235, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8381 4 visits [500.0, 423.0, 423.0, 423.0, 423.0, 422.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 18194 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8382 5 visits [500.0, 423.0, 423.0, 423.0, 423.0, 423.0, 422.0, 422.0, 500.0, 422.0]  episode_count: 18196 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8383 6 visits [500.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 422.0, 500.0, 422.0]  episode_count: 18200 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8384 7 visits [500.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 500.0, 422.0]  episode_count: 18202 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18204, "number_of_timesteps": 382432, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8385 9 visits [500.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 18204 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8386 1 visits [500.0, 424.0, 423.0, 423.0, 423.0, 423.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 18204 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8387 2 visits [500.0, 424.0, 424.0, 423.0, 423.0, 423.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 18206 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8388 3 visits [500.0, 424.0, 424.0, 424.0, 423.0, 423.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 18208 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8389 4 visits [500.0, 424.0, 424.0, 424.0, 424.0, 423.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 18210 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8390 5 visits [500.0, 424.0, 424.0, 424.0, 424.0, 424.0, 423.0, 423.0, 500.0, 423.0]  episode_count: 18210 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8391 6 visits [500.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 423.0, 500.0, 423.0]  episode_count: 18213 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18216, "number_of_timesteps": 382725, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8392 7 visits [500.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 500.0, 423.0]  episode_count: 18216 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8393 9 visits [500.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 18216 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8394 1 visits [500.0, 425.0, 424.0, 424.0, 424.0, 424.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 18218 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8395 2 visits [500.0, 425.0, 425.0, 424.0, 424.0, 424.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 18221 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8396 3 visits [500.0, 425.0, 425.0, 425.0, 424.0, 424.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 18224 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8397 4 visits [500.0, 425.0, 425.0, 425.0, 425.0, 424.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 18225 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18228, "number_of_timesteps": 383031, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8398 5 visits [500.0, 425.0, 425.0, 425.0, 425.0, 425.0, 424.0, 424.0, 500.0, 424.0]  episode_count: 18228 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8399 6 visits [500.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 424.0, 500.0, 424.0]  episode_count: 18230 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8400 7 visits [500.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 500.0, 424.0]  episode_count: 18234 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8401 9 visits [500.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 18234 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8402 1 visits [500.0, 426.0, 425.0, 425.0, 425.0, 425.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 18237 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18238, "number_of_timesteps": 383202, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8403 2 visits [500.0, 426.0, 426.0, 425.0, 425.0, 425.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 18238 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8404 3 visits [500.0, 426.0, 426.0, 426.0, 425.0, 425.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 18239 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8405 4 visits [500.0, 426.0, 426.0, 426.0, 426.0, 425.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 18242 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8406 5 visits [500.0, 426.0, 426.0, 426.0, 426.0, 426.0, 425.0, 425.0, 500.0, 425.0]  episode_count: 18245 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8407 6 visits [500.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 425.0, 500.0, 425.0]  episode_count: 18245 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18249, "number_of_timesteps": 383452, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8408 7 visits [500.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 500.0, 425.0]  episode_count: 18249 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8409 9 visits [500.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 18253 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8410 1 visits [500.0, 427.0, 426.0, 426.0, 426.0, 426.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 18254 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8411 2 visits [500.0, 427.0, 427.0, 426.0, 426.0, 426.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 18254 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8412 3 visits [500.0, 427.0, 427.0, 427.0, 426.0, 426.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 18258 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18259, "number_of_timesteps": 383627, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8413 4 visits [500.0, 427.0, 427.0, 427.0, 427.0, 426.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 18259 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8414 5 visits [500.0, 427.0, 427.0, 427.0, 427.0, 427.0, 426.0, 426.0, 500.0, 426.0]  episode_count: 18260 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8415 6 visits [500.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 426.0, 500.0, 426.0]  episode_count: 18261 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8416 7 visits [500.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 500.0, 426.0]  episode_count: 18265 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8417 9 visits [500.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 18266 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18269, "number_of_timesteps": 383888, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8418 1 visits [500.0, 428.0, 427.0, 427.0, 427.0, 427.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 18269 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8419 2 visits [500.0, 428.0, 428.0, 427.0, 427.0, 427.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 18271 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8420 3 visits [500.0, 428.0, 428.0, 428.0, 427.0, 427.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 18275 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18279, "number_of_timesteps": 384119, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8421 4 visits [500.0, 428.0, 428.0, 428.0, 428.0, 427.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 18279 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8422 5 visits [500.0, 428.0, 428.0, 428.0, 428.0, 428.0, 427.0, 427.0, 500.0, 427.0]  episode_count: 18279 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8423 6 visits [500.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 427.0, 500.0, 427.0]  episode_count: 18280 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8424 7 visits [500.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 500.0, 427.0]  episode_count: 18282 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8425 9 visits [500.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 18284 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8426 1 visits [500.0, 429.0, 428.0, 428.0, 428.0, 428.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 18286 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8427 2 visits [500.0, 429.0, 429.0, 428.0, 428.0, 428.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 18288 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18291, "number_of_timesteps": 384400, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8428 3 visits [500.0, 429.0, 429.0, 429.0, 428.0, 428.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 18291 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8429 4 visits [500.0, 429.0, 429.0, 429.0, 429.0, 428.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 18291 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8430 5 visits [500.0, 429.0, 429.0, 429.0, 429.0, 429.0, 428.0, 428.0, 500.0, 428.0]  episode_count: 18292 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8431 6 visits [500.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 428.0, 500.0, 428.0]  episode_count: 18293 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8432 7 visits [500.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 500.0, 428.0]  episode_count: 18297 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8433 9 visits [500.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 18300 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18301, "number_of_timesteps": 384638, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8434 1 visits [500.0, 430.0, 429.0, 429.0, 429.0, 429.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 18301 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8435 2 visits [500.0, 430.0, 430.0, 429.0, 429.0, 429.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 18302 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8436 3 visits [500.0, 430.0, 430.0, 430.0, 429.0, 429.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 18305 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8437 4 visits [500.0, 430.0, 430.0, 430.0, 430.0, 429.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 18309 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18311, "number_of_timesteps": 384876, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8438 5 visits [500.0, 430.0, 430.0, 430.0, 430.0, 430.0, 429.0, 429.0, 500.0, 429.0]  episode_count: 18311 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8439 6 visits [500.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 429.0, 500.0, 429.0]  episode_count: 18315 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8440 7 visits [500.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 500.0, 429.0]  episode_count: 18316 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8441 9 visits [500.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 18319 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18322, "number_of_timesteps": 385058, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8442 1 visits [500.0, 431.0, 430.0, 430.0, 430.0, 430.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 18322 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8443 2 visits [500.0, 431.0, 431.0, 430.0, 430.0, 430.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 18323 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8444 3 visits [500.0, 431.0, 431.0, 431.0, 430.0, 430.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 18325 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8445 4 visits [500.0, 431.0, 431.0, 431.0, 431.0, 430.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 18326 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8446 5 visits [500.0, 431.0, 431.0, 431.0, 431.0, 431.0, 430.0, 430.0, 500.0, 430.0]  episode_count: 18327 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8447 6 visits [500.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 430.0, 500.0, 430.0]  episode_count: 18330 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18333, "number_of_timesteps": 385304, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8448 7 visits [500.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 500.0, 430.0]  episode_count: 18333 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8449 9 visits [500.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 18335 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8450 1 visits [500.0, 432.0, 431.0, 431.0, 431.0, 431.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 18338 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8451 2 visits [500.0, 432.0, 432.0, 431.0, 431.0, 431.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 18339 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8452 3 visits [500.0, 432.0, 432.0, 432.0, 431.0, 431.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 18341 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18343, "number_of_timesteps": 385475, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8453 4 visits [500.0, 432.0, 432.0, 432.0, 432.0, 431.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 18343 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8454 5 visits [500.0, 432.0, 432.0, 432.0, 432.0, 432.0, 431.0, 431.0, 500.0, 431.0]  episode_count: 18345 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8455 6 visits [500.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 431.0, 500.0, 431.0]  episode_count: 18348 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8456 7 visits [500.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 500.0, 431.0]  episode_count: 18351 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8457 9 visits [500.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 18352 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18354, "number_of_timesteps": 385757, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8458 1 visits [500.0, 433.0, 432.0, 432.0, 432.0, 432.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 18354 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8459 2 visits [500.0, 433.0, 433.0, 432.0, 432.0, 432.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 18357 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8460 3 visits [500.0, 433.0, 433.0, 433.0, 432.0, 432.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 18359 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8461 4 visits [500.0, 433.0, 433.0, 433.0, 433.0, 432.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 18362 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18365, "number_of_timesteps": 385934, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8462 5 visits [500.0, 433.0, 433.0, 433.0, 433.0, 433.0, 432.0, 432.0, 500.0, 432.0]  episode_count: 18365 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8463 6 visits [500.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 432.0, 500.0, 432.0]  episode_count: 18366 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8464 7 visits [500.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 500.0, 432.0]  episode_count: 18371 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8465 9 visits [500.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 18372 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8466 1 visits [500.0, 434.0, 433.0, 433.0, 433.0, 433.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 18374 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18375, "number_of_timesteps": 386110, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8467 2 visits [500.0, 434.0, 434.0, 433.0, 433.0, 433.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 18375 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8468 3 visits [500.0, 434.0, 434.0, 434.0, 433.0, 433.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 18381 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8469 4 visits [500.0, 434.0, 434.0, 434.0, 434.0, 433.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 18384 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8470 5 visits [500.0, 434.0, 434.0, 434.0, 434.0, 434.0, 433.0, 433.0, 500.0, 433.0]  episode_count: 18384 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18386, "number_of_timesteps": 386332, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8471 6 visits [500.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 433.0, 500.0, 433.0]  episode_count: 18386 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8472 7 visits [500.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 500.0, 433.0]  episode_count: 18388 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8473 9 visits [500.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 18390 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8474 1 visits [500.0, 435.0, 434.0, 434.0, 434.0, 434.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 18393 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8475 2 visits [500.0, 435.0, 435.0, 434.0, 434.0, 434.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 18395 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18397, "number_of_timesteps": 386543, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8476 3 visits [500.0, 435.0, 435.0, 435.0, 434.0, 434.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 18397 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8477 4 visits [500.0, 435.0, 435.0, 435.0, 435.0, 434.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 18399 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8478 5 visits [500.0, 435.0, 435.0, 435.0, 435.0, 435.0, 434.0, 434.0, 500.0, 434.0]  episode_count: 18402 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8479 6 visits [500.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 434.0, 500.0, 434.0]  episode_count: 18404 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8480 7 visits [500.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 500.0, 434.0]  episode_count: 18406 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18407, "number_of_timesteps": 386773, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8481 9 visits [500.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 18407 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8482 1 visits [500.0, 436.0, 435.0, 435.0, 435.0, 435.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 18409 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8483 2 visits [500.0, 436.0, 436.0, 435.0, 435.0, 435.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 18412 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8484 3 visits [500.0, 436.0, 436.0, 436.0, 435.0, 435.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 18413 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8485 4 visits [500.0, 436.0, 436.0, 436.0, 436.0, 435.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 18416 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18418, "number_of_timesteps": 387036, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8486 5 visits [500.0, 436.0, 436.0, 436.0, 436.0, 436.0, 435.0, 435.0, 500.0, 435.0]  episode_count: 18418 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8487 6 visits [500.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 435.0, 500.0, 435.0]  episode_count: 18420 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8488 7 visits [500.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 500.0, 435.0]  episode_count: 18421 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8489 9 visits [500.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 18426 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8490 1 visits [500.0, 437.0, 436.0, 436.0, 436.0, 436.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 18426 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18429, "number_of_timesteps": 387273, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8491 2 visits [500.0, 437.0, 437.0, 436.0, 436.0, 436.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 18429 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8492 3 visits [500.0, 437.0, 437.0, 437.0, 436.0, 436.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 18431 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8493 4 visits [500.0, 437.0, 437.0, 437.0, 437.0, 436.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 18432 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8494 5 visits [500.0, 437.0, 437.0, 437.0, 437.0, 437.0, 436.0, 436.0, 500.0, 436.0]  episode_count: 18435 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8495 6 visits [500.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 436.0, 500.0, 436.0]  episode_count: 18437 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18442, "number_of_timesteps": 387537, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8496 7 visits [500.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 500.0, 436.0]  episode_count: 18442 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8497 9 visits [500.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 18443 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8498 1 visits [500.0, 438.0, 437.0, 437.0, 437.0, 437.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 18446 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8499 2 visits [500.0, 438.0, 438.0, 437.0, 437.0, 437.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 18449 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18452, "number_of_timesteps": 387716, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8500 3 visits [500.0, 438.0, 438.0, 438.0, 437.0, 437.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 18452 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8501 4 visits [500.0, 438.0, 438.0, 438.0, 438.0, 437.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 18453 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8502 5 visits [500.0, 438.0, 438.0, 438.0, 438.0, 438.0, 437.0, 437.0, 500.0, 437.0]  episode_count: 18453 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8503 6 visits [500.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 437.0, 500.0, 437.0]  episode_count: 18457 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8504 7 visits [500.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 500.0, 437.0]  episode_count: 18459 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8505 9 visits [500.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 18461 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18463, "number_of_timesteps": 387913, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8506 1 visits [500.0, 439.0, 438.0, 438.0, 438.0, 438.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 18463 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8507 2 visits [500.0, 439.0, 439.0, 438.0, 438.0, 438.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 18465 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8508 3 visits [500.0, 439.0, 439.0, 439.0, 438.0, 438.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 18468 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8509 4 visits [500.0, 439.0, 439.0, 439.0, 439.0, 438.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 18471 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8510 5 visits [500.0, 439.0, 439.0, 439.0, 439.0, 439.0, 438.0, 438.0, 500.0, 438.0]  episode_count: 18472 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18474, "number_of_timesteps": 388173, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8511 6 visits [500.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 438.0, 500.0, 438.0]  episode_count: 18474 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8512 7 visits [500.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 500.0, 438.0]  episode_count: 18475 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8513 9 visits [500.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 18479 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8514 1 visits [500.0, 440.0, 439.0, 439.0, 439.0, 439.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 18481 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18485, "number_of_timesteps": 388383, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8515 2 visits [500.0, 440.0, 440.0, 439.0, 439.0, 439.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 18485 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8516 3 visits [500.0, 440.0, 440.0, 440.0, 439.0, 439.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 18487 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8517 4 visits [500.0, 440.0, 440.0, 440.0, 440.0, 439.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 18487 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8518 5 visits [500.0, 440.0, 440.0, 440.0, 440.0, 440.0, 439.0, 439.0, 500.0, 439.0]  episode_count: 18490 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8519 6 visits [500.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 439.0, 500.0, 439.0]  episode_count: 18492 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18495, "number_of_timesteps": 388592, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8520 7 visits [500.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 500.0, 439.0]  episode_count: 18495 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8521 9 visits [500.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 18496 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8522 1 visits [500.0, 441.0, 440.0, 440.0, 440.0, 440.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 18498 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8523 2 visits [500.0, 441.0, 441.0, 440.0, 440.0, 440.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 18499 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8524 3 visits [500.0, 441.0, 441.0, 441.0, 440.0, 440.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 18503 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18505, "number_of_timesteps": 388820, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8525 4 visits [500.0, 441.0, 441.0, 441.0, 441.0, 440.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 18505 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8526 5 visits [500.0, 441.0, 441.0, 441.0, 441.0, 441.0, 440.0, 440.0, 500.0, 440.0]  episode_count: 18507 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8527 6 visits [500.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 440.0, 500.0, 440.0]  episode_count: 18509 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8528 7 visits [500.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 500.0, 440.0]  episode_count: 18509 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8529 9 visits [500.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 18514 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18517, "number_of_timesteps": 389067, "per_episode_reward": 14.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 8530 1 visits [500.0, 442.0, 441.0, 441.0, 441.0, 441.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 18517 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8531 2 visits [500.0, 442.0, 442.0, 441.0, 441.0, 441.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 18519 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8532 3 visits [500.0, 442.0, 442.0, 442.0, 441.0, 441.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 18521 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8533 4 visits [500.0, 442.0, 442.0, 442.0, 442.0, 441.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 18523 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8534 5 visits [500.0, 442.0, 442.0, 442.0, 442.0, 442.0, 441.0, 441.0, 500.0, 441.0]  episode_count: 18525 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18527, "number_of_timesteps": 389262, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 8535 6 visits [500.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 441.0, 500.0, 441.0]  episode_count: 18527 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8536 7 visits [500.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 500.0, 441.0]  episode_count: 18528 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8537 9 visits [500.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 18529 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8538 1 visits [500.0, 443.0, 442.0, 442.0, 442.0, 442.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 18531 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8539 2 visits [500.0, 443.0, 443.0, 442.0, 442.0, 442.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 18536 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18537, "number_of_timesteps": 389508, "per_episode_reward": 14.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 8540 3 visits [500.0, 443.0, 443.0, 443.0, 442.0, 442.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 18537 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8541 4 visits [500.0, 443.0, 443.0, 443.0, 443.0, 442.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 18538 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8542 5 visits [500.0, 443.0, 443.0, 443.0, 443.0, 443.0, 442.0, 442.0, 500.0, 442.0]  episode_count: 18542 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8543 6 visits [500.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 442.0, 500.0, 442.0]  episode_count: 18543 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8544 7 visits [500.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 500.0, 442.0]  episode_count: 18544 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18547, "number_of_timesteps": 389710, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8545 9 visits [500.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 18547 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8546 1 visits [500.0, 444.0, 443.0, 443.0, 443.0, 443.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 18547 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8547 2 visits [500.0, 444.0, 444.0, 443.0, 443.0, 443.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 18551 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8548 3 visits [500.0, 444.0, 444.0, 444.0, 443.0, 443.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 18552 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8549 4 visits [500.0, 444.0, 444.0, 444.0, 444.0, 443.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 18553 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18558, "number_of_timesteps": 389936, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8550 5 visits [500.0, 444.0, 444.0, 444.0, 444.0, 444.0, 443.0, 443.0, 500.0, 443.0]  episode_count: 18558 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8551 6 visits [500.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 443.0, 500.0, 443.0]  episode_count: 18559 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8552 7 visits [500.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 500.0, 443.0]  episode_count: 18561 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8553 9 visits [500.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 18563 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8554 1 visits [500.0, 445.0, 444.0, 444.0, 444.0, 444.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 18565 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8555 2 visits [500.0, 445.0, 445.0, 444.0, 444.0, 444.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 18567 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18570, "number_of_timesteps": 390221, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8556 3 visits [500.0, 445.0, 445.0, 445.0, 444.0, 444.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 18570 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8557 4 visits [500.0, 445.0, 445.0, 445.0, 445.0, 444.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 18571 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8558 5 visits [500.0, 445.0, 445.0, 445.0, 445.0, 445.0, 444.0, 444.0, 500.0, 444.0]  episode_count: 18572 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8559 6 visits [500.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 444.0, 500.0, 444.0]  episode_count: 18577 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8560 7 visits [500.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 500.0, 444.0]  episode_count: 18579 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18581, "number_of_timesteps": 390465, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8561 9 visits [500.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 18581 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8562 1 visits [500.0, 446.0, 445.0, 445.0, 445.0, 445.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 18584 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8563 2 visits [500.0, 446.0, 446.0, 445.0, 445.0, 445.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 18585 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8564 3 visits [500.0, 446.0, 446.0, 446.0, 445.0, 445.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 18589 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18591, "number_of_timesteps": 390637, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8565 4 visits [500.0, 446.0, 446.0, 446.0, 446.0, 445.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 18591 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8566 5 visits [500.0, 446.0, 446.0, 446.0, 446.0, 446.0, 445.0, 445.0, 500.0, 445.0]  episode_count: 18593 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8567 6 visits [500.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 445.0, 500.0, 445.0]  episode_count: 18594 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8568 7 visits [500.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 500.0, 445.0]  episode_count: 18598 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18602, "number_of_timesteps": 390845, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8569 9 visits [500.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 18602 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8570 1 visits [500.0, 447.0, 446.0, 446.0, 446.0, 446.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 18604 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8571 2 visits [500.0, 447.0, 447.0, 446.0, 446.0, 446.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 18607 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8572 3 visits [500.0, 447.0, 447.0, 447.0, 446.0, 446.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 18609 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18612, "number_of_timesteps": 390995, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 8573 4 visits [500.0, 447.0, 447.0, 447.0, 447.0, 446.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 18612 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8574 5 visits [500.0, 447.0, 447.0, 447.0, 447.0, 447.0, 446.0, 446.0, 500.0, 446.0]  episode_count: 18613 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8575 6 visits [500.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 446.0, 500.0, 446.0]  episode_count: 18617 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8576 7 visits [500.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 500.0, 446.0]  episode_count: 18618 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8577 9 visits [500.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 18620 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8578 1 visits [500.0, 448.0, 447.0, 447.0, 447.0, 447.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 18621 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18623, "number_of_timesteps": 391212, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8579 2 visits [500.0, 448.0, 448.0, 447.0, 447.0, 447.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 18623 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8580 3 visits [500.0, 448.0, 448.0, 448.0, 447.0, 447.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 18624 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8581 4 visits [500.0, 448.0, 448.0, 448.0, 448.0, 447.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 18628 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8582 5 visits [500.0, 448.0, 448.0, 448.0, 448.0, 448.0, 447.0, 447.0, 500.0, 447.0]  episode_count: 18632 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8583 6 visits [500.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 447.0, 500.0, 447.0]  episode_count: 18632 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18636, "number_of_timesteps": 391480, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 8584 7 visits [500.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 500.0, 447.0]  episode_count: 18636 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8585 9 visits [500.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 18637 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8586 1 visits [500.0, 449.0, 448.0, 448.0, 448.0, 448.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 18638 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8587 2 visits [500.0, 449.0, 449.0, 448.0, 448.0, 448.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 18641 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8588 3 visits [500.0, 449.0, 449.0, 449.0, 448.0, 448.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 18643 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8589 4 visits [500.0, 449.0, 449.0, 449.0, 449.0, 448.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 18644 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18646, "number_of_timesteps": 391677, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8590 5 visits [500.0, 449.0, 449.0, 449.0, 449.0, 449.0, 448.0, 448.0, 500.0, 448.0]  episode_count: 18646 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8591 6 visits [500.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 448.0, 500.0, 448.0]  episode_count: 18649 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8592 7 visits [500.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 500.0, 448.0]  episode_count: 18650 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8593 9 visits [500.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 18651 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18656, "number_of_timesteps": 391894, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8594 1 visits [500.0, 450.0, 449.0, 449.0, 449.0, 449.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 18656 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8595 2 visits [500.0, 450.0, 450.0, 449.0, 449.0, 449.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 18658 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8596 3 visits [500.0, 450.0, 450.0, 450.0, 449.0, 449.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 18659 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8597 4 visits [500.0, 450.0, 450.0, 450.0, 450.0, 449.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 18662 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8598 5 visits [500.0, 450.0, 450.0, 450.0, 450.0, 450.0, 449.0, 449.0, 500.0, 449.0]  episode_count: 18663 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8599 6 visits [500.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 449.0, 500.0, 449.0]  episode_count: 18665 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18667, "number_of_timesteps": 392170, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8600 7 visits [500.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 500.0, 449.0]  episode_count: 18667 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8601 9 visits [500.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 18669 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8602 1 visits [500.0, 451.0, 450.0, 450.0, 450.0, 450.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 18671 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8603 2 visits [500.0, 451.0, 451.0, 450.0, 450.0, 450.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 18671 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8604 3 visits [500.0, 451.0, 451.0, 451.0, 450.0, 450.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 18674 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8605 4 visits [500.0, 451.0, 451.0, 451.0, 451.0, 450.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 18676 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18679, "number_of_timesteps": 392473, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8606 5 visits [500.0, 451.0, 451.0, 451.0, 451.0, 451.0, 450.0, 450.0, 500.0, 450.0]  episode_count: 18679 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8607 6 visits [500.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 450.0, 500.0, 450.0]  episode_count: 18679 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8608 7 visits [500.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 500.0, 450.0]  episode_count: 18683 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8609 9 visits [500.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 18685 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8610 1 visits [500.0, 452.0, 451.0, 451.0, 451.0, 451.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 18686 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18689, "number_of_timesteps": 392691, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 8611 2 visits [500.0, 452.0, 452.0, 451.0, 451.0, 451.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 18689 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8612 3 visits [500.0, 452.0, 452.0, 452.0, 451.0, 451.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 18691 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8613 4 visits [500.0, 452.0, 452.0, 452.0, 452.0, 451.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 18693 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8614 5 visits [500.0, 452.0, 452.0, 452.0, 452.0, 452.0, 451.0, 451.0, 500.0, 451.0]  episode_count: 18694 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8615 6 visits [500.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 451.0, 500.0, 451.0]  episode_count: 18696 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18699, "number_of_timesteps": 392917, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8616 7 visits [500.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 500.0, 451.0]  episode_count: 18699 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8617 9 visits [500.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 18701 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8618 1 visits [500.0, 453.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 18703 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8619 2 visits [500.0, 453.0, 453.0, 452.0, 452.0, 452.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 18707 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18709, "number_of_timesteps": 393114, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8620 3 visits [500.0, 453.0, 453.0, 453.0, 452.0, 452.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 18709 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8621 4 visits [500.0, 453.0, 453.0, 453.0, 453.0, 452.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 18710 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8622 5 visits [500.0, 453.0, 453.0, 453.0, 453.0, 453.0, 452.0, 452.0, 500.0, 452.0]  episode_count: 18711 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8623 6 visits [500.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 452.0, 500.0, 452.0]  episode_count: 18716 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18719, "number_of_timesteps": 393333, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8624 7 visits [500.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 500.0, 452.0]  episode_count: 18719 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8625 9 visits [500.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 18719 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8626 1 visits [500.0, 454.0, 453.0, 453.0, 453.0, 453.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 18722 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8627 2 visits [500.0, 454.0, 454.0, 453.0, 453.0, 453.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 18724 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8628 3 visits [500.0, 454.0, 454.0, 454.0, 453.0, 453.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 18726 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18729, "number_of_timesteps": 393531, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8629 4 visits [500.0, 454.0, 454.0, 454.0, 454.0, 453.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 18729 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8630 5 visits [500.0, 454.0, 454.0, 454.0, 454.0, 454.0, 453.0, 453.0, 500.0, 453.0]  episode_count: 18731 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8631 6 visits [500.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 453.0, 500.0, 453.0]  episode_count: 18734 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8632 7 visits [500.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 500.0, 453.0]  episode_count: 18737 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18740, "number_of_timesteps": 393742, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8633 9 visits [500.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 18740 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8634 1 visits [500.0, 455.0, 454.0, 454.0, 454.0, 454.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 18743 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8635 2 visits [500.0, 455.0, 455.0, 454.0, 454.0, 454.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 18743 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8636 3 visits [500.0, 455.0, 455.0, 455.0, 454.0, 454.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 18747 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8637 4 visits [500.0, 455.0, 455.0, 455.0, 455.0, 454.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 18749 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18750, "number_of_timesteps": 393931, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8638 5 visits [500.0, 455.0, 455.0, 455.0, 455.0, 455.0, 454.0, 454.0, 500.0, 454.0]  episode_count: 18750 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8639 6 visits [500.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 454.0, 500.0, 454.0]  episode_count: 18752 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8640 7 visits [500.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 500.0, 454.0]  episode_count: 18755 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8641 9 visits [500.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 18756 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8642 1 visits [500.0, 456.0, 455.0, 455.0, 455.0, 455.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 18759 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8643 2 visits [500.0, 456.0, 456.0, 455.0, 455.0, 455.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 18759 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18760, "number_of_timesteps": 394135, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8644 3 visits [500.0, 456.0, 456.0, 456.0, 455.0, 455.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 18760 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8645 4 visits [500.0, 456.0, 456.0, 456.0, 456.0, 455.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 18765 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8646 5 visits [500.0, 456.0, 456.0, 456.0, 456.0, 456.0, 455.0, 455.0, 500.0, 455.0]  episode_count: 18765 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8647 6 visits [500.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 455.0, 500.0, 455.0]  episode_count: 18767 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18771, "number_of_timesteps": 394402, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8648 7 visits [500.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 500.0, 455.0]  episode_count: 18771 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8649 9 visits [500.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 18774 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8650 1 visits [500.0, 457.0, 456.0, 456.0, 456.0, 456.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 18775 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8651 2 visits [500.0, 457.0, 457.0, 456.0, 456.0, 456.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 18777 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8652 3 visits [500.0, 457.0, 457.0, 457.0, 456.0, 456.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 18779 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18781, "number_of_timesteps": 394603, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 8653 4 visits [500.0, 457.0, 457.0, 457.0, 457.0, 456.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 18781 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8654 5 visits [500.0, 457.0, 457.0, 457.0, 457.0, 457.0, 456.0, 456.0, 500.0, 456.0]  episode_count: 18784 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8655 6 visits [500.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 456.0, 500.0, 456.0]  episode_count: 18786 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8656 7 visits [500.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 500.0, 456.0]  episode_count: 18790 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18791, "number_of_timesteps": 394796, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8657 9 visits [500.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 18791 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8658 1 visits [500.0, 458.0, 457.0, 457.0, 457.0, 457.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 18792 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8659 2 visits [500.0, 458.0, 458.0, 457.0, 457.0, 457.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 18798 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8660 3 visits [500.0, 458.0, 458.0, 458.0, 457.0, 457.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 18798 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18803, "number_of_timesteps": 394975, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8661 4 visits [500.0, 458.0, 458.0, 458.0, 458.0, 457.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 18803 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8662 5 visits [500.0, 458.0, 458.0, 458.0, 458.0, 458.0, 457.0, 457.0, 500.0, 457.0]  episode_count: 18805 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8663 6 visits [500.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 457.0, 500.0, 457.0]  episode_count: 18808 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8664 7 visits [500.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 500.0, 457.0]  episode_count: 18811 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8665 9 visits [500.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 18812 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18813, "number_of_timesteps": 395193, "per_episode_reward": 14.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 8666 1 visits [500.0, 459.0, 458.0, 458.0, 458.0, 458.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 18813 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8667 2 visits [500.0, 459.0, 459.0, 458.0, 458.0, 458.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 18818 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8668 3 visits [500.0, 459.0, 459.0, 459.0, 458.0, 458.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 18819 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8669 4 visits [500.0, 459.0, 459.0, 459.0, 459.0, 458.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 18822 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18824, "number_of_timesteps": 395409, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8670 5 visits [500.0, 459.0, 459.0, 459.0, 459.0, 459.0, 458.0, 458.0, 500.0, 458.0]  episode_count: 18824 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8671 6 visits [500.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 458.0, 500.0, 458.0]  episode_count: 18825 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8672 7 visits [500.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 500.0, 458.0]  episode_count: 18827 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8673 9 visits [500.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 18832 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8674 1 visits [500.0, 460.0, 459.0, 459.0, 459.0, 459.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 18833 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18837, "number_of_timesteps": 395650, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8675 2 visits [500.0, 460.0, 460.0, 459.0, 459.0, 459.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 18837 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8676 3 visits [500.0, 460.0, 460.0, 460.0, 459.0, 459.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 18838 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8677 4 visits [500.0, 460.0, 460.0, 460.0, 460.0, 459.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 18841 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8678 5 visits [500.0, 460.0, 460.0, 460.0, 460.0, 460.0, 459.0, 459.0, 500.0, 459.0]  episode_count: 18845 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8679 6 visits [500.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 459.0, 500.0, 459.0]  episode_count: 18846 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18849, "number_of_timesteps": 395881, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8680 7 visits [500.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 500.0, 459.0]  episode_count: 18849 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8681 9 visits [500.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 18850 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8682 1 visits [500.0, 461.0, 460.0, 460.0, 460.0, 460.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 18853 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8683 2 visits [500.0, 461.0, 461.0, 460.0, 460.0, 460.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 18856 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8684 3 visits [500.0, 461.0, 461.0, 461.0, 460.0, 460.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 18857 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18859, "number_of_timesteps": 396075, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8685 4 visits [500.0, 461.0, 461.0, 461.0, 461.0, 460.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 18859 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8686 5 visits [500.0, 461.0, 461.0, 461.0, 461.0, 461.0, 460.0, 460.0, 500.0, 460.0]  episode_count: 18862 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8687 6 visits [500.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 460.0, 500.0, 460.0]  episode_count: 18865 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8688 7 visits [500.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 500.0, 460.0]  episode_count: 18867 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8689 9 visits [500.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 18868 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18870, "number_of_timesteps": 396291, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8690 1 visits [500.0, 462.0, 461.0, 461.0, 461.0, 461.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 18870 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8691 2 visits [500.0, 462.0, 462.0, 461.0, 461.0, 461.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 18874 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8692 3 visits [500.0, 462.0, 462.0, 462.0, 461.0, 461.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 18877 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8693 4 visits [500.0, 462.0, 462.0, 462.0, 462.0, 461.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 18879 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18882, "number_of_timesteps": 396501, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8694 5 visits [500.0, 462.0, 462.0, 462.0, 462.0, 462.0, 461.0, 461.0, 500.0, 461.0]  episode_count: 18882 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8695 6 visits [500.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 461.0, 500.0, 461.0]  episode_count: 18883 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8696 7 visits [500.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 500.0, 461.0]  episode_count: 18888 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8697 9 visits [500.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 18890 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8698 1 visits [500.0, 463.0, 462.0, 462.0, 462.0, 462.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 18891 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18893, "number_of_timesteps": 396699, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8699 2 visits [500.0, 463.0, 463.0, 462.0, 462.0, 462.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 18893 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8700 3 visits [500.0, 463.0, 463.0, 463.0, 462.0, 462.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 18895 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8701 4 visits [500.0, 463.0, 463.0, 463.0, 463.0, 462.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 18898 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8702 5 visits [500.0, 463.0, 463.0, 463.0, 463.0, 463.0, 462.0, 462.0, 500.0, 462.0]  episode_count: 18899 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8703 6 visits [500.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 462.0, 500.0, 462.0]  episode_count: 18902 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8704 7 visits [500.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 500.0, 462.0]  episode_count: 18902 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18907, "number_of_timesteps": 397023, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 8705 9 visits [500.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 18907 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8706 1 visits [500.0, 464.0, 463.0, 463.0, 463.0, 463.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 18910 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8707 2 visits [500.0, 464.0, 464.0, 463.0, 463.0, 463.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 18911 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8708 3 visits [500.0, 464.0, 464.0, 464.0, 463.0, 463.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 18912 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8709 4 visits [500.0, 464.0, 464.0, 464.0, 464.0, 463.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 18914 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18918, "number_of_timesteps": 397211, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 8710 5 visits [500.0, 464.0, 464.0, 464.0, 464.0, 464.0, 463.0, 463.0, 500.0, 463.0]  episode_count: 18918 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8711 6 visits [500.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 463.0, 500.0, 463.0]  episode_count: 18919 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8712 7 visits [500.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 500.0, 463.0]  episode_count: 18921 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8713 9 visits [500.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 18926 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18929, "number_of_timesteps": 397453, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8714 1 visits [500.0, 465.0, 464.0, 464.0, 464.0, 464.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 18929 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8715 2 visits [500.0, 465.0, 465.0, 464.0, 464.0, 464.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 18929 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8716 3 visits [500.0, 465.0, 465.0, 465.0, 464.0, 464.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 18931 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8717 4 visits [500.0, 465.0, 465.0, 465.0, 465.0, 464.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 18934 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8718 5 visits [500.0, 465.0, 465.0, 465.0, 465.0, 465.0, 464.0, 464.0, 500.0, 464.0]  episode_count: 18936 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8719 6 visits [500.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 464.0, 500.0, 464.0]  episode_count: 18938 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8720 7 visits [500.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 500.0, 464.0]  episode_count: 18938 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18942, "number_of_timesteps": 397678, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8721 9 visits [500.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 18942 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8722 1 visits [500.0, 466.0, 465.0, 465.0, 465.0, 465.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 18943 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8723 2 visits [500.0, 466.0, 466.0, 465.0, 465.0, 465.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 18946 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8724 3 visits [500.0, 466.0, 466.0, 466.0, 465.0, 465.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 18949 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8725 4 visits [500.0, 466.0, 466.0, 466.0, 466.0, 465.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 18951 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18953, "number_of_timesteps": 397951, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8726 5 visits [500.0, 466.0, 466.0, 466.0, 466.0, 466.0, 465.0, 465.0, 500.0, 465.0]  episode_count: 18953 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8727 6 visits [500.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 465.0, 500.0, 465.0]  episode_count: 18956 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8728 7 visits [500.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 500.0, 465.0]  episode_count: 18958 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8729 9 visits [500.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 18960 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18963, "number_of_timesteps": 398124, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8730 1 visits [500.0, 467.0, 466.0, 466.0, 466.0, 466.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 18963 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8731 2 visits [500.0, 467.0, 467.0, 466.0, 466.0, 466.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 18965 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8732 3 visits [500.0, 467.0, 467.0, 467.0, 466.0, 466.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 18966 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8733 4 visits [500.0, 467.0, 467.0, 467.0, 467.0, 466.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 18968 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8734 5 visits [500.0, 467.0, 467.0, 467.0, 467.0, 467.0, 466.0, 466.0, 500.0, 466.0]  episode_count: 18970 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8735 6 visits [500.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 466.0, 500.0, 466.0]  episode_count: 18971 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18973, "number_of_timesteps": 398321, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8736 7 visits [500.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 500.0, 466.0]  episode_count: 18973 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8737 9 visits [500.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 18976 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8738 1 visits [500.0, 468.0, 467.0, 467.0, 467.0, 467.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 18977 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8739 2 visits [500.0, 468.0, 468.0, 467.0, 467.0, 467.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 18979 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8740 3 visits [500.0, 468.0, 468.0, 468.0, 467.0, 467.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 18982 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18985, "number_of_timesteps": 398602, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8741 4 visits [500.0, 468.0, 468.0, 468.0, 468.0, 467.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 18985 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8742 5 visits [500.0, 468.0, 468.0, 468.0, 468.0, 468.0, 467.0, 467.0, 500.0, 467.0]  episode_count: 18988 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8743 6 visits [500.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 467.0, 500.0, 467.0]  episode_count: 18988 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8744 7 visits [500.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 500.0, 467.0]  episode_count: 18989 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8745 9 visits [500.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 18992 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8746 1 visits [500.0, 469.0, 468.0, 468.0, 468.0, 468.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 18994 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8747 2 visits [500.0, 469.0, 469.0, 468.0, 468.0, 468.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 18994 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 18996, "number_of_timesteps": 398820, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8748 3 visits [500.0, 469.0, 469.0, 469.0, 468.0, 468.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 18996 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8749 4 visits [500.0, 469.0, 469.0, 469.0, 469.0, 468.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 18997 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8750 5 visits [500.0, 469.0, 469.0, 469.0, 469.0, 469.0, 468.0, 468.0, 500.0, 468.0]  episode_count: 18998 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8751 6 visits [500.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 468.0, 500.0, 468.0]  episode_count: 19001 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8752 7 visits [500.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 500.0, 468.0]  episode_count: 19004 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8753 9 visits [500.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 19005 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19007, "number_of_timesteps": 399228, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8754 1 visits [500.0, 470.0, 469.0, 469.0, 469.0, 469.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 19007 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8755 2 visits [500.0, 470.0, 470.0, 469.0, 469.0, 469.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 19009 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8756 3 visits [500.0, 470.0, 470.0, 470.0, 469.0, 469.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 19011 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8757 4 visits [500.0, 470.0, 470.0, 470.0, 470.0, 469.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 19012 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8758 5 visits [500.0, 470.0, 470.0, 470.0, 470.0, 470.0, 469.0, 469.0, 500.0, 469.0]  episode_count: 19015 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19017, "number_of_timesteps": 399430, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8759 6 visits [500.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 469.0, 500.0, 469.0]  episode_count: 19017 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8760 7 visits [500.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 500.0, 469.0]  episode_count: 19018 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8761 9 visits [500.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 19020 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8762 1 visits [500.0, 471.0, 470.0, 470.0, 470.0, 470.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 19024 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19028, "number_of_timesteps": 399692, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8763 2 visits [500.0, 471.0, 471.0, 470.0, 470.0, 470.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 19028 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8764 3 visits [500.0, 471.0, 471.0, 471.0, 470.0, 470.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 19028 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8765 4 visits [500.0, 471.0, 471.0, 471.0, 471.0, 470.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 19028 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8766 5 visits [500.0, 471.0, 471.0, 471.0, 471.0, 471.0, 470.0, 470.0, 500.0, 470.0]  episode_count: 19032 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8767 6 visits [500.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 470.0, 500.0, 470.0]  episode_count: 19034 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8768 7 visits [500.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 500.0, 470.0]  episode_count: 19037 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19039, "number_of_timesteps": 399919, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8769 9 visits [500.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 19039 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8770 1 visits [500.0, 472.0, 471.0, 471.0, 471.0, 471.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 19041 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8771 2 visits [500.0, 472.0, 472.0, 471.0, 471.0, 471.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 19042 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8772 3 visits [500.0, 472.0, 472.0, 472.0, 471.0, 471.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 19043 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19050, "number_of_timesteps": 400142, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8773 4 visits [500.0, 472.0, 472.0, 472.0, 472.0, 471.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 19050 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8774 5 visits [500.0, 472.0, 472.0, 472.0, 472.0, 472.0, 471.0, 471.0, 500.0, 471.0]  episode_count: 19050 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8775 6 visits [500.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 471.0, 500.0, 471.0]  episode_count: 19053 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8776 7 visits [500.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 500.0, 471.0]  episode_count: 19054 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8777 9 visits [500.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 19057 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8778 1 visits [500.0, 473.0, 472.0, 472.0, 472.0, 472.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 19058 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19060, "number_of_timesteps": 400307, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8779 2 visits [500.0, 473.0, 473.0, 472.0, 472.0, 472.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 19060 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8780 3 visits [500.0, 473.0, 473.0, 473.0, 472.0, 472.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 19063 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8781 4 visits [500.0, 473.0, 473.0, 473.0, 473.0, 472.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 19065 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8782 5 visits [500.0, 473.0, 473.0, 473.0, 473.0, 473.0, 472.0, 472.0, 500.0, 472.0]  episode_count: 19067 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19070, "number_of_timesteps": 400551, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8783 6 visits [500.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 472.0, 500.0, 472.0]  episode_count: 19070 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8784 7 visits [500.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 500.0, 472.0]  episode_count: 19070 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8785 9 visits [500.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 19073 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8786 1 visits [500.0, 474.0, 473.0, 473.0, 473.0, 473.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 19075 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8787 2 visits [500.0, 474.0, 474.0, 473.0, 473.0, 473.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 19076 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19082, "number_of_timesteps": 400812, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8788 3 visits [500.0, 474.0, 474.0, 474.0, 473.0, 473.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 19082 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8789 4 visits [500.0, 474.0, 474.0, 474.0, 474.0, 473.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 19084 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8790 5 visits [500.0, 474.0, 474.0, 474.0, 474.0, 474.0, 473.0, 473.0, 500.0, 473.0]  episode_count: 19086 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8791 6 visits [500.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 473.0, 500.0, 473.0]  episode_count: 19088 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8792 7 visits [500.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 500.0, 473.0]  episode_count: 19091 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8793 9 visits [500.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 19091 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19094, "number_of_timesteps": 401009, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8794 1 visits [500.0, 475.0, 474.0, 474.0, 474.0, 474.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 19094 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8795 2 visits [500.0, 475.0, 475.0, 474.0, 474.0, 474.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 19095 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8796 3 visits [500.0, 475.0, 475.0, 475.0, 474.0, 474.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 19098 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8797 4 visits [500.0, 475.0, 475.0, 475.0, 475.0, 474.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 19101 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8798 5 visits [500.0, 475.0, 475.0, 475.0, 475.0, 475.0, 474.0, 474.0, 500.0, 474.0]  episode_count: 19102 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19104, "number_of_timesteps": 401268, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8799 6 visits [500.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 474.0, 500.0, 474.0]  episode_count: 19104 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8800 7 visits [500.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 500.0, 474.0]  episode_count: 19107 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8801 9 visits [500.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 19109 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8802 1 visits [500.0, 476.0, 475.0, 475.0, 475.0, 475.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 19110 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8803 2 visits [500.0, 476.0, 476.0, 475.0, 475.0, 475.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 19113 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19116, "number_of_timesteps": 401509, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8804 3 visits [500.0, 476.0, 476.0, 476.0, 475.0, 475.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 19116 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8805 4 visits [500.0, 476.0, 476.0, 476.0, 476.0, 475.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 19116 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8806 5 visits [500.0, 476.0, 476.0, 476.0, 476.0, 476.0, 475.0, 475.0, 500.0, 475.0]  episode_count: 19119 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8807 6 visits [500.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 475.0, 500.0, 475.0]  episode_count: 19121 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8808 7 visits [500.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 500.0, 475.0]  episode_count: 19122 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8809 9 visits [500.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 19125 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19128, "number_of_timesteps": 401781, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8810 1 visits [500.0, 477.0, 476.0, 476.0, 476.0, 476.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 19128 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8811 2 visits [500.0, 477.0, 477.0, 476.0, 476.0, 476.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 19129 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8812 3 visits [500.0, 477.0, 477.0, 477.0, 476.0, 476.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 19132 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8813 4 visits [500.0, 477.0, 477.0, 477.0, 477.0, 476.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 19134 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8814 5 visits [500.0, 477.0, 477.0, 477.0, 477.0, 477.0, 476.0, 476.0, 500.0, 476.0]  episode_count: 19136 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19139, "number_of_timesteps": 402030, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8815 6 visits [500.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 476.0, 500.0, 476.0]  episode_count: 19139 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8816 7 visits [500.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 500.0, 476.0]  episode_count: 19142 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8817 9 visits [500.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 19143 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8818 1 visits [500.0, 478.0, 477.0, 477.0, 477.0, 477.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 19146 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8819 2 visits [500.0, 478.0, 478.0, 477.0, 477.0, 477.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 19147 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19150, "number_of_timesteps": 402228, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8820 3 visits [500.0, 478.0, 478.0, 478.0, 477.0, 477.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 19150 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8821 4 visits [500.0, 478.0, 478.0, 478.0, 478.0, 477.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 19153 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8822 5 visits [500.0, 478.0, 478.0, 478.0, 478.0, 478.0, 477.0, 477.0, 500.0, 477.0]  episode_count: 19153 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8823 6 visits [500.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 477.0, 500.0, 477.0]  episode_count: 19154 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8824 7 visits [500.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 500.0, 477.0]  episode_count: 19158 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8825 9 visits [500.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 19159 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19162, "number_of_timesteps": 402533, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8826 1 visits [500.0, 479.0, 478.0, 478.0, 478.0, 478.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 19162 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8827 2 visits [500.0, 479.0, 479.0, 478.0, 478.0, 478.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 19165 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8828 3 visits [500.0, 479.0, 479.0, 479.0, 478.0, 478.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 19167 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8829 4 visits [500.0, 479.0, 479.0, 479.0, 479.0, 478.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 19169 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8830 5 visits [500.0, 479.0, 479.0, 479.0, 479.0, 479.0, 478.0, 478.0, 500.0, 478.0]  episode_count: 19169 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8831 6 visits [500.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 478.0, 500.0, 478.0]  episode_count: 19171 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19173, "number_of_timesteps": 402727, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8832 7 visits [500.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 500.0, 478.0]  episode_count: 19173 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8833 9 visits [500.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 19175 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8834 1 visits [500.0, 480.0, 479.0, 479.0, 479.0, 479.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 19178 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8835 2 visits [500.0, 480.0, 480.0, 479.0, 479.0, 479.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 19179 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8836 3 visits [500.0, 480.0, 480.0, 480.0, 479.0, 479.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 19182 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19185, "number_of_timesteps": 403026, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8837 4 visits [500.0, 480.0, 480.0, 480.0, 480.0, 479.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 19185 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8838 5 visits [500.0, 480.0, 480.0, 480.0, 480.0, 480.0, 479.0, 479.0, 500.0, 479.0]  episode_count: 19185 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8839 6 visits [500.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 479.0, 500.0, 479.0]  episode_count: 19187 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8840 7 visits [500.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 500.0, 479.0]  episode_count: 19190 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8841 9 visits [500.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 19192 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19196, "number_of_timesteps": 403285, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8842 1 visits [500.0, 481.0, 480.0, 480.0, 480.0, 480.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 19196 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8843 2 visits [500.0, 481.0, 481.0, 480.0, 480.0, 480.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 19197 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8844 3 visits [500.0, 481.0, 481.0, 481.0, 480.0, 480.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 19200 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8845 4 visits [500.0, 481.0, 481.0, 481.0, 481.0, 480.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 19201 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8846 5 visits [500.0, 481.0, 481.0, 481.0, 481.0, 481.0, 480.0, 480.0, 500.0, 480.0]  episode_count: 19203 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8847 6 visits [500.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 480.0, 500.0, 480.0]  episode_count: 19205 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19209, "number_of_timesteps": 403542, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8848 7 visits [500.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 500.0, 480.0]  episode_count: 19209 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8849 9 visits [500.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 19211 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8850 1 visits [500.0, 482.0, 481.0, 481.0, 481.0, 481.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 19213 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8851 2 visits [500.0, 482.0, 482.0, 481.0, 481.0, 481.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 19216 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8852 3 visits [500.0, 482.0, 482.0, 482.0, 481.0, 481.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 19218 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19221, "number_of_timesteps": 403774, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8853 4 visits [500.0, 482.0, 482.0, 482.0, 482.0, 481.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 19221 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8854 5 visits [500.0, 482.0, 482.0, 482.0, 482.0, 482.0, 481.0, 481.0, 500.0, 481.0]  episode_count: 19222 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8855 6 visits [500.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 481.0, 500.0, 481.0]  episode_count: 19224 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8856 7 visits [500.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 500.0, 481.0]  episode_count: 19228 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8857 9 visits [500.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 19230 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19232, "number_of_timesteps": 403995, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8858 1 visits [500.0, 483.0, 482.0, 482.0, 482.0, 482.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 19232 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8859 2 visits [500.0, 483.0, 483.0, 482.0, 482.0, 482.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 19233 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8860 3 visits [500.0, 483.0, 483.0, 483.0, 482.0, 482.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 19236 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8861 4 visits [500.0, 483.0, 483.0, 483.0, 483.0, 482.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 19238 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8862 5 visits [500.0, 483.0, 483.0, 483.0, 483.0, 483.0, 482.0, 482.0, 500.0, 482.0]  episode_count: 19240 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8863 6 visits [500.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 482.0, 500.0, 482.0]  episode_count: 19240 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19242, "number_of_timesteps": 404206, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8864 7 visits [500.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 500.0, 482.0]  episode_count: 19242 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8865 9 visits [500.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 19246 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8866 1 visits [500.0, 484.0, 483.0, 483.0, 483.0, 483.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 19248 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8867 2 visits [500.0, 484.0, 484.0, 483.0, 483.0, 483.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 19249 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8868 3 visits [500.0, 484.0, 484.0, 484.0, 483.0, 483.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 19250 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19253, "number_of_timesteps": 404428, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8869 4 visits [500.0, 484.0, 484.0, 484.0, 484.0, 483.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 19253 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8870 5 visits [500.0, 484.0, 484.0, 484.0, 484.0, 484.0, 483.0, 483.0, 500.0, 483.0]  episode_count: 19257 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8871 6 visits [500.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 483.0, 500.0, 483.0]  episode_count: 19258 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8872 7 visits [500.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 500.0, 483.0]  episode_count: 19260 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8873 9 visits [500.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 19261 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19264, "number_of_timesteps": 404683, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8874 1 visits [500.0, 485.0, 484.0, 484.0, 484.0, 484.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 19264 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8875 2 visits [500.0, 485.0, 485.0, 484.0, 484.0, 484.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 19268 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8876 3 visits [500.0, 485.0, 485.0, 485.0, 484.0, 484.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 19272 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19274, "number_of_timesteps": 404890, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8877 4 visits [500.0, 485.0, 485.0, 485.0, 485.0, 484.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 19274 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8878 5 visits [500.0, 485.0, 485.0, 485.0, 485.0, 485.0, 484.0, 484.0, 500.0, 484.0]  episode_count: 19275 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8879 6 visits [500.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 484.0, 500.0, 484.0]  episode_count: 19278 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8880 7 visits [500.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 500.0, 484.0]  episode_count: 19281 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8881 9 visits [500.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 19283 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19285, "number_of_timesteps": 405069, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8882 1 visits [500.0, 486.0, 485.0, 485.0, 485.0, 485.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 19285 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8883 2 visits [500.0, 486.0, 486.0, 485.0, 485.0, 485.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 19291 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8884 3 visits [500.0, 486.0, 486.0, 486.0, 485.0, 485.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 19291 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8885 4 visits [500.0, 486.0, 486.0, 486.0, 486.0, 485.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 19292 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8886 5 visits [500.0, 486.0, 486.0, 486.0, 486.0, 486.0, 485.0, 485.0, 500.0, 485.0]  episode_count: 19294 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19296, "number_of_timesteps": 405274, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8887 6 visits [500.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 485.0, 500.0, 485.0]  episode_count: 19296 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8888 7 visits [500.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 500.0, 485.0]  episode_count: 19297 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8889 9 visits [500.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 19298 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8890 1 visits [500.0, 487.0, 486.0, 486.0, 486.0, 486.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 19301 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8891 2 visits [500.0, 487.0, 487.0, 486.0, 486.0, 486.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 19303 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8892 3 visits [500.0, 487.0, 487.0, 487.0, 486.0, 486.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 19304 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8893 4 visits [500.0, 487.0, 487.0, 487.0, 487.0, 486.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 19304 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19310, "number_of_timesteps": 405599, "per_episode_reward": 14.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 8894 5 visits [500.0, 487.0, 487.0, 487.0, 487.0, 487.0, 486.0, 486.0, 500.0, 486.0]  episode_count: 19310 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8895 6 visits [500.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 486.0, 500.0, 486.0]  episode_count: 19311 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8896 7 visits [500.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 500.0, 486.0]  episode_count: 19312 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8897 9 visits [500.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 19315 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8898 1 visits [500.0, 488.0, 487.0, 487.0, 487.0, 487.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 19316 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19320, "number_of_timesteps": 405790, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8899 2 visits [500.0, 488.0, 488.0, 487.0, 487.0, 487.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 19320 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8900 3 visits [500.0, 488.0, 488.0, 488.0, 487.0, 487.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 19321 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8901 4 visits [500.0, 488.0, 488.0, 488.0, 488.0, 487.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 19323 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8902 5 visits [500.0, 488.0, 488.0, 488.0, 488.0, 488.0, 487.0, 487.0, 500.0, 487.0]  episode_count: 19327 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8903 6 visits [500.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 487.0, 500.0, 487.0]  episode_count: 19328 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19330, "number_of_timesteps": 405945, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8904 7 visits [500.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 500.0, 487.0]  episode_count: 19330 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8905 9 visits [500.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 19332 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8906 1 visits [500.0, 489.0, 488.0, 488.0, 488.0, 488.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 19335 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8907 2 visits [500.0, 489.0, 489.0, 488.0, 488.0, 488.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 19336 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8908 3 visits [500.0, 489.0, 489.0, 489.0, 488.0, 488.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 19336 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19342, "number_of_timesteps": 406340, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8909 4 visits [500.0, 489.0, 489.0, 489.0, 489.0, 488.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 19342 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8910 5 visits [500.0, 489.0, 489.0, 489.0, 489.0, 489.0, 488.0, 488.0, 500.0, 488.0]  episode_count: 19342 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8911 6 visits [500.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 488.0, 500.0, 488.0]  episode_count: 19343 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8912 7 visits [500.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 500.0, 488.0]  episode_count: 19344 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8913 9 visits [500.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 19347 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8914 1 visits [500.0, 490.0, 489.0, 489.0, 489.0, 489.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 19349 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8915 2 visits [500.0, 490.0, 490.0, 489.0, 489.0, 489.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 19351 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8916 3 visits [500.0, 490.0, 490.0, 490.0, 489.0, 489.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 19351 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19355, "number_of_timesteps": 406651, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8917 4 visits [500.0, 490.0, 490.0, 490.0, 490.0, 489.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 19355 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8918 5 visits [500.0, 490.0, 490.0, 490.0, 490.0, 490.0, 489.0, 489.0, 500.0, 489.0]  episode_count: 19357 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8919 6 visits [500.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 489.0, 500.0, 489.0]  episode_count: 19358 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8920 7 visits [500.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 500.0, 489.0]  episode_count: 19360 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8921 9 visits [500.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 19362 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8922 1 visits [500.0, 491.0, 490.0, 490.0, 490.0, 490.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 19363 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19365, "number_of_timesteps": 406881, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8923 2 visits [500.0, 491.0, 491.0, 490.0, 490.0, 490.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 19365 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8924 3 visits [500.0, 491.0, 491.0, 491.0, 490.0, 490.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 19368 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8925 4 visits [500.0, 491.0, 491.0, 491.0, 491.0, 490.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 19371 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8926 5 visits [500.0, 491.0, 491.0, 491.0, 491.0, 491.0, 490.0, 490.0, 500.0, 490.0]  episode_count: 19372 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19375, "number_of_timesteps": 407097, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8927 6 visits [500.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 490.0, 500.0, 490.0]  episode_count: 19375 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8928 7 visits [500.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 500.0, 490.0]  episode_count: 19378 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8929 9 visits [500.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 19379 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8930 1 visits [500.0, 492.0, 491.0, 491.0, 491.0, 491.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 19381 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8931 2 visits [500.0, 492.0, 492.0, 491.0, 491.0, 491.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 19382 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8932 3 visits [500.0, 492.0, 492.0, 492.0, 491.0, 491.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 19384 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19387, "number_of_timesteps": 407377, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8933 4 visits [500.0, 492.0, 492.0, 492.0, 492.0, 491.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 19387 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8934 5 visits [500.0, 492.0, 492.0, 492.0, 492.0, 492.0, 491.0, 491.0, 500.0, 491.0]  episode_count: 19391 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8935 6 visits [500.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 491.0, 500.0, 491.0]  episode_count: 19392 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8936 7 visits [500.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 500.0, 491.0]  episode_count: 19394 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8937 9 visits [500.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 19395 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19398, "number_of_timesteps": 407601, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 8938 1 visits [500.0, 493.0, 492.0, 492.0, 492.0, 492.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 19398 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8939 2 visits [500.0, 493.0, 493.0, 492.0, 492.0, 492.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 19400 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8940 3 visits [500.0, 493.0, 493.0, 493.0, 492.0, 492.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 19401 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8941 4 visits [500.0, 493.0, 493.0, 493.0, 493.0, 492.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 19404 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19408, "number_of_timesteps": 407843, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 8942 5 visits [500.0, 493.0, 493.0, 493.0, 493.0, 493.0, 492.0, 492.0, 500.0, 492.0]  episode_count: 19408 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8943 6 visits [500.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 492.0, 500.0, 492.0]  episode_count: 19409 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8944 7 visits [500.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 500.0, 492.0]  episode_count: 19411 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8945 9 visits [500.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 19415 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8946 1 visits [500.0, 494.0, 493.0, 493.0, 493.0, 493.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 19416 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8947 2 visits [500.0, 494.0, 494.0, 493.0, 493.0, 493.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 19416 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8948 3 visits [500.0, 494.0, 494.0, 494.0, 493.0, 493.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 19417 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19421, "number_of_timesteps": 408130, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8949 4 visits [500.0, 494.0, 494.0, 494.0, 494.0, 493.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 19421 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8950 5 visits [500.0, 494.0, 494.0, 494.0, 494.0, 494.0, 493.0, 493.0, 500.0, 493.0]  episode_count: 19423 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8951 6 visits [500.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 493.0, 500.0, 493.0]  episode_count: 19425 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8952 7 visits [500.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 500.0, 493.0]  episode_count: 19427 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19431, "number_of_timesteps": 408338, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8953 9 visits [500.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 19431 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8954 1 visits [500.0, 495.0, 494.0, 494.0, 494.0, 494.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 19433 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8955 2 visits [500.0, 495.0, 495.0, 494.0, 494.0, 494.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 19435 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8956 3 visits [500.0, 495.0, 495.0, 495.0, 494.0, 494.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 19439 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19442, "number_of_timesteps": 408547, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8957 4 visits [500.0, 495.0, 495.0, 495.0, 495.0, 494.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 19442 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8958 5 visits [500.0, 495.0, 495.0, 495.0, 495.0, 495.0, 494.0, 494.0, 500.0, 494.0]  episode_count: 19442 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8959 6 visits [500.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 494.0, 500.0, 494.0]  episode_count: 19443 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8960 7 visits [500.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 500.0, 494.0]  episode_count: 19446 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8961 9 visits [500.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 19451 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8962 1 visits [500.0, 496.0, 495.0, 495.0, 495.0, 495.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 19451 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19453, "number_of_timesteps": 408746, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8963 2 visits [500.0, 496.0, 496.0, 495.0, 495.0, 495.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 19453 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8964 3 visits [500.0, 496.0, 496.0, 496.0, 495.0, 495.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 19456 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8965 4 visits [500.0, 496.0, 496.0, 496.0, 496.0, 495.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 19458 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8966 5 visits [500.0, 496.0, 496.0, 496.0, 496.0, 496.0, 495.0, 495.0, 500.0, 495.0]  episode_count: 19460 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19463, "number_of_timesteps": 408955, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8967 6 visits [500.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 495.0, 500.0, 495.0]  episode_count: 19463 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8968 7 visits [500.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 500.0, 495.0]  episode_count: 19465 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8969 9 visits [500.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 19469 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8970 1 visits [500.0, 497.0, 496.0, 496.0, 496.0, 496.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 19470 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8971 2 visits [500.0, 497.0, 497.0, 496.0, 496.0, 496.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 19471 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19474, "number_of_timesteps": 409154, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8972 3 visits [500.0, 497.0, 497.0, 497.0, 496.0, 496.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 19474 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8973 4 visits [500.0, 497.0, 497.0, 497.0, 497.0, 496.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 19477 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8974 5 visits [500.0, 497.0, 497.0, 497.0, 497.0, 497.0, 496.0, 496.0, 500.0, 496.0]  episode_count: 19477 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8975 6 visits [500.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 496.0, 500.0, 496.0]  episode_count: 19478 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8976 7 visits [500.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 500.0, 496.0]  episode_count: 19478 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8977 9 visits [500.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 19481 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19485, "number_of_timesteps": 409429, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8978 1 visits [500.0, 498.0, 497.0, 497.0, 497.0, 497.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 19485 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8979 2 visits [500.0, 498.0, 498.0, 497.0, 497.0, 497.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 19486 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8980 3 visits [500.0, 498.0, 498.0, 498.0, 497.0, 497.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 19486 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8981 4 visits [500.0, 498.0, 498.0, 498.0, 498.0, 497.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 19491 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8982 5 visits [500.0, 498.0, 498.0, 498.0, 498.0, 498.0, 497.0, 497.0, 500.0, 497.0]  episode_count: 19494 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19495, "number_of_timesteps": 409674, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8983 6 visits [500.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 497.0, 500.0, 497.0]  episode_count: 19495 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8984 7 visits [500.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 500.0, 497.0]  episode_count: 19496 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8985 9 visits [500.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 19498 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8986 1 visits [500.0, 499.0, 498.0, 498.0, 498.0, 498.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 19501 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8987 2 visits [500.0, 499.0, 499.0, 498.0, 498.0, 498.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 19502 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8988 3 visits [500.0, 499.0, 499.0, 499.0, 498.0, 498.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 19503 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19506, "number_of_timesteps": 409874, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 8989 4 visits [500.0, 499.0, 499.0, 499.0, 499.0, 498.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 19506 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8990 5 visits [500.0, 499.0, 499.0, 499.0, 499.0, 499.0, 498.0, 498.0, 500.0, 498.0]  episode_count: 19508 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8991 6 visits [500.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 498.0, 500.0, 498.0]  episode_count: 19509 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8992 7 visits [500.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 500.0, 498.0]  episode_count: 19509 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8993 9 visits [500.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 499.0, 500.0, 499.0]  episode_count: 19513 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
Step 8994 1 visits [500.0, 500.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0, 0.0]  episode_count: 19513 q_vals: [-inf, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf, 0.0]
{"total_number_of_episodes": 19518, "number_of_timesteps": 410260, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.8000000000000007},
{"total_number_of_episodes": 19528, "number_of_timesteps": 410498, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.8000000000000007},
{"total_number_of_episodes": 19538, "number_of_timesteps": 410659, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.8000000000000007},
{"total_number_of_episodes": 19550, "number_of_timesteps": 410892, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.8000000000000007},
{"total_number_of_episodes": 19561, "number_of_timesteps": 411098, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.8000000000000007},
{"total_number_of_episodes": 19574, "number_of_timesteps": 411301, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.8000000000000007},
{"total_number_of_episodes": 19587, "number_of_timesteps": 411537, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.8000000000000007},
{"total_number_of_episodes": 19597, "number_of_timesteps": 411686, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.8000000000000007},
{"total_number_of_episodes": 19608, "number_of_timesteps": 411874, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.8000000000000007},
{"total_number_of_episodes": 19619, "number_of_timesteps": 412065, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19630, "number_of_timesteps": 412231, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19641, "number_of_timesteps": 412441, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19654, "number_of_timesteps": 412630, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19665, "number_of_timesteps": 412776, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19676, "number_of_timesteps": 412953, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19687, "number_of_timesteps": 413144, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19698, "number_of_timesteps": 413319, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19711, "number_of_timesteps": 413565, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19721, "number_of_timesteps": 413713, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19732, "number_of_timesteps": 413853, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19742, "number_of_timesteps": 414012, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19753, "number_of_timesteps": 414219, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19764, "number_of_timesteps": 414426, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19774, "number_of_timesteps": 414641, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19785, "number_of_timesteps": 414860, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19795, "number_of_timesteps": 415109, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19805, "number_of_timesteps": 415249, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19817, "number_of_timesteps": 415535, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19827, "number_of_timesteps": 415720, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19837, "number_of_timesteps": 416010, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19847, "number_of_timesteps": 416208, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19857, "number_of_timesteps": 416437, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19867, "number_of_timesteps": 416642, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19879, "number_of_timesteps": 417006, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19891, "number_of_timesteps": 417250, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19903, "number_of_timesteps": 417485, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19914, "number_of_timesteps": 417719, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19926, "number_of_timesteps": 417937, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19936, "number_of_timesteps": 418106, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19948, "number_of_timesteps": 418299, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19964, "number_of_timesteps": 418604, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19975, "number_of_timesteps": 418786, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19987, "number_of_timesteps": 418948, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 19999, "number_of_timesteps": 419196, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20010, "number_of_timesteps": 419364, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20021, "number_of_timesteps": 419543, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20032, "number_of_timesteps": 419757, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20044, "number_of_timesteps": 420002, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20054, "number_of_timesteps": 420215, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 20064, "number_of_timesteps": 420473, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 20074, "number_of_timesteps": 420694, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 20085, "number_of_timesteps": 420955, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 20095, "number_of_timesteps": 421181, "per_episode_reward": 12.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 20106, "number_of_timesteps": 421406, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20116, "number_of_timesteps": 421639, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20126, "number_of_timesteps": 421900, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20136, "number_of_timesteps": 422098, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20147, "number_of_timesteps": 422304, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20157, "number_of_timesteps": 422529, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20167, "number_of_timesteps": 422749, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20177, "number_of_timesteps": 423059, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20189, "number_of_timesteps": 423304, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 20201, "number_of_timesteps": 423594, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20213, "number_of_timesteps": 423944, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20223, "number_of_timesteps": 424151, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20233, "number_of_timesteps": 424411, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20244, "number_of_timesteps": 424648, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20255, "number_of_timesteps": 424912, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20265, "number_of_timesteps": 425104, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20277, "number_of_timesteps": 425337, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20289, "number_of_timesteps": 425569, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20299, "number_of_timesteps": 425758, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20312, "number_of_timesteps": 425997, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20322, "number_of_timesteps": 426227, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20333, "number_of_timesteps": 426420, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20344, "number_of_timesteps": 426648, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20355, "number_of_timesteps": 426860, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20366, "number_of_timesteps": 427085, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20378, "number_of_timesteps": 427341, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20389, "number_of_timesteps": 427580, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20400, "number_of_timesteps": 427771, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20410, "number_of_timesteps": 427910, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20421, "number_of_timesteps": 428139, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20431, "number_of_timesteps": 428389, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20441, "number_of_timesteps": 428594, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20454, "number_of_timesteps": 428937, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20464, "number_of_timesteps": 429163, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20475, "number_of_timesteps": 429369, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20487, "number_of_timesteps": 429618, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20498, "number_of_timesteps": 429854, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20508, "number_of_timesteps": 430073, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20520, "number_of_timesteps": 430305, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20530, "number_of_timesteps": 430542, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20541, "number_of_timesteps": 430718, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20551, "number_of_timesteps": 430946, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20564, "number_of_timesteps": 431180, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20578, "number_of_timesteps": 431357, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20588, "number_of_timesteps": 431517, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20600, "number_of_timesteps": 431804, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20613, "number_of_timesteps": 432076, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20624, "number_of_timesteps": 432251, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20636, "number_of_timesteps": 432434, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20650, "number_of_timesteps": 432727, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20660, "number_of_timesteps": 432913, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20670, "number_of_timesteps": 433125, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20680, "number_of_timesteps": 433335, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20693, "number_of_timesteps": 433546, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20706, "number_of_timesteps": 433792, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20716, "number_of_timesteps": 434021, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20727, "number_of_timesteps": 434252, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20738, "number_of_timesteps": 434477, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20748, "number_of_timesteps": 434636, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20758, "number_of_timesteps": 434898, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20769, "number_of_timesteps": 435128, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20779, "number_of_timesteps": 435354, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20789, "number_of_timesteps": 435561, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20799, "number_of_timesteps": 435797, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20809, "number_of_timesteps": 436010, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20821, "number_of_timesteps": 436208, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20834, "number_of_timesteps": 436417, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20847, "number_of_timesteps": 436672, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20857, "number_of_timesteps": 436888, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20869, "number_of_timesteps": 437162, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20880, "number_of_timesteps": 437409, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20893, "number_of_timesteps": 437636, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20903, "number_of_timesteps": 437847, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20915, "number_of_timesteps": 438048, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20926, "number_of_timesteps": 438228, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20938, "number_of_timesteps": 438478, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20949, "number_of_timesteps": 438677, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20960, "number_of_timesteps": 438933, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20970, "number_of_timesteps": 439168, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20981, "number_of_timesteps": 439450, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20994, "number_of_timesteps": 439707, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21008, "number_of_timesteps": 439911, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21020, "number_of_timesteps": 440101, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21030, "number_of_timesteps": 440252, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21041, "number_of_timesteps": 440409, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21051, "number_of_timesteps": 440583, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21064, "number_of_timesteps": 440763, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21074, "number_of_timesteps": 440907, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21085, "number_of_timesteps": 441089, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21096, "number_of_timesteps": 441299, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21109, "number_of_timesteps": 441570, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21120, "number_of_timesteps": 441826, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21132, "number_of_timesteps": 442120, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21143, "number_of_timesteps": 442376, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21153, "number_of_timesteps": 442602, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21166, "number_of_timesteps": 442946, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21176, "number_of_timesteps": 443197, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21188, "number_of_timesteps": 443450, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21201, "number_of_timesteps": 443698, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21212, "number_of_timesteps": 443921, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21222, "number_of_timesteps": 444160, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21232, "number_of_timesteps": 444334, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21242, "number_of_timesteps": 444580, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21252, "number_of_timesteps": 444829, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21263, "number_of_timesteps": 445152, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21274, "number_of_timesteps": 445345, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21285, "number_of_timesteps": 445588, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21295, "number_of_timesteps": 445805, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21307, "number_of_timesteps": 446047, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21318, "number_of_timesteps": 446347, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21328, "number_of_timesteps": 446587, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21338, "number_of_timesteps": 446816, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21348, "number_of_timesteps": 446990, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21358, "number_of_timesteps": 447142, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21371, "number_of_timesteps": 447407, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21382, "number_of_timesteps": 447585, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21395, "number_of_timesteps": 447799, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21407, "number_of_timesteps": 448074, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21418, "number_of_timesteps": 448288, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21430, "number_of_timesteps": 448604, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21441, "number_of_timesteps": 448868, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21452, "number_of_timesteps": 449145, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21463, "number_of_timesteps": 449372, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21474, "number_of_timesteps": 449569, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21484, "number_of_timesteps": 449779, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21495, "number_of_timesteps": 450049, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21505, "number_of_timesteps": 450336, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21520, "number_of_timesteps": 450654, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21531, "number_of_timesteps": 450839, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21544, "number_of_timesteps": 450992, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21555, "number_of_timesteps": 451145, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21569, "number_of_timesteps": 451322, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21579, "number_of_timesteps": 451447, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21592, "number_of_timesteps": 451626, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21602, "number_of_timesteps": 451802, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21612, "number_of_timesteps": 451980, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21622, "number_of_timesteps": 452157, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21634, "number_of_timesteps": 452354, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21645, "number_of_timesteps": 452561, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21656, "number_of_timesteps": 452825, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 21670, "number_of_timesteps": 453036, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21680, "number_of_timesteps": 453169, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21694, "number_of_timesteps": 453420, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21704, "number_of_timesteps": 453568, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21715, "number_of_timesteps": 453702, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21725, "number_of_timesteps": 453822, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21736, "number_of_timesteps": 453945, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21749, "number_of_timesteps": 454123, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21760, "number_of_timesteps": 454307, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21770, "number_of_timesteps": 454459, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21780, "number_of_timesteps": 454645, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21792, "number_of_timesteps": 454886, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21802, "number_of_timesteps": 455133, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21814, "number_of_timesteps": 455407, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21824, "number_of_timesteps": 455603, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21836, "number_of_timesteps": 455847, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21846, "number_of_timesteps": 456036, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21857, "number_of_timesteps": 456260, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21868, "number_of_timesteps": 456453, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21880, "number_of_timesteps": 456643, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21893, "number_of_timesteps": 456934, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21904, "number_of_timesteps": 457174, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21915, "number_of_timesteps": 457378, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21926, "number_of_timesteps": 457561, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21937, "number_of_timesteps": 457743, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21947, "number_of_timesteps": 457883, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21957, "number_of_timesteps": 458036, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21967, "number_of_timesteps": 458157, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21978, "number_of_timesteps": 458332, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 21988, "number_of_timesteps": 458533, "per_episode_reward": 12.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 21998, "number_of_timesteps": 458806, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22008, "number_of_timesteps": 459005, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22018, "number_of_timesteps": 459254, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22029, "number_of_timesteps": 459481, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22039, "number_of_timesteps": 459738, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22049, "number_of_timesteps": 459978, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22063, "number_of_timesteps": 460272, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22075, "number_of_timesteps": 460488, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22086, "number_of_timesteps": 460741, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22097, "number_of_timesteps": 460922, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22107, "number_of_timesteps": 461116, "per_episode_reward": 12.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22118, "number_of_timesteps": 461359, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22128, "number_of_timesteps": 461480, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22138, "number_of_timesteps": 461600, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22148, "number_of_timesteps": 461775, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22161, "number_of_timesteps": 461943, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22171, "number_of_timesteps": 462087, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22182, "number_of_timesteps": 462237, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22194, "number_of_timesteps": 462454, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22204, "number_of_timesteps": 462635, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 22216, "number_of_timesteps": 462906, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22226, "number_of_timesteps": 463120, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22237, "number_of_timesteps": 463344, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22248, "number_of_timesteps": 463617, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22259, "number_of_timesteps": 463812, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22271, "number_of_timesteps": 464052, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22281, "number_of_timesteps": 464171, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22291, "number_of_timesteps": 464339, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22303, "number_of_timesteps": 464586, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22314, "number_of_timesteps": 464812, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22324, "number_of_timesteps": 465016, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22334, "number_of_timesteps": 465175, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22344, "number_of_timesteps": 465415, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22357, "number_of_timesteps": 465646, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22369, "number_of_timesteps": 465926, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22379, "number_of_timesteps": 466099, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22391, "number_of_timesteps": 466327, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22403, "number_of_timesteps": 466593, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22415, "number_of_timesteps": 466767, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22426, "number_of_timesteps": 466927, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22437, "number_of_timesteps": 467056, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22448, "number_of_timesteps": 467195, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22458, "number_of_timesteps": 467330, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22468, "number_of_timesteps": 467454, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22479, "number_of_timesteps": 467619, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22490, "number_of_timesteps": 467772, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22502, "number_of_timesteps": 467995, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22513, "number_of_timesteps": 468210, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22526, "number_of_timesteps": 468446, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22536, "number_of_timesteps": 468625, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22546, "number_of_timesteps": 468850, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22557, "number_of_timesteps": 469106, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22568, "number_of_timesteps": 469275, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22578, "number_of_timesteps": 469406, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22588, "number_of_timesteps": 469556, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22600, "number_of_timesteps": 469750, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22612, "number_of_timesteps": 469972, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22622, "number_of_timesteps": 470188, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22634, "number_of_timesteps": 470376, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22644, "number_of_timesteps": 470570, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22655, "number_of_timesteps": 470830, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22666, "number_of_timesteps": 471045, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22678, "number_of_timesteps": 471268, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22688, "number_of_timesteps": 471482, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22699, "number_of_timesteps": 471711, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22711, "number_of_timesteps": 471939, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22722, "number_of_timesteps": 472092, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22732, "number_of_timesteps": 472307, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22742, "number_of_timesteps": 472512, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22754, "number_of_timesteps": 472776, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22767, "number_of_timesteps": 473156, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22778, "number_of_timesteps": 473377, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22788, "number_of_timesteps": 473601, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22800, "number_of_timesteps": 473997, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22810, "number_of_timesteps": 474309, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22821, "number_of_timesteps": 474548, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22831, "number_of_timesteps": 474799, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22842, "number_of_timesteps": 475030, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22852, "number_of_timesteps": 475252, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22862, "number_of_timesteps": 475468, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22872, "number_of_timesteps": 475625, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22883, "number_of_timesteps": 475863, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22893, "number_of_timesteps": 476033, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22903, "number_of_timesteps": 476197, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22913, "number_of_timesteps": 476391, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22924, "number_of_timesteps": 476654, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22936, "number_of_timesteps": 476920, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22948, "number_of_timesteps": 477139, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22960, "number_of_timesteps": 477435, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22972, "number_of_timesteps": 477673, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22982, "number_of_timesteps": 477833, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 22993, "number_of_timesteps": 478092, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23004, "number_of_timesteps": 478295, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23015, "number_of_timesteps": 478498, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23028, "number_of_timesteps": 478808, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23039, "number_of_timesteps": 479013, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23050, "number_of_timesteps": 479212, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23063, "number_of_timesteps": 479576, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23073, "number_of_timesteps": 479803, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23084, "number_of_timesteps": 480011, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23095, "number_of_timesteps": 480222, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23106, "number_of_timesteps": 480434, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23117, "number_of_timesteps": 480625, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23127, "number_of_timesteps": 480895, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23138, "number_of_timesteps": 481157, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23148, "number_of_timesteps": 481445, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23158, "number_of_timesteps": 481735, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23170, "number_of_timesteps": 481955, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23180, "number_of_timesteps": 482177, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23190, "number_of_timesteps": 482369, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23200, "number_of_timesteps": 482528, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23212, "number_of_timesteps": 482741, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23223, "number_of_timesteps": 482971, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23234, "number_of_timesteps": 483155, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23244, "number_of_timesteps": 483373, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23254, "number_of_timesteps": 483590, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23264, "number_of_timesteps": 483775, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23274, "number_of_timesteps": 483979, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23289, "number_of_timesteps": 484250, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23299, "number_of_timesteps": 484459, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23309, "number_of_timesteps": 484677, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23319, "number_of_timesteps": 484898, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23330, "number_of_timesteps": 485115, "per_episode_reward": 12.15, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23343, "number_of_timesteps": 485323, "per_episode_reward": 12.15, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23355, "number_of_timesteps": 485501, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23366, "number_of_timesteps": 485705, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23376, "number_of_timesteps": 485882, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23389, "number_of_timesteps": 486078, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23403, "number_of_timesteps": 486288, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23416, "number_of_timesteps": 486476, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23427, "number_of_timesteps": 486613, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23439, "number_of_timesteps": 486768, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23450, "number_of_timesteps": 486981, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23461, "number_of_timesteps": 487161, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23471, "number_of_timesteps": 487368, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23481, "number_of_timesteps": 487540, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23491, "number_of_timesteps": 487695, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23501, "number_of_timesteps": 487874, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23511, "number_of_timesteps": 488030, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23523, "number_of_timesteps": 488214, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23533, "number_of_timesteps": 488384, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23546, "number_of_timesteps": 488551, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23557, "number_of_timesteps": 488722, "per_episode_reward": 12.05, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 23567, "number_of_timesteps": 488859, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23582, "number_of_timesteps": 489043, "per_episode_reward": 12.05, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23592, "number_of_timesteps": 489176, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23604, "number_of_timesteps": 489349, "per_episode_reward": 12.05, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23614, "number_of_timesteps": 489472, "per_episode_reward": 12.05, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23624, "number_of_timesteps": 489628, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23634, "number_of_timesteps": 489766, "per_episode_reward": 12.05, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23647, "number_of_timesteps": 489945, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23659, "number_of_timesteps": 490216, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23671, "number_of_timesteps": 490407, "per_episode_reward": 12.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23683, "number_of_timesteps": 490661, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23697, "number_of_timesteps": 490847, "per_episode_reward": 12.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23709, "number_of_timesteps": 491080, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23722, "number_of_timesteps": 491262, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23732, "number_of_timesteps": 491433, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23743, "number_of_timesteps": 491559, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23754, "number_of_timesteps": 491710, "per_episode_reward": 11.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23765, "number_of_timesteps": 491870, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23778, "number_of_timesteps": 492121, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23790, "number_of_timesteps": 492347, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23804, "number_of_timesteps": 492558, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23815, "number_of_timesteps": 492762, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23826, "number_of_timesteps": 492918, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23839, "number_of_timesteps": 493110, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23850, "number_of_timesteps": 493267, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 23860, "number_of_timesteps": 493443, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 23874, "number_of_timesteps": 493695, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23885, "number_of_timesteps": 493948, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 23897, "number_of_timesteps": 494190, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23911, "number_of_timesteps": 494520, "per_episode_reward": 11.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23921, "number_of_timesteps": 494684, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23931, "number_of_timesteps": 494879, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23942, "number_of_timesteps": 495128, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23955, "number_of_timesteps": 495333, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23966, "number_of_timesteps": 495572, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23976, "number_of_timesteps": 495766, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23988, "number_of_timesteps": 496077, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 23999, "number_of_timesteps": 496252, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 24010, "number_of_timesteps": 496424, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 24020, "number_of_timesteps": 496646, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24030, "number_of_timesteps": 496858, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24040, "number_of_timesteps": 497086, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24050, "number_of_timesteps": 497354, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24061, "number_of_timesteps": 497609, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24074, "number_of_timesteps": 497872, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24085, "number_of_timesteps": 498088, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24095, "number_of_timesteps": 498297, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24108, "number_of_timesteps": 498577, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24119, "number_of_timesteps": 498779, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24130, "number_of_timesteps": 499084, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24144, "number_of_timesteps": 499367, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24155, "number_of_timesteps": 499544, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24166, "number_of_timesteps": 499735, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24177, "number_of_timesteps": 499944, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24188, "number_of_timesteps": 500195, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24199, "number_of_timesteps": 500386, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24212, "number_of_timesteps": 500612, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24223, "number_of_timesteps": 500777, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24234, "number_of_timesteps": 500929, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24246, "number_of_timesteps": 501127, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24258, "number_of_timesteps": 501299, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24268, "number_of_timesteps": 501446, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24278, "number_of_timesteps": 501617, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24288, "number_of_timesteps": 501812, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24300, "number_of_timesteps": 502054, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24311, "number_of_timesteps": 502289, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24322, "number_of_timesteps": 502541, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24332, "number_of_timesteps": 502756, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24344, "number_of_timesteps": 502980, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24358, "number_of_timesteps": 503261, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24369, "number_of_timesteps": 503436, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24380, "number_of_timesteps": 503636, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24392, "number_of_timesteps": 503813, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24404, "number_of_timesteps": 504075, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24416, "number_of_timesteps": 504309, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24427, "number_of_timesteps": 504491, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24439, "number_of_timesteps": 504695, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24450, "number_of_timesteps": 504876, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24460, "number_of_timesteps": 505080, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24470, "number_of_timesteps": 505273, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24481, "number_of_timesteps": 505501, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24493, "number_of_timesteps": 505734, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24503, "number_of_timesteps": 505926, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24515, "number_of_timesteps": 506177, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24525, "number_of_timesteps": 506439, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24535, "number_of_timesteps": 506627, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24547, "number_of_timesteps": 506861, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24557, "number_of_timesteps": 507055, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24569, "number_of_timesteps": 507331, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24579, "number_of_timesteps": 507668, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24593, "number_of_timesteps": 507896, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24605, "number_of_timesteps": 508049, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24617, "number_of_timesteps": 508190, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24627, "number_of_timesteps": 508321, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24639, "number_of_timesteps": 508489, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24649, "number_of_timesteps": 508614, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24659, "number_of_timesteps": 508733, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24669, "number_of_timesteps": 508873, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24681, "number_of_timesteps": 509059, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24691, "number_of_timesteps": 509277, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24702, "number_of_timesteps": 509495, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24713, "number_of_timesteps": 509778, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24723, "number_of_timesteps": 509975, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24734, "number_of_timesteps": 510229, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24744, "number_of_timesteps": 510427, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24755, "number_of_timesteps": 510636, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24767, "number_of_timesteps": 510845, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24780, "number_of_timesteps": 511054, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24791, "number_of_timesteps": 511212, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24801, "number_of_timesteps": 511326, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24813, "number_of_timesteps": 511487, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24825, "number_of_timesteps": 511652, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24836, "number_of_timesteps": 511849, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24849, "number_of_timesteps": 512142, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24859, "number_of_timesteps": 512376, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24869, "number_of_timesteps": 512580, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24879, "number_of_timesteps": 512793, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24889, "number_of_timesteps": 512990, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24900, "number_of_timesteps": 513219, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24910, "number_of_timesteps": 513422, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24920, "number_of_timesteps": 513545, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24934, "number_of_timesteps": 513743, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24946, "number_of_timesteps": 513922, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24957, "number_of_timesteps": 514119, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24967, "number_of_timesteps": 514287, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24977, "number_of_timesteps": 514508, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24987, "number_of_timesteps": 514755, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 24997, "number_of_timesteps": 514909, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25012, "number_of_timesteps": 515254, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25022, "number_of_timesteps": 515424, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25032, "number_of_timesteps": 515586, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25043, "number_of_timesteps": 515745, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25055, "number_of_timesteps": 515927, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25066, "number_of_timesteps": 516061, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25079, "number_of_timesteps": 516251, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25092, "number_of_timesteps": 516456, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25102, "number_of_timesteps": 516586, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25115, "number_of_timesteps": 516768, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25127, "number_of_timesteps": 516911, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25138, "number_of_timesteps": 517082, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25151, "number_of_timesteps": 517254, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25161, "number_of_timesteps": 517376, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25172, "number_of_timesteps": 517510, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25184, "number_of_timesteps": 517695, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25195, "number_of_timesteps": 517915, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25207, "number_of_timesteps": 518147, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25217, "number_of_timesteps": 518358, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25227, "number_of_timesteps": 518639, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25241, "number_of_timesteps": 518995, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25251, "number_of_timesteps": 519159, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25264, "number_of_timesteps": 519359, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25274, "number_of_timesteps": 519555, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25284, "number_of_timesteps": 519738, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25297, "number_of_timesteps": 519920, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25309, "number_of_timesteps": 520171, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25321, "number_of_timesteps": 520363, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25331, "number_of_timesteps": 520523, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25341, "number_of_timesteps": 520667, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25354, "number_of_timesteps": 520942, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25365, "number_of_timesteps": 521138, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25380, "number_of_timesteps": 521416, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25391, "number_of_timesteps": 521630, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25401, "number_of_timesteps": 521802, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25411, "number_of_timesteps": 521993, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25421, "number_of_timesteps": 522250, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25432, "number_of_timesteps": 522458, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25445, "number_of_timesteps": 522755, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25458, "number_of_timesteps": 522959, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25468, "number_of_timesteps": 523109, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25479, "number_of_timesteps": 523315, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25490, "number_of_timesteps": 523467, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25501, "number_of_timesteps": 523596, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25511, "number_of_timesteps": 523715, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25522, "number_of_timesteps": 523863, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25533, "number_of_timesteps": 524019, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25543, "number_of_timesteps": 524205, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25553, "number_of_timesteps": 524437, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25566, "number_of_timesteps": 524663, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25580, "number_of_timesteps": 524934, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25590, "number_of_timesteps": 525086, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25600, "number_of_timesteps": 525258, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25610, "number_of_timesteps": 525455, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25622, "number_of_timesteps": 525703, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25633, "number_of_timesteps": 525922, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25644, "number_of_timesteps": 526199, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25656, "number_of_timesteps": 526435, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25667, "number_of_timesteps": 526632, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25677, "number_of_timesteps": 526808, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25687, "number_of_timesteps": 527133, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25697, "number_of_timesteps": 527301, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25708, "number_of_timesteps": 527539, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25720, "number_of_timesteps": 527800, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25730, "number_of_timesteps": 528051, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25742, "number_of_timesteps": 528353, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25753, "number_of_timesteps": 528645, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25763, "number_of_timesteps": 528847, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25773, "number_of_timesteps": 529178, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25786, "number_of_timesteps": 529640, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25797, "number_of_timesteps": 529830, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25808, "number_of_timesteps": 530152, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25819, "number_of_timesteps": 530507, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25830, "number_of_timesteps": 530744, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25840, "number_of_timesteps": 530926, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25851, "number_of_timesteps": 531252, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25863, "number_of_timesteps": 531486, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25873, "number_of_timesteps": 531698, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25884, "number_of_timesteps": 531962, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25895, "number_of_timesteps": 532196, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25905, "number_of_timesteps": 532405, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25918, "number_of_timesteps": 532688, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25928, "number_of_timesteps": 532919, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25939, "number_of_timesteps": 533201, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25949, "number_of_timesteps": 533421, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25959, "number_of_timesteps": 533642, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25970, "number_of_timesteps": 533865, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25983, "number_of_timesteps": 534190, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 25995, "number_of_timesteps": 534478, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26005, "number_of_timesteps": 534712, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26015, "number_of_timesteps": 534991, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26025, "number_of_timesteps": 535281, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26036, "number_of_timesteps": 535538, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26046, "number_of_timesteps": 535786, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26058, "number_of_timesteps": 536117, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26068, "number_of_timesteps": 536375, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26078, "number_of_timesteps": 536684, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26090, "number_of_timesteps": 537029, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26100, "number_of_timesteps": 537249, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26110, "number_of_timesteps": 537464, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26122, "number_of_timesteps": 537714, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26133, "number_of_timesteps": 538044, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26143, "number_of_timesteps": 538244, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26155, "number_of_timesteps": 538478, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26166, "number_of_timesteps": 538681, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26180, "number_of_timesteps": 538996, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26190, "number_of_timesteps": 539228, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26201, "number_of_timesteps": 539533, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26212, "number_of_timesteps": 539851, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26223, "number_of_timesteps": 540033, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26236, "number_of_timesteps": 540312, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26246, "number_of_timesteps": 540529, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26260, "number_of_timesteps": 540922, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26270, "number_of_timesteps": 541172, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26281, "number_of_timesteps": 541433, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26291, "number_of_timesteps": 541672, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26301, "number_of_timesteps": 541949, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26311, "number_of_timesteps": 542201, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26322, "number_of_timesteps": 542513, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26333, "number_of_timesteps": 542771, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26343, "number_of_timesteps": 543056, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26355, "number_of_timesteps": 543321, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26365, "number_of_timesteps": 543644, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26375, "number_of_timesteps": 543932, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26386, "number_of_timesteps": 544233, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26397, "number_of_timesteps": 544539, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26408, "number_of_timesteps": 544846, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26419, "number_of_timesteps": 545111, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26429, "number_of_timesteps": 545366, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26441, "number_of_timesteps": 545717, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26451, "number_of_timesteps": 545911, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26463, "number_of_timesteps": 546186, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26473, "number_of_timesteps": 546429, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26484, "number_of_timesteps": 546781, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26494, "number_of_timesteps": 547127, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26504, "number_of_timesteps": 547437, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26515, "number_of_timesteps": 547733, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26525, "number_of_timesteps": 548007, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26536, "number_of_timesteps": 548286, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26547, "number_of_timesteps": 548605, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26558, "number_of_timesteps": 548986, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26568, "number_of_timesteps": 549246, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26581, "number_of_timesteps": 549547, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26591, "number_of_timesteps": 549759, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26604, "number_of_timesteps": 550077, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26615, "number_of_timesteps": 550310, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26628, "number_of_timesteps": 550676, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26640, "number_of_timesteps": 550991, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26651, "number_of_timesteps": 551254, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26662, "number_of_timesteps": 551533, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26674, "number_of_timesteps": 551834, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26686, "number_of_timesteps": 552260, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26697, "number_of_timesteps": 552507, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26708, "number_of_timesteps": 552748, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26719, "number_of_timesteps": 553000, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26729, "number_of_timesteps": 553239, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26739, "number_of_timesteps": 553472, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26750, "number_of_timesteps": 553714, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26762, "number_of_timesteps": 554028, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26774, "number_of_timesteps": 554314, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26784, "number_of_timesteps": 554584, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26794, "number_of_timesteps": 554895, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26806, "number_of_timesteps": 555231, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26816, "number_of_timesteps": 555558, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26826, "number_of_timesteps": 555927, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26838, "number_of_timesteps": 556249, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26848, "number_of_timesteps": 556581, "per_episode_reward": 11.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26858, "number_of_timesteps": 556911, "per_episode_reward": 11.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 26868, "number_of_timesteps": 557212, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 26878, "number_of_timesteps": 557520, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 26889, "number_of_timesteps": 557785, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 26901, "number_of_timesteps": 558102, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 26911, "number_of_timesteps": 558510, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 26921, "number_of_timesteps": 558811, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 26931, "number_of_timesteps": 559182, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 26941, "number_of_timesteps": 559500, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 26952, "number_of_timesteps": 559942, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 26963, "number_of_timesteps": 560231, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26973, "number_of_timesteps": 560520, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26983, "number_of_timesteps": 560741, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 26994, "number_of_timesteps": 561063, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27005, "number_of_timesteps": 561597, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27017, "number_of_timesteps": 562037, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27028, "number_of_timesteps": 562410, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27038, "number_of_timesteps": 562789, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27049, "number_of_timesteps": 563175, "per_episode_reward": 12.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27059, "number_of_timesteps": 563427, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27070, "number_of_timesteps": 563784, "per_episode_reward": 12.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27081, "number_of_timesteps": 564100, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27091, "number_of_timesteps": 564306, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27103, "number_of_timesteps": 564724, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27113, "number_of_timesteps": 565008, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27124, "number_of_timesteps": 565369, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27134, "number_of_timesteps": 565739, "per_episode_reward": 12.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27144, "number_of_timesteps": 566399, "per_episode_reward": 12.15, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27154, "number_of_timesteps": 566797, "per_episode_reward": 12.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27167, "number_of_timesteps": 567274, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27177, "number_of_timesteps": 567743, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27187, "number_of_timesteps": 568094, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27198, "number_of_timesteps": 568597, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27208, "number_of_timesteps": 568951, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27219, "number_of_timesteps": 569359, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27230, "number_of_timesteps": 569680, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 27240, "number_of_timesteps": 570102, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 27251, "number_of_timesteps": 570498, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 27262, "number_of_timesteps": 571022, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27275, "number_of_timesteps": 571378, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27285, "number_of_timesteps": 571731, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27295, "number_of_timesteps": 572081, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27305, "number_of_timesteps": 572406, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27316, "number_of_timesteps": 572909, "per_episode_reward": 12.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27326, "number_of_timesteps": 573337, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27337, "number_of_timesteps": 573718, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27348, "number_of_timesteps": 574364, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27359, "number_of_timesteps": 574969, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27369, "number_of_timesteps": 575325, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27379, "number_of_timesteps": 575820, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27389, "number_of_timesteps": 576342, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27399, "number_of_timesteps": 576767, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27409, "number_of_timesteps": 577241, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27419, "number_of_timesteps": 577628, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27429, "number_of_timesteps": 578079, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27439, "number_of_timesteps": 578637, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27449, "number_of_timesteps": 579101, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27460, "number_of_timesteps": 579700, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27470, "number_of_timesteps": 580265, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27480, "number_of_timesteps": 580614, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27491, "number_of_timesteps": 581038, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27502, "number_of_timesteps": 581623, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27512, "number_of_timesteps": 582147, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27524, "number_of_timesteps": 582775, "per_episode_reward": 12.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 27534, "number_of_timesteps": 583437, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27544, "number_of_timesteps": 584312, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27554, "number_of_timesteps": 584965, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27564, "number_of_timesteps": 585637, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27574, "number_of_timesteps": 586447, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27584, "number_of_timesteps": 586932, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27594, "number_of_timesteps": 587666, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27605, "number_of_timesteps": 588347, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27615, "number_of_timesteps": 588868, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27625, "number_of_timesteps": 589662, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27636, "number_of_timesteps": 590568, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27646, "number_of_timesteps": 591221, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27656, "number_of_timesteps": 592017, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27668, "number_of_timesteps": 593047, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27678, "number_of_timesteps": 593707, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27688, "number_of_timesteps": 594615, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27698, "number_of_timesteps": 595294, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27709, "number_of_timesteps": 596057, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27720, "number_of_timesteps": 597039, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27730, "number_of_timesteps": 597937, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27740, "number_of_timesteps": 598983, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27750, "number_of_timesteps": 600030, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27760, "number_of_timesteps": 600941, "per_episode_reward": 12.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 27770, "number_of_timesteps": 601936, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27780, "number_of_timesteps": 603118, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27790, "number_of_timesteps": 604413, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27800, "number_of_timesteps": 605293, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27810, "number_of_timesteps": 606449, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27820, "number_of_timesteps": 607252, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27831, "number_of_timesteps": 608914, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27841, "number_of_timesteps": 610643, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27851, "number_of_timesteps": 611230, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 27862, "number_of_timesteps": 612036, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27872, "number_of_timesteps": 612685, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27883, "number_of_timesteps": 614035, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27893, "number_of_timesteps": 614953, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27905, "number_of_timesteps": 616622, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27915, "number_of_timesteps": 617699, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27925, "number_of_timesteps": 619360, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27935, "number_of_timesteps": 621173, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27946, "number_of_timesteps": 623256, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27956, "number_of_timesteps": 624987, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27966, "number_of_timesteps": 626691, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27976, "number_of_timesteps": 628183, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27986, "number_of_timesteps": 629377, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 27996, "number_of_timesteps": 631645, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28006, "number_of_timesteps": 633458, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28016, "number_of_timesteps": 635380, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28026, "number_of_timesteps": 637814, "per_episode_reward": 12.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 28036, "number_of_timesteps": 639666, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 28046, "number_of_timesteps": 641832, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 28056, "number_of_timesteps": 643133, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 28066, "number_of_timesteps": 644438, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 28076, "number_of_timesteps": 645665, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 28086, "number_of_timesteps": 646476, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 28097, "number_of_timesteps": 647905, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 28107, "number_of_timesteps": 650892, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 28117, "number_of_timesteps": 652197, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 28127, "number_of_timesteps": 654308, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28137, "number_of_timesteps": 655948, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28147, "number_of_timesteps": 658614, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28157, "number_of_timesteps": 660615, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28167, "number_of_timesteps": 662472, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28177, "number_of_timesteps": 663732, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28187, "number_of_timesteps": 664753, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28197, "number_of_timesteps": 665569, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28207, "number_of_timesteps": 667271, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28217, "number_of_timesteps": 669922, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28227, "number_of_timesteps": 671630, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28237, "number_of_timesteps": 672658, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28247, "number_of_timesteps": 674305, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28257, "number_of_timesteps": 676265, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28267, "number_of_timesteps": 678115, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28278, "number_of_timesteps": 679844, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28288, "number_of_timesteps": 680691, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28298, "number_of_timesteps": 681129, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28308, "number_of_timesteps": 681897, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28318, "number_of_timesteps": 683156, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28331, "number_of_timesteps": 684654, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28341, "number_of_timesteps": 685152, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28352, "number_of_timesteps": 685432, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28362, "number_of_timesteps": 686482, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28372, "number_of_timesteps": 687542, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28383, "number_of_timesteps": 689294, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28394, "number_of_timesteps": 690627, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28404, "number_of_timesteps": 691631, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28414, "number_of_timesteps": 692135, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28425, "number_of_timesteps": 692847, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28435, "number_of_timesteps": 693398, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28446, "number_of_timesteps": 693927, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28456, "number_of_timesteps": 694272, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28467, "number_of_timesteps": 694613, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28478, "number_of_timesteps": 694919, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28491, "number_of_timesteps": 695153, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28503, "number_of_timesteps": 695385, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28513, "number_of_timesteps": 695560, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28526, "number_of_timesteps": 695802, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28536, "number_of_timesteps": 696009, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28547, "number_of_timesteps": 696226, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28559, "number_of_timesteps": 696557, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28570, "number_of_timesteps": 696927, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28581, "number_of_timesteps": 697285, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28591, "number_of_timesteps": 697553, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28601, "number_of_timesteps": 697908, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28611, "number_of_timesteps": 698534, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28621, "number_of_timesteps": 699312, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28631, "number_of_timesteps": 700006, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28641, "number_of_timesteps": 700444, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28651, "number_of_timesteps": 701324, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28661, "number_of_timesteps": 702291, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28672, "number_of_timesteps": 703255, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28682, "number_of_timesteps": 704107, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28692, "number_of_timesteps": 705110, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28703, "number_of_timesteps": 706178, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28713, "number_of_timesteps": 707029, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28723, "number_of_timesteps": 707713, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28733, "number_of_timesteps": 708166, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28743, "number_of_timesteps": 708651, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28755, "number_of_timesteps": 709267, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28765, "number_of_timesteps": 709914, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28776, "number_of_timesteps": 710620, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28786, "number_of_timesteps": 711172, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28797, "number_of_timesteps": 711927, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28807, "number_of_timesteps": 712555, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28817, "number_of_timesteps": 713146, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28827, "number_of_timesteps": 714094, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28837, "number_of_timesteps": 715044, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28848, "number_of_timesteps": 716147, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28858, "number_of_timesteps": 717230, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28869, "number_of_timesteps": 718193, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28879, "number_of_timesteps": 719600, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28889, "number_of_timesteps": 720931, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28900, "number_of_timesteps": 722635, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28911, "number_of_timesteps": 723781, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28921, "number_of_timesteps": 725543, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28931, "number_of_timesteps": 726523, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28941, "number_of_timesteps": 727824, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28952, "number_of_timesteps": 729302, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28962, "number_of_timesteps": 730716, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28972, "number_of_timesteps": 731649, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28982, "number_of_timesteps": 732550, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 28992, "number_of_timesteps": 733285, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29002, "number_of_timesteps": 733799, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29012, "number_of_timesteps": 734329, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29022, "number_of_timesteps": 735086, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29033, "number_of_timesteps": 735654, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29043, "number_of_timesteps": 735885, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29054, "number_of_timesteps": 736346, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29066, "number_of_timesteps": 736893, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29077, "number_of_timesteps": 737417, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29087, "number_of_timesteps": 737861, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29098, "number_of_timesteps": 738800, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29108, "number_of_timesteps": 739750, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29118, "number_of_timesteps": 741150, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29128, "number_of_timesteps": 742930, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29138, "number_of_timesteps": 744398, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29148, "number_of_timesteps": 745826, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29158, "number_of_timesteps": 746886, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29168, "number_of_timesteps": 748097, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29179, "number_of_timesteps": 749403, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29189, "number_of_timesteps": 750555, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29199, "number_of_timesteps": 751548, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29209, "number_of_timesteps": 752392, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29219, "number_of_timesteps": 753610, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29229, "number_of_timesteps": 755246, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29239, "number_of_timesteps": 756773, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29249, "number_of_timesteps": 758571, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29259, "number_of_timesteps": 760250, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29269, "number_of_timesteps": 762275, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29279, "number_of_timesteps": 764248, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29289, "number_of_timesteps": 766240, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29299, "number_of_timesteps": 767915, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29309, "number_of_timesteps": 769675, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29319, "number_of_timesteps": 771470, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29329, "number_of_timesteps": 773305, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29340, "number_of_timesteps": 774704, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29350, "number_of_timesteps": 775501, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29360, "number_of_timesteps": 775895, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29373, "number_of_timesteps": 776347, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29383, "number_of_timesteps": 776576, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29394, "number_of_timesteps": 776733, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29404, "number_of_timesteps": 776909, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29416, "number_of_timesteps": 777068, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29426, "number_of_timesteps": 777200, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29438, "number_of_timesteps": 777362, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29448, "number_of_timesteps": 777492, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29459, "number_of_timesteps": 777674, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29469, "number_of_timesteps": 777801, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29482, "number_of_timesteps": 777983, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29493, "number_of_timesteps": 778227, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29503, "number_of_timesteps": 778643, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29514, "number_of_timesteps": 779132, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29524, "number_of_timesteps": 779587, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29534, "number_of_timesteps": 780372, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29544, "number_of_timesteps": 781103, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29555, "number_of_timesteps": 782139, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29565, "number_of_timesteps": 782743, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29576, "number_of_timesteps": 783567, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29586, "number_of_timesteps": 784170, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29596, "number_of_timesteps": 784840, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29607, "number_of_timesteps": 785521, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29617, "number_of_timesteps": 786552, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29627, "number_of_timesteps": 787344, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29637, "number_of_timesteps": 788135, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29648, "number_of_timesteps": 789154, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29659, "number_of_timesteps": 789751, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29669, "number_of_timesteps": 790782, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29679, "number_of_timesteps": 791477, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29689, "number_of_timesteps": 792785, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29699, "number_of_timesteps": 793884, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29709, "number_of_timesteps": 795876, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29719, "number_of_timesteps": 797068, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29729, "number_of_timesteps": 798359, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29739, "number_of_timesteps": 799779, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29749, "number_of_timesteps": 800900, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29759, "number_of_timesteps": 802334, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29769, "number_of_timesteps": 803978, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29779, "number_of_timesteps": 805438, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29789, "number_of_timesteps": 807219, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29799, "number_of_timesteps": 809029, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29810, "number_of_timesteps": 811836, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29820, "number_of_timesteps": 813473, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29831, "number_of_timesteps": 817204, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29841, "number_of_timesteps": 819607, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29851, "number_of_timesteps": 823746, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29861, "number_of_timesteps": 827188, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29871, "number_of_timesteps": 829872, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29881, "number_of_timesteps": 831771, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29891, "number_of_timesteps": 833156, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29901, "number_of_timesteps": 834071, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29911, "number_of_timesteps": 834550, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29922, "number_of_timesteps": 835467, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29933, "number_of_timesteps": 835869, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29943, "number_of_timesteps": 836259, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29954, "number_of_timesteps": 836722, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29965, "number_of_timesteps": 837015, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29975, "number_of_timesteps": 837336, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29985, "number_of_timesteps": 837627, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 29997, "number_of_timesteps": 838328, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30009, "number_of_timesteps": 838828, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30019, "number_of_timesteps": 839139, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30029, "number_of_timesteps": 839739, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30040, "number_of_timesteps": 840461, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30052, "number_of_timesteps": 840862, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30064, "number_of_timesteps": 841092, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30074, "number_of_timesteps": 841429, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30086, "number_of_timesteps": 842010, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30097, "number_of_timesteps": 842397, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30108, "number_of_timesteps": 842753, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30118, "number_of_timesteps": 843007, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30129, "number_of_timesteps": 843632, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30140, "number_of_timesteps": 843953, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30151, "number_of_timesteps": 844339, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30162, "number_of_timesteps": 844666, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30172, "number_of_timesteps": 844817, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30183, "number_of_timesteps": 845015, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30193, "number_of_timesteps": 845260, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30205, "number_of_timesteps": 846114, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30215, "number_of_timesteps": 846656, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30225, "number_of_timesteps": 847237, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30235, "number_of_timesteps": 847910, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30245, "number_of_timesteps": 848482, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30255, "number_of_timesteps": 849289, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30265, "number_of_timesteps": 850984, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30275, "number_of_timesteps": 854950, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30285, "number_of_timesteps": 859614, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30295, "number_of_timesteps": 863317, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30305, "number_of_timesteps": 866753, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30315, "number_of_timesteps": 869421, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30325, "number_of_timesteps": 871446, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30335, "number_of_timesteps": 872513, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30345, "number_of_timesteps": 874091, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30356, "number_of_timesteps": 878165, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30366, "number_of_timesteps": 882094, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30376, "number_of_timesteps": 886812, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30386, "number_of_timesteps": 889690, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30396, "number_of_timesteps": 893536, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30406, "number_of_timesteps": 896594, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 30416, "number_of_timesteps": 898633, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 30427, "number_of_timesteps": 902592, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30437, "number_of_timesteps": 904872, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30447, "number_of_timesteps": 907949, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30457, "number_of_timesteps": 911003, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30469, "number_of_timesteps": 915171, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30479, "number_of_timesteps": 918145, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30489, "number_of_timesteps": 921853, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30500, "number_of_timesteps": 925271, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 30510, "number_of_timesteps": 928119, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 30520, "number_of_timesteps": 931464, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 30530, "number_of_timesteps": 934035, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 30540, "number_of_timesteps": 936811, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 30550, "number_of_timesteps": 940213, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 30560, "number_of_timesteps": 943062, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 30570, "number_of_timesteps": 946187, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 30580, "number_of_timesteps": 950423, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 30590, "number_of_timesteps": 954701, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 30601, "number_of_timesteps": 958632, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30611, "number_of_timesteps": 961557, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30621, "number_of_timesteps": 965467, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30631, "number_of_timesteps": 968888, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30641, "number_of_timesteps": 972076, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30651, "number_of_timesteps": 975039, "per_episode_reward": 13.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30661, "number_of_timesteps": 978014, "per_episode_reward": 13.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30671, "number_of_timesteps": 981495, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30681, "number_of_timesteps": 985028, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30691, "number_of_timesteps": 988127, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30701, "number_of_timesteps": 991674, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30711, "number_of_timesteps": 995403, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30721, "number_of_timesteps": 999261, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30731, "number_of_timesteps": 1003649, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30741, "number_of_timesteps": 1008426, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 30752, "number_of_timesteps": 1013350, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 30762, "number_of_timesteps": 1017506, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30772, "number_of_timesteps": 1021359, "per_episode_reward": 13.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30782, "number_of_timesteps": 1024255, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30792, "number_of_timesteps": 1028792, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30802, "number_of_timesteps": 1033220, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30812, "number_of_timesteps": 1037463, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30822, "number_of_timesteps": 1042156, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30832, "number_of_timesteps": 1046934, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30842, "number_of_timesteps": 1051436, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30852, "number_of_timesteps": 1055798, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 30862, "number_of_timesteps": 1060751, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 30872, "number_of_timesteps": 1064436, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30882, "number_of_timesteps": 1069264, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30892, "number_of_timesteps": 1073729, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30902, "number_of_timesteps": 1078729, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30912, "number_of_timesteps": 1083296, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30922, "number_of_timesteps": 1088031, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30932, "number_of_timesteps": 1092744, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30942, "number_of_timesteps": 1097447, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30952, "number_of_timesteps": 1101930, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30962, "number_of_timesteps": 1106823, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30972, "number_of_timesteps": 1111823, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30982, "number_of_timesteps": 1116231, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 30992, "number_of_timesteps": 1120942, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31002, "number_of_timesteps": 1125942, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31012, "number_of_timesteps": 1130515, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31022, "number_of_timesteps": 1135515, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31032, "number_of_timesteps": 1140515, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31042, "number_of_timesteps": 1145515, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31052, "number_of_timesteps": 1150367, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31062, "number_of_timesteps": 1155367, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31072, "number_of_timesteps": 1160100, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31082, "number_of_timesteps": 1165100, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31092, "number_of_timesteps": 1170100, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31102, "number_of_timesteps": 1174778, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31112, "number_of_timesteps": 1179535, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31122, "number_of_timesteps": 1184527, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31132, "number_of_timesteps": 1189527, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31142, "number_of_timesteps": 1194522, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31152, "number_of_timesteps": 1199522, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31162, "number_of_timesteps": 1204522, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31172, "number_of_timesteps": 1209522, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31182, "number_of_timesteps": 1214522, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31192, "number_of_timesteps": 1219257, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31202, "number_of_timesteps": 1223932, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31212, "number_of_timesteps": 1228932, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31222, "number_of_timesteps": 1233833, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31232, "number_of_timesteps": 1238833, "per_episode_reward": 13.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 31242, "number_of_timesteps": 1243833, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 31252, "number_of_timesteps": 1248833, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 31262, "number_of_timesteps": 1253833, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 31272, "number_of_timesteps": 1258833, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 31282, "number_of_timesteps": 1263753, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 31292, "number_of_timesteps": 1268753, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 31302, "number_of_timesteps": 1273753, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 31312, "number_of_timesteps": 1278753, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 31322, "number_of_timesteps": 1283355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 31332, "number_of_timesteps": 1288355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31342, "number_of_timesteps": 1293355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31352, "number_of_timesteps": 1298355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31362, "number_of_timesteps": 1303355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31372, "number_of_timesteps": 1308355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31382, "number_of_timesteps": 1313355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31392, "number_of_timesteps": 1318355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31402, "number_of_timesteps": 1323355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31412, "number_of_timesteps": 1328355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31422, "number_of_timesteps": 1333355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31432, "number_of_timesteps": 1338355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31442, "number_of_timesteps": 1343355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31452, "number_of_timesteps": 1348355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31462, "number_of_timesteps": 1353355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31472, "number_of_timesteps": 1358355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31482, "number_of_timesteps": 1363355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31492, "number_of_timesteps": 1368355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31502, "number_of_timesteps": 1373355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31512, "number_of_timesteps": 1378355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31522, "number_of_timesteps": 1383355, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31532, "number_of_timesteps": 1388064, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31542, "number_of_timesteps": 1393064, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31552, "number_of_timesteps": 1398064, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31562, "number_of_timesteps": 1403064, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31572, "number_of_timesteps": 1408064, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31582, "number_of_timesteps": 1412851, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31592, "number_of_timesteps": 1417851, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31602, "number_of_timesteps": 1422851, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31612, "number_of_timesteps": 1427851, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31622, "number_of_timesteps": 1432851, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31632, "number_of_timesteps": 1437851, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31642, "number_of_timesteps": 1442851, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31652, "number_of_timesteps": 1447851, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31662, "number_of_timesteps": 1452851, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31672, "number_of_timesteps": 1457851, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31682, "number_of_timesteps": 1462851, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31692, "number_of_timesteps": 1467584, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31702, "number_of_timesteps": 1472584, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31712, "number_of_timesteps": 1477486, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31722, "number_of_timesteps": 1482486, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31732, "number_of_timesteps": 1487486, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31742, "number_of_timesteps": 1492295, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31752, "number_of_timesteps": 1497295, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31762, "number_of_timesteps": 1502295, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31772, "number_of_timesteps": 1507295, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31782, "number_of_timesteps": 1512295, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31792, "number_of_timesteps": 1517295, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31802, "number_of_timesteps": 1522295, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31812, "number_of_timesteps": 1527295, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31822, "number_of_timesteps": 1532295, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31832, "number_of_timesteps": 1537295, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31842, "number_of_timesteps": 1542094, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31852, "number_of_timesteps": 1547094, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31862, "number_of_timesteps": 1552094, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31872, "number_of_timesteps": 1557094, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31882, "number_of_timesteps": 1562043, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31892, "number_of_timesteps": 1566867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31902, "number_of_timesteps": 1571867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31912, "number_of_timesteps": 1576867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31922, "number_of_timesteps": 1581867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31932, "number_of_timesteps": 1586867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31942, "number_of_timesteps": 1591867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31952, "number_of_timesteps": 1596867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31962, "number_of_timesteps": 1601867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31972, "number_of_timesteps": 1606867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31982, "number_of_timesteps": 1611867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 31992, "number_of_timesteps": 1616867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32002, "number_of_timesteps": 1621867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32012, "number_of_timesteps": 1626867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32022, "number_of_timesteps": 1631867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32032, "number_of_timesteps": 1636867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32042, "number_of_timesteps": 1641867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32052, "number_of_timesteps": 1646867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32062, "number_of_timesteps": 1651867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32072, "number_of_timesteps": 1656867, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32082, "number_of_timesteps": 1661684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32092, "number_of_timesteps": 1666684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32102, "number_of_timesteps": 1671684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32112, "number_of_timesteps": 1676684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32122, "number_of_timesteps": 1681684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32132, "number_of_timesteps": 1686684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32142, "number_of_timesteps": 1691684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32152, "number_of_timesteps": 1696684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32162, "number_of_timesteps": 1701684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32172, "number_of_timesteps": 1706684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32182, "number_of_timesteps": 1711684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32192, "number_of_timesteps": 1716684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32202, "number_of_timesteps": 1721684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32212, "number_of_timesteps": 1726684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32222, "number_of_timesteps": 1731684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32232, "number_of_timesteps": 1736684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32242, "number_of_timesteps": 1741684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32252, "number_of_timesteps": 1746684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32262, "number_of_timesteps": 1751684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32272, "number_of_timesteps": 1756684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32282, "number_of_timesteps": 1761684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32292, "number_of_timesteps": 1766684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32302, "number_of_timesteps": 1771684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32312, "number_of_timesteps": 1776684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32322, "number_of_timesteps": 1781684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32332, "number_of_timesteps": 1786684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32342, "number_of_timesteps": 1791684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32352, "number_of_timesteps": 1796684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32362, "number_of_timesteps": 1801684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32372, "number_of_timesteps": 1806684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32382, "number_of_timesteps": 1811684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32392, "number_of_timesteps": 1816684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32402, "number_of_timesteps": 1821684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32412, "number_of_timesteps": 1826684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32422, "number_of_timesteps": 1831684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32432, "number_of_timesteps": 1836684, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32442, "number_of_timesteps": 1841684, "per_episode_reward": 13.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 32452, "number_of_timesteps": 1846684, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32462, "number_of_timesteps": 1851684, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32472, "number_of_timesteps": 1856684, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32482, "number_of_timesteps": 1861684, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32492, "number_of_timesteps": 1866684, "per_episode_reward": 13.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32502, "number_of_timesteps": 1871684, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32512, "number_of_timesteps": 1876684, "per_episode_reward": 13.55, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32522, "number_of_timesteps": 1881684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32532, "number_of_timesteps": 1886684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32542, "number_of_timesteps": 1891684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32552, "number_of_timesteps": 1896684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32562, "number_of_timesteps": 1901684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32572, "number_of_timesteps": 1906684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32582, "number_of_timesteps": 1911684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32592, "number_of_timesteps": 1916684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32602, "number_of_timesteps": 1921684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 32612, "number_of_timesteps": 1926684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32622, "number_of_timesteps": 1931684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32632, "number_of_timesteps": 1936684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32642, "number_of_timesteps": 1941684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32652, "number_of_timesteps": 1946684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32662, "number_of_timesteps": 1951684, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32672, "number_of_timesteps": 1956563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32682, "number_of_timesteps": 1961563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32692, "number_of_timesteps": 1966563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32702, "number_of_timesteps": 1971563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32712, "number_of_timesteps": 1976563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32722, "number_of_timesteps": 1981563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32732, "number_of_timesteps": 1986563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32742, "number_of_timesteps": 1991563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32752, "number_of_timesteps": 1996563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32762, "number_of_timesteps": 2001563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32772, "number_of_timesteps": 2006563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32782, "number_of_timesteps": 2011563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32792, "number_of_timesteps": 2016563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32802, "number_of_timesteps": 2021563, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32812, "number_of_timesteps": 2026563, "per_episode_reward": 13.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32822, "number_of_timesteps": 2031563, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32832, "number_of_timesteps": 2036563, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32842, "number_of_timesteps": 2041563, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32852, "number_of_timesteps": 2046563, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32862, "number_of_timesteps": 2051563, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32872, "number_of_timesteps": 2056563, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32882, "number_of_timesteps": 2061563, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32892, "number_of_timesteps": 2066436, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 32902, "number_of_timesteps": 2071017, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 32912, "number_of_timesteps": 2076017, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32922, "number_of_timesteps": 2081017, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32932, "number_of_timesteps": 2086017, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32942, "number_of_timesteps": 2091017, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32952, "number_of_timesteps": 2095981, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32962, "number_of_timesteps": 2100743, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32972, "number_of_timesteps": 2105743, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32982, "number_of_timesteps": 2110743, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 32992, "number_of_timesteps": 2115743, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33002, "number_of_timesteps": 2120743, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33012, "number_of_timesteps": 2125743, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33022, "number_of_timesteps": 2130743, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33032, "number_of_timesteps": 2135743, "per_episode_reward": 13.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33042, "number_of_timesteps": 2140743, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33052, "number_of_timesteps": 2145743, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33062, "number_of_timesteps": 2150743, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33072, "number_of_timesteps": 2155743, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33082, "number_of_timesteps": 2160743, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33092, "number_of_timesteps": 2165469, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33102, "number_of_timesteps": 2170469, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33112, "number_of_timesteps": 2175469, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33122, "number_of_timesteps": 2180469, "per_episode_reward": 13.85, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33132, "number_of_timesteps": 2185469, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33142, "number_of_timesteps": 2190149, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33152, "number_of_timesteps": 2194989, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33162, "number_of_timesteps": 2199989, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33172, "number_of_timesteps": 2204989, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33182, "number_of_timesteps": 2209989, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33192, "number_of_timesteps": 2214724, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33202, "number_of_timesteps": 2219724, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33212, "number_of_timesteps": 2224724, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33222, "number_of_timesteps": 2229724, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33232, "number_of_timesteps": 2234724, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33242, "number_of_timesteps": 2239724, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33252, "number_of_timesteps": 2244724, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33262, "number_of_timesteps": 2249693, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33272, "number_of_timesteps": 2254693, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33282, "number_of_timesteps": 2259693, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33292, "number_of_timesteps": 2264693, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33302, "number_of_timesteps": 2269693, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33312, "number_of_timesteps": 2274693, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33322, "number_of_timesteps": 2279693, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33332, "number_of_timesteps": 2284693, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33342, "number_of_timesteps": 2289693, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33352, "number_of_timesteps": 2294693, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33362, "number_of_timesteps": 2299460, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33372, "number_of_timesteps": 2304460, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33382, "number_of_timesteps": 2309460, "per_episode_reward": 13.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 33392, "number_of_timesteps": 2314242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33402, "number_of_timesteps": 2319242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33412, "number_of_timesteps": 2324242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33422, "number_of_timesteps": 2329242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33432, "number_of_timesteps": 2334242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33442, "number_of_timesteps": 2339242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33452, "number_of_timesteps": 2344242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33462, "number_of_timesteps": 2349242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33472, "number_of_timesteps": 2354242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 33482, "number_of_timesteps": 2359242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33492, "number_of_timesteps": 2364242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33502, "number_of_timesteps": 2369242, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33512, "number_of_timesteps": 2374223, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33522, "number_of_timesteps": 2379223, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33532, "number_of_timesteps": 2384223, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33542, "number_of_timesteps": 2389223, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33552, "number_of_timesteps": 2394223, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33562, "number_of_timesteps": 2399223, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33572, "number_of_timesteps": 2404223, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33582, "number_of_timesteps": 2408869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33592, "number_of_timesteps": 2413869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33602, "number_of_timesteps": 2418869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33612, "number_of_timesteps": 2423869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33622, "number_of_timesteps": 2428869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33632, "number_of_timesteps": 2433869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33642, "number_of_timesteps": 2438869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33652, "number_of_timesteps": 2443869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33662, "number_of_timesteps": 2448869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33672, "number_of_timesteps": 2453869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33682, "number_of_timesteps": 2458869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33692, "number_of_timesteps": 2463869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33702, "number_of_timesteps": 2468869, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33712, "number_of_timesteps": 2473537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33722, "number_of_timesteps": 2478537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33732, "number_of_timesteps": 2483537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33742, "number_of_timesteps": 2488537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33752, "number_of_timesteps": 2493537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33762, "number_of_timesteps": 2498537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33772, "number_of_timesteps": 2503537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33782, "number_of_timesteps": 2508537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33792, "number_of_timesteps": 2513537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33802, "number_of_timesteps": 2518537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33812, "number_of_timesteps": 2523537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33822, "number_of_timesteps": 2528537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33832, "number_of_timesteps": 2533537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33842, "number_of_timesteps": 2538537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33852, "number_of_timesteps": 2543537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33862, "number_of_timesteps": 2548537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33872, "number_of_timesteps": 2553537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33882, "number_of_timesteps": 2558537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33892, "number_of_timesteps": 2563537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33902, "number_of_timesteps": 2568537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33912, "number_of_timesteps": 2573537, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33922, "number_of_timesteps": 2578225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33932, "number_of_timesteps": 2583225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33942, "number_of_timesteps": 2588225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33952, "number_of_timesteps": 2593225, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33962, "number_of_timesteps": 2597841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33972, "number_of_timesteps": 2602841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33982, "number_of_timesteps": 2607841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 33992, "number_of_timesteps": 2612841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34002, "number_of_timesteps": 2617841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34012, "number_of_timesteps": 2622841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34022, "number_of_timesteps": 2627841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34032, "number_of_timesteps": 2632841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34042, "number_of_timesteps": 2637841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34052, "number_of_timesteps": 2642841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34062, "number_of_timesteps": 2647841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34072, "number_of_timesteps": 2652841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34082, "number_of_timesteps": 2657841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34092, "number_of_timesteps": 2662841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34102, "number_of_timesteps": 2667841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34112, "number_of_timesteps": 2672841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34122, "number_of_timesteps": 2677841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34132, "number_of_timesteps": 2682841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34142, "number_of_timesteps": 2687841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34152, "number_of_timesteps": 2692841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34162, "number_of_timesteps": 2697841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34172, "number_of_timesteps": 2702841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34182, "number_of_timesteps": 2707841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34192, "number_of_timesteps": 2712841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34202, "number_of_timesteps": 2717841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34212, "number_of_timesteps": 2722841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34222, "number_of_timesteps": 2727841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34232, "number_of_timesteps": 2732841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34242, "number_of_timesteps": 2737841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34252, "number_of_timesteps": 2742841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34262, "number_of_timesteps": 2747841, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34272, "number_of_timesteps": 2752621, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34282, "number_of_timesteps": 2757516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34292, "number_of_timesteps": 2762516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34302, "number_of_timesteps": 2767516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34312, "number_of_timesteps": 2772516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34322, "number_of_timesteps": 2777516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34332, "number_of_timesteps": 2782516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34342, "number_of_timesteps": 2787516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34352, "number_of_timesteps": 2792516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34362, "number_of_timesteps": 2797516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34372, "number_of_timesteps": 2802516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34382, "number_of_timesteps": 2807516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34392, "number_of_timesteps": 2812516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34402, "number_of_timesteps": 2817516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34412, "number_of_timesteps": 2822516, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34422, "number_of_timesteps": 2827516, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 34432, "number_of_timesteps": 2832516, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 34442, "number_of_timesteps": 2837516, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 34452, "number_of_timesteps": 2842516, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 34462, "number_of_timesteps": 2847516, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 34472, "number_of_timesteps": 2852516, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 34482, "number_of_timesteps": 2857363, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 34492, "number_of_timesteps": 2862162, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 34502, "number_of_timesteps": 2867162, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 34512, "number_of_timesteps": 2872162, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 34522, "number_of_timesteps": 2876797, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34532, "number_of_timesteps": 2881797, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34542, "number_of_timesteps": 2886797, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34552, "number_of_timesteps": 2891797, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34562, "number_of_timesteps": 2896797, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34572, "number_of_timesteps": 2901797, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34582, "number_of_timesteps": 2906797, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34592, "number_of_timesteps": 2911797, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34602, "number_of_timesteps": 2916797, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34612, "number_of_timesteps": 2921797, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34622, "number_of_timesteps": 2926797, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 34632, "number_of_timesteps": 2931797, "per_episode_reward": 14.25, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 34642, "number_of_timesteps": 2936797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 34652, "number_of_timesteps": 2941797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 34662, "number_of_timesteps": 2946797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 34672, "number_of_timesteps": 2951797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 34682, "number_of_timesteps": 2956797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 34692, "number_of_timesteps": 2961797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 34702, "number_of_timesteps": 2966797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 34712, "number_of_timesteps": 2971797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 34722, "number_of_timesteps": 2976797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 34732, "number_of_timesteps": 2981797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34742, "number_of_timesteps": 2986797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34752, "number_of_timesteps": 2991797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34762, "number_of_timesteps": 2996797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34772, "number_of_timesteps": 3001797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34782, "number_of_timesteps": 3006797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34792, "number_of_timesteps": 3011797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34802, "number_of_timesteps": 3016797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34812, "number_of_timesteps": 3021797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34822, "number_of_timesteps": 3026797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34832, "number_of_timesteps": 3031797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34842, "number_of_timesteps": 3036797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34852, "number_of_timesteps": 3041797, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34862, "number_of_timesteps": 3046419, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34872, "number_of_timesteps": 3051174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34882, "number_of_timesteps": 3056174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34892, "number_of_timesteps": 3061174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34902, "number_of_timesteps": 3066174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34912, "number_of_timesteps": 3071174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34922, "number_of_timesteps": 3076174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34932, "number_of_timesteps": 3081174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34942, "number_of_timesteps": 3086174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34952, "number_of_timesteps": 3091174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34962, "number_of_timesteps": 3096174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34972, "number_of_timesteps": 3101174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34982, "number_of_timesteps": 3106174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 34992, "number_of_timesteps": 3111174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35002, "number_of_timesteps": 3116174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35012, "number_of_timesteps": 3121174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35022, "number_of_timesteps": 3126174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35032, "number_of_timesteps": 3131174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35042, "number_of_timesteps": 3136174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35052, "number_of_timesteps": 3141174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35062, "number_of_timesteps": 3146174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35072, "number_of_timesteps": 3151174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35082, "number_of_timesteps": 3156174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35092, "number_of_timesteps": 3161174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35102, "number_of_timesteps": 3166174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35112, "number_of_timesteps": 3171174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35122, "number_of_timesteps": 3176174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35132, "number_of_timesteps": 3181174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35142, "number_of_timesteps": 3186174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35152, "number_of_timesteps": 3191174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35162, "number_of_timesteps": 3196174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35172, "number_of_timesteps": 3201174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35182, "number_of_timesteps": 3206174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35192, "number_of_timesteps": 3211174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35202, "number_of_timesteps": 3216174, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35212, "number_of_timesteps": 3221174, "per_episode_reward": 14.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 35222, "number_of_timesteps": 3225802, "per_episode_reward": 14.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 35232, "number_of_timesteps": 3230802, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 35242, "number_of_timesteps": 3235802, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 35252, "number_of_timesteps": 3240520, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 35262, "number_of_timesteps": 3245520, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 35272, "number_of_timesteps": 3250520, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 35282, "number_of_timesteps": 3255520, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 35292, "number_of_timesteps": 3260520, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 35302, "number_of_timesteps": 3265520, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 35312, "number_of_timesteps": 3270520, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35322, "number_of_timesteps": 3275520, "per_episode_reward": 14.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35332, "number_of_timesteps": 3280061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35342, "number_of_timesteps": 3285061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35352, "number_of_timesteps": 3290061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35362, "number_of_timesteps": 3295061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35372, "number_of_timesteps": 3300061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35382, "number_of_timesteps": 3305061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35392, "number_of_timesteps": 3310061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35402, "number_of_timesteps": 3315061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35412, "number_of_timesteps": 3320061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 35422, "number_of_timesteps": 3325061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35432, "number_of_timesteps": 3330061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35442, "number_of_timesteps": 3335061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35452, "number_of_timesteps": 3340061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35462, "number_of_timesteps": 3345061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35472, "number_of_timesteps": 3350061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35482, "number_of_timesteps": 3355061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35492, "number_of_timesteps": 3360061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35502, "number_of_timesteps": 3365061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35512, "number_of_timesteps": 3370061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35522, "number_of_timesteps": 3375061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35532, "number_of_timesteps": 3380061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35542, "number_of_timesteps": 3385061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35552, "number_of_timesteps": 3390061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35562, "number_of_timesteps": 3395061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35572, "number_of_timesteps": 3400061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35582, "number_of_timesteps": 3405061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35592, "number_of_timesteps": 3410061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35602, "number_of_timesteps": 3415061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35612, "number_of_timesteps": 3420061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35622, "number_of_timesteps": 3425061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35632, "number_of_timesteps": 3430061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35642, "number_of_timesteps": 3435061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35652, "number_of_timesteps": 3440061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35662, "number_of_timesteps": 3445061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35672, "number_of_timesteps": 3450061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35682, "number_of_timesteps": 3455061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35692, "number_of_timesteps": 3460061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35702, "number_of_timesteps": 3465061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35712, "number_of_timesteps": 3470061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35722, "number_of_timesteps": 3475061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35732, "number_of_timesteps": 3480061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35742, "number_of_timesteps": 3485061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35752, "number_of_timesteps": 3490061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35762, "number_of_timesteps": 3495061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35772, "number_of_timesteps": 3500061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35782, "number_of_timesteps": 3505061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35792, "number_of_timesteps": 3510061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35802, "number_of_timesteps": 3515061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35812, "number_of_timesteps": 3520061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35822, "number_of_timesteps": 3525061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35832, "number_of_timesteps": 3530061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35842, "number_of_timesteps": 3535061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35852, "number_of_timesteps": 3540061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35862, "number_of_timesteps": 3545061, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35872, "number_of_timesteps": 3549778, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35882, "number_of_timesteps": 3554778, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35892, "number_of_timesteps": 3559435, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35902, "number_of_timesteps": 3564435, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35912, "number_of_timesteps": 3569435, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35922, "number_of_timesteps": 3574435, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 35932, "number_of_timesteps": 3579435, "per_episode_reward": 14.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35942, "number_of_timesteps": 3584435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35952, "number_of_timesteps": 3589435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35962, "number_of_timesteps": 3594435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35972, "number_of_timesteps": 3599435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35982, "number_of_timesteps": 3604435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 35992, "number_of_timesteps": 3609435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36002, "number_of_timesteps": 3614435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36012, "number_of_timesteps": 3619435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36022, "number_of_timesteps": 3624435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 36032, "number_of_timesteps": 3629435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36042, "number_of_timesteps": 3634435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36052, "number_of_timesteps": 3639435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36062, "number_of_timesteps": 3644435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36072, "number_of_timesteps": 3649435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36082, "number_of_timesteps": 3654435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36092, "number_of_timesteps": 3659435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36102, "number_of_timesteps": 3664435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36112, "number_of_timesteps": 3669435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36122, "number_of_timesteps": 3674435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36132, "number_of_timesteps": 3679435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36142, "number_of_timesteps": 3684435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36152, "number_of_timesteps": 3689435, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36162, "number_of_timesteps": 3694247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36172, "number_of_timesteps": 3699247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36182, "number_of_timesteps": 3704247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36192, "number_of_timesteps": 3709247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36202, "number_of_timesteps": 3714247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36212, "number_of_timesteps": 3719247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36222, "number_of_timesteps": 3724247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36232, "number_of_timesteps": 3729247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36242, "number_of_timesteps": 3734247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36252, "number_of_timesteps": 3739247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36262, "number_of_timesteps": 3744247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36272, "number_of_timesteps": 3749247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36282, "number_of_timesteps": 3754247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36292, "number_of_timesteps": 3759247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36302, "number_of_timesteps": 3764247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36312, "number_of_timesteps": 3769247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36322, "number_of_timesteps": 3774247, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36332, "number_of_timesteps": 3779247, "per_episode_reward": 14.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36342, "number_of_timesteps": 3784247, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36352, "number_of_timesteps": 3789247, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36362, "number_of_timesteps": 3794247, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36372, "number_of_timesteps": 3799247, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36382, "number_of_timesteps": 3804247, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36392, "number_of_timesteps": 3809247, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36402, "number_of_timesteps": 3814247, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36412, "number_of_timesteps": 3819247, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36422, "number_of_timesteps": 3824247, "per_episode_reward": 14.85, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36432, "number_of_timesteps": 3829247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36442, "number_of_timesteps": 3834247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36452, "number_of_timesteps": 3839247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36462, "number_of_timesteps": 3844247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36472, "number_of_timesteps": 3849247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36482, "number_of_timesteps": 3854247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36492, "number_of_timesteps": 3859247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36502, "number_of_timesteps": 3864247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36512, "number_of_timesteps": 3869247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36522, "number_of_timesteps": 3874247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36532, "number_of_timesteps": 3879247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36542, "number_of_timesteps": 3884247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36552, "number_of_timesteps": 3889247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36562, "number_of_timesteps": 3894247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36572, "number_of_timesteps": 3899247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36582, "number_of_timesteps": 3904247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36592, "number_of_timesteps": 3909247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36602, "number_of_timesteps": 3914247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36612, "number_of_timesteps": 3919247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36622, "number_of_timesteps": 3924247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36632, "number_of_timesteps": 3929247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36642, "number_of_timesteps": 3934247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36652, "number_of_timesteps": 3939247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36662, "number_of_timesteps": 3944247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36672, "number_of_timesteps": 3949247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36682, "number_of_timesteps": 3954247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36692, "number_of_timesteps": 3959247, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36702, "number_of_timesteps": 3964247, "per_episode_reward": 14.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 36712, "number_of_timesteps": 3969247, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36722, "number_of_timesteps": 3974247, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36732, "number_of_timesteps": 3979247, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36742, "number_of_timesteps": 3984247, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36752, "number_of_timesteps": 3989247, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36762, "number_of_timesteps": 3994247, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36772, "number_of_timesteps": 3999247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36782, "number_of_timesteps": 4004247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36792, "number_of_timesteps": 4009247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36802, "number_of_timesteps": 4014247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36812, "number_of_timesteps": 4019247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36822, "number_of_timesteps": 4024247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36832, "number_of_timesteps": 4029247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36842, "number_of_timesteps": 4034247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 36852, "number_of_timesteps": 4039247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 36862, "number_of_timesteps": 4044247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36872, "number_of_timesteps": 4049247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36882, "number_of_timesteps": 4054247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36892, "number_of_timesteps": 4059247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36902, "number_of_timesteps": 4064247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36912, "number_of_timesteps": 4069247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36922, "number_of_timesteps": 4074247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36932, "number_of_timesteps": 4079247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36942, "number_of_timesteps": 4084247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36952, "number_of_timesteps": 4089247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36962, "number_of_timesteps": 4094247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36972, "number_of_timesteps": 4099247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36982, "number_of_timesteps": 4104247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 36992, "number_of_timesteps": 4109247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37002, "number_of_timesteps": 4114247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37012, "number_of_timesteps": 4119247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37022, "number_of_timesteps": 4124247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37032, "number_of_timesteps": 4129247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37042, "number_of_timesteps": 4134247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37052, "number_of_timesteps": 4139247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37062, "number_of_timesteps": 4144247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37072, "number_of_timesteps": 4149247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37082, "number_of_timesteps": 4154247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37092, "number_of_timesteps": 4159247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37102, "number_of_timesteps": 4164247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37112, "number_of_timesteps": 4169247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37122, "number_of_timesteps": 4174247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37132, "number_of_timesteps": 4179247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37142, "number_of_timesteps": 4184247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37152, "number_of_timesteps": 4189247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37162, "number_of_timesteps": 4194247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37172, "number_of_timesteps": 4199247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37182, "number_of_timesteps": 4204247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37192, "number_of_timesteps": 4209247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37202, "number_of_timesteps": 4214247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37212, "number_of_timesteps": 4219247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37222, "number_of_timesteps": 4224247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37232, "number_of_timesteps": 4229247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37242, "number_of_timesteps": 4234247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37252, "number_of_timesteps": 4239247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37262, "number_of_timesteps": 4244247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37272, "number_of_timesteps": 4249247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37282, "number_of_timesteps": 4254247, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37292, "number_of_timesteps": 4259247, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37302, "number_of_timesteps": 4264247, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37312, "number_of_timesteps": 4269247, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37322, "number_of_timesteps": 4274247, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37332, "number_of_timesteps": 4279247, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37342, "number_of_timesteps": 4284247, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37352, "number_of_timesteps": 4288785, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37362, "number_of_timesteps": 4293785, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37372, "number_of_timesteps": 4298568, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37382, "number_of_timesteps": 4303568, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37392, "number_of_timesteps": 4308106, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37402, "number_of_timesteps": 4312683, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37412, "number_of_timesteps": 4317566, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37422, "number_of_timesteps": 4322566, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37432, "number_of_timesteps": 4327566, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37442, "number_of_timesteps": 4331983, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37452, "number_of_timesteps": 4336983, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37462, "number_of_timesteps": 4341983, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37472, "number_of_timesteps": 4346983, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37482, "number_of_timesteps": 4351983, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37492, "number_of_timesteps": 4356983, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37502, "number_of_timesteps": 4361983, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37512, "number_of_timesteps": 4366983, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37522, "number_of_timesteps": 4371741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37532, "number_of_timesteps": 4376741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37542, "number_of_timesteps": 4381741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37552, "number_of_timesteps": 4386741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37562, "number_of_timesteps": 4391741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37572, "number_of_timesteps": 4396741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37582, "number_of_timesteps": 4401741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37592, "number_of_timesteps": 4406741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37602, "number_of_timesteps": 4411741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37612, "number_of_timesteps": 4416741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37622, "number_of_timesteps": 4421741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37632, "number_of_timesteps": 4426741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37642, "number_of_timesteps": 4431741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37652, "number_of_timesteps": 4436741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37662, "number_of_timesteps": 4441741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37672, "number_of_timesteps": 4446741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37682, "number_of_timesteps": 4451741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37692, "number_of_timesteps": 4456741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37702, "number_of_timesteps": 4461741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37712, "number_of_timesteps": 4466741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37722, "number_of_timesteps": 4471741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37732, "number_of_timesteps": 4476741, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37742, "number_of_timesteps": 4481741, "per_episode_reward": 15.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 37752, "number_of_timesteps": 4486741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37762, "number_of_timesteps": 4491741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37772, "number_of_timesteps": 4496741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37782, "number_of_timesteps": 4501741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37792, "number_of_timesteps": 4506741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37802, "number_of_timesteps": 4511741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37812, "number_of_timesteps": 4516741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37822, "number_of_timesteps": 4521741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37832, "number_of_timesteps": 4526741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 37842, "number_of_timesteps": 4531741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37852, "number_of_timesteps": 4536741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37862, "number_of_timesteps": 4541741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37872, "number_of_timesteps": 4546741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37882, "number_of_timesteps": 4551741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37892, "number_of_timesteps": 4556741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37902, "number_of_timesteps": 4561741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37912, "number_of_timesteps": 4566741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37922, "number_of_timesteps": 4571741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37932, "number_of_timesteps": 4576741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37942, "number_of_timesteps": 4581741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37952, "number_of_timesteps": 4586741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37962, "number_of_timesteps": 4591741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37972, "number_of_timesteps": 4596741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37982, "number_of_timesteps": 4601741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 37992, "number_of_timesteps": 4606741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38002, "number_of_timesteps": 4611741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38012, "number_of_timesteps": 4616741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38022, "number_of_timesteps": 4621741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38032, "number_of_timesteps": 4626741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38042, "number_of_timesteps": 4631741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38052, "number_of_timesteps": 4636741, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38062, "number_of_timesteps": 4641741, "per_episode_reward": 15.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 38072, "number_of_timesteps": 4646741, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38082, "number_of_timesteps": 4651741, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38092, "number_of_timesteps": 4656741, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38102, "number_of_timesteps": 4661741, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38112, "number_of_timesteps": 4666741, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38122, "number_of_timesteps": 4671741, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38132, "number_of_timesteps": 4676741, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38142, "number_of_timesteps": 4681741, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38152, "number_of_timesteps": 4686741, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38162, "number_of_timesteps": 4691741, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38172, "number_of_timesteps": 4696741, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38182, "number_of_timesteps": 4701741, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38192, "number_of_timesteps": 4706741, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38202, "number_of_timesteps": 4711741, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38212, "number_of_timesteps": 4716741, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38222, "number_of_timesteps": 4721741, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38232, "number_of_timesteps": 4726741, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38242, "number_of_timesteps": 4731741, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38252, "number_of_timesteps": 4736741, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38262, "number_of_timesteps": 4741741, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 38272, "number_of_timesteps": 4746741, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38282, "number_of_timesteps": 4751741, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38292, "number_of_timesteps": 4756741, "per_episode_reward": 15.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38302, "number_of_timesteps": 4761741, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38312, "number_of_timesteps": 4766741, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38322, "number_of_timesteps": 4771741, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38332, "number_of_timesteps": 4776741, "per_episode_reward": 15.75, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38342, "number_of_timesteps": 4781741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38352, "number_of_timesteps": 4786741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38362, "number_of_timesteps": 4791741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38372, "number_of_timesteps": 4796741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38382, "number_of_timesteps": 4801741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38392, "number_of_timesteps": 4806741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38402, "number_of_timesteps": 4811741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38412, "number_of_timesteps": 4816741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38422, "number_of_timesteps": 4821741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 38432, "number_of_timesteps": 4826741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38442, "number_of_timesteps": 4831741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38452, "number_of_timesteps": 4836741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38462, "number_of_timesteps": 4841741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38472, "number_of_timesteps": 4846741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38482, "number_of_timesteps": 4851741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38492, "number_of_timesteps": 4856741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38502, "number_of_timesteps": 4861741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38512, "number_of_timesteps": 4866741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38522, "number_of_timesteps": 4871741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38532, "number_of_timesteps": 4876741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38542, "number_of_timesteps": 4881741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38552, "number_of_timesteps": 4886741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38562, "number_of_timesteps": 4891741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38572, "number_of_timesteps": 4896741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38582, "number_of_timesteps": 4901741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38592, "number_of_timesteps": 4906741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38602, "number_of_timesteps": 4911741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38612, "number_of_timesteps": 4916741, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38622, "number_of_timesteps": 4921741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 38632, "number_of_timesteps": 4926741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 38642, "number_of_timesteps": 4931741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 38652, "number_of_timesteps": 4936741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 38662, "number_of_timesteps": 4941741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 38672, "number_of_timesteps": 4946741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 38682, "number_of_timesteps": 4951741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 38692, "number_of_timesteps": 4956741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 38702, "number_of_timesteps": 4961741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 38712, "number_of_timesteps": 4966741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38722, "number_of_timesteps": 4971741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38732, "number_of_timesteps": 4976741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38742, "number_of_timesteps": 4981741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38752, "number_of_timesteps": 4986741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38762, "number_of_timesteps": 4991741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38772, "number_of_timesteps": 4996741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38782, "number_of_timesteps": 5001741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38792, "number_of_timesteps": 5006741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38802, "number_of_timesteps": 5011741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38812, "number_of_timesteps": 5016741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38822, "number_of_timesteps": 5021741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38832, "number_of_timesteps": 5026741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38842, "number_of_timesteps": 5031741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38852, "number_of_timesteps": 5036741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38862, "number_of_timesteps": 5041741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38872, "number_of_timesteps": 5046741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38882, "number_of_timesteps": 5051741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38892, "number_of_timesteps": 5056741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38902, "number_of_timesteps": 5061741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38912, "number_of_timesteps": 5066741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38922, "number_of_timesteps": 5071741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38932, "number_of_timesteps": 5076741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38942, "number_of_timesteps": 5081741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38952, "number_of_timesteps": 5086741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38962, "number_of_timesteps": 5091741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38972, "number_of_timesteps": 5096741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38982, "number_of_timesteps": 5101741, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 38992, "number_of_timesteps": 5106741, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 39002, "number_of_timesteps": 5111741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39012, "number_of_timesteps": 5116741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39022, "number_of_timesteps": 5121741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39032, "number_of_timesteps": 5126741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39042, "number_of_timesteps": 5131741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39052, "number_of_timesteps": 5136741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39062, "number_of_timesteps": 5141741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39072, "number_of_timesteps": 5146741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39082, "number_of_timesteps": 5151741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39092, "number_of_timesteps": 5156741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39102, "number_of_timesteps": 5161741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39112, "number_of_timesteps": 5166741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39122, "number_of_timesteps": 5171741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39132, "number_of_timesteps": 5176741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39142, "number_of_timesteps": 5181741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39152, "number_of_timesteps": 5186741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39162, "number_of_timesteps": 5191741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39172, "number_of_timesteps": 5196741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39182, "number_of_timesteps": 5201741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39192, "number_of_timesteps": 5206741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39202, "number_of_timesteps": 5211741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39212, "number_of_timesteps": 5216741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39222, "number_of_timesteps": 5221741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39232, "number_of_timesteps": 5226741, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39242, "number_of_timesteps": 5231741, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39252, "number_of_timesteps": 5236741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39262, "number_of_timesteps": 5241741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39272, "number_of_timesteps": 5246741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39282, "number_of_timesteps": 5251741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39292, "number_of_timesteps": 5256741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39302, "number_of_timesteps": 5261741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39312, "number_of_timesteps": 5266741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39322, "number_of_timesteps": 5271741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39332, "number_of_timesteps": 5276741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39342, "number_of_timesteps": 5281741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39352, "number_of_timesteps": 5286741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39362, "number_of_timesteps": 5291741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39372, "number_of_timesteps": 5296741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39382, "number_of_timesteps": 5301741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39392, "number_of_timesteps": 5306741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39402, "number_of_timesteps": 5311741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39412, "number_of_timesteps": 5316741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39422, "number_of_timesteps": 5321741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39432, "number_of_timesteps": 5326741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39442, "number_of_timesteps": 5331741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39452, "number_of_timesteps": 5336741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39462, "number_of_timesteps": 5341741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39472, "number_of_timesteps": 5346741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39482, "number_of_timesteps": 5351741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39492, "number_of_timesteps": 5356741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39502, "number_of_timesteps": 5361741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39512, "number_of_timesteps": 5366741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39522, "number_of_timesteps": 5371741, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39532, "number_of_timesteps": 5376741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 39542, "number_of_timesteps": 5381741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 39552, "number_of_timesteps": 5386741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 39562, "number_of_timesteps": 5391741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 39572, "number_of_timesteps": 5396741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 39582, "number_of_timesteps": 5401741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 39592, "number_of_timesteps": 5406741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 39602, "number_of_timesteps": 5411741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 39612, "number_of_timesteps": 5416741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 39622, "number_of_timesteps": 5421741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39632, "number_of_timesteps": 5426741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39642, "number_of_timesteps": 5431741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39652, "number_of_timesteps": 5436741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39662, "number_of_timesteps": 5441741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39672, "number_of_timesteps": 5446741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39682, "number_of_timesteps": 5451741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39692, "number_of_timesteps": 5456741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39702, "number_of_timesteps": 5461741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39712, "number_of_timesteps": 5466741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39722, "number_of_timesteps": 5471741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39732, "number_of_timesteps": 5476741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39742, "number_of_timesteps": 5481741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39752, "number_of_timesteps": 5486741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39762, "number_of_timesteps": 5491741, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39772, "number_of_timesteps": 5496741, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39782, "number_of_timesteps": 5501741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39792, "number_of_timesteps": 5506741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39802, "number_of_timesteps": 5511741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39812, "number_of_timesteps": 5516741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39822, "number_of_timesteps": 5521741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39832, "number_of_timesteps": 5526741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39842, "number_of_timesteps": 5531741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39852, "number_of_timesteps": 5536741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39862, "number_of_timesteps": 5541741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 39872, "number_of_timesteps": 5546741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39882, "number_of_timesteps": 5551741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39892, "number_of_timesteps": 5556741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39902, "number_of_timesteps": 5561741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39912, "number_of_timesteps": 5566741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39922, "number_of_timesteps": 5571741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39932, "number_of_timesteps": 5576741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39942, "number_of_timesteps": 5581741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39952, "number_of_timesteps": 5586741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39962, "number_of_timesteps": 5591741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39972, "number_of_timesteps": 5596741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39982, "number_of_timesteps": 5601741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 39992, "number_of_timesteps": 5606741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40002, "number_of_timesteps": 5611741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40012, "number_of_timesteps": 5616741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40022, "number_of_timesteps": 5621741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40032, "number_of_timesteps": 5626741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40042, "number_of_timesteps": 5631741, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40052, "number_of_timesteps": 5636741, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40062, "number_of_timesteps": 5641741, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40072, "number_of_timesteps": 5646741, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40082, "number_of_timesteps": 5651741, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40092, "number_of_timesteps": 5656741, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40102, "number_of_timesteps": 5661741, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40112, "number_of_timesteps": 5666741, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40122, "number_of_timesteps": 5671741, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40132, "number_of_timesteps": 5676741, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40142, "number_of_timesteps": 5681741, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 40152, "number_of_timesteps": 5686741, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40162, "number_of_timesteps": 5691741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40172, "number_of_timesteps": 5696741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40182, "number_of_timesteps": 5701741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40192, "number_of_timesteps": 5706741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40202, "number_of_timesteps": 5711741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40212, "number_of_timesteps": 5716741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40222, "number_of_timesteps": 5721741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40232, "number_of_timesteps": 5726741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40242, "number_of_timesteps": 5731741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40252, "number_of_timesteps": 5736741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40262, "number_of_timesteps": 5741741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40272, "number_of_timesteps": 5746741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40282, "number_of_timesteps": 5751741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40292, "number_of_timesteps": 5756741, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40302, "number_of_timesteps": 5761741, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40312, "number_of_timesteps": 5766741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 40322, "number_of_timesteps": 5771741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 40332, "number_of_timesteps": 5776741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 40342, "number_of_timesteps": 5781741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 40352, "number_of_timesteps": 5786741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 40362, "number_of_timesteps": 5791741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 40372, "number_of_timesteps": 5796741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 40382, "number_of_timesteps": 5801741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 40392, "number_of_timesteps": 5806741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 40402, "number_of_timesteps": 5811741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40412, "number_of_timesteps": 5816741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40422, "number_of_timesteps": 5821741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40432, "number_of_timesteps": 5826741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40442, "number_of_timesteps": 5831741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40452, "number_of_timesteps": 5836741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40462, "number_of_timesteps": 5841741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40472, "number_of_timesteps": 5846741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40482, "number_of_timesteps": 5851741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40492, "number_of_timesteps": 5856741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40502, "number_of_timesteps": 5861741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40512, "number_of_timesteps": 5866741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40522, "number_of_timesteps": 5871741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40532, "number_of_timesteps": 5876741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40542, "number_of_timesteps": 5881741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40552, "number_of_timesteps": 5886741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40562, "number_of_timesteps": 5891741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40572, "number_of_timesteps": 5896741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40582, "number_of_timesteps": 5901741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40592, "number_of_timesteps": 5906741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40602, "number_of_timesteps": 5911741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40612, "number_of_timesteps": 5916741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40622, "number_of_timesteps": 5921741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40632, "number_of_timesteps": 5926741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40642, "number_of_timesteps": 5931741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40652, "number_of_timesteps": 5936741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40662, "number_of_timesteps": 5941741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40672, "number_of_timesteps": 5946741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40682, "number_of_timesteps": 5951741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40692, "number_of_timesteps": 5956741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40702, "number_of_timesteps": 5961741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40712, "number_of_timesteps": 5966741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40722, "number_of_timesteps": 5971741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40732, "number_of_timesteps": 5976741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40742, "number_of_timesteps": 5981741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40752, "number_of_timesteps": 5986741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40762, "number_of_timesteps": 5991741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40772, "number_of_timesteps": 5996741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40782, "number_of_timesteps": 6001741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40792, "number_of_timesteps": 6006741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40802, "number_of_timesteps": 6011741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40812, "number_of_timesteps": 6016741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40822, "number_of_timesteps": 6021741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40832, "number_of_timesteps": 6026741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40842, "number_of_timesteps": 6031741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40852, "number_of_timesteps": 6036741, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 40862, "number_of_timesteps": 6041741, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40872, "number_of_timesteps": 6046741, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40882, "number_of_timesteps": 6051741, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40892, "number_of_timesteps": 6056741, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40902, "number_of_timesteps": 6061741, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40912, "number_of_timesteps": 6066741, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40922, "number_of_timesteps": 6071741, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40932, "number_of_timesteps": 6076741, "per_episode_reward": 16.85, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40942, "number_of_timesteps": 6081741, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40952, "number_of_timesteps": 6086741, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40962, "number_of_timesteps": 6091741, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40972, "number_of_timesteps": 6096741, "per_episode_reward": 16.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40982, "number_of_timesteps": 6101741, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 40992, "number_of_timesteps": 6106741, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41002, "number_of_timesteps": 6111741, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41012, "number_of_timesteps": 6116741, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41022, "number_of_timesteps": 6121741, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41032, "number_of_timesteps": 6126741, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41042, "number_of_timesteps": 6131741, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41052, "number_of_timesteps": 6136741, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41062, "number_of_timesteps": 6141741, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41072, "number_of_timesteps": 6146741, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41082, "number_of_timesteps": 6151741, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41092, "number_of_timesteps": 6156741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 41102, "number_of_timesteps": 6161741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 41112, "number_of_timesteps": 6166741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 41122, "number_of_timesteps": 6171741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 41132, "number_of_timesteps": 6176741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 41142, "number_of_timesteps": 6181741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 41152, "number_of_timesteps": 6186741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 41162, "number_of_timesteps": 6191741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 41172, "number_of_timesteps": 6196741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 41182, "number_of_timesteps": 6201741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41192, "number_of_timesteps": 6206741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41202, "number_of_timesteps": 6211741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41212, "number_of_timesteps": 6216741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41222, "number_of_timesteps": 6221741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41232, "number_of_timesteps": 6226741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41242, "number_of_timesteps": 6231741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41252, "number_of_timesteps": 6236741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41262, "number_of_timesteps": 6241741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41272, "number_of_timesteps": 6246741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41282, "number_of_timesteps": 6251741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41292, "number_of_timesteps": 6256741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41302, "number_of_timesteps": 6261741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41312, "number_of_timesteps": 6266741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41322, "number_of_timesteps": 6271741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41332, "number_of_timesteps": 6276741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41342, "number_of_timesteps": 6281741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41352, "number_of_timesteps": 6286741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41362, "number_of_timesteps": 6291741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41372, "number_of_timesteps": 6296741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41382, "number_of_timesteps": 6301741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41392, "number_of_timesteps": 6306741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41402, "number_of_timesteps": 6311741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41412, "number_of_timesteps": 6316741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41422, "number_of_timesteps": 6321741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41432, "number_of_timesteps": 6326741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41442, "number_of_timesteps": 6331741, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41452, "number_of_timesteps": 6336741, "per_episode_reward": 17.15, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 41462, "number_of_timesteps": 6341741, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41472, "number_of_timesteps": 6346741, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41482, "number_of_timesteps": 6351741, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41492, "number_of_timesteps": 6356741, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41502, "number_of_timesteps": 6361741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41512, "number_of_timesteps": 6366741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41522, "number_of_timesteps": 6371741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41532, "number_of_timesteps": 6376741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41542, "number_of_timesteps": 6381741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41552, "number_of_timesteps": 6386741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41562, "number_of_timesteps": 6391741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41572, "number_of_timesteps": 6396741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41582, "number_of_timesteps": 6401741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41592, "number_of_timesteps": 6406741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41602, "number_of_timesteps": 6411741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41612, "number_of_timesteps": 6416741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41622, "number_of_timesteps": 6421741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41632, "number_of_timesteps": 6426741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41642, "number_of_timesteps": 6431741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41652, "number_of_timesteps": 6436741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41662, "number_of_timesteps": 6441741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41672, "number_of_timesteps": 6446741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41682, "number_of_timesteps": 6451741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41692, "number_of_timesteps": 6456741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41702, "number_of_timesteps": 6461741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41712, "number_of_timesteps": 6466741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41722, "number_of_timesteps": 6471741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41732, "number_of_timesteps": 6476741, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41742, "number_of_timesteps": 6481741, "per_episode_reward": 17.35, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41752, "number_of_timesteps": 6486741, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41762, "number_of_timesteps": 6491741, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41772, "number_of_timesteps": 6496741, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41782, "number_of_timesteps": 6501741, "per_episode_reward": 17.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41792, "number_of_timesteps": 6506741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41802, "number_of_timesteps": 6511741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41812, "number_of_timesteps": 6516741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41822, "number_of_timesteps": 6521741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41832, "number_of_timesteps": 6526741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41842, "number_of_timesteps": 6531741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41852, "number_of_timesteps": 6536741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41862, "number_of_timesteps": 6541741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41872, "number_of_timesteps": 6546741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 41882, "number_of_timesteps": 6551741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41892, "number_of_timesteps": 6556741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41902, "number_of_timesteps": 6561741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41912, "number_of_timesteps": 6566741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41922, "number_of_timesteps": 6571741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41932, "number_of_timesteps": 6576741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41942, "number_of_timesteps": 6581741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41952, "number_of_timesteps": 6586741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41962, "number_of_timesteps": 6591741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41972, "number_of_timesteps": 6596741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41982, "number_of_timesteps": 6601741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 41992, "number_of_timesteps": 6606741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42002, "number_of_timesteps": 6611741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42012, "number_of_timesteps": 6616741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42022, "number_of_timesteps": 6621741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42032, "number_of_timesteps": 6626741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42042, "number_of_timesteps": 6631741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42052, "number_of_timesteps": 6636741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42062, "number_of_timesteps": 6641741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42072, "number_of_timesteps": 6646741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42082, "number_of_timesteps": 6651741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42092, "number_of_timesteps": 6656741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42102, "number_of_timesteps": 6661741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42112, "number_of_timesteps": 6666741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42122, "number_of_timesteps": 6671741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42132, "number_of_timesteps": 6676741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42142, "number_of_timesteps": 6681741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42152, "number_of_timesteps": 6686741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42162, "number_of_timesteps": 6691741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42172, "number_of_timesteps": 6696741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42182, "number_of_timesteps": 6701741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42192, "number_of_timesteps": 6706741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42202, "number_of_timesteps": 6711741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42212, "number_of_timesteps": 6716741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42222, "number_of_timesteps": 6721741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42232, "number_of_timesteps": 6726741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42242, "number_of_timesteps": 6731741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42252, "number_of_timesteps": 6736741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42262, "number_of_timesteps": 6741741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42272, "number_of_timesteps": 6746741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42282, "number_of_timesteps": 6751741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42292, "number_of_timesteps": 6756741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42302, "number_of_timesteps": 6761741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42312, "number_of_timesteps": 6766741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42322, "number_of_timesteps": 6771741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42332, "number_of_timesteps": 6776741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42342, "number_of_timesteps": 6781741, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42352, "number_of_timesteps": 6786741, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42362, "number_of_timesteps": 6791741, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42372, "number_of_timesteps": 6796741, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42382, "number_of_timesteps": 6801741, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 42392, "number_of_timesteps": 6806741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42402, "number_of_timesteps": 6811741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42412, "number_of_timesteps": 6816741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42422, "number_of_timesteps": 6821741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42432, "number_of_timesteps": 6826741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42442, "number_of_timesteps": 6831741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42452, "number_of_timesteps": 6836741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42462, "number_of_timesteps": 6841741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42472, "number_of_timesteps": 6846741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42482, "number_of_timesteps": 6851741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42492, "number_of_timesteps": 6856741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42502, "number_of_timesteps": 6861741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42512, "number_of_timesteps": 6866741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42522, "number_of_timesteps": 6871741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42532, "number_of_timesteps": 6876741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42542, "number_of_timesteps": 6881741, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42552, "number_of_timesteps": 6886741, "per_episode_reward": 17.85, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42562, "number_of_timesteps": 6891741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42572, "number_of_timesteps": 6896741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42582, "number_of_timesteps": 6901741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42592, "number_of_timesteps": 6906741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42602, "number_of_timesteps": 6911741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42612, "number_of_timesteps": 6916741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42622, "number_of_timesteps": 6921741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42632, "number_of_timesteps": 6926741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42642, "number_of_timesteps": 6931741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 42652, "number_of_timesteps": 6936741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42662, "number_of_timesteps": 6941741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42672, "number_of_timesteps": 6946741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42682, "number_of_timesteps": 6951741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42692, "number_of_timesteps": 6956741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42702, "number_of_timesteps": 6961741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42712, "number_of_timesteps": 6966741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42722, "number_of_timesteps": 6971741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42732, "number_of_timesteps": 6976741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42742, "number_of_timesteps": 6981741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42752, "number_of_timesteps": 6986741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42762, "number_of_timesteps": 6991741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42772, "number_of_timesteps": 6996741, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42782, "number_of_timesteps": 7001741, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42792, "number_of_timesteps": 7006741, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42802, "number_of_timesteps": 7011741, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42812, "number_of_timesteps": 7016741, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42822, "number_of_timesteps": 7021741, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42832, "number_of_timesteps": 7026741, "per_episode_reward": 18.05, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42842, "number_of_timesteps": 7031741, "per_episode_reward": 18.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42852, "number_of_timesteps": 7036741, "per_episode_reward": 18.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42862, "number_of_timesteps": 7041741, "per_episode_reward": 18.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 42872, "number_of_timesteps": 7046741, "per_episode_reward": 18.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42882, "number_of_timesteps": 7051741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42892, "number_of_timesteps": 7056741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42902, "number_of_timesteps": 7061741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42912, "number_of_timesteps": 7066741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42922, "number_of_timesteps": 7071741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42932, "number_of_timesteps": 7076741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42942, "number_of_timesteps": 7081741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42952, "number_of_timesteps": 7086741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42962, "number_of_timesteps": 7091741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 42972, "number_of_timesteps": 7096741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42982, "number_of_timesteps": 7101741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 42992, "number_of_timesteps": 7106741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43002, "number_of_timesteps": 7111741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43012, "number_of_timesteps": 7116741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43022, "number_of_timesteps": 7121741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43032, "number_of_timesteps": 7126741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43042, "number_of_timesteps": 7131741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43052, "number_of_timesteps": 7136741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43062, "number_of_timesteps": 7141741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43072, "number_of_timesteps": 7146741, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43082, "number_of_timesteps": 7151741, "per_episode_reward": 18.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43092, "number_of_timesteps": 7156741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43102, "number_of_timesteps": 7161741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43112, "number_of_timesteps": 7166741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43122, "number_of_timesteps": 7171741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43132, "number_of_timesteps": 7176741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43142, "number_of_timesteps": 7181741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43152, "number_of_timesteps": 7186741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43162, "number_of_timesteps": 7191741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43172, "number_of_timesteps": 7196741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43182, "number_of_timesteps": 7201741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43192, "number_of_timesteps": 7206741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43202, "number_of_timesteps": 7211741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43212, "number_of_timesteps": 7216741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43222, "number_of_timesteps": 7221741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43232, "number_of_timesteps": 7226741, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43242, "number_of_timesteps": 7231741, "per_episode_reward": 18.35, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43252, "number_of_timesteps": 7236741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43262, "number_of_timesteps": 7241741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43272, "number_of_timesteps": 7246741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43282, "number_of_timesteps": 7251741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43292, "number_of_timesteps": 7256741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43302, "number_of_timesteps": 7261741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43312, "number_of_timesteps": 7266741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43322, "number_of_timesteps": 7271741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43332, "number_of_timesteps": 7276741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 43342, "number_of_timesteps": 7281741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43352, "number_of_timesteps": 7286741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43362, "number_of_timesteps": 7291741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43372, "number_of_timesteps": 7296741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43382, "number_of_timesteps": 7301741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43392, "number_of_timesteps": 7306741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43402, "number_of_timesteps": 7311741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43412, "number_of_timesteps": 7316741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43422, "number_of_timesteps": 7321741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43432, "number_of_timesteps": 7326741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43442, "number_of_timesteps": 7331741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43452, "number_of_timesteps": 7336741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43462, "number_of_timesteps": 7341741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43472, "number_of_timesteps": 7346741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43482, "number_of_timesteps": 7351741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43492, "number_of_timesteps": 7356741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43502, "number_of_timesteps": 7361741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43512, "number_of_timesteps": 7366741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43522, "number_of_timesteps": 7371741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43532, "number_of_timesteps": 7376741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43542, "number_of_timesteps": 7381741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43552, "number_of_timesteps": 7386741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43562, "number_of_timesteps": 7391741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43572, "number_of_timesteps": 7396741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43582, "number_of_timesteps": 7401741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43592, "number_of_timesteps": 7406741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43602, "number_of_timesteps": 7411741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43612, "number_of_timesteps": 7416741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43622, "number_of_timesteps": 7421741, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 43632, "number_of_timesteps": 7426741, "per_episode_reward": 18.45, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43642, "number_of_timesteps": 7431741, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43652, "number_of_timesteps": 7436741, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43662, "number_of_timesteps": 7441741, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43672, "number_of_timesteps": 7446741, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43682, "number_of_timesteps": 7451741, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43692, "number_of_timesteps": 7456741, "per_episode_reward": 18.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43702, "number_of_timesteps": 7461741, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43712, "number_of_timesteps": 7466741, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43722, "number_of_timesteps": 7471741, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43732, "number_of_timesteps": 7476741, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43742, "number_of_timesteps": 7481741, "per_episode_reward": 18.65, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43752, "number_of_timesteps": 7486741, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43762, "number_of_timesteps": 7491741, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43772, "number_of_timesteps": 7496741, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43782, "number_of_timesteps": 7501741, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43792, "number_of_timesteps": 7506741, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43802, "number_of_timesteps": 7511741, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43812, "number_of_timesteps": 7516741, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43822, "number_of_timesteps": 7521741, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43832, "number_of_timesteps": 7526741, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43842, "number_of_timesteps": 7531741, "per_episode_reward": 18.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43852, "number_of_timesteps": 7536741, "per_episode_reward": 18.85, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 43862, "number_of_timesteps": 7541741, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 43872, "number_of_timesteps": 7546741, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 43882, "number_of_timesteps": 7551741, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 43892, "number_of_timesteps": 7556741, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 43902, "number_of_timesteps": 7561741, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 43912, "number_of_timesteps": 7566741, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 43922, "number_of_timesteps": 7571741, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 43932, "number_of_timesteps": 7576741, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 43942, "number_of_timesteps": 7581741, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 43952, "number_of_timesteps": 7586741, "per_episode_reward": 18.95, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43962, "number_of_timesteps": 7591741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43972, "number_of_timesteps": 7596741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43982, "number_of_timesteps": 7601741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 43992, "number_of_timesteps": 7606741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44002, "number_of_timesteps": 7611741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44012, "number_of_timesteps": 7616741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44022, "number_of_timesteps": 7621741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44032, "number_of_timesteps": 7626741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44042, "number_of_timesteps": 7631741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44052, "number_of_timesteps": 7636741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44062, "number_of_timesteps": 7641741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44072, "number_of_timesteps": 7646741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44082, "number_of_timesteps": 7651741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44092, "number_of_timesteps": 7656741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44102, "number_of_timesteps": 7661741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44112, "number_of_timesteps": 7666741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44122, "number_of_timesteps": 7671741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44132, "number_of_timesteps": 7676741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44142, "number_of_timesteps": 7681741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44152, "number_of_timesteps": 7686741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44162, "number_of_timesteps": 7691741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44172, "number_of_timesteps": 7696741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44182, "number_of_timesteps": 7701741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44192, "number_of_timesteps": 7706741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44202, "number_of_timesteps": 7711741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44212, "number_of_timesteps": 7716741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44222, "number_of_timesteps": 7721741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44232, "number_of_timesteps": 7726741, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44242, "number_of_timesteps": 7731741, "per_episode_reward": 19.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44252, "number_of_timesteps": 7736741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44262, "number_of_timesteps": 7741741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44272, "number_of_timesteps": 7746741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44282, "number_of_timesteps": 7751741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44292, "number_of_timesteps": 7756741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44302, "number_of_timesteps": 7761741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44312, "number_of_timesteps": 7766741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44322, "number_of_timesteps": 7771741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44332, "number_of_timesteps": 7776741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44342, "number_of_timesteps": 7781741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44352, "number_of_timesteps": 7786741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44362, "number_of_timesteps": 7791741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44372, "number_of_timesteps": 7796741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44382, "number_of_timesteps": 7801741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44392, "number_of_timesteps": 7806741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44402, "number_of_timesteps": 7811741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44412, "number_of_timesteps": 7816741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44422, "number_of_timesteps": 7821741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44432, "number_of_timesteps": 7826741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44442, "number_of_timesteps": 7831741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44452, "number_of_timesteps": 7836741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44462, "number_of_timesteps": 7841741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44472, "number_of_timesteps": 7846741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44482, "number_of_timesteps": 7851741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44492, "number_of_timesteps": 7856741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44502, "number_of_timesteps": 7861741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44512, "number_of_timesteps": 7866741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44522, "number_of_timesteps": 7871741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44532, "number_of_timesteps": 7876741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44542, "number_of_timesteps": 7881741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44552, "number_of_timesteps": 7886741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44562, "number_of_timesteps": 7891741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44572, "number_of_timesteps": 7896741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44582, "number_of_timesteps": 7901741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44592, "number_of_timesteps": 7906741, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44602, "number_of_timesteps": 7911741, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 44612, "number_of_timesteps": 7916741, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 44622, "number_of_timesteps": 7921741, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 44632, "number_of_timesteps": 7926741, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 44642, "number_of_timesteps": 7931741, "per_episode_reward": 19.25, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 44652, "number_of_timesteps": 7936741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 44662, "number_of_timesteps": 7941741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 44672, "number_of_timesteps": 7946741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 44682, "number_of_timesteps": 7951741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 44692, "number_of_timesteps": 7956741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44702, "number_of_timesteps": 7961741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44712, "number_of_timesteps": 7966741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44722, "number_of_timesteps": 7971741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44732, "number_of_timesteps": 7976741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44742, "number_of_timesteps": 7981741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44752, "number_of_timesteps": 7986741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44762, "number_of_timesteps": 7991741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44772, "number_of_timesteps": 7996741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44782, "number_of_timesteps": 8001741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44792, "number_of_timesteps": 8006741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44802, "number_of_timesteps": 8011741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44812, "number_of_timesteps": 8016741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44822, "number_of_timesteps": 8021741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44832, "number_of_timesteps": 8026741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44842, "number_of_timesteps": 8031741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44852, "number_of_timesteps": 8036741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44862, "number_of_timesteps": 8041741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44872, "number_of_timesteps": 8046741, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 44882, "number_of_timesteps": 8051741, "per_episode_reward": 19.35, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44892, "number_of_timesteps": 8056741, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44902, "number_of_timesteps": 8061741, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44912, "number_of_timesteps": 8066741, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44922, "number_of_timesteps": 8071741, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44932, "number_of_timesteps": 8076741, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44942, "number_of_timesteps": 8081741, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44952, "number_of_timesteps": 8086741, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44962, "number_of_timesteps": 8091741, "per_episode_reward": 19.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44972, "number_of_timesteps": 8096741, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44982, "number_of_timesteps": 8101741, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 44992, "number_of_timesteps": 8106741, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45002, "number_of_timesteps": 8111741, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45012, "number_of_timesteps": 8116741, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45022, "number_of_timesteps": 8121741, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45032, "number_of_timesteps": 8126741, "per_episode_reward": 19.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 45042, "number_of_timesteps": 8131741, "per_episode_reward": 19.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 45052, "number_of_timesteps": 8136741, "per_episode_reward": 19.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 45062, "number_of_timesteps": 8141741, "per_episode_reward": 19.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 45072, "number_of_timesteps": 8146741, "per_episode_reward": 19.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 45082, "number_of_timesteps": 8151741, "per_episode_reward": 19.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 45092, "number_of_timesteps": 8156741, "per_episode_reward": 19.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 45102, "number_of_timesteps": 8161741, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 45112, "number_of_timesteps": 8166741, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 45122, "number_of_timesteps": 8171741, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 45132, "number_of_timesteps": 8176741, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45142, "number_of_timesteps": 8181741, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45152, "number_of_timesteps": 8186741, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45162, "number_of_timesteps": 8191741, "per_episode_reward": 19.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45172, "number_of_timesteps": 8196741, "per_episode_reward": 19.85, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45182, "number_of_timesteps": 8201741, "per_episode_reward": 19.9, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45192, "number_of_timesteps": 8206741, "per_episode_reward": 19.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45202, "number_of_timesteps": 8211741, "per_episode_reward": 19.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45212, "number_of_timesteps": 8216741, "per_episode_reward": 19.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45222, "number_of_timesteps": 8221741, "per_episode_reward": 19.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45232, "number_of_timesteps": 8226741, "per_episode_reward": 19.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45242, "number_of_timesteps": 8231741, "per_episode_reward": 19.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45252, "number_of_timesteps": 8236741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45262, "number_of_timesteps": 8241741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45272, "number_of_timesteps": 8246741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45282, "number_of_timesteps": 8251741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45292, "number_of_timesteps": 8256741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45302, "number_of_timesteps": 8261741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45312, "number_of_timesteps": 8266741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45322, "number_of_timesteps": 8271741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45332, "number_of_timesteps": 8276741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45342, "number_of_timesteps": 8281741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45352, "number_of_timesteps": 8286741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45362, "number_of_timesteps": 8291741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45372, "number_of_timesteps": 8296741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45382, "number_of_timesteps": 8301741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45392, "number_of_timesteps": 8306741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45402, "number_of_timesteps": 8311741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45412, "number_of_timesteps": 8316741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45422, "number_of_timesteps": 8321741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45432, "number_of_timesteps": 8326741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45442, "number_of_timesteps": 8331741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45452, "number_of_timesteps": 8336741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45462, "number_of_timesteps": 8341741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45472, "number_of_timesteps": 8346741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45482, "number_of_timesteps": 8351741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45492, "number_of_timesteps": 8356741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45502, "number_of_timesteps": 8361741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45512, "number_of_timesteps": 8366741, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45522, "number_of_timesteps": 8371741, "per_episode_reward": 20.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45532, "number_of_timesteps": 8376741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45542, "number_of_timesteps": 8381741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45552, "number_of_timesteps": 8386741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45562, "number_of_timesteps": 8391741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45572, "number_of_timesteps": 8396741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45582, "number_of_timesteps": 8401741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45592, "number_of_timesteps": 8406741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45602, "number_of_timesteps": 8411741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45612, "number_of_timesteps": 8416741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45622, "number_of_timesteps": 8421741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45632, "number_of_timesteps": 8426741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45642, "number_of_timesteps": 8431741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45652, "number_of_timesteps": 8436741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45662, "number_of_timesteps": 8441741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45672, "number_of_timesteps": 8446741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45682, "number_of_timesteps": 8451741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45692, "number_of_timesteps": 8456741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45702, "number_of_timesteps": 8461741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45712, "number_of_timesteps": 8466741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45722, "number_of_timesteps": 8471741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45732, "number_of_timesteps": 8476741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45742, "number_of_timesteps": 8481741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45752, "number_of_timesteps": 8486741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45762, "number_of_timesteps": 8491741, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45772, "number_of_timesteps": 8496741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 45782, "number_of_timesteps": 8501741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 45792, "number_of_timesteps": 8506741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 45802, "number_of_timesteps": 8511741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 45812, "number_of_timesteps": 8516741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 45822, "number_of_timesteps": 8521741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 45832, "number_of_timesteps": 8526741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 45842, "number_of_timesteps": 8531741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 45852, "number_of_timesteps": 8536741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 45862, "number_of_timesteps": 8541741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45872, "number_of_timesteps": 8546741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45882, "number_of_timesteps": 8551741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45892, "number_of_timesteps": 8556741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45902, "number_of_timesteps": 8561741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45912, "number_of_timesteps": 8566741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45922, "number_of_timesteps": 8571741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45932, "number_of_timesteps": 8576741, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 45942, "number_of_timesteps": 8581741, "per_episode_reward": 20.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45952, "number_of_timesteps": 8586741, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45962, "number_of_timesteps": 8591741, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45972, "number_of_timesteps": 8596741, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45982, "number_of_timesteps": 8601741, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 45992, "number_of_timesteps": 8606741, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46002, "number_of_timesteps": 8611741, "per_episode_reward": 20.35, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46012, "number_of_timesteps": 8616741, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46022, "number_of_timesteps": 8621741, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46032, "number_of_timesteps": 8626741, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46042, "number_of_timesteps": 8631741, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46052, "number_of_timesteps": 8636741, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46062, "number_of_timesteps": 8641741, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46072, "number_of_timesteps": 8646741, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46082, "number_of_timesteps": 8651741, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46092, "number_of_timesteps": 8656741, "per_episode_reward": 20.45, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46102, "number_of_timesteps": 8661741, "per_episode_reward": 20.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 46112, "number_of_timesteps": 8666741, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 46122, "number_of_timesteps": 8671741, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 46132, "number_of_timesteps": 8676741, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 46142, "number_of_timesteps": 8681741, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 46152, "number_of_timesteps": 8686741, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 46162, "number_of_timesteps": 8691741, "per_episode_reward": 20.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 46172, "number_of_timesteps": 8696741, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 46182, "number_of_timesteps": 8701741, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 46192, "number_of_timesteps": 8706741, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46202, "number_of_timesteps": 8711741, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46212, "number_of_timesteps": 8716741, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46222, "number_of_timesteps": 8721741, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46232, "number_of_timesteps": 8726741, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46242, "number_of_timesteps": 8731741, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46252, "number_of_timesteps": 8736741, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46262, "number_of_timesteps": 8741741, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46272, "number_of_timesteps": 8746741, "per_episode_reward": 20.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46282, "number_of_timesteps": 8751741, "per_episode_reward": 20.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46292, "number_of_timesteps": 8756741, "per_episode_reward": 20.85, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46302, "number_of_timesteps": 8761741, "per_episode_reward": 20.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46312, "number_of_timesteps": 8766741, "per_episode_reward": 20.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46322, "number_of_timesteps": 8771741, "per_episode_reward": 20.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46332, "number_of_timesteps": 8776741, "per_episode_reward": 20.95, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46342, "number_of_timesteps": 8781741, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46352, "number_of_timesteps": 8786741, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46362, "number_of_timesteps": 8791741, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46372, "number_of_timesteps": 8796741, "per_episode_reward": 21.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46382, "number_of_timesteps": 8801741, "per_episode_reward": 21.05, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46392, "number_of_timesteps": 8806741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46402, "number_of_timesteps": 8811741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46412, "number_of_timesteps": 8816741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46422, "number_of_timesteps": 8821741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46432, "number_of_timesteps": 8826741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46442, "number_of_timesteps": 8831741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46452, "number_of_timesteps": 8836741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46462, "number_of_timesteps": 8841741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46472, "number_of_timesteps": 8846741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46482, "number_of_timesteps": 8851741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46492, "number_of_timesteps": 8856741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46502, "number_of_timesteps": 8861741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46512, "number_of_timesteps": 8866741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46522, "number_of_timesteps": 8871741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46532, "number_of_timesteps": 8876741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46542, "number_of_timesteps": 8881741, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46552, "number_of_timesteps": 8886741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46562, "number_of_timesteps": 8891741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46572, "number_of_timesteps": 8896741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46582, "number_of_timesteps": 8901741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46592, "number_of_timesteps": 8906741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46602, "number_of_timesteps": 8911741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46612, "number_of_timesteps": 8916741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46622, "number_of_timesteps": 8921741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46632, "number_of_timesteps": 8926741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46642, "number_of_timesteps": 8931741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46652, "number_of_timesteps": 8936741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46662, "number_of_timesteps": 8941741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46672, "number_of_timesteps": 8946741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46682, "number_of_timesteps": 8951741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46692, "number_of_timesteps": 8956741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46702, "number_of_timesteps": 8961741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46712, "number_of_timesteps": 8966741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46722, "number_of_timesteps": 8971741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46732, "number_of_timesteps": 8976741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46742, "number_of_timesteps": 8981741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46752, "number_of_timesteps": 8986741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46762, "number_of_timesteps": 8991741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46772, "number_of_timesteps": 8996741, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46782, "number_of_timesteps": 9001741, "per_episode_reward": 21.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46792, "number_of_timesteps": 9006741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46802, "number_of_timesteps": 9011741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46812, "number_of_timesteps": 9016741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46822, "number_of_timesteps": 9021741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46832, "number_of_timesteps": 9026741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46842, "number_of_timesteps": 9031741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46852, "number_of_timesteps": 9036741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46862, "number_of_timesteps": 9041741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46872, "number_of_timesteps": 9046741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 46882, "number_of_timesteps": 9051741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46892, "number_of_timesteps": 9056741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46902, "number_of_timesteps": 9061741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46912, "number_of_timesteps": 9066741, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46922, "number_of_timesteps": 9071472, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46932, "number_of_timesteps": 9076409, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 46942, "number_of_timesteps": 9081409, "per_episode_reward": 21.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46952, "number_of_timesteps": 9086409, "per_episode_reward": 21.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46962, "number_of_timesteps": 9091409, "per_episode_reward": 21.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46972, "number_of_timesteps": 9096409, "per_episode_reward": 21.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46982, "number_of_timesteps": 9101409, "per_episode_reward": 21.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 46992, "number_of_timesteps": 9106409, "per_episode_reward": 21.55, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47002, "number_of_timesteps": 9111409, "per_episode_reward": 21.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47012, "number_of_timesteps": 9116409, "per_episode_reward": 21.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47022, "number_of_timesteps": 9121409, "per_episode_reward": 21.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47032, "number_of_timesteps": 9126409, "per_episode_reward": 21.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47042, "number_of_timesteps": 9131409, "per_episode_reward": 21.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47052, "number_of_timesteps": 9136409, "per_episode_reward": 21.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47062, "number_of_timesteps": 9141409, "per_episode_reward": 21.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47072, "number_of_timesteps": 9146409, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47082, "number_of_timesteps": 9151409, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 47092, "number_of_timesteps": 9156409, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 47102, "number_of_timesteps": 9161409, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 47112, "number_of_timesteps": 9166409, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 47122, "number_of_timesteps": 9171409, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 47132, "number_of_timesteps": 9176409, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 47142, "number_of_timesteps": 9181409, "per_episode_reward": 21.75, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 47152, "number_of_timesteps": 9186409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 47162, "number_of_timesteps": 9191409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47172, "number_of_timesteps": 9196409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47182, "number_of_timesteps": 9201409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47192, "number_of_timesteps": 9206409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47202, "number_of_timesteps": 9211409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47212, "number_of_timesteps": 9216409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47222, "number_of_timesteps": 9221409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47232, "number_of_timesteps": 9226409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47242, "number_of_timesteps": 9231409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 47252, "number_of_timesteps": 9236409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 47262, "number_of_timesteps": 9241409, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 47272, "number_of_timesteps": 9246409, "per_episode_reward": 21.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 47282, "number_of_timesteps": 9251409, "per_episode_reward": 22.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47292, "number_of_timesteps": 9256409, "per_episode_reward": 22.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47302, "number_of_timesteps": 9261409, "per_episode_reward": 22.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47312, "number_of_timesteps": 9266409, "per_episode_reward": 22.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47322, "number_of_timesteps": 9271409, "per_episode_reward": 22.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47332, "number_of_timesteps": 9276409, "per_episode_reward": 22.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47342, "number_of_timesteps": 9281409, "per_episode_reward": 22.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47352, "number_of_timesteps": 9286409, "per_episode_reward": 22.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47362, "number_of_timesteps": 9291409, "per_episode_reward": 22.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47372, "number_of_timesteps": 9296409, "per_episode_reward": 22.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47382, "number_of_timesteps": 9301409, "per_episode_reward": 22.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47392, "number_of_timesteps": 9306409, "per_episode_reward": 22.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47402, "number_of_timesteps": 9311409, "per_episode_reward": 22.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47412, "number_of_timesteps": 9316409, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47422, "number_of_timesteps": 9321409, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47432, "number_of_timesteps": 9326409, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47442, "number_of_timesteps": 9331409, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47452, "number_of_timesteps": 9336409, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47462, "number_of_timesteps": 9341409, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47472, "number_of_timesteps": 9346409, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47482, "number_of_timesteps": 9351409, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47492, "number_of_timesteps": 9356409, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47502, "number_of_timesteps": 9361409, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 47512, "number_of_timesteps": 9366409, "per_episode_reward": 22.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47522, "number_of_timesteps": 9371409, "per_episode_reward": 22.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47532, "number_of_timesteps": 9376409, "per_episode_reward": 22.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47542, "number_of_timesteps": 9381409, "per_episode_reward": 22.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47552, "number_of_timesteps": 9386409, "per_episode_reward": 22.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47562, "number_of_timesteps": 9391409, "per_episode_reward": 22.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47572, "number_of_timesteps": 9396409, "per_episode_reward": 22.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47582, "number_of_timesteps": 9401409, "per_episode_reward": 22.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47592, "number_of_timesteps": 9406409, "per_episode_reward": 22.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47602, "number_of_timesteps": 9411409, "per_episode_reward": 22.35, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47612, "number_of_timesteps": 9416409, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47622, "number_of_timesteps": 9421409, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47632, "number_of_timesteps": 9426409, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47642, "number_of_timesteps": 9431409, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47652, "number_of_timesteps": 9436409, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47662, "number_of_timesteps": 9441409, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47672, "number_of_timesteps": 9446409, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47682, "number_of_timesteps": 9451409, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47692, "number_of_timesteps": 9456409, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 47702, "number_of_timesteps": 9461409, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 47712, "number_of_timesteps": 9466409, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 47722, "number_of_timesteps": 9471409, "per_episode_reward": 22.45, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47732, "number_of_timesteps": 9476409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47742, "number_of_timesteps": 9481409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47752, "number_of_timesteps": 9486409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47762, "number_of_timesteps": 9491409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47772, "number_of_timesteps": 9496409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47782, "number_of_timesteps": 9501409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47792, "number_of_timesteps": 9506409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47802, "number_of_timesteps": 9511409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47812, "number_of_timesteps": 9516409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47822, "number_of_timesteps": 9521409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 47832, "number_of_timesteps": 9526409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 47842, "number_of_timesteps": 9531409, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 47852, "number_of_timesteps": 9536409, "per_episode_reward": 22.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47862, "number_of_timesteps": 9541409, "per_episode_reward": 22.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47872, "number_of_timesteps": 9546409, "per_episode_reward": 22.65, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47882, "number_of_timesteps": 9551409, "per_episode_reward": 22.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47892, "number_of_timesteps": 9556409, "per_episode_reward": 22.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47902, "number_of_timesteps": 9561409, "per_episode_reward": 22.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47912, "number_of_timesteps": 9566409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47922, "number_of_timesteps": 9571409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47932, "number_of_timesteps": 9576409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 47942, "number_of_timesteps": 9581409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47952, "number_of_timesteps": 9586409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47962, "number_of_timesteps": 9591409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47972, "number_of_timesteps": 9596409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47982, "number_of_timesteps": 9601409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 47992, "number_of_timesteps": 9606409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48002, "number_of_timesteps": 9611409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 48012, "number_of_timesteps": 9616409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 48022, "number_of_timesteps": 9621409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 48032, "number_of_timesteps": 9626409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 48042, "number_of_timesteps": 9631409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 48052, "number_of_timesteps": 9636409, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 48062, "number_of_timesteps": 9641409, "per_episode_reward": 22.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 48072, "number_of_timesteps": 9646409, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48082, "number_of_timesteps": 9651409, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48092, "number_of_timesteps": 9656409, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48102, "number_of_timesteps": 9661409, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48112, "number_of_timesteps": 9666409, "per_episode_reward": 23.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48122, "number_of_timesteps": 9671409, "per_episode_reward": 23.15, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48132, "number_of_timesteps": 9676409, "per_episode_reward": 23.2, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48142, "number_of_timesteps": 9681409, "per_episode_reward": 23.2, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48152, "number_of_timesteps": 9686409, "per_episode_reward": 23.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48162, "number_of_timesteps": 9691409, "per_episode_reward": 23.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 48172, "number_of_timesteps": 9696409, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 48182, "number_of_timesteps": 9701409, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 48192, "number_of_timesteps": 9706409, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 48202, "number_of_timesteps": 9711409, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 48212, "number_of_timesteps": 9716409, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48222, "number_of_timesteps": 9721409, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48232, "number_of_timesteps": 9726409, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48242, "number_of_timesteps": 9731409, "per_episode_reward": 23.35, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48252, "number_of_timesteps": 9736409, "per_episode_reward": 23.4, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48262, "number_of_timesteps": 9741409, "per_episode_reward": 23.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48272, "number_of_timesteps": 9746409, "per_episode_reward": 23.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48282, "number_of_timesteps": 9751409, "per_episode_reward": 23.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48292, "number_of_timesteps": 9756409, "per_episode_reward": 23.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48302, "number_of_timesteps": 9761409, "per_episode_reward": 23.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48312, "number_of_timesteps": 9766409, "per_episode_reward": 23.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48322, "number_of_timesteps": 9771409, "per_episode_reward": 23.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48332, "number_of_timesteps": 9776409, "per_episode_reward": 23.5, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48342, "number_of_timesteps": 9781409, "per_episode_reward": 23.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48352, "number_of_timesteps": 9786409, "per_episode_reward": 23.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48362, "number_of_timesteps": 9791409, "per_episode_reward": 23.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48372, "number_of_timesteps": 9796409, "per_episode_reward": 23.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48382, "number_of_timesteps": 9801409, "per_episode_reward": 23.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48392, "number_of_timesteps": 9806409, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48402, "number_of_timesteps": 9811409, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48412, "number_of_timesteps": 9816409, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48422, "number_of_timesteps": 9821409, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48432, "number_of_timesteps": 9826409, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48442, "number_of_timesteps": 9831409, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48452, "number_of_timesteps": 9836409, "per_episode_reward": 23.65, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48462, "number_of_timesteps": 9841409, "per_episode_reward": 23.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48472, "number_of_timesteps": 9846409, "per_episode_reward": 23.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48482, "number_of_timesteps": 9851409, "per_episode_reward": 23.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48492, "number_of_timesteps": 9856409, "per_episode_reward": 23.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48502, "number_of_timesteps": 9861409, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48512, "number_of_timesteps": 9866409, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48522, "number_of_timesteps": 9871409, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48532, "number_of_timesteps": 9876409, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48542, "number_of_timesteps": 9881409, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48552, "number_of_timesteps": 9886409, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48562, "number_of_timesteps": 9891409, "per_episode_reward": 23.85, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48572, "number_of_timesteps": 9896409, "per_episode_reward": 23.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48582, "number_of_timesteps": 9901409, "per_episode_reward": 23.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48592, "number_of_timesteps": 9906409, "per_episode_reward": 23.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48602, "number_of_timesteps": 9911409, "per_episode_reward": 23.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48612, "number_of_timesteps": 9916409, "per_episode_reward": 23.9, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48622, "number_of_timesteps": 9921409, "per_episode_reward": 23.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48632, "number_of_timesteps": 9926409, "per_episode_reward": 24.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48642, "number_of_timesteps": 9931409, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48652, "number_of_timesteps": 9936409, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48662, "number_of_timesteps": 9941409, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48672, "number_of_timesteps": 9946409, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48682, "number_of_timesteps": 9951409, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48692, "number_of_timesteps": 9956409, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48702, "number_of_timesteps": 9961409, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48712, "number_of_timesteps": 9966409, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 48722, "number_of_timesteps": 9971409, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48732, "number_of_timesteps": 9976409, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 48742, "number_of_timesteps": 9981409, "per_episode_reward": 24.15, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 48752, "number_of_timesteps": 9986409, "per_episode_reward": 24.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48762, "number_of_timesteps": 9991409, "per_episode_reward": 24.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48772, "number_of_timesteps": 9996409, "per_episode_reward": 24.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48782, "number_of_timesteps": 10001409, "per_episode_reward": 24.25, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48792, "number_of_timesteps": 10006409, "per_episode_reward": 24.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48802, "number_of_timesteps": 10011409, "per_episode_reward": 24.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48812, "number_of_timesteps": 10016409, "per_episode_reward": 24.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48822, "number_of_timesteps": 10021409, "per_episode_reward": 24.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48832, "number_of_timesteps": 10026409, "per_episode_reward": 24.3, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48842, "number_of_timesteps": 10031409, "per_episode_reward": 24.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48852, "number_of_timesteps": 10036409, "per_episode_reward": 24.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48862, "number_of_timesteps": 10041409, "per_episode_reward": 24.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48872, "number_of_timesteps": 10046409, "per_episode_reward": 24.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48882, "number_of_timesteps": 10051409, "per_episode_reward": 24.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 48892, "number_of_timesteps": 10056409, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 48902, "number_of_timesteps": 10061409, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 48912, "number_of_timesteps": 10066409, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 48922, "number_of_timesteps": 10071409, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 48932, "number_of_timesteps": 10076409, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 48942, "number_of_timesteps": 10081409, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 48952, "number_of_timesteps": 10086409, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 48962, "number_of_timesteps": 10091409, "per_episode_reward": 24.65, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 48972, "number_of_timesteps": 10096409, "per_episode_reward": 24.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 48982, "number_of_timesteps": 10101409, "per_episode_reward": 24.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 48992, "number_of_timesteps": 10106409, "per_episode_reward": 24.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49002, "number_of_timesteps": 10111409, "per_episode_reward": 24.75, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49012, "number_of_timesteps": 10116409, "per_episode_reward": 24.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49022, "number_of_timesteps": 10121409, "per_episode_reward": 25.15, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.34999999999999787},
{"total_number_of_episodes": 49032, "number_of_timesteps": 10126409, "per_episode_reward": 25.2, "episode_reward_trend_value": 0.006666666666666643, "biggest_recent_change": 0.34999999999999787},
{"total_number_of_episodes": 49042, "number_of_timesteps": 10131409, "per_episode_reward": 25.2, "episode_reward_trend_value": 0.006666666666666643, "biggest_recent_change": 0.34999999999999787},
{"total_number_of_episodes": 49052, "number_of_timesteps": 10136409, "per_episode_reward": 25.2, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.34999999999999787},
{"total_number_of_episodes": 49062, "number_of_timesteps": 10141409, "per_episode_reward": 25.25, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.34999999999999787},
{"total_number_of_episodes": 49072, "number_of_timesteps": 10146409, "per_episode_reward": 25.35, "episode_reward_trend_value": 0.007222222222222246, "biggest_recent_change": 0.34999999999999787},
{"total_number_of_episodes": 49082, "number_of_timesteps": 10151409, "per_episode_reward": 25.45, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.34999999999999787},
{"total_number_of_episodes": 49092, "number_of_timesteps": 10156409, "per_episode_reward": 25.5, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.34999999999999787},
{"total_number_of_episodes": 49102, "number_of_timesteps": 10161409, "per_episode_reward": 25.55, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.34999999999999787},
{"total_number_of_episodes": 49112, "number_of_timesteps": 10166409, "per_episode_reward": 25.6, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 49122, "number_of_timesteps": 10171409, "per_episode_reward": 25.6, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 49132, "number_of_timesteps": 10176409, "per_episode_reward": 25.65, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 49142, "number_of_timesteps": 10181409, "per_episode_reward": 25.7, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 49152, "number_of_timesteps": 10186409, "per_episode_reward": 25.9, "episode_reward_trend_value": 0.007222222222222206, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49162, "number_of_timesteps": 10191409, "per_episode_reward": 25.9, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49172, "number_of_timesteps": 10196409, "per_episode_reward": 25.9, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49182, "number_of_timesteps": 10201409, "per_episode_reward": 25.95, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49192, "number_of_timesteps": 10206409, "per_episode_reward": 26.0, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49202, "number_of_timesteps": 10211409, "per_episode_reward": 26.1, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49212, "number_of_timesteps": 10216409, "per_episode_reward": 26.2, "episode_reward_trend_value": 0.006666666666666643, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49222, "number_of_timesteps": 10221409, "per_episode_reward": 26.2, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49232, "number_of_timesteps": 10226409, "per_episode_reward": 26.2, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49242, "number_of_timesteps": 10231409, "per_episode_reward": 26.25, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 49252, "number_of_timesteps": 10236409, "per_episode_reward": 26.35, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 49262, "number_of_timesteps": 10241409, "per_episode_reward": 26.4, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 49272, "number_of_timesteps": 10246409, "per_episode_reward": 26.4, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 49282, "number_of_timesteps": 10251409, "per_episode_reward": 26.8, "episode_reward_trend_value": 0.008888888888888896, "biggest_recent_change": 0.40000000000000213},
{"total_number_of_episodes": 49292, "number_of_timesteps": 10256409, "per_episode_reward": 26.85, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.40000000000000213},
{"total_number_of_episodes": 49302, "number_of_timesteps": 10261409, "per_episode_reward": 26.9, "episode_reward_trend_value": 0.00777777777777777, "biggest_recent_change": 0.40000000000000213},
{"total_number_of_episodes": 49312, "number_of_timesteps": 10266409, "per_episode_reward": 26.9, "episode_reward_trend_value": 0.00777777777777777, "biggest_recent_change": 0.40000000000000213},
{"total_number_of_episodes": 49322, "number_of_timesteps": 10271409, "per_episode_reward": 26.95, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.40000000000000213},
{"total_number_of_episodes": 49332, "number_of_timesteps": 10276409, "per_episode_reward": 27.0, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.40000000000000213},
{"total_number_of_episodes": 49342, "number_of_timesteps": 10281409, "per_episode_reward": 27.0, "episode_reward_trend_value": 0.007222222222222206, "biggest_recent_change": 0.40000000000000213},
{"total_number_of_episodes": 49352, "number_of_timesteps": 10286409, "per_episode_reward": 27.0, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.40000000000000213},
{"total_number_of_episodes": 49362, "number_of_timesteps": 10291409, "per_episode_reward": 27.0, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.40000000000000213},
{"total_number_of_episodes": 49372, "number_of_timesteps": 10296409, "per_episode_reward": 27.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49382, "number_of_timesteps": 10301409, "per_episode_reward": 27.05, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49392, "number_of_timesteps": 10306409, "per_episode_reward": 27.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49402, "number_of_timesteps": 10311409, "per_episode_reward": 27.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49412, "number_of_timesteps": 10316409, "per_episode_reward": 27.5, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 49422, "number_of_timesteps": 10321409, "per_episode_reward": 27.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 49432, "number_of_timesteps": 10326409, "per_episode_reward": 27.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 49442, "number_of_timesteps": 10331409, "per_episode_reward": 27.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 49452, "number_of_timesteps": 10336409, "per_episode_reward": 27.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 49462, "number_of_timesteps": 10341409, "per_episode_reward": 27.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 49472, "number_of_timesteps": 10346409, "per_episode_reward": 27.5, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 49482, "number_of_timesteps": 10351409, "per_episode_reward": 27.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 49492, "number_of_timesteps": 10356409, "per_episode_reward": 27.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 49502, "number_of_timesteps": 10361409, "per_episode_reward": 27.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49512, "number_of_timesteps": 10366409, "per_episode_reward": 27.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49522, "number_of_timesteps": 10371409, "per_episode_reward": 27.65, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49532, "number_of_timesteps": 10376409, "per_episode_reward": 27.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49542, "number_of_timesteps": 10381409, "per_episode_reward": 27.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49552, "number_of_timesteps": 10386409, "per_episode_reward": 27.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49562, "number_of_timesteps": 10391409, "per_episode_reward": 27.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49572, "number_of_timesteps": 10396409, "per_episode_reward": 27.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49582, "number_of_timesteps": 10401409, "per_episode_reward": 27.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49592, "number_of_timesteps": 10406409, "per_episode_reward": 27.9, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49602, "number_of_timesteps": 10411409, "per_episode_reward": 27.9, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49612, "number_of_timesteps": 10416409, "per_episode_reward": 27.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49622, "number_of_timesteps": 10421409, "per_episode_reward": 27.95, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 49632, "number_of_timesteps": 10426409, "per_episode_reward": 28.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49642, "number_of_timesteps": 10431409, "per_episode_reward": 28.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49652, "number_of_timesteps": 10436409, "per_episode_reward": 28.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49662, "number_of_timesteps": 10441409, "per_episode_reward": 28.0, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 49672, "number_of_timesteps": 10446409, "per_episode_reward": 28.5, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 49682, "number_of_timesteps": 10451409, "per_episode_reward": 28.5, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 49692, "number_of_timesteps": 10456409, "per_episode_reward": 28.5, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 49702, "number_of_timesteps": 10461409, "per_episode_reward": 28.5, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 49712, "number_of_timesteps": 10466409, "per_episode_reward": 28.5, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 49722, "number_of_timesteps": 10471409, "per_episode_reward": 28.65, "episode_reward_trend_value": 0.007222222222222206, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 49732, "number_of_timesteps": 10476409, "per_episode_reward": 28.85, "episode_reward_trend_value": 0.00944444444444446, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 49742, "number_of_timesteps": 10481409, "per_episode_reward": 29.0, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 49752, "number_of_timesteps": 10486409, "per_episode_reward": 29.1, "episode_reward_trend_value": 0.012222222222222238, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 49762, "number_of_timesteps": 10491409, "per_episode_reward": 29.1, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 49772, "number_of_timesteps": 10496409, "per_episode_reward": 29.1, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 49782, "number_of_timesteps": 10501409, "per_episode_reward": 29.1, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 49792, "number_of_timesteps": 10506409, "per_episode_reward": 29.1, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 49802, "number_of_timesteps": 10511409, "per_episode_reward": 29.35, "episode_reward_trend_value": 0.00944444444444446, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 49812, "number_of_timesteps": 10516409, "per_episode_reward": 29.45, "episode_reward_trend_value": 0.008888888888888896, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 49822, "number_of_timesteps": 10521409, "per_episode_reward": 29.5, "episode_reward_trend_value": 0.007222222222222206, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 49832, "number_of_timesteps": 10526409, "per_episode_reward": 29.6, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 49842, "number_of_timesteps": 10531409, "per_episode_reward": 29.75, "episode_reward_trend_value": 0.007222222222222206, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 49852, "number_of_timesteps": 10536409, "per_episode_reward": 29.8, "episode_reward_trend_value": 0.00777777777777777, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 49862, "number_of_timesteps": 10541409, "per_episode_reward": 29.8, "episode_reward_trend_value": 0.00777777777777777, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 49872, "number_of_timesteps": 10546409, "per_episode_reward": 29.8, "episode_reward_trend_value": 0.00777777777777777, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 49882, "number_of_timesteps": 10551409, "per_episode_reward": 29.9, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 49892, "number_of_timesteps": 10556409, "per_episode_reward": 30.0, "episode_reward_trend_value": 0.007222222222222206, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 49902, "number_of_timesteps": 10561409, "per_episode_reward": 30.0, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 49912, "number_of_timesteps": 10566409, "per_episode_reward": 30.0, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 49922, "number_of_timesteps": 10571409, "per_episode_reward": 30.0, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 49932, "number_of_timesteps": 10576409, "per_episode_reward": 30.3, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.3000000000000007},
{"total_number_of_episodes": 49942, "number_of_timesteps": 10581409, "per_episode_reward": 30.3, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3000000000000007},
{"total_number_of_episodes": 49952, "number_of_timesteps": 10586409, "per_episode_reward": 30.3, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3000000000000007},
{"total_number_of_episodes": 49962, "number_of_timesteps": 10591409, "per_episode_reward": 30.35, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.3000000000000007},
{"total_number_of_episodes": 49972, "number_of_timesteps": 10596409, "per_episode_reward": 30.4, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3000000000000007},
{"total_number_of_episodes": 49982, "number_of_timesteps": 10601409, "per_episode_reward": 30.4, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.3000000000000007},
{"total_number_of_episodes": 49992, "number_of_timesteps": 10606409, "per_episode_reward": 30.4, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.3000000000000007},
{"total_number_of_episodes": 50002, "number_of_timesteps": 10611409, "per_episode_reward": 30.4, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.3000000000000007},
{"total_number_of_episodes": 50012, "number_of_timesteps": 10616409, "per_episode_reward": 30.4, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.3000000000000007},
{"total_number_of_episodes": 50022, "number_of_timesteps": 10621409, "per_episode_reward": 30.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50032, "number_of_timesteps": 10626409, "per_episode_reward": 30.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50042, "number_of_timesteps": 10631409, "per_episode_reward": 30.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50052, "number_of_timesteps": 10636409, "per_episode_reward": 30.5, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50062, "number_of_timesteps": 10641409, "per_episode_reward": 30.95, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.4499999999999993},
{"total_number_of_episodes": 50072, "number_of_timesteps": 10646409, "per_episode_reward": 31.0, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.4499999999999993},
{"total_number_of_episodes": 50082, "number_of_timesteps": 10651409, "per_episode_reward": 31.0, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.4499999999999993},
{"total_number_of_episodes": 50092, "number_of_timesteps": 10656409, "per_episode_reward": 31.0, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.4499999999999993},
{"total_number_of_episodes": 50102, "number_of_timesteps": 10661409, "per_episode_reward": 31.0, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.4499999999999993},
{"total_number_of_episodes": 50112, "number_of_timesteps": 10666409, "per_episode_reward": 31.0, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.4499999999999993},
{"total_number_of_episodes": 50122, "number_of_timesteps": 10671409, "per_episode_reward": 31.05, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.4499999999999993},
{"total_number_of_episodes": 50132, "number_of_timesteps": 10676409, "per_episode_reward": 31.1, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.4499999999999993},
{"total_number_of_episodes": 50142, "number_of_timesteps": 10681409, "per_episode_reward": 31.1, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.4499999999999993},
{"total_number_of_episodes": 50152, "number_of_timesteps": 10686409, "per_episode_reward": 31.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50162, "number_of_timesteps": 10691409, "per_episode_reward": 31.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50172, "number_of_timesteps": 10696409, "per_episode_reward": 31.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50182, "number_of_timesteps": 10701409, "per_episode_reward": 31.1, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50192, "number_of_timesteps": 10706409, "per_episode_reward": 31.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 50202, "number_of_timesteps": 10711409, "per_episode_reward": 31.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 50212, "number_of_timesteps": 10716409, "per_episode_reward": 31.5, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 50222, "number_of_timesteps": 10721409, "per_episode_reward": 31.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 50232, "number_of_timesteps": 10726409, "per_episode_reward": 31.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 50242, "number_of_timesteps": 10731409, "per_episode_reward": 31.55, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 50252, "number_of_timesteps": 10736409, "per_episode_reward": 31.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 50262, "number_of_timesteps": 10741409, "per_episode_reward": 31.65, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 50272, "number_of_timesteps": 10746409, "per_episode_reward": 31.7, "episode_reward_trend_value": 0.006666666666666643, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 50282, "number_of_timesteps": 10751409, "per_episode_reward": 31.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50292, "number_of_timesteps": 10756409, "per_episode_reward": 31.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50302, "number_of_timesteps": 10761409, "per_episode_reward": 31.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50312, "number_of_timesteps": 10766409, "per_episode_reward": 31.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 50322, "number_of_timesteps": 10771409, "per_episode_reward": 31.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 50332, "number_of_timesteps": 10776409, "per_episode_reward": 31.9, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 50342, "number_of_timesteps": 10781409, "per_episode_reward": 31.95, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 50352, "number_of_timesteps": 10786409, "per_episode_reward": 32.1, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 50362, "number_of_timesteps": 10791409, "per_episode_reward": 32.25, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 50372, "number_of_timesteps": 10796409, "per_episode_reward": 32.3, "episode_reward_trend_value": 0.006666666666666643, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 50382, "number_of_timesteps": 10801409, "per_episode_reward": 32.3, "episode_reward_trend_value": 0.006666666666666643, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 50392, "number_of_timesteps": 10806409, "per_episode_reward": 32.3, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 50402, "number_of_timesteps": 10811409, "per_episode_reward": 32.4, "episode_reward_trend_value": 0.006666666666666643, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 50412, "number_of_timesteps": 10816409, "per_episode_reward": 32.5, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 50422, "number_of_timesteps": 10821409, "per_episode_reward": 32.5, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 50432, "number_of_timesteps": 10826409, "per_episode_reward": 32.5, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 50442, "number_of_timesteps": 10831409, "per_episode_reward": 32.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 50452, "number_of_timesteps": 10836409, "per_episode_reward": 33.0, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 50462, "number_of_timesteps": 10841409, "per_episode_reward": 33.1, "episode_reward_trend_value": 0.008888888888888936, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 50472, "number_of_timesteps": 10846409, "per_episode_reward": 33.2, "episode_reward_trend_value": 0.010000000000000063, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 50482, "number_of_timesteps": 10851409, "per_episode_reward": 33.35, "episode_reward_trend_value": 0.011666666666666714, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 50492, "number_of_timesteps": 10856409, "per_episode_reward": 33.55, "episode_reward_trend_value": 0.012777777777777763, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 50502, "number_of_timesteps": 10861409, "per_episode_reward": 33.8, "episode_reward_trend_value": 0.014444444444444413, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 50512, "number_of_timesteps": 10866409, "per_episode_reward": 34.0, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 50522, "number_of_timesteps": 10871409, "per_episode_reward": 34.05, "episode_reward_trend_value": 0.01722222222222219, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 50532, "number_of_timesteps": 10876409, "per_episode_reward": 34.1, "episode_reward_trend_value": 0.01777777777777779, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 50542, "number_of_timesteps": 10881409, "per_episode_reward": 34.15, "episode_reward_trend_value": 0.012777777777777763, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50552, "number_of_timesteps": 10886409, "per_episode_reward": 34.2, "episode_reward_trend_value": 0.012222222222222238, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50562, "number_of_timesteps": 10891409, "per_episode_reward": 34.25, "episode_reward_trend_value": 0.011666666666666634, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50572, "number_of_timesteps": 10896409, "per_episode_reward": 34.35, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50582, "number_of_timesteps": 10901409, "per_episode_reward": 34.9, "episode_reward_trend_value": 0.015000000000000017, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 50592, "number_of_timesteps": 10906409, "per_episode_reward": 35.1, "episode_reward_trend_value": 0.014444444444444492, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 50602, "number_of_timesteps": 10911409, "per_episode_reward": 35.3, "episode_reward_trend_value": 0.014444444444444413, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 50612, "number_of_timesteps": 10916409, "per_episode_reward": 35.5, "episode_reward_trend_value": 0.016111111111111142, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 50622, "number_of_timesteps": 10921409, "per_episode_reward": 35.5, "episode_reward_trend_value": 0.01555555555555554, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 50632, "number_of_timesteps": 10926409, "per_episode_reward": 35.5, "episode_reward_trend_value": 0.015000000000000017, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 50642, "number_of_timesteps": 10931409, "per_episode_reward": 35.55, "episode_reward_trend_value": 0.014999999999999935, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 50652, "number_of_timesteps": 10936409, "per_episode_reward": 35.6, "episode_reward_trend_value": 0.015000000000000017, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 50662, "number_of_timesteps": 10941409, "per_episode_reward": 35.6, "episode_reward_trend_value": 0.01388888888888889, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 50672, "number_of_timesteps": 10946409, "per_episode_reward": 35.6, "episode_reward_trend_value": 0.00777777777777781, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 50682, "number_of_timesteps": 10951409, "per_episode_reward": 35.65, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 50692, "number_of_timesteps": 10956409, "per_episode_reward": 35.7, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 50702, "number_of_timesteps": 10961409, "per_episode_reward": 36.0, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 50712, "number_of_timesteps": 10966409, "per_episode_reward": 37.8, "episode_reward_trend_value": 0.025555555555555526, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 50722, "number_of_timesteps": 10971409, "per_episode_reward": 37.8, "episode_reward_trend_value": 0.025555555555555526, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 50732, "number_of_timesteps": 10976409, "per_episode_reward": 37.8, "episode_reward_trend_value": 0.025, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 50742, "number_of_timesteps": 10981409, "per_episode_reward": 37.8, "episode_reward_trend_value": 0.024444444444444397, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 50752, "number_of_timesteps": 10986409, "per_episode_reward": 37.8, "episode_reward_trend_value": 0.024444444444444397, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 50762, "number_of_timesteps": 10991409, "per_episode_reward": 37.85, "episode_reward_trend_value": 0.025, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 50772, "number_of_timesteps": 10996409, "per_episode_reward": 37.9, "episode_reward_trend_value": 0.025, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 50782, "number_of_timesteps": 11001409, "per_episode_reward": 38.0, "episode_reward_trend_value": 0.025555555555555526, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 50792, "number_of_timesteps": 11006409, "per_episode_reward": 38.1, "episode_reward_trend_value": 0.023333333333333352, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 50802, "number_of_timesteps": 11011409, "per_episode_reward": 38.35, "episode_reward_trend_value": 0.006111111111111159, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50812, "number_of_timesteps": 11016409, "per_episode_reward": 38.6, "episode_reward_trend_value": 0.008888888888888936, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50822, "number_of_timesteps": 11021409, "per_episode_reward": 38.7, "episode_reward_trend_value": 0.010000000000000063, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50832, "number_of_timesteps": 11026409, "per_episode_reward": 38.8, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50842, "number_of_timesteps": 11031409, "per_episode_reward": 39.35, "episode_reward_trend_value": 0.01722222222222227, "biggest_recent_change": 0.5500000000000043},
{"total_number_of_episodes": 50852, "number_of_timesteps": 11036409, "per_episode_reward": 39.45, "episode_reward_trend_value": 0.01777777777777779, "biggest_recent_change": 0.5500000000000043},
{"total_number_of_episodes": 50862, "number_of_timesteps": 11041409, "per_episode_reward": 39.55, "episode_reward_trend_value": 0.01833333333333332, "biggest_recent_change": 0.5500000000000043},
{"total_number_of_episodes": 50872, "number_of_timesteps": 11046409, "per_episode_reward": 39.6, "episode_reward_trend_value": 0.01777777777777779, "biggest_recent_change": 0.5500000000000043},
{"total_number_of_episodes": 50882, "number_of_timesteps": 11051409, "per_episode_reward": 39.7, "episode_reward_trend_value": 0.01777777777777779, "biggest_recent_change": 0.5500000000000043},
{"total_number_of_episodes": 50892, "number_of_timesteps": 11056409, "per_episode_reward": 39.8, "episode_reward_trend_value": 0.016111111111111066, "biggest_recent_change": 0.5500000000000043},
{"total_number_of_episodes": 50902, "number_of_timesteps": 11061409, "per_episode_reward": 40.05, "episode_reward_trend_value": 0.016111111111111066, "biggest_recent_change": 0.5500000000000043},
{"total_number_of_episodes": 50912, "number_of_timesteps": 11066409, "per_episode_reward": 40.3, "episode_reward_trend_value": 0.017777777777777715, "biggest_recent_change": 0.5500000000000043},
{"total_number_of_episodes": 50922, "number_of_timesteps": 11071409, "per_episode_reward": 40.45, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.5500000000000043},
{"total_number_of_episodes": 50932, "number_of_timesteps": 11076409, "per_episode_reward": 40.6, "episode_reward_trend_value": 0.01388888888888889, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50942, "number_of_timesteps": 11081409, "per_episode_reward": 40.6, "episode_reward_trend_value": 0.012777777777777763, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50952, "number_of_timesteps": 11086409, "per_episode_reward": 40.6, "episode_reward_trend_value": 0.011666666666666714, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50962, "number_of_timesteps": 11091409, "per_episode_reward": 40.65, "episode_reward_trend_value": 0.011666666666666634, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 50972, "number_of_timesteps": 11096409, "per_episode_reward": 42.2, "episode_reward_trend_value": 0.02777777777777778, "biggest_recent_change": 1.5500000000000043},
{"total_number_of_episodes": 50982, "number_of_timesteps": 11101409, "per_episode_reward": 42.65, "episode_reward_trend_value": 0.03166666666666668, "biggest_recent_change": 1.5500000000000043},
{"total_number_of_episodes": 50992, "number_of_timesteps": 11106409, "per_episode_reward": 43.1, "episode_reward_trend_value": 0.033888888888888934, "biggest_recent_change": 1.5500000000000043},
{"total_number_of_episodes": 51002, "number_of_timesteps": 11111409, "per_episode_reward": 43.15, "episode_reward_trend_value": 0.03166666666666668, "biggest_recent_change": 1.5500000000000043},
{"total_number_of_episodes": 51012, "number_of_timesteps": 11116409, "per_episode_reward": 43.2, "episode_reward_trend_value": 0.030555555555555558, "biggest_recent_change": 1.5500000000000043},
{"total_number_of_episodes": 51022, "number_of_timesteps": 11121409, "per_episode_reward": 43.25, "episode_reward_trend_value": 0.02944444444444443, "biggest_recent_change": 1.5500000000000043},
{"total_number_of_episodes": 51032, "number_of_timesteps": 11126409, "per_episode_reward": 43.3, "episode_reward_trend_value": 0.029999999999999954, "biggest_recent_change": 1.5500000000000043},
{"total_number_of_episodes": 51042, "number_of_timesteps": 11131409, "per_episode_reward": 43.4, "episode_reward_trend_value": 0.03111111111111108, "biggest_recent_change": 1.5500000000000043},
{"total_number_of_episodes": 51052, "number_of_timesteps": 11136409, "per_episode_reward": 43.5, "episode_reward_trend_value": 0.03166666666666668, "biggest_recent_change": 1.5500000000000043},
{"total_number_of_episodes": 51062, "number_of_timesteps": 11141409, "per_episode_reward": 43.75, "episode_reward_trend_value": 0.01722222222222219, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 51072, "number_of_timesteps": 11146409, "per_episode_reward": 44.0, "episode_reward_trend_value": 0.015000000000000017, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 51082, "number_of_timesteps": 11151409, "per_episode_reward": 44.25, "episode_reward_trend_value": 0.012777777777777763, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 51092, "number_of_timesteps": 11156409, "per_episode_reward": 44.55, "episode_reward_trend_value": 0.01555555555555554, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 51102, "number_of_timesteps": 11161409, "per_episode_reward": 47.05, "episode_reward_trend_value": 0.04277777777777771, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 51112, "number_of_timesteps": 11166409, "per_episode_reward": 47.1, "episode_reward_trend_value": 0.04277777777777779, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 51122, "number_of_timesteps": 11171409, "per_episode_reward": 47.25, "episode_reward_trend_value": 0.04388888888888892, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 51132, "number_of_timesteps": 11176409, "per_episode_reward": 47.4, "episode_reward_trend_value": 0.04444444444444444, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 51142, "number_of_timesteps": 11181409, "per_episode_reward": 47.55, "episode_reward_trend_value": 0.04499999999999997, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 51152, "number_of_timesteps": 11186409, "per_episode_reward": 47.75, "episode_reward_trend_value": 0.04444444444444444, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 51162, "number_of_timesteps": 11191409, "per_episode_reward": 48.0, "episode_reward_trend_value": 0.04444444444444444, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 51172, "number_of_timesteps": 11196409, "per_episode_reward": 48.2, "episode_reward_trend_value": 0.04388888888888892, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 51182, "number_of_timesteps": 11201409, "per_episode_reward": 48.6, "episode_reward_trend_value": 0.04500000000000005, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 51192, "number_of_timesteps": 11206409, "per_episode_reward": 49.0, "episode_reward_trend_value": 0.0216666666666667, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 51202, "number_of_timesteps": 11211409, "per_episode_reward": 49.4, "episode_reward_trend_value": 0.025555555555555526, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 51212, "number_of_timesteps": 11216409, "per_episode_reward": 49.8, "episode_reward_trend_value": 0.0283333333333333, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 51222, "number_of_timesteps": 11221409, "per_episode_reward": 49.8, "episode_reward_trend_value": 0.02666666666666665, "biggest_recent_change": 0.3999999999999986},
{"total_number_of_episodes": 51232, "number_of_timesteps": 11226409, "per_episode_reward": 52.05, "episode_reward_trend_value": 0.05, "biggest_recent_change": 2.25},
{"total_number_of_episodes": 51242, "number_of_timesteps": 11231409, "per_episode_reward": 52.15, "episode_reward_trend_value": 0.04888888888888887, "biggest_recent_change": 2.25},
{"total_number_of_episodes": 51252, "number_of_timesteps": 11236409, "per_episode_reward": 52.2, "episode_reward_trend_value": 0.046666666666666703, "biggest_recent_change": 2.25},
{"total_number_of_episodes": 51262, "number_of_timesteps": 11241409, "per_episode_reward": 52.25, "episode_reward_trend_value": 0.04499999999999997, "biggest_recent_change": 2.25},
{"total_number_of_episodes": 51272, "number_of_timesteps": 11246409, "per_episode_reward": 52.3, "episode_reward_trend_value": 0.041111111111111064, "biggest_recent_change": 2.25},
{"total_number_of_episodes": 51282, "number_of_timesteps": 11251409, "per_episode_reward": 52.4, "episode_reward_trend_value": 0.03777777777777776, "biggest_recent_change": 2.25},
{"total_number_of_episodes": 51292, "number_of_timesteps": 11256409, "per_episode_reward": 52.5, "episode_reward_trend_value": 0.03444444444444446, "biggest_recent_change": 2.25},
{"total_number_of_episodes": 51302, "number_of_timesteps": 11261409, "per_episode_reward": 52.55, "episode_reward_trend_value": 0.030555555555555558, "biggest_recent_change": 2.25},
{"total_number_of_episodes": 51312, "number_of_timesteps": 11266409, "per_episode_reward": 52.6, "episode_reward_trend_value": 0.031111111111111155, "biggest_recent_change": 2.25},
{"total_number_of_episodes": 51322, "number_of_timesteps": 11271409, "per_episode_reward": 52.7, "episode_reward_trend_value": 0.007222222222222285, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 51332, "number_of_timesteps": 11276409, "per_episode_reward": 52.8, "episode_reward_trend_value": 0.007222222222222206, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 51342, "number_of_timesteps": 11281409, "per_episode_reward": 53.0, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 51352, "number_of_timesteps": 11286409, "per_episode_reward": 53.2, "episode_reward_trend_value": 0.010555555555555587, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 51362, "number_of_timesteps": 11291409, "per_episode_reward": 55.0, "episode_reward_trend_value": 0.030000000000000034, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 51372, "number_of_timesteps": 11296409, "per_episode_reward": 55.1, "episode_reward_trend_value": 0.030000000000000034, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 51382, "number_of_timesteps": 11301409, "per_episode_reward": 55.25, "episode_reward_trend_value": 0.030555555555555558, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 51392, "number_of_timesteps": 11306409, "per_episode_reward": 55.4, "episode_reward_trend_value": 0.03166666666666668, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 51402, "number_of_timesteps": 11311409, "per_episode_reward": 55.4, "episode_reward_trend_value": 0.03111111111111108, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 51412, "number_of_timesteps": 11316409, "per_episode_reward": 55.4, "episode_reward_trend_value": 0.029999999999999954, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 51422, "number_of_timesteps": 11321409, "per_episode_reward": 55.7, "episode_reward_trend_value": 0.032222222222222284, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 51432, "number_of_timesteps": 11326409, "per_episode_reward": 56.0, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 51442, "number_of_timesteps": 11331409, "per_episode_reward": 56.05, "episode_reward_trend_value": 0.03166666666666661, "biggest_recent_change": 1.7999999999999972},
{"total_number_of_episodes": 51452, "number_of_timesteps": 11336409, "per_episode_reward": 56.1, "episode_reward_trend_value": 0.012222222222222238, "biggest_recent_change": 0.30000000000000426},
{"total_number_of_episodes": 51462, "number_of_timesteps": 11341409, "per_episode_reward": 56.1, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.30000000000000426},
{"total_number_of_episodes": 51472, "number_of_timesteps": 11346409, "per_episode_reward": 56.1, "episode_reward_trend_value": 0.00944444444444446, "biggest_recent_change": 0.30000000000000426},
{"total_number_of_episodes": 51482, "number_of_timesteps": 11351409, "per_episode_reward": 56.4, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.30000000000000426},
{"total_number_of_episodes": 51492, "number_of_timesteps": 11356409, "per_episode_reward": 58.1, "episode_reward_trend_value": 0.030000000000000034, "biggest_recent_change": 1.7000000000000028},
{"total_number_of_episodes": 51502, "number_of_timesteps": 11361409, "per_episode_reward": 58.3, "episode_reward_trend_value": 0.03222222222222221, "biggest_recent_change": 1.7000000000000028},
{"total_number_of_episodes": 51512, "number_of_timesteps": 11366409, "per_episode_reward": 58.5, "episode_reward_trend_value": 0.03111111111111108, "biggest_recent_change": 1.7000000000000028},
{"total_number_of_episodes": 51522, "number_of_timesteps": 11371409, "per_episode_reward": 58.9, "episode_reward_trend_value": 0.03222222222222221, "biggest_recent_change": 1.7000000000000028},
{"total_number_of_episodes": 51532, "number_of_timesteps": 11376409, "per_episode_reward": 59.3, "episode_reward_trend_value": 0.03611111111111111, "biggest_recent_change": 1.7000000000000028},
{"total_number_of_episodes": 51542, "number_of_timesteps": 11381409, "per_episode_reward": 60.35, "episode_reward_trend_value": 0.04722222222222222, "biggest_recent_change": 1.7000000000000028},
{"total_number_of_episodes": 51552, "number_of_timesteps": 11386409, "per_episode_reward": 61.4, "episode_reward_trend_value": 0.05888888888888886, "biggest_recent_change": 1.7000000000000028},
{"total_number_of_episodes": 51562, "number_of_timesteps": 11391409, "per_episode_reward": 61.55, "episode_reward_trend_value": 0.06055555555555551, "biggest_recent_change": 1.7000000000000028},
{"total_number_of_episodes": 51572, "number_of_timesteps": 11396409, "per_episode_reward": 61.75, "episode_reward_trend_value": 0.05944444444444445, "biggest_recent_change": 1.7000000000000028},
{"total_number_of_episodes": 51582, "number_of_timesteps": 11401409, "per_episode_reward": 62.1, "episode_reward_trend_value": 0.04444444444444444, "biggest_recent_change": 1.0500000000000043},
{"total_number_of_episodes": 51592, "number_of_timesteps": 11406409, "per_episode_reward": 62.4, "episode_reward_trend_value": 0.04555555555555557, "biggest_recent_change": 1.0500000000000043},
{"total_number_of_episodes": 51602, "number_of_timesteps": 11411409, "per_episode_reward": 62.65, "episode_reward_trend_value": 0.046111111111111096, "biggest_recent_change": 1.0500000000000043},
{"total_number_of_episodes": 51612, "number_of_timesteps": 11416409, "per_episode_reward": 62.9, "episode_reward_trend_value": 0.04444444444444444, "biggest_recent_change": 1.0500000000000043},
{"total_number_of_episodes": 51622, "number_of_timesteps": 11421409, "per_episode_reward": 66.95, "episode_reward_trend_value": 0.08500000000000006, "biggest_recent_change": 4.050000000000004},
{"total_number_of_episodes": 51632, "number_of_timesteps": 11426409, "per_episode_reward": 67.0, "episode_reward_trend_value": 0.07388888888888887, "biggest_recent_change": 4.050000000000004},
{"total_number_of_episodes": 51642, "number_of_timesteps": 11431409, "per_episode_reward": 67.35, "episode_reward_trend_value": 0.06611111111111106, "biggest_recent_change": 4.050000000000004},
{"total_number_of_episodes": 51652, "number_of_timesteps": 11436409, "per_episode_reward": 67.75, "episode_reward_trend_value": 0.06888888888888892, "biggest_recent_change": 4.050000000000004},
{"total_number_of_episodes": 51662, "number_of_timesteps": 11441409, "per_episode_reward": 67.95, "episode_reward_trend_value": 0.06888888888888892, "biggest_recent_change": 4.050000000000004},
{"total_number_of_episodes": 51672, "number_of_timesteps": 11446409, "per_episode_reward": 68.1, "episode_reward_trend_value": 0.06666666666666658, "biggest_recent_change": 4.050000000000004},
{"total_number_of_episodes": 51682, "number_of_timesteps": 11451409, "per_episode_reward": 68.5, "episode_reward_trend_value": 0.0677777777777778, "biggest_recent_change": 4.050000000000004},
{"total_number_of_episodes": 51692, "number_of_timesteps": 11456409, "per_episode_reward": 68.95, "episode_reward_trend_value": 0.07000000000000005, "biggest_recent_change": 4.050000000000004},
{"total_number_of_episodes": 51702, "number_of_timesteps": 11461409, "per_episode_reward": 69.3, "episode_reward_trend_value": 0.0711111111111111, "biggest_recent_change": 4.050000000000004},
{"total_number_of_episodes": 51712, "number_of_timesteps": 11466409, "per_episode_reward": 69.6, "episode_reward_trend_value": 0.02944444444444435, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 51722, "number_of_timesteps": 11471409, "per_episode_reward": 70.3, "episode_reward_trend_value": 0.03666666666666664, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 51732, "number_of_timesteps": 11476409, "per_episode_reward": 71.0, "episode_reward_trend_value": 0.040555555555555615, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 51742, "number_of_timesteps": 11481409, "per_episode_reward": 71.0, "episode_reward_trend_value": 0.03611111111111111, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 51752, "number_of_timesteps": 11486409, "per_episode_reward": 71.0, "episode_reward_trend_value": 0.03388888888888886, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 51762, "number_of_timesteps": 11491409, "per_episode_reward": 71.0, "episode_reward_trend_value": 0.032222222222222284, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 51772, "number_of_timesteps": 11496409, "per_episode_reward": 71.0, "episode_reward_trend_value": 0.02777777777777778, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 51782, "number_of_timesteps": 11501409, "per_episode_reward": 71.0, "episode_reward_trend_value": 0.022777777777777748, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 51792, "number_of_timesteps": 11506409, "per_episode_reward": 71.0, "episode_reward_trend_value": 0.01888888888888892, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 51802, "number_of_timesteps": 11511409, "per_episode_reward": 71.0, "episode_reward_trend_value": 0.01555555555555562, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 51812, "number_of_timesteps": 11516409, "per_episode_reward": 71.0, "episode_reward_trend_value": 0.00777777777777781, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 51822, "number_of_timesteps": 11521409, "per_episode_reward": 71.05, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 51832, "number_of_timesteps": 11526409, "per_episode_reward": 71.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 51842, "number_of_timesteps": 11531409, "per_episode_reward": 71.15, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 51852, "number_of_timesteps": 11536409, "per_episode_reward": 71.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 51862, "number_of_timesteps": 11541409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 51872, "number_of_timesteps": 11546409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 51882, "number_of_timesteps": 11551409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 51892, "number_of_timesteps": 11556409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 51902, "number_of_timesteps": 11561409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 51912, "number_of_timesteps": 11566409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 51922, "number_of_timesteps": 11571409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 51932, "number_of_timesteps": 11576409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 51942, "number_of_timesteps": 11581409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 51952, "number_of_timesteps": 11586409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 51962, "number_of_timesteps": 11591409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 51972, "number_of_timesteps": 11596409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 51982, "number_of_timesteps": 11601409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 51992, "number_of_timesteps": 11606409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52002, "number_of_timesteps": 11611409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52012, "number_of_timesteps": 11616409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52022, "number_of_timesteps": 11621409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52032, "number_of_timesteps": 11626409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52042, "number_of_timesteps": 11631409, "per_episode_reward": 71.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52052, "number_of_timesteps": 11636409, "per_episode_reward": 71.35, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52062, "number_of_timesteps": 11641409, "per_episode_reward": 71.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52072, "number_of_timesteps": 11646409, "per_episode_reward": 71.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52082, "number_of_timesteps": 11651409, "per_episode_reward": 71.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52092, "number_of_timesteps": 11656409, "per_episode_reward": 71.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52102, "number_of_timesteps": 11661409, "per_episode_reward": 71.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52112, "number_of_timesteps": 11666409, "per_episode_reward": 71.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52122, "number_of_timesteps": 11671409, "per_episode_reward": 71.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52132, "number_of_timesteps": 11676409, "per_episode_reward": 71.45, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52142, "number_of_timesteps": 11681409, "per_episode_reward": 71.5, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52152, "number_of_timesteps": 11686409, "per_episode_reward": 71.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52162, "number_of_timesteps": 11691409, "per_episode_reward": 71.55, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52172, "number_of_timesteps": 11696409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52182, "number_of_timesteps": 11701409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52192, "number_of_timesteps": 11706409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52202, "number_of_timesteps": 11711409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52212, "number_of_timesteps": 11716409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52222, "number_of_timesteps": 11721409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52232, "number_of_timesteps": 11726409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52242, "number_of_timesteps": 11731409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52252, "number_of_timesteps": 11736409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52262, "number_of_timesteps": 11741409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52272, "number_of_timesteps": 11746409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52282, "number_of_timesteps": 11751409, "per_episode_reward": 71.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52292, "number_of_timesteps": 11756409, "per_episode_reward": 71.65, "episode_reward_trend_value": 0.0005555555555556819, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52302, "number_of_timesteps": 11761409, "per_episode_reward": 71.7, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52312, "number_of_timesteps": 11766409, "per_episode_reward": 71.75, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52322, "number_of_timesteps": 11771409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52332, "number_of_timesteps": 11776409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52342, "number_of_timesteps": 11781409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52352, "number_of_timesteps": 11786409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52362, "number_of_timesteps": 11791409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52372, "number_of_timesteps": 11796409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52382, "number_of_timesteps": 11801409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52392, "number_of_timesteps": 11806409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52402, "number_of_timesteps": 11811409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52412, "number_of_timesteps": 11816409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52422, "number_of_timesteps": 11821409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52432, "number_of_timesteps": 11826409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52442, "number_of_timesteps": 11831409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52452, "number_of_timesteps": 11836409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52462, "number_of_timesteps": 11841409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52472, "number_of_timesteps": 11846409, "per_episode_reward": 71.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52482, "number_of_timesteps": 11851409, "per_episode_reward": 71.85, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52492, "number_of_timesteps": 11856409, "per_episode_reward": 71.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52502, "number_of_timesteps": 11861409, "per_episode_reward": 71.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52512, "number_of_timesteps": 11866409, "per_episode_reward": 71.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52522, "number_of_timesteps": 11871409, "per_episode_reward": 71.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52532, "number_of_timesteps": 11876409, "per_episode_reward": 71.95, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52542, "number_of_timesteps": 11881409, "per_episode_reward": 72.0, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52552, "number_of_timesteps": 11886409, "per_episode_reward": 72.0, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52562, "number_of_timesteps": 11891409, "per_episode_reward": 72.0, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52572, "number_of_timesteps": 11896409, "per_episode_reward": 72.05, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52582, "number_of_timesteps": 11901409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52592, "number_of_timesteps": 11906409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52602, "number_of_timesteps": 11911409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52612, "number_of_timesteps": 11916409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52622, "number_of_timesteps": 11921409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52632, "number_of_timesteps": 11926409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52642, "number_of_timesteps": 11931409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52652, "number_of_timesteps": 11936409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52662, "number_of_timesteps": 11941409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52672, "number_of_timesteps": 11946409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52682, "number_of_timesteps": 11951409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52692, "number_of_timesteps": 11956409, "per_episode_reward": 72.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52702, "number_of_timesteps": 11961409, "per_episode_reward": 72.15, "episode_reward_trend_value": 0.0005555555555556819, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52712, "number_of_timesteps": 11966409, "per_episode_reward": 72.25, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 52722, "number_of_timesteps": 11971409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 52732, "number_of_timesteps": 11976409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 52742, "number_of_timesteps": 11981409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 52752, "number_of_timesteps": 11986409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 52762, "number_of_timesteps": 11991409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 52772, "number_of_timesteps": 11996409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 52782, "number_of_timesteps": 12001409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 52792, "number_of_timesteps": 12006409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 52802, "number_of_timesteps": 12011409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52812, "number_of_timesteps": 12016409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52822, "number_of_timesteps": 12021409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52832, "number_of_timesteps": 12026409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52842, "number_of_timesteps": 12031409, "per_episode_reward": 72.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52852, "number_of_timesteps": 12036409, "per_episode_reward": 72.35, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52862, "number_of_timesteps": 12041409, "per_episode_reward": 72.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52872, "number_of_timesteps": 12046409, "per_episode_reward": 72.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52882, "number_of_timesteps": 12051409, "per_episode_reward": 72.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52892, "number_of_timesteps": 12056409, "per_episode_reward": 72.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52902, "number_of_timesteps": 12061409, "per_episode_reward": 72.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52912, "number_of_timesteps": 12066409, "per_episode_reward": 72.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52922, "number_of_timesteps": 12071409, "per_episode_reward": 72.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52932, "number_of_timesteps": 12076409, "per_episode_reward": 72.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52942, "number_of_timesteps": 12081409, "per_episode_reward": 72.4, "episode_reward_trend_value": 0.0005555555555556819, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 52952, "number_of_timesteps": 12086409, "per_episode_reward": 72.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 52962, "number_of_timesteps": 12091409, "per_episode_reward": 72.45, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52972, "number_of_timesteps": 12096409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52982, "number_of_timesteps": 12101409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 52992, "number_of_timesteps": 12106409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53002, "number_of_timesteps": 12111409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53012, "number_of_timesteps": 12116409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53022, "number_of_timesteps": 12121409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53032, "number_of_timesteps": 12126409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53042, "number_of_timesteps": 12131409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53052, "number_of_timesteps": 12136409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53062, "number_of_timesteps": 12141409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 53072, "number_of_timesteps": 12146409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 53082, "number_of_timesteps": 12151409, "per_episode_reward": 72.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 53092, "number_of_timesteps": 12156409, "per_episode_reward": 72.55, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53102, "number_of_timesteps": 12161409, "per_episode_reward": 72.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53112, "number_of_timesteps": 12166409, "per_episode_reward": 72.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53122, "number_of_timesteps": 12171409, "per_episode_reward": 72.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53132, "number_of_timesteps": 12176409, "per_episode_reward": 72.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53142, "number_of_timesteps": 12181409, "per_episode_reward": 72.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53152, "number_of_timesteps": 12186409, "per_episode_reward": 72.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53162, "number_of_timesteps": 12191409, "per_episode_reward": 72.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53172, "number_of_timesteps": 12196409, "per_episode_reward": 72.65, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53182, "number_of_timesteps": 12201409, "per_episode_reward": 72.7, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53192, "number_of_timesteps": 12206409, "per_episode_reward": 72.75, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53202, "number_of_timesteps": 12211409, "per_episode_reward": 72.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53212, "number_of_timesteps": 12216409, "per_episode_reward": 72.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53222, "number_of_timesteps": 12221409, "per_episode_reward": 72.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53232, "number_of_timesteps": 12226409, "per_episode_reward": 72.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53242, "number_of_timesteps": 12231409, "per_episode_reward": 72.9, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53252, "number_of_timesteps": 12236409, "per_episode_reward": 72.9, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53262, "number_of_timesteps": 12241409, "per_episode_reward": 72.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53272, "number_of_timesteps": 12246409, "per_episode_reward": 72.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53282, "number_of_timesteps": 12251409, "per_episode_reward": 72.9, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53292, "number_of_timesteps": 12256409, "per_episode_reward": 72.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53302, "number_of_timesteps": 12261409, "per_episode_reward": 72.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53312, "number_of_timesteps": 12266409, "per_episode_reward": 72.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53322, "number_of_timesteps": 12271409, "per_episode_reward": 72.95, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53332, "number_of_timesteps": 12276409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53342, "number_of_timesteps": 12281409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53352, "number_of_timesteps": 12286409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53362, "number_of_timesteps": 12291409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53372, "number_of_timesteps": 12296409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53382, "number_of_timesteps": 12301409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53392, "number_of_timesteps": 12306409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53402, "number_of_timesteps": 12311409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53412, "number_of_timesteps": 12316409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53422, "number_of_timesteps": 12321409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 53432, "number_of_timesteps": 12326409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 53442, "number_of_timesteps": 12331409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 53452, "number_of_timesteps": 12336409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 53462, "number_of_timesteps": 12341409, "per_episode_reward": 73.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 53472, "number_of_timesteps": 12346409, "per_episode_reward": 73.05, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53482, "number_of_timesteps": 12351409, "per_episode_reward": 73.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53492, "number_of_timesteps": 12356409, "per_episode_reward": 73.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53502, "number_of_timesteps": 12361409, "per_episode_reward": 73.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53512, "number_of_timesteps": 12366409, "per_episode_reward": 73.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53522, "number_of_timesteps": 12371409, "per_episode_reward": 73.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53532, "number_of_timesteps": 12376409, "per_episode_reward": 73.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53542, "number_of_timesteps": 12381409, "per_episode_reward": 73.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53552, "number_of_timesteps": 12386409, "per_episode_reward": 73.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53562, "number_of_timesteps": 12391409, "per_episode_reward": 73.1, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53572, "number_of_timesteps": 12396409, "per_episode_reward": 73.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 53582, "number_of_timesteps": 12401409, "per_episode_reward": 73.15, "episode_reward_trend_value": 0.0005555555555556819, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53592, "number_of_timesteps": 12406409, "per_episode_reward": 73.25, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 53602, "number_of_timesteps": 12411409, "per_episode_reward": 73.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 53612, "number_of_timesteps": 12416409, "per_episode_reward": 73.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 53622, "number_of_timesteps": 12421409, "per_episode_reward": 73.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 53632, "number_of_timesteps": 12426409, "per_episode_reward": 73.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 53642, "number_of_timesteps": 12431409, "per_episode_reward": 73.4, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 53652, "number_of_timesteps": 12436409, "per_episode_reward": 73.4, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 53662, "number_of_timesteps": 12441409, "per_episode_reward": 73.4, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 53672, "number_of_timesteps": 12446409, "per_episode_reward": 73.4, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 53682, "number_of_timesteps": 12451409, "per_episode_reward": 73.4, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53692, "number_of_timesteps": 12456409, "per_episode_reward": 73.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53702, "number_of_timesteps": 12461409, "per_episode_reward": 73.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53712, "number_of_timesteps": 12466409, "per_episode_reward": 73.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53722, "number_of_timesteps": 12471409, "per_episode_reward": 73.4, "episode_reward_trend_value": 0.0005555555555556819, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53732, "number_of_timesteps": 12476409, "per_episode_reward": 73.45, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53742, "number_of_timesteps": 12481409, "per_episode_reward": 73.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53752, "number_of_timesteps": 12486409, "per_episode_reward": 73.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53762, "number_of_timesteps": 12491409, "per_episode_reward": 73.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53772, "number_of_timesteps": 12496409, "per_episode_reward": 73.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53782, "number_of_timesteps": 12501409, "per_episode_reward": 73.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53792, "number_of_timesteps": 12506409, "per_episode_reward": 73.55, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53802, "number_of_timesteps": 12511409, "per_episode_reward": 73.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 53812, "number_of_timesteps": 12516409, "per_episode_reward": 73.7, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 53822, "number_of_timesteps": 12521409, "per_episode_reward": 73.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 53832, "number_of_timesteps": 12526409, "per_episode_reward": 73.7, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 53842, "number_of_timesteps": 12531409, "per_episode_reward": 73.7, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 53852, "number_of_timesteps": 12536409, "per_episode_reward": 73.7, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 53862, "number_of_timesteps": 12541409, "per_episode_reward": 73.7, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 53872, "number_of_timesteps": 12546409, "per_episode_reward": 73.7, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 53882, "number_of_timesteps": 12551409, "per_episode_reward": 73.7, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 53892, "number_of_timesteps": 12556409, "per_episode_reward": 73.7, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53902, "number_of_timesteps": 12561409, "per_episode_reward": 73.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 53912, "number_of_timesteps": 12566409, "per_episode_reward": 73.75, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53922, "number_of_timesteps": 12571409, "per_episode_reward": 73.8, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53932, "number_of_timesteps": 12576409, "per_episode_reward": 73.8, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53942, "number_of_timesteps": 12581409, "per_episode_reward": 73.85, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 53952, "number_of_timesteps": 12586409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53962, "number_of_timesteps": 12591409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53972, "number_of_timesteps": 12596409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53982, "number_of_timesteps": 12601409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 53992, "number_of_timesteps": 12606409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54002, "number_of_timesteps": 12611409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54012, "number_of_timesteps": 12616409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54022, "number_of_timesteps": 12621409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54032, "number_of_timesteps": 12626409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0005555555555556819, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54042, "number_of_timesteps": 12631409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54052, "number_of_timesteps": 12636409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54062, "number_of_timesteps": 12641409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54072, "number_of_timesteps": 12646409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54082, "number_of_timesteps": 12651409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54092, "number_of_timesteps": 12656409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54102, "number_of_timesteps": 12661409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54112, "number_of_timesteps": 12666409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54122, "number_of_timesteps": 12671409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54132, "number_of_timesteps": 12676409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54142, "number_of_timesteps": 12681409, "per_episode_reward": 73.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54152, "number_of_timesteps": 12686409, "per_episode_reward": 73.95, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54162, "number_of_timesteps": 12691409, "per_episode_reward": 74.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54172, "number_of_timesteps": 12696409, "per_episode_reward": 74.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54182, "number_of_timesteps": 12701409, "per_episode_reward": 74.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54192, "number_of_timesteps": 12706409, "per_episode_reward": 74.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 54202, "number_of_timesteps": 12711409, "per_episode_reward": 74.2, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54212, "number_of_timesteps": 12716409, "per_episode_reward": 74.2, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54222, "number_of_timesteps": 12721409, "per_episode_reward": 74.25, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54232, "number_of_timesteps": 12726409, "per_episode_reward": 74.3, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54242, "number_of_timesteps": 12731409, "per_episode_reward": 74.3, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54252, "number_of_timesteps": 12736409, "per_episode_reward": 74.3, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54262, "number_of_timesteps": 12741409, "per_episode_reward": 74.3, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54272, "number_of_timesteps": 12746409, "per_episode_reward": 74.3, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54282, "number_of_timesteps": 12751409, "per_episode_reward": 74.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54292, "number_of_timesteps": 12756409, "per_episode_reward": 74.3, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54302, "number_of_timesteps": 12761409, "per_episode_reward": 74.3, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54312, "number_of_timesteps": 12766409, "per_episode_reward": 74.3, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54322, "number_of_timesteps": 12771409, "per_episode_reward": 74.35, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54332, "number_of_timesteps": 12776409, "per_episode_reward": 74.45, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54342, "number_of_timesteps": 12781409, "per_episode_reward": 74.5, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54352, "number_of_timesteps": 12786409, "per_episode_reward": 74.5, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54362, "number_of_timesteps": 12791409, "per_episode_reward": 74.5, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54372, "number_of_timesteps": 12796409, "per_episode_reward": 74.55, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54382, "number_of_timesteps": 12801409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54392, "number_of_timesteps": 12806409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54402, "number_of_timesteps": 12811409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54412, "number_of_timesteps": 12816409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 54422, "number_of_timesteps": 12821409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54432, "number_of_timesteps": 12826409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54442, "number_of_timesteps": 12831409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54452, "number_of_timesteps": 12836409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54462, "number_of_timesteps": 12841409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54472, "number_of_timesteps": 12846409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54482, "number_of_timesteps": 12851409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54492, "number_of_timesteps": 12856409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54502, "number_of_timesteps": 12861409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54512, "number_of_timesteps": 12866409, "per_episode_reward": 74.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54522, "number_of_timesteps": 12871409, "per_episode_reward": 74.65, "episode_reward_trend_value": 0.0005555555555556819, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54532, "number_of_timesteps": 12876409, "per_episode_reward": 74.7, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54542, "number_of_timesteps": 12881409, "per_episode_reward": 74.7, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54552, "number_of_timesteps": 12886409, "per_episode_reward": 74.75, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54562, "number_of_timesteps": 12891409, "per_episode_reward": 74.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54572, "number_of_timesteps": 12896409, "per_episode_reward": 74.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54582, "number_of_timesteps": 12901409, "per_episode_reward": 74.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54592, "number_of_timesteps": 12906409, "per_episode_reward": 74.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54602, "number_of_timesteps": 12911409, "per_episode_reward": 74.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54612, "number_of_timesteps": 12916409, "per_episode_reward": 74.85, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54622, "number_of_timesteps": 12921409, "per_episode_reward": 74.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54632, "number_of_timesteps": 12926409, "per_episode_reward": 74.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54642, "number_of_timesteps": 12931409, "per_episode_reward": 74.9, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54652, "number_of_timesteps": 12936409, "per_episode_reward": 74.95, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54662, "number_of_timesteps": 12941409, "per_episode_reward": 75.0, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54672, "number_of_timesteps": 12946409, "per_episode_reward": 75.0, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54682, "number_of_timesteps": 12951409, "per_episode_reward": 75.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54692, "number_of_timesteps": 12956409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54702, "number_of_timesteps": 12961409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54712, "number_of_timesteps": 12966409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54722, "number_of_timesteps": 12971409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54732, "number_of_timesteps": 12976409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54742, "number_of_timesteps": 12981409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54752, "number_of_timesteps": 12986409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54762, "number_of_timesteps": 12991409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54772, "number_of_timesteps": 12996409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 54782, "number_of_timesteps": 13001409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54792, "number_of_timesteps": 13006409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54802, "number_of_timesteps": 13011409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54812, "number_of_timesteps": 13016409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54822, "number_of_timesteps": 13021409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54832, "number_of_timesteps": 13026409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54842, "number_of_timesteps": 13031409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54852, "number_of_timesteps": 13036409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54862, "number_of_timesteps": 13041409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54872, "number_of_timesteps": 13046409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54882, "number_of_timesteps": 13051409, "per_episode_reward": 75.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 54892, "number_of_timesteps": 13056409, "per_episode_reward": 75.15, "episode_reward_trend_value": 0.0005555555555556819, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54902, "number_of_timesteps": 13061409, "per_episode_reward": 75.2, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54912, "number_of_timesteps": 13066409, "per_episode_reward": 75.2, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54922, "number_of_timesteps": 13071409, "per_episode_reward": 75.2, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54932, "number_of_timesteps": 13076409, "per_episode_reward": 75.2, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54942, "number_of_timesteps": 13081409, "per_episode_reward": 75.2, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54952, "number_of_timesteps": 13086409, "per_episode_reward": 75.2, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54962, "number_of_timesteps": 13091409, "per_episode_reward": 75.2, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 54972, "number_of_timesteps": 13096409, "per_episode_reward": 75.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 54982, "number_of_timesteps": 13101409, "per_episode_reward": 75.45, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 54992, "number_of_timesteps": 13106409, "per_episode_reward": 75.5, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55002, "number_of_timesteps": 13111409, "per_episode_reward": 75.5, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55012, "number_of_timesteps": 13116409, "per_episode_reward": 75.5, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55022, "number_of_timesteps": 13121409, "per_episode_reward": 75.5, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55032, "number_of_timesteps": 13126409, "per_episode_reward": 75.55, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55042, "number_of_timesteps": 13131409, "per_episode_reward": 75.6, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55052, "number_of_timesteps": 13136409, "per_episode_reward": 75.6, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55062, "number_of_timesteps": 13141409, "per_episode_reward": 75.65, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55072, "number_of_timesteps": 13146409, "per_episode_reward": 75.75, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55082, "number_of_timesteps": 13151409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55092, "number_of_timesteps": 13156409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55102, "number_of_timesteps": 13161409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55112, "number_of_timesteps": 13166409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55122, "number_of_timesteps": 13171409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55132, "number_of_timesteps": 13176409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55142, "number_of_timesteps": 13181409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55152, "number_of_timesteps": 13186409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55162, "number_of_timesteps": 13191409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55172, "number_of_timesteps": 13196409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 55182, "number_of_timesteps": 13201409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 55192, "number_of_timesteps": 13206409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 55202, "number_of_timesteps": 13211409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 55212, "number_of_timesteps": 13216409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 55222, "number_of_timesteps": 13221409, "per_episode_reward": 75.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 55232, "number_of_timesteps": 13226409, "per_episode_reward": 75.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55242, "number_of_timesteps": 13231409, "per_episode_reward": 76.0, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55252, "number_of_timesteps": 13236409, "per_episode_reward": 76.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55262, "number_of_timesteps": 13241409, "per_episode_reward": 76.1, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55272, "number_of_timesteps": 13246409, "per_episode_reward": 76.1, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55282, "number_of_timesteps": 13251409, "per_episode_reward": 76.1, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55292, "number_of_timesteps": 13256409, "per_episode_reward": 76.1, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55302, "number_of_timesteps": 13261409, "per_episode_reward": 76.1, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55312, "number_of_timesteps": 13266409, "per_episode_reward": 76.1, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55322, "number_of_timesteps": 13271409, "per_episode_reward": 76.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55332, "number_of_timesteps": 13276409, "per_episode_reward": 76.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55342, "number_of_timesteps": 13281409, "per_episode_reward": 76.15, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55352, "number_of_timesteps": 13286409, "per_episode_reward": 76.2, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55362, "number_of_timesteps": 13291409, "per_episode_reward": 76.2, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55372, "number_of_timesteps": 13296409, "per_episode_reward": 76.25, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55382, "number_of_timesteps": 13301409, "per_episode_reward": 76.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55392, "number_of_timesteps": 13306409, "per_episode_reward": 76.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55402, "number_of_timesteps": 13311409, "per_episode_reward": 76.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55412, "number_of_timesteps": 13316409, "per_episode_reward": 76.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55422, "number_of_timesteps": 13321409, "per_episode_reward": 76.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55432, "number_of_timesteps": 13326409, "per_episode_reward": 76.4, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55442, "number_of_timesteps": 13331409, "per_episode_reward": 76.4, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55452, "number_of_timesteps": 13336409, "per_episode_reward": 76.4, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55462, "number_of_timesteps": 13341409, "per_episode_reward": 76.4, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55472, "number_of_timesteps": 13346409, "per_episode_reward": 76.45, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55482, "number_of_timesteps": 13351409, "per_episode_reward": 76.5, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55492, "number_of_timesteps": 13356409, "per_episode_reward": 76.5, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55502, "number_of_timesteps": 13361409, "per_episode_reward": 76.5, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55512, "number_of_timesteps": 13366409, "per_episode_reward": 76.55, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55522, "number_of_timesteps": 13371409, "per_episode_reward": 76.6, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55532, "number_of_timesteps": 13376409, "per_episode_reward": 76.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55542, "number_of_timesteps": 13381409, "per_episode_reward": 76.7, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55552, "number_of_timesteps": 13386409, "per_episode_reward": 76.7, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55562, "number_of_timesteps": 13391409, "per_episode_reward": 76.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55572, "number_of_timesteps": 13396409, "per_episode_reward": 76.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55582, "number_of_timesteps": 13401409, "per_episode_reward": 76.8, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55592, "number_of_timesteps": 13406409, "per_episode_reward": 76.8, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55602, "number_of_timesteps": 13411409, "per_episode_reward": 76.9, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55612, "number_of_timesteps": 13416409, "per_episode_reward": 77.0, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55622, "number_of_timesteps": 13421409, "per_episode_reward": 77.0, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55632, "number_of_timesteps": 13426409, "per_episode_reward": 77.0, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55642, "number_of_timesteps": 13431409, "per_episode_reward": 77.0, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55652, "number_of_timesteps": 13436409, "per_episode_reward": 77.0, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55662, "number_of_timesteps": 13441409, "per_episode_reward": 77.0, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55672, "number_of_timesteps": 13446409, "per_episode_reward": 77.0, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55682, "number_of_timesteps": 13451409, "per_episode_reward": 77.0, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55692, "number_of_timesteps": 13456409, "per_episode_reward": 77.05, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55702, "number_of_timesteps": 13461409, "per_episode_reward": 77.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55712, "number_of_timesteps": 13466409, "per_episode_reward": 77.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55722, "number_of_timesteps": 13471409, "per_episode_reward": 77.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55732, "number_of_timesteps": 13476409, "per_episode_reward": 77.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55742, "number_of_timesteps": 13481409, "per_episode_reward": 77.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55752, "number_of_timesteps": 13486409, "per_episode_reward": 77.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55762, "number_of_timesteps": 13491409, "per_episode_reward": 77.1, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55772, "number_of_timesteps": 13496409, "per_episode_reward": 77.2, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55782, "number_of_timesteps": 13501409, "per_episode_reward": 77.3, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55792, "number_of_timesteps": 13506409, "per_episode_reward": 77.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55802, "number_of_timesteps": 13511409, "per_episode_reward": 77.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55812, "number_of_timesteps": 13516409, "per_episode_reward": 77.4, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55822, "number_of_timesteps": 13521409, "per_episode_reward": 77.4, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55832, "number_of_timesteps": 13526409, "per_episode_reward": 77.4, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55842, "number_of_timesteps": 13531409, "per_episode_reward": 77.4, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55852, "number_of_timesteps": 13536409, "per_episode_reward": 77.4, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 55862, "number_of_timesteps": 13541409, "per_episode_reward": 77.4, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 55872, "number_of_timesteps": 13546409, "per_episode_reward": 77.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55882, "number_of_timesteps": 13551409, "per_episode_reward": 77.4, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55892, "number_of_timesteps": 13556409, "per_episode_reward": 77.45, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 55902, "number_of_timesteps": 13561409, "per_episode_reward": 77.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55912, "number_of_timesteps": 13566409, "per_episode_reward": 77.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55922, "number_of_timesteps": 13571409, "per_episode_reward": 77.55, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 55932, "number_of_timesteps": 13576409, "per_episode_reward": 77.7, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55942, "number_of_timesteps": 13581409, "per_episode_reward": 77.8, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55952, "number_of_timesteps": 13586409, "per_episode_reward": 77.8, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55962, "number_of_timesteps": 13591409, "per_episode_reward": 77.85, "episode_reward_trend_value": 0.004999999999999874, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55972, "number_of_timesteps": 13596409, "per_episode_reward": 77.9, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55982, "number_of_timesteps": 13601409, "per_episode_reward": 77.9, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 55992, "number_of_timesteps": 13606409, "per_episode_reward": 77.9, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 56002, "number_of_timesteps": 13611409, "per_episode_reward": 77.9, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 56012, "number_of_timesteps": 13616409, "per_episode_reward": 77.9, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 56022, "number_of_timesteps": 13621409, "per_episode_reward": 77.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56032, "number_of_timesteps": 13626409, "per_episode_reward": 77.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56042, "number_of_timesteps": 13631409, "per_episode_reward": 77.9, "episode_reward_trend_value": 0.0011111111111112059, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56052, "number_of_timesteps": 13636409, "per_episode_reward": 77.9, "episode_reward_trend_value": 0.0005555555555556819, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56062, "number_of_timesteps": 13641409, "per_episode_reward": 77.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 56072, "number_of_timesteps": 13646409, "per_episode_reward": 77.95, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56082, "number_of_timesteps": 13651409, "per_episode_reward": 78.0, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56092, "number_of_timesteps": 13656409, "per_episode_reward": 78.05, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56102, "number_of_timesteps": 13661409, "per_episode_reward": 78.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56112, "number_of_timesteps": 13666409, "per_episode_reward": 78.2, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56122, "number_of_timesteps": 13671409, "per_episode_reward": 78.3, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56132, "number_of_timesteps": 13676409, "per_episode_reward": 78.3, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56142, "number_of_timesteps": 13681409, "per_episode_reward": 78.35, "episode_reward_trend_value": 0.004999999999999874, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56152, "number_of_timesteps": 13686409, "per_episode_reward": 78.4, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56162, "number_of_timesteps": 13691409, "per_episode_reward": 78.4, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56172, "number_of_timesteps": 13696409, "per_episode_reward": 78.4, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56182, "number_of_timesteps": 13701409, "per_episode_reward": 78.4, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56192, "number_of_timesteps": 13706409, "per_episode_reward": 78.4, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56202, "number_of_timesteps": 13711409, "per_episode_reward": 78.45, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56212, "number_of_timesteps": 13716409, "per_episode_reward": 78.5, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56222, "number_of_timesteps": 13721409, "per_episode_reward": 78.5, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56232, "number_of_timesteps": 13726409, "per_episode_reward": 78.5, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56242, "number_of_timesteps": 13731409, "per_episode_reward": 78.5, "episode_reward_trend_value": 0.001111111111111048, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56252, "number_of_timesteps": 13736409, "per_episode_reward": 78.6, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56262, "number_of_timesteps": 13741409, "per_episode_reward": 78.7, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56272, "number_of_timesteps": 13746409, "per_episode_reward": 78.7, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56282, "number_of_timesteps": 13751409, "per_episode_reward": 78.7, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56292, "number_of_timesteps": 13756409, "per_episode_reward": 78.75, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56302, "number_of_timesteps": 13761409, "per_episode_reward": 78.8, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56312, "number_of_timesteps": 13766409, "per_episode_reward": 78.85, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56322, "number_of_timesteps": 13771409, "per_episode_reward": 78.9, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56332, "number_of_timesteps": 13776409, "per_episode_reward": 78.9, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56342, "number_of_timesteps": 13781409, "per_episode_reward": 78.9, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56352, "number_of_timesteps": 13786409, "per_episode_reward": 78.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56362, "number_of_timesteps": 13791409, "per_episode_reward": 78.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56372, "number_of_timesteps": 13796409, "per_episode_reward": 78.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56382, "number_of_timesteps": 13801409, "per_episode_reward": 78.9, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56392, "number_of_timesteps": 13806409, "per_episode_reward": 78.95, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56402, "number_of_timesteps": 13811409, "per_episode_reward": 79.0, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56412, "number_of_timesteps": 13816409, "per_episode_reward": 79.05, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56422, "number_of_timesteps": 13821409, "per_episode_reward": 79.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56432, "number_of_timesteps": 13826409, "per_episode_reward": 79.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56442, "number_of_timesteps": 13831409, "per_episode_reward": 79.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56452, "number_of_timesteps": 13836409, "per_episode_reward": 79.15, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56462, "number_of_timesteps": 13841409, "per_episode_reward": 79.2, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56472, "number_of_timesteps": 13846409, "per_episode_reward": 79.2, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56482, "number_of_timesteps": 13851409, "per_episode_reward": 79.25, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56492, "number_of_timesteps": 13856409, "per_episode_reward": 79.35, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56502, "number_of_timesteps": 13861409, "per_episode_reward": 79.4, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56512, "number_of_timesteps": 13866409, "per_episode_reward": 79.4, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56522, "number_of_timesteps": 13871409, "per_episode_reward": 79.45, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56532, "number_of_timesteps": 13876409, "per_episode_reward": 79.5, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56542, "number_of_timesteps": 13881409, "per_episode_reward": 79.5, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56552, "number_of_timesteps": 13886409, "per_episode_reward": 79.5, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56562, "number_of_timesteps": 13891409, "per_episode_reward": 79.5, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56572, "number_of_timesteps": 13896409, "per_episode_reward": 79.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56582, "number_of_timesteps": 13901409, "per_episode_reward": 79.5, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56592, "number_of_timesteps": 13905974, "per_episode_reward": 79.6, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56602, "number_of_timesteps": 13910974, "per_episode_reward": 79.7, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56612, "number_of_timesteps": 13915974, "per_episode_reward": 79.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56622, "number_of_timesteps": 13920974, "per_episode_reward": 79.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56632, "number_of_timesteps": 13925974, "per_episode_reward": 79.8, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56642, "number_of_timesteps": 13930974, "per_episode_reward": 79.85, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56652, "number_of_timesteps": 13935974, "per_episode_reward": 79.9, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56662, "number_of_timesteps": 13940974, "per_episode_reward": 79.9, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56672, "number_of_timesteps": 13945974, "per_episode_reward": 79.95, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56682, "number_of_timesteps": 13950974, "per_episode_reward": 80.0, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56692, "number_of_timesteps": 13955974, "per_episode_reward": 80.0, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56702, "number_of_timesteps": 13960974, "per_episode_reward": 80.0, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56712, "number_of_timesteps": 13965974, "per_episode_reward": 80.05, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56722, "number_of_timesteps": 13970974, "per_episode_reward": 80.1, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56732, "number_of_timesteps": 13975974, "per_episode_reward": 80.1, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56742, "number_of_timesteps": 13980974, "per_episode_reward": 80.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56752, "number_of_timesteps": 13985974, "per_episode_reward": 80.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56762, "number_of_timesteps": 13990974, "per_episode_reward": 80.1, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56772, "number_of_timesteps": 13995974, "per_episode_reward": 80.15, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56782, "number_of_timesteps": 14000974, "per_episode_reward": 80.2, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56792, "number_of_timesteps": 14005974, "per_episode_reward": 80.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 56802, "number_of_timesteps": 14010854, "per_episode_reward": 80.35, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56812, "number_of_timesteps": 14015854, "per_episode_reward": 80.45, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56822, "number_of_timesteps": 14020854, "per_episode_reward": 80.55, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56832, "number_of_timesteps": 14025854, "per_episode_reward": 80.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56842, "number_of_timesteps": 14030854, "per_episode_reward": 80.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56852, "number_of_timesteps": 14035854, "per_episode_reward": 80.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56862, "number_of_timesteps": 14040854, "per_episode_reward": 80.6, "episode_reward_trend_value": 0.004999999999999874, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56872, "number_of_timesteps": 14045854, "per_episode_reward": 80.6, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56882, "number_of_timesteps": 14050854, "per_episode_reward": 80.6, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56892, "number_of_timesteps": 14055854, "per_episode_reward": 80.6, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 56902, "number_of_timesteps": 14060854, "per_episode_reward": 80.6, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 56912, "number_of_timesteps": 14065854, "per_episode_reward": 80.6, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 56922, "number_of_timesteps": 14070854, "per_episode_reward": 80.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 56932, "number_of_timesteps": 14075854, "per_episode_reward": 80.75, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 56942, "number_of_timesteps": 14080854, "per_episode_reward": 80.9, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 56952, "number_of_timesteps": 14085854, "per_episode_reward": 80.9, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 56962, "number_of_timesteps": 14090854, "per_episode_reward": 80.9, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 56972, "number_of_timesteps": 14095854, "per_episode_reward": 80.9, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 56982, "number_of_timesteps": 14100854, "per_episode_reward": 80.95, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 56992, "number_of_timesteps": 14105854, "per_episode_reward": 81.05, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57002, "number_of_timesteps": 14110854, "per_episode_reward": 81.1, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57012, "number_of_timesteps": 14115854, "per_episode_reward": 81.1, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57022, "number_of_timesteps": 14120854, "per_episode_reward": 81.1, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57032, "number_of_timesteps": 14125854, "per_episode_reward": 81.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57042, "number_of_timesteps": 14130854, "per_episode_reward": 81.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57052, "number_of_timesteps": 14135854, "per_episode_reward": 81.1, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57062, "number_of_timesteps": 14140854, "per_episode_reward": 81.15, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57072, "number_of_timesteps": 14145854, "per_episode_reward": 81.25, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57082, "number_of_timesteps": 14150854, "per_episode_reward": 81.3, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57092, "number_of_timesteps": 14155854, "per_episode_reward": 81.3, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57102, "number_of_timesteps": 14160854, "per_episode_reward": 81.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57112, "number_of_timesteps": 14165854, "per_episode_reward": 81.45, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57122, "number_of_timesteps": 14170854, "per_episode_reward": 81.5, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57132, "number_of_timesteps": 14175854, "per_episode_reward": 81.5, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57142, "number_of_timesteps": 14180854, "per_episode_reward": 81.5, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57152, "number_of_timesteps": 14185854, "per_episode_reward": 81.55, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57162, "number_of_timesteps": 14190854, "per_episode_reward": 81.6, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57172, "number_of_timesteps": 14195854, "per_episode_reward": 81.6, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57183, "number_of_timesteps": 14200897, "per_episode_reward": 81.6, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57193, "number_of_timesteps": 14205897, "per_episode_reward": 81.65, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57203, "number_of_timesteps": 14210897, "per_episode_reward": 81.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57213, "number_of_timesteps": 14215897, "per_episode_reward": 81.7, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57223, "number_of_timesteps": 14220897, "per_episode_reward": 81.7, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57233, "number_of_timesteps": 14225897, "per_episode_reward": 81.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57243, "number_of_timesteps": 14230897, "per_episode_reward": 81.85, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57253, "number_of_timesteps": 14235897, "per_episode_reward": 81.9, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57263, "number_of_timesteps": 14240897, "per_episode_reward": 81.9, "episode_reward_trend_value": 0.0033333333333334597, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57273, "number_of_timesteps": 14245897, "per_episode_reward": 81.95, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57283, "number_of_timesteps": 14250897, "per_episode_reward": 82.05, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57293, "number_of_timesteps": 14255897, "per_episode_reward": 82.1, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57303, "number_of_timesteps": 14260897, "per_episode_reward": 82.1, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57313, "number_of_timesteps": 14265897, "per_episode_reward": 82.1, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57323, "number_of_timesteps": 14270897, "per_episode_reward": 82.1, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57333, "number_of_timesteps": 14275897, "per_episode_reward": 82.2, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57343, "number_of_timesteps": 14280897, "per_episode_reward": 82.35, "episode_reward_trend_value": 0.004999999999999874, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 57353, "number_of_timesteps": 14285897, "per_episode_reward": 82.4, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 57363, "number_of_timesteps": 14290897, "per_episode_reward": 82.45, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 57373, "number_of_timesteps": 14295897, "per_episode_reward": 82.55, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 57383, "number_of_timesteps": 14300897, "per_episode_reward": 82.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 57393, "number_of_timesteps": 14305897, "per_episode_reward": 82.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 57403, "number_of_timesteps": 14310897, "per_episode_reward": 82.65, "episode_reward_trend_value": 0.006111111111111237, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 57413, "number_of_timesteps": 14315897, "per_episode_reward": 82.7, "episode_reward_trend_value": 0.006666666666666761, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 57423, "number_of_timesteps": 14320897, "per_episode_reward": 82.7, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 57433, "number_of_timesteps": 14325897, "per_episode_reward": 82.7, "episode_reward_trend_value": 0.0038888888888889833, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57443, "number_of_timesteps": 14330897, "per_episode_reward": 82.7, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57453, "number_of_timesteps": 14335897, "per_episode_reward": 82.75, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57463, "number_of_timesteps": 14340897, "per_episode_reward": 82.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57473, "number_of_timesteps": 14345897, "per_episode_reward": 82.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57483, "number_of_timesteps": 14350897, "per_episode_reward": 82.8, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57493, "number_of_timesteps": 14355897, "per_episode_reward": 82.85, "episode_reward_trend_value": 0.002222222222222096, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 57503, "number_of_timesteps": 14360897, "per_episode_reward": 82.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57513, "number_of_timesteps": 14365897, "per_episode_reward": 82.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57523, "number_of_timesteps": 14370897, "per_episode_reward": 82.9, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57533, "number_of_timesteps": 14375897, "per_episode_reward": 83.0, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57543, "number_of_timesteps": 14380897, "per_episode_reward": 83.15, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57553, "number_of_timesteps": 14385897, "per_episode_reward": 83.2, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57563, "number_of_timesteps": 14390897, "per_episode_reward": 83.2, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57573, "number_of_timesteps": 14395897, "per_episode_reward": 83.25, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57583, "number_of_timesteps": 14400897, "per_episode_reward": 83.35, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57593, "number_of_timesteps": 14405897, "per_episode_reward": 83.45, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57603, "number_of_timesteps": 14410897, "per_episode_reward": 83.5, "episode_reward_trend_value": 0.006666666666666604, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57613, "number_of_timesteps": 14415897, "per_episode_reward": 83.5, "episode_reward_trend_value": 0.006666666666666604, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57623, "number_of_timesteps": 14420897, "per_episode_reward": 83.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57633, "number_of_timesteps": 14425897, "per_episode_reward": 83.5, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57643, "number_of_timesteps": 14430897, "per_episode_reward": 83.5, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57653, "number_of_timesteps": 14435897, "per_episode_reward": 83.55, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57663, "number_of_timesteps": 14440897, "per_episode_reward": 83.6, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57673, "number_of_timesteps": 14445897, "per_episode_reward": 83.6, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57683, "number_of_timesteps": 14450897, "per_episode_reward": 83.6, "episode_reward_trend_value": 0.001666666666666572, "biggest_recent_change": 0.04999999999999716},
{"total_number_of_episodes": 57693, "number_of_timesteps": 14455897, "per_episode_reward": 83.65, "episode_reward_trend_value": 0.0016666666666667299, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57703, "number_of_timesteps": 14460897, "per_episode_reward": 83.7, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57713, "number_of_timesteps": 14465897, "per_episode_reward": 83.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000001137},
{"total_number_of_episodes": 57723, "number_of_timesteps": 14470897, "per_episode_reward": 83.85, "episode_reward_trend_value": 0.003888888888888826, "biggest_recent_change": 0.09999999999999432},
{"total_number_of_episodes": 57733, "number_of_timesteps": 14475897, "per_episode_reward": 83.95, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57743, "number_of_timesteps": 14480897, "per_episode_reward": 84.0, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57753, "number_of_timesteps": 14485897, "per_episode_reward": 84.0, "episode_reward_trend_value": 0.004444444444444508, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57763, "number_of_timesteps": 14490897, "per_episode_reward": 84.05, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57773, "number_of_timesteps": 14495897, "per_episode_reward": 84.15, "episode_reward_trend_value": 0.006111111111111237, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57783, "number_of_timesteps": 14500897, "per_episode_reward": 84.2, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57793, "number_of_timesteps": 14505897, "per_episode_reward": 84.25, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57803, "number_of_timesteps": 14510897, "per_episode_reward": 84.35, "episode_reward_trend_value": 0.006666666666666604, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57813, "number_of_timesteps": 14515897, "per_episode_reward": 84.4, "episode_reward_trend_value": 0.006111111111111237, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57823, "number_of_timesteps": 14520897, "per_episode_reward": 84.4, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57833, "number_of_timesteps": 14525897, "per_episode_reward": 84.45, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57843, "number_of_timesteps": 14530897, "per_episode_reward": 84.55, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57853, "number_of_timesteps": 14535897, "per_episode_reward": 84.65, "episode_reward_trend_value": 0.006666666666666761, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57863, "number_of_timesteps": 14540897, "per_episode_reward": 84.75, "episode_reward_trend_value": 0.006666666666666604, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57873, "number_of_timesteps": 14545897, "per_episode_reward": 84.8, "episode_reward_trend_value": 0.006666666666666604, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57883, "number_of_timesteps": 14550897, "per_episode_reward": 84.8, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57893, "number_of_timesteps": 14555680, "per_episode_reward": 84.8, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57903, "number_of_timesteps": 14560680, "per_episode_reward": 84.8, "episode_reward_trend_value": 0.00444444444444435, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57913, "number_of_timesteps": 14565680, "per_episode_reward": 84.85, "episode_reward_trend_value": 0.004999999999999874, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57923, "number_of_timesteps": 14570680, "per_episode_reward": 84.9, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57933, "number_of_timesteps": 14575680, "per_episode_reward": 85.0, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000853},
{"total_number_of_episodes": 57943, "number_of_timesteps": 14580680, "per_episode_reward": 85.15, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57953, "number_of_timesteps": 14585680, "per_episode_reward": 85.25, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57963, "number_of_timesteps": 14590680, "per_episode_reward": 85.3, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57973, "number_of_timesteps": 14595680, "per_episode_reward": 85.3, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57983, "number_of_timesteps": 14600680, "per_episode_reward": 85.3, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 57993, "number_of_timesteps": 14605680, "per_episode_reward": 85.65, "episode_reward_trend_value": 0.009444444444444538, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 58003, "number_of_timesteps": 14610680, "per_episode_reward": 85.75, "episode_reward_trend_value": 0.010000000000000063, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 58013, "number_of_timesteps": 14615680, "per_episode_reward": 85.8, "episode_reward_trend_value": 0.009999999999999905, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 58023, "number_of_timesteps": 14620680, "per_episode_reward": 85.8, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 58033, "number_of_timesteps": 14625680, "per_episode_reward": 85.85, "episode_reward_trend_value": 0.007777777777777652, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 58043, "number_of_timesteps": 14630680, "per_episode_reward": 85.9, "episode_reward_trend_value": 0.007222222222222285, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 58053, "number_of_timesteps": 14635680, "per_episode_reward": 86.0, "episode_reward_trend_value": 0.00777777777777781, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 58063, "number_of_timesteps": 14640680, "per_episode_reward": 86.15, "episode_reward_trend_value": 0.009444444444444538, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 58073, "number_of_timesteps": 14645680, "per_episode_reward": 86.2, "episode_reward_trend_value": 0.010000000000000063, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 58083, "number_of_timesteps": 14650680, "per_episode_reward": 86.25, "episode_reward_trend_value": 0.006666666666666604, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 58093, "number_of_timesteps": 14655680, "per_episode_reward": 86.35, "episode_reward_trend_value": 0.006666666666666604, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 58103, "number_of_timesteps": 14660680, "per_episode_reward": 86.4, "episode_reward_trend_value": 0.006666666666666761, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 58113, "number_of_timesteps": 14665680, "per_episode_reward": 86.4, "episode_reward_trend_value": 0.006666666666666761, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 58123, "number_of_timesteps": 14670680, "per_episode_reward": 86.7, "episode_reward_trend_value": 0.009444444444444538, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58133, "number_of_timesteps": 14675680, "per_episode_reward": 86.75, "episode_reward_trend_value": 0.009444444444444382, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58143, "number_of_timesteps": 14680680, "per_episode_reward": 86.8, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58153, "number_of_timesteps": 14685680, "per_episode_reward": 86.8, "episode_reward_trend_value": 0.007222222222222127, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58163, "number_of_timesteps": 14690680, "per_episode_reward": 86.8, "episode_reward_trend_value": 0.006666666666666604, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58173, "number_of_timesteps": 14695680, "per_episode_reward": 86.85, "episode_reward_trend_value": 0.006666666666666604, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58183, "number_of_timesteps": 14700680, "per_episode_reward": 86.95, "episode_reward_trend_value": 0.006666666666666761, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58193, "number_of_timesteps": 14705680, "per_episode_reward": 87.1, "episode_reward_trend_value": 0.007777777777777652, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58203, "number_of_timesteps": 14710680, "per_episode_reward": 87.2, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58213, "number_of_timesteps": 14715680, "per_episode_reward": 87.25, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 58223, "number_of_timesteps": 14720680, "per_episode_reward": 87.3, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 58233, "number_of_timesteps": 14725680, "per_episode_reward": 87.35, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 58243, "number_of_timesteps": 14730680, "per_episode_reward": 87.45, "episode_reward_trend_value": 0.007222222222222285, "biggest_recent_change": 0.14999999999999147},
{"total_number_of_episodes": 58253, "number_of_timesteps": 14735680, "per_episode_reward": 87.65, "episode_reward_trend_value": 0.009444444444444538, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58263, "number_of_timesteps": 14740680, "per_episode_reward": 87.7, "episode_reward_trend_value": 0.009444444444444538, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58273, "number_of_timesteps": 14745680, "per_episode_reward": 87.7, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58283, "number_of_timesteps": 14750680, "per_episode_reward": 87.7, "episode_reward_trend_value": 0.006666666666666761, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58293, "number_of_timesteps": 14755680, "per_episode_reward": 87.75, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58303, "number_of_timesteps": 14760680, "per_episode_reward": 87.85, "episode_reward_trend_value": 0.006666666666666604, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58313, "number_of_timesteps": 14765608, "per_episode_reward": 87.95, "episode_reward_trend_value": 0.007222222222222285, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58323, "number_of_timesteps": 14770608, "per_episode_reward": 88.05, "episode_reward_trend_value": 0.00777777777777781, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58333, "number_of_timesteps": 14775608, "per_episode_reward": 88.25, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58343, "number_of_timesteps": 14780608, "per_episode_reward": 88.45, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58353, "number_of_timesteps": 14785608, "per_episode_reward": 88.5, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58363, "number_of_timesteps": 14790608, "per_episode_reward": 88.5, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58373, "number_of_timesteps": 14795608, "per_episode_reward": 88.5, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58383, "number_of_timesteps": 14800608, "per_episode_reward": 88.65, "episode_reward_trend_value": 0.010000000000000063, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58393, "number_of_timesteps": 14805608, "per_episode_reward": 88.7, "episode_reward_trend_value": 0.009444444444444538, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58403, "number_of_timesteps": 14810608, "per_episode_reward": 88.7, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58413, "number_of_timesteps": 14815608, "per_episode_reward": 88.85, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58423, "number_of_timesteps": 14820608, "per_episode_reward": 89.05, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58433, "number_of_timesteps": 14825608, "per_episode_reward": 89.1, "episode_reward_trend_value": 0.007222222222222127, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58443, "number_of_timesteps": 14830608, "per_episode_reward": 89.15, "episode_reward_trend_value": 0.007222222222222285, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58453, "number_of_timesteps": 14835608, "per_episode_reward": 89.35, "episode_reward_trend_value": 0.009444444444444382, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58463, "number_of_timesteps": 14840608, "per_episode_reward": 89.5, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58473, "number_of_timesteps": 14845608, "per_episode_reward": 89.6, "episode_reward_trend_value": 0.01055555555555543, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58483, "number_of_timesteps": 14850608, "per_episode_reward": 89.75, "episode_reward_trend_value": 0.011666666666666634, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58493, "number_of_timesteps": 14855608, "per_episode_reward": 89.9, "episode_reward_trend_value": 0.013333333333333364, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58503, "number_of_timesteps": 14860608, "per_episode_reward": 90.05, "episode_reward_trend_value": 0.013333333333333364, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58513, "number_of_timesteps": 14865608, "per_episode_reward": 90.25, "episode_reward_trend_value": 0.013333333333333364, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58523, "number_of_timesteps": 14870608, "per_episode_reward": 90.35, "episode_reward_trend_value": 0.01388888888888889, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58533, "number_of_timesteps": 14875608, "per_episode_reward": 90.55, "episode_reward_trend_value": 0.015555555555555461, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58543, "number_of_timesteps": 14880608, "per_episode_reward": 90.75, "episode_reward_trend_value": 0.01555555555555562, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58553, "number_of_timesteps": 14885608, "per_episode_reward": 90.85, "episode_reward_trend_value": 0.014999999999999935, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58563, "number_of_timesteps": 14890608, "per_episode_reward": 90.95, "episode_reward_trend_value": 0.015000000000000093, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58573, "number_of_timesteps": 14895608, "per_episode_reward": 91.05, "episode_reward_trend_value": 0.014444444444444413, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58583, "number_of_timesteps": 14900608, "per_episode_reward": 91.2, "episode_reward_trend_value": 0.014444444444444413, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58593, "number_of_timesteps": 14905608, "per_episode_reward": 91.35, "episode_reward_trend_value": 0.014444444444444413, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58603, "number_of_timesteps": 14910608, "per_episode_reward": 91.45, "episode_reward_trend_value": 0.013333333333333364, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58613, "number_of_timesteps": 14915608, "per_episode_reward": 91.55, "episode_reward_trend_value": 0.013333333333333364, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58623, "number_of_timesteps": 14920608, "per_episode_reward": 91.6, "episode_reward_trend_value": 0.011666666666666634, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58633, "number_of_timesteps": 14925608, "per_episode_reward": 91.65, "episode_reward_trend_value": 0.010000000000000063, "biggest_recent_change": 0.15000000000000568},
{"total_number_of_episodes": 58643, "number_of_timesteps": 14930608, "per_episode_reward": 91.9, "episode_reward_trend_value": 0.011666666666666794, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58653, "number_of_timesteps": 14935608, "per_episode_reward": 91.95, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58663, "number_of_timesteps": 14940608, "per_episode_reward": 92.0, "episode_reward_trend_value": 0.010555555555555587, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58673, "number_of_timesteps": 14945608, "per_episode_reward": 92.0, "episode_reward_trend_value": 0.008888888888888858, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58683, "number_of_timesteps": 14950608, "per_episode_reward": 92.05, "episode_reward_trend_value": 0.00777777777777781, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58693, "number_of_timesteps": 14955608, "per_episode_reward": 92.15, "episode_reward_trend_value": 0.00777777777777781, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58703, "number_of_timesteps": 14960608, "per_episode_reward": 92.25, "episode_reward_trend_value": 0.00777777777777781, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58713, "number_of_timesteps": 14965608, "per_episode_reward": 92.3, "episode_reward_trend_value": 0.00777777777777781, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58723, "number_of_timesteps": 14970608, "per_episode_reward": 92.35, "episode_reward_trend_value": 0.007777777777777652, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58733, "number_of_timesteps": 14975608, "per_episode_reward": 92.55, "episode_reward_trend_value": 0.007222222222222127, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58743, "number_of_timesteps": 14980608, "per_episode_reward": 92.7, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58753, "number_of_timesteps": 14985608, "per_episode_reward": 92.85, "episode_reward_trend_value": 0.009444444444444382, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58763, "number_of_timesteps": 14990608, "per_episode_reward": 93.15, "episode_reward_trend_value": 0.012777777777777841, "biggest_recent_change": 0.30000000000001137},
{"total_number_of_episodes": 58773, "number_of_timesteps": 14995608, "per_episode_reward": 93.55, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 58783, "number_of_timesteps": 15000608, "per_episode_reward": 93.65, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 58793, "number_of_timesteps": 15005608, "per_episode_reward": 93.8, "episode_reward_trend_value": 0.01722222222222219, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 58803, "number_of_timesteps": 15010608, "per_episode_reward": 93.95, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 58813, "number_of_timesteps": 15015608, "per_episode_reward": 94.1, "episode_reward_trend_value": 0.019444444444444445, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 58823, "number_of_timesteps": 15020608, "per_episode_reward": 94.25, "episode_reward_trend_value": 0.01888888888888892, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 58833, "number_of_timesteps": 15025608, "per_episode_reward": 94.45, "episode_reward_trend_value": 0.019444444444444445, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 58843, "number_of_timesteps": 15030608, "per_episode_reward": 94.65, "episode_reward_trend_value": 0.020000000000000125, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 58853, "number_of_timesteps": 15035608, "per_episode_reward": 94.75, "episode_reward_trend_value": 0.017777777777777715, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 58863, "number_of_timesteps": 15040608, "per_episode_reward": 94.95, "episode_reward_trend_value": 0.01555555555555562, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 58873, "number_of_timesteps": 15045608, "per_episode_reward": 95.2, "episode_reward_trend_value": 0.01722222222222219, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58883, "number_of_timesteps": 15050305, "per_episode_reward": 95.3, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58893, "number_of_timesteps": 15055305, "per_episode_reward": 95.4, "episode_reward_trend_value": 0.016111111111111142, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 58903, "number_of_timesteps": 15060264, "per_episode_reward": 95.7, "episode_reward_trend_value": 0.01777777777777787, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58913, "number_of_timesteps": 15064821, "per_episode_reward": 95.9, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58923, "number_of_timesteps": 15069821, "per_episode_reward": 96.05, "episode_reward_trend_value": 0.017777777777777715, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58933, "number_of_timesteps": 15074821, "per_episode_reward": 96.1, "episode_reward_trend_value": 0.016111111111110986, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58943, "number_of_timesteps": 15079471, "per_episode_reward": 96.15, "episode_reward_trend_value": 0.01555555555555562, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58953, "number_of_timesteps": 15084471, "per_episode_reward": 96.35, "episode_reward_trend_value": 0.015555555555555461, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58963, "number_of_timesteps": 15089471, "per_episode_reward": 96.55, "episode_reward_trend_value": 0.014999999999999935, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58973, "number_of_timesteps": 15094471, "per_episode_reward": 96.7, "episode_reward_trend_value": 0.01555555555555562, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58983, "number_of_timesteps": 15099471, "per_episode_reward": 96.9, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 58993, "number_of_timesteps": 15104471, "per_episode_reward": 97.1, "episode_reward_trend_value": 0.015555555555555461, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59003, "number_of_timesteps": 15109471, "per_episode_reward": 97.2, "episode_reward_trend_value": 0.014444444444444413, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59013, "number_of_timesteps": 15114471, "per_episode_reward": 97.4, "episode_reward_trend_value": 0.015000000000000093, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59023, "number_of_timesteps": 15119471, "per_episode_reward": 97.7, "episode_reward_trend_value": 0.01777777777777787, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59033, "number_of_timesteps": 15124471, "per_episode_reward": 97.95, "episode_reward_trend_value": 0.01999999999999997, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59043, "number_of_timesteps": 15129471, "per_episode_reward": 98.1, "episode_reward_trend_value": 0.019444444444444445, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59053, "number_of_timesteps": 15134471, "per_episode_reward": 98.2, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59063, "number_of_timesteps": 15139014, "per_episode_reward": 98.4, "episode_reward_trend_value": 0.01888888888888892, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59073, "number_of_timesteps": 15144014, "per_episode_reward": 98.55, "episode_reward_trend_value": 0.018333333333333236, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59083, "number_of_timesteps": 15149014, "per_episode_reward": 98.75, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59093, "number_of_timesteps": 15154014, "per_episode_reward": 99.05, "episode_reward_trend_value": 0.020555555555555494, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59103, "number_of_timesteps": 15159014, "per_episode_reward": 99.2, "episode_reward_trend_value": 0.01999999999999997, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59113, "number_of_timesteps": 15164014, "per_episode_reward": 99.2, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59123, "number_of_timesteps": 15169014, "per_episode_reward": 99.3, "episode_reward_trend_value": 0.014999999999999935, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59133, "number_of_timesteps": 15174014, "per_episode_reward": 99.4, "episode_reward_trend_value": 0.01444444444444457, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59143, "number_of_timesteps": 15179014, "per_episode_reward": 99.4, "episode_reward_trend_value": 0.013333333333333364, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59153, "number_of_timesteps": 15184014, "per_episode_reward": 99.45, "episode_reward_trend_value": 0.011666666666666634, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59163, "number_of_timesteps": 15189014, "per_episode_reward": 99.65, "episode_reward_trend_value": 0.012222222222222318, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59173, "number_of_timesteps": 15194014, "per_episode_reward": 99.85, "episode_reward_trend_value": 0.012222222222222159, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 59183, "number_of_timesteps": 15199014, "per_episode_reward": 100.0, "episode_reward_trend_value": 0.010555555555555587, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59193, "number_of_timesteps": 15204014, "per_episode_reward": 100.2, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59203, "number_of_timesteps": 15209014, "per_episode_reward": 100.35, "episode_reward_trend_value": 0.012777777777777683, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59213, "number_of_timesteps": 15214014, "per_episode_reward": 100.4, "episode_reward_trend_value": 0.012222222222222318, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59223, "number_of_timesteps": 15218585, "per_episode_reward": 100.5, "episode_reward_trend_value": 0.012222222222222159, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59233, "number_of_timesteps": 15223585, "per_episode_reward": 100.65, "episode_reward_trend_value": 0.01388888888888889, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59243, "number_of_timesteps": 15228585, "per_episode_reward": 100.75, "episode_reward_trend_value": 0.014444444444444413, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59253, "number_of_timesteps": 15233585, "per_episode_reward": 100.95, "episode_reward_trend_value": 0.014444444444444413, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59263, "number_of_timesteps": 15238585, "per_episode_reward": 101.15, "episode_reward_trend_value": 0.01444444444444457, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59273, "number_of_timesteps": 15243585, "per_episode_reward": 101.35, "episode_reward_trend_value": 0.014999999999999935, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 59283, "number_of_timesteps": 15248585, "per_episode_reward": 101.7, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 59293, "number_of_timesteps": 15253585, "per_episode_reward": 102.25, "episode_reward_trend_value": 0.021111111111111174, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 59303, "number_of_timesteps": 15258585, "per_episode_reward": 102.65, "episode_reward_trend_value": 0.025, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 59313, "number_of_timesteps": 15263585, "per_episode_reward": 103.0, "episode_reward_trend_value": 0.02777777777777778, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 59323, "number_of_timesteps": 15268585, "per_episode_reward": 103.15, "episode_reward_trend_value": 0.02777777777777778, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 59333, "number_of_timesteps": 15273585, "per_episode_reward": 103.35, "episode_reward_trend_value": 0.028888888888888825, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 59344, "number_of_timesteps": 15278612, "per_episode_reward": 103.65, "episode_reward_trend_value": 0.030000000000000034, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 59354, "number_of_timesteps": 15283612, "per_episode_reward": 103.85, "episode_reward_trend_value": 0.02999999999999987, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 59364, "number_of_timesteps": 15288612, "per_episode_reward": 103.95, "episode_reward_trend_value": 0.028888888888888985, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 59374, "number_of_timesteps": 15293612, "per_episode_reward": 104.05, "episode_reward_trend_value": 0.026111111111111047, "biggest_recent_change": 0.5499999999999972},
{"total_number_of_episodes": 59384, "number_of_timesteps": 15298612, "per_episode_reward": 104.15, "episode_reward_trend_value": 0.021111111111111174, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59394, "number_of_timesteps": 15303612, "per_episode_reward": 104.3, "episode_reward_trend_value": 0.018333333333333236, "biggest_recent_change": 0.3499999999999943},
{"total_number_of_episodes": 59404, "number_of_timesteps": 15308612, "per_episode_reward": 104.45, "episode_reward_trend_value": 0.016111111111111142, "biggest_recent_change": 0.30000000000001137},
{"total_number_of_episodes": 59414, "number_of_timesteps": 15313612, "per_episode_reward": 104.6, "episode_reward_trend_value": 0.016111111111110986, "biggest_recent_change": 0.30000000000001137},
{"total_number_of_episodes": 59424, "number_of_timesteps": 15318612, "per_episode_reward": 105.0, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59434, "number_of_timesteps": 15323612, "per_episode_reward": 105.1, "episode_reward_trend_value": 0.016111111111110986, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59444, "number_of_timesteps": 15328612, "per_episode_reward": 105.35, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59454, "number_of_timesteps": 15333612, "per_episode_reward": 105.6, "episode_reward_trend_value": 0.018333333333333236, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59464, "number_of_timesteps": 15338612, "per_episode_reward": 105.7, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59475, "number_of_timesteps": 15343641, "per_episode_reward": 105.9, "episode_reward_trend_value": 0.019444444444444445, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59485, "number_of_timesteps": 15348641, "per_episode_reward": 106.1, "episode_reward_trend_value": 0.01999999999999997, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59495, "number_of_timesteps": 15353641, "per_episode_reward": 106.15, "episode_reward_trend_value": 0.01888888888888892, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59505, "number_of_timesteps": 15358641, "per_episode_reward": 106.25, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59515, "number_of_timesteps": 15363641, "per_episode_reward": 106.5, "episode_reward_trend_value": 0.016666666666666666, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 59525, "number_of_timesteps": 15368641, "per_episode_reward": 106.85, "episode_reward_trend_value": 0.019444444444444445, "biggest_recent_change": 0.3499999999999943},
{"total_number_of_episodes": 59535, "number_of_timesteps": 15373641, "per_episode_reward": 107.0, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.3499999999999943},
{"total_number_of_episodes": 59545, "number_of_timesteps": 15378641, "per_episode_reward": 107.05, "episode_reward_trend_value": 0.016111111111111142, "biggest_recent_change": 0.3499999999999943},
{"total_number_of_episodes": 59555, "number_of_timesteps": 15383641, "per_episode_reward": 107.75, "episode_reward_trend_value": 0.022777777777777748, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 59565, "number_of_timesteps": 15388641, "per_episode_reward": 108.0, "episode_reward_trend_value": 0.02333333333333327, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 59575, "number_of_timesteps": 15393641, "per_episode_reward": 108.1, "episode_reward_trend_value": 0.02222222222222222, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 59585, "number_of_timesteps": 15398641, "per_episode_reward": 108.2, "episode_reward_trend_value": 0.022777777777777748, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 59595, "number_of_timesteps": 15403641, "per_episode_reward": 108.4, "episode_reward_trend_value": 0.023888888888888953, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 59605, "number_of_timesteps": 15408641, "per_episode_reward": 108.55, "episode_reward_trend_value": 0.022777777777777748, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 59615, "number_of_timesteps": 15413641, "per_episode_reward": 108.7, "episode_reward_trend_value": 0.02055555555555565, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 59625, "number_of_timesteps": 15418641, "per_episode_reward": 108.85, "episode_reward_trend_value": 0.020555555555555494, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 59635, "number_of_timesteps": 15423641, "per_episode_reward": 109.05, "episode_reward_trend_value": 0.02222222222222222, "biggest_recent_change": 0.7000000000000028},
{"total_number_of_episodes": 59645, "number_of_timesteps": 15428641, "per_episode_reward": 109.3, "episode_reward_trend_value": 0.01722222222222219, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 59655, "number_of_timesteps": 15433641, "per_episode_reward": 109.55, "episode_reward_trend_value": 0.01722222222222219, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 59665, "number_of_timesteps": 15438641, "per_episode_reward": 109.7, "episode_reward_trend_value": 0.01777777777777787, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 59675, "number_of_timesteps": 15443641, "per_episode_reward": 109.75, "episode_reward_trend_value": 0.01722222222222219, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 59685, "number_of_timesteps": 15448641, "per_episode_reward": 110.25, "episode_reward_trend_value": 0.020555555555555494, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59695, "number_of_timesteps": 15453641, "per_episode_reward": 110.35, "episode_reward_trend_value": 0.01999999999999997, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59705, "number_of_timesteps": 15458641, "per_episode_reward": 110.5, "episode_reward_trend_value": 0.01999999999999997, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59715, "number_of_timesteps": 15463641, "per_episode_reward": 110.65, "episode_reward_trend_value": 0.020000000000000125, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59725, "number_of_timesteps": 15468641, "per_episode_reward": 110.85, "episode_reward_trend_value": 0.01999999999999997, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59735, "number_of_timesteps": 15473641, "per_episode_reward": 111.05, "episode_reward_trend_value": 0.019444444444444445, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59745, "number_of_timesteps": 15478641, "per_episode_reward": 111.15, "episode_reward_trend_value": 0.01777777777777787, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59755, "number_of_timesteps": 15483641, "per_episode_reward": 111.35, "episode_reward_trend_value": 0.018333333333333236, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59765, "number_of_timesteps": 15488641, "per_episode_reward": 111.6, "episode_reward_trend_value": 0.020555555555555494, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59775, "number_of_timesteps": 15493641, "per_episode_reward": 111.85, "episode_reward_trend_value": 0.017777777777777715, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 59785, "number_of_timesteps": 15498641, "per_episode_reward": 112.1, "episode_reward_trend_value": 0.019444444444444445, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 59795, "number_of_timesteps": 15503641, "per_episode_reward": 112.3, "episode_reward_trend_value": 0.01999999999999997, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 59805, "number_of_timesteps": 15508641, "per_episode_reward": 112.45, "episode_reward_trend_value": 0.01999999999999997, "biggest_recent_change": 0.25},
{"total_number_of_episodes": 59815, "number_of_timesteps": 15513641, "per_episode_reward": 112.95, "episode_reward_trend_value": 0.023333333333333428, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59825, "number_of_timesteps": 15518641, "per_episode_reward": 113.1, "episode_reward_trend_value": 0.022777777777777748, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59835, "number_of_timesteps": 15523641, "per_episode_reward": 113.5, "episode_reward_trend_value": 0.026111111111111047, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59845, "number_of_timesteps": 15528641, "per_episode_reward": 113.85, "episode_reward_trend_value": 0.02777777777777778, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59855, "number_of_timesteps": 15533641, "per_episode_reward": 113.9, "episode_reward_trend_value": 0.025555555555555682, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59865, "number_of_timesteps": 15538641, "per_episode_reward": 114.0, "episode_reward_trend_value": 0.023888888888888953, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59875, "number_of_timesteps": 15543641, "per_episode_reward": 114.2, "episode_reward_trend_value": 0.023333333333333428, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59885, "number_of_timesteps": 15548641, "per_episode_reward": 114.4, "episode_reward_trend_value": 0.023333333333333428, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59895, "number_of_timesteps": 15553641, "per_episode_reward": 114.65, "episode_reward_trend_value": 0.024444444444444477, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 59905, "number_of_timesteps": 15558641, "per_episode_reward": 114.85, "episode_reward_trend_value": 0.021111111111111018, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59915, "number_of_timesteps": 15563641, "per_episode_reward": 115.15, "episode_reward_trend_value": 0.022777777777777904, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 59925, "number_of_timesteps": 15568641, "per_episode_reward": 115.55, "episode_reward_trend_value": 0.022777777777777748, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 59935, "number_of_timesteps": 15573641, "per_episode_reward": 115.9, "episode_reward_trend_value": 0.022777777777777904, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 59945, "number_of_timesteps": 15578641, "per_episode_reward": 117.0, "episode_reward_trend_value": 0.03444444444444438, "biggest_recent_change": 1.0999999999999943},
{"total_number_of_episodes": 59955, "number_of_timesteps": 15583641, "per_episode_reward": 117.1, "episode_reward_trend_value": 0.03444444444444438, "biggest_recent_change": 1.0999999999999943},
{"total_number_of_episodes": 59965, "number_of_timesteps": 15588641, "per_episode_reward": 117.15, "episode_reward_trend_value": 0.03277777777777781, "biggest_recent_change": 1.0999999999999943},
{"total_number_of_episodes": 59975, "number_of_timesteps": 15593641, "per_episode_reward": 117.3, "episode_reward_trend_value": 0.03222222222222213, "biggest_recent_change": 1.0999999999999943},
{"total_number_of_episodes": 59985, "number_of_timesteps": 15598641, "per_episode_reward": 117.5, "episode_reward_trend_value": 0.03166666666666661, "biggest_recent_change": 1.0999999999999943},
{"total_number_of_episodes": 59995, "number_of_timesteps": 15603641, "per_episode_reward": 117.7, "episode_reward_trend_value": 0.03166666666666676, "biggest_recent_change": 1.0999999999999943},
{"total_number_of_episodes": 60005, "number_of_timesteps": 15608641, "per_episode_reward": 117.9, "episode_reward_trend_value": 0.030555555555555558, "biggest_recent_change": 1.0999999999999943},
{"total_number_of_episodes": 60015, "number_of_timesteps": 15613641, "per_episode_reward": 118.1, "episode_reward_trend_value": 0.0283333333333333, "biggest_recent_change": 1.0999999999999943},
{"total_number_of_episodes": 60025, "number_of_timesteps": 15618641, "per_episode_reward": 118.25, "episode_reward_trend_value": 0.026111111111111047, "biggest_recent_change": 1.0999999999999943},
{"total_number_of_episodes": 60036, "number_of_timesteps": 15623686, "per_episode_reward": 118.45, "episode_reward_trend_value": 0.016111111111111142, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 60046, "number_of_timesteps": 15628686, "per_episode_reward": 118.9, "episode_reward_trend_value": 0.020000000000000125, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60056, "number_of_timesteps": 15633686, "per_episode_reward": 119.2, "episode_reward_trend_value": 0.022777777777777748, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60066, "number_of_timesteps": 15638686, "per_episode_reward": 119.3, "episode_reward_trend_value": 0.02222222222222222, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60076, "number_of_timesteps": 15643686, "per_episode_reward": 119.75, "episode_reward_trend_value": 0.025, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60086, "number_of_timesteps": 15648686, "per_episode_reward": 119.9, "episode_reward_trend_value": 0.024444444444444477, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60096, "number_of_timesteps": 15653686, "per_episode_reward": 120.1, "episode_reward_trend_value": 0.024444444444444317, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60106, "number_of_timesteps": 15658686, "per_episode_reward": 120.25, "episode_reward_trend_value": 0.023888888888888953, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60116, "number_of_timesteps": 15663686, "per_episode_reward": 120.4, "episode_reward_trend_value": 0.023888888888888953, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60126, "number_of_timesteps": 15668686, "per_episode_reward": 120.55, "episode_reward_trend_value": 0.02333333333333327, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60136, "number_of_timesteps": 15673686, "per_episode_reward": 120.65, "episode_reward_trend_value": 0.019444444444444445, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60146, "number_of_timesteps": 15678545, "per_episode_reward": 120.8, "episode_reward_trend_value": 0.017777777777777715, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60156, "number_of_timesteps": 15683545, "per_episode_reward": 120.95, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.45000000000000284},
{"total_number_of_episodes": 60166, "number_of_timesteps": 15688545, "per_episode_reward": 121.05, "episode_reward_trend_value": 0.014444444444444413, "biggest_recent_change": 0.19999999999998863},
{"total_number_of_episodes": 60176, "number_of_timesteps": 15693545, "per_episode_reward": 121.25, "episode_reward_trend_value": 0.014999999999999935, "biggest_recent_change": 0.20000000000000284},
{"total_number_of_episodes": 60186, "number_of_timesteps": 15698545, "per_episode_reward": 121.55, "episode_reward_trend_value": 0.016111111111111142, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 60196, "number_of_timesteps": 15703472, "per_episode_reward": 121.9, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 60206, "number_of_timesteps": 15708070, "per_episode_reward": 123.4, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 60216, "number_of_timesteps": 15713070, "per_episode_reward": 123.65, "episode_reward_trend_value": 0.03444444444444454, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 60226, "number_of_timesteps": 15718070, "per_episode_reward": 123.95, "episode_reward_trend_value": 0.03666666666666664, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 60236, "number_of_timesteps": 15723070, "per_episode_reward": 124.35, "episode_reward_trend_value": 0.039444444444444414, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 60246, "number_of_timesteps": 15728070, "per_episode_reward": 124.6, "episode_reward_trend_value": 0.04055555555555546, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 60256, "number_of_timesteps": 15733070, "per_episode_reward": 124.85, "episode_reward_trend_value": 0.04222222222222219, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 60266, "number_of_timesteps": 15738070, "per_episode_reward": 125.1, "episode_reward_trend_value": 0.04277777777777771, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 60276, "number_of_timesteps": 15743070, "per_episode_reward": 125.45, "episode_reward_trend_value": 0.0433333333333334, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 60286, "number_of_timesteps": 15748070, "per_episode_reward": 125.8, "episode_reward_trend_value": 0.04333333333333324, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 60296, "number_of_timesteps": 15753070, "per_episode_reward": 126.1, "episode_reward_trend_value": 0.02999999999999987, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 60306, "number_of_timesteps": 15758070, "per_episode_reward": 126.35, "episode_reward_trend_value": 0.02999999999999987, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 60316, "number_of_timesteps": 15763070, "per_episode_reward": 126.45, "episode_reward_trend_value": 0.02777777777777778, "biggest_recent_change": 0.3999999999999915},
{"total_number_of_episodes": 60326, "number_of_timesteps": 15768070, "per_episode_reward": 126.5, "episode_reward_trend_value": 0.023888888888888953, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 60336, "number_of_timesteps": 15773070, "per_episode_reward": 126.6, "episode_reward_trend_value": 0.02222222222222222, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 60346, "number_of_timesteps": 15778070, "per_episode_reward": 126.8, "episode_reward_trend_value": 0.0216666666666667, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 60356, "number_of_timesteps": 15783070, "per_episode_reward": 126.95, "episode_reward_trend_value": 0.02055555555555565, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 60366, "number_of_timesteps": 15788070, "per_episode_reward": 127.0, "episode_reward_trend_value": 0.01722222222222219, "biggest_recent_change": 0.3499999999999943},
{"total_number_of_episodes": 60376, "number_of_timesteps": 15793070, "per_episode_reward": 127.1, "episode_reward_trend_value": 0.014444444444444413, "biggest_recent_change": 0.29999999999999716},
{"total_number_of_episodes": 60386, "number_of_timesteps": 15798070, "per_episode_reward": 127.45, "episode_reward_trend_value": 0.015000000000000093, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 60396, "number_of_timesteps": 15803070, "per_episode_reward": 127.8, "episode_reward_trend_value": 0.016111111111111142, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 60406, "number_of_timesteps": 15808070, "per_episode_reward": 128.0, "episode_reward_trend_value": 0.01722222222222219, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 60416, "number_of_timesteps": 15813070, "per_episode_reward": 128.15, "episode_reward_trend_value": 0.018333333333333396, "biggest_recent_change": 0.3500000000000085},
{"total_number_of_episodes": 60426, "number_of_timesteps": 15818070, "per_episode_reward": 128.55, "episode_reward_trend_value": 0.021666666666666855, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 60436, "number_of_timesteps": 15823070, "per_episode_reward": 128.9, "episode_reward_trend_value": 0.023333333333333428, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 60446, "number_of_timesteps": 15828070, "per_episode_reward": 129.05, "episode_reward_trend_value": 0.023333333333333428, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 60456, "number_of_timesteps": 15833070, "per_episode_reward": 129.3, "episode_reward_trend_value": 0.025555555555555682, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 60466, "number_of_timesteps": 15838070, "per_episode_reward": 129.45, "episode_reward_trend_value": 0.026111111111111047, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 60476, "number_of_timesteps": 15843070, "per_episode_reward": 129.65, "episode_reward_trend_value": 0.024444444444444477, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 60486, "number_of_timesteps": 15848070, "per_episode_reward": 130.15, "episode_reward_trend_value": 0.026111111111111206, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60496, "number_of_timesteps": 15853070, "per_episode_reward": 130.6, "episode_reward_trend_value": 0.028888888888888825, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60506, "number_of_timesteps": 15858070, "per_episode_reward": 131.0, "episode_reward_trend_value": 0.03166666666666661, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60516, "number_of_timesteps": 15863070, "per_episode_reward": 131.4, "episode_reward_trend_value": 0.03166666666666661, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60526, "number_of_timesteps": 15868070, "per_episode_reward": 131.75, "episode_reward_trend_value": 0.03166666666666661, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60536, "number_of_timesteps": 15873070, "per_episode_reward": 132.1, "episode_reward_trend_value": 0.033888888888888705, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60546, "number_of_timesteps": 15878070, "per_episode_reward": 132.3, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60556, "number_of_timesteps": 15883070, "per_episode_reward": 132.4, "episode_reward_trend_value": 0.03277777777777797, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60566, "number_of_timesteps": 15888070, "per_episode_reward": 132.55, "episode_reward_trend_value": 0.032222222222222284, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60576, "number_of_timesteps": 15893070, "per_episode_reward": 132.85, "episode_reward_trend_value": 0.02999999999999987, "biggest_recent_change": 0.44999999999998863},
{"total_number_of_episodes": 60586, "number_of_timesteps": 15898070, "per_episode_reward": 133.1, "episode_reward_trend_value": 0.02777777777777778, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 60596, "number_of_timesteps": 15903070, "per_episode_reward": 133.35, "episode_reward_trend_value": 0.026111111111111047, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 60606, "number_of_timesteps": 15908070, "per_episode_reward": 133.65, "episode_reward_trend_value": 0.025, "biggest_recent_change": 0.3499999999999943},
{"total_number_of_episodes": 60616, "number_of_timesteps": 15913070, "per_episode_reward": 133.85, "episode_reward_trend_value": 0.02333333333333327, "biggest_recent_change": 0.3499999999999943},
{"total_number_of_episodes": 60626, "number_of_timesteps": 15918070, "per_episode_reward": 134.0, "episode_reward_trend_value": 0.021111111111111174, "biggest_recent_change": 0.30000000000001137},
{"total_number_of_episodes": 60636, "number_of_timesteps": 15923070, "per_episode_reward": 134.2, "episode_reward_trend_value": 0.02111111111111086, "biggest_recent_change": 0.30000000000001137},
{"total_number_of_episodes": 60646, "number_of_timesteps": 15928070, "per_episode_reward": 134.55, "episode_reward_trend_value": 0.023888888888888953, "biggest_recent_change": 0.35000000000002274},
{"total_number_of_episodes": 60656, "number_of_timesteps": 15933070, "per_episode_reward": 134.9, "episode_reward_trend_value": 0.026111111111111047, "biggest_recent_change": 0.35000000000002274},
{"total_number_of_episodes": 60666, "number_of_timesteps": 15938070, "per_episode_reward": 135.15, "episode_reward_trend_value": 0.025555555555555682, "biggest_recent_change": 0.35000000000002274},
{"total_number_of_episodes": 60676, "number_of_timesteps": 15943070, "per_episode_reward": 135.3, "episode_reward_trend_value": 0.024444444444444637, "biggest_recent_change": 0.35000000000002274},
{"total_number_of_episodes": 60686, "number_of_timesteps": 15948070, "per_episode_reward": 135.8, "episode_reward_trend_value": 0.027222222222222415, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60696, "number_of_timesteps": 15953070, "per_episode_reward": 136.45, "episode_reward_trend_value": 0.031111111111110923, "biggest_recent_change": 0.6499999999999773},
{"total_number_of_episodes": 60706, "number_of_timesteps": 15958070, "per_episode_reward": 137.5, "episode_reward_trend_value": 0.040555555555555615, "biggest_recent_change": 1.0500000000000114},
{"total_number_of_episodes": 60716, "number_of_timesteps": 15963070, "per_episode_reward": 138.45, "episode_reward_trend_value": 0.04944444444444432, "biggest_recent_change": 1.0500000000000114},
{"total_number_of_episodes": 60726, "number_of_timesteps": 15968070, "per_episode_reward": 138.75, "episode_reward_trend_value": 0.05055555555555569, "biggest_recent_change": 1.0500000000000114},
{"total_number_of_episodes": 60736, "number_of_timesteps": 15973070, "per_episode_reward": 139.1, "episode_reward_trend_value": 0.05055555555555537, "biggest_recent_change": 1.0500000000000114},
{"total_number_of_episodes": 60746, "number_of_timesteps": 15978070, "per_episode_reward": 139.55, "episode_reward_trend_value": 0.05166666666666673, "biggest_recent_change": 1.0500000000000114},
{"total_number_of_episodes": 60756, "number_of_timesteps": 15983070, "per_episode_reward": 140.15, "episode_reward_trend_value": 0.05555555555555556, "biggest_recent_change": 1.0500000000000114},
{"total_number_of_episodes": 60766, "number_of_timesteps": 15988070, "per_episode_reward": 140.6, "episode_reward_trend_value": 0.0588888888888887, "biggest_recent_change": 1.0500000000000114},
{"total_number_of_episodes": 60776, "number_of_timesteps": 15993070, "per_episode_reward": 140.85, "episode_reward_trend_value": 0.056111111111110924, "biggest_recent_change": 1.0500000000000114},
{"total_number_of_episodes": 60786, "number_of_timesteps": 15998070, "per_episode_reward": 141.15, "episode_reward_trend_value": 0.05222222222222241, "biggest_recent_change": 1.0500000000000114},
{"total_number_of_episodes": 60796, "number_of_timesteps": 16003070, "per_episode_reward": 141.5, "episode_reward_trend_value": 0.04444444444444444, "biggest_recent_change": 0.9499999999999886},
{"total_number_of_episodes": 60806, "number_of_timesteps": 16008070, "per_episode_reward": 141.75, "episode_reward_trend_value": 0.03666666666666679, "biggest_recent_change": 0.5999999999999943},
{"total_number_of_episodes": 60816, "number_of_timesteps": 16013070, "per_episode_reward": 141.95, "episode_reward_trend_value": 0.03555555555555543, "biggest_recent_change": 0.5999999999999943},
{"total_number_of_episodes": 60826, "number_of_timesteps": 16018070, "per_episode_reward": 142.2, "episode_reward_trend_value": 0.03444444444444438, "biggest_recent_change": 0.5999999999999943},
{"total_number_of_episodes": 60836, "number_of_timesteps": 16023070, "per_episode_reward": 142.4, "episode_reward_trend_value": 0.03166666666666661, "biggest_recent_change": 0.5999999999999943},
{"total_number_of_episodes": 60846, "number_of_timesteps": 16028070, "per_episode_reward": 142.9, "episode_reward_trend_value": 0.030555555555555558, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60856, "number_of_timesteps": 16033070, "per_episode_reward": 143.6, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.6999999999999886},
{"total_number_of_episodes": 60866, "number_of_timesteps": 16038070, "per_episode_reward": 143.9, "episode_reward_trend_value": 0.03388888888888901, "biggest_recent_change": 0.6999999999999886},
{"total_number_of_episodes": 60876, "number_of_timesteps": 16043070, "per_episode_reward": 144.15, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.6999999999999886},
{"total_number_of_episodes": 60886, "number_of_timesteps": 16048070, "per_episode_reward": 144.45, "episode_reward_trend_value": 0.03277777777777765, "biggest_recent_change": 0.6999999999999886},
{"total_number_of_episodes": 60896, "number_of_timesteps": 16053070, "per_episode_reward": 144.75, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.6999999999999886},
{"total_number_of_episodes": 60906, "number_of_timesteps": 16058070, "per_episode_reward": 145.05, "episode_reward_trend_value": 0.0344444444444447, "biggest_recent_change": 0.6999999999999886},
{"total_number_of_episodes": 60916, "number_of_timesteps": 16063070, "per_episode_reward": 145.25, "episode_reward_trend_value": 0.03388888888888901, "biggest_recent_change": 0.6999999999999886},
{"total_number_of_episodes": 60926, "number_of_timesteps": 16068070, "per_episode_reward": 145.55, "episode_reward_trend_value": 0.035000000000000066, "biggest_recent_change": 0.6999999999999886},
{"total_number_of_episodes": 60936, "number_of_timesteps": 16073070, "per_episode_reward": 145.85, "episode_reward_trend_value": 0.03277777777777765, "biggest_recent_change": 0.6999999999999886},
{"total_number_of_episodes": 60946, "number_of_timesteps": 16078070, "per_episode_reward": 145.95, "episode_reward_trend_value": 0.026111111111111047, "biggest_recent_change": 0.30000000000001137},
{"total_number_of_episodes": 60956, "number_of_timesteps": 16083070, "per_episode_reward": 146.1, "episode_reward_trend_value": 0.024444444444444317, "biggest_recent_change": 0.30000000000001137},
{"total_number_of_episodes": 60966, "number_of_timesteps": 16088070, "per_episode_reward": 146.6, "episode_reward_trend_value": 0.0272222222222221, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60976, "number_of_timesteps": 16093070, "per_episode_reward": 147.0, "episode_reward_trend_value": 0.02833333333333346, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60986, "number_of_timesteps": 16098070, "per_episode_reward": 147.15, "episode_reward_trend_value": 0.026666666666666727, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 60996, "number_of_timesteps": 16103070, "per_episode_reward": 147.45, "episode_reward_trend_value": 0.026666666666666415, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 61006, "number_of_timesteps": 16108070, "per_episode_reward": 147.95, "episode_reward_trend_value": 0.02999999999999987, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 61016, "number_of_timesteps": 16113070, "per_episode_reward": 148.65, "episode_reward_trend_value": 0.03444444444444438, "biggest_recent_change": 0.700000000000017},
{"total_number_of_episodes": 61026, "number_of_timesteps": 16118070, "per_episode_reward": 149.15, "episode_reward_trend_value": 0.03666666666666679, "biggest_recent_change": 0.700000000000017},
{"total_number_of_episodes": 61036, "number_of_timesteps": 16123070, "per_episode_reward": 149.45, "episode_reward_trend_value": 0.03888888888888889, "biggest_recent_change": 0.700000000000017},
{"total_number_of_episodes": 61046, "number_of_timesteps": 16128070, "per_episode_reward": 149.85, "episode_reward_trend_value": 0.04166666666666667, "biggest_recent_change": 0.700000000000017},
{"total_number_of_episodes": 61056, "number_of_timesteps": 16133070, "per_episode_reward": 150.25, "episode_reward_trend_value": 0.040555555555555615, "biggest_recent_change": 0.700000000000017},
{"total_number_of_episodes": 61066, "number_of_timesteps": 16138070, "per_episode_reward": 150.7, "episode_reward_trend_value": 0.04111111111111099, "biggest_recent_change": 0.700000000000017},
{"total_number_of_episodes": 61076, "number_of_timesteps": 16143070, "per_episode_reward": 151.05, "episode_reward_trend_value": 0.0433333333333334, "biggest_recent_change": 0.700000000000017},
{"total_number_of_episodes": 61086, "number_of_timesteps": 16148070, "per_episode_reward": 151.15, "episode_reward_trend_value": 0.0411111111111113, "biggest_recent_change": 0.700000000000017},
{"total_number_of_episodes": 61096, "number_of_timesteps": 16153070, "per_episode_reward": 151.25, "episode_reward_trend_value": 0.03666666666666679, "biggest_recent_change": 0.700000000000017},
{"total_number_of_episodes": 61106, "number_of_timesteps": 16158070, "per_episode_reward": 151.45, "episode_reward_trend_value": 0.031111111111110923, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 61116, "number_of_timesteps": 16163070, "per_episode_reward": 151.7, "episode_reward_trend_value": 0.028333333333333145, "biggest_recent_change": 0.44999999999998863},
{"total_number_of_episodes": 61126, "number_of_timesteps": 16168070, "per_episode_reward": 152.0, "episode_reward_trend_value": 0.02833333333333346, "biggest_recent_change": 0.44999999999998863},
{"total_number_of_episodes": 61136, "number_of_timesteps": 16173070, "per_episode_reward": 152.3, "episode_reward_trend_value": 0.027222222222222415, "biggest_recent_change": 0.44999999999998863},
{"total_number_of_episodes": 61146, "number_of_timesteps": 16178070, "per_episode_reward": 152.6, "episode_reward_trend_value": 0.026111111111111047, "biggest_recent_change": 0.44999999999998863},
{"total_number_of_episodes": 61156, "number_of_timesteps": 16183070, "per_episode_reward": 153.0, "episode_reward_trend_value": 0.025555555555555682, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 61166, "number_of_timesteps": 16188070, "per_episode_reward": 153.4, "episode_reward_trend_value": 0.026111111111111047, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 61176, "number_of_timesteps": 16193070, "per_episode_reward": 153.7, "episode_reward_trend_value": 0.028333333333333145, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 61186, "number_of_timesteps": 16198070, "per_episode_reward": 154.1, "episode_reward_trend_value": 0.03166666666666661, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 61196, "number_of_timesteps": 16203070, "per_episode_reward": 154.45, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 61206, "number_of_timesteps": 16208070, "per_episode_reward": 154.65, "episode_reward_trend_value": 0.03277777777777797, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 61216, "number_of_timesteps": 16213070, "per_episode_reward": 155.0, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 61226, "number_of_timesteps": 16218070, "per_episode_reward": 155.35, "episode_reward_trend_value": 0.033888888888888705, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 61236, "number_of_timesteps": 16223070, "per_episode_reward": 155.65, "episode_reward_trend_value": 0.03388888888888901, "biggest_recent_change": 0.4000000000000057},
{"total_number_of_episodes": 61246, "number_of_timesteps": 16228070, "per_episode_reward": 156.15, "episode_reward_trend_value": 0.035000000000000066, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 61256, "number_of_timesteps": 16233070, "per_episode_reward": 156.6, "episode_reward_trend_value": 0.03555555555555543, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 61266, "number_of_timesteps": 16238070, "per_episode_reward": 157.25, "episode_reward_trend_value": 0.039444444444444574, "biggest_recent_change": 0.6500000000000057},
{"total_number_of_episodes": 61276, "number_of_timesteps": 16243070, "per_episode_reward": 157.9, "episode_reward_trend_value": 0.04222222222222235, "biggest_recent_change": 0.6500000000000057},
{"total_number_of_episodes": 61286, "number_of_timesteps": 16248070, "per_episode_reward": 158.1, "episode_reward_trend_value": 0.040555555555555615, "biggest_recent_change": 0.6500000000000057},
{"total_number_of_episodes": 61296, "number_of_timesteps": 16253070, "per_episode_reward": 158.3, "episode_reward_trend_value": 0.040555555555555615, "biggest_recent_change": 0.6500000000000057},
{"total_number_of_episodes": 61306, "number_of_timesteps": 16258070, "per_episode_reward": 158.75, "episode_reward_trend_value": 0.04166666666666667, "biggest_recent_change": 0.6500000000000057},
{"total_number_of_episodes": 61316, "number_of_timesteps": 16263070, "per_episode_reward": 159.1, "episode_reward_trend_value": 0.04166666666666667, "biggest_recent_change": 0.6500000000000057},
{"total_number_of_episodes": 61326, "number_of_timesteps": 16268070, "per_episode_reward": 159.25, "episode_reward_trend_value": 0.03999999999999994, "biggest_recent_change": 0.6500000000000057},
{"total_number_of_episodes": 61336, "number_of_timesteps": 16273070, "per_episode_reward": 159.4, "episode_reward_trend_value": 0.03611111111111111, "biggest_recent_change": 0.6500000000000057},
{"total_number_of_episodes": 61346, "number_of_timesteps": 16278070, "per_episode_reward": 159.75, "episode_reward_trend_value": 0.035000000000000066, "biggest_recent_change": 0.6500000000000057},
{"total_number_of_episodes": 61356, "number_of_timesteps": 16283070, "per_episode_reward": 160.25, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.6500000000000057},
{"total_number_of_episodes": 61366, "number_of_timesteps": 16287154, "per_episode_reward": 160.45, "episode_reward_trend_value": 0.028333333333333145, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 61376, "number_of_timesteps": 16292154, "per_episode_reward": 160.75, "episode_reward_trend_value": 0.029444444444444506, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 61386, "number_of_timesteps": 16297154, "per_episode_reward": 161.3, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.5500000000000114},
{"total_number_of_episodes": 61396, "number_of_timesteps": 16302154, "per_episode_reward": 161.75, "episode_reward_trend_value": 0.03333333333333333, "biggest_recent_change": 0.5500000000000114},
{"total_number_of_episodes": 61406, "number_of_timesteps": 16307154, "per_episode_reward": 162.05, "episode_reward_trend_value": 0.03277777777777797, "biggest_recent_change": 0.5500000000000114},
{"total_number_of_episodes": 61416, "number_of_timesteps": 16312154, "per_episode_reward": 162.4, "episode_reward_trend_value": 0.035000000000000066, "biggest_recent_change": 0.5500000000000114},
{"total_number_of_episodes": 61426, "number_of_timesteps": 16317154, "per_episode_reward": 162.8, "episode_reward_trend_value": 0.03777777777777784, "biggest_recent_change": 0.5500000000000114},
{"total_number_of_episodes": 61436, "number_of_timesteps": 16322154, "per_episode_reward": 163.15, "episode_reward_trend_value": 0.03777777777777784, "biggest_recent_change": 0.5500000000000114},
{"total_number_of_episodes": 61446, "number_of_timesteps": 16327154, "per_episode_reward": 163.6, "episode_reward_trend_value": 0.03722222222222216, "biggest_recent_change": 0.5500000000000114},
{"total_number_of_episodes": 61456, "number_of_timesteps": 16332154, "per_episode_reward": 164.1, "episode_reward_trend_value": 0.040555555555555615, "biggest_recent_change": 0.5500000000000114},
{"total_number_of_episodes": 61466, "number_of_timesteps": 16337154, "per_episode_reward": 164.45, "episode_reward_trend_value": 0.04111111111111099, "biggest_recent_change": 0.5500000000000114},
{"total_number_of_episodes": 61476, "number_of_timesteps": 16342154, "per_episode_reward": 164.7, "episode_reward_trend_value": 0.03777777777777753, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 61486, "number_of_timesteps": 16347154, "per_episode_reward": 165.05, "episode_reward_trend_value": 0.03666666666666679, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 61496, "number_of_timesteps": 16352154, "per_episode_reward": 165.5, "episode_reward_trend_value": 0.038333333333333205, "biggest_recent_change": 0.5},
{"total_number_of_episodes": 61506, "number_of_timesteps": 16357154, "per_episode_reward": 167.1, "episode_reward_trend_value": 0.052222222222222094, "biggest_recent_change": 1.5999999999999943},
{"total_number_of_episodes": 61516, "number_of_timesteps": 16362154, "per_episode_reward": 167.5, "episode_reward_trend_value": 0.052222222222222094, "biggest_recent_change": 1.5999999999999943},
{"total_number_of_episodes": 61526, "number_of_timesteps": 16367154, "per_episode_reward": 167.8, "episode_reward_trend_value": 0.05166666666666673, "biggest_recent_change": 1.5999999999999943},
{"total_number_of_episodes": 61536, "number_of_timesteps": 16372154, "per_episode_reward": 168.1, "episode_reward_trend_value": 0.05, "biggest_recent_change": 1.5999999999999943},
{"total_number_of_episodes": 61546, "number_of_timesteps": 16377154, "per_episode_reward": 168.65, "episode_reward_trend_value": 0.05055555555555569, "biggest_recent_change": 1.5999999999999943},
{"total_number_of_episodes": 61556, "number_of_timesteps": 16382154, "per_episode_reward": 169.35, "episode_reward_trend_value": 0.054444444444444504, "biggest_recent_change": 1.5999999999999943},
{"total_number_of_episodes": 61566, "number_of_timesteps": 16387154, "per_episode_reward": 170.1, "episode_reward_trend_value": 0.06000000000000007, "biggest_recent_change": 1.5999999999999943},
{"total_number_of_episodes": 61576, "number_of_timesteps": 16392154, "per_episode_reward": 170.8, "episode_reward_trend_value": 0.06388888888888888, "biggest_recent_change": 1.5999999999999943},
{"total_number_of_episodes": 61586, "number_of_timesteps": 16397154, "per_episode_reward": 171.2, "episode_reward_trend_value": 0.06333333333333321, "biggest_recent_change": 1.5999999999999943},
{"total_number_of_episodes": 61596, "number_of_timesteps": 16402154, "per_episode_reward": 171.45, "episode_reward_trend_value": 0.04833333333333327, "biggest_recent_change": 0.75},
{"total_number_of_episodes": 61606, "number_of_timesteps": 16407154, "per_episode_reward": 172.25, "episode_reward_trend_value": 0.05277777777777778, "biggest_recent_change": 0.8000000000000114},
{"total_number_of_episodes": 61616, "number_of_timesteps": 16412154, "per_episode_reward": 173.1, "episode_reward_trend_value": 0.0588888888888887, "biggest_recent_change": 0.8499999999999943},
{"total_number_of_episodes": 61626, "number_of_timesteps": 16417154, "per_episode_reward": 173.4, "episode_reward_trend_value": 0.05888888888888901, "biggest_recent_change": 0.8499999999999943},
{"total_number_of_episodes": 61636, "number_of_timesteps": 16422154, "per_episode_reward": 174.4, "episode_reward_trend_value": 0.06388888888888888, "biggest_recent_change": 1.0},
{"total_number_of_episodes": 61646, "number_of_timesteps": 16427154, "per_episode_reward": 175.6, "episode_reward_trend_value": 0.06944444444444445, "biggest_recent_change": 1.1999999999999886},
{"total_number_of_episodes": 61656, "number_of_timesteps": 16432154, "per_episode_reward": 176.85, "episode_reward_trend_value": 0.075, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 61666, "number_of_timesteps": 16437154, "per_episode_reward": 177.4, "episode_reward_trend_value": 0.07333333333333328, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 61676, "number_of_timesteps": 16442154, "per_episode_reward": 177.8, "episode_reward_trend_value": 0.07333333333333358, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 61686, "number_of_timesteps": 16447154, "per_episode_reward": 178.2, "episode_reward_trend_value": 0.075, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 61696, "number_of_timesteps": 16452154, "per_episode_reward": 178.6, "episode_reward_trend_value": 0.0705555555555555, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 61706, "number_of_timesteps": 16457154, "per_episode_reward": 179.35, "episode_reward_trend_value": 0.06944444444444445, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 61716, "number_of_timesteps": 16462154, "per_episode_reward": 180.2, "episode_reward_trend_value": 0.07555555555555536, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 61726, "number_of_timesteps": 16467154, "per_episode_reward": 180.7, "episode_reward_trend_value": 0.06999999999999981, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 61736, "number_of_timesteps": 16472154, "per_episode_reward": 181.05, "episode_reward_trend_value": 0.06055555555555574, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 61746, "number_of_timesteps": 16477154, "per_episode_reward": 181.5, "episode_reward_trend_value": 0.05166666666666673, "biggest_recent_change": 0.8499999999999943},
{"total_number_of_episodes": 61756, "number_of_timesteps": 16482154, "per_episode_reward": 182.2, "episode_reward_trend_value": 0.05333333333333314, "biggest_recent_change": 0.8499999999999943},
{"total_number_of_episodes": 61766, "number_of_timesteps": 16487154, "per_episode_reward": 183.7, "episode_reward_trend_value": 0.0655555555555553, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 61776, "number_of_timesteps": 16492154, "per_episode_reward": 184.4, "episode_reward_trend_value": 0.06888888888888908, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 61786, "number_of_timesteps": 16497154, "per_episode_reward": 184.6, "episode_reward_trend_value": 0.06666666666666667, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 61796, "number_of_timesteps": 16502154, "per_episode_reward": 184.8, "episode_reward_trend_value": 0.06055555555555574, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 61806, "number_of_timesteps": 16507154, "per_episode_reward": 186.55, "episode_reward_trend_value": 0.0705555555555558, "biggest_recent_change": 1.75},
{"total_number_of_episodes": 61816, "number_of_timesteps": 16512154, "per_episode_reward": 188.6, "episode_reward_trend_value": 0.08777777777777784, "biggest_recent_change": 2.049999999999983},
{"total_number_of_episodes": 61826, "number_of_timesteps": 16517154, "per_episode_reward": 189.3, "episode_reward_trend_value": 0.09166666666666666, "biggest_recent_change": 2.049999999999983},
{"total_number_of_episodes": 61836, "number_of_timesteps": 16522154, "per_episode_reward": 189.9, "episode_reward_trend_value": 0.09333333333333341, "biggest_recent_change": 2.049999999999983},
{"total_number_of_episodes": 61846, "number_of_timesteps": 16527154, "per_episode_reward": 190.35, "episode_reward_trend_value": 0.09055555555555563, "biggest_recent_change": 2.049999999999983},
{"total_number_of_episodes": 61856, "number_of_timesteps": 16532154, "per_episode_reward": 190.7, "episode_reward_trend_value": 0.07777777777777778, "biggest_recent_change": 2.049999999999983},
{"total_number_of_episodes": 61866, "number_of_timesteps": 16537154, "per_episode_reward": 191.3, "episode_reward_trend_value": 0.07666666666666673, "biggest_recent_change": 2.049999999999983},
{"total_number_of_episodes": 61876, "number_of_timesteps": 16542154, "per_episode_reward": 192.1, "episode_reward_trend_value": 0.08333333333333334, "biggest_recent_change": 2.049999999999983},
{"total_number_of_episodes": 61886, "number_of_timesteps": 16547154, "per_episode_reward": 192.85, "episode_reward_trend_value": 0.08944444444444426, "biggest_recent_change": 2.049999999999983},
{"total_number_of_episodes": 61896, "number_of_timesteps": 16552154, "per_episode_reward": 193.9, "episode_reward_trend_value": 0.0816666666666666, "biggest_recent_change": 2.049999999999983},
{"total_number_of_episodes": 61906, "number_of_timesteps": 16557154, "per_episode_reward": 194.2, "episode_reward_trend_value": 0.06222222222222216, "biggest_recent_change": 1.0500000000000114},
{"total_number_of_episodes": 61916, "number_of_timesteps": 16562154, "per_episode_reward": 194.6, "episode_reward_trend_value": 0.0588888888888887, "biggest_recent_change": 1.0500000000000114},
{"total_number_of_episodes": 61926, "number_of_timesteps": 16567154, "per_episode_reward": 196.6, "episode_reward_trend_value": 0.07444444444444431, "biggest_recent_change": 2.0},
{"total_number_of_episodes": 61936, "number_of_timesteps": 16572154, "per_episode_reward": 198.7, "episode_reward_trend_value": 0.09277777777777771, "biggest_recent_change": 2.0999999999999943},
{"total_number_of_episodes": 61946, "number_of_timesteps": 16577154, "per_episode_reward": 199.65, "episode_reward_trend_value": 0.09944444444444464, "biggest_recent_change": 2.0999999999999943},
{"total_number_of_episodes": 61956, "number_of_timesteps": 16582154, "per_episode_reward": 200.65, "episode_reward_trend_value": 0.10388888888888884, "biggest_recent_change": 2.0999999999999943},
{"total_number_of_episodes": 61966, "number_of_timesteps": 16587154, "per_episode_reward": 201.3, "episode_reward_trend_value": 0.10222222222222241, "biggest_recent_change": 2.0999999999999943},
{"total_number_of_episodes": 61976, "number_of_timesteps": 16592154, "per_episode_reward": 201.65, "episode_reward_trend_value": 0.09777777777777791, "biggest_recent_change": 2.0999999999999943},
{"total_number_of_episodes": 61986, "number_of_timesteps": 16597154, "per_episode_reward": 202.3, "episode_reward_trend_value": 0.09333333333333341, "biggest_recent_change": 2.0999999999999943},
{"total_number_of_episodes": 61996, "number_of_timesteps": 16602154, "per_episode_reward": 203.0, "episode_reward_trend_value": 0.09777777777777791, "biggest_recent_change": 2.0999999999999943},
{"total_number_of_episodes": 62006, "number_of_timesteps": 16607154, "per_episode_reward": 203.3, "episode_reward_trend_value": 0.09666666666666686, "biggest_recent_change": 2.0999999999999943},
{"total_number_of_episodes": 62016, "number_of_timesteps": 16612154, "per_episode_reward": 203.65, "episode_reward_trend_value": 0.07833333333333345, "biggest_recent_change": 2.0999999999999943},
{"total_number_of_episodes": 62026, "number_of_timesteps": 16617154, "per_episode_reward": 207.35, "episode_reward_trend_value": 0.09611111111111117, "biggest_recent_change": 3.6999999999999886},
{"total_number_of_episodes": 62036, "number_of_timesteps": 16622154, "per_episode_reward": 208.15, "episode_reward_trend_value": 0.09444444444444444, "biggest_recent_change": 3.6999999999999886},
{"total_number_of_episodes": 62046, "number_of_timesteps": 16627154, "per_episode_reward": 209.05, "episode_reward_trend_value": 0.09333333333333341, "biggest_recent_change": 3.6999999999999886},
{"total_number_of_episodes": 62056, "number_of_timesteps": 16632154, "per_episode_reward": 209.85, "episode_reward_trend_value": 0.0949999999999998, "biggest_recent_change": 3.6999999999999886},
{"total_number_of_episodes": 62066, "number_of_timesteps": 16637154, "per_episode_reward": 211.3, "episode_reward_trend_value": 0.10722222222222229, "biggest_recent_change": 3.6999999999999886},
{"total_number_of_episodes": 62076, "number_of_timesteps": 16642154, "per_episode_reward": 212.65, "episode_reward_trend_value": 0.11499999999999995, "biggest_recent_change": 3.6999999999999886},
{"total_number_of_episodes": 62086, "number_of_timesteps": 16647154, "per_episode_reward": 213.0, "episode_reward_trend_value": 0.11111111111111112, "biggest_recent_change": 3.6999999999999886},
{"total_number_of_episodes": 62096, "number_of_timesteps": 16652154, "per_episode_reward": 213.55, "episode_reward_trend_value": 0.11388888888888889, "biggest_recent_change": 3.6999999999999886},
{"total_number_of_episodes": 62106, "number_of_timesteps": 16657154, "per_episode_reward": 214.1, "episode_reward_trend_value": 0.11611111111111098, "biggest_recent_change": 3.6999999999999886},
{"total_number_of_episodes": 62116, "number_of_timesteps": 16662154, "per_episode_reward": 214.3, "episode_reward_trend_value": 0.07722222222222241, "biggest_recent_change": 1.450000000000017},
{"total_number_of_episodes": 62126, "number_of_timesteps": 16667154, "per_episode_reward": 214.7, "episode_reward_trend_value": 0.07277777777777758, "biggest_recent_change": 1.450000000000017},
{"total_number_of_episodes": 62136, "number_of_timesteps": 16672154, "per_episode_reward": 215.2, "episode_reward_trend_value": 0.06833333333333308, "biggest_recent_change": 1.450000000000017},
{"total_number_of_episodes": 62146, "number_of_timesteps": 16677154, "per_episode_reward": 215.55, "episode_reward_trend_value": 0.06333333333333352, "biggest_recent_change": 1.450000000000017},
{"total_number_of_episodes": 62156, "number_of_timesteps": 16682154, "per_episode_reward": 218.0, "episode_reward_trend_value": 0.07444444444444431, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62166, "number_of_timesteps": 16687154, "per_episode_reward": 218.15, "episode_reward_trend_value": 0.061111111111111116, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62176, "number_of_timesteps": 16692154, "per_episode_reward": 218.95, "episode_reward_trend_value": 0.06611111111111098, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62186, "number_of_timesteps": 16697154, "per_episode_reward": 219.9, "episode_reward_trend_value": 0.0705555555555555, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62196, "number_of_timesteps": 16702154, "per_episode_reward": 220.2, "episode_reward_trend_value": 0.06777777777777771, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62206, "number_of_timesteps": 16707154, "per_episode_reward": 220.75, "episode_reward_trend_value": 0.07166666666666655, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62216, "number_of_timesteps": 16712154, "per_episode_reward": 221.65, "episode_reward_trend_value": 0.07722222222222241, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62226, "number_of_timesteps": 16717154, "per_episode_reward": 222.5, "episode_reward_trend_value": 0.08111111111111123, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62236, "number_of_timesteps": 16722154, "per_episode_reward": 223.3, "episode_reward_trend_value": 0.08611111111111111, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62246, "number_of_timesteps": 16727154, "per_episode_reward": 223.95, "episode_reward_trend_value": 0.06611111111111098, "biggest_recent_change": 0.950000000000017},
{"total_number_of_episodes": 62256, "number_of_timesteps": 16732154, "per_episode_reward": 224.6, "episode_reward_trend_value": 0.07166666666666655, "biggest_recent_change": 0.950000000000017},
{"total_number_of_episodes": 62266, "number_of_timesteps": 16737154, "per_episode_reward": 225.1, "episode_reward_trend_value": 0.0683333333333334, "biggest_recent_change": 0.950000000000017},
{"total_number_of_episodes": 62276, "number_of_timesteps": 16742154, "per_episode_reward": 225.95, "episode_reward_trend_value": 0.06722222222222203, "biggest_recent_change": 0.9000000000000057},
{"total_number_of_episodes": 62286, "number_of_timesteps": 16747154, "per_episode_reward": 228.05, "episode_reward_trend_value": 0.08722222222222248, "biggest_recent_change": 2.1000000000000227},
{"total_number_of_episodes": 62296, "number_of_timesteps": 16752154, "per_episode_reward": 228.35, "episode_reward_trend_value": 0.08444444444444438, "biggest_recent_change": 2.1000000000000227},
{"total_number_of_episodes": 62306, "number_of_timesteps": 16757154, "per_episode_reward": 228.85, "episode_reward_trend_value": 0.07999999999999988, "biggest_recent_change": 2.1000000000000227},
{"total_number_of_episodes": 62316, "number_of_timesteps": 16762154, "per_episode_reward": 229.6, "episode_reward_trend_value": 0.07888888888888883, "biggest_recent_change": 2.1000000000000227},
{"total_number_of_episodes": 62326, "number_of_timesteps": 16767154, "per_episode_reward": 230.75, "episode_reward_trend_value": 0.08277777777777764, "biggest_recent_change": 2.1000000000000227},
{"total_number_of_episodes": 62336, "number_of_timesteps": 16772154, "per_episode_reward": 232.0, "episode_reward_trend_value": 0.08944444444444458, "biggest_recent_change": 2.1000000000000227},
{"total_number_of_episodes": 62346, "number_of_timesteps": 16777154, "per_episode_reward": 232.85, "episode_reward_trend_value": 0.09166666666666666, "biggest_recent_change": 2.1000000000000227},
{"total_number_of_episodes": 62356, "number_of_timesteps": 16782154, "per_episode_reward": 233.3, "episode_reward_trend_value": 0.0911111111111113, "biggest_recent_change": 2.1000000000000227},
{"total_number_of_episodes": 62366, "number_of_timesteps": 16787154, "per_episode_reward": 234.3, "episode_reward_trend_value": 0.09277777777777803, "biggest_recent_change": 2.1000000000000227},
{"total_number_of_episodes": 62376, "number_of_timesteps": 16792154, "per_episode_reward": 235.6, "episode_reward_trend_value": 0.08388888888888871, "biggest_recent_change": 1.299999999999983},
{"total_number_of_episodes": 62386, "number_of_timesteps": 16797154, "per_episode_reward": 236.7, "episode_reward_trend_value": 0.09277777777777771, "biggest_recent_change": 1.299999999999983},
{"total_number_of_episodes": 62396, "number_of_timesteps": 16802154, "per_episode_reward": 238.3, "episode_reward_trend_value": 0.10500000000000018, "biggest_recent_change": 1.6000000000000227},
{"total_number_of_episodes": 62406, "number_of_timesteps": 16807154, "per_episode_reward": 239.9, "episode_reward_trend_value": 0.11444444444444457, "biggest_recent_change": 1.6000000000000227},
{"total_number_of_episodes": 62416, "number_of_timesteps": 16812154, "per_episode_reward": 242.35, "episode_reward_trend_value": 0.12888888888888883, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62426, "number_of_timesteps": 16817154, "per_episode_reward": 243.1, "episode_reward_trend_value": 0.12333333333333327, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62436, "number_of_timesteps": 16822154, "per_episode_reward": 243.75, "episode_reward_trend_value": 0.12111111111111117, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62446, "number_of_timesteps": 16827154, "per_episode_reward": 244.4, "episode_reward_trend_value": 0.12333333333333327, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62456, "number_of_timesteps": 16832154, "per_episode_reward": 245.5, "episode_reward_trend_value": 0.12444444444444432, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62466, "number_of_timesteps": 16837154, "per_episode_reward": 246.4, "episode_reward_trend_value": 0.12000000000000013, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62476, "number_of_timesteps": 16842154, "per_episode_reward": 247.6, "episode_reward_trend_value": 0.12111111111111117, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62486, "number_of_timesteps": 16847154, "per_episode_reward": 248.85, "episode_reward_trend_value": 0.11722222222222203, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62496, "number_of_timesteps": 16852154, "per_episode_reward": 249.1, "episode_reward_trend_value": 0.1022222222222221, "biggest_recent_change": 2.4499999999999886},
{"total_number_of_episodes": 62506, "number_of_timesteps": 16857154, "per_episode_reward": 249.35, "episode_reward_trend_value": 0.07777777777777778, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 62516, "number_of_timesteps": 16862154, "per_episode_reward": 250.15, "episode_reward_trend_value": 0.07833333333333345, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 62526, "number_of_timesteps": 16867154, "per_episode_reward": 251.0, "episode_reward_trend_value": 0.08055555555555556, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 62536, "number_of_timesteps": 16872154, "per_episode_reward": 251.7, "episode_reward_trend_value": 0.08111111111111093, "biggest_recent_change": 1.25},
{"total_number_of_episodes": 62546, "number_of_timesteps": 16877154, "per_episode_reward": 257.9, "episode_reward_trend_value": 0.13777777777777753, "biggest_recent_change": 6.199999999999989},
{"total_number_of_episodes": 62556, "number_of_timesteps": 16882154, "per_episode_reward": 259.4, "episode_reward_trend_value": 0.14444444444444413, "biggest_recent_change": 6.199999999999989},
{"total_number_of_episodes": 62566, "number_of_timesteps": 16887154, "per_episode_reward": 260.3, "episode_reward_trend_value": 0.1411111111111113, "biggest_recent_change": 6.199999999999989},
{"total_number_of_episodes": 62576, "number_of_timesteps": 16892154, "per_episode_reward": 260.7, "episode_reward_trend_value": 0.1316666666666666, "biggest_recent_change": 6.199999999999989},
{"total_number_of_episodes": 62586, "number_of_timesteps": 16897154, "per_episode_reward": 261.35, "episode_reward_trend_value": 0.13611111111111143, "biggest_recent_change": 6.199999999999989},
{"total_number_of_episodes": 62596, "number_of_timesteps": 16902154, "per_episode_reward": 262.0, "episode_reward_trend_value": 0.1405555555555556, "biggest_recent_change": 6.199999999999989},
{"total_number_of_episodes": 62606, "number_of_timesteps": 16907154, "per_episode_reward": 263.0, "episode_reward_trend_value": 0.14277777777777773, "biggest_recent_change": 6.199999999999989},
{"total_number_of_episodes": 62616, "number_of_timesteps": 16912154, "per_episode_reward": 264.15, "episode_reward_trend_value": 0.14611111111111086, "biggest_recent_change": 6.199999999999989},
{"total_number_of_episodes": 62626, "number_of_timesteps": 16917154, "per_episode_reward": 264.9, "episode_reward_trend_value": 0.14666666666666656, "biggest_recent_change": 6.199999999999989},
{"total_number_of_episodes": 62636, "number_of_timesteps": 16922154, "per_episode_reward": 265.65, "episode_reward_trend_value": 0.08611111111111111, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 62646, "number_of_timesteps": 16927154, "per_episode_reward": 266.55, "episode_reward_trend_value": 0.07944444444444483, "biggest_recent_change": 1.1499999999999773},
{"total_number_of_episodes": 62656, "number_of_timesteps": 16932154, "per_episode_reward": 267.4, "episode_reward_trend_value": 0.07888888888888851, "biggest_recent_change": 1.1499999999999773},
{"total_number_of_episodes": 62666, "number_of_timesteps": 16937154, "per_episode_reward": 268.1, "episode_reward_trend_value": 0.0822222222222226, "biggest_recent_change": 1.1499999999999773},
{"total_number_of_episodes": 62676, "number_of_timesteps": 16942154, "per_episode_reward": 269.0, "episode_reward_trend_value": 0.08499999999999974, "biggest_recent_change": 1.1499999999999773},
{"total_number_of_episodes": 62686, "number_of_timesteps": 16947154, "per_episode_reward": 270.55, "episode_reward_trend_value": 0.09500000000000013, "biggest_recent_change": 1.5500000000000114},
{"total_number_of_episodes": 62696, "number_of_timesteps": 16952154, "per_episode_reward": 271.5, "episode_reward_trend_value": 0.09444444444444444, "biggest_recent_change": 1.5500000000000114},
{"total_number_of_episodes": 62706, "number_of_timesteps": 16957154, "per_episode_reward": 272.05, "episode_reward_trend_value": 0.08777777777777815, "biggest_recent_change": 1.5500000000000114},
{"total_number_of_episodes": 62716, "number_of_timesteps": 16962154, "per_episode_reward": 272.5, "episode_reward_trend_value": 0.0844444444444447, "biggest_recent_change": 1.5500000000000114},
{"total_number_of_episodes": 62726, "number_of_timesteps": 16967154, "per_episode_reward": 272.6, "episode_reward_trend_value": 0.07722222222222272, "biggest_recent_change": 1.5500000000000114},
{"total_number_of_episodes": 62736, "number_of_timesteps": 16972154, "per_episode_reward": 272.9, "episode_reward_trend_value": 0.07055555555555518, "biggest_recent_change": 1.5500000000000114},
{"total_number_of_episodes": 62746, "number_of_timesteps": 16977154, "per_episode_reward": 273.5, "episode_reward_trend_value": 0.06777777777777802, "biggest_recent_change": 1.5500000000000114},
{"total_number_of_episodes": 62756, "number_of_timesteps": 16982154, "per_episode_reward": 274.15, "episode_reward_trend_value": 0.06722222222222171, "biggest_recent_change": 1.5500000000000114},
{"total_number_of_episodes": 62766, "number_of_timesteps": 16987154, "per_episode_reward": 274.7, "episode_reward_trend_value": 0.06333333333333321, "biggest_recent_change": 1.5500000000000114},
{"total_number_of_episodes": 62776, "number_of_timesteps": 16992154, "per_episode_reward": 275.3, "episode_reward_trend_value": 0.05277777777777778, "biggest_recent_change": 0.9499999999999886},
{"total_number_of_episodes": 62786, "number_of_timesteps": 16997154, "per_episode_reward": 275.8, "episode_reward_trend_value": 0.047777777777777905, "biggest_recent_change": 0.6499999999999773},
{"total_number_of_episodes": 62796, "number_of_timesteps": 17002154, "per_episode_reward": 276.75, "episode_reward_trend_value": 0.052222222222222094, "biggest_recent_change": 0.9499999999999886},
{"total_number_of_episodes": 62806, "number_of_timesteps": 17007154, "per_episode_reward": 277.95, "episode_reward_trend_value": 0.06055555555555543, "biggest_recent_change": 1.1999999999999886},
{"total_number_of_episodes": 62816, "number_of_timesteps": 17012154, "per_episode_reward": 278.75, "episode_reward_trend_value": 0.06833333333333308, "biggest_recent_change": 1.1999999999999886},
{"total_number_of_episodes": 62826, "number_of_timesteps": 17017154, "per_episode_reward": 279.35, "episode_reward_trend_value": 0.07166666666666717, "biggest_recent_change": 1.1999999999999886},
{"total_number_of_episodes": 62836, "number_of_timesteps": 17022154, "per_episode_reward": 280.3, "episode_reward_trend_value": 0.07555555555555568, "biggest_recent_change": 1.1999999999999886},
{"total_number_of_episodes": 62846, "number_of_timesteps": 17027154, "per_episode_reward": 283.3, "episode_reward_trend_value": 0.10166666666666704, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 62856, "number_of_timesteps": 17032154, "per_episode_reward": 285.95, "episode_reward_trend_value": 0.125, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 62866, "number_of_timesteps": 17037154, "per_episode_reward": 287.3, "episode_reward_trend_value": 0.13333333333333333, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 62876, "number_of_timesteps": 17042154, "per_episode_reward": 288.5, "episode_reward_trend_value": 0.141111111111111, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 62886, "number_of_timesteps": 17047154, "per_episode_reward": 289.35, "episode_reward_trend_value": 0.14000000000000026, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 62896, "number_of_timesteps": 17052154, "per_episode_reward": 290.0, "episode_reward_trend_value": 0.133888888888889, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 62906, "number_of_timesteps": 17057154, "per_episode_reward": 290.25, "episode_reward_trend_value": 0.12777777777777777, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 62916, "number_of_timesteps": 17062154, "per_episode_reward": 290.95, "episode_reward_trend_value": 0.12888888888888853, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 62926, "number_of_timesteps": 17067154, "per_episode_reward": 291.75, "episode_reward_trend_value": 0.1272222222222221, "biggest_recent_change": 3.0},
{"total_number_of_episodes": 62936, "number_of_timesteps": 17072154, "per_episode_reward": 292.25, "episode_reward_trend_value": 0.09944444444444431, "biggest_recent_change": 2.6499999999999773},
{"total_number_of_episodes": 62946, "number_of_timesteps": 17077154, "per_episode_reward": 292.5, "episode_reward_trend_value": 0.07277777777777791, "biggest_recent_change": 1.3500000000000227},
{"total_number_of_episodes": 62956, "number_of_timesteps": 17082154, "per_episode_reward": 293.0, "episode_reward_trend_value": 0.06333333333333321, "biggest_recent_change": 1.1999999999999886},
{"total_number_of_episodes": 62966, "number_of_timesteps": 17087154, "per_episode_reward": 293.4, "episode_reward_trend_value": 0.0544444444444442, "biggest_recent_change": 0.8500000000000227},
{"total_number_of_episodes": 62976, "number_of_timesteps": 17092154, "per_episode_reward": 293.6, "episode_reward_trend_value": 0.04722222222222222, "biggest_recent_change": 0.8000000000000114},
{"total_number_of_episodes": 62986, "number_of_timesteps": 17097154, "per_episode_reward": 294.0, "episode_reward_trend_value": 0.04444444444444444, "biggest_recent_change": 0.8000000000000114},
{"total_number_of_episodes": 62996, "number_of_timesteps": 17102154, "per_episode_reward": 295.15, "episode_reward_trend_value": 0.0544444444444442, "biggest_recent_change": 1.1499999999999773},
{"total_number_of_episodes": 63006, "number_of_timesteps": 17107154, "per_episode_reward": 296.6, "episode_reward_trend_value": 0.06277777777777815, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63016, "number_of_timesteps": 17112154, "per_episode_reward": 297.15, "episode_reward_trend_value": 0.05999999999999974, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63026, "number_of_timesteps": 17117154, "per_episode_reward": 297.4, "episode_reward_trend_value": 0.05722222222222197, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63036, "number_of_timesteps": 17122154, "per_episode_reward": 299.05, "episode_reward_trend_value": 0.07277777777777791, "biggest_recent_change": 1.650000000000034},
{"total_number_of_episodes": 63046, "number_of_timesteps": 17127154, "per_episode_reward": 300.6, "episode_reward_trend_value": 0.0844444444444447, "biggest_recent_change": 1.650000000000034},
{"total_number_of_episodes": 63056, "number_of_timesteps": 17132154, "per_episode_reward": 300.95, "episode_reward_trend_value": 0.08388888888888901, "biggest_recent_change": 1.650000000000034},
{"total_number_of_episodes": 63066, "number_of_timesteps": 17137154, "per_episode_reward": 301.25, "episode_reward_trend_value": 0.08499999999999974, "biggest_recent_change": 1.650000000000034},
{"total_number_of_episodes": 63076, "number_of_timesteps": 17142154, "per_episode_reward": 301.7, "episode_reward_trend_value": 0.08555555555555543, "biggest_recent_change": 1.650000000000034},
{"total_number_of_episodes": 63086, "number_of_timesteps": 17147154, "per_episode_reward": 302.2, "episode_reward_trend_value": 0.07833333333333345, "biggest_recent_change": 1.650000000000034},
{"total_number_of_episodes": 63096, "number_of_timesteps": 17152154, "per_episode_reward": 302.65, "episode_reward_trend_value": 0.06722222222222171, "biggest_recent_change": 1.650000000000034},
{"total_number_of_episodes": 63106, "number_of_timesteps": 17157154, "per_episode_reward": 303.25, "episode_reward_trend_value": 0.06777777777777802, "biggest_recent_change": 1.650000000000034},
{"total_number_of_episodes": 63116, "number_of_timesteps": 17162154, "per_episode_reward": 304.25, "episode_reward_trend_value": 0.07611111111111137, "biggest_recent_change": 1.650000000000034},
{"total_number_of_episodes": 63126, "number_of_timesteps": 17167154, "per_episode_reward": 305.05, "episode_reward_trend_value": 0.06666666666666667, "biggest_recent_change": 1.5500000000000114},
{"total_number_of_episodes": 63136, "number_of_timesteps": 17172154, "per_episode_reward": 305.3, "episode_reward_trend_value": 0.052222222222222094, "biggest_recent_change": 1.0},
{"total_number_of_episodes": 63146, "number_of_timesteps": 17177154, "per_episode_reward": 305.55, "episode_reward_trend_value": 0.051111111111111364, "biggest_recent_change": 1.0},
{"total_number_of_episodes": 63156, "number_of_timesteps": 17182154, "per_episode_reward": 306.05, "episode_reward_trend_value": 0.053333333333333455, "biggest_recent_change": 1.0},
{"total_number_of_episodes": 63166, "number_of_timesteps": 17187154, "per_episode_reward": 306.8, "episode_reward_trend_value": 0.05666666666666692, "biggest_recent_change": 1.0},
{"total_number_of_episodes": 63176, "number_of_timesteps": 17192154, "per_episode_reward": 307.7, "episode_reward_trend_value": 0.061111111111111116, "biggest_recent_change": 1.0},
{"total_number_of_episodes": 63186, "number_of_timesteps": 17197154, "per_episode_reward": 308.3, "episode_reward_trend_value": 0.06277777777777815, "biggest_recent_change": 1.0},
{"total_number_of_episodes": 63196, "number_of_timesteps": 17202154, "per_episode_reward": 309.65, "episode_reward_trend_value": 0.07111111111111086, "biggest_recent_change": 1.349999999999966},
{"total_number_of_episodes": 63206, "number_of_timesteps": 17206842, "per_episode_reward": 311.1, "episode_reward_trend_value": 0.07611111111111137, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63216, "number_of_timesteps": 17211842, "per_episode_reward": 311.75, "episode_reward_trend_value": 0.07444444444444431, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63226, "number_of_timesteps": 17216842, "per_episode_reward": 312.65, "episode_reward_trend_value": 0.08166666666666629, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63236, "number_of_timesteps": 17221842, "per_episode_reward": 313.3, "episode_reward_trend_value": 0.08611111111111111, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63246, "number_of_timesteps": 17226842, "per_episode_reward": 313.8, "episode_reward_trend_value": 0.08611111111111111, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63256, "number_of_timesteps": 17231842, "per_episode_reward": 314.65, "episode_reward_trend_value": 0.08722222222222184, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63266, "number_of_timesteps": 17236842, "per_episode_reward": 315.75, "episode_reward_trend_value": 0.08944444444444458, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63276, "number_of_timesteps": 17241842, "per_episode_reward": 316.55, "episode_reward_trend_value": 0.09166666666666666, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63286, "number_of_timesteps": 17246842, "per_episode_reward": 317.55, "episode_reward_trend_value": 0.08777777777777815, "biggest_recent_change": 1.4500000000000455},
{"total_number_of_episodes": 63296, "number_of_timesteps": 17251842, "per_episode_reward": 318.75, "episode_reward_trend_value": 0.08499999999999974, "biggest_recent_change": 1.1999999999999886},
{"total_number_of_episodes": 63306, "number_of_timesteps": 17256842, "per_episode_reward": 320.15, "episode_reward_trend_value": 0.09333333333333307, "biggest_recent_change": 1.3999999999999773},
{"total_number_of_episodes": 63316, "number_of_timesteps": 17261842, "per_episode_reward": 321.65, "episode_reward_trend_value": 0.1, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 63326, "number_of_timesteps": 17266842, "per_episode_reward": 322.55, "episode_reward_trend_value": 0.10277777777777777, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 63336, "number_of_timesteps": 17271842, "per_episode_reward": 323.6, "episode_reward_trend_value": 0.10888888888888901, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 63346, "number_of_timesteps": 17276842, "per_episode_reward": 324.95, "episode_reward_trend_value": 0.11444444444444457, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 63356, "number_of_timesteps": 17281842, "per_episode_reward": 326.1, "episode_reward_trend_value": 0.11500000000000025, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 63366, "number_of_timesteps": 17286842, "per_episode_reward": 326.9, "episode_reward_trend_value": 0.11499999999999962, "biggest_recent_change": 1.5},
{"total_number_of_episodes": 63376, "number_of_timesteps": 17291842, "per_episode_reward": 328.5, "episode_reward_trend_value": 0.12166666666666655, "biggest_recent_change": 1.6000000000000227},
{"total_number_of_episodes": 63386, "number_of_timesteps": 17296842, "per_episode_reward": 330.0, "episode_reward_trend_value": 0.125, "biggest_recent_change": 1.6000000000000227},
{"total_number_of_episodes": 63396, "number_of_timesteps": 17301842, "per_episode_reward": 330.65, "episode_reward_trend_value": 0.11666666666666667, "biggest_recent_change": 1.6000000000000227},
{"total_number_of_episodes": 63406, "number_of_timesteps": 17306842, "per_episode_reward": 331.25, "episode_reward_trend_value": 0.10666666666666691, "biggest_recent_change": 1.6000000000000227},
{"total_number_of_episodes": 63416, "number_of_timesteps": 17311842, "per_episode_reward": 333.45, "episode_reward_trend_value": 0.12111111111111086, "biggest_recent_change": 2.1999999999999886},
{"total_number_of_episodes": 63426, "number_of_timesteps": 17316842, "per_episode_reward": 335.95, "episode_reward_trend_value": 0.13722222222222186, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 63436, "number_of_timesteps": 17321842, "per_episode_reward": 337.15, "episode_reward_trend_value": 0.13555555555555543, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 63446, "number_of_timesteps": 17326842, "per_episode_reward": 339.0, "episode_reward_trend_value": 0.1433333333333331, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 63456, "number_of_timesteps": 17331842, "per_episode_reward": 340.7, "episode_reward_trend_value": 0.15333333333333346, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 63466, "number_of_timesteps": 17336842, "per_episode_reward": 341.55, "episode_reward_trend_value": 0.14500000000000013, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 63476, "number_of_timesteps": 17341842, "per_episode_reward": 342.65, "episode_reward_trend_value": 0.1405555555555553, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 63486, "number_of_timesteps": 17346842, "per_episode_reward": 343.65, "episode_reward_trend_value": 0.14444444444444443, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 63496, "number_of_timesteps": 17351842, "per_episode_reward": 344.45, "episode_reward_trend_value": 0.14666666666666656, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 63506, "number_of_timesteps": 17356842, "per_episode_reward": 345.45, "episode_reward_trend_value": 0.13333333333333333, "biggest_recent_change": 2.5},
{"total_number_of_episodes": 63516, "number_of_timesteps": 17361842, "per_episode_reward": 345.8, "episode_reward_trend_value": 0.1094444444444447, "biggest_recent_change": 1.8500000000000227},
{"total_number_of_episodes": 63526, "number_of_timesteps": 17366399, "per_episode_reward": 346.05, "episode_reward_trend_value": 0.09888888888888928, "biggest_recent_change": 1.8500000000000227},
{"total_number_of_episodes": 63536, "number_of_timesteps": 17371399, "per_episode_reward": 346.3, "episode_reward_trend_value": 0.08111111111111123, "biggest_recent_change": 1.6999999999999886},
{"total_number_of_episodes": 63546, "number_of_timesteps": 17376399, "per_episode_reward": 347.2, "episode_reward_trend_value": 0.07222222222222222, "biggest_recent_change": 1.099999999999966},
{"total_number_of_episodes": 63556, "number_of_timesteps": 17381399, "per_episode_reward": 348.1, "episode_reward_trend_value": 0.07277777777777791, "biggest_recent_change": 1.099999999999966},
{"total_number_of_episodes": 63566, "number_of_timesteps": 17386399, "per_episode_reward": 349.05, "episode_reward_trend_value": 0.07111111111111149, "biggest_recent_change": 1.0},
{"total_number_of_episodes": 63576, "number_of_timesteps": 17391399, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0705555555555558, "biggest_recent_change": 1.0},
{"total_number_of_episodes": 63586, "number_of_timesteps": 17396399, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.06166666666666679, "biggest_recent_change": 1.0},
{"total_number_of_episodes": 63596, "number_of_timesteps": 17401013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.05055555555555569, "biggest_recent_change": 0.9499999999999886},
{"total_number_of_episodes": 63606, "number_of_timesteps": 17406013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.04666666666666654, "biggest_recent_change": 0.9499999999999886},
{"total_number_of_episodes": 63616, "number_of_timesteps": 17411013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.04388888888888876, "biggest_recent_change": 0.9499999999999886},
{"total_number_of_episodes": 63626, "number_of_timesteps": 17416013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.04111111111111099, "biggest_recent_change": 0.9499999999999886},
{"total_number_of_episodes": 63636, "number_of_timesteps": 17421013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.03111111111111124, "biggest_recent_change": 0.9499999999999886},
{"total_number_of_episodes": 63646, "number_of_timesteps": 17426013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.02111111111111086, "biggest_recent_change": 0.9499999999999886},
{"total_number_of_episodes": 63656, "number_of_timesteps": 17431013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.01055555555555543, "biggest_recent_change": 0.9499999999999886},
{"total_number_of_episodes": 63666, "number_of_timesteps": 17436013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63676, "number_of_timesteps": 17441013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63686, "number_of_timesteps": 17446013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63696, "number_of_timesteps": 17451013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63706, "number_of_timesteps": 17456013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63716, "number_of_timesteps": 17461013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63726, "number_of_timesteps": 17466013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63736, "number_of_timesteps": 17471013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63746, "number_of_timesteps": 17476013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63756, "number_of_timesteps": 17481013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63766, "number_of_timesteps": 17486013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63776, "number_of_timesteps": 17491013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63786, "number_of_timesteps": 17496013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63796, "number_of_timesteps": 17501013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63806, "number_of_timesteps": 17506013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63816, "number_of_timesteps": 17511013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63826, "number_of_timesteps": 17516013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63836, "number_of_timesteps": 17521013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63846, "number_of_timesteps": 17526013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63856, "number_of_timesteps": 17531013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63866, "number_of_timesteps": 17536013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63876, "number_of_timesteps": 17541013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63886, "number_of_timesteps": 17546013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63896, "number_of_timesteps": 17551013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63906, "number_of_timesteps": 17556013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63916, "number_of_timesteps": 17561013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63926, "number_of_timesteps": 17566013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63936, "number_of_timesteps": 17571013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63946, "number_of_timesteps": 17576013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63956, "number_of_timesteps": 17581013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63966, "number_of_timesteps": 17586013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63976, "number_of_timesteps": 17591013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63986, "number_of_timesteps": 17596013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 63996, "number_of_timesteps": 17601013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64006, "number_of_timesteps": 17606013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64016, "number_of_timesteps": 17611013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64026, "number_of_timesteps": 17616013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64036, "number_of_timesteps": 17621013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64046, "number_of_timesteps": 17626013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64056, "number_of_timesteps": 17631013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64066, "number_of_timesteps": 17636013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64076, "number_of_timesteps": 17641013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64086, "number_of_timesteps": 17646013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64096, "number_of_timesteps": 17651013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64106, "number_of_timesteps": 17656013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64116, "number_of_timesteps": 17661013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64126, "number_of_timesteps": 17666013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64136, "number_of_timesteps": 17671013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64146, "number_of_timesteps": 17676013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64156, "number_of_timesteps": 17681013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64166, "number_of_timesteps": 17686013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64176, "number_of_timesteps": 17691013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64186, "number_of_timesteps": 17696013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64196, "number_of_timesteps": 17701013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64206, "number_of_timesteps": 17706013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64216, "number_of_timesteps": 17711013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64226, "number_of_timesteps": 17716013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64236, "number_of_timesteps": 17721013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64246, "number_of_timesteps": 17726013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64256, "number_of_timesteps": 17731013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64266, "number_of_timesteps": 17736013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64276, "number_of_timesteps": 17741013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64286, "number_of_timesteps": 17746013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64296, "number_of_timesteps": 17751013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64306, "number_of_timesteps": 17756013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64316, "number_of_timesteps": 17761013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64326, "number_of_timesteps": 17766013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64336, "number_of_timesteps": 17771013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64346, "number_of_timesteps": 17776013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64356, "number_of_timesteps": 17781013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64366, "number_of_timesteps": 17786013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64376, "number_of_timesteps": 17791013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64386, "number_of_timesteps": 17796013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64396, "number_of_timesteps": 17801013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64406, "number_of_timesteps": 17806013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64416, "number_of_timesteps": 17811013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64426, "number_of_timesteps": 17816013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64436, "number_of_timesteps": 17821013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64446, "number_of_timesteps": 17826013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64456, "number_of_timesteps": 17831013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64466, "number_of_timesteps": 17836013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64476, "number_of_timesteps": 17841013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64486, "number_of_timesteps": 17846013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64496, "number_of_timesteps": 17851013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64506, "number_of_timesteps": 17856013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64516, "number_of_timesteps": 17861013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64526, "number_of_timesteps": 17866013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64536, "number_of_timesteps": 17871013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64546, "number_of_timesteps": 17876013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64556, "number_of_timesteps": 17881013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64566, "number_of_timesteps": 17886013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64576, "number_of_timesteps": 17891013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64586, "number_of_timesteps": 17896013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64596, "number_of_timesteps": 17901013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64606, "number_of_timesteps": 17906013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64616, "number_of_timesteps": 17911013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64626, "number_of_timesteps": 17916013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64636, "number_of_timesteps": 17921013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64646, "number_of_timesteps": 17926013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64656, "number_of_timesteps": 17931013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64666, "number_of_timesteps": 17936013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64676, "number_of_timesteps": 17941013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64686, "number_of_timesteps": 17946013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64696, "number_of_timesteps": 17951013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64706, "number_of_timesteps": 17956013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64716, "number_of_timesteps": 17961013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64726, "number_of_timesteps": 17966013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64736, "number_of_timesteps": 17971013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64746, "number_of_timesteps": 17976013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64756, "number_of_timesteps": 17981013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64766, "number_of_timesteps": 17986013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64776, "number_of_timesteps": 17991013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64786, "number_of_timesteps": 17996013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64796, "number_of_timesteps": 18001013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64806, "number_of_timesteps": 18006013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64816, "number_of_timesteps": 18011013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64826, "number_of_timesteps": 18016013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64836, "number_of_timesteps": 18021013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64846, "number_of_timesteps": 18026013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64856, "number_of_timesteps": 18031013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64866, "number_of_timesteps": 18036013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64876, "number_of_timesteps": 18041013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64886, "number_of_timesteps": 18046013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64896, "number_of_timesteps": 18051013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64906, "number_of_timesteps": 18056013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64916, "number_of_timesteps": 18061013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64926, "number_of_timesteps": 18066013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64936, "number_of_timesteps": 18071013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64946, "number_of_timesteps": 18076013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64956, "number_of_timesteps": 18081013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64966, "number_of_timesteps": 18086013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64976, "number_of_timesteps": 18091013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64986, "number_of_timesteps": 18096013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 64996, "number_of_timesteps": 18101013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65006, "number_of_timesteps": 18106013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65016, "number_of_timesteps": 18111013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65026, "number_of_timesteps": 18116013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65036, "number_of_timesteps": 18121013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65046, "number_of_timesteps": 18126013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65056, "number_of_timesteps": 18131013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65066, "number_of_timesteps": 18136013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65076, "number_of_timesteps": 18141013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65086, "number_of_timesteps": 18146013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65096, "number_of_timesteps": 18151013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65106, "number_of_timesteps": 18156013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65116, "number_of_timesteps": 18161013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65126, "number_of_timesteps": 18166013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65136, "number_of_timesteps": 18171013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65146, "number_of_timesteps": 18176013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65156, "number_of_timesteps": 18181013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65166, "number_of_timesteps": 18186013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65176, "number_of_timesteps": 18191013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65186, "number_of_timesteps": 18196013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65196, "number_of_timesteps": 18201013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65206, "number_of_timesteps": 18206013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65216, "number_of_timesteps": 18211013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65226, "number_of_timesteps": 18216013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65236, "number_of_timesteps": 18221013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65246, "number_of_timesteps": 18226013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65256, "number_of_timesteps": 18231013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65266, "number_of_timesteps": 18236013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65276, "number_of_timesteps": 18241013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65286, "number_of_timesteps": 18246013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65296, "number_of_timesteps": 18251013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65306, "number_of_timesteps": 18256013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65316, "number_of_timesteps": 18261013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65326, "number_of_timesteps": 18266013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65336, "number_of_timesteps": 18271013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65346, "number_of_timesteps": 18276013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65356, "number_of_timesteps": 18281013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65366, "number_of_timesteps": 18286013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65376, "number_of_timesteps": 18291013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65386, "number_of_timesteps": 18296013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65396, "number_of_timesteps": 18301013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65406, "number_of_timesteps": 18306013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65416, "number_of_timesteps": 18311013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65426, "number_of_timesteps": 18316013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65436, "number_of_timesteps": 18321013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65446, "number_of_timesteps": 18326013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65456, "number_of_timesteps": 18331013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65466, "number_of_timesteps": 18336013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65476, "number_of_timesteps": 18341013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65486, "number_of_timesteps": 18346013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65496, "number_of_timesteps": 18351013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65506, "number_of_timesteps": 18356013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65516, "number_of_timesteps": 18361013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65526, "number_of_timesteps": 18366013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65536, "number_of_timesteps": 18371013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65546, "number_of_timesteps": 18376013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65556, "number_of_timesteps": 18381013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65566, "number_of_timesteps": 18386013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65576, "number_of_timesteps": 18391013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65586, "number_of_timesteps": 18396013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65596, "number_of_timesteps": 18401013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65606, "number_of_timesteps": 18406013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65616, "number_of_timesteps": 18411013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65626, "number_of_timesteps": 18416013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65636, "number_of_timesteps": 18421013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65646, "number_of_timesteps": 18426013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65656, "number_of_timesteps": 18431013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65666, "number_of_timesteps": 18436013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65676, "number_of_timesteps": 18441013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65686, "number_of_timesteps": 18446013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65696, "number_of_timesteps": 18451013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65706, "number_of_timesteps": 18456013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65716, "number_of_timesteps": 18461013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65726, "number_of_timesteps": 18466013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65736, "number_of_timesteps": 18471013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65746, "number_of_timesteps": 18476013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65756, "number_of_timesteps": 18481013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65766, "number_of_timesteps": 18486013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65776, "number_of_timesteps": 18491013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65786, "number_of_timesteps": 18496013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65796, "number_of_timesteps": 18501013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65806, "number_of_timesteps": 18506013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65816, "number_of_timesteps": 18511013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65826, "number_of_timesteps": 18516013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65836, "number_of_timesteps": 18521013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65846, "number_of_timesteps": 18526013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65856, "number_of_timesteps": 18531013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65866, "number_of_timesteps": 18536013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65876, "number_of_timesteps": 18541013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65886, "number_of_timesteps": 18546013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65896, "number_of_timesteps": 18551013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65906, "number_of_timesteps": 18556013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65916, "number_of_timesteps": 18561013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65926, "number_of_timesteps": 18566013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65936, "number_of_timesteps": 18571013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65946, "number_of_timesteps": 18576013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65956, "number_of_timesteps": 18581013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65966, "number_of_timesteps": 18586013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65976, "number_of_timesteps": 18591013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65986, "number_of_timesteps": 18596013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 65996, "number_of_timesteps": 18601013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66006, "number_of_timesteps": 18606013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66016, "number_of_timesteps": 18611013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66026, "number_of_timesteps": 18616013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66036, "number_of_timesteps": 18621013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66046, "number_of_timesteps": 18626013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66056, "number_of_timesteps": 18631013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66066, "number_of_timesteps": 18636013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66076, "number_of_timesteps": 18641013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66086, "number_of_timesteps": 18646013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66096, "number_of_timesteps": 18651013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66106, "number_of_timesteps": 18656013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66116, "number_of_timesteps": 18661013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66126, "number_of_timesteps": 18666013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66136, "number_of_timesteps": 18671013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66146, "number_of_timesteps": 18676013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66156, "number_of_timesteps": 18681013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66166, "number_of_timesteps": 18686013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66176, "number_of_timesteps": 18691013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66186, "number_of_timesteps": 18696013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66196, "number_of_timesteps": 18701013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66206, "number_of_timesteps": 18706013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66216, "number_of_timesteps": 18711013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66226, "number_of_timesteps": 18716013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66236, "number_of_timesteps": 18721013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66246, "number_of_timesteps": 18726013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66256, "number_of_timesteps": 18731013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66266, "number_of_timesteps": 18736013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66276, "number_of_timesteps": 18741013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66286, "number_of_timesteps": 18746013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66296, "number_of_timesteps": 18751013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66306, "number_of_timesteps": 18756013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66316, "number_of_timesteps": 18761013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66326, "number_of_timesteps": 18766013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66336, "number_of_timesteps": 18771013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66346, "number_of_timesteps": 18776013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66356, "number_of_timesteps": 18781013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66366, "number_of_timesteps": 18786013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66376, "number_of_timesteps": 18791013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66386, "number_of_timesteps": 18796013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66396, "number_of_timesteps": 18801013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66406, "number_of_timesteps": 18806013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66416, "number_of_timesteps": 18811013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66426, "number_of_timesteps": 18816013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66436, "number_of_timesteps": 18821013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66446, "number_of_timesteps": 18826013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66456, "number_of_timesteps": 18831013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66466, "number_of_timesteps": 18836013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66476, "number_of_timesteps": 18841013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66486, "number_of_timesteps": 18846013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66496, "number_of_timesteps": 18851013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66506, "number_of_timesteps": 18856013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66516, "number_of_timesteps": 18861013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66526, "number_of_timesteps": 18866013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66536, "number_of_timesteps": 18871013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66546, "number_of_timesteps": 18876013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66556, "number_of_timesteps": 18881013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66566, "number_of_timesteps": 18886013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66576, "number_of_timesteps": 18891013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66586, "number_of_timesteps": 18896013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66596, "number_of_timesteps": 18901013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66606, "number_of_timesteps": 18906013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66616, "number_of_timesteps": 18911013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66626, "number_of_timesteps": 18916013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66636, "number_of_timesteps": 18921013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66646, "number_of_timesteps": 18926013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66656, "number_of_timesteps": 18931013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66666, "number_of_timesteps": 18936013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66676, "number_of_timesteps": 18941013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66686, "number_of_timesteps": 18946013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66696, "number_of_timesteps": 18951013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66706, "number_of_timesteps": 18956013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66716, "number_of_timesteps": 18961013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66726, "number_of_timesteps": 18966013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66736, "number_of_timesteps": 18971013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66746, "number_of_timesteps": 18976013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66756, "number_of_timesteps": 18981013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66766, "number_of_timesteps": 18986013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66776, "number_of_timesteps": 18991013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66786, "number_of_timesteps": 18996013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66796, "number_of_timesteps": 19001013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66806, "number_of_timesteps": 19006013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66816, "number_of_timesteps": 19011013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66826, "number_of_timesteps": 19016013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66836, "number_of_timesteps": 19021013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66846, "number_of_timesteps": 19026013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66856, "number_of_timesteps": 19031013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66866, "number_of_timesteps": 19036013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66876, "number_of_timesteps": 19041013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66886, "number_of_timesteps": 19046013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66896, "number_of_timesteps": 19051013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66906, "number_of_timesteps": 19056013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66916, "number_of_timesteps": 19061013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66926, "number_of_timesteps": 19066013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66936, "number_of_timesteps": 19071013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66946, "number_of_timesteps": 19076013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66956, "number_of_timesteps": 19081013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66966, "number_of_timesteps": 19086013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66976, "number_of_timesteps": 19091013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66986, "number_of_timesteps": 19096013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 66996, "number_of_timesteps": 19101013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67006, "number_of_timesteps": 19106013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67016, "number_of_timesteps": 19111013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67026, "number_of_timesteps": 19116013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67036, "number_of_timesteps": 19121013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67046, "number_of_timesteps": 19126013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67056, "number_of_timesteps": 19131013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67066, "number_of_timesteps": 19136013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67076, "number_of_timesteps": 19141013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67086, "number_of_timesteps": 19146013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67096, "number_of_timesteps": 19151013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67106, "number_of_timesteps": 19156013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67116, "number_of_timesteps": 19161013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67126, "number_of_timesteps": 19166013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67136, "number_of_timesteps": 19171013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67146, "number_of_timesteps": 19176013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67156, "number_of_timesteps": 19181013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67166, "number_of_timesteps": 19186013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67176, "number_of_timesteps": 19191013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67186, "number_of_timesteps": 19196013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67196, "number_of_timesteps": 19201013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67206, "number_of_timesteps": 19206013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67216, "number_of_timesteps": 19211013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67226, "number_of_timesteps": 19216013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67236, "number_of_timesteps": 19221013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67246, "number_of_timesteps": 19226013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67256, "number_of_timesteps": 19231013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67266, "number_of_timesteps": 19236013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67276, "number_of_timesteps": 19241013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67286, "number_of_timesteps": 19246013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67296, "number_of_timesteps": 19251013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67306, "number_of_timesteps": 19256013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67316, "number_of_timesteps": 19261013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67326, "number_of_timesteps": 19266013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67336, "number_of_timesteps": 19271013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67346, "number_of_timesteps": 19276013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67356, "number_of_timesteps": 19281013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67366, "number_of_timesteps": 19286013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67376, "number_of_timesteps": 19291013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67386, "number_of_timesteps": 19296013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67396, "number_of_timesteps": 19301013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67406, "number_of_timesteps": 19306013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67416, "number_of_timesteps": 19311013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67426, "number_of_timesteps": 19316013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67436, "number_of_timesteps": 19321013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67446, "number_of_timesteps": 19326013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67456, "number_of_timesteps": 19331013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67466, "number_of_timesteps": 19336013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67476, "number_of_timesteps": 19341013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67486, "number_of_timesteps": 19346013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67496, "number_of_timesteps": 19351013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67506, "number_of_timesteps": 19356013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67516, "number_of_timesteps": 19361013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67526, "number_of_timesteps": 19366013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67536, "number_of_timesteps": 19371013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67546, "number_of_timesteps": 19376013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67556, "number_of_timesteps": 19381013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67566, "number_of_timesteps": 19386013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67576, "number_of_timesteps": 19391013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67586, "number_of_timesteps": 19396013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67596, "number_of_timesteps": 19401013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67606, "number_of_timesteps": 19406013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67616, "number_of_timesteps": 19411013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67626, "number_of_timesteps": 19416013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67636, "number_of_timesteps": 19421013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67646, "number_of_timesteps": 19426013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67656, "number_of_timesteps": 19431013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67666, "number_of_timesteps": 19436013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67676, "number_of_timesteps": 19441013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67686, "number_of_timesteps": 19446013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67696, "number_of_timesteps": 19451013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67706, "number_of_timesteps": 19456013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67716, "number_of_timesteps": 19461013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67726, "number_of_timesteps": 19466013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67736, "number_of_timesteps": 19471013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67746, "number_of_timesteps": 19476013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67756, "number_of_timesteps": 19481013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67766, "number_of_timesteps": 19486013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67776, "number_of_timesteps": 19491013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67786, "number_of_timesteps": 19496013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67796, "number_of_timesteps": 19501013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67806, "number_of_timesteps": 19506013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67816, "number_of_timesteps": 19511013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67826, "number_of_timesteps": 19516013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67836, "number_of_timesteps": 19521013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67846, "number_of_timesteps": 19526013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67856, "number_of_timesteps": 19531013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67866, "number_of_timesteps": 19536013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67876, "number_of_timesteps": 19541013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67886, "number_of_timesteps": 19546013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67896, "number_of_timesteps": 19551013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67906, "number_of_timesteps": 19556013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67916, "number_of_timesteps": 19561013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67926, "number_of_timesteps": 19566013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67936, "number_of_timesteps": 19571013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67946, "number_of_timesteps": 19576013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67956, "number_of_timesteps": 19581013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67966, "number_of_timesteps": 19586013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67976, "number_of_timesteps": 19591013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67986, "number_of_timesteps": 19596013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 67996, "number_of_timesteps": 19601013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68006, "number_of_timesteps": 19606013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68016, "number_of_timesteps": 19611013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68026, "number_of_timesteps": 19616013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68036, "number_of_timesteps": 19621013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68046, "number_of_timesteps": 19626013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68056, "number_of_timesteps": 19631013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68066, "number_of_timesteps": 19636013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68076, "number_of_timesteps": 19641013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68086, "number_of_timesteps": 19646013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68096, "number_of_timesteps": 19651013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68106, "number_of_timesteps": 19656013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68116, "number_of_timesteps": 19661013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68126, "number_of_timesteps": 19666013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68136, "number_of_timesteps": 19671013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68146, "number_of_timesteps": 19676013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68156, "number_of_timesteps": 19681013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68166, "number_of_timesteps": 19686013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68176, "number_of_timesteps": 19691013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68186, "number_of_timesteps": 19696013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68196, "number_of_timesteps": 19701013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68206, "number_of_timesteps": 19706013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68216, "number_of_timesteps": 19711013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68226, "number_of_timesteps": 19716013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68236, "number_of_timesteps": 19721013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68246, "number_of_timesteps": 19726013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68256, "number_of_timesteps": 19731013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68266, "number_of_timesteps": 19736013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68276, "number_of_timesteps": 19741013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68286, "number_of_timesteps": 19746013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68296, "number_of_timesteps": 19751013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68306, "number_of_timesteps": 19756013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68316, "number_of_timesteps": 19761013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68326, "number_of_timesteps": 19766013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68336, "number_of_timesteps": 19771013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68346, "number_of_timesteps": 19776013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68356, "number_of_timesteps": 19781013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68366, "number_of_timesteps": 19786013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68376, "number_of_timesteps": 19791013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68386, "number_of_timesteps": 19796013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68396, "number_of_timesteps": 19801013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68406, "number_of_timesteps": 19806013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68416, "number_of_timesteps": 19811013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68426, "number_of_timesteps": 19816013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68436, "number_of_timesteps": 19821013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68446, "number_of_timesteps": 19826013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68456, "number_of_timesteps": 19831013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68466, "number_of_timesteps": 19836013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68476, "number_of_timesteps": 19841013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68486, "number_of_timesteps": 19846013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68496, "number_of_timesteps": 19851013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68506, "number_of_timesteps": 19856013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68516, "number_of_timesteps": 19861013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68526, "number_of_timesteps": 19866013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68536, "number_of_timesteps": 19871013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68546, "number_of_timesteps": 19876013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68556, "number_of_timesteps": 19881013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68566, "number_of_timesteps": 19886013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68576, "number_of_timesteps": 19891013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68586, "number_of_timesteps": 19896013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68596, "number_of_timesteps": 19901013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68606, "number_of_timesteps": 19906013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68616, "number_of_timesteps": 19911013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68626, "number_of_timesteps": 19916013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68636, "number_of_timesteps": 19921013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68646, "number_of_timesteps": 19926013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68656, "number_of_timesteps": 19931013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68666, "number_of_timesteps": 19936013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68676, "number_of_timesteps": 19941013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68686, "number_of_timesteps": 19946013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68696, "number_of_timesteps": 19951013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68706, "number_of_timesteps": 19956013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68716, "number_of_timesteps": 19961013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68726, "number_of_timesteps": 19966013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68736, "number_of_timesteps": 19971013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68746, "number_of_timesteps": 19976013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68756, "number_of_timesteps": 19981013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68766, "number_of_timesteps": 19986013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68776, "number_of_timesteps": 19991013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68786, "number_of_timesteps": 19996013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68796, "number_of_timesteps": 20001013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68806, "number_of_timesteps": 20006013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68816, "number_of_timesteps": 20011013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68826, "number_of_timesteps": 20016013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68836, "number_of_timesteps": 20021013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68846, "number_of_timesteps": 20026013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68856, "number_of_timesteps": 20031013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68866, "number_of_timesteps": 20036013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68876, "number_of_timesteps": 20041013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68886, "number_of_timesteps": 20046013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68896, "number_of_timesteps": 20051013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68906, "number_of_timesteps": 20056013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68916, "number_of_timesteps": 20061013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68926, "number_of_timesteps": 20066013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68936, "number_of_timesteps": 20071013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68946, "number_of_timesteps": 20076013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68956, "number_of_timesteps": 20081013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68966, "number_of_timesteps": 20086013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68976, "number_of_timesteps": 20091013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68986, "number_of_timesteps": 20096013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 68996, "number_of_timesteps": 20101013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69006, "number_of_timesteps": 20106013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69016, "number_of_timesteps": 20111013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69026, "number_of_timesteps": 20116013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69036, "number_of_timesteps": 20121013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69046, "number_of_timesteps": 20126013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69056, "number_of_timesteps": 20131013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69066, "number_of_timesteps": 20136013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69076, "number_of_timesteps": 20141013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69086, "number_of_timesteps": 20146013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69096, "number_of_timesteps": 20151013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69106, "number_of_timesteps": 20156013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69116, "number_of_timesteps": 20161013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69126, "number_of_timesteps": 20166013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69136, "number_of_timesteps": 20171013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69146, "number_of_timesteps": 20176013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69156, "number_of_timesteps": 20181013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69166, "number_of_timesteps": 20186013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69176, "number_of_timesteps": 20191013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69186, "number_of_timesteps": 20196013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69196, "number_of_timesteps": 20201013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69206, "number_of_timesteps": 20206013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69216, "number_of_timesteps": 20211013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69226, "number_of_timesteps": 20216013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69236, "number_of_timesteps": 20221013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69246, "number_of_timesteps": 20226013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69256, "number_of_timesteps": 20231013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69266, "number_of_timesteps": 20236013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69276, "number_of_timesteps": 20241013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69286, "number_of_timesteps": 20246013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69296, "number_of_timesteps": 20251013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69306, "number_of_timesteps": 20256013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69316, "number_of_timesteps": 20261013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69326, "number_of_timesteps": 20266013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69336, "number_of_timesteps": 20271013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69346, "number_of_timesteps": 20276013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69356, "number_of_timesteps": 20281013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69366, "number_of_timesteps": 20286013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69376, "number_of_timesteps": 20291013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69386, "number_of_timesteps": 20296013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69396, "number_of_timesteps": 20301013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69406, "number_of_timesteps": 20306013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69416, "number_of_timesteps": 20311013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69426, "number_of_timesteps": 20316013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69436, "number_of_timesteps": 20321013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69446, "number_of_timesteps": 20326013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69456, "number_of_timesteps": 20331013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69466, "number_of_timesteps": 20336013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69476, "number_of_timesteps": 20341013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69486, "number_of_timesteps": 20346013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69496, "number_of_timesteps": 20351013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69506, "number_of_timesteps": 20356013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69516, "number_of_timesteps": 20361013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69526, "number_of_timesteps": 20366013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69536, "number_of_timesteps": 20371013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69546, "number_of_timesteps": 20376013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69556, "number_of_timesteps": 20381013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69566, "number_of_timesteps": 20386013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69576, "number_of_timesteps": 20391013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69586, "number_of_timesteps": 20396013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69596, "number_of_timesteps": 20401013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69606, "number_of_timesteps": 20406013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69616, "number_of_timesteps": 20411013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69626, "number_of_timesteps": 20416013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69636, "number_of_timesteps": 20421013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69646, "number_of_timesteps": 20426013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69656, "number_of_timesteps": 20431013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69666, "number_of_timesteps": 20436013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69676, "number_of_timesteps": 20441013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69686, "number_of_timesteps": 20446013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69696, "number_of_timesteps": 20451013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69706, "number_of_timesteps": 20456013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69716, "number_of_timesteps": 20461013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69726, "number_of_timesteps": 20466013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69736, "number_of_timesteps": 20471013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69746, "number_of_timesteps": 20476013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69756, "number_of_timesteps": 20481013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69766, "number_of_timesteps": 20486013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69776, "number_of_timesteps": 20491013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69786, "number_of_timesteps": 20496013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69796, "number_of_timesteps": 20501013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69806, "number_of_timesteps": 20506013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69816, "number_of_timesteps": 20511013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69826, "number_of_timesteps": 20516013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69836, "number_of_timesteps": 20521013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69846, "number_of_timesteps": 20526013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69856, "number_of_timesteps": 20531013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69866, "number_of_timesteps": 20536013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69876, "number_of_timesteps": 20541013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69886, "number_of_timesteps": 20546013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69896, "number_of_timesteps": 20551013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69906, "number_of_timesteps": 20556013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69916, "number_of_timesteps": 20561013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69926, "number_of_timesteps": 20566013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69936, "number_of_timesteps": 20571013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69946, "number_of_timesteps": 20576013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69956, "number_of_timesteps": 20581013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69966, "number_of_timesteps": 20586013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69976, "number_of_timesteps": 20591013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69986, "number_of_timesteps": 20596013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 69996, "number_of_timesteps": 20601013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70006, "number_of_timesteps": 20606013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70016, "number_of_timesteps": 20611013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70026, "number_of_timesteps": 20616013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70036, "number_of_timesteps": 20621013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70046, "number_of_timesteps": 20626013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70056, "number_of_timesteps": 20631013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70066, "number_of_timesteps": 20636013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70076, "number_of_timesteps": 20641013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70086, "number_of_timesteps": 20646013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70096, "number_of_timesteps": 20651013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70106, "number_of_timesteps": 20656013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70116, "number_of_timesteps": 20661013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70126, "number_of_timesteps": 20666013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70136, "number_of_timesteps": 20671013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70146, "number_of_timesteps": 20676013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70156, "number_of_timesteps": 20681013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70166, "number_of_timesteps": 20686013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70176, "number_of_timesteps": 20691013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70186, "number_of_timesteps": 20696013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70196, "number_of_timesteps": 20701013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70206, "number_of_timesteps": 20706013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70216, "number_of_timesteps": 20711013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70226, "number_of_timesteps": 20716013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70236, "number_of_timesteps": 20721013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70246, "number_of_timesteps": 20726013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70256, "number_of_timesteps": 20731013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70266, "number_of_timesteps": 20736013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70276, "number_of_timesteps": 20741013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70286, "number_of_timesteps": 20746013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70296, "number_of_timesteps": 20751013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70306, "number_of_timesteps": 20756013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70316, "number_of_timesteps": 20761013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70326, "number_of_timesteps": 20766013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70336, "number_of_timesteps": 20771013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70346, "number_of_timesteps": 20776013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70356, "number_of_timesteps": 20781013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70366, "number_of_timesteps": 20786013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70376, "number_of_timesteps": 20791013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70386, "number_of_timesteps": 20796013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70396, "number_of_timesteps": 20801013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70406, "number_of_timesteps": 20806013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70416, "number_of_timesteps": 20811013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70426, "number_of_timesteps": 20816013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70436, "number_of_timesteps": 20821013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70446, "number_of_timesteps": 20826013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70456, "number_of_timesteps": 20831013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70466, "number_of_timesteps": 20836013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70476, "number_of_timesteps": 20841013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70486, "number_of_timesteps": 20846013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70496, "number_of_timesteps": 20851013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70506, "number_of_timesteps": 20856013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70516, "number_of_timesteps": 20861013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70526, "number_of_timesteps": 20866013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70536, "number_of_timesteps": 20871013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70546, "number_of_timesteps": 20876013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70556, "number_of_timesteps": 20881013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70566, "number_of_timesteps": 20886013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70576, "number_of_timesteps": 20891013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70586, "number_of_timesteps": 20896013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70596, "number_of_timesteps": 20901013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70606, "number_of_timesteps": 20906013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70616, "number_of_timesteps": 20911013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70626, "number_of_timesteps": 20916013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70636, "number_of_timesteps": 20921013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70646, "number_of_timesteps": 20926013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70656, "number_of_timesteps": 20931013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70666, "number_of_timesteps": 20936013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70676, "number_of_timesteps": 20941013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70686, "number_of_timesteps": 20946013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70696, "number_of_timesteps": 20951013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70706, "number_of_timesteps": 20956013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70716, "number_of_timesteps": 20961013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70726, "number_of_timesteps": 20966013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70736, "number_of_timesteps": 20971013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70746, "number_of_timesteps": 20976013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70756, "number_of_timesteps": 20981013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70766, "number_of_timesteps": 20986013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70776, "number_of_timesteps": 20991013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70786, "number_of_timesteps": 20996013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70796, "number_of_timesteps": 21001013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70806, "number_of_timesteps": 21006013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70816, "number_of_timesteps": 21011013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70826, "number_of_timesteps": 21016013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70836, "number_of_timesteps": 21021013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70846, "number_of_timesteps": 21026013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70856, "number_of_timesteps": 21031013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70866, "number_of_timesteps": 21036013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70876, "number_of_timesteps": 21041013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70886, "number_of_timesteps": 21046013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70896, "number_of_timesteps": 21051013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70906, "number_of_timesteps": 21056013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70916, "number_of_timesteps": 21061013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70926, "number_of_timesteps": 21066013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70936, "number_of_timesteps": 21071013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70946, "number_of_timesteps": 21076013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70956, "number_of_timesteps": 21081013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70966, "number_of_timesteps": 21086013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70976, "number_of_timesteps": 21091013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70986, "number_of_timesteps": 21096013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 70996, "number_of_timesteps": 21101013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71006, "number_of_timesteps": 21106013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71016, "number_of_timesteps": 21111013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71026, "number_of_timesteps": 21116013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71036, "number_of_timesteps": 21121013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71046, "number_of_timesteps": 21126013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71056, "number_of_timesteps": 21131013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71066, "number_of_timesteps": 21136013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71076, "number_of_timesteps": 21141013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71086, "number_of_timesteps": 21146013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71096, "number_of_timesteps": 21151013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71106, "number_of_timesteps": 21156013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71116, "number_of_timesteps": 21161013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71126, "number_of_timesteps": 21166013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71136, "number_of_timesteps": 21171013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71146, "number_of_timesteps": 21176013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71156, "number_of_timesteps": 21181013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71166, "number_of_timesteps": 21186013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71176, "number_of_timesteps": 21191013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71186, "number_of_timesteps": 21196013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71196, "number_of_timesteps": 21201013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71206, "number_of_timesteps": 21206013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71216, "number_of_timesteps": 21211013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71226, "number_of_timesteps": 21216013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71236, "number_of_timesteps": 21221013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71246, "number_of_timesteps": 21226013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71256, "number_of_timesteps": 21231013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71266, "number_of_timesteps": 21236013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71276, "number_of_timesteps": 21241013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71286, "number_of_timesteps": 21246013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71296, "number_of_timesteps": 21251013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71306, "number_of_timesteps": 21256013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71316, "number_of_timesteps": 21261013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71326, "number_of_timesteps": 21266013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71336, "number_of_timesteps": 21271013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71346, "number_of_timesteps": 21276013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71356, "number_of_timesteps": 21281013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71366, "number_of_timesteps": 21286013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71376, "number_of_timesteps": 21291013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71386, "number_of_timesteps": 21296013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71396, "number_of_timesteps": 21301013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71406, "number_of_timesteps": 21306013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71416, "number_of_timesteps": 21311013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71426, "number_of_timesteps": 21316013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71436, "number_of_timesteps": 21321013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71446, "number_of_timesteps": 21326013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71456, "number_of_timesteps": 21331013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71466, "number_of_timesteps": 21336013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71476, "number_of_timesteps": 21341013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71486, "number_of_timesteps": 21346013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71496, "number_of_timesteps": 21351013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71506, "number_of_timesteps": 21356013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71516, "number_of_timesteps": 21361013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71526, "number_of_timesteps": 21366013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71536, "number_of_timesteps": 21371013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71546, "number_of_timesteps": 21376013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71556, "number_of_timesteps": 21381013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71566, "number_of_timesteps": 21386013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71576, "number_of_timesteps": 21391013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71586, "number_of_timesteps": 21396013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71596, "number_of_timesteps": 21401013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71606, "number_of_timesteps": 21406013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71616, "number_of_timesteps": 21411013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71626, "number_of_timesteps": 21416013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71636, "number_of_timesteps": 21421013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71646, "number_of_timesteps": 21426013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71656, "number_of_timesteps": 21431013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71666, "number_of_timesteps": 21436013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71676, "number_of_timesteps": 21441013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71686, "number_of_timesteps": 21446013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71696, "number_of_timesteps": 21451013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71706, "number_of_timesteps": 21456013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71716, "number_of_timesteps": 21461013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71726, "number_of_timesteps": 21466013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71736, "number_of_timesteps": 21471013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71746, "number_of_timesteps": 21476013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71756, "number_of_timesteps": 21481013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71766, "number_of_timesteps": 21486013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71776, "number_of_timesteps": 21491013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71786, "number_of_timesteps": 21496013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71796, "number_of_timesteps": 21501013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71806, "number_of_timesteps": 21506013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71816, "number_of_timesteps": 21511013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71826, "number_of_timesteps": 21516013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71836, "number_of_timesteps": 21521013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71846, "number_of_timesteps": 21526013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71856, "number_of_timesteps": 21531013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71866, "number_of_timesteps": 21536013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71876, "number_of_timesteps": 21541013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71886, "number_of_timesteps": 21546013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71896, "number_of_timesteps": 21551013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71906, "number_of_timesteps": 21556013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71916, "number_of_timesteps": 21561013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71926, "number_of_timesteps": 21566013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71936, "number_of_timesteps": 21571013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71946, "number_of_timesteps": 21576013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71956, "number_of_timesteps": 21581013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71966, "number_of_timesteps": 21586013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71976, "number_of_timesteps": 21591013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71986, "number_of_timesteps": 21596013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 71996, "number_of_timesteps": 21601013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72006, "number_of_timesteps": 21606013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72016, "number_of_timesteps": 21611013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72026, "number_of_timesteps": 21616013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72036, "number_of_timesteps": 21621013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72046, "number_of_timesteps": 21626013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72056, "number_of_timesteps": 21631013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72066, "number_of_timesteps": 21636013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72076, "number_of_timesteps": 21641013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72086, "number_of_timesteps": 21646013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72096, "number_of_timesteps": 21651013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72106, "number_of_timesteps": 21656013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72116, "number_of_timesteps": 21661013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72126, "number_of_timesteps": 21666013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72136, "number_of_timesteps": 21671013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72146, "number_of_timesteps": 21676013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72156, "number_of_timesteps": 21681013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72166, "number_of_timesteps": 21686013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72176, "number_of_timesteps": 21691013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72186, "number_of_timesteps": 21696013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72196, "number_of_timesteps": 21701013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72206, "number_of_timesteps": 21706013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72216, "number_of_timesteps": 21711013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72226, "number_of_timesteps": 21716013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72236, "number_of_timesteps": 21721013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72246, "number_of_timesteps": 21726013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72256, "number_of_timesteps": 21731013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72266, "number_of_timesteps": 21736013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72276, "number_of_timesteps": 21741013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72286, "number_of_timesteps": 21746013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72296, "number_of_timesteps": 21751013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72306, "number_of_timesteps": 21756013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72316, "number_of_timesteps": 21761013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72326, "number_of_timesteps": 21766013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72336, "number_of_timesteps": 21771013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72346, "number_of_timesteps": 21776013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72356, "number_of_timesteps": 21781013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72366, "number_of_timesteps": 21786013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72376, "number_of_timesteps": 21791013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72386, "number_of_timesteps": 21796013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72396, "number_of_timesteps": 21801013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72406, "number_of_timesteps": 21806013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72416, "number_of_timesteps": 21811013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72426, "number_of_timesteps": 21816013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72436, "number_of_timesteps": 21821013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72446, "number_of_timesteps": 21826013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72456, "number_of_timesteps": 21831013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72466, "number_of_timesteps": 21836013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72476, "number_of_timesteps": 21841013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72486, "number_of_timesteps": 21846013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72496, "number_of_timesteps": 21851013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72506, "number_of_timesteps": 21856013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72516, "number_of_timesteps": 21861013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72526, "number_of_timesteps": 21866013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72536, "number_of_timesteps": 21871013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72546, "number_of_timesteps": 21876013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72556, "number_of_timesteps": 21881013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72566, "number_of_timesteps": 21886013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72576, "number_of_timesteps": 21891013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72586, "number_of_timesteps": 21896013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72596, "number_of_timesteps": 21901013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72606, "number_of_timesteps": 21906013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72616, "number_of_timesteps": 21911013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72626, "number_of_timesteps": 21916013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72636, "number_of_timesteps": 21921013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72646, "number_of_timesteps": 21926013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72656, "number_of_timesteps": 21931013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72666, "number_of_timesteps": 21936013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72676, "number_of_timesteps": 21941013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72686, "number_of_timesteps": 21946013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72696, "number_of_timesteps": 21951013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72706, "number_of_timesteps": 21956013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72716, "number_of_timesteps": 21961013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72726, "number_of_timesteps": 21966013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72736, "number_of_timesteps": 21971013, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72746, "number_of_timesteps": 21975548, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72756, "number_of_timesteps": 21980548, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72766, "number_of_timesteps": 21984599, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72776, "number_of_timesteps": 21989599, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72786, "number_of_timesteps": 21994112, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72796, "number_of_timesteps": 21998624, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72806, "number_of_timesteps": 22003624, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72816, "number_of_timesteps": 22008624, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72826, "number_of_timesteps": 22013138, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72836, "number_of_timesteps": 22018138, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72846, "number_of_timesteps": 22022653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72856, "number_of_timesteps": 22027653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72866, "number_of_timesteps": 22032653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72876, "number_of_timesteps": 22037653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72886, "number_of_timesteps": 22042653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72896, "number_of_timesteps": 22047653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72906, "number_of_timesteps": 22052653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72916, "number_of_timesteps": 22057653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72926, "number_of_timesteps": 22062653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72936, "number_of_timesteps": 22067653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72946, "number_of_timesteps": 22072653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72956, "number_of_timesteps": 22077653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72966, "number_of_timesteps": 22082653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72976, "number_of_timesteps": 22087653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72986, "number_of_timesteps": 22092653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 72996, "number_of_timesteps": 22097653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73006, "number_of_timesteps": 22102653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73016, "number_of_timesteps": 22107653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73026, "number_of_timesteps": 22112653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73036, "number_of_timesteps": 22117653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73046, "number_of_timesteps": 22122653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73056, "number_of_timesteps": 22127653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73066, "number_of_timesteps": 22132653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73076, "number_of_timesteps": 22137653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73086, "number_of_timesteps": 22142653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73096, "number_of_timesteps": 22147653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73106, "number_of_timesteps": 22152653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73116, "number_of_timesteps": 22157653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73126, "number_of_timesteps": 22162653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73136, "number_of_timesteps": 22167653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73146, "number_of_timesteps": 22172653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73156, "number_of_timesteps": 22177653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73166, "number_of_timesteps": 22182653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73176, "number_of_timesteps": 22187653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73186, "number_of_timesteps": 22192653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73196, "number_of_timesteps": 22197653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73206, "number_of_timesteps": 22202653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73216, "number_of_timesteps": 22207653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73226, "number_of_timesteps": 22212653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73236, "number_of_timesteps": 22217653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73246, "number_of_timesteps": 22222653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73256, "number_of_timesteps": 22227653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73266, "number_of_timesteps": 22232653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73276, "number_of_timesteps": 22237653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73286, "number_of_timesteps": 22242653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73296, "number_of_timesteps": 22247653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73306, "number_of_timesteps": 22252653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73316, "number_of_timesteps": 22257653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73326, "number_of_timesteps": 22262653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73336, "number_of_timesteps": 22267653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73346, "number_of_timesteps": 22272653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73356, "number_of_timesteps": 22277653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73366, "number_of_timesteps": 22282653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73376, "number_of_timesteps": 22287653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73386, "number_of_timesteps": 22292653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73396, "number_of_timesteps": 22297653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73406, "number_of_timesteps": 22302653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73416, "number_of_timesteps": 22307653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73426, "number_of_timesteps": 22312653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73436, "number_of_timesteps": 22317653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73446, "number_of_timesteps": 22322653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73456, "number_of_timesteps": 22327653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73466, "number_of_timesteps": 22332653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73476, "number_of_timesteps": 22337653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73486, "number_of_timesteps": 22342653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73496, "number_of_timesteps": 22347653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73506, "number_of_timesteps": 22352653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73516, "number_of_timesteps": 22357653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73526, "number_of_timesteps": 22362653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73536, "number_of_timesteps": 22367653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73546, "number_of_timesteps": 22372653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73556, "number_of_timesteps": 22377653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73566, "number_of_timesteps": 22382653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73576, "number_of_timesteps": 22387653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73586, "number_of_timesteps": 22392653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73596, "number_of_timesteps": 22397653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73606, "number_of_timesteps": 22402653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73616, "number_of_timesteps": 22407653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73626, "number_of_timesteps": 22412653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73636, "number_of_timesteps": 22417653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73646, "number_of_timesteps": 22422653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73656, "number_of_timesteps": 22427653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73666, "number_of_timesteps": 22432653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73676, "number_of_timesteps": 22437653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73686, "number_of_timesteps": 22442653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73696, "number_of_timesteps": 22447653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73706, "number_of_timesteps": 22452653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73716, "number_of_timesteps": 22457653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73726, "number_of_timesteps": 22462653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73736, "number_of_timesteps": 22467653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73746, "number_of_timesteps": 22472653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73756, "number_of_timesteps": 22477653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73766, "number_of_timesteps": 22482653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73776, "number_of_timesteps": 22487653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73786, "number_of_timesteps": 22492653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73796, "number_of_timesteps": 22497653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73806, "number_of_timesteps": 22502653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73816, "number_of_timesteps": 22507653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73826, "number_of_timesteps": 22512653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73836, "number_of_timesteps": 22517653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73846, "number_of_timesteps": 22522653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73856, "number_of_timesteps": 22527653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73866, "number_of_timesteps": 22532653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73876, "number_of_timesteps": 22537653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73886, "number_of_timesteps": 22542653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73896, "number_of_timesteps": 22547653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73906, "number_of_timesteps": 22552653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73916, "number_of_timesteps": 22557653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73926, "number_of_timesteps": 22562653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73936, "number_of_timesteps": 22567653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73946, "number_of_timesteps": 22572653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73956, "number_of_timesteps": 22577653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73966, "number_of_timesteps": 22582653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73976, "number_of_timesteps": 22587653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73986, "number_of_timesteps": 22592653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 73996, "number_of_timesteps": 22597653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74006, "number_of_timesteps": 22602653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74016, "number_of_timesteps": 22607653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74026, "number_of_timesteps": 22612653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74036, "number_of_timesteps": 22617653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74046, "number_of_timesteps": 22622653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74056, "number_of_timesteps": 22627653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74066, "number_of_timesteps": 22632653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74076, "number_of_timesteps": 22637653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74086, "number_of_timesteps": 22642653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74096, "number_of_timesteps": 22647653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74106, "number_of_timesteps": 22652653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74116, "number_of_timesteps": 22657653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74126, "number_of_timesteps": 22662653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74136, "number_of_timesteps": 22667653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74146, "number_of_timesteps": 22672653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74156, "number_of_timesteps": 22677653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74166, "number_of_timesteps": 22682653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74176, "number_of_timesteps": 22687653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74186, "number_of_timesteps": 22692653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74196, "number_of_timesteps": 22697653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74206, "number_of_timesteps": 22702653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74216, "number_of_timesteps": 22707653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74226, "number_of_timesteps": 22712653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74236, "number_of_timesteps": 22717653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74246, "number_of_timesteps": 22722653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74256, "number_of_timesteps": 22727653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74266, "number_of_timesteps": 22732653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74276, "number_of_timesteps": 22737653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74286, "number_of_timesteps": 22742653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74296, "number_of_timesteps": 22747653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74306, "number_of_timesteps": 22752653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74316, "number_of_timesteps": 22757653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74326, "number_of_timesteps": 22762653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74336, "number_of_timesteps": 22767653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74346, "number_of_timesteps": 22772653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74356, "number_of_timesteps": 22777653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74366, "number_of_timesteps": 22782653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74376, "number_of_timesteps": 22787653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74386, "number_of_timesteps": 22792653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74396, "number_of_timesteps": 22797653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74406, "number_of_timesteps": 22802653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74416, "number_of_timesteps": 22807653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74426, "number_of_timesteps": 22812653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74436, "number_of_timesteps": 22817653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74446, "number_of_timesteps": 22822653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74456, "number_of_timesteps": 22827653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74466, "number_of_timesteps": 22832653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74476, "number_of_timesteps": 22837653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74486, "number_of_timesteps": 22842653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74496, "number_of_timesteps": 22847653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74506, "number_of_timesteps": 22852653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74516, "number_of_timesteps": 22857653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74526, "number_of_timesteps": 22862653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74536, "number_of_timesteps": 22867653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74546, "number_of_timesteps": 22872653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74556, "number_of_timesteps": 22877653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74566, "number_of_timesteps": 22882653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74576, "number_of_timesteps": 22887653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74586, "number_of_timesteps": 22892653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74596, "number_of_timesteps": 22897653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74606, "number_of_timesteps": 22902653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74616, "number_of_timesteps": 22907653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74626, "number_of_timesteps": 22912653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74636, "number_of_timesteps": 22917653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74646, "number_of_timesteps": 22922653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74656, "number_of_timesteps": 22927653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74666, "number_of_timesteps": 22932653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74676, "number_of_timesteps": 22937653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74686, "number_of_timesteps": 22942653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74696, "number_of_timesteps": 22947653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74706, "number_of_timesteps": 22952653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74716, "number_of_timesteps": 22957653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74726, "number_of_timesteps": 22962653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74736, "number_of_timesteps": 22967653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74746, "number_of_timesteps": 22972653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74756, "number_of_timesteps": 22977653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74766, "number_of_timesteps": 22982653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74776, "number_of_timesteps": 22987653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74786, "number_of_timesteps": 22992653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74796, "number_of_timesteps": 22997653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74806, "number_of_timesteps": 23002653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74816, "number_of_timesteps": 23007653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74826, "number_of_timesteps": 23012653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74836, "number_of_timesteps": 23017653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74846, "number_of_timesteps": 23022653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74856, "number_of_timesteps": 23027653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74866, "number_of_timesteps": 23032653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74876, "number_of_timesteps": 23037653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74886, "number_of_timesteps": 23042653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74896, "number_of_timesteps": 23047653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74906, "number_of_timesteps": 23052653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74916, "number_of_timesteps": 23057653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74926, "number_of_timesteps": 23062653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74936, "number_of_timesteps": 23067653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74946, "number_of_timesteps": 23072653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74956, "number_of_timesteps": 23077653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74966, "number_of_timesteps": 23082653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74976, "number_of_timesteps": 23087653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74986, "number_of_timesteps": 23092653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 74996, "number_of_timesteps": 23097653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75006, "number_of_timesteps": 23102653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75016, "number_of_timesteps": 23107653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75026, "number_of_timesteps": 23112653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75036, "number_of_timesteps": 23117653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75046, "number_of_timesteps": 23122653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75056, "number_of_timesteps": 23127653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75066, "number_of_timesteps": 23132653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75076, "number_of_timesteps": 23137653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75086, "number_of_timesteps": 23142653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75096, "number_of_timesteps": 23147653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75106, "number_of_timesteps": 23152653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75116, "number_of_timesteps": 23157653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75126, "number_of_timesteps": 23162653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75136, "number_of_timesteps": 23167653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75146, "number_of_timesteps": 23172653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75156, "number_of_timesteps": 23177653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75166, "number_of_timesteps": 23182653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75176, "number_of_timesteps": 23187653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75186, "number_of_timesteps": 23192653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75196, "number_of_timesteps": 23197653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75206, "number_of_timesteps": 23202653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75216, "number_of_timesteps": 23207653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75226, "number_of_timesteps": 23212653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75236, "number_of_timesteps": 23217653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75246, "number_of_timesteps": 23222653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75256, "number_of_timesteps": 23227653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75266, "number_of_timesteps": 23232653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75276, "number_of_timesteps": 23237653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75286, "number_of_timesteps": 23242653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75296, "number_of_timesteps": 23247653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75306, "number_of_timesteps": 23252653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75316, "number_of_timesteps": 23257653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75326, "number_of_timesteps": 23262653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75336, "number_of_timesteps": 23267653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75346, "number_of_timesteps": 23272653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75356, "number_of_timesteps": 23277653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75366, "number_of_timesteps": 23282653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75376, "number_of_timesteps": 23287653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75386, "number_of_timesteps": 23292653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75396, "number_of_timesteps": 23297653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75406, "number_of_timesteps": 23302653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75416, "number_of_timesteps": 23307653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75426, "number_of_timesteps": 23312653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75436, "number_of_timesteps": 23317653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75446, "number_of_timesteps": 23322653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75456, "number_of_timesteps": 23327653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75466, "number_of_timesteps": 23332653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75476, "number_of_timesteps": 23337653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75486, "number_of_timesteps": 23342653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75496, "number_of_timesteps": 23347653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75506, "number_of_timesteps": 23352653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75516, "number_of_timesteps": 23357653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75526, "number_of_timesteps": 23362653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75536, "number_of_timesteps": 23367653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75546, "number_of_timesteps": 23372653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75556, "number_of_timesteps": 23377653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75566, "number_of_timesteps": 23382653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75576, "number_of_timesteps": 23387653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75586, "number_of_timesteps": 23392653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75596, "number_of_timesteps": 23397653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75606, "number_of_timesteps": 23402653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75616, "number_of_timesteps": 23407653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75626, "number_of_timesteps": 23412653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75636, "number_of_timesteps": 23417653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75646, "number_of_timesteps": 23422653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75656, "number_of_timesteps": 23427653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75666, "number_of_timesteps": 23432653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75676, "number_of_timesteps": 23437653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75686, "number_of_timesteps": 23442653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75696, "number_of_timesteps": 23447653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75706, "number_of_timesteps": 23452653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75716, "number_of_timesteps": 23457653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75726, "number_of_timesteps": 23462653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75736, "number_of_timesteps": 23467653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75746, "number_of_timesteps": 23472653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75756, "number_of_timesteps": 23477653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75766, "number_of_timesteps": 23482653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75776, "number_of_timesteps": 23487653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75786, "number_of_timesteps": 23492653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75796, "number_of_timesteps": 23497653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75806, "number_of_timesteps": 23502653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75816, "number_of_timesteps": 23507653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75826, "number_of_timesteps": 23512653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75836, "number_of_timesteps": 23517653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75846, "number_of_timesteps": 23522653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75856, "number_of_timesteps": 23527653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75866, "number_of_timesteps": 23532653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75876, "number_of_timesteps": 23537653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75886, "number_of_timesteps": 23542653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75896, "number_of_timesteps": 23547653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75906, "number_of_timesteps": 23552653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75916, "number_of_timesteps": 23557653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75926, "number_of_timesteps": 23562653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75936, "number_of_timesteps": 23567653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75946, "number_of_timesteps": 23572653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75956, "number_of_timesteps": 23577653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75966, "number_of_timesteps": 23582653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75976, "number_of_timesteps": 23587653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75986, "number_of_timesteps": 23592653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 75996, "number_of_timesteps": 23597653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76006, "number_of_timesteps": 23602653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76016, "number_of_timesteps": 23607653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76026, "number_of_timesteps": 23612653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76036, "number_of_timesteps": 23617653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76046, "number_of_timesteps": 23622653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76056, "number_of_timesteps": 23627653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76066, "number_of_timesteps": 23632653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76076, "number_of_timesteps": 23637653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76086, "number_of_timesteps": 23642653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76096, "number_of_timesteps": 23647653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76106, "number_of_timesteps": 23652653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76116, "number_of_timesteps": 23657653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76126, "number_of_timesteps": 23662653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76136, "number_of_timesteps": 23667653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76146, "number_of_timesteps": 23672653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76156, "number_of_timesteps": 23677653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76166, "number_of_timesteps": 23682653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76176, "number_of_timesteps": 23687653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76186, "number_of_timesteps": 23692653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76196, "number_of_timesteps": 23697653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76206, "number_of_timesteps": 23702653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76216, "number_of_timesteps": 23707653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76226, "number_of_timesteps": 23712653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76236, "number_of_timesteps": 23717653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76246, "number_of_timesteps": 23722653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76256, "number_of_timesteps": 23727653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76266, "number_of_timesteps": 23732653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76276, "number_of_timesteps": 23737653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76286, "number_of_timesteps": 23742653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76296, "number_of_timesteps": 23747653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76306, "number_of_timesteps": 23752653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76316, "number_of_timesteps": 23757653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76326, "number_of_timesteps": 23762653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76336, "number_of_timesteps": 23767653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76346, "number_of_timesteps": 23772653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76356, "number_of_timesteps": 23777653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76366, "number_of_timesteps": 23782653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76376, "number_of_timesteps": 23787653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76386, "number_of_timesteps": 23792653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76396, "number_of_timesteps": 23797653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76406, "number_of_timesteps": 23802653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76416, "number_of_timesteps": 23807653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76426, "number_of_timesteps": 23812653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76436, "number_of_timesteps": 23817653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76446, "number_of_timesteps": 23822653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76456, "number_of_timesteps": 23827653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76466, "number_of_timesteps": 23832653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76476, "number_of_timesteps": 23837653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76486, "number_of_timesteps": 23842653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76496, "number_of_timesteps": 23847653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76506, "number_of_timesteps": 23852653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76516, "number_of_timesteps": 23857653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76526, "number_of_timesteps": 23862653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76536, "number_of_timesteps": 23867653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76546, "number_of_timesteps": 23872653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76556, "number_of_timesteps": 23877653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76566, "number_of_timesteps": 23882653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76576, "number_of_timesteps": 23887653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76586, "number_of_timesteps": 23892653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76596, "number_of_timesteps": 23897653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76606, "number_of_timesteps": 23902653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76616, "number_of_timesteps": 23907653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76626, "number_of_timesteps": 23912653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76636, "number_of_timesteps": 23917653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76646, "number_of_timesteps": 23922653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76656, "number_of_timesteps": 23927653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76666, "number_of_timesteps": 23932653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76676, "number_of_timesteps": 23937653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76686, "number_of_timesteps": 23942653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76696, "number_of_timesteps": 23947653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76706, "number_of_timesteps": 23952653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76716, "number_of_timesteps": 23957653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76726, "number_of_timesteps": 23962653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76736, "number_of_timesteps": 23967653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76746, "number_of_timesteps": 23972653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76756, "number_of_timesteps": 23977653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76766, "number_of_timesteps": 23982653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76776, "number_of_timesteps": 23987653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76786, "number_of_timesteps": 23992653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76796, "number_of_timesteps": 23997653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76806, "number_of_timesteps": 24002653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76816, "number_of_timesteps": 24007653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76826, "number_of_timesteps": 24012653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76836, "number_of_timesteps": 24017653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76846, "number_of_timesteps": 24022653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76856, "number_of_timesteps": 24027653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76866, "number_of_timesteps": 24032653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76876, "number_of_timesteps": 24037653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76886, "number_of_timesteps": 24042653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76896, "number_of_timesteps": 24047653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76906, "number_of_timesteps": 24052653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76916, "number_of_timesteps": 24057653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76926, "number_of_timesteps": 24062653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76936, "number_of_timesteps": 24067653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76946, "number_of_timesteps": 24072653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76956, "number_of_timesteps": 24077653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76966, "number_of_timesteps": 24082653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76976, "number_of_timesteps": 24087653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76986, "number_of_timesteps": 24092653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 76996, "number_of_timesteps": 24097653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77006, "number_of_timesteps": 24102653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77016, "number_of_timesteps": 24107653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77026, "number_of_timesteps": 24112653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77036, "number_of_timesteps": 24117653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77046, "number_of_timesteps": 24122653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77056, "number_of_timesteps": 24127653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77066, "number_of_timesteps": 24132653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77076, "number_of_timesteps": 24137653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77086, "number_of_timesteps": 24142653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77096, "number_of_timesteps": 24147653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77106, "number_of_timesteps": 24152653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77116, "number_of_timesteps": 24157653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77126, "number_of_timesteps": 24162653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77136, "number_of_timesteps": 24167653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77146, "number_of_timesteps": 24172653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77156, "number_of_timesteps": 24177653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77166, "number_of_timesteps": 24182653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77176, "number_of_timesteps": 24187653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77186, "number_of_timesteps": 24192653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77196, "number_of_timesteps": 24197653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77206, "number_of_timesteps": 24202653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77216, "number_of_timesteps": 24207653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77226, "number_of_timesteps": 24212653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77236, "number_of_timesteps": 24217653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77246, "number_of_timesteps": 24222653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77256, "number_of_timesteps": 24227653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77266, "number_of_timesteps": 24232653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77276, "number_of_timesteps": 24237653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77286, "number_of_timesteps": 24242653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77296, "number_of_timesteps": 24247653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77306, "number_of_timesteps": 24252653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77316, "number_of_timesteps": 24257653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77326, "number_of_timesteps": 24262653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77336, "number_of_timesteps": 24267653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77346, "number_of_timesteps": 24272653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77356, "number_of_timesteps": 24277653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77366, "number_of_timesteps": 24282653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77376, "number_of_timesteps": 24287653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77386, "number_of_timesteps": 24292653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77396, "number_of_timesteps": 24297653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77406, "number_of_timesteps": 24302653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77416, "number_of_timesteps": 24307653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77426, "number_of_timesteps": 24312653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77436, "number_of_timesteps": 24317653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77446, "number_of_timesteps": 24322653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77456, "number_of_timesteps": 24327653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77466, "number_of_timesteps": 24332653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77476, "number_of_timesteps": 24337653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77486, "number_of_timesteps": 24342653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77496, "number_of_timesteps": 24347653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77506, "number_of_timesteps": 24352653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77516, "number_of_timesteps": 24357653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77526, "number_of_timesteps": 24362653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77536, "number_of_timesteps": 24367653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77546, "number_of_timesteps": 24372653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77556, "number_of_timesteps": 24377653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77566, "number_of_timesteps": 24382653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77576, "number_of_timesteps": 24387653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77586, "number_of_timesteps": 24392653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77596, "number_of_timesteps": 24397653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77606, "number_of_timesteps": 24402653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77616, "number_of_timesteps": 24407653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77626, "number_of_timesteps": 24412653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77636, "number_of_timesteps": 24417653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77646, "number_of_timesteps": 24422653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77656, "number_of_timesteps": 24427653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77666, "number_of_timesteps": 24432653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77676, "number_of_timesteps": 24437653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77686, "number_of_timesteps": 24442653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77696, "number_of_timesteps": 24447653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77706, "number_of_timesteps": 24452653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77716, "number_of_timesteps": 24457653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77726, "number_of_timesteps": 24462653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77736, "number_of_timesteps": 24467653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77746, "number_of_timesteps": 24472653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77756, "number_of_timesteps": 24477653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77766, "number_of_timesteps": 24482653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77776, "number_of_timesteps": 24487653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77786, "number_of_timesteps": 24492653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77796, "number_of_timesteps": 24497653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77806, "number_of_timesteps": 24502653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77816, "number_of_timesteps": 24507653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77826, "number_of_timesteps": 24512653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77836, "number_of_timesteps": 24517653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77846, "number_of_timesteps": 24522653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77856, "number_of_timesteps": 24527653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77866, "number_of_timesteps": 24532653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77876, "number_of_timesteps": 24537653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77886, "number_of_timesteps": 24542653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77896, "number_of_timesteps": 24547653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77906, "number_of_timesteps": 24552653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77916, "number_of_timesteps": 24557653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77926, "number_of_timesteps": 24562653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77936, "number_of_timesteps": 24567653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77946, "number_of_timesteps": 24572653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77956, "number_of_timesteps": 24577653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77966, "number_of_timesteps": 24582653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77976, "number_of_timesteps": 24587653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77986, "number_of_timesteps": 24592653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 77996, "number_of_timesteps": 24597653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78006, "number_of_timesteps": 24602653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78016, "number_of_timesteps": 24607653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78026, "number_of_timesteps": 24612653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78036, "number_of_timesteps": 24617653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78046, "number_of_timesteps": 24622653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78056, "number_of_timesteps": 24627653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78066, "number_of_timesteps": 24632653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78076, "number_of_timesteps": 24637653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78086, "number_of_timesteps": 24642653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78096, "number_of_timesteps": 24647653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78106, "number_of_timesteps": 24652653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78116, "number_of_timesteps": 24657653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78126, "number_of_timesteps": 24662653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78136, "number_of_timesteps": 24667653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78146, "number_of_timesteps": 24672653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78156, "number_of_timesteps": 24677653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78166, "number_of_timesteps": 24682653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78176, "number_of_timesteps": 24687653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78186, "number_of_timesteps": 24692653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78196, "number_of_timesteps": 24697653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78206, "number_of_timesteps": 24702653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78216, "number_of_timesteps": 24707653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78226, "number_of_timesteps": 24712653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78236, "number_of_timesteps": 24717653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78246, "number_of_timesteps": 24722653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78256, "number_of_timesteps": 24727653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78266, "number_of_timesteps": 24732653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78276, "number_of_timesteps": 24737653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78286, "number_of_timesteps": 24742653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78296, "number_of_timesteps": 24747653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78306, "number_of_timesteps": 24752653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78316, "number_of_timesteps": 24757653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78326, "number_of_timesteps": 24762653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78336, "number_of_timesteps": 24767653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78346, "number_of_timesteps": 24772653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78356, "number_of_timesteps": 24777653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78366, "number_of_timesteps": 24782653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78376, "number_of_timesteps": 24787653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78386, "number_of_timesteps": 24792653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78396, "number_of_timesteps": 24797653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78406, "number_of_timesteps": 24802653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78416, "number_of_timesteps": 24807653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78426, "number_of_timesteps": 24812653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78436, "number_of_timesteps": 24817653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78446, "number_of_timesteps": 24822653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78456, "number_of_timesteps": 24827653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78466, "number_of_timesteps": 24832653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78476, "number_of_timesteps": 24837653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78486, "number_of_timesteps": 24842653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78496, "number_of_timesteps": 24847653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78506, "number_of_timesteps": 24852653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78516, "number_of_timesteps": 24857653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78526, "number_of_timesteps": 24862653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78536, "number_of_timesteps": 24867653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78546, "number_of_timesteps": 24872653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78556, "number_of_timesteps": 24877653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78566, "number_of_timesteps": 24882653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78576, "number_of_timesteps": 24887653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78586, "number_of_timesteps": 24892653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78596, "number_of_timesteps": 24897653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78606, "number_of_timesteps": 24902653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78616, "number_of_timesteps": 24907653, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78626, "number_of_timesteps": 24911679, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78636, "number_of_timesteps": 24916679, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78646, "number_of_timesteps": 24920703, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78656, "number_of_timesteps": 24925216, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78666, "number_of_timesteps": 24930216, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78676, "number_of_timesteps": 24934730, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78686, "number_of_timesteps": 24939730, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78696, "number_of_timesteps": 24944730, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78706, "number_of_timesteps": 24949730, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78716, "number_of_timesteps": 24954730, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78726, "number_of_timesteps": 24959730, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78736, "number_of_timesteps": 24964730, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78746, "number_of_timesteps": 24969243, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78756, "number_of_timesteps": 24974243, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78766, "number_of_timesteps": 24979243, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78776, "number_of_timesteps": 24984243, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78786, "number_of_timesteps": 24989243, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78796, "number_of_timesteps": 24994243, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78806, "number_of_timesteps": 24998756, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78816, "number_of_timesteps": 25003756, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78826, "number_of_timesteps": 25008268, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78836, "number_of_timesteps": 25013268, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78846, "number_of_timesteps": 25017781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78856, "number_of_timesteps": 25022781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78866, "number_of_timesteps": 25027781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78876, "number_of_timesteps": 25032781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78886, "number_of_timesteps": 25037781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78896, "number_of_timesteps": 25042781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78906, "number_of_timesteps": 25047781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78916, "number_of_timesteps": 25052781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78926, "number_of_timesteps": 25057781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78936, "number_of_timesteps": 25062781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78946, "number_of_timesteps": 25067781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78956, "number_of_timesteps": 25072781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78966, "number_of_timesteps": 25077781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78976, "number_of_timesteps": 25082781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78986, "number_of_timesteps": 25087781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 78996, "number_of_timesteps": 25092781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79006, "number_of_timesteps": 25097781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79016, "number_of_timesteps": 25102781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79026, "number_of_timesteps": 25107781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79036, "number_of_timesteps": 25112781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79046, "number_of_timesteps": 25117781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79056, "number_of_timesteps": 25122781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79066, "number_of_timesteps": 25127781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79076, "number_of_timesteps": 25132781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79086, "number_of_timesteps": 25137781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79096, "number_of_timesteps": 25142781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79106, "number_of_timesteps": 25147781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79116, "number_of_timesteps": 25152781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79126, "number_of_timesteps": 25157781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79136, "number_of_timesteps": 25162781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79146, "number_of_timesteps": 25167781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79156, "number_of_timesteps": 25172781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79166, "number_of_timesteps": 25177781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79176, "number_of_timesteps": 25182781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79186, "number_of_timesteps": 25187781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79196, "number_of_timesteps": 25192781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79206, "number_of_timesteps": 25197781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79216, "number_of_timesteps": 25202781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79226, "number_of_timesteps": 25207781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79236, "number_of_timesteps": 25212781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79246, "number_of_timesteps": 25217781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79256, "number_of_timesteps": 25222781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79266, "number_of_timesteps": 25227781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79276, "number_of_timesteps": 25232781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79286, "number_of_timesteps": 25237781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79296, "number_of_timesteps": 25242781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79306, "number_of_timesteps": 25247781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79316, "number_of_timesteps": 25252781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79326, "number_of_timesteps": 25257781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79336, "number_of_timesteps": 25262781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79346, "number_of_timesteps": 25267781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79356, "number_of_timesteps": 25272781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79366, "number_of_timesteps": 25277781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79376, "number_of_timesteps": 25282781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79386, "number_of_timesteps": 25287781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79396, "number_of_timesteps": 25292781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79406, "number_of_timesteps": 25297781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79416, "number_of_timesteps": 25302781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79426, "number_of_timesteps": 25307781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79436, "number_of_timesteps": 25312781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79446, "number_of_timesteps": 25317781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79456, "number_of_timesteps": 25322781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79466, "number_of_timesteps": 25327781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79476, "number_of_timesteps": 25332781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79486, "number_of_timesteps": 25337781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79496, "number_of_timesteps": 25342781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79506, "number_of_timesteps": 25347781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79516, "number_of_timesteps": 25352781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79526, "number_of_timesteps": 25357781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79536, "number_of_timesteps": 25362781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79546, "number_of_timesteps": 25367781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79556, "number_of_timesteps": 25372781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79566, "number_of_timesteps": 25377781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79576, "number_of_timesteps": 25382781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79586, "number_of_timesteps": 25387781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79596, "number_of_timesteps": 25392781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79606, "number_of_timesteps": 25397781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79616, "number_of_timesteps": 25402781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79626, "number_of_timesteps": 25407781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79636, "number_of_timesteps": 25412781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79646, "number_of_timesteps": 25417781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79656, "number_of_timesteps": 25422781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79666, "number_of_timesteps": 25427781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79676, "number_of_timesteps": 25432781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79686, "number_of_timesteps": 25437781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79696, "number_of_timesteps": 25442781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79706, "number_of_timesteps": 25447781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79716, "number_of_timesteps": 25452781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79726, "number_of_timesteps": 25457781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79736, "number_of_timesteps": 25462781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79746, "number_of_timesteps": 25467781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79756, "number_of_timesteps": 25472781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79766, "number_of_timesteps": 25477781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79776, "number_of_timesteps": 25482781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79786, "number_of_timesteps": 25487781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79796, "number_of_timesteps": 25492781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79806, "number_of_timesteps": 25497781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79816, "number_of_timesteps": 25502781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79826, "number_of_timesteps": 25507781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79836, "number_of_timesteps": 25512781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79846, "number_of_timesteps": 25517781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79856, "number_of_timesteps": 25522781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79866, "number_of_timesteps": 25527781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79876, "number_of_timesteps": 25532781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79886, "number_of_timesteps": 25537781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79896, "number_of_timesteps": 25542781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79906, "number_of_timesteps": 25547781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79916, "number_of_timesteps": 25552781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79926, "number_of_timesteps": 25557781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79936, "number_of_timesteps": 25562781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79946, "number_of_timesteps": 25567781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79956, "number_of_timesteps": 25572781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79966, "number_of_timesteps": 25577781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79976, "number_of_timesteps": 25582781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79986, "number_of_timesteps": 25587781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 79996, "number_of_timesteps": 25592781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80006, "number_of_timesteps": 25597781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80016, "number_of_timesteps": 25602781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80026, "number_of_timesteps": 25607781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80036, "number_of_timesteps": 25612781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80046, "number_of_timesteps": 25617781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80056, "number_of_timesteps": 25622781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80066, "number_of_timesteps": 25627781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80076, "number_of_timesteps": 25632781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80086, "number_of_timesteps": 25637781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80096, "number_of_timesteps": 25642781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80106, "number_of_timesteps": 25647781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80116, "number_of_timesteps": 25652781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80126, "number_of_timesteps": 25657781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80136, "number_of_timesteps": 25662781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80146, "number_of_timesteps": 25667781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80156, "number_of_timesteps": 25672781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80166, "number_of_timesteps": 25677781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80176, "number_of_timesteps": 25682781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80186, "number_of_timesteps": 25687781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80196, "number_of_timesteps": 25692781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80206, "number_of_timesteps": 25697781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80216, "number_of_timesteps": 25702781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80226, "number_of_timesteps": 25707781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80236, "number_of_timesteps": 25712781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80246, "number_of_timesteps": 25717781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80256, "number_of_timesteps": 25722781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80266, "number_of_timesteps": 25727781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80276, "number_of_timesteps": 25732781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80286, "number_of_timesteps": 25737781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80296, "number_of_timesteps": 25742781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80306, "number_of_timesteps": 25747781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80316, "number_of_timesteps": 25752781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80326, "number_of_timesteps": 25757781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80336, "number_of_timesteps": 25762781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80346, "number_of_timesteps": 25767781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80356, "number_of_timesteps": 25772781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80366, "number_of_timesteps": 25777781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80376, "number_of_timesteps": 25782781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80386, "number_of_timesteps": 25787781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80396, "number_of_timesteps": 25792781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80406, "number_of_timesteps": 25797781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80416, "number_of_timesteps": 25802781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80426, "number_of_timesteps": 25807781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80436, "number_of_timesteps": 25812781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80446, "number_of_timesteps": 25817781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80456, "number_of_timesteps": 25822781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80466, "number_of_timesteps": 25827781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80476, "number_of_timesteps": 25832781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80486, "number_of_timesteps": 25837781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80496, "number_of_timesteps": 25842781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80506, "number_of_timesteps": 25847781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80516, "number_of_timesteps": 25852781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80526, "number_of_timesteps": 25857781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80536, "number_of_timesteps": 25862781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80546, "number_of_timesteps": 25867781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80556, "number_of_timesteps": 25872781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80566, "number_of_timesteps": 25877781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80576, "number_of_timesteps": 25882781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80586, "number_of_timesteps": 25887781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80596, "number_of_timesteps": 25892781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80606, "number_of_timesteps": 25897781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80616, "number_of_timesteps": 25902781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80626, "number_of_timesteps": 25907781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80636, "number_of_timesteps": 25912781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80646, "number_of_timesteps": 25917781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80656, "number_of_timesteps": 25922781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80666, "number_of_timesteps": 25927781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80676, "number_of_timesteps": 25932781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80686, "number_of_timesteps": 25937781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80696, "number_of_timesteps": 25942781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80706, "number_of_timesteps": 25947781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80716, "number_of_timesteps": 25952781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80726, "number_of_timesteps": 25957781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80736, "number_of_timesteps": 25962781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80746, "number_of_timesteps": 25967781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80756, "number_of_timesteps": 25972781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80766, "number_of_timesteps": 25977781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80776, "number_of_timesteps": 25982781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80786, "number_of_timesteps": 25987781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80796, "number_of_timesteps": 25992781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80806, "number_of_timesteps": 25997781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80816, "number_of_timesteps": 26002781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80826, "number_of_timesteps": 26007781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80836, "number_of_timesteps": 26012781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80846, "number_of_timesteps": 26017781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80856, "number_of_timesteps": 26022781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80866, "number_of_timesteps": 26027781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80876, "number_of_timesteps": 26032781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80886, "number_of_timesteps": 26037781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80896, "number_of_timesteps": 26042781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80906, "number_of_timesteps": 26047781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80916, "number_of_timesteps": 26052781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80926, "number_of_timesteps": 26057781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80936, "number_of_timesteps": 26062781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80946, "number_of_timesteps": 26067781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80956, "number_of_timesteps": 26072781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80966, "number_of_timesteps": 26077781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80976, "number_of_timesteps": 26082781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80986, "number_of_timesteps": 26087781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 80996, "number_of_timesteps": 26092781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81006, "number_of_timesteps": 26097781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81016, "number_of_timesteps": 26102781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81026, "number_of_timesteps": 26107781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81036, "number_of_timesteps": 26112781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81046, "number_of_timesteps": 26117781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81056, "number_of_timesteps": 26122781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81066, "number_of_timesteps": 26127781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81076, "number_of_timesteps": 26132781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81086, "number_of_timesteps": 26137781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81096, "number_of_timesteps": 26142781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81106, "number_of_timesteps": 26147781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81116, "number_of_timesteps": 26152781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81126, "number_of_timesteps": 26157781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81136, "number_of_timesteps": 26162781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81146, "number_of_timesteps": 26167781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81156, "number_of_timesteps": 26172781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81166, "number_of_timesteps": 26177781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81176, "number_of_timesteps": 26182781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81186, "number_of_timesteps": 26187781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81196, "number_of_timesteps": 26192781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81206, "number_of_timesteps": 26197781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81216, "number_of_timesteps": 26202781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81226, "number_of_timesteps": 26207781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81236, "number_of_timesteps": 26212781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81246, "number_of_timesteps": 26217781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81256, "number_of_timesteps": 26222781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81266, "number_of_timesteps": 26227781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81276, "number_of_timesteps": 26232781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81286, "number_of_timesteps": 26237781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81296, "number_of_timesteps": 26242781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81306, "number_of_timesteps": 26247781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81316, "number_of_timesteps": 26252781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81326, "number_of_timesteps": 26257781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81336, "number_of_timesteps": 26262781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81346, "number_of_timesteps": 26267781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81356, "number_of_timesteps": 26272781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81366, "number_of_timesteps": 26277781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81376, "number_of_timesteps": 26282781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81386, "number_of_timesteps": 26287781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81396, "number_of_timesteps": 26292781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81406, "number_of_timesteps": 26297781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81416, "number_of_timesteps": 26302781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81426, "number_of_timesteps": 26307781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81436, "number_of_timesteps": 26312781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81446, "number_of_timesteps": 26317781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81456, "number_of_timesteps": 26322781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81466, "number_of_timesteps": 26327781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81476, "number_of_timesteps": 26332781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81486, "number_of_timesteps": 26337781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81496, "number_of_timesteps": 26342781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81506, "number_of_timesteps": 26347781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81516, "number_of_timesteps": 26352781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81526, "number_of_timesteps": 26357781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81536, "number_of_timesteps": 26362781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81546, "number_of_timesteps": 26367781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81556, "number_of_timesteps": 26372781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81566, "number_of_timesteps": 26377781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81576, "number_of_timesteps": 26382781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81586, "number_of_timesteps": 26387781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81596, "number_of_timesteps": 26392781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81606, "number_of_timesteps": 26397781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81616, "number_of_timesteps": 26402781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81626, "number_of_timesteps": 26407781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81636, "number_of_timesteps": 26412781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81646, "number_of_timesteps": 26417781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81656, "number_of_timesteps": 26422781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81666, "number_of_timesteps": 26427781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81676, "number_of_timesteps": 26432781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81686, "number_of_timesteps": 26437781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81696, "number_of_timesteps": 26442781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81706, "number_of_timesteps": 26447781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81716, "number_of_timesteps": 26452781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81726, "number_of_timesteps": 26457781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81736, "number_of_timesteps": 26462781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81746, "number_of_timesteps": 26467781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81756, "number_of_timesteps": 26472781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81766, "number_of_timesteps": 26477781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81776, "number_of_timesteps": 26482781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81786, "number_of_timesteps": 26487781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81796, "number_of_timesteps": 26492781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81806, "number_of_timesteps": 26497781, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81816, "number_of_timesteps": 26502668, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81826, "number_of_timesteps": 26507668, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81836, "number_of_timesteps": 26512215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81846, "number_of_timesteps": 26517215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81856, "number_of_timesteps": 26522215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81866, "number_of_timesteps": 26527215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81876, "number_of_timesteps": 26532215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81886, "number_of_timesteps": 26537215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81896, "number_of_timesteps": 26542215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81906, "number_of_timesteps": 26547215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81916, "number_of_timesteps": 26552215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81926, "number_of_timesteps": 26557215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81936, "number_of_timesteps": 26562215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81946, "number_of_timesteps": 26567215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81956, "number_of_timesteps": 26572215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81966, "number_of_timesteps": 26576791, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81976, "number_of_timesteps": 26581791, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81986, "number_of_timesteps": 26586791, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 81996, "number_of_timesteps": 26591791, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82006, "number_of_timesteps": 26596669, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82016, "number_of_timesteps": 26601669, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82026, "number_of_timesteps": 26606669, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82036, "number_of_timesteps": 26611258, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82046, "number_of_timesteps": 26616258, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82056, "number_of_timesteps": 26621258, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82066, "number_of_timesteps": 26625887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82076, "number_of_timesteps": 26630887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82086, "number_of_timesteps": 26635887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82096, "number_of_timesteps": 26640887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82106, "number_of_timesteps": 26645887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82116, "number_of_timesteps": 26650887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82126, "number_of_timesteps": 26655887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82136, "number_of_timesteps": 26660887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82146, "number_of_timesteps": 26665887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82156, "number_of_timesteps": 26670887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82166, "number_of_timesteps": 26675887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82176, "number_of_timesteps": 26680887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82186, "number_of_timesteps": 26685887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82196, "number_of_timesteps": 26690887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82206, "number_of_timesteps": 26695887, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82216, "number_of_timesteps": 26700518, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82226, "number_of_timesteps": 26705518, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82236, "number_of_timesteps": 26710518, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82246, "number_of_timesteps": 26715062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82256, "number_of_timesteps": 26719602, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82266, "number_of_timesteps": 26724191, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82276, "number_of_timesteps": 26729191, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82286, "number_of_timesteps": 26734191, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82296, "number_of_timesteps": 26739191, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82306, "number_of_timesteps": 26744191, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82316, "number_of_timesteps": 26749062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82326, "number_of_timesteps": 26754062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82336, "number_of_timesteps": 26759062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82346, "number_of_timesteps": 26764062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82356, "number_of_timesteps": 26769062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82366, "number_of_timesteps": 26774062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82376, "number_of_timesteps": 26779062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82386, "number_of_timesteps": 26784062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82396, "number_of_timesteps": 26789062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82406, "number_of_timesteps": 26794062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82416, "number_of_timesteps": 26799062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82426, "number_of_timesteps": 26804062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82436, "number_of_timesteps": 26809062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82446, "number_of_timesteps": 26814062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82456, "number_of_timesteps": 26819062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82466, "number_of_timesteps": 26824062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82476, "number_of_timesteps": 26829062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82486, "number_of_timesteps": 26834062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82496, "number_of_timesteps": 26839062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82506, "number_of_timesteps": 26844062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82516, "number_of_timesteps": 26849062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82526, "number_of_timesteps": 26854062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82536, "number_of_timesteps": 26859062, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82546, "number_of_timesteps": 26864012, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82556, "number_of_timesteps": 26869012, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82566, "number_of_timesteps": 26874012, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82576, "number_of_timesteps": 26879012, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82586, "number_of_timesteps": 26884012, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82596, "number_of_timesteps": 26888593, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82606, "number_of_timesteps": 26893140, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82616, "number_of_timesteps": 26897705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82626, "number_of_timesteps": 26902705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82636, "number_of_timesteps": 26907705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82646, "number_of_timesteps": 26912705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82656, "number_of_timesteps": 26917705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82666, "number_of_timesteps": 26922705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82676, "number_of_timesteps": 26927705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82686, "number_of_timesteps": 26932705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82696, "number_of_timesteps": 26937705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82706, "number_of_timesteps": 26942705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82716, "number_of_timesteps": 26947705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82726, "number_of_timesteps": 26952705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82736, "number_of_timesteps": 26957705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82746, "number_of_timesteps": 26962705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82756, "number_of_timesteps": 26967705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82766, "number_of_timesteps": 26972705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82776, "number_of_timesteps": 26977705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82786, "number_of_timesteps": 26982705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82796, "number_of_timesteps": 26987705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82806, "number_of_timesteps": 26992705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82816, "number_of_timesteps": 26997705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82826, "number_of_timesteps": 27002705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82836, "number_of_timesteps": 27007705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82846, "number_of_timesteps": 27012705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82856, "number_of_timesteps": 27017705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82866, "number_of_timesteps": 27022705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82876, "number_of_timesteps": 27027705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82886, "number_of_timesteps": 27032705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82896, "number_of_timesteps": 27037705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82906, "number_of_timesteps": 27042705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82916, "number_of_timesteps": 27047705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82926, "number_of_timesteps": 27052705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82936, "number_of_timesteps": 27057705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82946, "number_of_timesteps": 27062705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82956, "number_of_timesteps": 27067705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82966, "number_of_timesteps": 27072705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82976, "number_of_timesteps": 27077705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82986, "number_of_timesteps": 27082705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 82996, "number_of_timesteps": 27087705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83006, "number_of_timesteps": 27092705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83016, "number_of_timesteps": 27097705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83026, "number_of_timesteps": 27102705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83036, "number_of_timesteps": 27107705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83046, "number_of_timesteps": 27112705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83056, "number_of_timesteps": 27117705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83066, "number_of_timesteps": 27122705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83076, "number_of_timesteps": 27127705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83086, "number_of_timesteps": 27132705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83096, "number_of_timesteps": 27137705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83106, "number_of_timesteps": 27142705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83116, "number_of_timesteps": 27147705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83126, "number_of_timesteps": 27152705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83136, "number_of_timesteps": 27157705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83146, "number_of_timesteps": 27162705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83156, "number_of_timesteps": 27167705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83166, "number_of_timesteps": 27172705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83176, "number_of_timesteps": 27177705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83186, "number_of_timesteps": 27182705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83196, "number_of_timesteps": 27187705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83206, "number_of_timesteps": 27192705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83216, "number_of_timesteps": 27197705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83226, "number_of_timesteps": 27202705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83236, "number_of_timesteps": 27207705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83246, "number_of_timesteps": 27212705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83256, "number_of_timesteps": 27217705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83266, "number_of_timesteps": 27222705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83276, "number_of_timesteps": 27227705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83286, "number_of_timesteps": 27232705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83296, "number_of_timesteps": 27237705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83306, "number_of_timesteps": 27242705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83316, "number_of_timesteps": 27247705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83326, "number_of_timesteps": 27252705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83336, "number_of_timesteps": 27257705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83346, "number_of_timesteps": 27262705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83356, "number_of_timesteps": 27267705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83366, "number_of_timesteps": 27272705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83376, "number_of_timesteps": 27277705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83386, "number_of_timesteps": 27282705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83396, "number_of_timesteps": 27287705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83406, "number_of_timesteps": 27292705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83416, "number_of_timesteps": 27297705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83426, "number_of_timesteps": 27302705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83436, "number_of_timesteps": 27307705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83446, "number_of_timesteps": 27312705, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83456, "number_of_timesteps": 27317252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83466, "number_of_timesteps": 27322252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83476, "number_of_timesteps": 27327252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83486, "number_of_timesteps": 27332252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83496, "number_of_timesteps": 27337252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83506, "number_of_timesteps": 27342252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83516, "number_of_timesteps": 27347252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83526, "number_of_timesteps": 27352252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83536, "number_of_timesteps": 27357252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83546, "number_of_timesteps": 27362252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83556, "number_of_timesteps": 27367252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83566, "number_of_timesteps": 27372252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83576, "number_of_timesteps": 27377252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83586, "number_of_timesteps": 27382252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83596, "number_of_timesteps": 27387252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83606, "number_of_timesteps": 27392252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83616, "number_of_timesteps": 27397252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83626, "number_of_timesteps": 27402252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83636, "number_of_timesteps": 27407252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83646, "number_of_timesteps": 27412252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83656, "number_of_timesteps": 27417252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83666, "number_of_timesteps": 27422252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83676, "number_of_timesteps": 27427252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83686, "number_of_timesteps": 27432252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83696, "number_of_timesteps": 27437252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83706, "number_of_timesteps": 27442252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83716, "number_of_timesteps": 27447252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83726, "number_of_timesteps": 27452252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83736, "number_of_timesteps": 27457252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83746, "number_of_timesteps": 27462252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83756, "number_of_timesteps": 27467252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83766, "number_of_timesteps": 27472252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83776, "number_of_timesteps": 27477252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83786, "number_of_timesteps": 27482252, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83796, "number_of_timesteps": 27486782, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83806, "number_of_timesteps": 27491782, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83816, "number_of_timesteps": 27496420, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83826, "number_of_timesteps": 27501420, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83836, "number_of_timesteps": 27506420, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83846, "number_of_timesteps": 27511420, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83856, "number_of_timesteps": 27516420, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83866, "number_of_timesteps": 27521420, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83876, "number_of_timesteps": 27526420, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83886, "number_of_timesteps": 27531420, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83896, "number_of_timesteps": 27536217, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83906, "number_of_timesteps": 27541217, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83916, "number_of_timesteps": 27546217, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83926, "number_of_timesteps": 27551217, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83936, "number_of_timesteps": 27555523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83946, "number_of_timesteps": 27560523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83956, "number_of_timesteps": 27565523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83966, "number_of_timesteps": 27570523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83976, "number_of_timesteps": 27575523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83986, "number_of_timesteps": 27580523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 83996, "number_of_timesteps": 27585523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84006, "number_of_timesteps": 27590523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84016, "number_of_timesteps": 27595523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84026, "number_of_timesteps": 27600523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84036, "number_of_timesteps": 27605523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84046, "number_of_timesteps": 27610523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84056, "number_of_timesteps": 27615523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84066, "number_of_timesteps": 27620523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84076, "number_of_timesteps": 27625523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84086, "number_of_timesteps": 27630523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84096, "number_of_timesteps": 27635523, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84106, "number_of_timesteps": 27640070, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84116, "number_of_timesteps": 27645070, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84126, "number_of_timesteps": 27649927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84136, "number_of_timesteps": 27654927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84146, "number_of_timesteps": 27659927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84156, "number_of_timesteps": 27664927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84166, "number_of_timesteps": 27669927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84176, "number_of_timesteps": 27674927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84186, "number_of_timesteps": 27679927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84196, "number_of_timesteps": 27684927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84206, "number_of_timesteps": 27689927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84216, "number_of_timesteps": 27694927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84226, "number_of_timesteps": 27699927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84236, "number_of_timesteps": 27704927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84246, "number_of_timesteps": 27709927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84256, "number_of_timesteps": 27714927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84266, "number_of_timesteps": 27719927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84276, "number_of_timesteps": 27724927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84286, "number_of_timesteps": 27729927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84296, "number_of_timesteps": 27734927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84306, "number_of_timesteps": 27739927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84316, "number_of_timesteps": 27744927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84326, "number_of_timesteps": 27749927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84336, "number_of_timesteps": 27754927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84346, "number_of_timesteps": 27759927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84356, "number_of_timesteps": 27764927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84366, "number_of_timesteps": 27769927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84376, "number_of_timesteps": 27774927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84386, "number_of_timesteps": 27779927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84396, "number_of_timesteps": 27784927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84406, "number_of_timesteps": 27789927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84416, "number_of_timesteps": 27794927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84426, "number_of_timesteps": 27799927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84436, "number_of_timesteps": 27804927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84446, "number_of_timesteps": 27809927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84456, "number_of_timesteps": 27814927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84466, "number_of_timesteps": 27819927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84476, "number_of_timesteps": 27824927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84486, "number_of_timesteps": 27829927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84496, "number_of_timesteps": 27834927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84506, "number_of_timesteps": 27839927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84516, "number_of_timesteps": 27844927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84526, "number_of_timesteps": 27849927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84536, "number_of_timesteps": 27854927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84546, "number_of_timesteps": 27859927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84556, "number_of_timesteps": 27864927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84566, "number_of_timesteps": 27869927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84576, "number_of_timesteps": 27874927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84586, "number_of_timesteps": 27879927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84596, "number_of_timesteps": 27884927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84606, "number_of_timesteps": 27889927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84616, "number_of_timesteps": 27894927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84626, "number_of_timesteps": 27899927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84636, "number_of_timesteps": 27904927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84646, "number_of_timesteps": 27909927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84656, "number_of_timesteps": 27914927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84666, "number_of_timesteps": 27919927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84676, "number_of_timesteps": 27924927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84686, "number_of_timesteps": 27929927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84696, "number_of_timesteps": 27934927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84706, "number_of_timesteps": 27939927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84716, "number_of_timesteps": 27944927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84726, "number_of_timesteps": 27949927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84736, "number_of_timesteps": 27954927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84746, "number_of_timesteps": 27959927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84756, "number_of_timesteps": 27964927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84766, "number_of_timesteps": 27969927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84776, "number_of_timesteps": 27974927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84786, "number_of_timesteps": 27979927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84796, "number_of_timesteps": 27984927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84806, "number_of_timesteps": 27989927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84816, "number_of_timesteps": 27994927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84826, "number_of_timesteps": 27999927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84836, "number_of_timesteps": 28004927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84846, "number_of_timesteps": 28009927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84856, "number_of_timesteps": 28014927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84866, "number_of_timesteps": 28019927, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84876, "number_of_timesteps": 28024440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84886, "number_of_timesteps": 28029440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84896, "number_of_timesteps": 28034440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84906, "number_of_timesteps": 28039440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84916, "number_of_timesteps": 28044440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84926, "number_of_timesteps": 28049440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84936, "number_of_timesteps": 28054440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84946, "number_of_timesteps": 28059440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84956, "number_of_timesteps": 28064440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84966, "number_of_timesteps": 28069440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84976, "number_of_timesteps": 28074440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84986, "number_of_timesteps": 28079440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 84996, "number_of_timesteps": 28084440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85006, "number_of_timesteps": 28089440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85016, "number_of_timesteps": 28094440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85026, "number_of_timesteps": 28099440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85036, "number_of_timesteps": 28104440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85046, "number_of_timesteps": 28109440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85056, "number_of_timesteps": 28114440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85066, "number_of_timesteps": 28119440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85076, "number_of_timesteps": 28124440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85086, "number_of_timesteps": 28129440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85096, "number_of_timesteps": 28134440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85106, "number_of_timesteps": 28139440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85116, "number_of_timesteps": 28144440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85126, "number_of_timesteps": 28149440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85136, "number_of_timesteps": 28154440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85146, "number_of_timesteps": 28159440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85156, "number_of_timesteps": 28164440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85166, "number_of_timesteps": 28169440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85176, "number_of_timesteps": 28174440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85186, "number_of_timesteps": 28179440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85196, "number_of_timesteps": 28184440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85206, "number_of_timesteps": 28189440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85216, "number_of_timesteps": 28194440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85226, "number_of_timesteps": 28199440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85236, "number_of_timesteps": 28204440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85246, "number_of_timesteps": 28209440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85256, "number_of_timesteps": 28214440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85266, "number_of_timesteps": 28219440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85276, "number_of_timesteps": 28224440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85286, "number_of_timesteps": 28229440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85296, "number_of_timesteps": 28234440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85306, "number_of_timesteps": 28239440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85316, "number_of_timesteps": 28244440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85326, "number_of_timesteps": 28249440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85336, "number_of_timesteps": 28254440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85346, "number_of_timesteps": 28259440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85356, "number_of_timesteps": 28264440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85366, "number_of_timesteps": 28269440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85376, "number_of_timesteps": 28274440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85386, "number_of_timesteps": 28279440, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85396, "number_of_timesteps": 28283956, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85406, "number_of_timesteps": 28288956, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85416, "number_of_timesteps": 28293492, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85426, "number_of_timesteps": 28298492, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85436, "number_of_timesteps": 28301053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85446, "number_of_timesteps": 28306053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85456, "number_of_timesteps": 28311053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85466, "number_of_timesteps": 28316053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85476, "number_of_timesteps": 28321053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85486, "number_of_timesteps": 28326053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85496, "number_of_timesteps": 28331053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85506, "number_of_timesteps": 28336053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85516, "number_of_timesteps": 28341053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85526, "number_of_timesteps": 28346053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85536, "number_of_timesteps": 28351053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85546, "number_of_timesteps": 28356053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85556, "number_of_timesteps": 28361053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85566, "number_of_timesteps": 28366053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85576, "number_of_timesteps": 28371053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85586, "number_of_timesteps": 28376053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85596, "number_of_timesteps": 28381053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85606, "number_of_timesteps": 28386053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85616, "number_of_timesteps": 28391053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85626, "number_of_timesteps": 28396053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85636, "number_of_timesteps": 28401053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85646, "number_of_timesteps": 28406053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85656, "number_of_timesteps": 28411053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85666, "number_of_timesteps": 28416053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85676, "number_of_timesteps": 28421053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85686, "number_of_timesteps": 28426053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85696, "number_of_timesteps": 28431053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85706, "number_of_timesteps": 28436053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85716, "number_of_timesteps": 28441053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85726, "number_of_timesteps": 28446053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85736, "number_of_timesteps": 28451053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85746, "number_of_timesteps": 28456053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85756, "number_of_timesteps": 28461053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85766, "number_of_timesteps": 28466053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85776, "number_of_timesteps": 28471053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85786, "number_of_timesteps": 28476053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85796, "number_of_timesteps": 28481053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85806, "number_of_timesteps": 28486053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85816, "number_of_timesteps": 28491053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85826, "number_of_timesteps": 28496053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85836, "number_of_timesteps": 28501053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85846, "number_of_timesteps": 28506053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85856, "number_of_timesteps": 28511053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85866, "number_of_timesteps": 28516053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85876, "number_of_timesteps": 28521053, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85886, "number_of_timesteps": 28525643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85896, "number_of_timesteps": 28530643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85906, "number_of_timesteps": 28535643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85916, "number_of_timesteps": 28540643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85926, "number_of_timesteps": 28545643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85936, "number_of_timesteps": 28550643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85946, "number_of_timesteps": 28555643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85956, "number_of_timesteps": 28560643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85966, "number_of_timesteps": 28565643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85976, "number_of_timesteps": 28570643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85986, "number_of_timesteps": 28575643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 85996, "number_of_timesteps": 28580643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86006, "number_of_timesteps": 28585569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86016, "number_of_timesteps": 28590569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86026, "number_of_timesteps": 28595569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86036, "number_of_timesteps": 28600569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86046, "number_of_timesteps": 28605569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86056, "number_of_timesteps": 28610569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86066, "number_of_timesteps": 28615569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86076, "number_of_timesteps": 28620569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86086, "number_of_timesteps": 28625569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86096, "number_of_timesteps": 28630569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86106, "number_of_timesteps": 28635569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86116, "number_of_timesteps": 28640569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86126, "number_of_timesteps": 28645569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86136, "number_of_timesteps": 28650569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86146, "number_of_timesteps": 28655569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86156, "number_of_timesteps": 28660569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86166, "number_of_timesteps": 28665569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86176, "number_of_timesteps": 28670569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86186, "number_of_timesteps": 28675569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86196, "number_of_timesteps": 28680569, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86206, "number_of_timesteps": 28685119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86216, "number_of_timesteps": 28690119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86226, "number_of_timesteps": 28695119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86236, "number_of_timesteps": 28700119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86246, "number_of_timesteps": 28705119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86256, "number_of_timesteps": 28710119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86266, "number_of_timesteps": 28715119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86276, "number_of_timesteps": 28720119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86286, "number_of_timesteps": 28725119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86296, "number_of_timesteps": 28730119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86306, "number_of_timesteps": 28735119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86316, "number_of_timesteps": 28740119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86326, "number_of_timesteps": 28745119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86336, "number_of_timesteps": 28750119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86346, "number_of_timesteps": 28755119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86356, "number_of_timesteps": 28760119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86366, "number_of_timesteps": 28765119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86376, "number_of_timesteps": 28770119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86386, "number_of_timesteps": 28775119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86396, "number_of_timesteps": 28780119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86406, "number_of_timesteps": 28785119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86416, "number_of_timesteps": 28790119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86426, "number_of_timesteps": 28795119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86436, "number_of_timesteps": 28800119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86446, "number_of_timesteps": 28805119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86456, "number_of_timesteps": 28810119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86466, "number_of_timesteps": 28815119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86476, "number_of_timesteps": 28820119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86486, "number_of_timesteps": 28825119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86496, "number_of_timesteps": 28830119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86506, "number_of_timesteps": 28835119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86516, "number_of_timesteps": 28840119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86526, "number_of_timesteps": 28845119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86536, "number_of_timesteps": 28850119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86546, "number_of_timesteps": 28855119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86556, "number_of_timesteps": 28860119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86566, "number_of_timesteps": 28865119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86576, "number_of_timesteps": 28870119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86586, "number_of_timesteps": 28875119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86596, "number_of_timesteps": 28880119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86606, "number_of_timesteps": 28885119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86616, "number_of_timesteps": 28890119, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86626, "number_of_timesteps": 28894855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86636, "number_of_timesteps": 28899855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86646, "number_of_timesteps": 28904855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86656, "number_of_timesteps": 28909855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86666, "number_of_timesteps": 28914855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86676, "number_of_timesteps": 28919855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86686, "number_of_timesteps": 28924855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86696, "number_of_timesteps": 28929855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86706, "number_of_timesteps": 28934855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86716, "number_of_timesteps": 28939855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86726, "number_of_timesteps": 28944855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86736, "number_of_timesteps": 28949855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86746, "number_of_timesteps": 28954855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86756, "number_of_timesteps": 28959855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86766, "number_of_timesteps": 28964855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86776, "number_of_timesteps": 28969855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86786, "number_of_timesteps": 28974855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86796, "number_of_timesteps": 28979855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86806, "number_of_timesteps": 28984855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86816, "number_of_timesteps": 28989855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86826, "number_of_timesteps": 28994855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86836, "number_of_timesteps": 28999855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86846, "number_of_timesteps": 29004855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86856, "number_of_timesteps": 29009855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86866, "number_of_timesteps": 29014855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86876, "number_of_timesteps": 29019855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86886, "number_of_timesteps": 29024855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86896, "number_of_timesteps": 29029855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86906, "number_of_timesteps": 29034855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86916, "number_of_timesteps": 29039855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86926, "number_of_timesteps": 29044855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86936, "number_of_timesteps": 29049855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86946, "number_of_timesteps": 29054855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86956, "number_of_timesteps": 29059855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86966, "number_of_timesteps": 29064855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86976, "number_of_timesteps": 29069855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86986, "number_of_timesteps": 29074855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 86996, "number_of_timesteps": 29079855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87006, "number_of_timesteps": 29084855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87016, "number_of_timesteps": 29089855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87026, "number_of_timesteps": 29094855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87036, "number_of_timesteps": 29099855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87046, "number_of_timesteps": 29104855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87056, "number_of_timesteps": 29109855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87066, "number_of_timesteps": 29114855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87076, "number_of_timesteps": 29119855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87086, "number_of_timesteps": 29124855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87096, "number_of_timesteps": 29129855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87106, "number_of_timesteps": 29134855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87116, "number_of_timesteps": 29139855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87126, "number_of_timesteps": 29144855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87136, "number_of_timesteps": 29149855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87146, "number_of_timesteps": 29154855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87156, "number_of_timesteps": 29159855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87166, "number_of_timesteps": 29164855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87176, "number_of_timesteps": 29169855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87186, "number_of_timesteps": 29174855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87196, "number_of_timesteps": 29179855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87206, "number_of_timesteps": 29184855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87216, "number_of_timesteps": 29189855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87226, "number_of_timesteps": 29194855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87236, "number_of_timesteps": 29199855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87246, "number_of_timesteps": 29204855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87256, "number_of_timesteps": 29209855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87266, "number_of_timesteps": 29214855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87276, "number_of_timesteps": 29219855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87286, "number_of_timesteps": 29224855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87296, "number_of_timesteps": 29229855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87306, "number_of_timesteps": 29234855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87316, "number_of_timesteps": 29239855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87326, "number_of_timesteps": 29244855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87336, "number_of_timesteps": 29249855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87346, "number_of_timesteps": 29254855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87356, "number_of_timesteps": 29259855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87366, "number_of_timesteps": 29264855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87376, "number_of_timesteps": 29269855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87386, "number_of_timesteps": 29274855, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87396, "number_of_timesteps": 29279454, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87406, "number_of_timesteps": 29283882, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87416, "number_of_timesteps": 29288646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87426, "number_of_timesteps": 29293646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87436, "number_of_timesteps": 29298646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87446, "number_of_timesteps": 29303646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87456, "number_of_timesteps": 29308646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87466, "number_of_timesteps": 29313646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87476, "number_of_timesteps": 29318646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87486, "number_of_timesteps": 29323646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87496, "number_of_timesteps": 29328646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87506, "number_of_timesteps": 29333646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87516, "number_of_timesteps": 29338646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87526, "number_of_timesteps": 29343646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87536, "number_of_timesteps": 29348646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87546, "number_of_timesteps": 29353646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87556, "number_of_timesteps": 29358646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87566, "number_of_timesteps": 29363646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87576, "number_of_timesteps": 29368646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87586, "number_of_timesteps": 29373646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87596, "number_of_timesteps": 29378646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87606, "number_of_timesteps": 29383646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87616, "number_of_timesteps": 29388646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87626, "number_of_timesteps": 29393646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87636, "number_of_timesteps": 29398646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87646, "number_of_timesteps": 29403646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87656, "number_of_timesteps": 29408646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87666, "number_of_timesteps": 29413646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87676, "number_of_timesteps": 29418464, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87686, "number_of_timesteps": 29423464, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87696, "number_of_timesteps": 29428464, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87706, "number_of_timesteps": 29433464, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87716, "number_of_timesteps": 29438403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87726, "number_of_timesteps": 29443403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87736, "number_of_timesteps": 29448403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87746, "number_of_timesteps": 29453403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87756, "number_of_timesteps": 29458403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87766, "number_of_timesteps": 29463403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87776, "number_of_timesteps": 29468403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87786, "number_of_timesteps": 29473403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87796, "number_of_timesteps": 29478403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87806, "number_of_timesteps": 29483403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87816, "number_of_timesteps": 29487919, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87826, "number_of_timesteps": 29492746, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87836, "number_of_timesteps": 29497746, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87846, "number_of_timesteps": 29502308, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87856, "number_of_timesteps": 29507308, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87866, "number_of_timesteps": 29512308, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87876, "number_of_timesteps": 29517308, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87886, "number_of_timesteps": 29521875, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87896, "number_of_timesteps": 29526875, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87906, "number_of_timesteps": 29531875, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87916, "number_of_timesteps": 29536875, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87926, "number_of_timesteps": 29541875, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87936, "number_of_timesteps": 29546875, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87946, "number_of_timesteps": 29551875, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87956, "number_of_timesteps": 29556875, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87966, "number_of_timesteps": 29561875, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87976, "number_of_timesteps": 29566875, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87986, "number_of_timesteps": 29571875, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 87996, "number_of_timesteps": 29576451, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88006, "number_of_timesteps": 29581451, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88016, "number_of_timesteps": 29586451, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88026, "number_of_timesteps": 29591451, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88036, "number_of_timesteps": 29595823, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88046, "number_of_timesteps": 29600644, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88056, "number_of_timesteps": 29605644, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88066, "number_of_timesteps": 29610644, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88076, "number_of_timesteps": 29615178, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88086, "number_of_timesteps": 29620178, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88096, "number_of_timesteps": 29625178, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88106, "number_of_timesteps": 29629724, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88116, "number_of_timesteps": 29634724, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88126, "number_of_timesteps": 29639170, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88136, "number_of_timesteps": 29644170, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88146, "number_of_timesteps": 29649170, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88156, "number_of_timesteps": 29653901, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88166, "number_of_timesteps": 29658901, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88176, "number_of_timesteps": 29663901, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88186, "number_of_timesteps": 29668901, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88196, "number_of_timesteps": 29673901, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88206, "number_of_timesteps": 29678901, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88216, "number_of_timesteps": 29683901, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88226, "number_of_timesteps": 29688901, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88236, "number_of_timesteps": 29693607, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88246, "number_of_timesteps": 29698607, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88256, "number_of_timesteps": 29703607, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88266, "number_of_timesteps": 29708607, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88276, "number_of_timesteps": 29713198, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88286, "number_of_timesteps": 29718198, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88296, "number_of_timesteps": 29723198, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88306, "number_of_timesteps": 29728135, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88316, "number_of_timesteps": 29733135, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88326, "number_of_timesteps": 29738135, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88336, "number_of_timesteps": 29743135, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88346, "number_of_timesteps": 29747669, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88356, "number_of_timesteps": 29752235, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88366, "number_of_timesteps": 29756764, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88376, "number_of_timesteps": 29761293, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88386, "number_of_timesteps": 29766293, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88396, "number_of_timesteps": 29771293, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88406, "number_of_timesteps": 29776293, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88416, "number_of_timesteps": 29781293, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88426, "number_of_timesteps": 29786293, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88436, "number_of_timesteps": 29791293, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88446, "number_of_timesteps": 29796293, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88456, "number_of_timesteps": 29801293, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88466, "number_of_timesteps": 29806293, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88476, "number_of_timesteps": 29810869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88486, "number_of_timesteps": 29815869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88496, "number_of_timesteps": 29820869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88506, "number_of_timesteps": 29825869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88516, "number_of_timesteps": 29830869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88526, "number_of_timesteps": 29835869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88536, "number_of_timesteps": 29840869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88546, "number_of_timesteps": 29845869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88556, "number_of_timesteps": 29850869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88566, "number_of_timesteps": 29855869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88576, "number_of_timesteps": 29860869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88586, "number_of_timesteps": 29865869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88596, "number_of_timesteps": 29870869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88606, "number_of_timesteps": 29875869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88616, "number_of_timesteps": 29880869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88626, "number_of_timesteps": 29885869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88636, "number_of_timesteps": 29890869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88646, "number_of_timesteps": 29895869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88656, "number_of_timesteps": 29900869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88666, "number_of_timesteps": 29905869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88676, "number_of_timesteps": 29910869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88686, "number_of_timesteps": 29915869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88696, "number_of_timesteps": 29920869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88706, "number_of_timesteps": 29925869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88716, "number_of_timesteps": 29930869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88726, "number_of_timesteps": 29935869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88736, "number_of_timesteps": 29940869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88746, "number_of_timesteps": 29945869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88756, "number_of_timesteps": 29950869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88766, "number_of_timesteps": 29955869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88776, "number_of_timesteps": 29960869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88786, "number_of_timesteps": 29965869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88796, "number_of_timesteps": 29970869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88806, "number_of_timesteps": 29975869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88816, "number_of_timesteps": 29980869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88826, "number_of_timesteps": 29985869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88836, "number_of_timesteps": 29990869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88846, "number_of_timesteps": 29995869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88856, "number_of_timesteps": 30000869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88866, "number_of_timesteps": 30005869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88876, "number_of_timesteps": 30010869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88886, "number_of_timesteps": 30015869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88896, "number_of_timesteps": 30020869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88906, "number_of_timesteps": 30025869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88916, "number_of_timesteps": 30030869, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88926, "number_of_timesteps": 30035398, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88936, "number_of_timesteps": 30040398, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88946, "number_of_timesteps": 30044612, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88956, "number_of_timesteps": 30049612, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88966, "number_of_timesteps": 30054234, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88976, "number_of_timesteps": 30059153, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88986, "number_of_timesteps": 30063456, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 88996, "number_of_timesteps": 30067578, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89007, "number_of_timesteps": 30072478, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89017, "number_of_timesteps": 30077478, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89027, "number_of_timesteps": 30082478, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89037, "number_of_timesteps": 30087478, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89047, "number_of_timesteps": 30092478, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89057, "number_of_timesteps": 30097478, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89068, "number_of_timesteps": 30102677, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89078, "number_of_timesteps": 30107677, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89088, "number_of_timesteps": 30112677, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89098, "number_of_timesteps": 30117677, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89108, "number_of_timesteps": 30122677, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89118, "number_of_timesteps": 30127677, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89128, "number_of_timesteps": 30132677, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89138, "number_of_timesteps": 30137677, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89148, "number_of_timesteps": 30142677, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89159, "number_of_timesteps": 30147739, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89169, "number_of_timesteps": 30152739, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89179, "number_of_timesteps": 30157739, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89189, "number_of_timesteps": 30162344, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89199, "number_of_timesteps": 30167344, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89209, "number_of_timesteps": 30172344, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89219, "number_of_timesteps": 30177344, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89229, "number_of_timesteps": 30182344, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89239, "number_of_timesteps": 30186854, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89249, "number_of_timesteps": 30191854, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89259, "number_of_timesteps": 30196368, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89269, "number_of_timesteps": 30201368, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89279, "number_of_timesteps": 30206368, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89289, "number_of_timesteps": 30211131, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89299, "number_of_timesteps": 30216065, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89309, "number_of_timesteps": 30219719, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89319, "number_of_timesteps": 30224627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89329, "number_of_timesteps": 30229627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89339, "number_of_timesteps": 30234627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89349, "number_of_timesteps": 30239627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89359, "number_of_timesteps": 30244627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89369, "number_of_timesteps": 30249627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89379, "number_of_timesteps": 30254627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89389, "number_of_timesteps": 30259627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89399, "number_of_timesteps": 30264627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89409, "number_of_timesteps": 30269627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89419, "number_of_timesteps": 30274627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89429, "number_of_timesteps": 30279627, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89439, "number_of_timesteps": 30284575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89449, "number_of_timesteps": 30289575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89459, "number_of_timesteps": 30294575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89469, "number_of_timesteps": 30299575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89479, "number_of_timesteps": 30304109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89489, "number_of_timesteps": 30309109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89499, "number_of_timesteps": 30314109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89509, "number_of_timesteps": 30319109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89519, "number_of_timesteps": 30324109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89529, "number_of_timesteps": 30329109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89539, "number_of_timesteps": 30334109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89549, "number_of_timesteps": 30339109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89559, "number_of_timesteps": 30344109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89569, "number_of_timesteps": 30349109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89579, "number_of_timesteps": 30354109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89589, "number_of_timesteps": 30359109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89599, "number_of_timesteps": 30364109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89609, "number_of_timesteps": 30369109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89619, "number_of_timesteps": 30374109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89629, "number_of_timesteps": 30379109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89639, "number_of_timesteps": 30384109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89649, "number_of_timesteps": 30389109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89659, "number_of_timesteps": 30394109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89669, "number_of_timesteps": 30399109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89679, "number_of_timesteps": 30404109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89689, "number_of_timesteps": 30409109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89699, "number_of_timesteps": 30414109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89709, "number_of_timesteps": 30419109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89719, "number_of_timesteps": 30424109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89729, "number_of_timesteps": 30429109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89739, "number_of_timesteps": 30434109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89749, "number_of_timesteps": 30439109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89759, "number_of_timesteps": 30444109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89769, "number_of_timesteps": 30449109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89779, "number_of_timesteps": 30454109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89789, "number_of_timesteps": 30459109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89799, "number_of_timesteps": 30464109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89809, "number_of_timesteps": 30469109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89819, "number_of_timesteps": 30474109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89829, "number_of_timesteps": 30479109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89839, "number_of_timesteps": 30484109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89849, "number_of_timesteps": 30489109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89859, "number_of_timesteps": 30494109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89869, "number_of_timesteps": 30499109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89879, "number_of_timesteps": 30504109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89889, "number_of_timesteps": 30509109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89899, "number_of_timesteps": 30514109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89909, "number_of_timesteps": 30519109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89919, "number_of_timesteps": 30524109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89929, "number_of_timesteps": 30529109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89939, "number_of_timesteps": 30534109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89949, "number_of_timesteps": 30539109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89959, "number_of_timesteps": 30544109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89969, "number_of_timesteps": 30549109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89979, "number_of_timesteps": 30554109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89989, "number_of_timesteps": 30559109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 89999, "number_of_timesteps": 30564109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90009, "number_of_timesteps": 30569109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90019, "number_of_timesteps": 30574109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90029, "number_of_timesteps": 30579109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90039, "number_of_timesteps": 30584109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90049, "number_of_timesteps": 30589109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90059, "number_of_timesteps": 30594109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90069, "number_of_timesteps": 30599109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90079, "number_of_timesteps": 30604109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90089, "number_of_timesteps": 30609109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90099, "number_of_timesteps": 30614109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90109, "number_of_timesteps": 30619109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90119, "number_of_timesteps": 30624109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90129, "number_of_timesteps": 30629109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90139, "number_of_timesteps": 30634109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90149, "number_of_timesteps": 30639109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90159, "number_of_timesteps": 30644109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90169, "number_of_timesteps": 30649109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90179, "number_of_timesteps": 30654109, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90189, "number_of_timesteps": 30658643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90199, "number_of_timesteps": 30663643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90209, "number_of_timesteps": 30668643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90219, "number_of_timesteps": 30673643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90229, "number_of_timesteps": 30678643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90239, "number_of_timesteps": 30683643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90249, "number_of_timesteps": 30688643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90259, "number_of_timesteps": 30693643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90269, "number_of_timesteps": 30698643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90279, "number_of_timesteps": 30703643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90289, "number_of_timesteps": 30708643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90299, "number_of_timesteps": 30713643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90309, "number_of_timesteps": 30718643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90319, "number_of_timesteps": 30723643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90329, "number_of_timesteps": 30728643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90339, "number_of_timesteps": 30733643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90349, "number_of_timesteps": 30738643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90359, "number_of_timesteps": 30743643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90369, "number_of_timesteps": 30748643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90379, "number_of_timesteps": 30753643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90389, "number_of_timesteps": 30758643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90399, "number_of_timesteps": 30763643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90409, "number_of_timesteps": 30768643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90419, "number_of_timesteps": 30773643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90429, "number_of_timesteps": 30778643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90439, "number_of_timesteps": 30783643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90449, "number_of_timesteps": 30788643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90459, "number_of_timesteps": 30793643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90469, "number_of_timesteps": 30798643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90479, "number_of_timesteps": 30803643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90489, "number_of_timesteps": 30808643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90499, "number_of_timesteps": 30813643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90509, "number_of_timesteps": 30818643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90519, "number_of_timesteps": 30823643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90529, "number_of_timesteps": 30828643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90539, "number_of_timesteps": 30833643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90549, "number_of_timesteps": 30838643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90559, "number_of_timesteps": 30843643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90569, "number_of_timesteps": 30848643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90579, "number_of_timesteps": 30853643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90589, "number_of_timesteps": 30858643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90599, "number_of_timesteps": 30863643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90609, "number_of_timesteps": 30868643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90619, "number_of_timesteps": 30873643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90629, "number_of_timesteps": 30878643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90639, "number_of_timesteps": 30883643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90649, "number_of_timesteps": 30888643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90659, "number_of_timesteps": 30893643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90669, "number_of_timesteps": 30898643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90679, "number_of_timesteps": 30903643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90689, "number_of_timesteps": 30908643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90699, "number_of_timesteps": 30913643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90709, "number_of_timesteps": 30918643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90719, "number_of_timesteps": 30923643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90729, "number_of_timesteps": 30928643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90739, "number_of_timesteps": 30933643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90749, "number_of_timesteps": 30938643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90759, "number_of_timesteps": 30943643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90769, "number_of_timesteps": 30948643, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90779, "number_of_timesteps": 30953173, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90789, "number_of_timesteps": 30958173, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90799, "number_of_timesteps": 30963173, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90809, "number_of_timesteps": 30968173, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90819, "number_of_timesteps": 30973173, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90829, "number_of_timesteps": 30977721, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90839, "number_of_timesteps": 30982721, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90849, "number_of_timesteps": 30987721, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90859, "number_of_timesteps": 30992721, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90869, "number_of_timesteps": 30997721, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90879, "number_of_timesteps": 31002721, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90889, "number_of_timesteps": 31007721, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90899, "number_of_timesteps": 31012721, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90909, "number_of_timesteps": 31017721, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90919, "number_of_timesteps": 31022352, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90929, "number_of_timesteps": 31026472, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90939, "number_of_timesteps": 31031207, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90949, "number_of_timesteps": 31035747, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90959, "number_of_timesteps": 31040747, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90970, "number_of_timesteps": 31045792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90980, "number_of_timesteps": 31050792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 90990, "number_of_timesteps": 31055792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91000, "number_of_timesteps": 31060792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91010, "number_of_timesteps": 31065792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91020, "number_of_timesteps": 31070792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91030, "number_of_timesteps": 31075792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91040, "number_of_timesteps": 31080792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91050, "number_of_timesteps": 31085792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91060, "number_of_timesteps": 31090792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91070, "number_of_timesteps": 31095792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91080, "number_of_timesteps": 31100792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91090, "number_of_timesteps": 31105792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91100, "number_of_timesteps": 31110792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91110, "number_of_timesteps": 31115792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91120, "number_of_timesteps": 31120792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91130, "number_of_timesteps": 31125792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91140, "number_of_timesteps": 31130792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91150, "number_of_timesteps": 31135792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91160, "number_of_timesteps": 31140792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91170, "number_of_timesteps": 31145792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91180, "number_of_timesteps": 31150792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91190, "number_of_timesteps": 31155792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91200, "number_of_timesteps": 31160792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91210, "number_of_timesteps": 31165792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91220, "number_of_timesteps": 31170792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91230, "number_of_timesteps": 31175792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91240, "number_of_timesteps": 31180792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91250, "number_of_timesteps": 31185792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91260, "number_of_timesteps": 31190792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91270, "number_of_timesteps": 31195792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91280, "number_of_timesteps": 31200792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91290, "number_of_timesteps": 31205792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91300, "number_of_timesteps": 31210792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91310, "number_of_timesteps": 31215792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91320, "number_of_timesteps": 31220792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91330, "number_of_timesteps": 31225792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91340, "number_of_timesteps": 31230792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91350, "number_of_timesteps": 31235792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91360, "number_of_timesteps": 31240792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91370, "number_of_timesteps": 31245792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91380, "number_of_timesteps": 31250792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91390, "number_of_timesteps": 31255792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91400, "number_of_timesteps": 31260792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91410, "number_of_timesteps": 31265792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91420, "number_of_timesteps": 31270792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91430, "number_of_timesteps": 31275792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91440, "number_of_timesteps": 31280792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91450, "number_of_timesteps": 31285792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91460, "number_of_timesteps": 31290792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91470, "number_of_timesteps": 31295792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91480, "number_of_timesteps": 31300792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91490, "number_of_timesteps": 31305792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91500, "number_of_timesteps": 31310792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91510, "number_of_timesteps": 31315792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91520, "number_of_timesteps": 31320792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91530, "number_of_timesteps": 31325792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91540, "number_of_timesteps": 31330792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91550, "number_of_timesteps": 31335792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91560, "number_of_timesteps": 31340792, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91570, "number_of_timesteps": 31345540, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91580, "number_of_timesteps": 31350540, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91590, "number_of_timesteps": 31355540, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91600, "number_of_timesteps": 31360540, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91610, "number_of_timesteps": 31365540, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91620, "number_of_timesteps": 31370540, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91630, "number_of_timesteps": 31375540, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91640, "number_of_timesteps": 31380540, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91650, "number_of_timesteps": 31385310, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91660, "number_of_timesteps": 31390310, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91670, "number_of_timesteps": 31395310, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91680, "number_of_timesteps": 31400310, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91690, "number_of_timesteps": 31405310, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91701, "number_of_timesteps": 31410342, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91711, "number_of_timesteps": 31415342, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91722, "number_of_timesteps": 31420372, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91732, "number_of_timesteps": 31425372, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91742, "number_of_timesteps": 31430372, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91752, "number_of_timesteps": 31435372, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91762, "number_of_timesteps": 31439904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91772, "number_of_timesteps": 31444904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91782, "number_of_timesteps": 31449904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91792, "number_of_timesteps": 31454904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91802, "number_of_timesteps": 31459904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91812, "number_of_timesteps": 31464904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91822, "number_of_timesteps": 31469904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91832, "number_of_timesteps": 31474904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91842, "number_of_timesteps": 31479904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91852, "number_of_timesteps": 31484904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91862, "number_of_timesteps": 31489904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91872, "number_of_timesteps": 31494904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91882, "number_of_timesteps": 31499904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91892, "number_of_timesteps": 31504904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91902, "number_of_timesteps": 31509904, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91912, "number_of_timesteps": 31514436, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91922, "number_of_timesteps": 31519436, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91932, "number_of_timesteps": 31524436, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91942, "number_of_timesteps": 31529436, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91952, "number_of_timesteps": 31534436, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91962, "number_of_timesteps": 31539436, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91972, "number_of_timesteps": 31544436, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91982, "number_of_timesteps": 31549436, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 91992, "number_of_timesteps": 31554436, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92002, "number_of_timesteps": 31559436, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92012, "number_of_timesteps": 31564020, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92022, "number_of_timesteps": 31569020, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92032, "number_of_timesteps": 31574020, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92042, "number_of_timesteps": 31579020, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92052, "number_of_timesteps": 31583936, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92062, "number_of_timesteps": 31588936, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92072, "number_of_timesteps": 31593936, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92082, "number_of_timesteps": 31598936, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92092, "number_of_timesteps": 31603936, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92102, "number_of_timesteps": 31608936, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92112, "number_of_timesteps": 31613936, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92122, "number_of_timesteps": 31618934, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92132, "number_of_timesteps": 31623934, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92142, "number_of_timesteps": 31628934, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92152, "number_of_timesteps": 31633934, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92162, "number_of_timesteps": 31638934, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92172, "number_of_timesteps": 31643934, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92182, "number_of_timesteps": 31648465, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92192, "number_of_timesteps": 31653084, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92202, "number_of_timesteps": 31657631, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92212, "number_of_timesteps": 31662213, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92222, "number_of_timesteps": 31666787, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92232, "number_of_timesteps": 31670902, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92242, "number_of_timesteps": 31675322, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92252, "number_of_timesteps": 31680322, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92262, "number_of_timesteps": 31685322, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92272, "number_of_timesteps": 31690322, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92282, "number_of_timesteps": 31695322, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92292, "number_of_timesteps": 31700322, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92302, "number_of_timesteps": 31705322, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92312, "number_of_timesteps": 31710322, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92322, "number_of_timesteps": 31715322, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92332, "number_of_timesteps": 31720322, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92342, "number_of_timesteps": 31725322, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92352, "number_of_timesteps": 31730123, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92362, "number_of_timesteps": 31734651, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92372, "number_of_timesteps": 31739473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92382, "number_of_timesteps": 31744473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92392, "number_of_timesteps": 31749473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92402, "number_of_timesteps": 31754473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92412, "number_of_timesteps": 31759473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92422, "number_of_timesteps": 31764473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92432, "number_of_timesteps": 31769473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92442, "number_of_timesteps": 31774473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92452, "number_of_timesteps": 31779473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92462, "number_of_timesteps": 31784473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92472, "number_of_timesteps": 31789473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92482, "number_of_timesteps": 31794473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92492, "number_of_timesteps": 31799473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92502, "number_of_timesteps": 31804473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92512, "number_of_timesteps": 31809473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92522, "number_of_timesteps": 31814473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92532, "number_of_timesteps": 31819473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92542, "number_of_timesteps": 31824473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92552, "number_of_timesteps": 31829473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92562, "number_of_timesteps": 31834473, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92572, "number_of_timesteps": 31839082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92582, "number_of_timesteps": 31844082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92592, "number_of_timesteps": 31849082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92602, "number_of_timesteps": 31854082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92612, "number_of_timesteps": 31859082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92622, "number_of_timesteps": 31864082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92632, "number_of_timesteps": 31869082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92642, "number_of_timesteps": 31874082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92652, "number_of_timesteps": 31879082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92662, "number_of_timesteps": 31884082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92672, "number_of_timesteps": 31889082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92682, "number_of_timesteps": 31894082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92692, "number_of_timesteps": 31899082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92702, "number_of_timesteps": 31904082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92712, "number_of_timesteps": 31909082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92722, "number_of_timesteps": 31914082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92732, "number_of_timesteps": 31919082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92742, "number_of_timesteps": 31924082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92752, "number_of_timesteps": 31929082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92762, "number_of_timesteps": 31934082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92772, "number_of_timesteps": 31939082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92782, "number_of_timesteps": 31944082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92792, "number_of_timesteps": 31949082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92802, "number_of_timesteps": 31954082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92812, "number_of_timesteps": 31959082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92822, "number_of_timesteps": 31964082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92832, "number_of_timesteps": 31969082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92842, "number_of_timesteps": 31974082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92852, "number_of_timesteps": 31979082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92862, "number_of_timesteps": 31984082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92872, "number_of_timesteps": 31989082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92882, "number_of_timesteps": 31994082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92892, "number_of_timesteps": 31999082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92902, "number_of_timesteps": 32004082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92912, "number_of_timesteps": 32009082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92922, "number_of_timesteps": 32014082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92932, "number_of_timesteps": 32019082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92942, "number_of_timesteps": 32024082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92952, "number_of_timesteps": 32029082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92962, "number_of_timesteps": 32034082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92972, "number_of_timesteps": 32039082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92982, "number_of_timesteps": 32044082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 92992, "number_of_timesteps": 32049082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93002, "number_of_timesteps": 32054082, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93012, "number_of_timesteps": 32058646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93022, "number_of_timesteps": 32063646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93032, "number_of_timesteps": 32068646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93042, "number_of_timesteps": 32073646, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93052, "number_of_timesteps": 32078390, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93062, "number_of_timesteps": 32083390, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93072, "number_of_timesteps": 32088301, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93082, "number_of_timesteps": 32093301, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93092, "number_of_timesteps": 32098301, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93102, "number_of_timesteps": 32103083, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93112, "number_of_timesteps": 32108083, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93122, "number_of_timesteps": 32113083, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93132, "number_of_timesteps": 32118083, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93142, "number_of_timesteps": 32123083, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93152, "number_of_timesteps": 32128083, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93162, "number_of_timesteps": 32133083, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93172, "number_of_timesteps": 32138083, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93182, "number_of_timesteps": 32143083, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93192, "number_of_timesteps": 32147934, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93202, "number_of_timesteps": 32152381, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93212, "number_of_timesteps": 32156982, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93222, "number_of_timesteps": 32161982, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93232, "number_of_timesteps": 32166982, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93242, "number_of_timesteps": 32171516, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93252, "number_of_timesteps": 32176516, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93262, "number_of_timesteps": 32181516, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93272, "number_of_timesteps": 32186516, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93282, "number_of_timesteps": 32191516, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93292, "number_of_timesteps": 32196516, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93302, "number_of_timesteps": 32201516, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93312, "number_of_timesteps": 32206044, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93322, "number_of_timesteps": 32211044, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93332, "number_of_timesteps": 32216044, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93342, "number_of_timesteps": 32221044, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93352, "number_of_timesteps": 32226044, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93362, "number_of_timesteps": 32231044, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93372, "number_of_timesteps": 32235676, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93382, "number_of_timesteps": 32240676, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93392, "number_of_timesteps": 32245676, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93402, "number_of_timesteps": 32250676, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93412, "number_of_timesteps": 32255676, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93422, "number_of_timesteps": 32260676, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93432, "number_of_timesteps": 32265676, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93442, "number_of_timesteps": 32270622, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93452, "number_of_timesteps": 32275622, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93462, "number_of_timesteps": 32280622, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93472, "number_of_timesteps": 32285622, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93482, "number_of_timesteps": 32290622, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93492, "number_of_timesteps": 32295622, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93502, "number_of_timesteps": 32300299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93512, "number_of_timesteps": 32305299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93522, "number_of_timesteps": 32310299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93532, "number_of_timesteps": 32315299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93542, "number_of_timesteps": 32320299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93552, "number_of_timesteps": 32325299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93562, "number_of_timesteps": 32330299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93572, "number_of_timesteps": 32335299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93582, "number_of_timesteps": 32340299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93592, "number_of_timesteps": 32345299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93602, "number_of_timesteps": 32350299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93612, "number_of_timesteps": 32355299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93622, "number_of_timesteps": 32360299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93632, "number_of_timesteps": 32365299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93642, "number_of_timesteps": 32370299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93652, "number_of_timesteps": 32375299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93662, "number_of_timesteps": 32380299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93672, "number_of_timesteps": 32385299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93682, "number_of_timesteps": 32390299, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93692, "number_of_timesteps": 32394780, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93702, "number_of_timesteps": 32399450, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93712, "number_of_timesteps": 32404450, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93722, "number_of_timesteps": 32409450, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93732, "number_of_timesteps": 32414450, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93742, "number_of_timesteps": 32419450, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93752, "number_of_timesteps": 32424041, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93762, "number_of_timesteps": 32429041, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93772, "number_of_timesteps": 32434041, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93782, "number_of_timesteps": 32439041, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93792, "number_of_timesteps": 32443592, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93802, "number_of_timesteps": 32448592, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93812, "number_of_timesteps": 32453592, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93822, "number_of_timesteps": 32458592, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93832, "number_of_timesteps": 32463592, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93842, "number_of_timesteps": 32468592, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93852, "number_of_timesteps": 32473251, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93862, "number_of_timesteps": 32478251, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93872, "number_of_timesteps": 32482657, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93882, "number_of_timesteps": 32487657, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93892, "number_of_timesteps": 32492341, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93902, "number_of_timesteps": 32497341, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93912, "number_of_timesteps": 32502341, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93922, "number_of_timesteps": 32507341, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93932, "number_of_timesteps": 32512341, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93942, "number_of_timesteps": 32516872, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93952, "number_of_timesteps": 32521872, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93962, "number_of_timesteps": 32526872, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93972, "number_of_timesteps": 32531872, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93982, "number_of_timesteps": 32536872, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 93992, "number_of_timesteps": 32541872, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94002, "number_of_timesteps": 32546872, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94012, "number_of_timesteps": 32551872, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94022, "number_of_timesteps": 32556872, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94032, "number_of_timesteps": 32561751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94042, "number_of_timesteps": 32566751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94052, "number_of_timesteps": 32571751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94062, "number_of_timesteps": 32576751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94072, "number_of_timesteps": 32581751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94082, "number_of_timesteps": 32586751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94092, "number_of_timesteps": 32591751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94102, "number_of_timesteps": 32596751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94112, "number_of_timesteps": 32601751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94122, "number_of_timesteps": 32606751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94132, "number_of_timesteps": 32611751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94142, "number_of_timesteps": 32616751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94152, "number_of_timesteps": 32621751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94162, "number_of_timesteps": 32626751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94172, "number_of_timesteps": 32631751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94182, "number_of_timesteps": 32636751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94192, "number_of_timesteps": 32641751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94202, "number_of_timesteps": 32646751, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94212, "number_of_timesteps": 32651613, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94222, "number_of_timesteps": 32656613, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94232, "number_of_timesteps": 32661613, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94242, "number_of_timesteps": 32666613, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94252, "number_of_timesteps": 32671613, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94262, "number_of_timesteps": 32676613, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94272, "number_of_timesteps": 32681613, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94282, "number_of_timesteps": 32686613, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94292, "number_of_timesteps": 32691613, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94302, "number_of_timesteps": 32696613, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94312, "number_of_timesteps": 32701613, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94322, "number_of_timesteps": 32706164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94332, "number_of_timesteps": 32711164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94342, "number_of_timesteps": 32716164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94352, "number_of_timesteps": 32721164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94362, "number_of_timesteps": 32726164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94372, "number_of_timesteps": 32731164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94382, "number_of_timesteps": 32736164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94392, "number_of_timesteps": 32741164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94402, "number_of_timesteps": 32746164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94412, "number_of_timesteps": 32751164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94422, "number_of_timesteps": 32756164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94432, "number_of_timesteps": 32761164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94442, "number_of_timesteps": 32766164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94452, "number_of_timesteps": 32771164, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94462, "number_of_timesteps": 32775696, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94472, "number_of_timesteps": 32780228, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94482, "number_of_timesteps": 32785228, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94492, "number_of_timesteps": 32790228, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94502, "number_of_timesteps": 32795228, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94512, "number_of_timesteps": 32799796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94522, "number_of_timesteps": 32804796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94532, "number_of_timesteps": 32809796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94542, "number_of_timesteps": 32814449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94552, "number_of_timesteps": 32819449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94562, "number_of_timesteps": 32824449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94572, "number_of_timesteps": 32829449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94582, "number_of_timesteps": 32834449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94592, "number_of_timesteps": 32839449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94602, "number_of_timesteps": 32844449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94612, "number_of_timesteps": 32849449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94622, "number_of_timesteps": 32854449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94632, "number_of_timesteps": 32859449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94642, "number_of_timesteps": 32864449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94652, "number_of_timesteps": 32869449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94662, "number_of_timesteps": 32874449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94672, "number_of_timesteps": 32879449, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94682, "number_of_timesteps": 32884135, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94692, "number_of_timesteps": 32889135, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94702, "number_of_timesteps": 32894135, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94712, "number_of_timesteps": 32899135, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94722, "number_of_timesteps": 32903684, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94732, "number_of_timesteps": 32908215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94742, "number_of_timesteps": 32913215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94752, "number_of_timesteps": 32918215, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94762, "number_of_timesteps": 32923019, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94772, "number_of_timesteps": 32928019, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94782, "number_of_timesteps": 32933019, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94792, "number_of_timesteps": 32937520, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94802, "number_of_timesteps": 32940994, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94812, "number_of_timesteps": 32945559, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94822, "number_of_timesteps": 32950559, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94832, "number_of_timesteps": 32955559, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94842, "number_of_timesteps": 32960559, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94852, "number_of_timesteps": 32965559, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94862, "number_of_timesteps": 32970474, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94872, "number_of_timesteps": 32975474, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94882, "number_of_timesteps": 32980474, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94892, "number_of_timesteps": 32985474, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94902, "number_of_timesteps": 32990474, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94912, "number_of_timesteps": 32995474, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94922, "number_of_timesteps": 33000474, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94932, "number_of_timesteps": 33005474, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94942, "number_of_timesteps": 33010474, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94952, "number_of_timesteps": 33015133, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94962, "number_of_timesteps": 33020133, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94972, "number_of_timesteps": 33025133, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94982, "number_of_timesteps": 33029736, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 94992, "number_of_timesteps": 33034660, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95002, "number_of_timesteps": 33039055, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95012, "number_of_timesteps": 33043666, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95022, "number_of_timesteps": 33048343, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95032, "number_of_timesteps": 33053102, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95042, "number_of_timesteps": 33057933, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95052, "number_of_timesteps": 33062535, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95062, "number_of_timesteps": 33067478, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95072, "number_of_timesteps": 33071413, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95082, "number_of_timesteps": 33075571, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95092, "number_of_timesteps": 33080571, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95102, "number_of_timesteps": 33085536, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95112, "number_of_timesteps": 33090488, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95122, "number_of_timesteps": 33095488, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95132, "number_of_timesteps": 33100488, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95142, "number_of_timesteps": 33105488, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95152, "number_of_timesteps": 33110488, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95162, "number_of_timesteps": 33115488, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95172, "number_of_timesteps": 33120488, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95182, "number_of_timesteps": 33125211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95192, "number_of_timesteps": 33130211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95202, "number_of_timesteps": 33135211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95212, "number_of_timesteps": 33140211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95222, "number_of_timesteps": 33145211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95232, "number_of_timesteps": 33150211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95242, "number_of_timesteps": 33155211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95252, "number_of_timesteps": 33160211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95262, "number_of_timesteps": 33165211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95272, "number_of_timesteps": 33170211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95282, "number_of_timesteps": 33175211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95292, "number_of_timesteps": 33180211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95302, "number_of_timesteps": 33185211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95312, "number_of_timesteps": 33190211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95322, "number_of_timesteps": 33195211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95332, "number_of_timesteps": 33200211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95342, "number_of_timesteps": 33205211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95352, "number_of_timesteps": 33210211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95362, "number_of_timesteps": 33215211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95372, "number_of_timesteps": 33220211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95382, "number_of_timesteps": 33225211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95392, "number_of_timesteps": 33230211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95402, "number_of_timesteps": 33235211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95412, "number_of_timesteps": 33240211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95422, "number_of_timesteps": 33245211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95432, "number_of_timesteps": 33250211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95442, "number_of_timesteps": 33255211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95452, "number_of_timesteps": 33260211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95462, "number_of_timesteps": 33265211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95472, "number_of_timesteps": 33270211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95482, "number_of_timesteps": 33275211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95492, "number_of_timesteps": 33280211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95502, "number_of_timesteps": 33285211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95512, "number_of_timesteps": 33290211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95522, "number_of_timesteps": 33295211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95532, "number_of_timesteps": 33300211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95542, "number_of_timesteps": 33305211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95552, "number_of_timesteps": 33310211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95562, "number_of_timesteps": 33315211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95572, "number_of_timesteps": 33320211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95582, "number_of_timesteps": 33325211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95592, "number_of_timesteps": 33330211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95602, "number_of_timesteps": 33335211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95612, "number_of_timesteps": 33340211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95622, "number_of_timesteps": 33345211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95632, "number_of_timesteps": 33350211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95642, "number_of_timesteps": 33355211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95652, "number_of_timesteps": 33360211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95662, "number_of_timesteps": 33365211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95672, "number_of_timesteps": 33370211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95682, "number_of_timesteps": 33375211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95692, "number_of_timesteps": 33380211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95702, "number_of_timesteps": 33385211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95712, "number_of_timesteps": 33390211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95722, "number_of_timesteps": 33395211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95732, "number_of_timesteps": 33400211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95742, "number_of_timesteps": 33405211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95752, "number_of_timesteps": 33410211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95762, "number_of_timesteps": 33415211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95772, "number_of_timesteps": 33420211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95782, "number_of_timesteps": 33425211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95792, "number_of_timesteps": 33430211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95802, "number_of_timesteps": 33435211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95812, "number_of_timesteps": 33440211, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95822, "number_of_timesteps": 33444796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95832, "number_of_timesteps": 33449796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95842, "number_of_timesteps": 33454796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95852, "number_of_timesteps": 33459796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95862, "number_of_timesteps": 33464796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95872, "number_of_timesteps": 33469796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95882, "number_of_timesteps": 33474796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95892, "number_of_timesteps": 33479796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95902, "number_of_timesteps": 33484796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95912, "number_of_timesteps": 33489796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95922, "number_of_timesteps": 33494796, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95932, "number_of_timesteps": 33499328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95942, "number_of_timesteps": 33504328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95952, "number_of_timesteps": 33509328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95962, "number_of_timesteps": 33514328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95972, "number_of_timesteps": 33519328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95982, "number_of_timesteps": 33524328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 95992, "number_of_timesteps": 33529328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96002, "number_of_timesteps": 33534328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96012, "number_of_timesteps": 33539328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96022, "number_of_timesteps": 33544328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96032, "number_of_timesteps": 33549328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96042, "number_of_timesteps": 33554328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96052, "number_of_timesteps": 33559328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96062, "number_of_timesteps": 33564328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96072, "number_of_timesteps": 33569328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96082, "number_of_timesteps": 33574328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96092, "number_of_timesteps": 33579328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96102, "number_of_timesteps": 33584328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96112, "number_of_timesteps": 33589328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96122, "number_of_timesteps": 33594328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96132, "number_of_timesteps": 33599328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96142, "number_of_timesteps": 33604328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96152, "number_of_timesteps": 33609328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96162, "number_of_timesteps": 33614328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96172, "number_of_timesteps": 33619328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96182, "number_of_timesteps": 33624328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96192, "number_of_timesteps": 33629328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96202, "number_of_timesteps": 33634328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96212, "number_of_timesteps": 33639328, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96222, "number_of_timesteps": 33643859, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96232, "number_of_timesteps": 33648859, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96242, "number_of_timesteps": 33653570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96252, "number_of_timesteps": 33658570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96262, "number_of_timesteps": 33663570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96272, "number_of_timesteps": 33668570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96282, "number_of_timesteps": 33673570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96292, "number_of_timesteps": 33678570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96302, "number_of_timesteps": 33683570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96312, "number_of_timesteps": 33688570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96322, "number_of_timesteps": 33693570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96332, "number_of_timesteps": 33698570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96342, "number_of_timesteps": 33703570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96352, "number_of_timesteps": 33708570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96362, "number_of_timesteps": 33713570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96372, "number_of_timesteps": 33718570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96382, "number_of_timesteps": 33723570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96392, "number_of_timesteps": 33728570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96402, "number_of_timesteps": 33733570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96412, "number_of_timesteps": 33738570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96422, "number_of_timesteps": 33743570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96432, "number_of_timesteps": 33748570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96442, "number_of_timesteps": 33753570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96452, "number_of_timesteps": 33758570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96462, "number_of_timesteps": 33763570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96472, "number_of_timesteps": 33768570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96482, "number_of_timesteps": 33773570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96492, "number_of_timesteps": 33778570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96502, "number_of_timesteps": 33783570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96512, "number_of_timesteps": 33788570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96522, "number_of_timesteps": 33793570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96532, "number_of_timesteps": 33798570, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96542, "number_of_timesteps": 33803085, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96552, "number_of_timesteps": 33808085, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96562, "number_of_timesteps": 33813085, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96572, "number_of_timesteps": 33818085, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96582, "number_of_timesteps": 33823085, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96592, "number_of_timesteps": 33828085, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96602, "number_of_timesteps": 33833085, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96612, "number_of_timesteps": 33838085, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96622, "number_of_timesteps": 33843085, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96632, "number_of_timesteps": 33847599, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96642, "number_of_timesteps": 33852599, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96652, "number_of_timesteps": 33857234, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96662, "number_of_timesteps": 33862234, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96672, "number_of_timesteps": 33867234, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96682, "number_of_timesteps": 33871718, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96692, "number_of_timesteps": 33876718, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96702, "number_of_timesteps": 33881718, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96712, "number_of_timesteps": 33886718, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96722, "number_of_timesteps": 33891247, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96732, "number_of_timesteps": 33896247, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96742, "number_of_timesteps": 33901247, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96752, "number_of_timesteps": 33906247, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96762, "number_of_timesteps": 33910313, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96772, "number_of_timesteps": 33915313, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96782, "number_of_timesteps": 33920313, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96792, "number_of_timesteps": 33925001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96802, "number_of_timesteps": 33930001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96812, "number_of_timesteps": 33935001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96822, "number_of_timesteps": 33940001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96832, "number_of_timesteps": 33945001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96842, "number_of_timesteps": 33950001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96852, "number_of_timesteps": 33955001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96862, "number_of_timesteps": 33960001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96872, "number_of_timesteps": 33965001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96882, "number_of_timesteps": 33970001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96892, "number_of_timesteps": 33975001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96902, "number_of_timesteps": 33980001, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96912, "number_of_timesteps": 33984532, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96922, "number_of_timesteps": 33989532, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96932, "number_of_timesteps": 33994532, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96942, "number_of_timesteps": 33999532, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96952, "number_of_timesteps": 34004403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96962, "number_of_timesteps": 34009403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96972, "number_of_timesteps": 34014403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96982, "number_of_timesteps": 34019403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 96992, "number_of_timesteps": 34024403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97002, "number_of_timesteps": 34029403, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97012, "number_of_timesteps": 34034005, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97022, "number_of_timesteps": 34039005, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97032, "number_of_timesteps": 34044005, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97042, "number_of_timesteps": 34049005, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97052, "number_of_timesteps": 34054005, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97062, "number_of_timesteps": 34059005, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97072, "number_of_timesteps": 34064005, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97082, "number_of_timesteps": 34068575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97092, "number_of_timesteps": 34073575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97102, "number_of_timesteps": 34078575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97112, "number_of_timesteps": 34083575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97122, "number_of_timesteps": 34088575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97132, "number_of_timesteps": 34093575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97142, "number_of_timesteps": 34098575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97152, "number_of_timesteps": 34103575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97162, "number_of_timesteps": 34108575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97172, "number_of_timesteps": 34113575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97182, "number_of_timesteps": 34118575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97192, "number_of_timesteps": 34123575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97202, "number_of_timesteps": 34128575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97212, "number_of_timesteps": 34133575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97222, "number_of_timesteps": 34138575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97232, "number_of_timesteps": 34143575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97242, "number_of_timesteps": 34148575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97252, "number_of_timesteps": 34153575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97262, "number_of_timesteps": 34158575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97272, "number_of_timesteps": 34163575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97282, "number_of_timesteps": 34168575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97292, "number_of_timesteps": 34173575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97302, "number_of_timesteps": 34178575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97312, "number_of_timesteps": 34183575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97322, "number_of_timesteps": 34188575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97332, "number_of_timesteps": 34193575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97342, "number_of_timesteps": 34198575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97352, "number_of_timesteps": 34203575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97362, "number_of_timesteps": 34208575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97372, "number_of_timesteps": 34213575, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97382, "number_of_timesteps": 34218107, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97392, "number_of_timesteps": 34222620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97402, "number_of_timesteps": 34227620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97412, "number_of_timesteps": 34232620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97422, "number_of_timesteps": 34237620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97432, "number_of_timesteps": 34242620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97442, "number_of_timesteps": 34247620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97452, "number_of_timesteps": 34252620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97462, "number_of_timesteps": 34257620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97472, "number_of_timesteps": 34262620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97482, "number_of_timesteps": 34267620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97492, "number_of_timesteps": 34272620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97502, "number_of_timesteps": 34277620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97512, "number_of_timesteps": 34282620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97522, "number_of_timesteps": 34287620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97532, "number_of_timesteps": 34292620, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97542, "number_of_timesteps": 34297441, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97552, "number_of_timesteps": 34302441, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97562, "number_of_timesteps": 34307441, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97572, "number_of_timesteps": 34312441, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97582, "number_of_timesteps": 34317441, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97592, "number_of_timesteps": 34322441, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97602, "number_of_timesteps": 34327307, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97612, "number_of_timesteps": 34332018, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97622, "number_of_timesteps": 34337018, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97634, "number_of_timesteps": 34342097, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97644, "number_of_timesteps": 34347097, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97654, "number_of_timesteps": 34352097, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97664, "number_of_timesteps": 34356630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97674, "number_of_timesteps": 34361630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97684, "number_of_timesteps": 34366630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97694, "number_of_timesteps": 34371630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97704, "number_of_timesteps": 34376630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97714, "number_of_timesteps": 34381630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97724, "number_of_timesteps": 34386630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97734, "number_of_timesteps": 34391630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97744, "number_of_timesteps": 34396630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97754, "number_of_timesteps": 34401630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97764, "number_of_timesteps": 34406630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97774, "number_of_timesteps": 34411630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97784, "number_of_timesteps": 34416630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97794, "number_of_timesteps": 34421630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97804, "number_of_timesteps": 34426630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97814, "number_of_timesteps": 34431630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97824, "number_of_timesteps": 34436630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97834, "number_of_timesteps": 34441630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97844, "number_of_timesteps": 34446630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97854, "number_of_timesteps": 34451630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97864, "number_of_timesteps": 34456630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97874, "number_of_timesteps": 34461630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97884, "number_of_timesteps": 34466630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97894, "number_of_timesteps": 34471630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97904, "number_of_timesteps": 34476630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97914, "number_of_timesteps": 34481630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97924, "number_of_timesteps": 34486630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97934, "number_of_timesteps": 34491630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97944, "number_of_timesteps": 34496630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97954, "number_of_timesteps": 34501630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97964, "number_of_timesteps": 34506630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97974, "number_of_timesteps": 34511630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97984, "number_of_timesteps": 34516630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 97994, "number_of_timesteps": 34521630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98004, "number_of_timesteps": 34526630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98014, "number_of_timesteps": 34531630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98024, "number_of_timesteps": 34536630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98034, "number_of_timesteps": 34541630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98044, "number_of_timesteps": 34546630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98054, "number_of_timesteps": 34551630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98064, "number_of_timesteps": 34556630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98074, "number_of_timesteps": 34561630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98084, "number_of_timesteps": 34566630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98094, "number_of_timesteps": 34571630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98104, "number_of_timesteps": 34576630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98114, "number_of_timesteps": 34581630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98124, "number_of_timesteps": 34586630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98134, "number_of_timesteps": 34591630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98144, "number_of_timesteps": 34596630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98154, "number_of_timesteps": 34601630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98164, "number_of_timesteps": 34606630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98174, "number_of_timesteps": 34611630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98184, "number_of_timesteps": 34616630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98194, "number_of_timesteps": 34621630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98204, "number_of_timesteps": 34626630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98214, "number_of_timesteps": 34631630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98224, "number_of_timesteps": 34636630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98234, "number_of_timesteps": 34641630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98244, "number_of_timesteps": 34646630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98254, "number_of_timesteps": 34651630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98264, "number_of_timesteps": 34656630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98274, "number_of_timesteps": 34661630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98284, "number_of_timesteps": 34666630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98294, "number_of_timesteps": 34671630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98304, "number_of_timesteps": 34676630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98314, "number_of_timesteps": 34681630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98324, "number_of_timesteps": 34686630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98334, "number_of_timesteps": 34691630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98344, "number_of_timesteps": 34696630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98354, "number_of_timesteps": 34701630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98364, "number_of_timesteps": 34706630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98374, "number_of_timesteps": 34711630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98384, "number_of_timesteps": 34716630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98394, "number_of_timesteps": 34721630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98404, "number_of_timesteps": 34726630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98414, "number_of_timesteps": 34731630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98424, "number_of_timesteps": 34736630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98434, "number_of_timesteps": 34741630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98444, "number_of_timesteps": 34746630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98454, "number_of_timesteps": 34751630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98464, "number_of_timesteps": 34756630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98474, "number_of_timesteps": 34761630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98484, "number_of_timesteps": 34766630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98494, "number_of_timesteps": 34771630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98504, "number_of_timesteps": 34776630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98514, "number_of_timesteps": 34781630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98524, "number_of_timesteps": 34786630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98534, "number_of_timesteps": 34791630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98544, "number_of_timesteps": 34796630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98554, "number_of_timesteps": 34801630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98564, "number_of_timesteps": 34806630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98574, "number_of_timesteps": 34811630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98584, "number_of_timesteps": 34816630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98594, "number_of_timesteps": 34821630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98604, "number_of_timesteps": 34826630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98614, "number_of_timesteps": 34831630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98624, "number_of_timesteps": 34836630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98634, "number_of_timesteps": 34841630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98644, "number_of_timesteps": 34846630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98654, "number_of_timesteps": 34851630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98664, "number_of_timesteps": 34856630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98674, "number_of_timesteps": 34861630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98684, "number_of_timesteps": 34866630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98694, "number_of_timesteps": 34871630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98704, "number_of_timesteps": 34876630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98714, "number_of_timesteps": 34881630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98724, "number_of_timesteps": 34886630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98734, "number_of_timesteps": 34891630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98744, "number_of_timesteps": 34896630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98754, "number_of_timesteps": 34901630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98764, "number_of_timesteps": 34906630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98774, "number_of_timesteps": 34911630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98784, "number_of_timesteps": 34916630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98794, "number_of_timesteps": 34921630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98804, "number_of_timesteps": 34926630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98814, "number_of_timesteps": 34931630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98824, "number_of_timesteps": 34936630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98834, "number_of_timesteps": 34941630, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98844, "number_of_timesteps": 34946524, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98854, "number_of_timesteps": 34950590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98864, "number_of_timesteps": 34955590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98874, "number_of_timesteps": 34960590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98884, "number_of_timesteps": 34965590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98894, "number_of_timesteps": 34970590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98904, "number_of_timesteps": 34975590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98914, "number_of_timesteps": 34980590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98924, "number_of_timesteps": 34985590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98934, "number_of_timesteps": 34990590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98944, "number_of_timesteps": 34995590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98954, "number_of_timesteps": 35000590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98964, "number_of_timesteps": 35005590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98974, "number_of_timesteps": 35010590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98984, "number_of_timesteps": 35015590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 98994, "number_of_timesteps": 35020590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99004, "number_of_timesteps": 35025590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99014, "number_of_timesteps": 35030590, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99024, "number_of_timesteps": 35035439, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99034, "number_of_timesteps": 35040439, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99044, "number_of_timesteps": 35045439, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99054, "number_of_timesteps": 35050439, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99064, "number_of_timesteps": 35055439, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99074, "number_of_timesteps": 35060439, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99084, "number_of_timesteps": 35065439, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99094, "number_of_timesteps": 35070302, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99104, "number_of_timesteps": 35075302, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99114, "number_of_timesteps": 35080302, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99124, "number_of_timesteps": 35085302, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99134, "number_of_timesteps": 35089849, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99144, "number_of_timesteps": 35094849, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99154, "number_of_timesteps": 35099849, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99164, "number_of_timesteps": 35104849, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99174, "number_of_timesteps": 35109849, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99184, "number_of_timesteps": 35114849, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99194, "number_of_timesteps": 35119849, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99204, "number_of_timesteps": 35124849, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99214, "number_of_timesteps": 35129849, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99224, "number_of_timesteps": 35134849, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99234, "number_of_timesteps": 35139849, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99244, "number_of_timesteps": 35144361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99254, "number_of_timesteps": 35149361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99264, "number_of_timesteps": 35154361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99274, "number_of_timesteps": 35159361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99284, "number_of_timesteps": 35164361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99294, "number_of_timesteps": 35169361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99304, "number_of_timesteps": 35174361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99314, "number_of_timesteps": 35179048, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99324, "number_of_timesteps": 35184048, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99334, "number_of_timesteps": 35189048, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99344, "number_of_timesteps": 35194048, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99354, "number_of_timesteps": 35199048, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99364, "number_of_timesteps": 35204048, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99374, "number_of_timesteps": 35208581, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99384, "number_of_timesteps": 35213581, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99394, "number_of_timesteps": 35218581, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99404, "number_of_timesteps": 35223581, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99414, "number_of_timesteps": 35228244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99424, "number_of_timesteps": 35233244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99434, "number_of_timesteps": 35238244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99444, "number_of_timesteps": 35243244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99454, "number_of_timesteps": 35248244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99464, "number_of_timesteps": 35253244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99474, "number_of_timesteps": 35258244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99484, "number_of_timesteps": 35263244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99494, "number_of_timesteps": 35268244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99504, "number_of_timesteps": 35273244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99514, "number_of_timesteps": 35278244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99524, "number_of_timesteps": 35283244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99534, "number_of_timesteps": 35288244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99544, "number_of_timesteps": 35293244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99554, "number_of_timesteps": 35298244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99564, "number_of_timesteps": 35303244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99574, "number_of_timesteps": 35308244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99584, "number_of_timesteps": 35313244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
[starting run_func()]
[starting train_loop()]
{"total_number_of_episodes": 99594, "number_of_timesteps": 35318244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99604, "number_of_timesteps": 35323244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99614, "number_of_timesteps": 35328244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99624, "number_of_timesteps": 35333244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99634, "number_of_timesteps": 35338244, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99644, "number_of_timesteps": 35342780, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99654, "number_of_timesteps": 35345091, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99664, "number_of_timesteps": 35347325, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99674, "number_of_timesteps": 35350384, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99684, "number_of_timesteps": 35355266, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99694, "number_of_timesteps": 35359287, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99704, "number_of_timesteps": 35364287, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99714, "number_of_timesteps": 35369287, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99724, "number_of_timesteps": 35374287, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99734, "number_of_timesteps": 35379287, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99744, "number_of_timesteps": 35384287, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99754, "number_of_timesteps": 35388313, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99764, "number_of_timesteps": 35393313, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99774, "number_of_timesteps": 35398313, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99784, "number_of_timesteps": 35402848, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99794, "number_of_timesteps": 35407361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99804, "number_of_timesteps": 35412361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99814, "number_of_timesteps": 35417361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99824, "number_of_timesteps": 35422361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99834, "number_of_timesteps": 35427361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99844, "number_of_timesteps": 35432361, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99854, "number_of_timesteps": 35436877, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99864, "number_of_timesteps": 35441877, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99875, "number_of_timesteps": 35446889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99885, "number_of_timesteps": 35451889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99895, "number_of_timesteps": 35456889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99905, "number_of_timesteps": 35461889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99915, "number_of_timesteps": 35466889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99925, "number_of_timesteps": 35471889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99935, "number_of_timesteps": 35476889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99945, "number_of_timesteps": 35481889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99955, "number_of_timesteps": 35486889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99965, "number_of_timesteps": 35491889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99975, "number_of_timesteps": 35496889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99985, "number_of_timesteps": 35501889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 99995, "number_of_timesteps": 35506889, "per_episode_reward": 350.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},




[starting run_func()]
[starting train_loop()]




[starting run_func()]
[starting train_loop()]




[starting run_func()]
[starting train_loop()]




[starting run_func()]
[starting train_loop()]




[starting run_func()]
[starting train_loop()]




Process Process-9:
Traceback (most recent call last):
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 598, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 567, in f
    train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 158, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 610, in wait
    self._enter() # Block while the barrier drains.
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 634, in _enter
    raise BrokenBarrierError
threading.BrokenBarrierError
Process Process-5:
Traceback (most recent call last):
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 598, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 567, in f
    train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 158, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 610, in wait
    self._enter() # Block while the barrier drains.
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 634, in _enter
    raise BrokenBarrierError
threading.BrokenBarrierError
Process Process-4:
Traceback (most recent call last):
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 598, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 567, in f
    train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 158, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 610, in wait
    self._enter() # Block while the barrier drains.
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 634, in _enter
    raise BrokenBarrierError
threading.BrokenBarrierError
Process Process-10:
Traceback (most recent call last):
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 598, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 567, in f
    train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 158, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 610, in wait
    self._enter() # Block while the barrier drains.
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 634, in _enter
    raise BrokenBarrierError
threading.BrokenBarrierError
Process Process-7:
Traceback (most recent call last):
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 598, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 567, in f
    train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 158, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 610, in wait
    self._enter() # Block while the barrier drains.
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 634, in _enter
    raise BrokenBarrierError
threading.BrokenBarrierError
Process Process-8:
Traceback (most recent call last):
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 598, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 567, in f
    train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 158, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 610, in wait
    self._enter() # Block while the barrier drains.
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 634, in _enter
    raise BrokenBarrierError
threading.BrokenBarrierError
[starting run_func()]
[starting train_loop()]




[starting run_func()]
[starting train_loop()]




[starting run_func()]
[starting train_loop()]




Process Process-6:
Traceback (most recent call last):
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 598, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 567, in f
    train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 158, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 610, in wait
    self._enter() # Block while the barrier drains.
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 634, in _enter
    raise BrokenBarrierError
threading.BrokenBarrierError
Process Process-2:
Traceback (most recent call last):
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 598, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 567, in f
    train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 158, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 610, in wait
    self._enter() # Block while the barrier drains.
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 634, in _enter
    raise BrokenBarrierError
threading.BrokenBarrierError
Process Process-3:
Traceback (most recent call last):
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 598, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 567, in f
    train_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 158, in train_loop
    all_updated_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 610, in wait
    self._enter() # Block while the barrier drains.
  File "/nix/store/x0yzsy3pk7qvvw1x6igaifqr1434isqk-python3-3.8.12/lib/python3.8/threading.py", line 634, in _enter
    raise BrokenBarrierError
threading.BrokenBarrierError
[done calling async_.run_async()]
n_steps: 125000 mean: 500.0 median: 500.0 stdev: 0.0

