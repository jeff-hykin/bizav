config = {
    "evaluation": {
        "enabled": True, 
        "number_of_episodes_before_eval": 130, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": 125000, 
            "number_of_episodes": None, 
        }, 
    }, 
    "verbose": True, 
    "number_of_processes": 7, 
    "number_of_malicious_processes": 0, 
    "expected_number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": {
        0: 0.1, 
        1: 0.08, 
        2: 0.063, 
        3: 0.05, 
        4: 0.04, 
        5: 0.032, 
        6: 0.025, 
        7: 0.02, 
        8: 0.016, 
        9: 0.012, 
        10: 0.01, 
        11: 0.008, 
        12: 0.0063, 
        13: 0.005, 
        14: 0.004, 
        15: 0.0032, 
        16: 0.0025, 
        17: 0.002, 
        18: 0.0016, 
        19: 0.0012, 
        20: 0.001, 
        21: 0.0008, 
        22: 0.00063, 
        23: 0.0005, 
        24: 0.0004, 
        25: 0.00032, 
        26: 0.00025, 
        27: 0.0002, 
        28: 0.00016, 
        29: 0.00012, 
        30: 1e-05, 
        31: 8e-06, 
        32: 6.3e-06, 
        33: 5e-06, 
        34: 4e-06, 
        35: 3.2e-06, 
        36: 2.5e-06, 
        37: 2e-06, 
        38: 1.6e-06, 
        39: 1.2e-06, 
    }, 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": {0: 0, }, 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0, 
        "min_number_of_episodes": 30, 
        "thresholds": {}, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": {0: 0, 1: 1, 2: 2, }, }, 
            "sequential_options": {
                "t_max": {0: 3, 1: 5, 2: 10, 3: 20, 4: 30, 5: 50, }, 
                "hidden_size": {0: 16, 1: 32, 2: 64, 3: 128, }, 
                "learning_rate": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
                "beta": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
                "beta": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 21000, }, 
    "env_config": {
        "env_name": "CartPole-v1", 
        "learning_rate": 0.001, 
        "beta": 2e-05, 
        "t_max": 5, 
        "activation": 1, 
        "hidden_size": 64, 
        "permaban_threshold": 500, 
        "variance_scaling_factor": 1, 
    }, 
}
args = {
    "processes": 7, 
    "env": "CartPole-v1", 
    "seed": 810962030, 
    "outdir": "results", 
    "t_max": 5, 
    "beta": 2e-05, 
    "profile": False, 
    "steps": 21000, 
    "max_frames": (108000, ), 
    "lr": 0.001, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 500, 
    "malicious": 0, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 1, 
}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting train_loop()]
Step 0 0 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]Step 1 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-6.385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]Step 2 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 1 q_vals: [-6.385, -5.815, 0.0, 0.0, 0.0, 0.0, 0.0]Step 3 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 3 q_vals: [-6.385, -5.815, 0.0, 0.0, 0.0, 0.0, 0.0]Step 4 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 4 q_vals: [-6.385, -5.815, 0.0, 0.0, 0.0, 0.0, 0.0]Step 5 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 4 q_vals: [-6.385, -5.815, 0.0, 0.0, -4.569, 0.0, 0.0]Step 6 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 5 q_vals: [-6.385, -5.815, 0.0, 0.0, -4.569, -4.202, 0.0]Step 7 6 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 9 q_vals: [-6.385, -5.815, 0.0, 0.0, -4.569, -4.202, -4.103]Step 8 2 visits [1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 11 q_vals: [-6.385, -5.815, -3.585, 0.0, -4.569, -4.202, -4.103]Step 9 3 visits [1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 11 q_vals: [-6.385, -5.815, -3.585, -3.433, -4.569, -4.202, -4.103]Step 10 3 visits [1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 12 q_vals: [-6.385, -5.815, -3.585, -3.805, -4.569, -4.202, -4.103]Step 11 2 visits [1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0]  episode_count: 15 q_vals: [-6.385, -5.815, -3.747, -3.805, -4.569, -4.202, -4.103]Step 12 6 visits [1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0]  episode_count: 16 q_vals: [-6.385, -5.815, -3.747, -3.805, -4.569, -4.202, -4.09]Step 13 5 visits [1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 2.0]  episode_count: 16 q_vals: [-6.385, -5.815, -3.747, -3.805, -4.569, -3.143, -4.09]Step 14 5 visits [1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 2.0]  episode_count: 17 q_vals: [-6.385, -5.815, -3.747, -3.805, -4.569, -4.186, -4.09]Step 15 2 visits [1.0, 1.0, 4.0, 3.0, 1.0, 3.0, 2.0]  episode_count: 18 q_vals: [-6.385, -5.815, -4.279, -3.805, -4.569, -4.186, -4.09]Step 16 3 visits [1.0, 1.0, 4.0, 4.0, 1.0, 3.0, 2.0]  episode_count: 21 q_vals: [-6.385, -5.815, -4.279, -2.854, -4.569, -4.186, -4.09]Step 17 3 visits [1.0, 1.0, 4.0, 5.0, 1.0, 3.0, 2.0]  episode_count: 23 q_vals: [-6.385, -5.815, -4.279, -3.29, -4.569, -4.186, -4.09]Step 18 3 visits [1.0, 1.0, 4.0, 6.0, 1.0, 3.0, 2.0]  episode_count: 25 q_vals: [-6.385, -5.815, -4.279, -3.166, -4.569, -4.186, -4.09]Step 19 3 visits [1.0, 1.0, 4.0, 7.0, 1.0, 3.0, 2.0]  episode_count: 28 q_vals: [-6.385, -5.815, -4.279, -3.425, -4.569, -4.186, -4.09]Step 20 3 visits [1.0, 1.0, 4.0, 8.0, 1.0, 3.0, 2.0]  episode_count: 29 q_vals: [-6.385, -5.815, -4.279, -3.711, -4.569, -4.186, -4.09]Step 21 4 visits [1.0, 1.0, 4.0, 8.0, 2.0, 3.0, 2.0]  episode_count: 30 q_vals: [-6.385, -5.815, -4.279, -3.711, -5.505, -4.186, -4.09]{"total_number_of_episodes": 32, "number_of_timesteps": 643, "per_episode_reward": 20.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Step 22 6 visits [1.0, 1.0, 4.0, 8.0, 2.0, 3.0, 3.0]  episode_count: 32 q_vals: [-6.385, -5.815, -4.279, -3.711, -5.505, -4.186, -4.695]Step 23 3 visits [1.0, 1.0, 4.0, 9.0, 2.0, 3.0, 3.0]  episode_count: 35 q_vals: [-6.385, -5.815, -4.279, -3.299, -5.505, -4.186, -4.695]Step 24 3 visits [1.0, 1.0, 4.0, 10.0, 2.0, 3.0, 3.0]  episode_count: 37 q_vals: [-6.385, -5.815, -4.279, -3.674, -5.505, -4.186, -4.695]Step 25 3 visits [1.0, 1.0, 4.0, 11.0, 2.0, 3.0, 3.0]  episode_count: 38 q_vals: [-6.385, -5.815, -4.279, -3.34, -5.505, -4.186, -4.695]Step 26 3 visits [1.0, 1.0, 4.0, 12.0, 2.0, 3.0, 3.0]  episode_count: 38 q_vals: [-6.385, -5.815, -4.279, -3.629, -5.505, -4.186, -4.695]Step 27 3 visits [1.0, 1.0, 4.0, 13.0, 2.0, 3.0, 3.0]  episode_count: 41 q_vals: [-6.385, -5.815, -4.279, -3.937, -5.505, -4.186, -4.695]Step 28 5 visits [1.0, 1.0, 4.0, 13.0, 2.0, 4.0, 3.0]  episode_count: 41 q_vals: [-6.385, -5.815, -4.279, -3.937, -5.505, -4.206, -4.695]{"total_number_of_episodes": 44, "number_of_timesteps": 854, "per_episode_reward": 18.64, "episode_reward_trend_value": -0.17857142857142846, "biggest_recent_change": NaN},
Step 29 5 visits [1.0, 1.0, 4.0, 13.0, 2.0, 5.0, 3.0]  episode_count: 44 q_vals: [-6.385, -5.815, -4.279, -3.937, -5.505, -5.347, -4.695]Step 30 2 visits [1.0, 1.0, 5.0, 13.0, 2.0, 5.0, 3.0]  episode_count: 44 q_vals: [-6.385, -5.815, -4.742, -3.937, -5.505, -5.347, -4.695]Step 31 3 visits [1.0, 1.0, 5.0, 14.0, 2.0, 5.0, 3.0]  episode_count: 46 q_vals: [-6.385, -5.815, -4.742, -3.656, -5.505, -5.347, -4.695]Step 32 3 visits [1.0, 1.0, 5.0, 15.0, 2.0, 5.0, 3.0]  episode_count: 48 q_vals: [-6.385, -5.815, -4.742, -3.961, -5.505, -5.347, -4.695]Step 33 3 visits [1.0, 1.0, 5.0, 16.0, 2.0, 5.0, 3.0]  episode_count: 48 q_vals: [-6.385, -5.815, -4.742, -4.202, -5.505, -5.347, -4.695]Step 34 6 visits [1.0, 1.0, 5.0, 16.0, 2.0, 5.0, 4.0]  episode_count: 51 q_vals: [-6.385, -5.815, -4.742, -4.202, -5.505, -5.347, -6.046]Step 35 3 visits [1.0, 1.0, 5.0, 17.0, 2.0, 5.0, 4.0]  episode_count: 51 q_vals: [-6.385, -5.815, -4.742, -4.4, -5.505, -5.347, -6.046]Step 36 2 visits [1.0, 1.0, 6.0, 17.0, 2.0, 5.0, 4.0]  episode_count: 52 q_vals: [-6.385, -5.815, -3.951, -4.4, -5.505, -5.347, -6.046]{"total_number_of_episodes": 54, "number_of_timesteps": 1099, "per_episode_reward": 18.79, "episode_reward_trend_value": -0.08214285714285711, "biggest_recent_change": NaN},
Step 37 2 visits [1.0, 1.0, 7.0, 17.0, 2.0, 5.0, 4.0]  episode_count: 54 q_vals: [-6.385, -5.815, -4.642, -4.4, -5.505, -5.347, -6.046]Step 38 1 visits [1.0, 2.0, 7.0, 17.0, 2.0, 5.0, 4.0]  episode_count: 55 q_vals: [-6.385, -7.25, -4.642, -4.4, -5.505, -5.347, -6.046]Step 39 2 visits [1.0, 2.0, 8.0, 17.0, 2.0, 5.0, 4.0]  episode_count: 57 q_vals: [-6.385, -7.25, -5.131, -4.4, -5.505, -5.347, -6.046]Step 40 3 visits [1.0, 2.0, 8.0, 18.0, 2.0, 5.0, 4.0]  episode_count: 58 q_vals: [-6.385, -7.25, -5.131, -4.773, -5.505, -5.347, -6.046]Step 41 4 visits [1.0, 2.0, 8.0, 18.0, 3.0, 5.0, 4.0]  episode_count: 60 q_vals: [-6.385, -7.25, -5.131, -4.773, -6.661, -5.347, -6.046]Step 42 3 visits [1.0, 2.0, 8.0, 19.0, 3.0, 5.0, 4.0]  episode_count: 61 q_vals: [-6.385, -7.25, -5.131, -4.98, -6.661, -5.347, -6.046]Step 43 2 visits [1.0, 2.0, 9.0, 19.0, 3.0, 5.0, 4.0]  episode_count: 61 q_vals: [-6.385, -7.25, -5.795, -4.98, -6.661, -5.347, -6.046]Step 44 0 visits [2.0, 2.0, 9.0, 19.0, 3.0, 5.0, 4.0]  episode_count: 61 q_vals: [-7.965, -7.25, -5.795, -4.98, -6.661, -5.347, -6.046]{"total_number_of_episodes": 64, "number_of_timesteps": 1351, "per_episode_reward": 19.07, "episode_reward_trend_value": -0.04523809523809514, "biggest_recent_change": NaN},
Step 45 5 visits [2.0, 2.0, 9.0, 19.0, 3.0, 6.0, 4.0]  episode_count: 64 q_vals: [-7.965, -7.25, -5.795, -4.98, -6.661, -6.308, -6.046]Step 46 3 visits [2.0, 2.0, 9.0, 20.0, 3.0, 6.0, 4.0]  episode_count: 65 q_vals: [-7.965, -7.25, -5.795, -5.286, -6.661, -6.308, -6.046]Step 47 3 visits [2.0, 2.0, 9.0, 21.0, 3.0, 6.0, 4.0]  episode_count: 67 q_vals: [-7.965, -7.25, -5.795, -5.564, -6.661, -6.308, -6.046]Step 48 6 visits [2.0, 2.0, 9.0, 21.0, 3.0, 6.0, 5.0]  episode_count: 68 q_vals: [-7.965, -7.25, -5.795, -5.564, -6.661, -6.308, -6.778]Step 49 3 visits [2.0, 2.0, 9.0, 22.0, 3.0, 6.0, 5.0]  episode_count: 70 q_vals: [-7.965, -7.25, -5.795, -5.311, -6.661, -6.308, -6.778]Step 50 3 visits [2.0, 2.0, 9.0, 23.0, 3.0, 6.0, 5.0]  episode_count: 73 q_vals: [-7.965, -7.25, -5.795, -5.08, -6.661, -6.308, -6.778]Step 51 3 visits [2.0, 2.0, 9.0, 24.0, 3.0, 6.0, 5.0]  episode_count: 73 q_vals: [-7.965, -7.25, -5.795, -5.331, -6.661, -6.308, -6.778]{"total_number_of_episodes": 75, "number_of_timesteps": 1594, "per_episode_reward": 19.79, "episode_reward_trend_value": -0.01607142857142856, "biggest_recent_change": NaN},
Step 52 3 visits [2.0, 2.0, 9.0, 25.0, 3.0, 6.0, 5.0]  episode_count: 75 q_vals: [-7.965, -7.25, -5.795, -5.118, -6.661, -6.308, -6.778]Step 53 3 visits [2.0, 2.0, 9.0, 26.0, 3.0, 6.0, 5.0]  episode_count: 75 q_vals: [-7.965, -7.25, -5.795, -5.349, -6.661, -6.308, -6.778]Step 54 3 visits [2.0, 2.0, 9.0, 27.0, 3.0, 6.0, 5.0]  episode_count: 77 q_vals: [-7.965, -7.25, -5.795, -5.555, -6.661, -6.308, -6.778]Step 55 2 visits [2.0, 2.0, 10.0, 27.0, 3.0, 6.0, 5.0]  episode_count: 78 q_vals: [-7.965, -7.25, -6.312, -5.555, -6.661, -6.308, -6.778]Step 56 3 visits [2.0, 2.0, 10.0, 28.0, 3.0, 6.0, 5.0]  episode_count: 80 q_vals: [-7.965, -7.25, -6.312, -5.753, -6.661, -6.308, -6.778]Step 57 3 visits [2.0, 2.0, 10.0, 29.0, 3.0, 6.0, 5.0]  episode_count: 82 q_vals: [-7.965, -7.25, -6.312, -5.555, -6.661, -6.308, -6.778]Step 58 3 visits [2.0, 2.0, 10.0, 30.0, 3.0, 6.0, 5.0]  episode_count: 83 q_vals: [-7.965, -7.25, -6.312, -5.733, -6.661, -6.308, -6.778]{"total_number_of_episodes": 85, "number_of_timesteps": 1809, "per_episode_reward": 19.93, "episode_reward_trend_value": -0.01, "biggest_recent_change": NaN},
Step 59 3 visits [2.0, 2.0, 10.0, 31.0, 3.0, 6.0, 5.0]  episode_count: 85 q_vals: [-7.965, -7.25, -6.312, -5.907, -6.661, -6.308, -6.778]Step 60 5 visits [2.0, 2.0, 10.0, 31.0, 3.0, 7.0, 5.0]  episode_count: 87 q_vals: [-7.965, -7.25, -6.312, -5.907, -6.661, -6.994, -6.778]Step 61 4 visits [2.0, 2.0, 10.0, 31.0, 4.0, 7.0, 5.0]  episode_count: 89 q_vals: [-7.965, -7.25, -6.312, -5.907, -7.773, -6.994, -6.778]Step 62 3 visits [2.0, 2.0, 10.0, 32.0, 4.0, 7.0, 5.0]  episode_count: 91 q_vals: [-7.965, -7.25, -6.312, -6.069, -7.773, -6.994, -6.778]Step 63 2 visits [2.0, 2.0, 11.0, 32.0, 4.0, 7.0, 5.0]  episode_count: 91 q_vals: [-7.965, -7.25, -6.749, -6.069, -7.773, -6.994, -6.778]Step 64 3 visits [2.0, 2.0, 11.0, 33.0, 4.0, 7.0, 5.0]  episode_count: 92 q_vals: [-7.965, -7.25, -6.749, -6.222, -7.773, -6.994, -6.778]{"total_number_of_episodes": 95, "number_of_timesteps": 2028, "per_episode_reward": 19.43, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": NaN},
Step 65 1 visits [2.0, 3.0, 11.0, 33.0, 4.0, 7.0, 5.0]  episode_count: 95 q_vals: [-7.965, -8.537, -6.749, -6.222, -7.773, -6.994, -6.778]Step 66 6 visits [2.0, 3.0, 11.0, 33.0, 4.0, 7.0, 6.0]  episode_count: 96 q_vals: [-7.965, -8.537, -6.749, -6.222, -7.773, -6.994, -5.648]Step 67 6 visits [2.0, 3.0, 11.0, 33.0, 4.0, 7.0, 7.0]  episode_count: 96 q_vals: [-7.965, -8.537, -6.749, -6.222, -7.773, -6.994, -6.429]Step 68 6 visits [2.0, 3.0, 11.0, 33.0, 4.0, 7.0, 8.0]  episode_count: 98 q_vals: [-7.965, -8.537, -6.749, -6.222, -7.773, -6.994, -7.014]Step 69 3 visits [2.0, 3.0, 11.0, 34.0, 4.0, 7.0, 8.0]  episode_count: 101 q_vals: [-7.965, -8.537, -6.749, -6.366, -7.773, -6.994, -7.014]Step 70 3 visits [2.0, 3.0, 11.0, 35.0, 4.0, 7.0, 8.0]  episode_count: 103 q_vals: [-7.965, -8.537, -6.749, -6.502, -7.773, -6.994, -7.014]Step 71 2 visits [2.0, 3.0, 12.0, 35.0, 4.0, 7.0, 8.0]  episode_count: 104 q_vals: [-7.965, -8.537, -7.112, -6.502, -7.773, -6.994, -7.014]{"total_number_of_episodes": 107, "number_of_timesteps": 2267, "per_episode_reward": 19.29, "episode_reward_trend_value": -0.016326530612244892, "biggest_recent_change": NaN},
Step 72 3 visits [2.0, 3.0, 12.0, 36.0, 4.0, 7.0, 8.0]  episode_count: 107 q_vals: [-7.965, -8.537, -7.112, -6.63, -7.773, -6.994, -7.014]Step 73 5 visits [2.0, 3.0, 12.0, 36.0, 4.0, 8.0, 8.0]  episode_count: 107 q_vals: [-7.965, -8.537, -7.112, -6.63, -7.773, -7.509, -7.014]Step 74 6 visits [2.0, 3.0, 12.0, 36.0, 4.0, 8.0, 9.0]  episode_count: 107 q_vals: [-7.965, -8.537, -7.112, -6.63, -7.773, -7.509, -7.469]Step 75 3 visits [2.0, 3.0, 12.0, 37.0, 4.0, 8.0, 9.0]  episode_count: 109 q_vals: [-7.965, -8.537, -7.112, -6.751, -7.773, -7.509, -7.469]Step 76 3 visits [2.0, 3.0, 12.0, 38.0, 4.0, 8.0, 9.0]  episode_count: 114 q_vals: [-7.965, -8.537, -7.112, -6.573, -7.773, -7.509, -7.469]Step 77 3 visits [2.0, 3.0, 12.0, 39.0, 4.0, 8.0, 9.0]  episode_count: 114 q_vals: [-7.965, -8.537, -7.112, -6.689, -7.773, -7.509, -7.469]Step 78 3 visits [2.0, 3.0, 12.0, 40.0, 4.0, 8.0, 9.0]  episode_count: 116 q_vals: [-7.965, -8.537, -7.112, -6.522, -7.773, -7.509, -7.469]{"total_number_of_episodes": 118, "number_of_timesteps": 2473, "per_episode_reward": 19.36, "episode_reward_trend_value": -0.013392857142857118, "biggest_recent_change": NaN},
Step 79 3 visits [2.0, 3.0, 12.0, 41.0, 4.0, 8.0, 9.0]  episode_count: 118 q_vals: [-7.965, -8.537, -7.112, -6.634, -7.773, -7.509, -7.469]Step 80 3 visits [2.0, 3.0, 12.0, 42.0, 4.0, 8.0, 9.0]  episode_count: 119 q_vals: [-7.965, -8.537, -7.112, -6.741, -7.773, -7.509, -7.469]Step 81 3 visits [2.0, 3.0, 12.0, 43.0, 4.0, 8.0, 9.0]  episode_count: 120 q_vals: [-7.965, -8.537, -7.112, -6.584, -7.773, -7.509, -7.469]Step 82 3 visits [2.0, 3.0, 12.0, 44.0, 4.0, 8.0, 9.0]  episode_count: 123 q_vals: [-7.965, -8.537, -7.112, -6.434, -7.773, -7.509, -7.469]Step 83 3 visits [2.0, 3.0, 12.0, 45.0, 4.0, 8.0, 9.0]  episode_count: 124 q_vals: [-7.965, -8.537, -7.112, -6.538, -7.773, -7.509, -7.469]Step 84 3 visits [2.0, 3.0, 12.0, 46.0, 4.0, 8.0, 9.0]  episode_count: 124 q_vals: [-7.965, -8.537, -7.112, -6.638, -7.773, -7.509, -7.469]Step 85 3 visits [2.0, 3.0, 12.0, 47.0, 4.0, 8.0, 9.0]  episode_count: 126 q_vals: [-7.965, -8.537, -7.112, -6.733, -7.773, -7.509, -7.469]{"total_number_of_episodes": 129, "number_of_timesteps": 2703, "per_episode_reward": 19.86, "episode_reward_trend_value": -0.006349206349206327, "biggest_recent_change": 1.7857142857142847},
Step 86 3 visits [2.0, 3.0, 12.0, 48.0, 4.0, 8.0, 9.0]  episode_count: 129 q_vals: [-7.965, -8.537, -7.112, -6.824, -7.773, -7.509, -7.469]Step 87 0 visits [3.0, 3.0, 12.0, 48.0, 4.0, 8.0, 9.0]  episode_count: 129 q_vals: [-9.014, -8.537, -7.112, -6.824, -7.773, -7.509, -7.469]Step 88 2 visits [3.0, 3.0, 13.0, 48.0, 4.0, 8.0, 9.0]  episode_count: 131 q_vals: [-9.014, -8.537, -7.42, -6.824, -7.773, -7.509, -7.469]Step 89 3 visits [3.0, 3.0, 13.0, 49.0, 4.0, 8.0, 9.0]  episode_count: 134 q_vals: [-9.014, -8.537, -7.42, -6.912, -7.773, -7.509, -7.469]Step 90 3 visits [3.0, 3.0, 13.0, 50.0, 4.0, 8.0, 9.0]  episode_count: 135 q_vals: [-9.014, -8.537, -7.42, -6.996, -7.773, -7.509, -7.469]Step 91 3 visits [3.0, 3.0, 13.0, 51.0, 4.0, 8.0, 9.0]  episode_count: 137 q_vals: [-9.014, -8.537, -7.42, -6.858, -7.773, -7.509, -7.469]{"total_number_of_episodes": 141, "number_of_timesteps": 2912, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.0071428571428571366, "biggest_recent_change": 1.8571428571428577},
Step 92 3 visits [3.0, 3.0, 13.0, 52.0, 4.0, 8.0, 9.0]  episode_count: 141 q_vals: [-9.014, -8.537, -7.42, -6.94, -7.773, -7.509, -7.469]Step 93 3 visits [3.0, 3.0, 13.0, 53.0, 4.0, 8.0, 9.0]  episode_count: 142 q_vals: [-9.014, -8.537, -7.42, -6.809, -7.773, -7.509, -7.469]Step 94 3 visits [3.0, 3.0, 13.0, 54.0, 4.0, 8.0, 9.0]  episode_count: 142 q_vals: [-9.014, -8.537, -7.42, -6.889, -7.773, -7.509, -7.469]Step 95 3 visits [3.0, 3.0, 13.0, 55.0, 4.0, 8.0, 9.0]  episode_count: 144 q_vals: [-9.014, -8.537, -7.42, -6.966, -7.773, -7.509, -7.469]Step 96 3 visits [3.0, 3.0, 13.0, 56.0, 4.0, 8.0, 9.0]  episode_count: 146 q_vals: [-9.014, -8.537, -7.42, -6.841, -7.773, -7.509, -7.469]Step 97 3 visits [3.0, 3.0, 13.0, 57.0, 4.0, 8.0, 9.0]  episode_count: 149 q_vals: [-9.014, -8.537, -7.42, -6.916, -7.773, -7.509, -7.469]Step 98 3 visits [3.0, 3.0, 13.0, 58.0, 4.0, 8.0, 9.0]  episode_count: 149 q_vals: [-9.014, -8.537, -7.42, -6.988, -7.773, -7.509, -7.469]Step 99 4 visits [3.0, 3.0, 13.0, 58.0, 5.0, 8.0, 9.0]  episode_count: 149 q_vals: [-9.014, -8.537, -7.42, -6.988, -8.441, -7.509, -7.469]{"total_number_of_episodes": 151, "number_of_timesteps": 3093, "per_episode_reward": 17.07, "episode_reward_trend_value": -0.019047619047619018, "biggest_recent_change": 1.8571428571428577},
Step 100 3 visits [3.0, 3.0, 13.0, 59.0, 5.0, 8.0, 9.0]  episode_count: 151 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -7.509, -7.469]Step 101 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 9.0, 9.0]  episode_count: 153 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -6.674, -7.469]Step 102 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 10.0, 9.0]  episode_count: 156 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -7.118, -7.469]Step 103 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 11.0, 9.0]  episode_count: 159 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -6.471, -7.469]Step 104 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 12.0, 9.0]  episode_count: 159 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -5.932, -7.469]{"total_number_of_episodes": 162, "number_of_timesteps": 3303, "per_episode_reward": 17.86, "episode_reward_trend_value": -0.013492063492063503, "biggest_recent_change": 1.8571428571428577},
Step 105 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 13.0, 9.0]  episode_count: 162 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -5.475, -7.469]Step 106 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 14.0, 9.0]  episode_count: 163 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -5.878, -7.469]Step 107 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 15.0, 9.0]  episode_count: 165 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -6.227, -7.469]Step 108 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 16.0, 9.0]  episode_count: 166 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -6.532, -7.469]Step 109 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 17.0, 9.0]  episode_count: 168 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -6.801, -7.469]Step 110 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 18.0, 9.0]  episode_count: 169 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -7.041, -7.469]{"total_number_of_episodes": 172, "number_of_timesteps": 3492, "per_episode_reward": 18.43, "episode_reward_trend_value": -0.015079365079365085, "biggest_recent_change": 1.8571428571428577},
Step 111 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 19.0, 9.0]  episode_count: 172 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -7.255, -7.469]Step 112 6 visits [3.0, 3.0, 13.0, 59.0, 5.0, 19.0, 10.0]  episode_count: 173 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -7.255, -7.833]Step 113 5 visits [3.0, 3.0, 13.0, 59.0, 5.0, 20.0, 10.0]  episode_count: 176 q_vals: [-9.014, -8.537, -7.42, -7.058, -8.441, -7.448, -7.833]Step 114 3 visits [3.0, 3.0, 13.0, 60.0, 5.0, 20.0, 10.0]  episode_count: 176 q_vals: [-9.014, -8.537, -7.42, -7.126, -8.441, -7.448, -7.833]Step 115 2 visits [3.0, 3.0, 14.0, 60.0, 5.0, 20.0, 10.0]  episode_count: 179 q_vals: [-9.014, -8.537, -7.683, -7.126, -8.441, -7.448, -7.833]Step 116 3 visits [3.0, 3.0, 14.0, 61.0, 5.0, 20.0, 10.0]  episode_count: 180 q_vals: [-9.014, -8.537, -7.683, -7.191, -8.441, -7.448, -7.833]Step 117 3 visits [3.0, 3.0, 14.0, 62.0, 5.0, 20.0, 10.0]  episode_count: 181 q_vals: [-9.014, -8.537, -7.683, -7.254, -8.441, -7.448, -7.833]{"total_number_of_episodes": 185, "number_of_timesteps": 3722, "per_episode_reward": 17.57, "episode_reward_trend_value": -0.02619047619047616, "biggest_recent_change": 1.8571428571428577},
Step 118 5 visits [3.0, 3.0, 14.0, 62.0, 5.0, 21.0, 10.0]  episode_count: 185 q_vals: [-9.014, -8.537, -7.683, -7.254, -8.441, -7.622, -7.833]Step 119 3 visits [3.0, 3.0, 14.0, 63.0, 5.0, 21.0, 10.0]  episode_count: 186 q_vals: [-9.014, -8.537, -7.683, -7.316, -8.441, -7.622, -7.833]Step 120 3 visits [3.0, 3.0, 14.0, 64.0, 5.0, 21.0, 10.0]  episode_count: 188 q_vals: [-9.014, -8.537, -7.683, -7.375, -8.441, -7.622, -7.833]Step 121 2 visits [3.0, 3.0, 15.0, 64.0, 5.0, 21.0, 10.0]  episode_count: 189 q_vals: [-9.014, -8.537, -7.912, -7.375, -8.441, -7.622, -7.833]Step 122 3 visits [3.0, 3.0, 15.0, 65.0, 5.0, 21.0, 10.0]  episode_count: 190 q_vals: [-9.014, -8.537, -7.912, -7.432, -8.441, -7.622, -7.833]Step 123 6 visits [3.0, 3.0, 15.0, 65.0, 5.0, 21.0, 11.0]  episode_count: 190 q_vals: [-9.014, -8.537, -7.912, -7.432, -8.441, -7.622, -8.131]Step 124 5 visits [3.0, 3.0, 15.0, 65.0, 5.0, 22.0, 11.0]  episode_count: 193 q_vals: [-9.014, -8.537, -7.912, -7.432, -8.441, -7.781, -8.131]Step 125 3 visits [3.0, 3.0, 15.0, 66.0, 5.0, 22.0, 11.0]  episode_count: 193 q_vals: [-9.014, -8.537, -7.912, -7.488, -8.441, -7.781, -8.131]{"total_number_of_episodes": 195, "number_of_timesteps": 3902, "per_episode_reward": 17.64, "episode_reward_trend_value": -0.01984126984126983, "biggest_recent_change": 1.8571428571428577},
Step 126 3 visits [3.0, 3.0, 15.0, 67.0, 5.0, 22.0, 11.0]  episode_count: 195 q_vals: [-9.014, -8.537, -7.912, -7.542, -8.441, -7.781, -8.131]Step 127 1 visits [3.0, 4.0, 15.0, 67.0, 5.0, 22.0, 11.0]  episode_count: 197 q_vals: [-9.014, -6.403, -7.912, -7.542, -8.441, -7.781, -8.131]Step 128 1 visits [3.0, 5.0, 15.0, 67.0, 5.0, 22.0, 11.0]  episode_count: 199 q_vals: [-9.014, -7.345, -7.912, -7.542, -8.441, -7.781, -8.131]Step 129 1 visits [3.0, 6.0, 15.0, 67.0, 5.0, 22.0, 11.0]  episode_count: 201 q_vals: [-9.014, -7.972, -7.912, -7.542, -8.441, -7.781, -8.131]Step 130 1 visits [3.0, 7.0, 15.0, 67.0, 5.0, 22.0, 11.0]  episode_count: 202 q_vals: [-9.014, -8.421, -7.912, -7.542, -8.441, -7.781, -8.131]{"total_number_of_episodes": 206, "number_of_timesteps": 4135, "per_episode_reward": 17.93, "episode_reward_trend_value": -0.015079365079365085, "biggest_recent_change": 1.8571428571428577},
Step 131 3 visits [3.0, 7.0, 15.0, 68.0, 5.0, 22.0, 11.0]  episode_count: 206 q_vals: [-9.014, -8.421, -7.912, -7.431, -8.441, -7.781, -8.131]Step 132 3 visits [3.0, 7.0, 15.0, 69.0, 5.0, 22.0, 11.0]  episode_count: 207 q_vals: [-9.014, -8.421, -7.912, -7.485, -8.441, -7.781, -8.131]Step 133 3 visits [3.0, 7.0, 15.0, 70.0, 5.0, 22.0, 11.0]  episode_count: 209 q_vals: [-9.014, -8.421, -7.912, -7.537, -8.441, -7.781, -8.131]Step 134 3 visits [3.0, 7.0, 15.0, 71.0, 5.0, 22.0, 11.0]  episode_count: 210 q_vals: [-9.014, -8.421, -7.912, -7.587, -8.441, -7.781, -8.131]Step 135 5 visits [3.0, 7.0, 15.0, 71.0, 5.0, 23.0, 11.0]  episode_count: 210 q_vals: [-9.014, -8.421, -7.912, -7.587, -8.441, -7.926, -8.131]Step 136 3 visits [3.0, 7.0, 15.0, 72.0, 5.0, 23.0, 11.0]  episode_count: 212 q_vals: [-9.014, -8.421, -7.912, -7.636, -8.441, -7.926, -8.131]Step 137 2 visits [3.0, 7.0, 16.0, 72.0, 5.0, 23.0, 11.0]  episode_count: 213 q_vals: [-9.014, -8.421, -8.112, -7.636, -8.441, -7.926, -8.131]Step 138 3 visits [3.0, 7.0, 16.0, 73.0, 5.0, 23.0, 11.0]  episode_count: 214 q_vals: [-9.014, -8.421, -8.112, -7.683, -8.441, -7.926, -8.131]{"total_number_of_episodes": 216, "number_of_timesteps": 4305, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.017460317460317475, "biggest_recent_change": 1.8571428571428577},
Step 139 3 visits [3.0, 7.0, 16.0, 74.0, 5.0, 23.0, 11.0]  episode_count: 216 q_vals: [-9.014, -8.421, -8.112, -7.73, -8.441, -7.926, -8.131]Step 140 4 visits [3.0, 7.0, 16.0, 74.0, 6.0, 23.0, 11.0]  episode_count: 220 q_vals: [-9.014, -8.421, -8.112, -7.73, -8.886, -7.926, -8.131]Step 141 6 visits [3.0, 7.0, 16.0, 74.0, 6.0, 23.0, 12.0]  episode_count: 222 q_vals: [-9.014, -8.421, -8.112, -7.73, -8.886, -7.926, -8.38]Step 142 5 visits [3.0, 7.0, 16.0, 74.0, 6.0, 24.0, 12.0]  episode_count: 222 q_vals: [-9.014, -8.421, -8.112, -7.73, -8.886, -8.058, -8.38]Step 143 3 visits [3.0, 7.0, 16.0, 75.0, 6.0, 24.0, 12.0]  episode_count: 223 q_vals: [-9.014, -8.421, -8.112, -7.775, -8.886, -8.058, -8.38]{"total_number_of_episodes": 226, "number_of_timesteps": 4529, "per_episode_reward": 17.93, "episode_reward_trend_value": -0.021428571428571453, "biggest_recent_change": 1.8571428571428577},
Step 144 3 visits [3.0, 7.0, 16.0, 76.0, 6.0, 24.0, 12.0]  episode_count: 226 q_vals: [-9.014, -8.421, -8.112, -7.819, -8.886, -8.058, -8.38]Step 145 2 visits [3.0, 7.0, 17.0, 76.0, 6.0, 24.0, 12.0]  episode_count: 228 q_vals: [-9.014, -8.421, -8.288, -7.819, -8.886, -8.058, -8.38]Step 146 3 visits [3.0, 7.0, 17.0, 77.0, 6.0, 24.0, 12.0]  episode_count: 228 q_vals: [-9.014, -8.421, -8.288, -7.861, -8.886, -8.058, -8.38]Step 147 1 visits [3.0, 8.0, 17.0, 77.0, 6.0, 24.0, 12.0]  episode_count: 230 q_vals: [-9.014, -7.368, -8.288, -7.861, -8.886, -8.058, -8.38]Step 148 1 visits [3.0, 9.0, 17.0, 77.0, 6.0, 24.0, 12.0]  episode_count: 233 q_vals: [-9.014, -7.784, -8.288, -7.861, -8.886, -8.058, -8.38]Step 149 1 visits [3.0, 10.0, 17.0, 77.0, 6.0, 24.0, 12.0]  episode_count: 234 q_vals: [-9.014, -7.006, -8.288, -7.861, -8.886, -8.058, -8.38]Step 150 1 visits [3.0, 11.0, 17.0, 77.0, 6.0, 24.0, 12.0]  episode_count: 234 q_vals: [-9.014, -7.379, -8.288, -7.861, -8.886, -8.058, -8.38]{"total_number_of_episodes": 237, "number_of_timesteps": 4731, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.928571428571427},
Step 151 1 visits [3.0, 12.0, 17.0, 77.0, 6.0, 24.0, 12.0]  episode_count: 237 q_vals: [-9.014, -7.69, -8.288, -7.861, -8.886, -8.058, -8.38]Step 152 1 visits [3.0, 13.0, 17.0, 77.0, 6.0, 24.0, 12.0]  episode_count: 240 q_vals: [-9.014, -7.953, -8.288, -7.861, -8.886, -8.058, -8.38]Step 153 1 visits [3.0, 14.0, 17.0, 77.0, 6.0, 24.0, 12.0]  episode_count: 241 q_vals: [-9.014, -8.179, -8.288, -7.861, -8.886, -8.058, -8.38]Step 154 1 visits [3.0, 15.0, 17.0, 77.0, 6.0, 24.0, 12.0]  episode_count: 243 q_vals: [-9.014, -8.374, -8.288, -7.861, -8.886, -8.058, -8.38]Step 155 5 visits [3.0, 15.0, 17.0, 77.0, 6.0, 25.0, 12.0]  episode_count: 243 q_vals: [-9.014, -8.374, -8.288, -7.861, -8.886, -8.181, -8.38]{"total_number_of_episodes": 247, "number_of_timesteps": 4918, "per_episode_reward": 17.93, "episode_reward_trend_value": 0.00952380952380949, "biggest_recent_change": 0.8571428571428541},
Step 156 3 visits [3.0, 15.0, 17.0, 78.0, 6.0, 25.0, 12.0]  episode_count: 247 q_vals: [-9.014, -8.374, -8.288, -7.761, -8.886, -8.181, -8.38]Step 157 3 visits [3.0, 15.0, 17.0, 79.0, 6.0, 25.0, 12.0]  episode_count: 247 q_vals: [-9.014, -8.374, -8.288, -7.803, -8.886, -8.181, -8.38]Step 158 3 visits [3.0, 15.0, 17.0, 80.0, 6.0, 25.0, 12.0]  episode_count: 247 q_vals: [-9.014, -8.374, -8.288, -7.844, -8.886, -8.181, -8.38]Step 159 3 visits [3.0, 15.0, 17.0, 81.0, 6.0, 25.0, 12.0]  episode_count: 250 q_vals: [-9.014, -8.374, -8.288, -7.885, -8.886, -8.181, -8.38]Step 160 3 visits [3.0, 15.0, 17.0, 82.0, 6.0, 25.0, 12.0]  episode_count: 252 q_vals: [-9.014, -8.374, -8.288, -7.924, -8.886, -8.181, -8.38]Step 161 3 visits [3.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 252 q_vals: [-9.014, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 162 0 visits [4.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 255 q_vals: [-6.76, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 163 0 visits [5.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 255 q_vals: [-7.63, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]{"total_number_of_episodes": 258, "number_of_timesteps": 5168, "per_episode_reward": 17.71, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.8571428571428541},
Step 164 0 visits [6.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 258 q_vals: [-6.359, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 165 0 visits [7.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 260 q_vals: [-7.038, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 166 0 visits [8.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 260 q_vals: [-7.547, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 167 0 visits [9.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 262 q_vals: [-7.943, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 168 0 visits [10.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 264 q_vals: [-8.26, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 169 0 visits [11.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 265 q_vals: [-7.509, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 170 0 visits [12.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 266 q_vals: [-7.809, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]{"total_number_of_episodes": 269, "number_of_timesteps": 5391, "per_episode_reward": 17.64, "episode_reward_trend_value": -0.008730158730158718, "biggest_recent_change": 0.8571428571428541},
Step 171 0 visits [13.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 269 q_vals: [-8.063, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 172 0 visits [14.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 270 q_vals: [-8.281, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 173 0 visits [15.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 271 q_vals: [-7.729, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 174 0 visits [16.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 273 q_vals: [-7.94, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 175 0 visits [17.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 275 q_vals: [-8.127, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 176 0 visits [18.0, 15.0, 17.0, 83.0, 6.0, 25.0, 12.0]  episode_count: 275 q_vals: [-8.292, -8.374, -8.288, -7.963, -8.886, -8.181, -8.38]Step 177 3 visits [18.0, 15.0, 17.0, 84.0, 6.0, 25.0, 12.0]  episode_count: 276 q_vals: [-8.292, -8.374, -8.288, -8.0, -8.886, -8.181, -8.38]{"total_number_of_episodes": 279, "number_of_timesteps": 5581, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.2857142857142847},
Step 178 6 visits [18.0, 15.0, 17.0, 84.0, 6.0, 25.0, 13.0]  episode_count: 279 q_vals: [-8.292, -8.374, -8.288, -8.0, -8.886, -8.181, -8.59]Step 179 5 visits [18.0, 15.0, 17.0, 84.0, 6.0, 26.0, 13.0]  episode_count: 280 q_vals: [-8.292, -8.374, -8.288, -8.0, -8.886, -8.293, -8.59]Step 180 2 visits [18.0, 15.0, 18.0, 84.0, 6.0, 26.0, 13.0]  episode_count: 281 q_vals: [-8.292, -8.374, -8.445, -8.0, -8.886, -8.293, -8.59]Step 181 3 visits [18.0, 15.0, 18.0, 85.0, 6.0, 26.0, 13.0]  episode_count: 281 q_vals: [-8.292, -8.374, -8.445, -8.037, -8.886, -8.293, -8.59]Step 182 0 visits [19.0, 15.0, 18.0, 85.0, 6.0, 26.0, 13.0]  episode_count: 282 q_vals: [-8.441, -8.374, -8.445, -8.037, -8.886, -8.293, -8.59]Step 183 1 visits [19.0, 16.0, 18.0, 85.0, 6.0, 26.0, 13.0]  episode_count: 283 q_vals: [-8.441, -8.545, -8.445, -8.037, -8.886, -8.293, -8.59]Step 184 3 visits [19.0, 16.0, 18.0, 86.0, 6.0, 26.0, 13.0]  episode_count: 285 q_vals: [-8.441, -8.545, -8.445, -8.072, -8.886, -8.293, -8.59]Step 185 3 visits [19.0, 16.0, 18.0, 87.0, 6.0, 26.0, 13.0]  episode_count: 288 q_vals: [-8.441, -8.545, -8.445, -8.107, -8.886, -8.293, -8.59]Step 186 5 visits [19.0, 16.0, 18.0, 87.0, 6.0, 27.0, 13.0]  episode_count: 288 q_vals: [-8.441, -8.545, -8.445, -8.107, -8.886, -8.398, -8.59]{"total_number_of_episodes": 290, "number_of_timesteps": 5820, "per_episode_reward": 17.71, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.2857142857142847},
Step 187 3 visits [19.0, 16.0, 18.0, 88.0, 6.0, 27.0, 13.0]  episode_count: 290 q_vals: [-8.441, -8.545, -8.445, -8.141, -8.886, -8.398, -8.59]Step 188 3 visits [19.0, 16.0, 18.0, 89.0, 6.0, 27.0, 13.0]  episode_count: 291 q_vals: [-8.441, -8.545, -8.445, -8.175, -8.886, -8.398, -8.59]Step 189 2 visits [19.0, 16.0, 19.0, 89.0, 6.0, 27.0, 13.0]  episode_count: 292 q_vals: [-8.441, -8.545, -8.585, -8.175, -8.886, -8.398, -8.59]Step 190 0 visits [20.0, 16.0, 19.0, 89.0, 6.0, 27.0, 13.0]  episode_count: 293 q_vals: [-8.574, -8.545, -8.585, -8.175, -8.886, -8.398, -8.59]Step 191 3 visits [20.0, 16.0, 19.0, 90.0, 6.0, 27.0, 13.0]  episode_count: 295 q_vals: [-8.574, -8.545, -8.585, -8.084, -8.886, -8.398, -8.59]Step 192 3 visits [20.0, 16.0, 19.0, 91.0, 6.0, 27.0, 13.0]  episode_count: 298 q_vals: [-8.574, -8.545, -8.585, -8.117, -8.886, -8.398, -8.59]{"total_number_of_episodes": 300, "number_of_timesteps": 6114, "per_episode_reward": 17.79, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571175},
Step 193 3 visits [20.0, 16.0, 19.0, 92.0, 6.0, 27.0, 13.0]  episode_count: 300 q_vals: [-8.574, -8.545, -8.585, -8.15, -8.886, -8.398, -8.59]Step 194 3 visits [20.0, 16.0, 19.0, 93.0, 6.0, 27.0, 13.0]  episode_count: 301 q_vals: [-8.574, -8.545, -8.585, -8.182, -8.886, -8.398, -8.59]Step 195 3 visits [20.0, 16.0, 19.0, 94.0, 6.0, 27.0, 13.0]  episode_count: 303 q_vals: [-8.574, -8.545, -8.585, -8.213, -8.886, -8.398, -8.59]Step 196 4 visits [20.0, 16.0, 19.0, 94.0, 7.0, 27.0, 13.0]  episode_count: 304 q_vals: [-8.574, -8.545, -8.585, -8.213, -9.204, -8.398, -8.59]Step 197 6 visits [20.0, 16.0, 19.0, 94.0, 7.0, 27.0, 14.0]  episode_count: 306 q_vals: [-8.574, -8.545, -8.585, -8.213, -9.204, -8.398, -8.77]Step 198 5 visits [20.0, 16.0, 19.0, 94.0, 7.0, 28.0, 14.0]  episode_count: 308 q_vals: [-8.574, -8.545, -8.585, -8.213, -9.204, -8.495, -8.77]{"total_number_of_episodes": 310, "number_of_timesteps": 6290, "per_episode_reward": 17.71, "episode_reward_trend_value": -0.0007936507936507711, "biggest_recent_change": 0.21428571428571175},
Step 199 1 visits [20.0, 17.0, 19.0, 94.0, 7.0, 28.0, 14.0]  episode_count: 310 q_vals: [-8.574, -8.696, -8.585, -8.213, -9.204, -8.495, -8.77]Step 200 3 visits [20.0, 17.0, 19.0, 95.0, 7.0, 28.0, 14.0]  episode_count: 311 q_vals: [-8.574, -8.696, -8.585, -8.243, -9.204, -8.495, -8.77]Step 201 3 visits [20.0, 17.0, 19.0, 96.0, 7.0, 28.0, 14.0]  episode_count: 314 q_vals: [-8.574, -8.696, -8.585, -8.273, -9.204, -8.495, -8.77]Step 202 3 visits [20.0, 17.0, 19.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 318 q_vals: [-8.574, -8.696, -8.585, -8.302, -9.204, -8.495, -8.77]Step 203 2 visits [20.0, 17.0, 20.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 319 q_vals: [-8.574, -8.696, -8.156, -8.302, -9.204, -8.495, -8.77]{"total_number_of_episodes": 321, "number_of_timesteps": 6450, "per_episode_reward": 17.57, "episode_reward_trend_value": -0.003968253968253935, "biggest_recent_change": 0.21428571428571175},
Step 204 2 visits [20.0, 17.0, 21.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 321 q_vals: [-8.574, -8.696, -8.297, -8.302, -9.204, -8.495, -8.77]Step 205 2 visits [20.0, 17.0, 22.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 323 q_vals: [-8.574, -8.696, -8.425, -8.302, -9.204, -8.495, -8.77]Step 206 2 visits [20.0, 17.0, 23.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 324 q_vals: [-8.574, -8.696, -8.542, -8.302, -9.204, -8.495, -8.77]Step 207 0 visits [21.0, 17.0, 23.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 326 q_vals: [-8.166, -8.696, -8.542, -8.302, -9.204, -8.495, -8.77]Step 208 0 visits [22.0, 17.0, 23.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 329 q_vals: [-8.3, -8.696, -8.542, -8.302, -9.204, -8.495, -8.77]Step 209 0 visits [23.0, 17.0, 23.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 330 q_vals: [-8.422, -8.696, -8.542, -8.302, -9.204, -8.495, -8.77]{"total_number_of_episodes": 334, "number_of_timesteps": 6643, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.21428571428571175},
Step 210 0 visits [24.0, 17.0, 23.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 334 q_vals: [-8.071, -8.696, -8.542, -8.302, -9.204, -8.495, -8.77]Step 211 0 visits [25.0, 17.0, 23.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 336 q_vals: [-8.193, -8.696, -8.542, -8.302, -9.204, -8.495, -8.77]Step 212 0 visits [26.0, 17.0, 23.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 336 q_vals: [-8.305, -8.696, -8.542, -8.302, -9.204, -8.495, -8.77]Step 213 0 visits [27.0, 17.0, 23.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 339 q_vals: [-8.409, -8.696, -8.542, -8.302, -9.204, -8.495, -8.77]Step 214 0 visits [28.0, 17.0, 23.0, 97.0, 7.0, 28.0, 14.0]  episode_count: 340 q_vals: [-8.505, -8.696, -8.542, -8.302, -9.204, -8.495, -8.77]Step 215 5 visits [28.0, 17.0, 23.0, 97.0, 7.0, 29.0, 14.0]  episode_count: 343 q_vals: [-8.505, -8.696, -8.542, -8.302, -9.204, -8.585, -8.77]{"total_number_of_episodes": 345, "number_of_timesteps": 6813, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.0071428571428571366, "biggest_recent_change": 0.2142857142857153},
Step 216 2 visits [28.0, 17.0, 24.0, 97.0, 7.0, 29.0, 14.0]  episode_count: 345 q_vals: [-8.505, -8.696, -8.649, -8.302, -9.204, -8.585, -8.77]Step 217 3 visits [28.0, 17.0, 24.0, 98.0, 7.0, 29.0, 14.0]  episode_count: 345 q_vals: [-8.505, -8.696, -8.649, -8.331, -9.204, -8.585, -8.77]Step 218 0 visits [29.0, 17.0, 24.0, 98.0, 7.0, 29.0, 14.0]  episode_count: 346 q_vals: [-8.595, -8.696, -8.649, -8.331, -9.204, -8.585, -8.77]Step 219 3 visits [29.0, 17.0, 24.0, 99.0, 7.0, 29.0, 14.0]  episode_count: 351 q_vals: [-8.595, -8.696, -8.649, -8.359, -9.204, -8.585, -8.77]Step 220 3 visits [29.0, 17.0, 24.0, 100.0, 7.0, 29.0, 14.0]  episode_count: 352 q_vals: [-8.595, -8.696, -8.649, -8.387, -9.204, -8.585, -8.77]Step 221 1 visits [29.0, 18.0, 24.0, 100.0, 7.0, 29.0, 14.0]  episode_count: 353 q_vals: [-8.595, -8.83, -8.649, -8.387, -9.204, -8.585, -8.77]{"total_number_of_episodes": 357, "number_of_timesteps": 6999, "per_episode_reward": 17.14, "episode_reward_trend_value": -0.006349206349206366, "biggest_recent_change": 0.2142857142857153},
Step 222 6 visits [29.0, 18.0, 24.0, 100.0, 7.0, 29.0, 15.0]  episode_count: 357 q_vals: [-8.595, -8.83, -8.649, -8.387, -9.204, -8.585, -8.926]Step 223 5 visits [29.0, 18.0, 24.0, 100.0, 7.0, 30.0, 15.0]  episode_count: 358 q_vals: [-8.595, -8.83, -8.649, -8.387, -9.204, -8.669, -8.926]Step 224 3 visits [29.0, 18.0, 24.0, 101.0, 7.0, 30.0, 15.0]  episode_count: 360 q_vals: [-8.595, -8.83, -8.649, -8.414, -9.204, -8.669, -8.926]Step 225 0 visits [30.0, 18.0, 24.0, 101.0, 7.0, 30.0, 15.0]  episode_count: 361 q_vals: [-8.309, -8.83, -8.649, -8.414, -9.204, -8.669, -8.926]Step 226 0 visits [31.0, 18.0, 24.0, 101.0, 7.0, 30.0, 15.0]  episode_count: 364 q_vals: [-8.399, -8.83, -8.649, -8.414, -9.204, -8.669, -8.926]Step 227 0 visits [32.0, 18.0, 24.0, 101.0, 7.0, 30.0, 15.0]  episode_count: 365 q_vals: [-8.484, -8.83, -8.649, -8.414, -9.204, -8.669, -8.926]Step 228 0 visits [33.0, 18.0, 24.0, 101.0, 7.0, 30.0, 15.0]  episode_count: 366 q_vals: [-8.564, -8.83, -8.649, -8.414, -9.204, -8.669, -8.926]{"total_number_of_episodes": 369, "number_of_timesteps": 7196, "per_episode_reward": 17.14, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.2142857142857153},
Step 229 0 visits [34.0, 18.0, 24.0, 101.0, 7.0, 30.0, 15.0]  episode_count: 369 q_vals: [-8.638, -8.83, -8.649, -8.414, -9.204, -8.669, -8.926]Step 230 2 visits [34.0, 18.0, 25.0, 101.0, 7.0, 30.0, 15.0]  episode_count: 371 q_vals: [-8.638, -8.83, -8.303, -8.414, -9.204, -8.669, -8.926]Step 231 2 visits [34.0, 18.0, 26.0, 101.0, 7.0, 30.0, 15.0]  episode_count: 371 q_vals: [-8.638, -8.83, -8.411, -8.414, -9.204, -8.669, -8.926]Step 232 2 visits [34.0, 18.0, 27.0, 101.0, 7.0, 30.0, 15.0]  episode_count: 372 q_vals: [-8.638, -8.83, -8.511, -8.414, -9.204, -8.669, -8.926]Step 233 2 visits [34.0, 18.0, 28.0, 101.0, 7.0, 30.0, 15.0]  episode_count: 376 q_vals: [-8.638, -8.83, -8.604, -8.414, -9.204, -8.669, -8.926]Step 234 2 visits [34.0, 18.0, 29.0, 101.0, 7.0, 30.0, 15.0]  episode_count: 376 q_vals: [-8.638, -8.83, -8.69, -8.414, -9.204, -8.669, -8.926]Step 235 3 visits [34.0, 18.0, 29.0, 102.0, 7.0, 30.0, 15.0]  episode_count: 378 q_vals: [-8.638, -8.83, -8.69, -8.331, -9.204, -8.669, -8.926]Step 236 3 visits [34.0, 18.0, 29.0, 103.0, 7.0, 30.0, 15.0]  episode_count: 378 q_vals: [-8.638, -8.83, -8.69, -8.358, -9.204, -8.669, -8.926]{"total_number_of_episodes": 380, "number_of_timesteps": 7400, "per_episode_reward": 17.07, "episode_reward_trend_value": -0.0071428571428571366, "biggest_recent_change": 0.2142857142857153},
Step 237 3 visits [34.0, 18.0, 29.0, 104.0, 7.0, 30.0, 15.0]  episode_count: 380 q_vals: [-8.638, -8.83, -8.69, -8.385, -9.204, -8.669, -8.926]Step 238 3 visits [34.0, 18.0, 29.0, 105.0, 7.0, 30.0, 15.0]  episode_count: 383 q_vals: [-8.638, -8.83, -8.69, -8.411, -9.204, -8.669, -8.926]Step 239 3 visits [34.0, 18.0, 29.0, 106.0, 7.0, 30.0, 15.0]  episode_count: 384 q_vals: [-8.638, -8.83, -8.69, -8.331, -9.204, -8.669, -8.926]Step 240 3 visits [34.0, 18.0, 29.0, 107.0, 7.0, 30.0, 15.0]  episode_count: 385 q_vals: [-8.638, -8.83, -8.69, -8.357, -9.204, -8.669, -8.926]Step 241 3 visits [34.0, 18.0, 29.0, 108.0, 7.0, 30.0, 15.0]  episode_count: 388 q_vals: [-8.638, -8.83, -8.69, -8.383, -9.204, -8.669, -8.926]Step 242 3 visits [34.0, 18.0, 29.0, 109.0, 7.0, 30.0, 15.0]  episode_count: 389 q_vals: [-8.638, -8.83, -8.69, -8.408, -9.204, -8.669, -8.926]{"total_number_of_episodes": 390, "number_of_timesteps": 7636, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
Step 243 3 visits [34.0, 18.0, 29.0, 110.0, 7.0, 30.0, 15.0]  episode_count: 390 q_vals: [-8.638, -8.83, -8.69, -8.432, -9.204, -8.669, -8.926]Step 244 3 visits [34.0, 18.0, 29.0, 111.0, 7.0, 30.0, 15.0]  episode_count: 393 q_vals: [-8.638, -8.83, -8.69, -8.456, -9.204, -8.669, -8.926]Step 245 3 visits [34.0, 18.0, 29.0, 112.0, 7.0, 30.0, 15.0]  episode_count: 395 q_vals: [-8.638, -8.83, -8.69, -8.48, -9.204, -8.669, -8.926]Step 246 0 visits [35.0, 18.0, 29.0, 112.0, 7.0, 30.0, 15.0]  episode_count: 396 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.669, -8.926]Step 247 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 31.0, 15.0]  episode_count: 398 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.389, -8.926]Step 248 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 32.0, 15.0]  episode_count: 399 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.474, -8.926]{"total_number_of_episodes": 400, "number_of_timesteps": 7806, "per_episode_reward": 17.29, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.2142857142857153},
Step 249 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 33.0, 15.0]  episode_count: 400 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.554, -8.926]Step 250 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 34.0, 15.0]  episode_count: 403 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.303, -8.926]Step 251 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 35.0, 15.0]  episode_count: 405 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.383, -8.926]Step 252 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 36.0, 15.0]  episode_count: 407 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.459, -8.926]{"total_number_of_episodes": 410, "number_of_timesteps": 7982, "per_episode_reward": 17.36, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
Step 253 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 37.0, 15.0]  episode_count: 410 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.23, -8.926]Step 254 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 38.0, 15.0]  episode_count: 412 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.014, -8.926]Step 255 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 39.0, 15.0]  episode_count: 413 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.093, -8.926]Step 256 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 40.0, 15.0]  episode_count: 416 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.168, -8.926]Step 257 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 41.0, 15.0]  episode_count: 417 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.24, -8.926]Step 258 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 42.0, 15.0]  episode_count: 419 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.309, -8.926]Step 259 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 43.0, 15.0]  episode_count: 419 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.374, -8.926]{"total_number_of_episodes": 421, "number_of_timesteps": 8140, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.006349206349206366, "biggest_recent_change": 0.35714285714285765},
Step 260 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 44.0, 15.0]  episode_count: 421 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.436, -8.926]Step 261 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 45.0, 15.0]  episode_count: 423 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.495, -8.926]Step 262 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 46.0, 15.0]  episode_count: 426 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.552, -8.926]Step 263 5 visits [35.0, 18.0, 29.0, 112.0, 7.0, 47.0, 15.0]  episode_count: 427 q_vals: [-8.709, -8.83, -8.69, -8.48, -9.204, -8.607, -8.926]Step 264 2 visits [35.0, 18.0, 30.0, 112.0, 7.0, 47.0, 15.0]  episode_count: 428 q_vals: [-8.709, -8.83, -8.771, -8.48, -9.204, -8.607, -8.926]Step 265 3 visits [35.0, 18.0, 30.0, 113.0, 7.0, 47.0, 15.0]  episode_count: 430 q_vals: [-8.709, -8.83, -8.771, -8.503, -9.204, -8.607, -8.926]{"total_number_of_episodes": 433, "number_of_timesteps": 8368, "per_episode_reward": 16.86, "episode_reward_trend_value": -0.0071428571428571366, "biggest_recent_change": 0.35714285714285765},
Step 266 5 visits [35.0, 18.0, 30.0, 113.0, 7.0, 48.0, 15.0]  episode_count: 433 q_vals: [-8.709, -8.83, -8.771, -8.503, -9.204, -8.659, -8.926]Step 267 1 visits [35.0, 19.0, 30.0, 113.0, 7.0, 48.0, 15.0]  episode_count: 435 q_vals: [-8.709, -8.366, -8.771, -8.503, -9.204, -8.659, -8.926]Step 268 1 visits [35.0, 20.0, 30.0, 113.0, 7.0, 48.0, 15.0]  episode_count: 435 q_vals: [-8.709, -8.503, -8.771, -8.503, -9.204, -8.659, -8.926]Step 269 1 visits [35.0, 21.0, 30.0, 113.0, 7.0, 48.0, 15.0]  episode_count: 436 q_vals: [-8.709, -8.627, -8.771, -8.503, -9.204, -8.659, -8.926]Step 270 1 visits [35.0, 22.0, 30.0, 113.0, 7.0, 48.0, 15.0]  episode_count: 438 q_vals: [-8.709, -8.74, -8.771, -8.503, -9.204, -8.659, -8.926]Step 271 1 visits [35.0, 23.0, 30.0, 113.0, 7.0, 48.0, 15.0]  episode_count: 439 q_vals: [-8.709, -8.843, -8.771, -8.503, -9.204, -8.659, -8.926]Step 272 3 visits [35.0, 23.0, 30.0, 114.0, 7.0, 48.0, 15.0]  episode_count: 440 q_vals: [-8.709, -8.843, -8.771, -8.526, -9.204, -8.659, -8.926]Step 273 3 visits [35.0, 23.0, 30.0, 115.0, 7.0, 48.0, 15.0]  episode_count: 441 q_vals: [-8.709, -8.843, -8.771, -8.452, -9.204, -8.659, -8.926]Step 274 3 visits [35.0, 23.0, 30.0, 116.0, 7.0, 48.0, 15.0]  episode_count: 442 q_vals: [-8.709, -8.843, -8.771, -8.475, -9.204, -8.659, -8.926]{"total_number_of_episodes": 445, "number_of_timesteps": 8640, "per_episode_reward": 16.79, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.35714285714285765},
Step 275 3 visits [35.0, 23.0, 30.0, 117.0, 7.0, 48.0, 15.0]  episode_count: 445 q_vals: [-8.709, -8.843, -8.771, -8.498, -9.204, -8.659, -8.926]Step 276 3 visits [35.0, 23.0, 30.0, 118.0, 7.0, 48.0, 15.0]  episode_count: 448 q_vals: [-8.709, -8.843, -8.771, -8.52, -9.204, -8.659, -8.926]Step 277 3 visits [35.0, 23.0, 30.0, 119.0, 7.0, 48.0, 15.0]  episode_count: 448 q_vals: [-8.709, -8.843, -8.771, -8.542, -9.204, -8.659, -8.926]Step 278 4 visits [35.0, 23.0, 30.0, 119.0, 8.0, 48.0, 15.0]  episode_count: 450 q_vals: [-8.709, -8.843, -8.771, -8.542, -9.442, -8.659, -8.926]Step 279 0 visits [36.0, 23.0, 30.0, 119.0, 8.0, 48.0, 15.0]  episode_count: 451 q_vals: [-8.776, -8.843, -8.771, -8.542, -9.442, -8.659, -8.926]Step 280 6 visits [36.0, 23.0, 30.0, 119.0, 8.0, 48.0, 16.0]  episode_count: 452 q_vals: [-8.776, -8.843, -8.771, -8.542, -9.442, -8.659, -9.063]Step 281 5 visits [36.0, 23.0, 30.0, 119.0, 8.0, 49.0, 16.0]  episode_count: 454 q_vals: [-8.776, -8.843, -8.771, -8.542, -9.442, -8.709, -9.063]{"total_number_of_episodes": 456, "number_of_timesteps": 8853, "per_episode_reward": 16.79, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.35714285714285765},
Step 282 3 visits [36.0, 23.0, 30.0, 120.0, 8.0, 49.0, 16.0]  episode_count: 456 q_vals: [-8.776, -8.843, -8.771, -8.563, -9.442, -8.709, -9.063]Step 283 2 visits [36.0, 23.0, 31.0, 120.0, 8.0, 49.0, 16.0]  episode_count: 456 q_vals: [-8.776, -8.843, -8.846, -8.563, -9.442, -8.709, -9.063]Step 284 3 visits [36.0, 23.0, 31.0, 121.0, 8.0, 49.0, 16.0]  episode_count: 458 q_vals: [-8.776, -8.843, -8.846, -8.584, -9.442, -8.709, -9.063]Step 285 1 visits [36.0, 24.0, 31.0, 121.0, 8.0, 49.0, 16.0]  episode_count: 460 q_vals: [-8.776, -8.938, -8.846, -8.584, -9.442, -8.709, -9.063]Step 286 3 visits [36.0, 24.0, 31.0, 122.0, 8.0, 49.0, 16.0]  episode_count: 461 q_vals: [-8.776, -8.938, -8.846, -8.605, -9.442, -8.709, -9.063]Step 287 5 visits [36.0, 24.0, 31.0, 122.0, 8.0, 50.0, 16.0]  episode_count: 463 q_vals: [-8.776, -8.938, -8.846, -8.605, -9.442, -8.757, -9.063]Step 288 0 visits [37.0, 24.0, 31.0, 122.0, 8.0, 50.0, 16.0]  episode_count: 464 q_vals: [-8.839, -8.938, -8.846, -8.605, -9.442, -8.757, -9.063]{"total_number_of_episodes": 468, "number_of_timesteps": 9102, "per_episode_reward": 16.86, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.35714285714285765},
Step 289 3 visits [37.0, 24.0, 31.0, 123.0, 8.0, 50.0, 16.0]  episode_count: 468 q_vals: [-8.839, -8.938, -8.846, -8.625, -9.442, -8.757, -9.063]Step 290 3 visits [37.0, 24.0, 31.0, 124.0, 8.0, 50.0, 16.0]  episode_count: 469 q_vals: [-8.839, -8.938, -8.846, -8.645, -9.442, -8.757, -9.063]Step 291 2 visits [37.0, 24.0, 32.0, 124.0, 8.0, 50.0, 16.0]  episode_count: 472 q_vals: [-8.839, -8.938, -8.917, -8.645, -9.442, -8.757, -9.063]Step 292 5 visits [37.0, 24.0, 32.0, 124.0, 8.0, 51.0, 16.0]  episode_count: 472 q_vals: [-8.839, -8.938, -8.917, -8.645, -9.442, -8.803, -9.063]Step 293 3 visits [37.0, 24.0, 32.0, 125.0, 8.0, 51.0, 16.0]  episode_count: 473 q_vals: [-8.839, -8.938, -8.917, -8.576, -9.442, -8.803, -9.063]Step 294 3 visits [37.0, 24.0, 32.0, 126.0, 8.0, 51.0, 16.0]  episode_count: 476 q_vals: [-8.839, -8.938, -8.917, -8.596, -9.442, -8.803, -9.063]{"total_number_of_episodes": 478, "number_of_timesteps": 9255, "per_episode_reward": 16.86, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.35714285714285765},
Step 295 3 visits [37.0, 24.0, 32.0, 127.0, 8.0, 51.0, 16.0]  episode_count: 478 q_vals: [-8.839, -8.938, -8.917, -8.616, -9.442, -8.803, -9.063]Step 296 3 visits [37.0, 24.0, 32.0, 128.0, 8.0, 51.0, 16.0]  episode_count: 480 q_vals: [-8.839, -8.938, -8.917, -8.635, -9.442, -8.803, -9.063]Step 297 3 visits [37.0, 24.0, 32.0, 129.0, 8.0, 51.0, 16.0]  episode_count: 483 q_vals: [-8.839, -8.938, -8.917, -8.655, -9.442, -8.803, -9.063]Step 298 3 visits [37.0, 24.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 486 q_vals: [-8.839, -8.938, -8.917, -8.674, -9.442, -8.803, -9.063]Step 299 0 visits [38.0, 24.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 487 q_vals: [-8.899, -8.938, -8.917, -8.674, -9.442, -8.803, -9.063]{"total_number_of_episodes": 489, "number_of_timesteps": 9437, "per_episode_reward": 16.79, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.35714285714285765},
Step 300 1 visits [38.0, 25.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 489 q_vals: [-8.899, -8.58, -8.917, -8.674, -9.442, -8.803, -9.063]Step 301 1 visits [38.0, 26.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 491 q_vals: [-8.899, -8.677, -8.917, -8.674, -9.442, -8.803, -9.063]Step 302 1 visits [38.0, 27.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 493 q_vals: [-8.899, -8.768, -8.917, -8.674, -9.442, -8.803, -9.063]Step 303 1 visits [38.0, 28.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 494 q_vals: [-8.899, -8.454, -8.917, -8.674, -9.442, -8.803, -9.063]Step 304 1 visits [38.0, 29.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 497 q_vals: [-8.899, -8.546, -8.917, -8.674, -9.442, -8.803, -9.063]Step 305 1 visits [38.0, 30.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 498 q_vals: [-8.899, -8.631, -8.917, -8.674, -9.442, -8.803, -9.063]Step 306 1 visits [38.0, 31.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 498 q_vals: [-8.899, -8.711, -8.917, -8.674, -9.442, -8.803, -9.063]{"total_number_of_episodes": 499, "number_of_timesteps": 9592, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.009523809523809528, "biggest_recent_change": 0.35714285714285765},
Step 307 1 visits [38.0, 32.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 499 q_vals: [-8.899, -8.786, -8.917, -8.674, -9.442, -8.803, -9.063]Step 308 1 visits [38.0, 33.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 502 q_vals: [-8.899, -8.857, -8.917, -8.674, -9.442, -8.803, -9.063]Step 309 1 visits [38.0, 34.0, 32.0, 130.0, 8.0, 51.0, 16.0]  episode_count: 504 q_vals: [-8.899, -8.923, -8.917, -8.674, -9.442, -8.803, -9.063]Step 310 3 visits [38.0, 34.0, 32.0, 131.0, 8.0, 51.0, 16.0]  episode_count: 504 q_vals: [-8.899, -8.923, -8.917, -8.692, -9.442, -8.803, -9.063]Step 311 6 visits [38.0, 34.0, 32.0, 131.0, 8.0, 51.0, 17.0]  episode_count: 507 q_vals: [-8.899, -8.923, -8.917, -8.692, -9.442, -8.803, -9.183]{"total_number_of_episodes": 509, "number_of_timesteps": 9821, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.01031746031746034, "biggest_recent_change": 0.35714285714285765},
Step 312 5 visits [38.0, 34.0, 32.0, 131.0, 8.0, 52.0, 17.0]  episode_count: 509 q_vals: [-8.899, -8.923, -8.917, -8.692, -9.442, -8.847, -9.183]Step 313 3 visits [38.0, 34.0, 32.0, 132.0, 8.0, 52.0, 17.0]  episode_count: 510 q_vals: [-8.899, -8.923, -8.917, -8.71, -9.442, -8.847, -9.183]Step 314 2 visits [38.0, 34.0, 33.0, 132.0, 8.0, 52.0, 17.0]  episode_count: 511 q_vals: [-8.899, -8.923, -8.984, -8.71, -9.442, -8.847, -9.183]Step 315 3 visits [38.0, 34.0, 33.0, 133.0, 8.0, 52.0, 17.0]  episode_count: 514 q_vals: [-8.899, -8.923, -8.984, -8.728, -9.442, -8.847, -9.183]Step 316 0 visits [39.0, 34.0, 33.0, 133.0, 8.0, 52.0, 17.0]  episode_count: 515 q_vals: [-8.671, -8.923, -8.984, -8.728, -9.442, -8.847, -9.183]Step 317 0 visits [40.0, 34.0, 33.0, 133.0, 8.0, 52.0, 17.0]  episode_count: 515 q_vals: [-8.732, -8.923, -8.984, -8.728, -9.442, -8.847, -9.183]Step 318 0 visits [41.0, 34.0, 33.0, 133.0, 8.0, 52.0, 17.0]  episode_count: 517 q_vals: [-8.79, -8.923, -8.984, -8.728, -9.442, -8.847, -9.183]Step 319 0 visits [42.0, 34.0, 33.0, 133.0, 8.0, 52.0, 17.0]  episode_count: 518 q_vals: [-8.845, -8.923, -8.984, -8.728, -9.442, -8.847, -9.183]{"total_number_of_episodes": 519, "number_of_timesteps": 10030, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.006349206349206366, "biggest_recent_change": 0.35714285714285765},
Step 320 0 visits [43.0, 34.0, 33.0, 133.0, 8.0, 52.0, 17.0]  episode_count: 519 q_vals: [-8.898, -8.923, -8.984, -8.728, -9.442, -8.847, -9.183]Step 321 1 visits [43.0, 35.0, 33.0, 133.0, 8.0, 52.0, 17.0]  episode_count: 520 q_vals: [-8.898, -8.986, -8.984, -8.728, -9.442, -8.847, -9.183]Step 322 5 visits [43.0, 35.0, 33.0, 133.0, 8.0, 53.0, 17.0]  episode_count: 521 q_vals: [-8.898, -8.986, -8.984, -8.728, -9.442, -8.89, -9.183]Step 323 3 visits [43.0, 35.0, 33.0, 134.0, 8.0, 53.0, 17.0]  episode_count: 522 q_vals: [-8.898, -8.986, -8.984, -8.746, -9.442, -8.89, -9.183]Step 324 0 visits [44.0, 35.0, 33.0, 134.0, 8.0, 53.0, 17.0]  episode_count: 523 q_vals: [-8.948, -8.986, -8.984, -8.746, -9.442, -8.89, -9.183]Step 325 3 visits [44.0, 35.0, 33.0, 135.0, 8.0, 53.0, 17.0]  episode_count: 526 q_vals: [-8.948, -8.986, -8.984, -8.764, -9.442, -8.89, -9.183]Step 326 3 visits [44.0, 35.0, 33.0, 136.0, 8.0, 53.0, 17.0]  episode_count: 526 q_vals: [-8.948, -8.986, -8.984, -8.781, -9.442, -8.89, -9.183]Step 327 5 visits [44.0, 35.0, 33.0, 136.0, 8.0, 54.0, 17.0]  episode_count: 527 q_vals: [-8.948, -8.986, -8.984, -8.781, -9.442, -8.931, -9.183]{"total_number_of_episodes": 529, "number_of_timesteps": 10325, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.004761904761904785, "biggest_recent_change": 0.35714285714285765},
Step 328 2 visits [44.0, 35.0, 34.0, 136.0, 8.0, 54.0, 17.0]  episode_count: 529 q_vals: [-8.948, -8.986, -9.046, -8.781, -9.442, -8.931, -9.183]Step 329 3 visits [44.0, 35.0, 34.0, 137.0, 8.0, 54.0, 17.0]  episode_count: 530 q_vals: [-8.948, -8.986, -9.046, -8.717, -9.442, -8.931, -9.183]Step 330 3 visits [44.0, 35.0, 34.0, 138.0, 8.0, 54.0, 17.0]  episode_count: 531 q_vals: [-8.948, -8.986, -9.046, -8.654, -9.442, -8.931, -9.183]Step 331 3 visits [44.0, 35.0, 34.0, 139.0, 8.0, 54.0, 17.0]  episode_count: 534 q_vals: [-8.948, -8.986, -9.046, -8.671, -9.442, -8.931, -9.183]Step 332 3 visits [44.0, 35.0, 34.0, 140.0, 8.0, 54.0, 17.0]  episode_count: 535 q_vals: [-8.948, -8.986, -9.046, -8.61, -9.442, -8.931, -9.183]Step 333 3 visits [44.0, 35.0, 34.0, 141.0, 8.0, 54.0, 17.0]  episode_count: 535 q_vals: [-8.948, -8.986, -9.046, -8.627, -9.442, -8.931, -9.183]Step 334 3 visits [44.0, 35.0, 34.0, 142.0, 8.0, 54.0, 17.0]  episode_count: 535 q_vals: [-8.948, -8.986, -9.046, -8.645, -9.442, -8.931, -9.183]Step 335 3 visits [44.0, 35.0, 34.0, 143.0, 8.0, 54.0, 17.0]  episode_count: 537 q_vals: [-8.948, -8.986, -9.046, -8.662, -9.442, -8.931, -9.183]{"total_number_of_episodes": 540, "number_of_timesteps": 10589, "per_episode_reward": 16.64, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.35714285714285765},
Step 336 3 visits [44.0, 35.0, 34.0, 144.0, 8.0, 54.0, 17.0]  episode_count: 540 q_vals: [-8.948, -8.986, -9.046, -8.679, -9.442, -8.931, -9.183]Step 337 3 visits [44.0, 35.0, 34.0, 145.0, 8.0, 54.0, 17.0]  episode_count: 542 q_vals: [-8.948, -8.986, -9.046, -8.696, -9.442, -8.931, -9.183]Step 338 3 visits [44.0, 35.0, 34.0, 146.0, 8.0, 54.0, 17.0]  episode_count: 544 q_vals: [-8.948, -8.986, -9.046, -8.712, -9.442, -8.931, -9.183]Step 339 3 visits [44.0, 35.0, 34.0, 147.0, 8.0, 54.0, 17.0]  episode_count: 545 q_vals: [-8.948, -8.986, -9.046, -8.729, -9.442, -8.931, -9.183]Step 340 3 visits [44.0, 35.0, 34.0, 148.0, 8.0, 54.0, 17.0]  episode_count: 547 q_vals: [-8.948, -8.986, -9.046, -8.745, -9.442, -8.931, -9.183]{"total_number_of_episodes": 550, "number_of_timesteps": 10773, "per_episode_reward": 16.79, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.35714285714285765},
Step 341 3 visits [44.0, 35.0, 34.0, 149.0, 8.0, 54.0, 17.0]  episode_count: 550 q_vals: [-8.948, -8.986, -9.046, -8.761, -9.442, -8.931, -9.183]Step 342 3 visits [44.0, 35.0, 34.0, 150.0, 8.0, 54.0, 17.0]  episode_count: 550 q_vals: [-8.948, -8.986, -9.046, -8.776, -9.442, -8.931, -9.183]Step 343 1 visits [44.0, 36.0, 34.0, 150.0, 8.0, 54.0, 17.0]  episode_count: 550 q_vals: [-8.948, -9.045, -9.046, -8.776, -9.442, -8.931, -9.183]Step 344 3 visits [44.0, 36.0, 34.0, 151.0, 8.0, 54.0, 17.0]  episode_count: 555 q_vals: [-8.948, -9.045, -9.046, -8.792, -9.442, -8.931, -9.183]Step 345 0 visits [45.0, 36.0, 34.0, 151.0, 8.0, 54.0, 17.0]  episode_count: 555 q_vals: [-8.996, -9.045, -9.046, -8.792, -9.442, -8.931, -9.183]Step 346 4 visits [45.0, 36.0, 34.0, 151.0, 9.0, 54.0, 17.0]  episode_count: 558 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.393, -8.931, -9.183]Step 347 4 visits [45.0, 36.0, 34.0, 151.0, 10.0, 54.0, 17.0]  episode_count: 559 q_vals: [-8.996, -9.045, -9.046, -8.792, -7.554, -8.931, -9.183]{"total_number_of_episodes": 560, "number_of_timesteps": 10954, "per_episode_reward": 16.43, "episode_reward_trend_value": -0.004761904761904785, "biggest_recent_change": 0.35714285714285765},
Step 348 4 visits [45.0, 36.0, 34.0, 151.0, 11.0, 54.0, 17.0]  episode_count: 560 q_vals: [-8.996, -9.045, -9.046, -8.792, -7.877, -8.931, -9.183]Step 349 4 visits [45.0, 36.0, 34.0, 151.0, 12.0, 54.0, 17.0]  episode_count: 561 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.147, -8.931, -9.183]Step 350 4 visits [45.0, 36.0, 34.0, 151.0, 13.0, 54.0, 17.0]  episode_count: 565 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.375, -8.931, -9.183]Step 351 4 visits [45.0, 36.0, 34.0, 151.0, 14.0, 54.0, 17.0]  episode_count: 566 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.57, -8.931, -9.183]Step 352 4 visits [45.0, 36.0, 34.0, 151.0, 15.0, 54.0, 17.0]  episode_count: 566 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.74, -8.931, -9.183]Step 353 4 visits [45.0, 36.0, 34.0, 151.0, 16.0, 54.0, 17.0]  episode_count: 568 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.888, -8.931, -9.183]{"total_number_of_episodes": 570, "number_of_timesteps": 11158, "per_episode_reward": 16.71, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.35714285714285765},
Step 354 4 visits [45.0, 36.0, 34.0, 151.0, 17.0, 54.0, 17.0]  episode_count: 570 q_vals: [-8.996, -9.045, -9.046, -8.792, -9.019, -8.931, -9.183]Step 355 4 visits [45.0, 36.0, 34.0, 151.0, 18.0, 54.0, 17.0]  episode_count: 572 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.518, -8.931, -9.183]Step 356 4 visits [45.0, 36.0, 34.0, 151.0, 19.0, 54.0, 17.0]  episode_count: 572 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.654, -8.931, -9.183]Step 357 4 visits [45.0, 36.0, 34.0, 151.0, 20.0, 54.0, 17.0]  episode_count: 574 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.777, -8.931, -9.183]Step 358 4 visits [45.0, 36.0, 34.0, 151.0, 21.0, 54.0, 17.0]  episode_count: 576 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.888, -8.931, -9.183]Step 359 4 visits [45.0, 36.0, 34.0, 151.0, 22.0, 54.0, 17.0]  episode_count: 577 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.989, -8.931, -9.183]Step 360 4 visits [45.0, 36.0, 34.0, 151.0, 23.0, 54.0, 17.0]  episode_count: 578 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.598, -8.931, -9.183]{"total_number_of_episodes": 580, "number_of_timesteps": 11353, "per_episode_reward": 16.93, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.35714285714285765},
Step 361 4 visits [45.0, 36.0, 34.0, 151.0, 24.0, 54.0, 17.0]  episode_count: 580 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.703, -8.931, -9.183]Step 362 4 visits [45.0, 36.0, 34.0, 151.0, 25.0, 54.0, 17.0]  episode_count: 582 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.799, -8.931, -9.183]Step 363 4 visits [45.0, 36.0, 34.0, 151.0, 26.0, 54.0, 17.0]  episode_count: 582 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.888, -8.931, -9.183]Step 364 4 visits [45.0, 36.0, 34.0, 151.0, 27.0, 54.0, 17.0]  episode_count: 585 q_vals: [-8.996, -9.045, -9.046, -8.792, -8.971, -8.931, -9.183]Step 365 4 visits [45.0, 36.0, 34.0, 151.0, 28.0, 54.0, 17.0]  episode_count: 588 q_vals: [-8.996, -9.045, -9.046, -8.792, -9.047, -8.931, -9.183]Step 366 4 visits [45.0, 36.0, 34.0, 151.0, 29.0, 54.0, 17.0]  episode_count: 588 q_vals: [-8.996, -9.045, -9.046, -8.792, -9.118, -8.931, -9.183]{"total_number_of_episodes": 590, "number_of_timesteps": 11538, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.35714285714285765},
Step 367 6 visits [45.0, 36.0, 34.0, 151.0, 29.0, 54.0, 18.0]  episode_count: 590 q_vals: [-8.996, -9.045, -9.046, -8.792, -9.118, -8.931, -9.29]Step 368 3 visits [45.0, 36.0, 34.0, 152.0, 29.0, 54.0, 18.0]  episode_count: 592 q_vals: [-8.996, -9.045, -9.046, -8.807, -9.118, -8.931, -9.29]Step 369 5 visits [45.0, 36.0, 34.0, 152.0, 29.0, 55.0, 18.0]  episode_count: 594 q_vals: [-8.996, -9.045, -9.046, -8.807, -9.118, -8.971, -9.29]Step 370 3 visits [45.0, 36.0, 34.0, 153.0, 29.0, 55.0, 18.0]  episode_count: 595 q_vals: [-8.996, -9.045, -9.046, -8.822, -9.118, -8.971, -9.29]Step 371 3 visits [45.0, 36.0, 34.0, 154.0, 29.0, 55.0, 18.0]  episode_count: 598 q_vals: [-8.996, -9.045, -9.046, -8.837, -9.118, -8.971, -9.29]{"total_number_of_episodes": 601, "number_of_timesteps": 11762, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.35714285714285765},
Step 372 2 visits [45.0, 36.0, 35.0, 154.0, 29.0, 55.0, 18.0]  episode_count: 601 q_vals: [-8.996, -9.045, -9.105, -8.837, -9.118, -8.971, -9.29]Step 373 0 visits [46.0, 36.0, 35.0, 154.0, 29.0, 55.0, 18.0]  episode_count: 602 q_vals: [-9.042, -9.045, -9.105, -8.837, -9.118, -8.971, -9.29]Step 374 1 visits [46.0, 37.0, 35.0, 154.0, 29.0, 55.0, 18.0]  episode_count: 602 q_vals: [-9.042, -9.101, -9.105, -8.837, -9.118, -8.971, -9.29]Step 375 3 visits [46.0, 37.0, 35.0, 155.0, 29.0, 55.0, 18.0]  episode_count: 606 q_vals: [-9.042, -9.101, -9.105, -8.852, -9.118, -8.971, -9.29]Step 376 5 visits [46.0, 37.0, 35.0, 155.0, 29.0, 56.0, 18.0]  episode_count: 608 q_vals: [-9.042, -9.101, -9.105, -8.852, -9.118, -9.009, -9.29]Step 377 3 visits [46.0, 37.0, 35.0, 156.0, 29.0, 56.0, 18.0]  episode_count: 608 q_vals: [-9.042, -9.101, -9.105, -8.866, -9.118, -9.009, -9.29]Step 378 4 visits [46.0, 37.0, 35.0, 156.0, 30.0, 56.0, 18.0]  episode_count: 610 q_vals: [-9.042, -9.101, -9.105, -8.866, -9.185, -9.009, -9.29]{"total_number_of_episodes": 613, "number_of_timesteps": 11974, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.004761904761904785, "biggest_recent_change": 0.35714285714285765},
Step 379 3 visits [46.0, 37.0, 35.0, 157.0, 30.0, 56.0, 18.0]  episode_count: 613 q_vals: [-9.042, -9.101, -9.105, -8.81, -9.185, -9.009, -9.29]Step 380 3 visits [46.0, 37.0, 35.0, 158.0, 30.0, 56.0, 18.0]  episode_count: 614 q_vals: [-9.042, -9.101, -9.105, -8.824, -9.185, -9.009, -9.29]Step 381 3 visits [46.0, 37.0, 35.0, 159.0, 30.0, 56.0, 18.0]  episode_count: 616 q_vals: [-9.042, -9.101, -9.105, -8.769, -9.185, -9.009, -9.29]Step 382 3 visits [46.0, 37.0, 35.0, 160.0, 30.0, 56.0, 18.0]  episode_count: 618 q_vals: [-9.042, -9.101, -9.105, -8.783, -9.185, -9.009, -9.29]Step 383 3 visits [46.0, 37.0, 35.0, 161.0, 30.0, 56.0, 18.0]  episode_count: 620 q_vals: [-9.042, -9.101, -9.105, -8.798, -9.185, -9.009, -9.29]Step 384 3 visits [46.0, 37.0, 35.0, 162.0, 30.0, 56.0, 18.0]  episode_count: 621 q_vals: [-9.042, -9.101, -9.105, -8.812, -9.185, -9.009, -9.29]{"total_number_of_episodes": 623, "number_of_timesteps": 12139, "per_episode_reward": 16.79, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.35714285714285765},
Step 385 3 visits [46.0, 37.0, 35.0, 163.0, 30.0, 56.0, 18.0]  episode_count: 623 q_vals: [-9.042, -9.101, -9.105, -8.826, -9.185, -9.009, -9.29]Step 386 3 visits [46.0, 37.0, 35.0, 164.0, 30.0, 56.0, 18.0]  episode_count: 625 q_vals: [-9.042, -9.101, -9.105, -8.84, -9.185, -9.009, -9.29]Step 387 3 visits [46.0, 37.0, 35.0, 165.0, 30.0, 56.0, 18.0]  episode_count: 626 q_vals: [-9.042, -9.101, -9.105, -8.854, -9.185, -9.009, -9.29]Step 388 3 visits [46.0, 37.0, 35.0, 166.0, 30.0, 56.0, 18.0]  episode_count: 627 q_vals: [-9.042, -9.101, -9.105, -8.867, -9.185, -9.009, -9.29]Step 389 3 visits [46.0, 37.0, 35.0, 167.0, 30.0, 56.0, 18.0]  episode_count: 630 q_vals: [-9.042, -9.101, -9.105, -8.881, -9.185, -9.009, -9.29]Step 390 0 visits [47.0, 37.0, 35.0, 167.0, 30.0, 56.0, 18.0]  episode_count: 631 q_vals: [-9.086, -9.101, -9.105, -8.881, -9.185, -9.009, -9.29]Step 391 5 visits [47.0, 37.0, 35.0, 167.0, 30.0, 57.0, 18.0]  episode_count: 631 q_vals: [-9.086, -9.101, -9.105, -8.881, -9.185, -9.046, -9.29]{"total_number_of_episodes": 634, "number_of_timesteps": 12361, "per_episode_reward": 16.79, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.35714285714285765},
Step 392 3 visits [47.0, 37.0, 35.0, 168.0, 30.0, 57.0, 18.0]  episode_count: 634 q_vals: [-9.086, -9.101, -9.105, -8.828, -9.185, -9.046, -9.29]Step 393 3 visits [47.0, 37.0, 35.0, 169.0, 30.0, 57.0, 18.0]  episode_count: 636 q_vals: [-9.086, -9.101, -9.105, -8.842, -9.185, -9.046, -9.29]Step 394 3 visits [47.0, 37.0, 35.0, 170.0, 30.0, 57.0, 18.0]  episode_count: 636 q_vals: [-9.086, -9.101, -9.105, -8.855, -9.185, -9.046, -9.29]Step 395 3 visits [47.0, 37.0, 35.0, 171.0, 30.0, 57.0, 18.0]  episode_count: 638 q_vals: [-9.086, -9.101, -9.105, -8.868, -9.185, -9.046, -9.29]Step 396 3 visits [47.0, 37.0, 35.0, 172.0, 30.0, 57.0, 18.0]  episode_count: 640 q_vals: [-9.086, -9.101, -9.105, -8.881, -9.185, -9.046, -9.29]Step 397 2 visits [47.0, 37.0, 36.0, 172.0, 30.0, 57.0, 18.0]  episode_count: 643 q_vals: [-9.086, -9.101, -9.161, -8.881, -9.185, -9.046, -9.29]Step 398 3 visits [47.0, 37.0, 36.0, 173.0, 30.0, 57.0, 18.0]  episode_count: 643 q_vals: [-9.086, -9.101, -9.161, -8.894, -9.185, -9.046, -9.29]{"total_number_of_episodes": 646, "number_of_timesteps": 12585, "per_episode_reward": 16.79, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.35714285714285765},
Step 399 1 visits [47.0, 38.0, 36.0, 173.0, 30.0, 57.0, 18.0]  episode_count: 646 q_vals: [-9.086, -9.154, -9.161, -8.894, -9.185, -9.046, -9.29]Step 400 3 visits [47.0, 38.0, 36.0, 174.0, 30.0, 57.0, 18.0]  episode_count: 648 q_vals: [-9.086, -9.154, -9.161, -8.907, -9.185, -9.046, -9.29]Step 401 6 visits [47.0, 38.0, 36.0, 174.0, 30.0, 57.0, 19.0]  episode_count: 650 q_vals: [-9.086, -9.154, -9.161, -8.907, -9.185, -9.046, -9.386]Step 402 3 visits [47.0, 38.0, 36.0, 175.0, 30.0, 57.0, 19.0]  episode_count: 652 q_vals: [-9.086, -9.154, -9.161, -8.856, -9.185, -9.046, -9.386]Step 403 3 visits [47.0, 38.0, 36.0, 176.0, 30.0, 57.0, 19.0]  episode_count: 652 q_vals: [-9.086, -9.154, -9.161, -8.869, -9.185, -9.046, -9.386]Step 404 3 visits [47.0, 38.0, 36.0, 177.0, 30.0, 57.0, 19.0]  episode_count: 654 q_vals: [-9.086, -9.154, -9.161, -8.881, -9.185, -9.046, -9.386]Step 405 3 visits [47.0, 38.0, 36.0, 178.0, 30.0, 57.0, 19.0]  episode_count: 655 q_vals: [-9.086, -9.154, -9.161, -8.894, -9.185, -9.046, -9.386]{"total_number_of_episodes": 658, "number_of_timesteps": 12824, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.0015873015873016211, "biggest_recent_change": 0.28571428571428825},
Step 406 3 visits [47.0, 38.0, 36.0, 179.0, 30.0, 57.0, 19.0]  episode_count: 658 q_vals: [-9.086, -9.154, -9.161, -8.906, -9.185, -9.046, -9.386]Step 407 5 visits [47.0, 38.0, 36.0, 179.0, 30.0, 58.0, 19.0]  episode_count: 659 q_vals: [-9.086, -9.154, -9.161, -8.906, -9.185, -9.082, -9.386]Step 408 3 visits [47.0, 38.0, 36.0, 180.0, 30.0, 58.0, 19.0]  episode_count: 661 q_vals: [-9.086, -9.154, -9.161, -8.919, -9.185, -9.082, -9.386]Step 409 0 visits [48.0, 38.0, 36.0, 180.0, 30.0, 58.0, 19.0]  episode_count: 663 q_vals: [-9.128, -9.154, -9.161, -8.919, -9.185, -9.082, -9.386]Step 410 3 visits [48.0, 38.0, 36.0, 181.0, 30.0, 58.0, 19.0]  episode_count: 664 q_vals: [-9.128, -9.154, -9.161, -8.931, -9.185, -9.082, -9.386]Step 411 4 visits [48.0, 38.0, 36.0, 181.0, 31.0, 58.0, 19.0]  episode_count: 666 q_vals: [-9.128, -9.154, -9.161, -8.931, -9.247, -9.082, -9.386]Step 412 3 visits [48.0, 38.0, 36.0, 182.0, 31.0, 58.0, 19.0]  episode_count: 667 q_vals: [-9.128, -9.154, -9.161, -8.943, -9.247, -9.082, -9.386]{"total_number_of_episodes": 669, "number_of_timesteps": 13000, "per_episode_reward": 16.64, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.21428571428571175},
Step 413 2 visits [48.0, 38.0, 37.0, 182.0, 31.0, 58.0, 19.0]  episode_count: 669 q_vals: [-9.128, -9.154, -9.214, -8.943, -9.247, -9.082, -9.386]Step 414 1 visits [48.0, 39.0, 37.0, 182.0, 31.0, 58.0, 19.0]  episode_count: 671 q_vals: [-9.128, -9.204, -9.214, -8.943, -9.247, -9.082, -9.386]Step 415 5 visits [48.0, 39.0, 37.0, 182.0, 31.0, 59.0, 19.0]  episode_count: 671 q_vals: [-9.128, -9.204, -9.214, -8.943, -9.247, -9.116, -9.386]Step 416 3 visits [48.0, 39.0, 37.0, 183.0, 31.0, 59.0, 19.0]  episode_count: 673 q_vals: [-9.128, -9.204, -9.214, -8.954, -9.247, -9.116, -9.386]Step 417 3 visits [48.0, 39.0, 37.0, 184.0, 31.0, 59.0, 19.0]  episode_count: 674 q_vals: [-9.128, -9.204, -9.214, -8.966, -9.247, -9.116, -9.386]Step 418 0 visits [49.0, 39.0, 37.0, 184.0, 31.0, 59.0, 19.0]  episode_count: 677 q_vals: [-8.942, -9.204, -9.214, -8.966, -9.247, -9.116, -9.386]{"total_number_of_episodes": 680, "number_of_timesteps": 13236, "per_episode_reward": 16.64, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.21428571428571175},
Step 419 0 visits [50.0, 39.0, 37.0, 184.0, 31.0, 59.0, 19.0]  episode_count: 680 q_vals: [-8.985, -9.204, -9.214, -8.966, -9.247, -9.116, -9.386]Step 420 0 visits [51.0, 39.0, 37.0, 184.0, 31.0, 59.0, 19.0]  episode_count: 681 q_vals: [-9.027, -9.204, -9.214, -8.966, -9.247, -9.116, -9.386]Step 421 0 visits [52.0, 39.0, 37.0, 184.0, 31.0, 59.0, 19.0]  episode_count: 681 q_vals: [-9.067, -9.204, -9.214, -8.966, -9.247, -9.116, -9.386]Step 422 0 visits [53.0, 39.0, 37.0, 184.0, 31.0, 59.0, 19.0]  episode_count: 683 q_vals: [-9.106, -9.204, -9.214, -8.966, -9.247, -9.116, -9.386]Step 423 0 visits [54.0, 39.0, 37.0, 184.0, 31.0, 59.0, 19.0]  episode_count: 685 q_vals: [-9.143, -9.204, -9.214, -8.966, -9.247, -9.116, -9.386]Step 424 3 visits [54.0, 39.0, 37.0, 185.0, 31.0, 59.0, 19.0]  episode_count: 687 q_vals: [-9.143, -9.204, -9.214, -8.978, -9.247, -9.116, -9.386]Step 425 5 visits [54.0, 39.0, 37.0, 185.0, 31.0, 60.0, 19.0]  episode_count: 688 q_vals: [-9.143, -9.204, -9.214, -8.978, -9.247, -9.149, -9.386]{"total_number_of_episodes": 691, "number_of_timesteps": 13452, "per_episode_reward": 16.64, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.21428571428571175},
Step 426 3 visits [54.0, 39.0, 37.0, 186.0, 31.0, 60.0, 19.0]  episode_count: 691 q_vals: [-9.143, -9.204, -9.214, -8.989, -9.247, -9.149, -9.386]Step 427 4 visits [54.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 692 q_vals: [-9.143, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]Step 428 0 visits [55.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 695 q_vals: [-8.977, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]Step 429 0 visits [56.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 695 q_vals: [-9.015, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]Step 430 0 visits [57.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 697 q_vals: [-9.051, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]Step 431 0 visits [58.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 698 q_vals: [-9.087, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]Step 432 0 visits [59.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 700 q_vals: [-9.121, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]{"total_number_of_episodes": 701, "number_of_timesteps": 13607, "per_episode_reward": 16.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.21428571428571175},
Step 433 0 visits [60.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 701 q_vals: [-8.969, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]Step 434 0 visits [61.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 701 q_vals: [-9.004, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]Step 435 0 visits [62.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 704 q_vals: [-9.038, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]Step 436 0 visits [63.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 705 q_vals: [-9.071, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]Step 437 0 visits [64.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 705 q_vals: [-9.103, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]Step 438 0 visits [65.0, 39.0, 37.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 709 q_vals: [-9.134, -9.204, -9.214, -8.989, -9.305, -9.149, -9.386]Step 439 2 visits [65.0, 39.0, 38.0, 186.0, 32.0, 60.0, 19.0]  episode_count: 710 q_vals: [-9.134, -9.204, -9.264, -8.989, -9.305, -9.149, -9.386]Step 440 3 visits [65.0, 39.0, 38.0, 187.0, 32.0, 60.0, 19.0]  episode_count: 710 q_vals: [-9.134, -9.204, -9.264, -9.001, -9.305, -9.149, -9.386]{"total_number_of_episodes": 711, "number_of_timesteps": 13879, "per_episode_reward": 16.79, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.21428571428571175},
Step 441 1 visits [65.0, 40.0, 38.0, 187.0, 32.0, 60.0, 19.0]  episode_count: 711 q_vals: [-9.134, -9.251, -9.264, -9.001, -9.305, -9.149, -9.386]Step 442 6 visits [65.0, 40.0, 38.0, 187.0, 32.0, 60.0, 20.0]  episode_count: 713 q_vals: [-9.134, -9.251, -9.264, -9.001, -9.305, -9.149, -9.472]Step 443 3 visits [65.0, 40.0, 38.0, 188.0, 32.0, 60.0, 20.0]  episode_count: 716 q_vals: [-9.134, -9.251, -9.264, -9.012, -9.305, -9.149, -9.472]Step 444 0 visits [66.0, 40.0, 38.0, 188.0, 32.0, 60.0, 20.0]  episode_count: 717 q_vals: [-9.164, -9.251, -9.264, -9.012, -9.305, -9.149, -9.472]Step 445 5 visits [66.0, 40.0, 38.0, 188.0, 32.0, 61.0, 20.0]  episode_count: 719 q_vals: [-9.164, -9.251, -9.264, -9.012, -9.305, -9.181, -9.472]Step 446 3 visits [66.0, 40.0, 38.0, 189.0, 32.0, 61.0, 20.0]  episode_count: 720 q_vals: [-9.164, -9.251, -9.264, -9.023, -9.305, -9.181, -9.472]{"total_number_of_episodes": 721, "number_of_timesteps": 14102, "per_episode_reward": 16.86, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.21428571428571175},
Step 447 3 visits [66.0, 40.0, 38.0, 190.0, 32.0, 61.0, 20.0]  episode_count: 721 q_vals: [-9.164, -9.251, -9.264, -9.034, -9.305, -9.181, -9.472]Step 448 3 visits [66.0, 40.0, 38.0, 191.0, 32.0, 61.0, 20.0]  episode_count: 727 q_vals: [-9.164, -9.251, -9.264, -9.045, -9.305, -9.181, -9.472]Step 449 0 visits [67.0, 40.0, 38.0, 191.0, 32.0, 61.0, 20.0]  episode_count: 728 q_vals: [-9.193, -9.251, -9.264, -9.045, -9.305, -9.181, -9.472]Step 450 1 visits [67.0, 41.0, 38.0, 191.0, 32.0, 61.0, 20.0]  episode_count: 730 q_vals: [-9.193, -9.297, -9.264, -9.045, -9.305, -9.181, -9.472]{"total_number_of_episodes": 734, "number_of_timesteps": 14288, "per_episode_reward": 16.64, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 451 2 visits [67.0, 41.0, 39.0, 191.0, 32.0, 61.0, 20.0]  episode_count: 734 q_vals: [-9.193, -9.297, -9.311, -9.045, -9.305, -9.181, -9.472]Step 452 5 visits [67.0, 41.0, 39.0, 191.0, 32.0, 62.0, 20.0]  episode_count: 734 q_vals: [-9.193, -9.297, -9.311, -9.045, -9.305, -9.213, -9.472]Step 453 3 visits [67.0, 41.0, 39.0, 192.0, 32.0, 62.0, 20.0]  episode_count: 739 q_vals: [-9.193, -9.297, -9.311, -9.056, -9.305, -9.213, -9.472]Step 454 4 visits [67.0, 41.0, 39.0, 192.0, 33.0, 62.0, 20.0]  episode_count: 739 q_vals: [-9.193, -9.297, -9.311, -9.056, -9.023, -9.213, -9.472]Step 455 4 visits [67.0, 41.0, 39.0, 192.0, 34.0, 62.0, 20.0]  episode_count: 740 q_vals: [-9.193, -9.297, -9.311, -9.056, -9.084, -9.213, -9.472]{"total_number_of_episodes": 744, "number_of_timesteps": 14422, "per_episode_reward": 16.57, "episode_reward_trend_value": -0.0023809523809523525, "biggest_recent_change": 0.2142857142857153},
Step 456 4 visits [67.0, 41.0, 39.0, 192.0, 35.0, 62.0, 20.0]  episode_count: 744 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.825, -9.213, -9.472]Step 457 4 visits [67.0, 41.0, 39.0, 192.0, 36.0, 62.0, 20.0]  episode_count: 746 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.58, -9.213, -9.472]Step 458 4 visits [67.0, 41.0, 39.0, 192.0, 37.0, 62.0, 20.0]  episode_count: 748 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.648, -9.213, -9.472]Step 459 4 visits [67.0, 41.0, 39.0, 192.0, 38.0, 62.0, 20.0]  episode_count: 750 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.713, -9.213, -9.472]Step 460 4 visits [67.0, 41.0, 39.0, 192.0, 39.0, 62.0, 20.0]  episode_count: 751 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.774, -9.213, -9.472]Step 461 4 visits [67.0, 41.0, 39.0, 192.0, 40.0, 62.0, 20.0]  episode_count: 753 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.555, -9.213, -9.472]{"total_number_of_episodes": 754, "number_of_timesteps": 14568, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.2142857142857153},
Step 462 4 visits [67.0, 41.0, 39.0, 192.0, 41.0, 62.0, 20.0]  episode_count: 754 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.617, -9.213, -9.472]Step 463 4 visits [67.0, 41.0, 39.0, 192.0, 42.0, 62.0, 20.0]  episode_count: 758 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.677, -9.213, -9.472]Step 464 4 visits [67.0, 41.0, 39.0, 192.0, 43.0, 62.0, 20.0]  episode_count: 760 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.733, -9.213, -9.472]Step 465 4 visits [67.0, 41.0, 39.0, 192.0, 44.0, 62.0, 20.0]  episode_count: 761 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.535, -9.213, -9.472]Step 466 4 visits [67.0, 41.0, 39.0, 192.0, 45.0, 62.0, 20.0]  episode_count: 762 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.592, -9.213, -9.472]Step 467 4 visits [67.0, 41.0, 39.0, 192.0, 46.0, 62.0, 20.0]  episode_count: 763 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.647, -9.213, -9.472]{"total_number_of_episodes": 766, "number_of_timesteps": 14772, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 468 4 visits [67.0, 41.0, 39.0, 192.0, 47.0, 62.0, 20.0]  episode_count: 766 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.699, -9.213, -9.472]Step 469 4 visits [67.0, 41.0, 39.0, 192.0, 48.0, 62.0, 20.0]  episode_count: 768 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.75, -9.213, -9.472]Step 470 4 visits [67.0, 41.0, 39.0, 192.0, 49.0, 62.0, 20.0]  episode_count: 769 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.798, -9.213, -9.472]Step 471 4 visits [67.0, 41.0, 39.0, 192.0, 50.0, 62.0, 20.0]  episode_count: 771 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.622, -9.213, -9.472]Step 472 4 visits [67.0, 41.0, 39.0, 192.0, 51.0, 62.0, 20.0]  episode_count: 773 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.671, -9.213, -9.472]Step 473 4 visits [67.0, 41.0, 39.0, 192.0, 52.0, 62.0, 20.0]  episode_count: 775 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.718, -9.213, -9.472]{"total_number_of_episodes": 777, "number_of_timesteps": 14979, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 474 4 visits [67.0, 41.0, 39.0, 192.0, 53.0, 62.0, 20.0]  episode_count: 777 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.763, -9.213, -9.472]Step 475 4 visits [67.0, 41.0, 39.0, 192.0, 54.0, 62.0, 20.0]  episode_count: 777 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.8, -9.213, -9.472]Step 476 4 visits [67.0, 41.0, 39.0, 192.0, 55.0, 62.0, 20.0]  episode_count: 780 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.64, -9.213, -9.472]Step 477 4 visits [67.0, 41.0, 39.0, 192.0, 56.0, 62.0, 20.0]  episode_count: 783 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.684, -9.213, -9.472]Step 478 4 visits [67.0, 41.0, 39.0, 192.0, 57.0, 62.0, 20.0]  episode_count: 785 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.727, -9.213, -9.472]{"total_number_of_episodes": 787, "number_of_timesteps": 15130, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 479 4 visits [67.0, 41.0, 39.0, 192.0, 58.0, 62.0, 20.0]  episode_count: 787 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.768, -9.213, -9.472]Step 480 4 visits [67.0, 41.0, 39.0, 192.0, 59.0, 62.0, 20.0]  episode_count: 788 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.806, -9.213, -9.472]Step 481 4 visits [67.0, 41.0, 39.0, 192.0, 60.0, 62.0, 20.0]  episode_count: 791 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.845, -9.213, -9.472]Step 482 4 visits [67.0, 41.0, 39.0, 192.0, 61.0, 62.0, 20.0]  episode_count: 792 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.882, -9.213, -9.472]Step 483 4 visits [67.0, 41.0, 39.0, 192.0, 62.0, 62.0, 20.0]  episode_count: 795 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.918, -9.213, -9.472]{"total_number_of_episodes": 798, "number_of_timesteps": 15307, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.004761904761904785, "biggest_recent_change": 0.2142857142857153},
Step 484 4 visits [67.0, 41.0, 39.0, 192.0, 63.0, 62.0, 20.0]  episode_count: 798 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.953, -9.213, -9.472]Step 485 4 visits [67.0, 41.0, 39.0, 192.0, 64.0, 62.0, 20.0]  episode_count: 799 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.983, -9.213, -9.472]Step 486 4 visits [67.0, 41.0, 39.0, 192.0, 65.0, 62.0, 20.0]  episode_count: 803 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.844, -9.213, -9.472]Step 487 4 visits [67.0, 41.0, 39.0, 192.0, 66.0, 62.0, 20.0]  episode_count: 806 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.879, -9.213, -9.472]Step 488 4 visits [67.0, 41.0, 39.0, 192.0, 67.0, 62.0, 20.0]  episode_count: 807 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.912, -9.213, -9.472]{"total_number_of_episodes": 811, "number_of_timesteps": 15457, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.2142857142857153},
Step 489 4 visits [67.0, 41.0, 39.0, 192.0, 68.0, 62.0, 20.0]  episode_count: 811 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.944, -9.213, -9.472]Step 490 4 visits [67.0, 41.0, 39.0, 192.0, 69.0, 62.0, 20.0]  episode_count: 813 q_vals: [-9.193, -9.297, -9.311, -9.056, -8.976, -9.213, -9.472]Step 491 4 visits [67.0, 41.0, 39.0, 192.0, 70.0, 62.0, 20.0]  episode_count: 816 q_vals: [-9.193, -9.297, -9.311, -9.056, -9.006, -9.213, -9.472]Step 492 4 visits [67.0, 41.0, 39.0, 192.0, 71.0, 62.0, 20.0]  episode_count: 816 q_vals: [-9.193, -9.297, -9.311, -9.056, -9.029, -9.213, -9.472]Step 493 4 visits [67.0, 41.0, 39.0, 192.0, 72.0, 62.0, 20.0]  episode_count: 818 q_vals: [-9.193, -9.297, -9.311, -9.056, -9.058, -9.213, -9.472]{"total_number_of_episodes": 821, "number_of_timesteps": 15600, "per_episode_reward": 16.21, "episode_reward_trend_value": -0.0071428571428571366, "biggest_recent_change": 0.2142857142857153},
Step 494 4 visits [67.0, 41.0, 39.0, 192.0, 73.0, 62.0, 20.0]  episode_count: 821 q_vals: [-9.193, -9.297, -9.311, -9.056, -9.086, -9.213, -9.472]Step 495 4 visits [67.0, 41.0, 39.0, 192.0, 74.0, 62.0, 20.0]  episode_count: 823 q_vals: [-9.193, -9.297, -9.311, -9.056, -9.113, -9.213, -9.472]Step 496 4 visits [67.0, 41.0, 39.0, 192.0, 75.0, 62.0, 20.0]  episode_count: 825 q_vals: [-9.193, -9.297, -9.311, -9.056, -9.134, -9.213, -9.472]Step 497 4 visits [67.0, 41.0, 39.0, 192.0, 76.0, 62.0, 20.0]  episode_count: 827 q_vals: [-9.193, -9.297, -9.311, -9.056, -9.16, -9.213, -9.472]Step 498 4 visits [67.0, 41.0, 39.0, 192.0, 77.0, 62.0, 20.0]  episode_count: 829 q_vals: [-9.193, -9.297, -9.311, -9.056, -9.186, -9.213, -9.472]Step 499 3 visits [67.0, 41.0, 39.0, 193.0, 77.0, 62.0, 20.0]  episode_count: 829 q_vals: [-9.193, -9.297, -9.311, -9.066, -9.186, -9.213, -9.472]{"total_number_of_episodes": 832, "number_of_timesteps": 15762, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
Step 500 3 visits [67.0, 41.0, 39.0, 194.0, 77.0, 62.0, 20.0]  episode_count: 832 q_vals: [-9.193, -9.297, -9.311, -9.077, -9.186, -9.213, -9.472]Step 501 0 visits [68.0, 41.0, 39.0, 194.0, 77.0, 62.0, 20.0]  episode_count: 833 q_vals: [-9.221, -9.297, -9.311, -9.077, -9.186, -9.213, -9.472]Step 502 5 visits [68.0, 41.0, 39.0, 194.0, 77.0, 63.0, 20.0]  episode_count: 837 q_vals: [-9.221, -9.297, -9.311, -9.077, -9.186, -9.243, -9.472]Step 503 3 visits [68.0, 41.0, 39.0, 195.0, 77.0, 63.0, 20.0]  episode_count: 837 q_vals: [-9.221, -9.297, -9.311, -9.087, -9.186, -9.243, -9.472]Step 504 4 visits [68.0, 41.0, 39.0, 195.0, 78.0, 63.0, 20.0]  episode_count: 838 q_vals: [-9.221, -9.297, -9.311, -9.087, -9.21, -9.243, -9.472]{"total_number_of_episodes": 843, "number_of_timesteps": 15947, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.003174603174603203, "biggest_recent_change": 0.2142857142857153},
Step 505 1 visits [68.0, 42.0, 39.0, 195.0, 78.0, 63.0, 20.0]  episode_count: 843 q_vals: [-9.221, -9.34, -9.311, -9.087, -9.21, -9.243, -9.472]Step 506 3 visits [68.0, 42.0, 39.0, 196.0, 78.0, 63.0, 20.0]  episode_count: 844 q_vals: [-9.221, -9.34, -9.311, -9.098, -9.21, -9.243, -9.472]Step 507 2 visits [68.0, 42.0, 40.0, 196.0, 78.0, 63.0, 20.0]  episode_count: 846 q_vals: [-9.221, -9.34, -9.356, -9.098, -9.21, -9.243, -9.472]Step 508 6 visits [68.0, 42.0, 40.0, 196.0, 78.0, 63.0, 21.0]  episode_count: 847 q_vals: [-9.221, -9.34, -9.356, -9.098, -9.21, -9.243, -9.522]Step 509 0 visits [69.0, 42.0, 40.0, 196.0, 78.0, 63.0, 21.0]  episode_count: 849 q_vals: [-9.249, -9.34, -9.356, -9.098, -9.21, -9.243, -9.522]Step 510 3 visits [69.0, 42.0, 40.0, 197.0, 78.0, 63.0, 21.0]  episode_count: 852 q_vals: [-9.249, -9.34, -9.356, -9.108, -9.21, -9.243, -9.522]{"total_number_of_episodes": 853, "number_of_timesteps": 16100, "per_episode_reward": 16.21, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.2142857142857153},
Step 511 4 visits [69.0, 42.0, 40.0, 197.0, 79.0, 63.0, 21.0]  episode_count: 853 q_vals: [-9.249, -9.34, -9.356, -9.108, -9.234, -9.243, -9.522]Step 512 5 visits [69.0, 42.0, 40.0, 197.0, 79.0, 64.0, 21.0]  episode_count: 853 q_vals: [-9.249, -9.34, -9.356, -9.108, -9.234, -9.22, -9.522]Step 513 5 visits [69.0, 42.0, 40.0, 197.0, 79.0, 65.0, 21.0]  episode_count: 855 q_vals: [-9.249, -9.34, -9.356, -9.108, -9.234, -9.249, -9.522]Step 514 3 visits [69.0, 42.0, 40.0, 198.0, 79.0, 65.0, 21.0]  episode_count: 858 q_vals: [-9.249, -9.34, -9.356, -9.116, -9.234, -9.249, -9.522]Step 515 3 visits [69.0, 42.0, 40.0, 199.0, 79.0, 65.0, 21.0]  episode_count: 860 q_vals: [-9.249, -9.34, -9.356, -9.07, -9.234, -9.249, -9.522]{"total_number_of_episodes": 863, "number_of_timesteps": 16290, "per_episode_reward": 16.21, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.2142857142857153},
Step 516 3 visits [69.0, 42.0, 40.0, 200.0, 79.0, 65.0, 21.0]  episode_count: 863 q_vals: [-9.249, -9.34, -9.356, -9.081, -9.234, -9.249, -9.522]Step 517 3 visits [69.0, 42.0, 40.0, 201.0, 79.0, 65.0, 21.0]  episode_count: 864 q_vals: [-9.249, -9.34, -9.356, -9.091, -9.234, -9.249, -9.522]Step 518 3 visits [69.0, 42.0, 40.0, 202.0, 79.0, 65.0, 21.0]  episode_count: 864 q_vals: [-9.249, -9.34, -9.356, -9.101, -9.234, -9.249, -9.522]Step 519 3 visits [69.0, 42.0, 40.0, 203.0, 79.0, 65.0, 21.0]  episode_count: 866 q_vals: [-9.249, -9.34, -9.356, -9.111, -9.234, -9.249, -9.522]Step 520 3 visits [69.0, 42.0, 40.0, 204.0, 79.0, 65.0, 21.0]  episode_count: 868 q_vals: [-9.249, -9.34, -9.356, -9.12, -9.234, -9.249, -9.522]Step 521 5 visits [69.0, 42.0, 40.0, 204.0, 79.0, 66.0, 21.0]  episode_count: 870 q_vals: [-9.249, -9.34, -9.356, -9.12, -9.234, -9.277, -9.522]Step 522 3 visits [69.0, 42.0, 40.0, 205.0, 79.0, 66.0, 21.0]  episode_count: 871 q_vals: [-9.249, -9.34, -9.356, -9.13, -9.234, -9.277, -9.522]Step 523 0 visits [70.0, 42.0, 40.0, 205.0, 79.0, 66.0, 21.0]  episode_count: 872 q_vals: [-9.275, -9.34, -9.356, -9.13, -9.234, -9.277, -9.522]{"total_number_of_episodes": 873, "number_of_timesteps": 16485, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.003968253968253973, "biggest_recent_change": 0.2142857142857153},
Step 524 4 visits [70.0, 42.0, 40.0, 205.0, 80.0, 66.0, 21.0]  episode_count: 873 q_vals: [-9.275, -9.34, -9.356, -9.13, -9.258, -9.277, -9.522]Step 525 1 visits [70.0, 43.0, 40.0, 205.0, 80.0, 66.0, 21.0]  episode_count: 875 q_vals: [-9.275, -9.381, -9.356, -9.13, -9.258, -9.277, -9.522]Step 526 3 visits [70.0, 43.0, 40.0, 206.0, 80.0, 66.0, 21.0]  episode_count: 875 q_vals: [-9.275, -9.381, -9.356, -9.14, -9.258, -9.277, -9.522]Step 527 2 visits [70.0, 43.0, 41.0, 206.0, 80.0, 66.0, 21.0]  episode_count: 875 q_vals: [-9.275, -9.381, -9.399, -9.14, -9.258, -9.277, -9.522]Step 528 3 visits [70.0, 43.0, 41.0, 207.0, 80.0, 66.0, 21.0]  episode_count: 875 q_vals: [-9.275, -9.381, -9.399, -9.096, -9.258, -9.277, -9.522]Step 529 3 visits [70.0, 43.0, 41.0, 208.0, 80.0, 66.0, 21.0]  episode_count: 879 q_vals: [-9.275, -9.381, -9.399, -9.052, -9.258, -9.277, -9.522]Step 530 3 visits [70.0, 43.0, 41.0, 209.0, 80.0, 66.0, 21.0]  episode_count: 879 q_vals: [-9.275, -9.381, -9.399, -9.062, -9.258, -9.277, -9.522]Step 531 3 visits [70.0, 43.0, 41.0, 210.0, 80.0, 66.0, 21.0]  episode_count: 880 q_vals: [-9.275, -9.381, -9.399, -9.071, -9.258, -9.277, -9.522]Step 532 3 visits [70.0, 43.0, 41.0, 211.0, 80.0, 66.0, 21.0]  episode_count: 880 q_vals: [-9.275, -9.381, -9.399, -9.08, -9.258, -9.277, -9.522]Step 533 3 visits [70.0, 43.0, 41.0, 212.0, 80.0, 66.0, 21.0]  episode_count: 882 q_vals: [-9.275, -9.381, -9.399, -9.09, -9.258, -9.277, -9.522]{"total_number_of_episodes": 883, "number_of_timesteps": 16760, "per_episode_reward": 16.29, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.2142857142857153},
Step 534 3 visits [70.0, 43.0, 41.0, 213.0, 80.0, 66.0, 21.0]  episode_count: 883 q_vals: [-9.275, -9.381, -9.399, -9.099, -9.258, -9.277, -9.522]Step 535 3 visits [70.0, 43.0, 41.0, 214.0, 80.0, 66.0, 21.0]  episode_count: 884 q_vals: [-9.275, -9.381, -9.399, -9.108, -9.258, -9.277, -9.522]Step 536 3 visits [70.0, 43.0, 41.0, 215.0, 80.0, 66.0, 21.0]  episode_count: 886 q_vals: [-9.275, -9.381, -9.399, -9.118, -9.258, -9.277, -9.522]Step 537 3 visits [70.0, 43.0, 41.0, 216.0, 80.0, 66.0, 21.0]  episode_count: 886 q_vals: [-9.275, -9.381, -9.399, -9.127, -9.258, -9.277, -9.522]Step 538 3 visits [70.0, 43.0, 41.0, 217.0, 80.0, 66.0, 21.0]  episode_count: 887 q_vals: [-9.275, -9.381, -9.399, -9.136, -9.258, -9.277, -9.522]Step 539 3 visits [70.0, 43.0, 41.0, 218.0, 80.0, 66.0, 21.0]  episode_count: 891 q_vals: [-9.275, -9.381, -9.399, -9.145, -9.258, -9.277, -9.522]Step 540 5 visits [70.0, 43.0, 41.0, 218.0, 80.0, 67.0, 21.0]  episode_count: 892 q_vals: [-9.275, -9.381, -9.399, -9.145, -9.258, -9.304, -9.522]{"total_number_of_episodes": 893, "number_of_timesteps": 17069, "per_episode_reward": 16.36, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714235},
Step 541 6 visits [70.0, 43.0, 41.0, 218.0, 80.0, 67.0, 22.0]  episode_count: 893 q_vals: [-9.275, -9.381, -9.399, -9.145, -9.258, -9.304, -9.594]Step 542 3 visits [70.0, 43.0, 41.0, 219.0, 80.0, 67.0, 22.0]  episode_count: 893 q_vals: [-9.275, -9.381, -9.399, -9.154, -9.258, -9.304, -9.594]Step 543 0 visits [71.0, 43.0, 41.0, 219.0, 80.0, 67.0, 22.0]  episode_count: 895 q_vals: [-9.301, -9.381, -9.399, -9.154, -9.258, -9.304, -9.594]Step 544 4 visits [71.0, 43.0, 41.0, 219.0, 81.0, 67.0, 22.0]  episode_count: 896 q_vals: [-9.301, -9.381, -9.399, -9.154, -9.281, -9.304, -9.594]Step 545 3 visits [71.0, 43.0, 41.0, 220.0, 81.0, 67.0, 22.0]  episode_count: 898 q_vals: [-9.301, -9.381, -9.399, -9.163, -9.281, -9.304, -9.594]Step 546 3 visits [71.0, 43.0, 41.0, 221.0, 81.0, 67.0, 22.0]  episode_count: 899 q_vals: [-9.301, -9.381, -9.399, -9.122, -9.281, -9.304, -9.594]Step 547 3 visits [71.0, 43.0, 41.0, 222.0, 81.0, 67.0, 22.0]  episode_count: 901 q_vals: [-9.301, -9.381, -9.399, -9.129, -9.281, -9.304, -9.594]{"total_number_of_episodes": 903, "number_of_timesteps": 17276, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 548 3 visits [71.0, 43.0, 41.0, 223.0, 81.0, 67.0, 22.0]  episode_count: 903 q_vals: [-9.301, -9.381, -9.399, -9.138, -9.281, -9.304, -9.594]Step 549 3 visits [71.0, 43.0, 41.0, 224.0, 81.0, 67.0, 22.0]  episode_count: 903 q_vals: [-9.301, -9.381, -9.399, -9.147, -9.281, -9.304, -9.594]Step 550 3 visits [71.0, 43.0, 41.0, 225.0, 81.0, 67.0, 22.0]  episode_count: 905 q_vals: [-9.301, -9.381, -9.399, -9.156, -9.281, -9.304, -9.594]Step 551 3 visits [71.0, 43.0, 41.0, 226.0, 81.0, 67.0, 22.0]  episode_count: 906 q_vals: [-9.301, -9.381, -9.399, -9.164, -9.281, -9.304, -9.594]Step 552 3 visits [71.0, 43.0, 41.0, 227.0, 81.0, 67.0, 22.0]  episode_count: 909 q_vals: [-9.301, -9.381, -9.399, -9.173, -9.281, -9.304, -9.594]Step 553 5 visits [71.0, 43.0, 41.0, 227.0, 81.0, 68.0, 22.0]  episode_count: 911 q_vals: [-9.301, -9.381, -9.399, -9.173, -9.281, -9.325, -9.594]Step 554 1 visits [71.0, 44.0, 41.0, 227.0, 81.0, 68.0, 22.0]  episode_count: 912 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.281, -9.325, -9.594]{"total_number_of_episodes": 915, "number_of_timesteps": 17516, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.14285714285714235},
Step 555 4 visits [71.0, 44.0, 41.0, 227.0, 82.0, 68.0, 22.0]  episode_count: 915 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.192, -9.325, -9.594]Step 556 4 visits [71.0, 44.0, 41.0, 227.0, 83.0, 68.0, 22.0]  episode_count: 916 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.081, -9.325, -9.594]Step 557 4 visits [71.0, 44.0, 41.0, 227.0, 84.0, 68.0, 22.0]  episode_count: 919 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.077, -9.325, -9.594]Step 558 4 visits [71.0, 44.0, 41.0, 227.0, 85.0, 68.0, 22.0]  episode_count: 921 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.101, -9.325, -9.594]Step 559 4 visits [71.0, 44.0, 41.0, 227.0, 86.0, 68.0, 22.0]  episode_count: 923 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.125, -9.325, -9.594]Step 560 4 visits [71.0, 44.0, 41.0, 227.0, 87.0, 68.0, 22.0]  episode_count: 924 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.147, -9.325, -9.594]{"total_number_of_episodes": 927, "number_of_timesteps": 17734, "per_episode_reward": 16.36, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714235},
Step 561 4 visits [71.0, 44.0, 41.0, 227.0, 88.0, 68.0, 22.0]  episode_count: 927 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.17, -9.325, -9.594]Step 562 4 visits [71.0, 44.0, 41.0, 227.0, 89.0, 68.0, 22.0]  episode_count: 929 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.067, -9.325, -9.594]Step 563 4 visits [71.0, 44.0, 41.0, 227.0, 90.0, 68.0, 22.0]  episode_count: 930 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.089, -9.325, -9.594]Step 564 4 visits [71.0, 44.0, 41.0, 227.0, 91.0, 68.0, 22.0]  episode_count: 931 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.112, -9.325, -9.594]Step 565 4 visits [71.0, 44.0, 41.0, 227.0, 92.0, 68.0, 22.0]  episode_count: 933 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.133, -9.325, -9.594]Step 566 4 visits [71.0, 44.0, 41.0, 227.0, 93.0, 68.0, 22.0]  episode_count: 934 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.148, -9.325, -9.594]Step 567 4 visits [71.0, 44.0, 41.0, 227.0, 94.0, 68.0, 22.0]  episode_count: 934 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.05, -9.325, -9.594]Step 568 4 visits [71.0, 44.0, 41.0, 227.0, 95.0, 68.0, 22.0]  episode_count: 936 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.071, -9.325, -9.594]{"total_number_of_episodes": 938, "number_of_timesteps": 17950, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 569 4 visits [71.0, 44.0, 41.0, 227.0, 96.0, 68.0, 22.0]  episode_count: 938 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.092, -9.325, -9.594]Step 570 4 visits [71.0, 44.0, 41.0, 227.0, 97.0, 68.0, 22.0]  episode_count: 938 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.113, -9.325, -9.594]Step 571 4 visits [71.0, 44.0, 41.0, 227.0, 98.0, 68.0, 22.0]  episode_count: 938 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.133, -9.325, -9.594]Step 572 4 visits [71.0, 44.0, 41.0, 227.0, 99.0, 68.0, 22.0]  episode_count: 941 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.153, -9.325, -9.594]Step 573 4 visits [71.0, 44.0, 41.0, 227.0, 100.0, 68.0, 22.0]  episode_count: 942 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.171, -9.325, -9.594]Step 574 4 visits [71.0, 44.0, 41.0, 227.0, 101.0, 68.0, 22.0]  episode_count: 942 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.19, -9.325, -9.594]Step 575 4 visits [71.0, 44.0, 41.0, 227.0, 102.0, 68.0, 22.0]  episode_count: 943 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.209, -9.325, -9.594]{"total_number_of_episodes": 948, "number_of_timesteps": 18212, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.14285714285714235},
Step 576 4 visits [71.0, 44.0, 41.0, 227.0, 103.0, 68.0, 22.0]  episode_count: 948 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.225, -9.325, -9.594]Step 577 4 visits [71.0, 44.0, 41.0, 227.0, 104.0, 68.0, 22.0]  episode_count: 949 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.235, -9.325, -9.594]Step 578 4 visits [71.0, 44.0, 41.0, 227.0, 105.0, 68.0, 22.0]  episode_count: 950 q_vals: [-9.301, -9.42, -9.399, -9.173, -9.253, -9.325, -9.594]Step 579 0 visits [72.0, 44.0, 41.0, 227.0, 105.0, 68.0, 22.0]  episode_count: 951 q_vals: [-9.326, -9.42, -9.399, -9.173, -9.253, -9.325, -9.594]Step 580 2 visits [72.0, 44.0, 42.0, 227.0, 105.0, 68.0, 22.0]  episode_count: 953 q_vals: [-9.326, -9.42, -9.439, -9.173, -9.253, -9.325, -9.594]Step 581 3 visits [72.0, 44.0, 42.0, 228.0, 105.0, 68.0, 22.0]  episode_count: 954 q_vals: [-9.326, -9.42, -9.439, -9.181, -9.253, -9.325, -9.594]Step 582 4 visits [72.0, 44.0, 42.0, 228.0, 106.0, 68.0, 22.0]  episode_count: 955 q_vals: [-9.326, -9.42, -9.439, -9.181, -9.268, -9.325, -9.594]Step 583 3 visits [72.0, 44.0, 42.0, 229.0, 106.0, 68.0, 22.0]  episode_count: 956 q_vals: [-9.326, -9.42, -9.439, -9.187, -9.268, -9.325, -9.594]{"total_number_of_episodes": 959, "number_of_timesteps": 18422, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0007936507936507711, "biggest_recent_change": 0.14285714285714235},
Step 584 5 visits [72.0, 44.0, 42.0, 229.0, 106.0, 69.0, 22.0]  episode_count: 959 q_vals: [-9.326, -9.42, -9.439, -9.187, -9.268, -9.351, -9.594]Step 585 3 visits [72.0, 44.0, 42.0, 230.0, 106.0, 69.0, 22.0]  episode_count: 959 q_vals: [-9.326, -9.42, -9.439, -9.147, -9.268, -9.351, -9.594]Step 586 3 visits [72.0, 44.0, 42.0, 231.0, 106.0, 69.0, 22.0]  episode_count: 964 q_vals: [-9.326, -9.42, -9.439, -9.153, -9.268, -9.351, -9.594]Step 587 3 visits [72.0, 44.0, 42.0, 232.0, 106.0, 69.0, 22.0]  episode_count: 965 q_vals: [-9.326, -9.42, -9.439, -9.162, -9.268, -9.351, -9.594]Step 588 3 visits [72.0, 44.0, 42.0, 233.0, 106.0, 69.0, 22.0]  episode_count: 967 q_vals: [-9.326, -9.42, -9.439, -9.169, -9.268, -9.351, -9.594]{"total_number_of_episodes": 969, "number_of_timesteps": 18611, "per_episode_reward": 16.21, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714235},
Step 589 3 visits [72.0, 44.0, 42.0, 234.0, 106.0, 69.0, 22.0]  episode_count: 969 q_vals: [-9.326, -9.42, -9.439, -9.177, -9.268, -9.351, -9.594]Step 590 3 visits [72.0, 44.0, 42.0, 235.0, 106.0, 69.0, 22.0]  episode_count: 972 q_vals: [-9.326, -9.42, -9.439, -9.185, -9.268, -9.351, -9.594]Step 591 3 visits [72.0, 44.0, 42.0, 236.0, 106.0, 69.0, 22.0]  episode_count: 976 q_vals: [-9.326, -9.42, -9.439, -9.147, -9.268, -9.351, -9.594]Step 592 3 visits [72.0, 44.0, 42.0, 237.0, 106.0, 69.0, 22.0]  episode_count: 977 q_vals: [-9.326, -9.42, -9.439, -9.155, -9.268, -9.351, -9.594]{"total_number_of_episodes": 979, "number_of_timesteps": 18735, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
Step 593 3 visits [72.0, 44.0, 42.0, 238.0, 106.0, 69.0, 22.0]  episode_count: 979 q_vals: [-9.326, -9.42, -9.439, -9.163, -9.268, -9.351, -9.594]Step 594 3 visits [72.0, 44.0, 42.0, 239.0, 106.0, 69.0, 22.0]  episode_count: 983 q_vals: [-9.326, -9.42, -9.439, -9.171, -9.268, -9.351, -9.594]Step 595 3 visits [72.0, 44.0, 42.0, 240.0, 106.0, 69.0, 22.0]  episode_count: 984 q_vals: [-9.326, -9.42, -9.439, -9.179, -9.268, -9.351, -9.594]Step 596 3 visits [72.0, 44.0, 42.0, 241.0, 106.0, 69.0, 22.0]  episode_count: 985 q_vals: [-9.326, -9.42, -9.439, -9.187, -9.268, -9.351, -9.594]Step 597 4 visits [72.0, 44.0, 42.0, 241.0, 107.0, 69.0, 22.0]  episode_count: 988 q_vals: [-9.326, -9.42, -9.439, -9.187, -9.285, -9.351, -9.594]Step 598 3 visits [72.0, 44.0, 42.0, 242.0, 107.0, 69.0, 22.0]  episode_count: 988 q_vals: [-9.326, -9.42, -9.439, -9.195, -9.285, -9.351, -9.594]{"total_number_of_episodes": 989, "number_of_timesteps": 18878, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
Step 599 0 visits [73.0, 44.0, 42.0, 242.0, 107.0, 69.0, 22.0]  episode_count: 989 q_vals: [-9.351, -9.42, -9.439, -9.195, -9.285, -9.351, -9.594]Step 600 3 visits [73.0, 44.0, 42.0, 243.0, 107.0, 69.0, 22.0]  episode_count: 993 q_vals: [-9.351, -9.42, -9.439, -9.201, -9.285, -9.351, -9.594]Step 601 3 visits [73.0, 44.0, 42.0, 244.0, 107.0, 69.0, 22.0]  episode_count: 993 q_vals: [-9.351, -9.42, -9.439, -9.207, -9.285, -9.351, -9.594]Step 602 1 visits [73.0, 45.0, 42.0, 244.0, 107.0, 69.0, 22.0]  episode_count: 993 q_vals: [-9.351, -9.458, -9.439, -9.207, -9.285, -9.351, -9.594]Step 603 4 visits [73.0, 45.0, 42.0, 244.0, 108.0, 69.0, 22.0]  episode_count: 997 q_vals: [-9.351, -9.458, -9.439, -9.207, -9.302, -9.351, -9.594]{"total_number_of_episodes": 999, "number_of_timesteps": 19090, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
Step 604 3 visits [73.0, 45.0, 42.0, 245.0, 108.0, 69.0, 22.0]  episode_count: 999 q_vals: [-9.351, -9.458, -9.439, -9.213, -9.302, -9.351, -9.594]Step 605 5 visits [73.0, 45.0, 42.0, 245.0, 108.0, 70.0, 22.0]  episode_count: 999 q_vals: [-9.351, -9.458, -9.439, -9.213, -9.302, -9.37, -9.594]Step 606 2 visits [73.0, 45.0, 43.0, 245.0, 108.0, 70.0, 22.0]  episode_count: 1001 q_vals: [-9.351, -9.458, -9.453, -9.213, -9.302, -9.37, -9.594]Step 607 3 visits [73.0, 45.0, 43.0, 246.0, 108.0, 70.0, 22.0]  episode_count: 1002 q_vals: [-9.351, -9.458, -9.453, -9.221, -9.302, -9.37, -9.594]Step 608 0 visits [74.0, 45.0, 43.0, 246.0, 108.0, 70.0, 22.0]  episode_count: 1004 q_vals: [-9.374, -9.458, -9.453, -9.221, -9.302, -9.37, -9.594]Step 609 6 visits [74.0, 45.0, 43.0, 246.0, 108.0, 70.0, 23.0]  episode_count: 1005 q_vals: [-9.374, -9.458, -9.453, -9.221, -9.302, -9.37, -9.66]Step 610 4 visits [74.0, 45.0, 43.0, 246.0, 109.0, 70.0, 23.0]  episode_count: 1008 q_vals: [-9.374, -9.458, -9.453, -9.221, -9.297, -9.37, -9.66]Step 611 4 visits [74.0, 45.0, 43.0, 246.0, 110.0, 70.0, 23.0]  episode_count: 1008 q_vals: [-9.374, -9.458, -9.453, -9.221, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1009, "number_of_timesteps": 19305, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857295},
Step 612 3 visits [74.0, 45.0, 43.0, 247.0, 110.0, 70.0, 23.0]  episode_count: 1009 q_vals: [-9.374, -9.458, -9.453, -9.228, -9.313, -9.37, -9.66]Step 613 2 visits [74.0, 45.0, 44.0, 247.0, 110.0, 70.0, 23.0]  episode_count: 1009 q_vals: [-9.374, -9.458, -9.49, -9.228, -9.313, -9.37, -9.66]Step 614 3 visits [74.0, 45.0, 44.0, 248.0, 110.0, 70.0, 23.0]  episode_count: 1011 q_vals: [-9.374, -9.458, -9.49, -9.191, -9.313, -9.37, -9.66]Step 615 3 visits [74.0, 45.0, 44.0, 249.0, 110.0, 70.0, 23.0]  episode_count: 1013 q_vals: [-9.374, -9.458, -9.49, -9.199, -9.313, -9.37, -9.66]Step 616 3 visits [74.0, 45.0, 44.0, 250.0, 110.0, 70.0, 23.0]  episode_count: 1016 q_vals: [-9.374, -9.458, -9.49, -9.205, -9.313, -9.37, -9.66]Step 617 3 visits [74.0, 45.0, 44.0, 251.0, 110.0, 70.0, 23.0]  episode_count: 1017 q_vals: [-9.374, -9.458, -9.49, -9.169, -9.313, -9.37, -9.66]Step 618 3 visits [74.0, 45.0, 44.0, 252.0, 110.0, 70.0, 23.0]  episode_count: 1017 q_vals: [-9.374, -9.458, -9.49, -9.132, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1019, "number_of_timesteps": 19534, "per_episode_reward": 16.07, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.07142857142857295},
Step 619 3 visits [74.0, 45.0, 44.0, 253.0, 110.0, 70.0, 23.0]  episode_count: 1019 q_vals: [-9.374, -9.458, -9.49, -9.14, -9.313, -9.37, -9.66]Step 620 3 visits [74.0, 45.0, 44.0, 254.0, 110.0, 70.0, 23.0]  episode_count: 1021 q_vals: [-9.374, -9.458, -9.49, -9.148, -9.313, -9.37, -9.66]Step 621 3 visits [74.0, 45.0, 44.0, 255.0, 110.0, 70.0, 23.0]  episode_count: 1022 q_vals: [-9.374, -9.458, -9.49, -9.156, -9.313, -9.37, -9.66]Step 622 3 visits [74.0, 45.0, 44.0, 256.0, 110.0, 70.0, 23.0]  episode_count: 1023 q_vals: [-9.374, -9.458, -9.49, -9.163, -9.313, -9.37, -9.66]Step 623 3 visits [74.0, 45.0, 44.0, 257.0, 110.0, 70.0, 23.0]  episode_count: 1025 q_vals: [-9.374, -9.458, -9.49, -9.128, -9.313, -9.37, -9.66]Step 624 3 visits [74.0, 45.0, 44.0, 258.0, 110.0, 70.0, 23.0]  episode_count: 1026 q_vals: [-9.374, -9.458, -9.49, -9.092, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1029, "number_of_timesteps": 19758, "per_episode_reward": 16.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.21428571428571175},
Step 625 3 visits [74.0, 45.0, 44.0, 259.0, 110.0, 70.0, 23.0]  episode_count: 1029 q_vals: [-9.374, -9.458, -9.49, -9.097, -9.313, -9.37, -9.66]Step 626 3 visits [74.0, 45.0, 44.0, 260.0, 110.0, 70.0, 23.0]  episode_count: 1031 q_vals: [-9.374, -9.458, -9.49, -9.105, -9.313, -9.37, -9.66]Step 627 3 visits [74.0, 45.0, 44.0, 261.0, 110.0, 70.0, 23.0]  episode_count: 1031 q_vals: [-9.374, -9.458, -9.49, -9.11, -9.313, -9.37, -9.66]Step 628 3 visits [74.0, 45.0, 44.0, 262.0, 110.0, 70.0, 23.0]  episode_count: 1034 q_vals: [-9.374, -9.458, -9.49, -9.117, -9.313, -9.37, -9.66]Step 629 3 visits [74.0, 45.0, 44.0, 263.0, 110.0, 70.0, 23.0]  episode_count: 1036 q_vals: [-9.374, -9.458, -9.49, -9.125, -9.313, -9.37, -9.66]Step 630 3 visits [74.0, 45.0, 44.0, 264.0, 110.0, 70.0, 23.0]  episode_count: 1037 q_vals: [-9.374, -9.458, -9.49, -9.132, -9.313, -9.37, -9.66]Step 631 3 visits [74.0, 45.0, 44.0, 265.0, 110.0, 70.0, 23.0]  episode_count: 1038 q_vals: [-9.374, -9.458, -9.49, -9.137, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1040, "number_of_timesteps": 19948, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.21428571428571175},
Step 632 3 visits [74.0, 45.0, 44.0, 266.0, 110.0, 70.0, 23.0]  episode_count: 1040 q_vals: [-9.374, -9.458, -9.49, -9.144, -9.313, -9.37, -9.66]Step 633 3 visits [74.0, 45.0, 44.0, 267.0, 110.0, 70.0, 23.0]  episode_count: 1041 q_vals: [-9.374, -9.458, -9.49, -9.11, -9.313, -9.37, -9.66]Step 634 3 visits [74.0, 45.0, 44.0, 268.0, 110.0, 70.0, 23.0]  episode_count: 1042 q_vals: [-9.374, -9.458, -9.49, -9.114, -9.313, -9.37, -9.66]Step 635 3 visits [74.0, 45.0, 44.0, 269.0, 110.0, 70.0, 23.0]  episode_count: 1043 q_vals: [-9.374, -9.458, -9.49, -9.08, -9.313, -9.37, -9.66]Step 636 3 visits [74.0, 45.0, 44.0, 270.0, 110.0, 70.0, 23.0]  episode_count: 1046 q_vals: [-9.374, -9.458, -9.49, -9.087, -9.313, -9.37, -9.66]Step 637 3 visits [74.0, 45.0, 44.0, 271.0, 110.0, 70.0, 23.0]  episode_count: 1048 q_vals: [-9.374, -9.458, -9.49, -9.094, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1050, "number_of_timesteps": 20175, "per_episode_reward": 16.57, "episode_reward_trend_value": 0.003174603174603203, "biggest_recent_change": 0.21428571428571175},
Step 638 3 visits [74.0, 45.0, 44.0, 272.0, 110.0, 70.0, 23.0]  episode_count: 1050 q_vals: [-9.374, -9.458, -9.49, -9.102, -9.313, -9.37, -9.66]Step 639 3 visits [74.0, 45.0, 44.0, 273.0, 110.0, 70.0, 23.0]  episode_count: 1051 q_vals: [-9.374, -9.458, -9.49, -9.068, -9.313, -9.37, -9.66]Step 640 3 visits [74.0, 45.0, 44.0, 274.0, 110.0, 70.0, 23.0]  episode_count: 1052 q_vals: [-9.374, -9.458, -9.49, -9.072, -9.313, -9.37, -9.66]Step 641 3 visits [74.0, 45.0, 44.0, 275.0, 110.0, 70.0, 23.0]  episode_count: 1056 q_vals: [-9.374, -9.458, -9.49, -9.08, -9.313, -9.37, -9.66]Step 642 3 visits [74.0, 45.0, 44.0, 276.0, 110.0, 70.0, 23.0]  episode_count: 1058 q_vals: [-9.374, -9.458, -9.49, -9.047, -9.313, -9.37, -9.66]Step 643 3 visits [74.0, 45.0, 44.0, 277.0, 110.0, 70.0, 23.0]  episode_count: 1058 q_vals: [-9.374, -9.458, -9.49, -9.054, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1060, "number_of_timesteps": 20332, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.21428571428571175},
Step 644 3 visits [74.0, 45.0, 44.0, 278.0, 110.0, 70.0, 23.0]  episode_count: 1060 q_vals: [-9.374, -9.458, -9.49, -9.059, -9.313, -9.37, -9.66]Step 645 3 visits [74.0, 45.0, 44.0, 279.0, 110.0, 70.0, 23.0]  episode_count: 1061 q_vals: [-9.374, -9.458, -9.49, -9.066, -9.313, -9.37, -9.66]Step 646 3 visits [74.0, 45.0, 44.0, 280.0, 110.0, 70.0, 23.0]  episode_count: 1063 q_vals: [-9.374, -9.458, -9.49, -9.073, -9.313, -9.37, -9.66]Step 647 3 visits [74.0, 45.0, 44.0, 281.0, 110.0, 70.0, 23.0]  episode_count: 1065 q_vals: [-9.374, -9.458, -9.49, -9.08, -9.313, -9.37, -9.66]Step 648 3 visits [74.0, 45.0, 44.0, 282.0, 110.0, 70.0, 23.0]  episode_count: 1068 q_vals: [-9.374, -9.458, -9.49, -9.087, -9.313, -9.37, -9.66]Step 649 3 visits [74.0, 45.0, 44.0, 283.0, 110.0, 70.0, 23.0]  episode_count: 1069 q_vals: [-9.374, -9.458, -9.49, -9.095, -9.313, -9.37, -9.66]Step 650 3 visits [74.0, 45.0, 44.0, 284.0, 110.0, 70.0, 23.0]  episode_count: 1069 q_vals: [-9.374, -9.458, -9.49, -9.063, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1072, "number_of_timesteps": 20562, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.21428571428571175},
Step 651 3 visits [74.0, 45.0, 44.0, 285.0, 110.0, 70.0, 23.0]  episode_count: 1072 q_vals: [-9.374, -9.458, -9.49, -9.07, -9.313, -9.37, -9.66]Step 652 3 visits [74.0, 45.0, 44.0, 286.0, 110.0, 70.0, 23.0]  episode_count: 1073 q_vals: [-9.374, -9.458, -9.49, -9.077, -9.313, -9.37, -9.66]Step 653 3 visits [74.0, 45.0, 44.0, 287.0, 110.0, 70.0, 23.0]  episode_count: 1076 q_vals: [-9.374, -9.458, -9.49, -9.083, -9.313, -9.37, -9.66]Step 654 3 visits [74.0, 45.0, 44.0, 288.0, 110.0, 70.0, 23.0]  episode_count: 1077 q_vals: [-9.374, -9.458, -9.49, -9.09, -9.313, -9.37, -9.66]Step 655 3 visits [74.0, 45.0, 44.0, 289.0, 110.0, 70.0, 23.0]  episode_count: 1078 q_vals: [-9.374, -9.458, -9.49, -9.097, -9.313, -9.37, -9.66]Step 656 3 visits [74.0, 45.0, 44.0, 290.0, 110.0, 70.0, 23.0]  episode_count: 1081 q_vals: [-9.374, -9.458, -9.49, -9.104, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1083, "number_of_timesteps": 20764, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.21428571428571175},
Step 657 3 visits [74.0, 45.0, 44.0, 291.0, 110.0, 70.0, 23.0]  episode_count: 1083 q_vals: [-9.374, -9.458, -9.49, -9.107, -9.313, -9.37, -9.66]Step 658 3 visits [74.0, 45.0, 44.0, 292.0, 110.0, 70.0, 23.0]  episode_count: 1084 q_vals: [-9.374, -9.458, -9.49, -9.114, -9.313, -9.37, -9.66]Step 659 3 visits [74.0, 45.0, 44.0, 293.0, 110.0, 70.0, 23.0]  episode_count: 1088 q_vals: [-9.374, -9.458, -9.49, -9.121, -9.313, -9.37, -9.66]Step 660 3 visits [74.0, 45.0, 44.0, 294.0, 110.0, 70.0, 23.0]  episode_count: 1089 q_vals: [-9.374, -9.458, -9.49, -9.128, -9.313, -9.37, -9.66]Step 661 3 visits [74.0, 45.0, 44.0, 295.0, 110.0, 70.0, 23.0]  episode_count: 1091 q_vals: [-9.374, -9.458, -9.49, -9.131, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1093, "number_of_timesteps": 20912, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.21428571428571175},
Step 662 3 visits [74.0, 45.0, 44.0, 296.0, 110.0, 70.0, 23.0]  episode_count: 1093 q_vals: [-9.374, -9.458, -9.49, -9.138, -9.313, -9.37, -9.66]Step 663 3 visits [74.0, 45.0, 44.0, 297.0, 110.0, 70.0, 23.0]  episode_count: 1094 q_vals: [-9.374, -9.458, -9.49, -9.142, -9.313, -9.37, -9.66]Step 664 3 visits [74.0, 45.0, 44.0, 298.0, 110.0, 70.0, 23.0]  episode_count: 1095 q_vals: [-9.374, -9.458, -9.49, -9.148, -9.313, -9.37, -9.66]Step 665 3 visits [74.0, 45.0, 44.0, 299.0, 110.0, 70.0, 23.0]  episode_count: 1098 q_vals: [-9.374, -9.458, -9.49, -9.155, -9.313, -9.37, -9.66]Step 666 3 visits [74.0, 45.0, 44.0, 300.0, 110.0, 70.0, 23.0]  episode_count: 1099 q_vals: [-9.374, -9.458, -9.49, -9.161, -9.313, -9.37, -9.66]Step 667 3 visits [74.0, 45.0, 44.0, 301.0, 110.0, 70.0, 23.0]  episode_count: 1102 q_vals: [-9.374, -9.458, -9.49, -9.168, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1104, "number_of_timesteps": 21099, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.003968253968253973, "biggest_recent_change": 0.21428571428571175},
Step 668 3 visits [74.0, 45.0, 44.0, 302.0, 110.0, 70.0, 23.0]  episode_count: 1104 q_vals: [-9.374, -9.458, -9.49, -9.174, -9.313, -9.37, -9.66]Step 669 3 visits [74.0, 45.0, 44.0, 303.0, 110.0, 70.0, 23.0]  episode_count: 1105 q_vals: [-9.374, -9.458, -9.49, -9.181, -9.313, -9.37, -9.66]Step 670 3 visits [74.0, 45.0, 44.0, 304.0, 110.0, 70.0, 23.0]  episode_count: 1109 q_vals: [-9.374, -9.458, -9.49, -9.187, -9.313, -9.37, -9.66]Step 671 3 visits [74.0, 45.0, 44.0, 305.0, 110.0, 70.0, 23.0]  episode_count: 1111 q_vals: [-9.374, -9.458, -9.49, -9.193, -9.313, -9.37, -9.66]Step 672 3 visits [74.0, 45.0, 44.0, 306.0, 110.0, 70.0, 23.0]  episode_count: 1113 q_vals: [-9.374, -9.458, -9.49, -9.2, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1116, "number_of_timesteps": 21260, "per_episode_reward": 16.43, "episode_reward_trend_value": 0.003968253968253935, "biggest_recent_change": 0.21428571428571175},
Step 673 3 visits [74.0, 45.0, 44.0, 307.0, 110.0, 70.0, 23.0]  episode_count: 1116 q_vals: [-9.374, -9.458, -9.49, -9.206, -9.313, -9.37, -9.66]Step 674 3 visits [74.0, 45.0, 44.0, 308.0, 110.0, 70.0, 23.0]  episode_count: 1119 q_vals: [-9.374, -9.458, -9.49, -9.209, -9.313, -9.37, -9.66]Step 675 3 visits [74.0, 45.0, 44.0, 309.0, 110.0, 70.0, 23.0]  episode_count: 1121 q_vals: [-9.374, -9.458, -9.49, -9.179, -9.313, -9.37, -9.66]Step 676 3 visits [74.0, 45.0, 44.0, 310.0, 110.0, 70.0, 23.0]  episode_count: 1123 q_vals: [-9.374, -9.458, -9.49, -9.181, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1127, "number_of_timesteps": 21395, "per_episode_reward": 16.14, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2857142857142847},
Step 677 3 visits [74.0, 45.0, 44.0, 311.0, 110.0, 70.0, 23.0]  episode_count: 1127 q_vals: [-9.374, -9.458, -9.49, -9.185, -9.313, -9.37, -9.66]Step 678 3 visits [74.0, 45.0, 44.0, 312.0, 110.0, 70.0, 23.0]  episode_count: 1128 q_vals: [-9.374, -9.458, -9.49, -9.191, -9.313, -9.37, -9.66]Step 679 3 visits [74.0, 45.0, 44.0, 313.0, 110.0, 70.0, 23.0]  episode_count: 1130 q_vals: [-9.374, -9.458, -9.49, -9.193, -9.313, -9.37, -9.66]Step 680 3 visits [74.0, 45.0, 44.0, 314.0, 110.0, 70.0, 23.0]  episode_count: 1133 q_vals: [-9.374, -9.458, -9.49, -9.199, -9.313, -9.37, -9.66]{"total_number_of_episodes": 1137, "number_of_timesteps": 21524, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.004761904761904745, "biggest_recent_change": 0.2857142857142847},
Step 681 3 visits [74.0, 45.0, 44.0, 315.0, 110.0, 70.0, 23.0]  episode_count: 1137 q_vals: [-9.374, -9.458, -9.49, -9.202, -9.313, -9.37, -9.66]Step 682 3 visits [74.0, 45.0, 44.0, 316.0, 110.0, 70.0, 23.0]  episode_count: 1138 q_vals: [-9.374, -9.458, -9.49, -9.208, -9.313, -9.37, -9.66]Step 683 3 visits [74.0, 45.0, 44.0, 317.0, 110.0, 70.0, 23.0]  episode_count: 1140 q_vals: [-9.374, -9.458, -9.49, -9.214, -9.313, -9.37, -9.66]Step 684 5 visits [74.0, 45.0, 44.0, 317.0, 110.0, 71.0, 23.0]  episode_count: 1144 q_vals: [-9.374, -9.458, -9.49, -9.214, -9.313, -9.395, -9.66]Step 685 4 visits [74.0, 45.0, 44.0, 317.0, 111.0, 71.0, 23.0]  episode_count: 1144 q_vals: [-9.374, -9.458, -9.49, -9.214, -9.229, -9.395, -9.66]{"total_number_of_episodes": 1147, "number_of_timesteps": 21648, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.006349206349206366, "biggest_recent_change": 0.2857142857142847},
Step 686 4 visits [74.0, 45.0, 44.0, 317.0, 112.0, 71.0, 23.0]  episode_count: 1147 q_vals: [-9.374, -9.458, -9.49, -9.214, -9.245, -9.395, -9.66]Step 687 4 visits [74.0, 45.0, 44.0, 317.0, 113.0, 71.0, 23.0]  episode_count: 1150 q_vals: [-9.374, -9.458, -9.49, -9.214, -9.254, -9.395, -9.66]Step 688 4 visits [74.0, 45.0, 44.0, 317.0, 114.0, 71.0, 23.0]  episode_count: 1152 q_vals: [-9.374, -9.458, -9.49, -9.214, -9.269, -9.395, -9.66]Step 689 4 visits [74.0, 45.0, 44.0, 317.0, 115.0, 71.0, 23.0]  episode_count: 1155 q_vals: [-9.374, -9.458, -9.49, -9.214, -9.285, -9.395, -9.66]{"total_number_of_episodes": 1157, "number_of_timesteps": 21775, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.2857142857142847},
Step 690 4 visits [74.0, 45.0, 44.0, 317.0, 116.0, 71.0, 23.0]  episode_count: 1157 q_vals: [-9.374, -9.458, -9.49, -9.214, -9.29, -9.395, -9.66]Step 691 4 visits [74.0, 45.0, 44.0, 317.0, 117.0, 71.0, 23.0]  episode_count: 1161 q_vals: [-9.374, -9.458, -9.49, -9.214, -9.304, -9.395, -9.66]Step 692 4 visits [74.0, 45.0, 44.0, 317.0, 118.0, 71.0, 23.0]  episode_count: 1161 q_vals: [-9.374, -9.458, -9.49, -9.214, -9.312, -9.395, -9.66]Step 693 3 visits [74.0, 45.0, 44.0, 318.0, 118.0, 71.0, 23.0]  episode_count: 1165 q_vals: [-9.374, -9.458, -9.49, -9.216, -9.312, -9.395, -9.66]{"total_number_of_episodes": 1168, "number_of_timesteps": 21904, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.004761904761904745, "biggest_recent_change": 0.2857142857142847},
Step 694 3 visits [74.0, 45.0, 44.0, 319.0, 118.0, 71.0, 23.0]  episode_count: 1168 q_vals: [-9.374, -9.458, -9.49, -9.218, -9.312, -9.395, -9.66]Step 695 3 visits [74.0, 45.0, 44.0, 320.0, 118.0, 71.0, 23.0]  episode_count: 1168 q_vals: [-9.374, -9.458, -9.49, -9.224, -9.312, -9.395, -9.66]Step 696 4 visits [74.0, 45.0, 44.0, 320.0, 119.0, 71.0, 23.0]  episode_count: 1174 q_vals: [-9.374, -9.458, -9.49, -9.224, -9.316, -9.395, -9.66]Step 697 1 visits [74.0, 46.0, 44.0, 320.0, 119.0, 71.0, 23.0]  episode_count: 1174 q_vals: [-9.374, -9.494, -9.49, -9.224, -9.316, -9.395, -9.66]Step 698 0 visits [75.0, 46.0, 44.0, 320.0, 119.0, 71.0, 23.0]  episode_count: 1177 q_vals: [-9.398, -9.494, -9.49, -9.224, -9.316, -9.395, -9.66]{"total_number_of_episodes": 1180, "number_of_timesteps": 22054, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.007936507936507927, "biggest_recent_change": 0.2857142857142865},
Step 699 3 visits [75.0, 46.0, 44.0, 321.0, 119.0, 71.0, 23.0]  episode_count: 1180 q_vals: [-9.398, -9.494, -9.49, -9.226, -9.316, -9.395, -9.66]Step 700 4 visits [75.0, 46.0, 44.0, 321.0, 120.0, 71.0, 23.0]  episode_count: 1181 q_vals: [-9.398, -9.494, -9.49, -9.226, -9.331, -9.395, -9.66]Step 701 3 visits [75.0, 46.0, 44.0, 322.0, 120.0, 71.0, 23.0]  episode_count: 1185 q_vals: [-9.398, -9.494, -9.49, -9.197, -9.331, -9.395, -9.66]Step 702 3 visits [75.0, 46.0, 44.0, 323.0, 120.0, 71.0, 23.0]  episode_count: 1188 q_vals: [-9.398, -9.494, -9.49, -9.203, -9.331, -9.395, -9.66]Step 703 3 visits [75.0, 46.0, 44.0, 324.0, 120.0, 71.0, 23.0]  episode_count: 1188 q_vals: [-9.398, -9.494, -9.49, -9.205, -9.331, -9.395, -9.66]{"total_number_of_episodes": 1193, "number_of_timesteps": 22205, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.007936507936507927, "biggest_recent_change": 0.2857142857142865},
Step 704 3 visits [75.0, 46.0, 44.0, 325.0, 120.0, 71.0, 23.0]  episode_count: 1193 q_vals: [-9.398, -9.494, -9.49, -9.211, -9.331, -9.395, -9.66]Step 705 3 visits [75.0, 46.0, 44.0, 326.0, 120.0, 71.0, 23.0]  episode_count: 1195 q_vals: [-9.398, -9.494, -9.49, -9.217, -9.331, -9.395, -9.66]Step 706 3 visits [75.0, 46.0, 44.0, 327.0, 120.0, 71.0, 23.0]  episode_count: 1196 q_vals: [-9.398, -9.494, -9.49, -9.223, -9.331, -9.395, -9.66]Step 707 3 visits [75.0, 46.0, 44.0, 328.0, 120.0, 71.0, 23.0]  episode_count: 1200 q_vals: [-9.398, -9.494, -9.49, -9.194, -9.331, -9.395, -9.66]Step 708 3 visits [75.0, 46.0, 44.0, 329.0, 120.0, 71.0, 23.0]  episode_count: 1202 q_vals: [-9.398, -9.494, -9.49, -9.167, -9.331, -9.395, -9.66]Step 709 3 visits [75.0, 46.0, 44.0, 330.0, 120.0, 71.0, 23.0]  episode_count: 1202 q_vals: [-9.398, -9.494, -9.49, -9.168, -9.331, -9.395, -9.66]{"total_number_of_episodes": 1206, "number_of_timesteps": 22382, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.008730158730158737, "biggest_recent_change": 0.2857142857142865},
Step 710 3 visits [75.0, 46.0, 44.0, 331.0, 120.0, 71.0, 23.0]  episode_count: 1206 q_vals: [-9.398, -9.494, -9.49, -9.171, -9.331, -9.395, -9.66]Step 711 3 visits [75.0, 46.0, 44.0, 332.0, 120.0, 71.0, 23.0]  episode_count: 1208 q_vals: [-9.398, -9.494, -9.49, -9.175, -9.331, -9.395, -9.66]Step 712 3 visits [75.0, 46.0, 44.0, 333.0, 120.0, 71.0, 23.0]  episode_count: 1209 q_vals: [-9.398, -9.494, -9.49, -9.181, -9.331, -9.395, -9.66]Step 713 3 visits [75.0, 46.0, 44.0, 334.0, 120.0, 71.0, 23.0]  episode_count: 1212 q_vals: [-9.398, -9.494, -9.49, -9.183, -9.331, -9.395, -9.66]Step 714 3 visits [75.0, 46.0, 44.0, 335.0, 120.0, 71.0, 23.0]  episode_count: 1214 q_vals: [-9.398, -9.494, -9.49, -9.189, -9.331, -9.395, -9.66]{"total_number_of_episodes": 1216, "number_of_timesteps": 22530, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.007936507936507927, "biggest_recent_change": 0.2857142857142865},
Step 715 3 visits [75.0, 46.0, 44.0, 336.0, 120.0, 71.0, 23.0]  episode_count: 1216 q_vals: [-9.398, -9.494, -9.49, -9.192, -9.331, -9.395, -9.66]Step 716 3 visits [75.0, 46.0, 44.0, 337.0, 120.0, 71.0, 23.0]  episode_count: 1219 q_vals: [-9.398, -9.494, -9.49, -9.194, -9.331, -9.395, -9.66]Step 717 3 visits [75.0, 46.0, 44.0, 338.0, 120.0, 71.0, 23.0]  episode_count: 1221 q_vals: [-9.398, -9.494, -9.49, -9.2, -9.331, -9.395, -9.66]Step 718 3 visits [75.0, 46.0, 44.0, 339.0, 120.0, 71.0, 23.0]  episode_count: 1223 q_vals: [-9.398, -9.494, -9.49, -9.173, -9.331, -9.395, -9.66]Step 719 3 visits [75.0, 46.0, 44.0, 340.0, 120.0, 71.0, 23.0]  episode_count: 1223 q_vals: [-9.398, -9.494, -9.49, -9.178, -9.331, -9.395, -9.66]Step 720 3 visits [75.0, 46.0, 44.0, 341.0, 120.0, 71.0, 23.0]  episode_count: 1225 q_vals: [-9.398, -9.494, -9.49, -9.18, -9.331, -9.395, -9.66]{"total_number_of_episodes": 1226, "number_of_timesteps": 22671, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.004761904761904764, "biggest_recent_change": 0.2857142857142865},
Step 721 3 visits [75.0, 46.0, 44.0, 342.0, 120.0, 71.0, 23.0]  episode_count: 1226 q_vals: [-9.398, -9.494, -9.49, -9.182, -9.331, -9.395, -9.66]Step 722 3 visits [75.0, 46.0, 44.0, 343.0, 120.0, 71.0, 23.0]  episode_count: 1228 q_vals: [-9.398, -9.494, -9.49, -9.188, -9.331, -9.395, -9.66]Step 723 3 visits [75.0, 46.0, 44.0, 344.0, 120.0, 71.0, 23.0]  episode_count: 1228 q_vals: [-9.398, -9.494, -9.49, -9.194, -9.331, -9.395, -9.66]Step 724 3 visits [75.0, 46.0, 44.0, 345.0, 120.0, 71.0, 23.0]  episode_count: 1231 q_vals: [-9.398, -9.494, -9.49, -9.199, -9.331, -9.395, -9.66]Step 725 3 visits [75.0, 46.0, 44.0, 346.0, 120.0, 71.0, 23.0]  episode_count: 1232 q_vals: [-9.398, -9.494, -9.49, -9.203, -9.331, -9.395, -9.66]Step 726 3 visits [75.0, 46.0, 44.0, 347.0, 120.0, 71.0, 23.0]  episode_count: 1234 q_vals: [-9.398, -9.494, -9.49, -9.208, -9.331, -9.395, -9.66]Step 727 3 visits [75.0, 46.0, 44.0, 348.0, 120.0, 71.0, 23.0]  episode_count: 1235 q_vals: [-9.398, -9.494, -9.49, -9.214, -9.331, -9.395, -9.66]{"total_number_of_episodes": 1237, "number_of_timesteps": 22927, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.2857142857142865},
Step 728 3 visits [75.0, 46.0, 44.0, 349.0, 120.0, 71.0, 23.0]  episode_count: 1237 q_vals: [-9.398, -9.494, -9.49, -9.218, -9.331, -9.395, -9.66]Step 729 3 visits [75.0, 46.0, 44.0, 350.0, 120.0, 71.0, 23.0]  episode_count: 1240 q_vals: [-9.398, -9.494, -9.49, -9.224, -9.331, -9.395, -9.66]Step 730 3 visits [75.0, 46.0, 44.0, 351.0, 120.0, 71.0, 23.0]  episode_count: 1242 q_vals: [-9.398, -9.494, -9.49, -9.216, -9.331, -9.395, -9.66]Step 731 3 visits [75.0, 46.0, 44.0, 352.0, 120.0, 71.0, 23.0]  episode_count: 1242 q_vals: [-9.398, -9.494, -9.49, -9.221, -9.331, -9.395, -9.66]Step 732 3 visits [75.0, 46.0, 44.0, 353.0, 120.0, 71.0, 23.0]  episode_count: 1245 q_vals: [-9.398, -9.494, -9.49, -9.195, -9.331, -9.395, -9.66]{"total_number_of_episodes": 1247, "number_of_timesteps": 23104, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.2857142857142865},
Step 733 3 visits [75.0, 46.0, 44.0, 354.0, 120.0, 71.0, 23.0]  episode_count: 1247 q_vals: [-9.398, -9.494, -9.49, -9.2, -9.331, -9.395, -9.66]Step 734 3 visits [75.0, 46.0, 44.0, 355.0, 120.0, 71.0, 23.0]  episode_count: 1247 q_vals: [-9.398, -9.494, -9.49, -9.205, -9.331, -9.395, -9.66]Step 735 3 visits [75.0, 46.0, 44.0, 356.0, 120.0, 71.0, 23.0]  episode_count: 1247 q_vals: [-9.398, -9.494, -9.49, -9.207, -9.331, -9.395, -9.66]Step 736 3 visits [75.0, 46.0, 44.0, 357.0, 120.0, 71.0, 23.0]  episode_count: 1249 q_vals: [-9.398, -9.494, -9.49, -9.208, -9.331, -9.395, -9.66]Step 737 3 visits [75.0, 46.0, 44.0, 358.0, 120.0, 71.0, 23.0]  episode_count: 1251 q_vals: [-9.398, -9.494, -9.49, -9.213, -9.331, -9.395, -9.66]Step 738 3 visits [75.0, 46.0, 44.0, 359.0, 120.0, 71.0, 23.0]  episode_count: 1252 q_vals: [-9.398, -9.494, -9.49, -9.217, -9.331, -9.395, -9.66]Step 739 3 visits [75.0, 46.0, 44.0, 360.0, 120.0, 71.0, 23.0]  episode_count: 1255 q_vals: [-9.398, -9.494, -9.49, -9.219, -9.331, -9.395, -9.66]{"total_number_of_episodes": 1257, "number_of_timesteps": 23296, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.2857142857142865},
Step 740 3 visits [75.0, 46.0, 44.0, 361.0, 120.0, 71.0, 23.0]  episode_count: 1257 q_vals: [-9.398, -9.494, -9.49, -9.22, -9.331, -9.395, -9.66]Step 741 3 visits [75.0, 46.0, 44.0, 362.0, 120.0, 71.0, 23.0]  episode_count: 1258 q_vals: [-9.398, -9.494, -9.49, -9.225, -9.331, -9.395, -9.66]Step 742 5 visits [75.0, 46.0, 44.0, 362.0, 120.0, 72.0, 23.0]  episode_count: 1261 q_vals: [-9.398, -9.494, -9.49, -9.225, -9.331, -9.419, -9.66]Step 743 3 visits [75.0, 46.0, 44.0, 363.0, 120.0, 72.0, 23.0]  episode_count: 1261 q_vals: [-9.398, -9.494, -9.49, -9.23, -9.331, -9.419, -9.66]Step 744 3 visits [75.0, 46.0, 44.0, 364.0, 120.0, 72.0, 23.0]  episode_count: 1262 q_vals: [-9.398, -9.494, -9.49, -9.205, -9.331, -9.419, -9.66]Step 745 3 visits [75.0, 46.0, 44.0, 365.0, 120.0, 72.0, 23.0]  episode_count: 1265 q_vals: [-9.398, -9.494, -9.49, -9.21, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1267, "number_of_timesteps": 23501, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.2857142857142865},
Step 746 3 visits [75.0, 46.0, 44.0, 366.0, 120.0, 72.0, 23.0]  episode_count: 1267 q_vals: [-9.398, -9.494, -9.49, -9.185, -9.331, -9.419, -9.66]Step 747 3 visits [75.0, 46.0, 44.0, 367.0, 120.0, 72.0, 23.0]  episode_count: 1268 q_vals: [-9.398, -9.494, -9.49, -9.16, -9.331, -9.419, -9.66]Step 748 3 visits [75.0, 46.0, 44.0, 368.0, 120.0, 72.0, 23.0]  episode_count: 1269 q_vals: [-9.398, -9.494, -9.49, -9.164, -9.331, -9.419, -9.66]Step 749 3 visits [75.0, 46.0, 44.0, 369.0, 120.0, 72.0, 23.0]  episode_count: 1270 q_vals: [-9.398, -9.494, -9.49, -9.165, -9.331, -9.419, -9.66]Step 750 3 visits [75.0, 46.0, 44.0, 370.0, 120.0, 72.0, 23.0]  episode_count: 1274 q_vals: [-9.398, -9.494, -9.49, -9.14, -9.331, -9.419, -9.66]Step 751 3 visits [75.0, 46.0, 44.0, 371.0, 120.0, 72.0, 23.0]  episode_count: 1276 q_vals: [-9.398, -9.494, -9.49, -9.145, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1277, "number_of_timesteps": 23704, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 752 3 visits [75.0, 46.0, 44.0, 372.0, 120.0, 72.0, 23.0]  episode_count: 1277 q_vals: [-9.398, -9.494, -9.49, -9.148, -9.331, -9.419, -9.66]Step 753 3 visits [75.0, 46.0, 44.0, 373.0, 120.0, 72.0, 23.0]  episode_count: 1278 q_vals: [-9.398, -9.494, -9.49, -9.15, -9.331, -9.419, -9.66]Step 754 3 visits [75.0, 46.0, 44.0, 374.0, 120.0, 72.0, 23.0]  episode_count: 1278 q_vals: [-9.398, -9.494, -9.49, -9.125, -9.331, -9.419, -9.66]Step 755 3 visits [75.0, 46.0, 44.0, 375.0, 120.0, 72.0, 23.0]  episode_count: 1281 q_vals: [-9.398, -9.494, -9.49, -9.128, -9.331, -9.419, -9.66]Step 756 3 visits [75.0, 46.0, 44.0, 376.0, 120.0, 72.0, 23.0]  episode_count: 1282 q_vals: [-9.398, -9.494, -9.49, -9.103, -9.331, -9.419, -9.66]Step 757 3 visits [75.0, 46.0, 44.0, 377.0, 120.0, 72.0, 23.0]  episode_count: 1284 q_vals: [-9.398, -9.494, -9.49, -9.109, -9.331, -9.419, -9.66]Step 758 3 visits [75.0, 46.0, 44.0, 378.0, 120.0, 72.0, 23.0]  episode_count: 1284 q_vals: [-9.398, -9.494, -9.49, -9.114, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1288, "number_of_timesteps": 23937, "per_episode_reward": 15.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 759 3 visits [75.0, 46.0, 44.0, 379.0, 120.0, 72.0, 23.0]  episode_count: 1288 q_vals: [-9.398, -9.494, -9.49, -9.114, -9.331, -9.419, -9.66]Step 760 3 visits [75.0, 46.0, 44.0, 380.0, 120.0, 72.0, 23.0]  episode_count: 1289 q_vals: [-9.398, -9.494, -9.49, -9.119, -9.331, -9.419, -9.66]Step 761 3 visits [75.0, 46.0, 44.0, 381.0, 120.0, 72.0, 23.0]  episode_count: 1290 q_vals: [-9.398, -9.494, -9.49, -9.125, -9.331, -9.419, -9.66]Step 762 3 visits [75.0, 46.0, 44.0, 382.0, 120.0, 72.0, 23.0]  episode_count: 1292 q_vals: [-9.398, -9.494, -9.49, -9.13, -9.331, -9.419, -9.66]Step 763 3 visits [75.0, 46.0, 44.0, 383.0, 120.0, 72.0, 23.0]  episode_count: 1294 q_vals: [-9.398, -9.494, -9.49, -9.135, -9.331, -9.419, -9.66]Step 764 3 visits [75.0, 46.0, 44.0, 384.0, 120.0, 72.0, 23.0]  episode_count: 1294 q_vals: [-9.398, -9.494, -9.49, -9.111, -9.331, -9.419, -9.66]Step 765 3 visits [75.0, 46.0, 44.0, 385.0, 120.0, 72.0, 23.0]  episode_count: 1297 q_vals: [-9.398, -9.494, -9.49, -9.108, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1298, "number_of_timesteps": 24119, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
Step 766 3 visits [75.0, 46.0, 44.0, 386.0, 120.0, 72.0, 23.0]  episode_count: 1298 q_vals: [-9.398, -9.494, -9.49, -9.109, -9.331, -9.419, -9.66]Step 767 3 visits [75.0, 46.0, 44.0, 387.0, 120.0, 72.0, 23.0]  episode_count: 1300 q_vals: [-9.398, -9.494, -9.49, -9.109, -9.331, -9.419, -9.66]Step 768 3 visits [75.0, 46.0, 44.0, 388.0, 120.0, 72.0, 23.0]  episode_count: 1301 q_vals: [-9.398, -9.494, -9.49, -9.086, -9.331, -9.419, -9.66]Step 769 3 visits [75.0, 46.0, 44.0, 389.0, 120.0, 72.0, 23.0]  episode_count: 1302 q_vals: [-9.398, -9.494, -9.49, -9.091, -9.331, -9.419, -9.66]Step 770 3 visits [75.0, 46.0, 44.0, 390.0, 120.0, 72.0, 23.0]  episode_count: 1306 q_vals: [-9.398, -9.494, -9.49, -9.094, -9.331, -9.419, -9.66]Step 771 3 visits [75.0, 46.0, 44.0, 391.0, 120.0, 72.0, 23.0]  episode_count: 1306 q_vals: [-9.398, -9.494, -9.49, -9.099, -9.331, -9.419, -9.66]Step 772 3 visits [75.0, 46.0, 44.0, 392.0, 120.0, 72.0, 23.0]  episode_count: 1307 q_vals: [-9.398, -9.494, -9.49, -9.099, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1310, "number_of_timesteps": 24372, "per_episode_reward": 15.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 773 3 visits [75.0, 46.0, 44.0, 393.0, 120.0, 72.0, 23.0]  episode_count: 1310 q_vals: [-9.398, -9.494, -9.49, -9.104, -9.331, -9.419, -9.66]Step 774 3 visits [75.0, 46.0, 44.0, 394.0, 120.0, 72.0, 23.0]  episode_count: 1313 q_vals: [-9.398, -9.494, -9.49, -9.109, -9.331, -9.419, -9.66]Step 775 3 visits [75.0, 46.0, 44.0, 395.0, 120.0, 72.0, 23.0]  episode_count: 1313 q_vals: [-9.398, -9.494, -9.49, -9.086, -9.331, -9.419, -9.66]Step 776 3 visits [75.0, 46.0, 44.0, 396.0, 120.0, 72.0, 23.0]  episode_count: 1315 q_vals: [-9.398, -9.494, -9.49, -9.087, -9.331, -9.419, -9.66]Step 777 3 visits [75.0, 46.0, 44.0, 397.0, 120.0, 72.0, 23.0]  episode_count: 1316 q_vals: [-9.398, -9.494, -9.49, -9.064, -9.331, -9.419, -9.66]Step 778 3 visits [75.0, 46.0, 44.0, 398.0, 120.0, 72.0, 23.0]  episode_count: 1318 q_vals: [-9.398, -9.494, -9.49, -9.069, -9.331, -9.419, -9.66]Step 779 3 visits [75.0, 46.0, 44.0, 399.0, 120.0, 72.0, 23.0]  episode_count: 1319 q_vals: [-9.398, -9.494, -9.49, -9.07, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1321, "number_of_timesteps": 24582, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 780 3 visits [75.0, 46.0, 44.0, 400.0, 120.0, 72.0, 23.0]  episode_count: 1321 q_vals: [-9.398, -9.494, -9.49, -9.072, -9.331, -9.419, -9.66]Step 781 3 visits [75.0, 46.0, 44.0, 401.0, 120.0, 72.0, 23.0]  episode_count: 1322 q_vals: [-9.398, -9.494, -9.49, -9.073, -9.331, -9.419, -9.66]Step 782 3 visits [75.0, 46.0, 44.0, 402.0, 120.0, 72.0, 23.0]  episode_count: 1324 q_vals: [-9.398, -9.494, -9.49, -9.078, -9.331, -9.419, -9.66]Step 783 3 visits [75.0, 46.0, 44.0, 403.0, 120.0, 72.0, 23.0]  episode_count: 1325 q_vals: [-9.398, -9.494, -9.49, -9.084, -9.331, -9.419, -9.66]Step 784 3 visits [75.0, 46.0, 44.0, 404.0, 120.0, 72.0, 23.0]  episode_count: 1325 q_vals: [-9.398, -9.494, -9.49, -9.086, -9.331, -9.419, -9.66]Step 785 3 visits [75.0, 46.0, 44.0, 405.0, 120.0, 72.0, 23.0]  episode_count: 1327 q_vals: [-9.398, -9.494, -9.49, -9.091, -9.331, -9.419, -9.66]Step 786 3 visits [75.0, 46.0, 44.0, 406.0, 120.0, 72.0, 23.0]  episode_count: 1329 q_vals: [-9.398, -9.494, -9.49, -9.091, -9.331, -9.419, -9.66]Step 787 3 visits [75.0, 46.0, 44.0, 407.0, 120.0, 72.0, 23.0]  episode_count: 1330 q_vals: [-9.398, -9.494, -9.49, -9.092, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1331, "number_of_timesteps": 24812, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 788 3 visits [75.0, 46.0, 44.0, 408.0, 120.0, 72.0, 23.0]  episode_count: 1331 q_vals: [-9.398, -9.494, -9.49, -9.092, -9.331, -9.419, -9.66]Step 789 3 visits [75.0, 46.0, 44.0, 409.0, 120.0, 72.0, 23.0]  episode_count: 1333 q_vals: [-9.398, -9.494, -9.49, -9.097, -9.331, -9.419, -9.66]Step 790 3 visits [75.0, 46.0, 44.0, 410.0, 120.0, 72.0, 23.0]  episode_count: 1333 q_vals: [-9.398, -9.494, -9.49, -9.102, -9.331, -9.419, -9.66]Step 791 3 visits [75.0, 46.0, 44.0, 411.0, 120.0, 72.0, 23.0]  episode_count: 1336 q_vals: [-9.398, -9.494, -9.49, -9.104, -9.331, -9.419, -9.66]Step 792 3 visits [75.0, 46.0, 44.0, 412.0, 120.0, 72.0, 23.0]  episode_count: 1336 q_vals: [-9.398, -9.494, -9.49, -9.106, -9.331, -9.419, -9.66]Step 793 3 visits [75.0, 46.0, 44.0, 413.0, 120.0, 72.0, 23.0]  episode_count: 1337 q_vals: [-9.398, -9.494, -9.49, -9.11, -9.331, -9.419, -9.66]Step 794 3 visits [75.0, 46.0, 44.0, 414.0, 120.0, 72.0, 23.0]  episode_count: 1338 q_vals: [-9.398, -9.494, -9.49, -9.115, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1342, "number_of_timesteps": 25071, "per_episode_reward": 15.93, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
Step 795 3 visits [75.0, 46.0, 44.0, 415.0, 120.0, 72.0, 23.0]  episode_count: 1342 q_vals: [-9.398, -9.494, -9.49, -9.116, -9.331, -9.419, -9.66]Step 796 3 visits [75.0, 46.0, 44.0, 416.0, 120.0, 72.0, 23.0]  episode_count: 1344 q_vals: [-9.398, -9.494, -9.49, -9.12, -9.331, -9.419, -9.66]Step 797 3 visits [75.0, 46.0, 44.0, 417.0, 120.0, 72.0, 23.0]  episode_count: 1346 q_vals: [-9.398, -9.494, -9.49, -9.12, -9.331, -9.419, -9.66]Step 798 3 visits [75.0, 46.0, 44.0, 418.0, 120.0, 72.0, 23.0]  episode_count: 1346 q_vals: [-9.398, -9.494, -9.49, -9.098, -9.331, -9.419, -9.66]Step 799 3 visits [75.0, 46.0, 44.0, 419.0, 120.0, 72.0, 23.0]  episode_count: 1349 q_vals: [-9.398, -9.494, -9.49, -9.103, -9.331, -9.419, -9.66]Step 800 3 visits [75.0, 46.0, 44.0, 420.0, 120.0, 72.0, 23.0]  episode_count: 1351 q_vals: [-9.398, -9.494, -9.49, -9.105, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1354, "number_of_timesteps": 25274, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 801 3 visits [75.0, 46.0, 44.0, 421.0, 120.0, 72.0, 23.0]  episode_count: 1354 q_vals: [-9.398, -9.494, -9.49, -9.105, -9.331, -9.419, -9.66]Step 802 3 visits [75.0, 46.0, 44.0, 422.0, 120.0, 72.0, 23.0]  episode_count: 1355 q_vals: [-9.398, -9.494, -9.49, -9.105, -9.331, -9.419, -9.66]Step 803 3 visits [75.0, 46.0, 44.0, 423.0, 120.0, 72.0, 23.0]  episode_count: 1356 q_vals: [-9.398, -9.494, -9.49, -9.11, -9.331, -9.419, -9.66]Step 804 3 visits [75.0, 46.0, 44.0, 424.0, 120.0, 72.0, 23.0]  episode_count: 1361 q_vals: [-9.398, -9.494, -9.49, -9.115, -9.331, -9.419, -9.66]Step 805 3 visits [75.0, 46.0, 44.0, 425.0, 120.0, 72.0, 23.0]  episode_count: 1361 q_vals: [-9.398, -9.494, -9.49, -9.115, -9.331, -9.419, -9.66]Step 806 3 visits [75.0, 46.0, 44.0, 426.0, 120.0, 72.0, 23.0]  episode_count: 1361 q_vals: [-9.398, -9.494, -9.49, -9.117, -9.331, -9.419, -9.66]Step 807 3 visits [75.0, 46.0, 44.0, 427.0, 120.0, 72.0, 23.0]  episode_count: 1363 q_vals: [-9.398, -9.494, -9.49, -9.117, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1366, "number_of_timesteps": 25473, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 808 3 visits [75.0, 46.0, 44.0, 428.0, 120.0, 72.0, 23.0]  episode_count: 1366 q_vals: [-9.398, -9.494, -9.49, -9.122, -9.331, -9.419, -9.66]Step 809 3 visits [75.0, 46.0, 44.0, 429.0, 120.0, 72.0, 23.0]  episode_count: 1369 q_vals: [-9.398, -9.494, -9.49, -9.126, -9.331, -9.419, -9.66]Step 810 3 visits [75.0, 46.0, 44.0, 430.0, 120.0, 72.0, 23.0]  episode_count: 1370 q_vals: [-9.398, -9.494, -9.49, -9.105, -9.331, -9.419, -9.66]Step 811 3 visits [75.0, 46.0, 44.0, 431.0, 120.0, 72.0, 23.0]  episode_count: 1372 q_vals: [-9.398, -9.494, -9.49, -9.11, -9.331, -9.419, -9.66]Step 812 3 visits [75.0, 46.0, 44.0, 432.0, 120.0, 72.0, 23.0]  episode_count: 1374 q_vals: [-9.398, -9.494, -9.49, -9.114, -9.331, -9.419, -9.66]Step 813 3 visits [75.0, 46.0, 44.0, 433.0, 120.0, 72.0, 23.0]  episode_count: 1374 q_vals: [-9.398, -9.494, -9.49, -9.118, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1376, "number_of_timesteps": 25637, "per_episode_reward": 15.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
Step 814 3 visits [75.0, 46.0, 44.0, 434.0, 120.0, 72.0, 23.0]  episode_count: 1376 q_vals: [-9.398, -9.494, -9.49, -9.118, -9.331, -9.419, -9.66]Step 815 3 visits [75.0, 46.0, 44.0, 435.0, 120.0, 72.0, 23.0]  episode_count: 1380 q_vals: [-9.398, -9.494, -9.49, -9.118, -9.331, -9.419, -9.66]Step 816 3 visits [75.0, 46.0, 44.0, 436.0, 120.0, 72.0, 23.0]  episode_count: 1381 q_vals: [-9.398, -9.494, -9.49, -9.097, -9.331, -9.419, -9.66]Step 817 3 visits [75.0, 46.0, 44.0, 437.0, 120.0, 72.0, 23.0]  episode_count: 1381 q_vals: [-9.398, -9.494, -9.49, -9.101, -9.331, -9.419, -9.66]Step 818 3 visits [75.0, 46.0, 44.0, 438.0, 120.0, 72.0, 23.0]  episode_count: 1384 q_vals: [-9.398, -9.494, -9.49, -9.106, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1386, "number_of_timesteps": 25829, "per_episode_reward": 15.71, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
Step 819 3 visits [75.0, 46.0, 44.0, 439.0, 120.0, 72.0, 23.0]  episode_count: 1386 q_vals: [-9.398, -9.494, -9.49, -9.108, -9.331, -9.419, -9.66]Step 820 3 visits [75.0, 46.0, 44.0, 440.0, 120.0, 72.0, 23.0]  episode_count: 1388 q_vals: [-9.398, -9.494, -9.49, -9.112, -9.331, -9.419, -9.66]Step 821 3 visits [75.0, 46.0, 44.0, 441.0, 120.0, 72.0, 23.0]  episode_count: 1389 q_vals: [-9.398, -9.494, -9.49, -9.112, -9.331, -9.419, -9.66]Step 822 3 visits [75.0, 46.0, 44.0, 442.0, 120.0, 72.0, 23.0]  episode_count: 1392 q_vals: [-9.398, -9.494, -9.49, -9.091, -9.331, -9.419, -9.66]Step 823 3 visits [75.0, 46.0, 44.0, 443.0, 120.0, 72.0, 23.0]  episode_count: 1393 q_vals: [-9.398, -9.494, -9.49, -9.096, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1397, "number_of_timesteps": 26009, "per_episode_reward": 15.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
Step 824 3 visits [75.0, 46.0, 44.0, 444.0, 120.0, 72.0, 23.0]  episode_count: 1397 q_vals: [-9.398, -9.494, -9.49, -9.076, -9.331, -9.419, -9.66]Step 825 3 visits [75.0, 46.0, 44.0, 445.0, 120.0, 72.0, 23.0]  episode_count: 1398 q_vals: [-9.398, -9.494, -9.49, -9.08, -9.331, -9.419, -9.66]Step 826 3 visits [75.0, 46.0, 44.0, 446.0, 120.0, 72.0, 23.0]  episode_count: 1400 q_vals: [-9.398, -9.494, -9.49, -9.08, -9.331, -9.419, -9.66]Step 827 3 visits [75.0, 46.0, 44.0, 447.0, 120.0, 72.0, 23.0]  episode_count: 1401 q_vals: [-9.398, -9.494, -9.49, -9.08, -9.331, -9.419, -9.66]Step 828 3 visits [75.0, 46.0, 44.0, 448.0, 120.0, 72.0, 23.0]  episode_count: 1403 q_vals: [-9.398, -9.494, -9.49, -9.084, -9.331, -9.419, -9.66]Step 829 3 visits [75.0, 46.0, 44.0, 449.0, 120.0, 72.0, 23.0]  episode_count: 1404 q_vals: [-9.398, -9.494, -9.49, -9.089, -9.331, -9.419, -9.66]Step 830 3 visits [75.0, 46.0, 44.0, 450.0, 120.0, 72.0, 23.0]  episode_count: 1406 q_vals: [-9.398, -9.494, -9.49, -9.09, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1408, "number_of_timesteps": 26196, "per_episode_reward": 15.79, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
Step 831 3 visits [75.0, 46.0, 44.0, 451.0, 120.0, 72.0, 23.0]  episode_count: 1408 q_vals: [-9.398, -9.494, -9.49, -9.092, -9.331, -9.419, -9.66]Step 832 3 visits [75.0, 46.0, 44.0, 452.0, 120.0, 72.0, 23.0]  episode_count: 1411 q_vals: [-9.398, -9.494, -9.49, -9.097, -9.331, -9.419, -9.66]Step 833 3 visits [75.0, 46.0, 44.0, 453.0, 120.0, 72.0, 23.0]  episode_count: 1411 q_vals: [-9.398, -9.494, -9.49, -9.076, -9.331, -9.419, -9.66]Step 834 3 visits [75.0, 46.0, 44.0, 454.0, 120.0, 72.0, 23.0]  episode_count: 1413 q_vals: [-9.398, -9.494, -9.49, -9.076, -9.331, -9.419, -9.66]Step 835 3 visits [75.0, 46.0, 44.0, 455.0, 120.0, 72.0, 23.0]  episode_count: 1414 q_vals: [-9.398, -9.494, -9.49, -9.056, -9.331, -9.419, -9.66]Step 836 3 visits [75.0, 46.0, 44.0, 456.0, 120.0, 72.0, 23.0]  episode_count: 1416 q_vals: [-9.398, -9.494, -9.49, -9.061, -9.331, -9.419, -9.66]Step 837 3 visits [75.0, 46.0, 44.0, 457.0, 120.0, 72.0, 23.0]  episode_count: 1416 q_vals: [-9.398, -9.494, -9.49, -9.061, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1419, "number_of_timesteps": 26388, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
Step 838 3 visits [75.0, 46.0, 44.0, 458.0, 120.0, 72.0, 23.0]  episode_count: 1419 q_vals: [-9.398, -9.494, -9.49, -9.063, -9.331, -9.419, -9.66]Step 839 3 visits [75.0, 46.0, 44.0, 459.0, 120.0, 72.0, 23.0]  episode_count: 1421 q_vals: [-9.398, -9.494, -9.49, -9.043, -9.331, -9.419, -9.66]Step 840 3 visits [75.0, 46.0, 44.0, 460.0, 120.0, 72.0, 23.0]  episode_count: 1422 q_vals: [-9.398, -9.494, -9.49, -9.024, -9.331, -9.419, -9.66]Step 841 3 visits [75.0, 46.0, 44.0, 461.0, 120.0, 72.0, 23.0]  episode_count: 1426 q_vals: [-9.398, -9.494, -9.49, -9.028, -9.331, -9.419, -9.66]Step 842 3 visits [75.0, 46.0, 44.0, 462.0, 120.0, 72.0, 23.0]  episode_count: 1428 q_vals: [-9.398, -9.494, -9.49, -9.028, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1430, "number_of_timesteps": 26588, "per_episode_reward": 15.79, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
Step 843 3 visits [75.0, 46.0, 44.0, 463.0, 120.0, 72.0, 23.0]  episode_count: 1430 q_vals: [-9.398, -9.494, -9.49, -9.033, -9.331, -9.419, -9.66]Step 844 3 visits [75.0, 46.0, 44.0, 464.0, 120.0, 72.0, 23.0]  episode_count: 1432 q_vals: [-9.398, -9.494, -9.49, -9.033, -9.331, -9.419, -9.66]Step 845 3 visits [75.0, 46.0, 44.0, 465.0, 120.0, 72.0, 23.0]  episode_count: 1435 q_vals: [-9.398, -9.494, -9.49, -9.032, -9.331, -9.419, -9.66]Step 846 3 visits [75.0, 46.0, 44.0, 466.0, 120.0, 72.0, 23.0]  episode_count: 1436 q_vals: [-9.398, -9.494, -9.49, -9.035, -9.331, -9.419, -9.66]Step 847 3 visits [75.0, 46.0, 44.0, 467.0, 120.0, 72.0, 23.0]  episode_count: 1439 q_vals: [-9.398, -9.494, -9.49, -9.039, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1440, "number_of_timesteps": 26736, "per_episode_reward": 15.86, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
Step 848 3 visits [75.0, 46.0, 44.0, 468.0, 120.0, 72.0, 23.0]  episode_count: 1440 q_vals: [-9.398, -9.494, -9.49, -9.02, -9.331, -9.419, -9.66]Step 849 3 visits [75.0, 46.0, 44.0, 469.0, 120.0, 72.0, 23.0]  episode_count: 1442 q_vals: [-9.398, -9.494, -9.49, -9.02, -9.331, -9.419, -9.66]Step 850 3 visits [75.0, 46.0, 44.0, 470.0, 120.0, 72.0, 23.0]  episode_count: 1444 q_vals: [-9.398, -9.494, -9.49, -9.021, -9.331, -9.419, -9.66]Step 851 3 visits [75.0, 46.0, 44.0, 471.0, 120.0, 72.0, 23.0]  episode_count: 1445 q_vals: [-9.398, -9.494, -9.49, -9.021, -9.331, -9.419, -9.66]Step 852 3 visits [75.0, 46.0, 44.0, 472.0, 120.0, 72.0, 23.0]  episode_count: 1447 q_vals: [-9.398, -9.494, -9.49, -9.02, -9.331, -9.419, -9.66]Step 853 3 visits [75.0, 46.0, 44.0, 473.0, 120.0, 72.0, 23.0]  episode_count: 1448 q_vals: [-9.398, -9.494, -9.49, -9.001, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1450, "number_of_timesteps": 26908, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
Step 854 3 visits [75.0, 46.0, 44.0, 474.0, 120.0, 72.0, 23.0]  episode_count: 1450 q_vals: [-9.398, -9.494, -9.49, -9.002, -9.331, -9.419, -9.66]Step 855 3 visits [75.0, 46.0, 44.0, 475.0, 120.0, 72.0, 23.0]  episode_count: 1452 q_vals: [-9.398, -9.494, -9.49, -8.995, -9.331, -9.419, -9.66]Step 856 3 visits [75.0, 46.0, 44.0, 476.0, 120.0, 72.0, 23.0]  episode_count: 1452 q_vals: [-9.398, -9.494, -9.49, -9.0, -9.331, -9.419, -9.66]Step 857 3 visits [75.0, 46.0, 44.0, 477.0, 120.0, 72.0, 23.0]  episode_count: 1452 q_vals: [-9.398, -9.494, -9.49, -9.002, -9.331, -9.419, -9.66]Step 858 3 visits [75.0, 46.0, 44.0, 478.0, 120.0, 72.0, 23.0]  episode_count: 1455 q_vals: [-9.398, -9.494, -9.49, -9.006, -9.331, -9.419, -9.66]Step 859 3 visits [75.0, 46.0, 44.0, 479.0, 120.0, 72.0, 23.0]  episode_count: 1456 q_vals: [-9.398, -9.494, -9.49, -9.006, -9.331, -9.419, -9.66]Step 860 3 visits [75.0, 46.0, 44.0, 480.0, 120.0, 72.0, 23.0]  episode_count: 1458 q_vals: [-9.398, -9.494, -9.49, -9.01, -9.331, -9.419, -9.66]Step 861 3 visits [75.0, 46.0, 44.0, 481.0, 120.0, 72.0, 23.0]  episode_count: 1459 q_vals: [-9.398, -9.494, -9.49, -9.01, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1462, "number_of_timesteps": 27150, "per_episode_reward": 15.79, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
Step 862 3 visits [75.0, 46.0, 44.0, 482.0, 120.0, 72.0, 23.0]  episode_count: 1462 q_vals: [-9.398, -9.494, -9.49, -9.014, -9.331, -9.419, -9.66]Step 863 3 visits [75.0, 46.0, 44.0, 483.0, 120.0, 72.0, 23.0]  episode_count: 1466 q_vals: [-9.398, -9.494, -9.49, -9.014, -9.331, -9.419, -9.66]Step 864 3 visits [75.0, 46.0, 44.0, 484.0, 120.0, 72.0, 23.0]  episode_count: 1466 q_vals: [-9.398, -9.494, -9.49, -8.995, -9.331, -9.419, -9.66]Step 865 3 visits [75.0, 46.0, 44.0, 485.0, 120.0, 72.0, 23.0]  episode_count: 1470 q_vals: [-9.398, -9.494, -9.49, -8.995, -9.331, -9.419, -9.66]Step 866 3 visits [75.0, 46.0, 44.0, 486.0, 120.0, 72.0, 23.0]  episode_count: 1470 q_vals: [-9.398, -9.494, -9.49, -9.0, -9.331, -9.419, -9.66]Step 867 3 visits [75.0, 46.0, 44.0, 487.0, 120.0, 72.0, 23.0]  episode_count: 1470 q_vals: [-9.398, -9.494, -9.49, -9.004, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1473, "number_of_timesteps": 27362, "per_episode_reward": 15.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 868 3 visits [75.0, 46.0, 44.0, 488.0, 120.0, 72.0, 23.0]  episode_count: 1473 q_vals: [-9.398, -9.494, -9.49, -9.006, -9.331, -9.419, -9.66]Step 869 3 visits [75.0, 46.0, 44.0, 489.0, 120.0, 72.0, 23.0]  episode_count: 1475 q_vals: [-9.398, -9.494, -9.49, -9.005, -9.331, -9.419, -9.66]Step 870 3 visits [75.0, 46.0, 44.0, 490.0, 120.0, 72.0, 23.0]  episode_count: 1475 q_vals: [-9.398, -9.494, -9.49, -9.004, -9.331, -9.419, -9.66]Step 871 3 visits [75.0, 46.0, 44.0, 491.0, 120.0, 72.0, 23.0]  episode_count: 1477 q_vals: [-9.398, -9.494, -9.49, -8.986, -9.331, -9.419, -9.66]Step 872 3 visits [75.0, 46.0, 44.0, 492.0, 120.0, 72.0, 23.0]  episode_count: 1477 q_vals: [-9.398, -9.494, -9.49, -8.968, -9.331, -9.419, -9.66]Step 873 3 visits [75.0, 46.0, 44.0, 493.0, 120.0, 72.0, 23.0]  episode_count: 1479 q_vals: [-9.398, -9.494, -9.49, -8.968, -9.331, -9.419, -9.66]Step 874 3 visits [75.0, 46.0, 44.0, 494.0, 120.0, 72.0, 23.0]  episode_count: 1481 q_vals: [-9.398, -9.494, -9.49, -8.969, -9.331, -9.419, -9.66]Step 875 3 visits [75.0, 46.0, 44.0, 495.0, 120.0, 72.0, 23.0]  episode_count: 1482 q_vals: [-9.398, -9.494, -9.49, -8.973, -9.331, -9.419, -9.66]Step 876 3 visits [75.0, 46.0, 44.0, 496.0, 120.0, 72.0, 23.0]  episode_count: 1482 q_vals: [-9.398, -9.494, -9.49, -8.973, -9.331, -9.419, -9.66]{"total_number_of_episodes": 1484, "number_of_timesteps": 27614, "per_episode_reward": 15.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 877 3 visits [75.0, 46.0, 44.0, 497.0, 120.0, 72.0, 23.0]  episode_count: 1484 q_vals: [-9.398, -9.494, -9.49, -8.973, -9.331, -9.419, -9.66]Step 878 3 visits [75.0, 46.0, 44.0, 498.0, 120.0, 72.0, 23.0]  episode_count: 1487 q_vals: [-9.398, -9.494, -9.49, -8.975, -9.331, -9.419, -9.66]Step 879 3 visits [75.0, 46.0, 44.0, 499.0, 120.0, 72.0, 23.0]  episode_count: 1487 q_vals: [-9.398, -9.494, -9.49, -8.979, -9.331, -9.419, -9.66]Step 880 3 visits [0.0, 0.0, 0.0, 500.0, 0.0, 0.0, 0.0]  episode_count: 1489 q_vals: [0.0, 0.0, 0.0, -inf, 0.0, 0.0, 0.0]Step 881 0 visits [1.0, 0.0, 0.0, 500.0, 0.0, 0.0, 0.0]  episode_count: 1490 q_vals: [-10.713, 0.0, 0.0, -inf, 0.0, 0.0, 0.0]Step 882 1 visits [1.0, 1.0, 0.0, 500.0, 0.0, 0.0, 0.0]  episode_count: 1491 q_vals: [-10.713, 0.0, 0.0, -inf, 0.0, 0.0, 0.0]Step 883 2 visits [1.0, 1.0, 1.0, 500.0, 0.0, 0.0, 0.0]  episode_count: 1492 q_vals: [-10.713, 0.0, -12.8, -inf, 0.0, 0.0, 0.0]Step 884 4 visits [1.0, 1.0, 1.0, 500.0, 1.0, 0.0, 0.0]  episode_count: 1493 q_vals: [-10.713, 0.0, -12.8, -inf, -9.848, 0.0, 0.0]{"total_number_of_episodes": 1496, "number_of_timesteps": 27924, "per_episode_reward": 13.57, "episode_reward_trend_value": -0.024603174603174616, "biggest_recent_change": 2.2857142857142865},
Step 885 5 visits [1.0, 1.0, 1.0, 500.0, 1.0, 1.0, 0.0]  episode_count: 1496 q_vals: [-10.713, 0.0, -12.8, -inf, -9.848, -12.8, 0.0]Step 886 6 visits [1.0, 1.0, 1.0, 500.0, 1.0, 1.0, 1.0]  episode_count: 1497 q_vals: [-10.713, 0.0, -12.8, -inf, -9.848, -12.8, 0.0]Step 887 1 visits [1.0, 2.0, 1.0, 500.0, 1.0, 1.0, 1.0]  episode_count: 1499 q_vals: [-10.713, -5.542, -12.8, -inf, -9.848, -12.8, 0.0]Step 888 6 visits [1.0, 2.0, 1.0, 500.0, 1.0, 1.0, 2.0]  episode_count: 1502 q_vals: [-10.713, -5.542, -12.8, -inf, -9.848, -12.8, -6.4]Step 889 1 visits [1.0, 3.0, 1.0, 500.0, 1.0, 1.0, 2.0]  episode_count: 1502 q_vals: [-10.713, -7.961, -12.8, -inf, -9.848, -12.8, -6.4]Step 890 6 visits [1.0, 3.0, 1.0, 500.0, 1.0, 1.0, 3.0]  episode_count: 1504 q_vals: [-10.713, -7.961, -12.8, -inf, -9.848, -12.8, -7.475]{"total_number_of_episodes": 1507, "number_of_timesteps": 28122, "per_episode_reward": 13.57, "episode_reward_trend_value": -0.024603174603174616, "biggest_recent_change": 2.2857142857142865},
Step 891 6 visits [1.0, 3.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1507 q_vals: [-10.713, -7.961, -12.8, -inf, -9.848, -12.8, -8.807]Step 892 1 visits [1.0, 4.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1508 q_vals: [-10.713, -5.971, -12.8, -inf, -9.848, -12.8, -8.807]Step 893 1 visits [1.0, 5.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1509 q_vals: [-10.713, -7.337, -12.8, -inf, -9.848, -12.8, -8.807]Step 894 1 visits [1.0, 6.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1511 q_vals: [-10.713, -6.114, -12.8, -inf, -9.848, -12.8, -8.807]Step 895 1 visits [1.0, 7.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1511 q_vals: [-10.713, -7.069, -12.8, -inf, -9.848, -12.8, -8.807]Step 896 1 visits [1.0, 8.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1513 q_vals: [-10.713, -7.444, -12.8, -inf, -9.848, -12.8, -8.807]Step 897 1 visits [1.0, 9.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1515 q_vals: [-10.713, -8.039, -12.8, -inf, -9.848, -12.8, -8.807]{"total_number_of_episodes": 1517, "number_of_timesteps": 28340, "per_episode_reward": 13.57, "episode_reward_trend_value": -0.025396825396825407, "biggest_recent_change": 2.2857142857142865},
Step 898 1 visits [1.0, 10.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1517 q_vals: [-10.713, -7.235, -12.8, -inf, -9.848, -12.8, -8.807]Step 899 1 visits [1.0, 11.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1518 q_vals: [-10.713, -7.404, -12.8, -inf, -9.848, -12.8, -8.807]Step 900 1 visits [1.0, 12.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1521 q_vals: [-10.713, -7.853, -12.8, -inf, -9.848, -12.8, -8.807]Step 901 1 visits [1.0, 13.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1521 q_vals: [-10.713, -8.043, -12.8, -inf, -9.848, -12.8, -8.807]Step 902 1 visits [1.0, 14.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1523 q_vals: [-10.713, -8.161, -12.8, -inf, -9.848, -12.8, -8.807]Step 903 1 visits [1.0, 15.0, 1.0, 500.0, 1.0, 1.0, 4.0]  episode_count: 1524 q_vals: [-10.713, -8.471, -12.8, -inf, -9.848, -12.8, -8.807]Step 904 6 visits [1.0, 15.0, 1.0, 500.0, 1.0, 1.0, 5.0]  episode_count: 1526 q_vals: [-10.713, -8.471, -12.8, -inf, -9.848, -12.8, -9.354]{"total_number_of_episodes": 1527, "number_of_timesteps": 28515, "per_episode_reward": 13.57, "episode_reward_trend_value": -0.024603174603174616, "biggest_recent_change": 2.2857142857142865},
Step 905 1 visits [1.0, 16.0, 1.0, 500.0, 1.0, 1.0, 5.0]  episode_count: 1527 q_vals: [-10.713, -7.941, -12.8, -inf, -9.848, -12.8, -9.354]Step 906 1 visits [1.0, 17.0, 1.0, 500.0, 1.0, 1.0, 5.0]  episode_count: 1528 q_vals: [-10.713, -8.078, -12.8, -inf, -9.848, -12.8, -9.354]Step 907 1 visits [1.0, 18.0, 1.0, 500.0, 1.0, 1.0, 5.0]  episode_count: 1529 q_vals: [-10.713, -8.341, -12.8, -inf, -9.848, -12.8, -9.354]Step 908 1 visits [1.0, 19.0, 1.0, 500.0, 1.0, 1.0, 5.0]  episode_count: 1530 q_vals: [-10.713, -8.483, -12.8, -inf, -9.848, -12.8, -9.354]Step 909 4 visits [1.0, 19.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1531 q_vals: [-10.713, -8.483, -12.8, -inf, -9.871, -12.8, -9.354]Step 910 1 visits [1.0, 20.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1531 q_vals: [-10.713, -8.58, -12.8, -inf, -9.871, -12.8, -9.354]Step 911 1 visits [1.0, 21.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1534 q_vals: [-10.713, -8.581, -12.8, -inf, -9.871, -12.8, -9.354]Step 912 1 visits [1.0, 22.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1534 q_vals: [-10.713, -8.773, -12.8, -inf, -9.871, -12.8, -9.354]Step 913 1 visits [1.0, 23.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1534 q_vals: [-10.713, -8.677, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1539, "number_of_timesteps": 28865, "per_episode_reward": 13.57, "episode_reward_trend_value": -0.025396825396825407, "biggest_recent_change": 2.2857142857142865},
Step 914 1 visits [1.0, 24.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1539 q_vals: [-10.713, -8.315, -12.8, -inf, -9.871, -12.8, -9.354]Step 915 1 visits [1.0, 25.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1539 q_vals: [-10.713, -8.495, -12.8, -inf, -9.871, -12.8, -9.354]Step 916 1 visits [1.0, 26.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1539 q_vals: [-10.713, -8.66, -12.8, -inf, -9.871, -12.8, -9.354]Step 917 1 visits [1.0, 27.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1542 q_vals: [-10.713, -8.514, -12.8, -inf, -9.871, -12.8, -9.354]Step 918 1 visits [1.0, 28.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1543 q_vals: [-10.713, -8.667, -12.8, -inf, -9.871, -12.8, -9.354]Step 919 1 visits [1.0, 29.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1544 q_vals: [-10.713, -8.605, -12.8, -inf, -9.871, -12.8, -9.354]Step 920 1 visits [1.0, 30.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1545 q_vals: [-10.713, -8.318, -12.8, -inf, -9.871, -12.8, -9.354]Step 921 1 visits [1.0, 31.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1546 q_vals: [-10.713, -8.419, -12.8, -inf, -9.871, -12.8, -9.354]Step 922 1 visits [1.0, 32.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1548 q_vals: [-10.713, -8.556, -12.8, -inf, -9.871, -12.8, -9.354]Step 923 1 visits [1.0, 33.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1548 q_vals: [-10.713, -8.685, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1550, "number_of_timesteps": 29108, "per_episode_reward": 13.64, "episode_reward_trend_value": -0.024603174603174616, "biggest_recent_change": 2.2857142857142865},
Step 924 1 visits [1.0, 34.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1550 q_vals: [-10.713, -8.429, -12.8, -inf, -9.871, -12.8, -9.354]Step 925 1 visits [1.0, 35.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1551 q_vals: [-10.713, -8.189, -12.8, -inf, -9.871, -12.8, -9.354]Step 926 1 visits [1.0, 36.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1552 q_vals: [-10.713, -8.249, -12.8, -inf, -9.871, -12.8, -9.354]Step 927 1 visits [1.0, 37.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1554 q_vals: [-10.713, -8.026, -12.8, -inf, -9.871, -12.8, -9.354]Step 928 1 visits [1.0, 38.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1554 q_vals: [-10.713, -8.152, -12.8, -inf, -9.871, -12.8, -9.354]Step 929 1 visits [1.0, 39.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1557 q_vals: [-10.713, -8.102, -12.8, -inf, -9.871, -12.8, -9.354]Step 930 1 visits [1.0, 40.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1558 q_vals: [-10.713, -8.219, -12.8, -inf, -9.871, -12.8, -9.354]Step 931 1 visits [1.0, 41.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1559 q_vals: [-10.713, -8.331, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1561, "number_of_timesteps": 29418, "per_episode_reward": 13.71, "episode_reward_trend_value": -0.023015873015873035, "biggest_recent_change": 2.2857142857142865},
Step 932 1 visits [1.0, 42.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1561 q_vals: [-10.713, -8.357, -12.8, -inf, -9.871, -12.8, -9.354]Step 933 1 visits [1.0, 43.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1564 q_vals: [-10.713, -8.163, -12.8, -inf, -9.871, -12.8, -9.354]Step 934 1 visits [1.0, 44.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1565 q_vals: [-10.713, -8.202, -12.8, -inf, -9.871, -12.8, -9.354]Step 935 1 visits [1.0, 45.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1568 q_vals: [-10.713, -8.251, -12.8, -inf, -9.871, -12.8, -9.354]Step 936 1 visits [1.0, 46.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1570 q_vals: [-10.713, -8.072, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1572, "number_of_timesteps": 29610, "per_episode_reward": 13.71, "episode_reward_trend_value": -0.023015873015873035, "biggest_recent_change": 2.2857142857142865},
Step 937 1 visits [1.0, 47.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1572 q_vals: [-10.713, -8.157, -12.8, -inf, -9.871, -12.8, -9.354]Step 938 1 visits [1.0, 48.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1576 q_vals: [-10.713, -8.254, -12.8, -inf, -9.871, -12.8, -9.354]Step 939 1 visits [1.0, 49.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1577 q_vals: [-10.713, -8.085, -12.8, -inf, -9.871, -12.8, -9.354]Step 940 1 visits [1.0, 50.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1578 q_vals: [-10.713, -8.111, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1582, "number_of_timesteps": 29737, "per_episode_reward": 13.57, "episode_reward_trend_value": -0.025396825396825407, "biggest_recent_change": 2.2857142857142865},
Step 941 1 visits [1.0, 51.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1582 q_vals: [-10.713, -8.167, -12.8, -inf, -9.871, -12.8, -9.354]Step 942 1 visits [1.0, 52.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1583 q_vals: [-10.713, -8.228, -12.8, -inf, -9.871, -12.8, -9.354]Step 943 1 visits [1.0, 53.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1583 q_vals: [-10.713, -8.315, -12.8, -inf, -9.871, -12.8, -9.354]Step 944 1 visits [1.0, 54.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1586 q_vals: [-10.713, -8.379, -12.8, -inf, -9.871, -12.8, -9.354]Step 945 1 visits [1.0, 55.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1588 q_vals: [-10.713, -8.46, -12.8, -inf, -9.871, -12.8, -9.354]Step 946 1 visits [1.0, 56.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1588 q_vals: [-10.713, -8.475, -12.8, -inf, -9.871, -12.8, -9.354]Step 947 1 visits [1.0, 57.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1591 q_vals: [-10.713, -8.326, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1593, "number_of_timesteps": 29945, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 948 1 visits [1.0, 58.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1593 q_vals: [-10.713, -8.403, -12.8, -inf, -9.871, -12.8, -9.354]Step 949 1 visits [1.0, 59.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1595 q_vals: [-10.713, -8.463, -12.8, -inf, -9.871, -12.8, -9.354]Step 950 1 visits [1.0, 60.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1598 q_vals: [-10.713, -8.513, -12.8, -inf, -9.871, -12.8, -9.354]Step 951 1 visits [1.0, 61.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1600 q_vals: [-10.713, -8.373, -12.8, -inf, -9.871, -12.8, -9.354]Step 952 1 visits [1.0, 62.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1601 q_vals: [-10.713, -8.391, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1604, "number_of_timesteps": 30116, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 953 1 visits [1.0, 63.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1604 q_vals: [-10.713, -8.258, -12.8, -inf, -9.871, -12.8, -9.354]Step 954 1 visits [1.0, 64.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1607 q_vals: [-10.713, -8.327, -12.8, -inf, -9.871, -12.8, -9.354]Step 955 1 visits [1.0, 65.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1607 q_vals: [-10.713, -8.349, -12.8, -inf, -9.871, -12.8, -9.354]Step 956 1 visits [1.0, 66.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1608 q_vals: [-10.713, -8.372, -12.8, -inf, -9.871, -12.8, -9.354]Step 957 1 visits [1.0, 67.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1612 q_vals: [-10.713, -8.247, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1614, "number_of_timesteps": 30258, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 958 1 visits [1.0, 68.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1614 q_vals: [-10.713, -8.263, -12.8, -inf, -9.871, -12.8, -9.354]Step 959 1 visits [1.0, 69.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1614 q_vals: [-10.713, -8.279, -12.8, -inf, -9.871, -12.8, -9.354]Step 960 1 visits [1.0, 70.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1614 q_vals: [-10.713, -8.294, -12.8, -inf, -9.871, -12.8, -9.354]Step 961 1 visits [1.0, 71.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1617 q_vals: [-10.713, -8.313, -12.8, -inf, -9.871, -12.8, -9.354]Step 962 1 visits [1.0, 72.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1618 q_vals: [-10.713, -8.197, -12.8, -inf, -9.871, -12.8, -9.354]Step 963 1 visits [1.0, 73.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1622 q_vals: [-10.713, -8.26, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1625, "number_of_timesteps": 30476, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 964 1 visits [1.0, 74.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1625 q_vals: [-10.713, -8.149, -12.8, -inf, -9.871, -12.8, -9.354]Step 965 1 visits [1.0, 75.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1625 q_vals: [-10.713, -8.04, -12.8, -inf, -9.871, -12.8, -9.354]Step 966 1 visits [1.0, 76.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1627 q_vals: [-10.713, -8.056, -12.8, -inf, -9.871, -12.8, -9.354]Step 967 1 visits [1.0, 77.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1631 q_vals: [-10.713, -8.101, -12.8, -inf, -9.871, -12.8, -9.354]Step 968 1 visits [1.0, 78.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1631 q_vals: [-10.713, -7.997, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1635, "number_of_timesteps": 30622, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 969 1 visits [1.0, 79.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1635 q_vals: [-10.713, -7.896, -12.8, -inf, -9.871, -12.8, -9.354]Step 970 1 visits [1.0, 80.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1636 q_vals: [-10.713, -7.923, -12.8, -inf, -9.871, -12.8, -9.354]Step 971 1 visits [1.0, 81.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1637 q_vals: [-10.713, -7.983, -12.8, -inf, -9.871, -12.8, -9.354]Step 972 1 visits [1.0, 82.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1641 q_vals: [-10.713, -8.042, -12.8, -inf, -9.871, -12.8, -9.354]Step 973 1 visits [1.0, 83.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1643 q_vals: [-10.713, -8.059, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1647, "number_of_timesteps": 30788, "per_episode_reward": 13.57, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 974 1 visits [1.0, 84.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1647 q_vals: [-10.713, -8.074, -12.8, -inf, -9.871, -12.8, -9.354]Step 975 1 visits [1.0, 85.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1647 q_vals: [-10.713, -7.979, -12.8, -inf, -9.871, -12.8, -9.354]Step 976 1 visits [1.0, 86.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1649 q_vals: [-10.713, -8.004, -12.8, -inf, -9.871, -12.8, -9.354]Step 977 1 visits [1.0, 87.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1653 q_vals: [-10.713, -8.038, -12.8, -inf, -9.871, -12.8, -9.354]Step 978 1 visits [1.0, 88.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1654 q_vals: [-10.713, -8.092, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1659, "number_of_timesteps": 30940, "per_episode_reward": 13.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 979 1 visits [1.0, 89.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1659 q_vals: [-10.713, -8.105, -12.8, -inf, -9.871, -12.8, -9.354]Step 980 1 visits [1.0, 90.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1660 q_vals: [-10.713, -8.148, -12.8, -inf, -9.871, -12.8, -9.354]Step 981 1 visits [1.0, 91.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1663 q_vals: [-10.713, -8.199, -12.8, -inf, -9.871, -12.8, -9.354]Step 982 1 visits [1.0, 92.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1667 q_vals: [-10.713, -8.215, -12.8, -inf, -9.871, -12.8, -9.354]Step 983 1 visits [1.0, 93.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1667 q_vals: [-10.713, -8.264, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1671, "number_of_timesteps": 31083, "per_episode_reward": 13.57, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 984 1 visits [1.0, 94.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1671 q_vals: [-10.713, -8.312, -12.8, -inf, -9.871, -12.8, -9.354]Step 985 1 visits [1.0, 95.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1674 q_vals: [-10.713, -8.225, -12.8, -inf, -9.871, -12.8, -9.354]Step 986 1 visits [1.0, 96.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1674 q_vals: [-10.713, -8.245, -12.8, -inf, -9.871, -12.8, -9.354]Step 987 1 visits [1.0, 97.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1677 q_vals: [-10.713, -8.254, -12.8, -inf, -9.871, -12.8, -9.354]Step 988 1 visits [1.0, 98.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1679 q_vals: [-10.713, -8.17, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1681, "number_of_timesteps": 31222, "per_episode_reward": 13.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 989 1 visits [1.0, 99.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1681 q_vals: [-10.713, -8.18, -12.8, -inf, -9.871, -12.8, -9.354]Step 990 1 visits [1.0, 100.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1681 q_vals: [-10.713, -8.216, -12.8, -inf, -9.871, -12.8, -9.354]Step 991 1 visits [1.0, 101.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1682 q_vals: [-10.713, -8.253, -12.8, -inf, -9.871, -12.8, -9.354]Step 992 1 visits [1.0, 102.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1686 q_vals: [-10.713, -8.172, -12.8, -inf, -9.871, -12.8, -9.354]Step 993 1 visits [1.0, 103.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1688 q_vals: [-10.713, -8.185, -12.8, -inf, -9.871, -12.8, -9.354]Step 994 1 visits [1.0, 104.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1689 q_vals: [-10.713, -8.198, -12.8, -inf, -9.871, -12.8, -9.354]Step 995 1 visits [1.0, 105.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1690 q_vals: [-10.713, -8.216, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1693, "number_of_timesteps": 31429, "per_episode_reward": 13.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 996 1 visits [1.0, 106.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1693 q_vals: [-10.713, -8.139, -12.8, -inf, -9.871, -12.8, -9.354]Step 997 1 visits [1.0, 107.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1694 q_vals: [-10.713, -8.148, -12.8, -inf, -9.871, -12.8, -9.354]Step 998 1 visits [1.0, 108.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1695 q_vals: [-10.713, -8.183, -12.8, -inf, -9.871, -12.8, -9.354]Step 999 1 visits [1.0, 109.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1698 q_vals: [-10.713, -8.108, -12.8, -inf, -9.871, -12.8, -9.354]Step 1000 1 visits [1.0, 110.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1699 q_vals: [-10.713, -8.034, -12.8, -inf, -9.871, -12.8, -9.354]Step 1001 1 visits [1.0, 111.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1702 q_vals: [-10.713, -8.077, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1705, "number_of_timesteps": 31643, "per_episode_reward": 13.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1002 1 visits [1.0, 112.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1705 q_vals: [-10.713, -8.005, -12.8, -inf, -9.871, -12.8, -9.354]Step 1003 1 visits [1.0, 113.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1706 q_vals: [-10.713, -8.026, -12.8, -inf, -9.871, -12.8, -9.354]Step 1004 1 visits [1.0, 114.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1709 q_vals: [-10.713, -7.955, -12.8, -inf, -9.871, -12.8, -9.354]Step 1005 1 visits [1.0, 115.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1710 q_vals: [-10.713, -7.998, -12.8, -inf, -9.871, -12.8, -9.354]Step 1006 1 visits [1.0, 116.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1713 q_vals: [-10.713, -8.037, -12.8, -inf, -9.871, -12.8, -9.354]Step 1007 1 visits [1.0, 117.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1714 q_vals: [-10.713, -8.045, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1717, "number_of_timesteps": 31796, "per_episode_reward": 13.5, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1008 1 visits [1.0, 118.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1717 q_vals: [-10.713, -8.076, -12.8, -inf, -9.871, -12.8, -9.354]Step 1009 1 visits [1.0, 119.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1718 q_vals: [-10.713, -8.11, -12.8, -inf, -9.871, -12.8, -9.354]Step 1010 1 visits [1.0, 120.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1721 q_vals: [-10.713, -8.042, -12.8, -inf, -9.871, -12.8, -9.354]Step 1011 1 visits [1.0, 121.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1722 q_vals: [-10.713, -8.065, -12.8, -inf, -9.871, -12.8, -9.354]Step 1012 1 visits [1.0, 122.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1722 q_vals: [-10.713, -7.999, -12.8, -inf, -9.871, -12.8, -9.354]Step 1013 1 visits [1.0, 123.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1725 q_vals: [-10.713, -8.017, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1728, "number_of_timesteps": 32002, "per_episode_reward": 13.5, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1014 1 visits [1.0, 124.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1728 q_vals: [-10.713, -8.043, -12.8, -inf, -9.871, -12.8, -9.354]Step 1015 1 visits [1.0, 125.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1730 q_vals: [-10.713, -8.068, -12.8, -inf, -9.871, -12.8, -9.354]Step 1016 1 visits [1.0, 126.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1732 q_vals: [-10.713, -8.105, -12.8, -inf, -9.871, -12.8, -9.354]Step 1017 1 visits [1.0, 127.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1735 q_vals: [-10.713, -8.119, -12.8, -inf, -9.871, -12.8, -9.354]Step 1018 1 visits [1.0, 128.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1737 q_vals: [-10.713, -8.056, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1738, "number_of_timesteps": 32135, "per_episode_reward": 13.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1019 1 visits [1.0, 129.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1738 q_vals: [-10.713, -8.092, -12.8, -inf, -9.871, -12.8, -9.354]Step 1020 1 visits [1.0, 130.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1742 q_vals: [-10.713, -8.03, -12.8, -inf, -9.871, -12.8, -9.354]Step 1021 1 visits [1.0, 131.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1744 q_vals: [-10.713, -8.044, -12.8, -inf, -9.871, -12.8, -9.354]Step 1022 1 visits [1.0, 132.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1745 q_vals: [-10.713, -8.064, -12.8, -inf, -9.871, -12.8, -9.354]Step 1023 1 visits [1.0, 133.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1747 q_vals: [-10.713, -8.074, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1752, "number_of_timesteps": 32338, "per_episode_reward": 13.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1024 1 visits [1.0, 134.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1752 q_vals: [-10.713, -8.101, -12.8, -inf, -9.871, -12.8, -9.354]Step 1025 1 visits [1.0, 135.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1752 q_vals: [-10.713, -8.136, -12.8, -inf, -9.871, -12.8, -9.354]Step 1026 1 visits [1.0, 136.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1755 q_vals: [-10.713, -8.146, -12.8, -inf, -9.871, -12.8, -9.354]Step 1027 1 visits [1.0, 137.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1756 q_vals: [-10.713, -8.153, -12.8, -inf, -9.871, -12.8, -9.354]Step 1028 1 visits [1.0, 138.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1758 q_vals: [-10.713, -8.16, -12.8, -inf, -9.871, -12.8, -9.354]Step 1029 1 visits [1.0, 139.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1760 q_vals: [-10.713, -8.166, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1763, "number_of_timesteps": 32500, "per_episode_reward": 13.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1030 1 visits [1.0, 140.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1763 q_vals: [-10.713, -8.167, -12.8, -inf, -9.871, -12.8, -9.354]Step 1031 1 visits [1.0, 141.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1766 q_vals: [-10.713, -8.197, -12.8, -inf, -9.871, -12.8, -9.354]Step 1032 1 visits [1.0, 142.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1768 q_vals: [-10.713, -8.139, -12.8, -inf, -9.871, -12.8, -9.354]Step 1033 1 visits [1.0, 143.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1768 q_vals: [-10.713, -8.144, -12.8, -inf, -9.871, -12.8, -9.354]Step 1034 1 visits [1.0, 144.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1770 q_vals: [-10.713, -8.088, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1774, "number_of_timesteps": 32667, "per_episode_reward": 13.5, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1035 1 visits [1.0, 145.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1774 q_vals: [-10.713, -8.103, -12.8, -inf, -9.871, -12.8, -9.354]Step 1036 1 visits [1.0, 146.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1775 q_vals: [-10.713, -8.047, -12.8, -inf, -9.871, -12.8, -9.354]Step 1037 1 visits [1.0, 147.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1777 q_vals: [-10.713, -7.992, -12.8, -inf, -9.871, -12.8, -9.354]Step 1038 1 visits [1.0, 148.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1780 q_vals: [-10.713, -7.998, -12.8, -inf, -9.871, -12.8, -9.354]Step 1039 1 visits [1.0, 149.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1782 q_vals: [-10.713, -8.01, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1784, "number_of_timesteps": 32804, "per_episode_reward": 13.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1040 1 visits [1.0, 150.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1784 q_vals: [-10.713, -8.03, -12.8, -inf, -9.871, -12.8, -9.354]Step 1041 1 visits [1.0, 151.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1786 q_vals: [-10.713, -8.043, -12.8, -inf, -9.871, -12.8, -9.354]Step 1042 1 visits [1.0, 152.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1787 q_vals: [-10.713, -7.991, -12.8, -inf, -9.871, -12.8, -9.354]Step 1043 1 visits [1.0, 153.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1791 q_vals: [-10.713, -7.938, -12.8, -inf, -9.871, -12.8, -9.354]Step 1044 1 visits [1.0, 154.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1793 q_vals: [-10.713, -7.95, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1794, "number_of_timesteps": 32952, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1045 1 visits [1.0, 155.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1794 q_vals: [-10.713, -7.968, -12.8, -inf, -9.871, -12.8, -9.354]Step 1046 1 visits [1.0, 156.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1795 q_vals: [-10.713, -7.983, -12.8, -inf, -9.871, -12.8, -9.354]Step 1047 1 visits [1.0, 157.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1796 q_vals: [-10.713, -7.994, -12.8, -inf, -9.871, -12.8, -9.354]Step 1048 1 visits [1.0, 158.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1802 q_vals: [-10.713, -8.024, -12.8, -inf, -9.871, -12.8, -9.354]Step 1049 1 visits [1.0, 159.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1802 q_vals: [-10.713, -7.973, -12.8, -inf, -9.871, -12.8, -9.354]Step 1050 1 visits [1.0, 160.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1802 q_vals: [-10.713, -7.981, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1808, "number_of_timesteps": 33168, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1051 1 visits [1.0, 161.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1808 q_vals: [-10.713, -7.986, -12.8, -inf, -9.871, -12.8, -9.354]Step 1052 1 visits [1.0, 162.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1808 q_vals: [-10.713, -7.936, -12.8, -inf, -9.871, -12.8, -9.354]Step 1053 1 visits [1.0, 163.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1811 q_vals: [-10.713, -7.926, -12.8, -inf, -9.871, -12.8, -9.354]Step 1054 1 visits [1.0, 164.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1815 q_vals: [-10.713, -7.932, -12.8, -inf, -9.871, -12.8, -9.354]Step 1055 1 visits [1.0, 165.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1816 q_vals: [-10.713, -7.954, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1819, "number_of_timesteps": 33311, "per_episode_reward": 13.36, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1056 1 visits [1.0, 166.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1819 q_vals: [-10.713, -7.983, -12.8, -inf, -9.871, -12.8, -9.354]Step 1057 1 visits [1.0, 167.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1820 q_vals: [-10.713, -7.99, -12.8, -inf, -9.871, -12.8, -9.354]Step 1058 1 visits [1.0, 168.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1821 q_vals: [-10.713, -8.006, -12.8, -inf, -9.871, -12.8, -9.354]Step 1059 1 visits [1.0, 169.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1822 q_vals: [-10.713, -8.014, -12.8, -inf, -9.871, -12.8, -9.354]Step 1060 1 visits [1.0, 170.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1824 q_vals: [-10.713, -7.967, -12.8, -inf, -9.871, -12.8, -9.354]Step 1061 1 visits [1.0, 171.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1826 q_vals: [-10.713, -7.976, -12.8, -inf, -9.871, -12.8, -9.354]Step 1062 1 visits [1.0, 172.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1828 q_vals: [-10.713, -7.981, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1830, "number_of_timesteps": 33524, "per_episode_reward": 13.36, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1063 1 visits [1.0, 173.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1830 q_vals: [-10.713, -8.008, -12.8, -inf, -9.871, -12.8, -9.354]Step 1064 1 visits [1.0, 174.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1831 q_vals: [-10.713, -8.015, -12.8, -inf, -9.871, -12.8, -9.354]Step 1065 1 visits [1.0, 175.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1832 q_vals: [-10.713, -8.024, -12.8, -inf, -9.871, -12.8, -9.354]Step 1066 1 visits [1.0, 176.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1835 q_vals: [-10.713, -7.979, -12.8, -inf, -9.871, -12.8, -9.354]Step 1067 1 visits [1.0, 177.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1835 q_vals: [-10.713, -8.006, -12.8, -inf, -9.871, -12.8, -9.354]Step 1068 1 visits [1.0, 178.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1836 q_vals: [-10.713, -7.961, -12.8, -inf, -9.871, -12.8, -9.354]Step 1069 1 visits [1.0, 179.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1838 q_vals: [-10.713, -7.971, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1840, "number_of_timesteps": 33714, "per_episode_reward": 13.36, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1070 1 visits [1.0, 180.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1840 q_vals: [-10.713, -7.977, -12.8, -inf, -9.871, -12.8, -9.354]Step 1071 1 visits [1.0, 181.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1840 q_vals: [-10.713, -8.004, -12.8, -inf, -9.871, -12.8, -9.354]Step 1072 1 visits [1.0, 182.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1843 q_vals: [-10.713, -8.028, -12.8, -inf, -9.871, -12.8, -9.354]Step 1073 1 visits [1.0, 183.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1843 q_vals: [-10.713, -8.037, -12.8, -inf, -9.871, -12.8, -9.354]Step 1074 1 visits [1.0, 184.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1845 q_vals: [-10.713, -8.053, -12.8, -inf, -9.871, -12.8, -9.354]Step 1075 1 visits [1.0, 185.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1847 q_vals: [-10.713, -8.079, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1850, "number_of_timesteps": 33940, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1076 1 visits [1.0, 186.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1850 q_vals: [-10.713, -8.086, -12.8, -inf, -9.871, -12.8, -9.354]Step 1077 1 visits [1.0, 187.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1851 q_vals: [-10.713, -8.095, -12.8, -inf, -9.871, -12.8, -9.354]Step 1078 1 visits [1.0, 188.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1852 q_vals: [-10.713, -8.1, -12.8, -inf, -9.871, -12.8, -9.354]Step 1079 1 visits [1.0, 189.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1855 q_vals: [-10.713, -8.057, -12.8, -inf, -9.871, -12.8, -9.354]Step 1080 1 visits [1.0, 190.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1855 q_vals: [-10.713, -8.082, -12.8, -inf, -9.871, -12.8, -9.354]Step 1081 1 visits [1.0, 191.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1858 q_vals: [-10.713, -8.086, -12.8, -inf, -9.871, -12.8, -9.354]Step 1082 1 visits [1.0, 192.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1859 q_vals: [-10.713, -8.093, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1860, "number_of_timesteps": 34137, "per_episode_reward": 13.36, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1083 1 visits [1.0, 193.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1860 q_vals: [-10.713, -8.097, -12.8, -inf, -9.871, -12.8, -9.354]Step 1084 1 visits [1.0, 194.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1861 q_vals: [-10.713, -8.113, -12.8, -inf, -9.871, -12.8, -9.354]Step 1085 1 visits [1.0, 195.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1861 q_vals: [-10.713, -8.071, -12.8, -inf, -9.871, -12.8, -9.354]Step 1086 1 visits [1.0, 196.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1863 q_vals: [-10.713, -8.095, -12.8, -inf, -9.871, -12.8, -9.354]Step 1087 1 visits [1.0, 197.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1866 q_vals: [-10.713, -8.101, -12.8, -inf, -9.871, -12.8, -9.354]Step 1088 1 visits [1.0, 198.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1867 q_vals: [-10.713, -8.06, -12.8, -inf, -9.871, -12.8, -9.354]Step 1089 1 visits [1.0, 199.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1869 q_vals: [-10.713, -8.019, -12.8, -inf, -9.871, -12.8, -9.354]Step 1090 1 visits [1.0, 200.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1869 q_vals: [-10.713, -7.979, -12.8, -inf, -9.871, -12.8, -9.354]Step 1091 1 visits [1.0, 201.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1869 q_vals: [-10.713, -7.94, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1871, "number_of_timesteps": 34379, "per_episode_reward": 13.43, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1092 1 visits [1.0, 202.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1871 q_vals: [-10.713, -7.944, -12.8, -inf, -9.871, -12.8, -9.354]Step 1093 1 visits [1.0, 203.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1873 q_vals: [-10.713, -7.905, -12.8, -inf, -9.871, -12.8, -9.354]Step 1094 1 visits [1.0, 204.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1874 q_vals: [-10.713, -7.908, -12.8, -inf, -9.871, -12.8, -9.354]Step 1095 1 visits [1.0, 205.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1876 q_vals: [-10.713, -7.87, -12.8, -inf, -9.871, -12.8, -9.354]Step 1096 1 visits [1.0, 206.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1877 q_vals: [-10.713, -7.873, -12.8, -inf, -9.871, -12.8, -9.354]Step 1097 1 visits [1.0, 207.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1880 q_vals: [-10.713, -7.835, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1881, "number_of_timesteps": 34634, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1098 1 visits [1.0, 208.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1881 q_vals: [-10.713, -7.846, -12.8, -inf, -9.871, -12.8, -9.354]Step 1099 1 visits [1.0, 209.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1883 q_vals: [-10.713, -7.809, -12.8, -inf, -9.871, -12.8, -9.354]Step 1100 1 visits [1.0, 210.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1885 q_vals: [-10.713, -7.818, -12.8, -inf, -9.871, -12.8, -9.354]Step 1101 1 visits [1.0, 211.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1887 q_vals: [-10.713, -7.82, -12.8, -inf, -9.871, -12.8, -9.354]Step 1102 1 visits [1.0, 212.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1888 q_vals: [-10.713, -7.825, -12.8, -inf, -9.871, -12.8, -9.354]Step 1103 1 visits [1.0, 213.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1890 q_vals: [-10.713, -7.788, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1893, "number_of_timesteps": 34852, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1104 1 visits [1.0, 214.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1893 q_vals: [-10.713, -7.752, -12.8, -inf, -9.871, -12.8, -9.354]Step 1105 1 visits [1.0, 215.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1894 q_vals: [-10.713, -7.716, -12.8, -inf, -9.871, -12.8, -9.354]Step 1106 1 visits [1.0, 216.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1896 q_vals: [-10.713, -7.732, -12.8, -inf, -9.871, -12.8, -9.354]Step 1107 1 visits [1.0, 217.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1898 q_vals: [-10.713, -7.735, -12.8, -inf, -9.871, -12.8, -9.354]Step 1108 1 visits [1.0, 218.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1901 q_vals: [-10.713, -7.7, -12.8, -inf, -9.871, -12.8, -9.354]Step 1109 1 visits [1.0, 219.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1902 q_vals: [-10.713, -7.665, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1904, "number_of_timesteps": 35017, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1110 1 visits [1.0, 220.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1904 q_vals: [-10.713, -7.63, -12.8, -inf, -9.871, -12.8, -9.354]Step 1111 1 visits [1.0, 221.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1905 q_vals: [-10.713, -7.634, -12.8, -inf, -9.871, -12.8, -9.354]Step 1112 1 visits [1.0, 222.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1905 q_vals: [-10.713, -7.657, -12.8, -inf, -9.871, -12.8, -9.354]Step 1113 1 visits [1.0, 223.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1908 q_vals: [-10.713, -7.674, -12.8, -inf, -9.871, -12.8, -9.354]Step 1114 1 visits [1.0, 224.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1910 q_vals: [-10.713, -7.697, -12.8, -inf, -9.871, -12.8, -9.354]Step 1115 1 visits [1.0, 225.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1910 q_vals: [-10.713, -7.699, -12.8, -inf, -9.871, -12.8, -9.354]Step 1116 1 visits [1.0, 226.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1911 q_vals: [-10.713, -7.681, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1915, "number_of_timesteps": 35244, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1117 1 visits [1.0, 227.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1915 q_vals: [-10.713, -7.686, -12.8, -inf, -9.871, -12.8, -9.354]Step 1118 1 visits [1.0, 228.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1915 q_vals: [-10.713, -7.709, -12.8, -inf, -9.871, -12.8, -9.354]Step 1119 1 visits [1.0, 229.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1917 q_vals: [-10.713, -7.731, -12.8, -inf, -9.871, -12.8, -9.354]Step 1120 1 visits [1.0, 230.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1919 q_vals: [-10.713, -7.753, -12.8, -inf, -9.871, -12.8, -9.354]Step 1121 1 visits [1.0, 231.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1920 q_vals: [-10.713, -7.762, -12.8, -inf, -9.871, -12.8, -9.354]Step 1122 1 visits [1.0, 232.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1920 q_vals: [-10.713, -7.728, -12.8, -inf, -9.871, -12.8, -9.354]Step 1123 1 visits [1.0, 233.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1922 q_vals: [-10.713, -7.73, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1925, "number_of_timesteps": 35448, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1124 1 visits [1.0, 234.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1925 q_vals: [-10.713, -7.732, -12.8, -inf, -9.871, -12.8, -9.354]Step 1125 1 visits [1.0, 235.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1926 q_vals: [-10.713, -7.744, -12.8, -inf, -9.871, -12.8, -9.354]Step 1126 1 visits [1.0, 236.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1928 q_vals: [-10.713, -7.711, -12.8, -inf, -9.871, -12.8, -9.354]Step 1127 1 visits [1.0, 237.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1930 q_vals: [-10.713, -7.679, -12.8, -inf, -9.871, -12.8, -9.354]Step 1128 1 visits [1.0, 238.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1933 q_vals: [-10.713, -7.7, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1935, "number_of_timesteps": 35640, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1129 1 visits [1.0, 239.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1935 q_vals: [-10.713, -7.703, -12.8, -inf, -9.871, -12.8, -9.354]Step 1130 1 visits [1.0, 240.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1937 q_vals: [-10.713, -7.724, -12.8, -inf, -9.871, -12.8, -9.354]Step 1131 1 visits [1.0, 241.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1940 q_vals: [-10.713, -7.731, -12.8, -inf, -9.871, -12.8, -9.354]Step 1132 1 visits [1.0, 242.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1941 q_vals: [-10.713, -7.737, -12.8, -inf, -9.871, -12.8, -9.354]Step 1133 1 visits [1.0, 243.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1944 q_vals: [-10.713, -7.746, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1946, "number_of_timesteps": 35786, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1134 1 visits [1.0, 244.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1946 q_vals: [-10.713, -7.748, -12.8, -inf, -9.871, -12.8, -9.354]Step 1135 1 visits [1.0, 245.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1948 q_vals: [-10.713, -7.763, -12.8, -inf, -9.871, -12.8, -9.354]Step 1136 1 visits [1.0, 246.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1952 q_vals: [-10.713, -7.732, -12.8, -inf, -9.871, -12.8, -9.354]Step 1137 1 visits [1.0, 247.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1954 q_vals: [-10.713, -7.734, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1956, "number_of_timesteps": 35911, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1138 1 visits [1.0, 248.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1956 q_vals: [-10.713, -7.744, -12.8, -inf, -9.871, -12.8, -9.354]Step 1139 1 visits [1.0, 249.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1959 q_vals: [-10.713, -7.713, -12.8, -inf, -9.871, -12.8, -9.354]Step 1140 1 visits [1.0, 250.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1962 q_vals: [-10.713, -7.715, -12.8, -inf, -9.871, -12.8, -9.354]Step 1141 1 visits [1.0, 251.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1964 q_vals: [-10.713, -7.684, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1966, "number_of_timesteps": 36037, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1142 1 visits [1.0, 252.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1966 q_vals: [-10.713, -7.654, -12.8, -inf, -9.871, -12.8, -9.354]Step 1143 1 visits [1.0, 253.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1969 q_vals: [-10.713, -7.655, -12.8, -inf, -9.871, -12.8, -9.354]Step 1144 1 visits [1.0, 254.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1970 q_vals: [-10.713, -7.661, -12.8, -inf, -9.871, -12.8, -9.354]Step 1145 1 visits [1.0, 255.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1972 q_vals: [-10.713, -7.663, -12.8, -inf, -9.871, -12.8, -9.354]Step 1146 1 visits [1.0, 256.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1973 q_vals: [-10.713, -7.68, -12.8, -inf, -9.871, -12.8, -9.354]Step 1147 1 visits [1.0, 257.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1974 q_vals: [-10.713, -7.682, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1976, "number_of_timesteps": 36181, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1148 1 visits [1.0, 258.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1976 q_vals: [-10.713, -7.652, -12.8, -inf, -9.871, -12.8, -9.354]Step 1149 1 visits [1.0, 259.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1977 q_vals: [-10.713, -7.63, -12.8, -inf, -9.871, -12.8, -9.354]Step 1150 1 visits [1.0, 260.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1977 q_vals: [-10.713, -7.6, -12.8, -inf, -9.871, -12.8, -9.354]Step 1151 1 visits [1.0, 261.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1978 q_vals: [-10.713, -7.601, -12.8, -inf, -9.871, -12.8, -9.354]Step 1152 1 visits [1.0, 262.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1979 q_vals: [-10.713, -7.62, -12.8, -inf, -9.871, -12.8, -9.354]Step 1153 1 visits [1.0, 263.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1980 q_vals: [-10.713, -7.623, -12.8, -inf, -9.871, -12.8, -9.354]Step 1154 1 visits [1.0, 264.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1982 q_vals: [-10.713, -7.622, -12.8, -inf, -9.871, -12.8, -9.354]Step 1155 1 visits [1.0, 265.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1983 q_vals: [-10.713, -7.593, -12.8, -inf, -9.871, -12.8, -9.354]Step 1156 1 visits [1.0, 266.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1983 q_vals: [-10.713, -7.564, -12.8, -inf, -9.871, -12.8, -9.354]Step 1157 1 visits [1.0, 267.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1985 q_vals: [-10.713, -7.536, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1986, "number_of_timesteps": 36408, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1158 1 visits [1.0, 268.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1986 q_vals: [-10.713, -7.508, -12.8, -inf, -9.871, -12.8, -9.354]Step 1159 1 visits [1.0, 269.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1986 q_vals: [-10.713, -7.509, -12.8, -inf, -9.871, -12.8, -9.354]Step 1160 1 visits [1.0, 270.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1988 q_vals: [-10.713, -7.513, -12.8, -inf, -9.871, -12.8, -9.354]Step 1161 1 visits [1.0, 271.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1991 q_vals: [-10.713, -7.485, -12.8, -inf, -9.871, -12.8, -9.354]Step 1162 1 visits [1.0, 272.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1992 q_vals: [-10.713, -7.505, -12.8, -inf, -9.871, -12.8, -9.354]Step 1163 1 visits [1.0, 273.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1992 q_vals: [-10.713, -7.506, -12.8, -inf, -9.871, -12.8, -9.354]Step 1164 1 visits [1.0, 274.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1992 q_vals: [-10.713, -7.525, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 1996, "number_of_timesteps": 36751, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1165 1 visits [1.0, 275.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1996 q_vals: [-10.713, -7.537, -12.8, -inf, -9.871, -12.8, -9.354]Step 1166 1 visits [1.0, 276.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1997 q_vals: [-10.713, -7.545, -12.8, -inf, -9.871, -12.8, -9.354]Step 1167 1 visits [1.0, 277.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 1997 q_vals: [-10.713, -7.518, -12.8, -inf, -9.871, -12.8, -9.354]Step 1168 1 visits [1.0, 278.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2000 q_vals: [-10.713, -7.519, -12.8, -inf, -9.871, -12.8, -9.354]Step 1169 1 visits [1.0, 279.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2002 q_vals: [-10.713, -7.519, -12.8, -inf, -9.871, -12.8, -9.354]Step 1170 1 visits [1.0, 280.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2003 q_vals: [-10.713, -7.538, -12.8, -inf, -9.871, -12.8, -9.354]Step 1171 1 visits [1.0, 281.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2005 q_vals: [-10.713, -7.54, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2008, "number_of_timesteps": 36998, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1172 1 visits [1.0, 282.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2008 q_vals: [-10.713, -7.55, -12.8, -inf, -9.871, -12.8, -9.354]Step 1173 1 visits [1.0, 283.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2009 q_vals: [-10.713, -7.55, -12.8, -inf, -9.871, -12.8, -9.354]Step 1174 1 visits [1.0, 284.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2011 q_vals: [-10.713, -7.552, -12.8, -inf, -9.871, -12.8, -9.354]Step 1175 1 visits [1.0, 285.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2013 q_vals: [-10.713, -7.57, -12.8, -inf, -9.871, -12.8, -9.354]Step 1176 1 visits [1.0, 286.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2013 q_vals: [-10.713, -7.544, -12.8, -inf, -9.871, -12.8, -9.354]Step 1177 1 visits [1.0, 287.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2017 q_vals: [-10.713, -7.562, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2018, "number_of_timesteps": 37136, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1178 1 visits [1.0, 288.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2018 q_vals: [-10.713, -7.577, -12.8, -inf, -9.871, -12.8, -9.354]Step 1179 1 visits [1.0, 289.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2019 q_vals: [-10.713, -7.551, -12.8, -inf, -9.871, -12.8, -9.354]Step 1180 1 visits [1.0, 290.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2023 q_vals: [-10.713, -7.556, -12.8, -inf, -9.871, -12.8, -9.354]Step 1181 1 visits [1.0, 291.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2024 q_vals: [-10.713, -7.574, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2028, "number_of_timesteps": 37309, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1182 1 visits [1.0, 292.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2028 q_vals: [-10.713, -7.575, -12.8, -inf, -9.871, -12.8, -9.354]Step 1183 1 visits [1.0, 293.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2030 q_vals: [-10.713, -7.576, -12.8, -inf, -9.871, -12.8, -9.354]Step 1184 1 visits [1.0, 294.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2032 q_vals: [-10.713, -7.574, -12.8, -inf, -9.871, -12.8, -9.354]Step 1185 1 visits [1.0, 295.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2035 q_vals: [-10.713, -7.579, -12.8, -inf, -9.871, -12.8, -9.354]Step 1186 1 visits [1.0, 296.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2035 q_vals: [-10.713, -7.58, -12.8, -inf, -9.871, -12.8, -9.354]Step 1187 1 visits [1.0, 297.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2036 q_vals: [-10.713, -7.585, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2041, "number_of_timesteps": 37500, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1188 1 visits [1.0, 298.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2041 q_vals: [-10.713, -7.593, -12.8, -inf, -9.871, -12.8, -9.354]Step 1189 1 visits [1.0, 299.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2041 q_vals: [-10.713, -7.594, -12.8, -inf, -9.871, -12.8, -9.354]Step 1190 1 visits [1.0, 300.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2044 q_vals: [-10.713, -7.593, -12.8, -inf, -9.871, -12.8, -9.354]Step 1191 1 visits [1.0, 301.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2046 q_vals: [-10.713, -7.568, -12.8, -inf, -9.871, -12.8, -9.354]Step 1192 1 visits [1.0, 302.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2048 q_vals: [-10.713, -7.569, -12.8, -inf, -9.871, -12.8, -9.354]Step 1193 1 visits [1.0, 303.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2049 q_vals: [-10.713, -7.545, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2051, "number_of_timesteps": 37646, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1194 1 visits [1.0, 304.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2051 q_vals: [-10.713, -7.549, -12.8, -inf, -9.871, -12.8, -9.354]Step 1195 1 visits [1.0, 305.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2051 q_vals: [-10.713, -7.549, -12.8, -inf, -9.871, -12.8, -9.354]Step 1196 1 visits [1.0, 306.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2054 q_vals: [-10.713, -7.552, -12.8, -inf, -9.871, -12.8, -9.354]Step 1197 1 visits [1.0, 307.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2056 q_vals: [-10.713, -7.528, -12.8, -inf, -9.871, -12.8, -9.354]Step 1198 1 visits [1.0, 308.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2057 q_vals: [-10.713, -7.529, -12.8, -inf, -9.871, -12.8, -9.354]Step 1199 1 visits [1.0, 309.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2059 q_vals: [-10.713, -7.505, -12.8, -inf, -9.871, -12.8, -9.354]Step 1200 1 visits [1.0, 310.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2059 q_vals: [-10.713, -7.48, -12.8, -inf, -9.871, -12.8, -9.354]Step 1201 1 visits [1.0, 311.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2060 q_vals: [-10.713, -7.486, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2064, "number_of_timesteps": 37909, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1202 1 visits [1.0, 312.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2064 q_vals: [-10.713, -7.462, -12.8, -inf, -9.871, -12.8, -9.354]Step 1203 1 visits [1.0, 313.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2065 q_vals: [-10.713, -7.438, -12.8, -inf, -9.871, -12.8, -9.354]Step 1204 1 visits [1.0, 314.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2066 q_vals: [-10.713, -7.438, -12.8, -inf, -9.871, -12.8, -9.354]Step 1205 1 visits [1.0, 315.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2069 q_vals: [-10.713, -7.44, -12.8, -inf, -9.871, -12.8, -9.354]Step 1206 1 visits [1.0, 316.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2070 q_vals: [-10.713, -7.444, -12.8, -inf, -9.871, -12.8, -9.354]Step 1207 1 visits [1.0, 317.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2070 q_vals: [-10.713, -7.421, -12.8, -inf, -9.871, -12.8, -9.354]Step 1208 1 visits [1.0, 318.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2072 q_vals: [-10.713, -7.432, -12.8, -inf, -9.871, -12.8, -9.354]Step 1209 1 visits [1.0, 319.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2073 q_vals: [-10.713, -7.435, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2076, "number_of_timesteps": 38169, "per_episode_reward": 13.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1210 1 visits [1.0, 320.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2076 q_vals: [-10.713, -7.437, -12.8, -inf, -9.871, -12.8, -9.354]Step 1211 1 visits [1.0, 321.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2076 q_vals: [-10.713, -7.444, -12.8, -inf, -9.871, -12.8, -9.354]Step 1212 1 visits [1.0, 322.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2079 q_vals: [-10.713, -7.449, -12.8, -inf, -9.871, -12.8, -9.354]Step 1213 1 visits [1.0, 323.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2080 q_vals: [-10.713, -7.452, -12.8, -inf, -9.871, -12.8, -9.354]Step 1214 1 visits [1.0, 324.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2081 q_vals: [-10.713, -7.452, -12.8, -inf, -9.871, -12.8, -9.354]Step 1215 1 visits [1.0, 325.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2081 q_vals: [-10.713, -7.46, -12.8, -inf, -9.871, -12.8, -9.354]Step 1216 1 visits [1.0, 326.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2083 q_vals: [-10.713, -7.462, -12.8, -inf, -9.871, -12.8, -9.354]Step 1217 1 visits [1.0, 327.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2083 q_vals: [-10.713, -7.439, -12.8, -inf, -9.871, -12.8, -9.354]Step 1218 1 visits [1.0, 328.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2084 q_vals: [-10.713, -7.439, -12.8, -inf, -9.871, -12.8, -9.354]Step 1219 1 visits [1.0, 329.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2084 q_vals: [-10.713, -7.433, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2089, "number_of_timesteps": 38503, "per_episode_reward": 13.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
Step 1220 1 visits [1.0, 330.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2089 q_vals: [-10.713, -7.433, -12.8, -inf, -9.871, -12.8, -9.354]Step 1221 1 visits [1.0, 331.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2089 q_vals: [-10.713, -7.436, -12.8, -inf, -9.871, -12.8, -9.354]Step 1222 1 visits [1.0, 332.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2090 q_vals: [-10.713, -7.425, -12.8, -inf, -9.871, -12.8, -9.354]Step 1223 1 visits [1.0, 333.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2092 q_vals: [-10.713, -7.438, -12.8, -inf, -9.871, -12.8, -9.354]Step 1224 1 visits [1.0, 334.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2093 q_vals: [-10.713, -7.454, -12.8, -inf, -9.871, -12.8, -9.354]Step 1225 1 visits [1.0, 335.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2096 q_vals: [-10.713, -7.454, -12.8, -inf, -9.871, -12.8, -9.354]Step 1226 1 visits [1.0, 336.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2098 q_vals: [-10.713, -7.457, -12.8, -inf, -9.871, -12.8, -9.354]Step 1227 1 visits [1.0, 337.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2098 q_vals: [-10.713, -7.467, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2100, "number_of_timesteps": 38754, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1228 1 visits [1.0, 338.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2100 q_vals: [-10.713, -7.477, -12.8, -inf, -9.871, -12.8, -9.354]Step 1229 1 visits [1.0, 339.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2100 q_vals: [-10.713, -7.487, -12.8, -inf, -9.871, -12.8, -9.354]Step 1230 1 visits [1.0, 340.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2103 q_vals: [-10.713, -7.485, -12.8, -inf, -9.871, -12.8, -9.354]Step 1231 1 visits [1.0, 341.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2104 q_vals: [-10.713, -7.491, -12.8, -inf, -9.871, -12.8, -9.354]Step 1232 1 visits [1.0, 342.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2105 q_vals: [-10.713, -7.469, -12.8, -inf, -9.871, -12.8, -9.354]Step 1233 1 visits [1.0, 343.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2106 q_vals: [-10.713, -7.447, -12.8, -inf, -9.871, -12.8, -9.354]Step 1234 1 visits [1.0, 344.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2109 q_vals: [-10.713, -7.457, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2110, "number_of_timesteps": 38980, "per_episode_reward": 13.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1235 1 visits [1.0, 345.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2110 q_vals: [-10.713, -7.435, -12.8, -inf, -9.871, -12.8, -9.354]Step 1236 1 visits [1.0, 346.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2113 q_vals: [-10.713, -7.435, -12.8, -inf, -9.871, -12.8, -9.354]Step 1237 1 visits [1.0, 347.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2115 q_vals: [-10.713, -7.435, -12.8, -inf, -9.871, -12.8, -9.354]Step 1238 1 visits [1.0, 348.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2117 q_vals: [-10.713, -7.414, -12.8, -inf, -9.871, -12.8, -9.354]Step 1239 1 visits [1.0, 349.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2119 q_vals: [-10.713, -7.415, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2120, "number_of_timesteps": 39131, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1240 1 visits [1.0, 350.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2120 q_vals: [-10.713, -7.393, -12.8, -inf, -9.871, -12.8, -9.354]Step 1241 1 visits [1.0, 351.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2122 q_vals: [-10.713, -7.397, -12.8, -inf, -9.871, -12.8, -9.354]Step 1242 1 visits [1.0, 352.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2124 q_vals: [-10.713, -7.399, -12.8, -inf, -9.871, -12.8, -9.354]Step 1243 1 visits [1.0, 353.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2125 q_vals: [-10.713, -7.415, -12.8, -inf, -9.871, -12.8, -9.354]Step 1244 1 visits [1.0, 354.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2128 q_vals: [-10.713, -7.394, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2130, "number_of_timesteps": 39310, "per_episode_reward": 13.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1245 1 visits [1.0, 355.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2130 q_vals: [-10.713, -7.402, -12.8, -inf, -9.871, -12.8, -9.354]Step 1246 1 visits [1.0, 356.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2131 q_vals: [-10.713, -7.402, -12.8, -inf, -9.871, -12.8, -9.354]Step 1247 1 visits [1.0, 357.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2133 q_vals: [-10.713, -7.401, -12.8, -inf, -9.871, -12.8, -9.354]Step 1248 1 visits [1.0, 358.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2135 q_vals: [-10.713, -7.401, -12.8, -inf, -9.871, -12.8, -9.354]Step 1249 1 visits [1.0, 359.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2139 q_vals: [-10.713, -7.409, -12.8, -inf, -9.871, -12.8, -9.354]Step 1250 1 visits [1.0, 360.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2139 q_vals: [-10.713, -7.414, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2141, "number_of_timesteps": 39472, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1251 1 visits [1.0, 361.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2141 q_vals: [-10.713, -7.393, -12.8, -inf, -9.871, -12.8, -9.354]Step 1252 1 visits [1.0, 362.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2144 q_vals: [-10.713, -7.373, -12.8, -inf, -9.871, -12.8, -9.354]Step 1253 1 visits [1.0, 363.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2146 q_vals: [-10.713, -7.376, -12.8, -inf, -9.871, -12.8, -9.354]Step 1254 1 visits [1.0, 364.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2148 q_vals: [-10.713, -7.382, -12.8, -inf, -9.871, -12.8, -9.354]Step 1255 1 visits [1.0, 365.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2150 q_vals: [-10.713, -7.397, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2152, "number_of_timesteps": 39632, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1256 1 visits [1.0, 366.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2152 q_vals: [-10.713, -7.403, -12.8, -inf, -9.871, -12.8, -9.354]Step 1257 1 visits [1.0, 367.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2154 q_vals: [-10.713, -7.383, -12.8, -inf, -9.871, -12.8, -9.354]Step 1258 1 visits [1.0, 368.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2156 q_vals: [-10.713, -7.382, -12.8, -inf, -9.871, -12.8, -9.354]Step 1259 1 visits [1.0, 369.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2159 q_vals: [-10.713, -7.397, -12.8, -inf, -9.871, -12.8, -9.354]Step 1260 1 visits [1.0, 370.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2161 q_vals: [-10.713, -7.399, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2162, "number_of_timesteps": 39775, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1261 1 visits [1.0, 371.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2162 q_vals: [-10.713, -7.398, -12.8, -inf, -9.871, -12.8, -9.354]Step 1262 1 visits [1.0, 372.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2166 q_vals: [-10.713, -7.397, -12.8, -inf, -9.871, -12.8, -9.354]Step 1263 1 visits [1.0, 373.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2166 q_vals: [-10.713, -7.401, -12.8, -inf, -9.871, -12.8, -9.354]Step 1264 1 visits [1.0, 374.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2169 q_vals: [-10.713, -7.402, -12.8, -inf, -9.871, -12.8, -9.354]Step 1265 1 visits [1.0, 375.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2171 q_vals: [-10.713, -7.405, -12.8, -inf, -9.871, -12.8, -9.354]Step 1266 1 visits [1.0, 376.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2171 q_vals: [-10.713, -7.41, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2175, "number_of_timesteps": 39967, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
Step 1267 1 visits [1.0, 377.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2175 q_vals: [-10.713, -7.409, -12.8, -inf, -9.871, -12.8, -9.354]Step 1268 1 visits [1.0, 378.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2177 q_vals: [-10.713, -7.409, -12.8, -inf, -9.871, -12.8, -9.354]Step 1269 1 visits [1.0, 379.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2179 q_vals: [-10.713, -7.414, -12.8, -inf, -9.871, -12.8, -9.354]Step 1270 1 visits [1.0, 380.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2181 q_vals: [-10.713, -7.428, -12.8, -inf, -9.871, -12.8, -9.354]Step 1271 1 visits [1.0, 381.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2183 q_vals: [-10.713, -7.409, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2186, "number_of_timesteps": 40140, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1272 1 visits [1.0, 382.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2186 q_vals: [-10.713, -7.41, -12.8, -inf, -9.871, -12.8, -9.354]Step 1273 1 visits [1.0, 383.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2187 q_vals: [-10.713, -7.41, -12.8, -inf, -9.871, -12.8, -9.354]Step 1274 1 visits [1.0, 384.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2191 q_vals: [-10.713, -7.414, -12.8, -inf, -9.871, -12.8, -9.354]Step 1275 1 visits [1.0, 385.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2192 q_vals: [-10.713, -7.413, -12.8, -inf, -9.871, -12.8, -9.354]Step 1276 1 visits [1.0, 386.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2195 q_vals: [-10.713, -7.394, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2198, "number_of_timesteps": 40298, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
Step 1277 1 visits [1.0, 387.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2198 q_vals: [-10.713, -7.393, -12.8, -inf, -9.871, -12.8, -9.354]Step 1278 1 visits [1.0, 388.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2199 q_vals: [-10.713, -7.395, -12.8, -inf, -9.871, -12.8, -9.354]Step 1279 1 visits [1.0, 389.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2201 q_vals: [-10.713, -7.376, -12.8, -inf, -9.871, -12.8, -9.354]Step 1280 1 visits [1.0, 390.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2203 q_vals: [-10.713, -7.375, -12.8, -inf, -9.871, -12.8, -9.354]Step 1281 1 visits [1.0, 391.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2205 q_vals: [-10.713, -7.375, -12.8, -inf, -9.871, -12.8, -9.354]Step 1282 1 visits [1.0, 392.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2206 q_vals: [-10.713, -7.375, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2208, "number_of_timesteps": 40455, "per_episode_reward": 13.29, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
Step 1283 1 visits [1.0, 393.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2208 q_vals: [-10.713, -7.376, -12.8, -inf, -9.871, -12.8, -9.354]Step 1284 1 visits [1.0, 394.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2210 q_vals: [-10.713, -7.375, -12.8, -inf, -9.871, -12.8, -9.354]Step 1285 1 visits [1.0, 395.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2213 q_vals: [-10.713, -7.375, -12.8, -inf, -9.871, -12.8, -9.354]Step 1286 1 visits [1.0, 396.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2215 q_vals: [-10.713, -7.356, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2219, "number_of_timesteps": 40605, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 1287 1 visits [1.0, 397.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2219 q_vals: [-10.713, -7.337, -12.8, -inf, -9.871, -12.8, -9.354]Step 1288 1 visits [1.0, 398.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2220 q_vals: [-10.713, -7.351, -12.8, -inf, -9.871, -12.8, -9.354]Step 1289 1 visits [1.0, 399.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2223 q_vals: [-10.713, -7.351, -12.8, -inf, -9.871, -12.8, -9.354]Step 1290 1 visits [1.0, 400.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2226 q_vals: [-10.713, -7.352, -12.8, -inf, -9.871, -12.8, -9.354]Step 1291 1 visits [1.0, 401.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2227 q_vals: [-10.713, -7.353, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2229, "number_of_timesteps": 40719, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.14285714285714413},
Step 1292 1 visits [1.0, 402.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2229 q_vals: [-10.713, -7.352, -12.8, -inf, -9.871, -12.8, -9.354]Step 1293 1 visits [1.0, 403.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2232 q_vals: [-10.713, -7.351, -12.8, -inf, -9.871, -12.8, -9.354]Step 1294 1 visits [1.0, 404.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2233 q_vals: [-10.713, -7.333, -12.8, -inf, -9.871, -12.8, -9.354]Step 1295 1 visits [1.0, 405.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2235 q_vals: [-10.713, -7.315, -12.8, -inf, -9.871, -12.8, -9.354]Step 1296 1 visits [1.0, 406.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2237 q_vals: [-10.713, -7.314, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2239, "number_of_timesteps": 40874, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 1297 1 visits [1.0, 407.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2239 q_vals: [-10.713, -7.315, -12.8, -inf, -9.871, -12.8, -9.354]Step 1298 1 visits [1.0, 408.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2239 q_vals: [-10.713, -7.315, -12.8, -inf, -9.871, -12.8, -9.354]Step 1299 1 visits [1.0, 409.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2239 q_vals: [-10.713, -7.316, -12.8, -inf, -9.871, -12.8, -9.354]Step 1300 1 visits [1.0, 410.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2242 q_vals: [-10.713, -7.315, -12.8, -inf, -9.871, -12.8, -9.354]Step 1301 1 visits [1.0, 411.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2243 q_vals: [-10.713, -7.307, -12.8, -inf, -9.871, -12.8, -9.354]Step 1302 1 visits [1.0, 412.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2244 q_vals: [-10.713, -7.321, -12.8, -inf, -9.871, -12.8, -9.354]Step 1303 1 visits [1.0, 413.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2244 q_vals: [-10.713, -7.321, -12.8, -inf, -9.871, -12.8, -9.354]Step 1304 1 visits [1.0, 414.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2248 q_vals: [-10.713, -7.304, -12.8, -inf, -9.871, -12.8, -9.354]Step 1305 1 visits [1.0, 415.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2248 q_vals: [-10.713, -7.306, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2251, "number_of_timesteps": 41140, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 1306 1 visits [1.0, 416.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2251 q_vals: [-10.713, -7.304, -12.8, -inf, -9.871, -12.8, -9.354]Step 1307 1 visits [1.0, 417.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2253 q_vals: [-10.713, -7.306, -12.8, -inf, -9.871, -12.8, -9.354]Step 1308 1 visits [1.0, 418.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2254 q_vals: [-10.713, -7.303, -12.8, -inf, -9.871, -12.8, -9.354]Step 1309 1 visits [1.0, 419.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2257 q_vals: [-10.713, -7.286, -12.8, -inf, -9.871, -12.8, -9.354]Step 1310 1 visits [1.0, 420.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2258 q_vals: [-10.713, -7.269, -12.8, -inf, -9.871, -12.8, -9.354]Step 1311 1 visits [1.0, 421.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2259 q_vals: [-10.713, -7.251, -12.8, -inf, -9.871, -12.8, -9.354]Step 1312 1 visits [1.0, 422.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2260 q_vals: [-10.713, -7.259, -12.8, -inf, -9.871, -12.8, -9.354]Step 1313 1 visits [1.0, 423.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2260 q_vals: [-10.713, -7.242, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2263, "number_of_timesteps": 41385, "per_episode_reward": 13.21, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
Step 1314 1 visits [1.0, 424.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2263 q_vals: [-10.713, -7.241, -12.8, -inf, -9.871, -12.8, -9.354]Step 1315 1 visits [1.0, 425.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2263 q_vals: [-10.713, -7.242, -12.8, -inf, -9.871, -12.8, -9.354]Step 1316 1 visits [1.0, 426.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2265 q_vals: [-10.713, -7.225, -12.8, -inf, -9.871, -12.8, -9.354]Step 1317 1 visits [1.0, 427.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2268 q_vals: [-10.713, -7.225, -12.8, -inf, -9.871, -12.8, -9.354]Step 1318 1 visits [1.0, 428.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2268 q_vals: [-10.713, -7.226, -12.8, -inf, -9.871, -12.8, -9.354]Step 1319 1 visits [1.0, 429.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2270 q_vals: [-10.713, -7.229, -12.8, -inf, -9.871, -12.8, -9.354]Step 1320 1 visits [1.0, 430.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2271 q_vals: [-10.713, -7.228, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2274, "number_of_timesteps": 41651, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.14285714285714413},
Step 1321 1 visits [1.0, 431.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2274 q_vals: [-10.713, -7.211, -12.8, -inf, -9.871, -12.8, -9.354]Step 1322 1 visits [1.0, 432.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2276 q_vals: [-10.713, -7.214, -12.8, -inf, -9.871, -12.8, -9.354]Step 1323 1 visits [1.0, 433.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2277 q_vals: [-10.713, -7.213, -12.8, -inf, -9.871, -12.8, -9.354]Step 1324 1 visits [1.0, 434.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2279 q_vals: [-10.713, -7.226, -12.8, -inf, -9.871, -12.8, -9.354]Step 1325 1 visits [1.0, 435.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2279 q_vals: [-10.713, -7.225, -12.8, -inf, -9.871, -12.8, -9.354]Step 1326 1 visits [1.0, 436.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2281 q_vals: [-10.713, -7.225, -12.8, -inf, -9.871, -12.8, -9.354]Step 1327 1 visits [1.0, 437.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2283 q_vals: [-10.713, -7.224, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2284, "number_of_timesteps": 41834, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.2142857142857153},
Step 1328 1 visits [1.0, 438.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2284 q_vals: [-10.713, -7.216, -12.8, -inf, -9.871, -12.8, -9.354]Step 1329 1 visits [1.0, 439.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2287 q_vals: [-10.713, -7.217, -12.8, -inf, -9.871, -12.8, -9.354]Step 1330 1 visits [1.0, 440.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2288 q_vals: [-10.713, -7.2, -12.8, -inf, -9.871, -12.8, -9.354]Step 1331 1 visits [1.0, 441.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2290 q_vals: [-10.713, -7.199, -12.8, -inf, -9.871, -12.8, -9.354]Step 1332 1 visits [1.0, 442.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2292 q_vals: [-10.713, -7.204, -12.8, -inf, -9.871, -12.8, -9.354]Step 1333 1 visits [1.0, 443.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2292 q_vals: [-10.713, -7.217, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2295, "number_of_timesteps": 42035, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.2142857142857153},
Step 1334 1 visits [1.0, 444.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2295 q_vals: [-10.713, -7.218, -12.8, -inf, -9.871, -12.8, -9.354]Step 1335 1 visits [1.0, 445.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2298 q_vals: [-10.713, -7.216, -12.8, -inf, -9.871, -12.8, -9.354]Step 1336 1 visits [1.0, 446.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2298 q_vals: [-10.713, -7.215, -12.8, -inf, -9.871, -12.8, -9.354]Step 1337 1 visits [1.0, 447.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2300 q_vals: [-10.713, -7.216, -12.8, -inf, -9.871, -12.8, -9.354]Step 1338 1 visits [1.0, 448.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2301 q_vals: [-10.713, -7.227, -12.8, -inf, -9.871, -12.8, -9.354]Step 1339 1 visits [1.0, 449.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2304 q_vals: [-10.713, -7.227, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2306, "number_of_timesteps": 42242, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.2142857142857153},
Step 1340 1 visits [1.0, 450.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2306 q_vals: [-10.713, -7.232, -12.8, -inf, -9.871, -12.8, -9.354]Step 1341 1 visits [1.0, 451.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2306 q_vals: [-10.713, -7.235, -12.8, -inf, -9.871, -12.8, -9.354]Step 1342 1 visits [1.0, 452.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2309 q_vals: [-10.713, -7.247, -12.8, -inf, -9.871, -12.8, -9.354]Step 1343 1 visits [1.0, 453.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2313 q_vals: [-10.713, -7.252, -12.8, -inf, -9.871, -12.8, -9.354]Step 1344 1 visits [1.0, 454.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2313 q_vals: [-10.713, -7.249, -12.8, -inf, -9.871, -12.8, -9.354]Step 1345 1 visits [1.0, 455.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2315 q_vals: [-10.713, -7.261, -12.8, -inf, -9.871, -12.8, -9.354]Step 1346 1 visits [1.0, 456.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2315 q_vals: [-10.713, -7.245, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2317, "number_of_timesteps": 42421, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.2142857142857153},
Step 1347 1 visits [1.0, 457.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2317 q_vals: [-10.713, -7.244, -12.8, -inf, -9.871, -12.8, -9.354]Step 1348 1 visits [1.0, 458.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2318 q_vals: [-10.713, -7.243, -12.8, -inf, -9.871, -12.8, -9.354]Step 1349 1 visits [1.0, 459.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2321 q_vals: [-10.713, -7.242, -12.8, -inf, -9.871, -12.8, -9.354]Step 1350 1 visits [1.0, 460.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2324 q_vals: [-10.713, -7.241, -12.8, -inf, -9.871, -12.8, -9.354]Step 1351 1 visits [1.0, 461.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2325 q_vals: [-10.713, -7.239, -12.8, -inf, -9.871, -12.8, -9.354]Step 1352 1 visits [1.0, 462.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2326 q_vals: [-10.713, -7.238, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2327, "number_of_timesteps": 42603, "per_episode_reward": 13.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.2142857142857153},
Step 1353 1 visits [1.0, 463.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2327 q_vals: [-10.713, -7.222, -12.8, -inf, -9.871, -12.8, -9.354]Step 1354 1 visits [1.0, 464.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2330 q_vals: [-10.713, -7.222, -12.8, -inf, -9.871, -12.8, -9.354]Step 1355 1 visits [1.0, 465.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2331 q_vals: [-10.713, -7.229, -12.8, -inf, -9.871, -12.8, -9.354]Step 1356 1 visits [1.0, 466.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2331 q_vals: [-10.713, -7.213, -12.8, -inf, -9.871, -12.8, -9.354]Step 1357 1 visits [1.0, 467.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2334 q_vals: [-10.713, -7.225, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2337, "number_of_timesteps": 42814, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.2142857142857153},
Step 1358 1 visits [1.0, 468.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2337 q_vals: [-10.713, -7.225, -12.8, -inf, -9.871, -12.8, -9.354]Step 1359 1 visits [1.0, 469.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2339 q_vals: [-10.713, -7.226, -12.8, -inf, -9.871, -12.8, -9.354]Step 1360 1 visits [1.0, 470.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2340 q_vals: [-10.713, -7.211, -12.8, -inf, -9.871, -12.8, -9.354]Step 1361 1 visits [1.0, 471.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2341 q_vals: [-10.713, -7.209, -12.8, -inf, -9.871, -12.8, -9.354]Step 1362 1 visits [1.0, 472.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2343 q_vals: [-10.713, -7.208, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2347, "number_of_timesteps": 42982, "per_episode_reward": 13.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.2142857142857153},
Step 1363 1 visits [1.0, 473.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2347 q_vals: [-10.713, -7.192, -12.8, -inf, -9.871, -12.8, -9.354]Step 1364 1 visits [1.0, 474.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2349 q_vals: [-10.713, -7.204, -12.8, -inf, -9.871, -12.8, -9.354]Step 1365 1 visits [1.0, 475.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2350 q_vals: [-10.713, -7.216, -12.8, -inf, -9.871, -12.8, -9.354]Step 1366 1 visits [1.0, 476.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2354 q_vals: [-10.713, -7.201, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2357, "number_of_timesteps": 43106, "per_episode_reward": 13.07, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.2142857142857153},
Step 1367 1 visits [1.0, 477.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2357 q_vals: [-10.713, -7.186, -12.8, -inf, -9.871, -12.8, -9.354]Step 1368 1 visits [1.0, 478.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2357 q_vals: [-10.713, -7.187, -12.8, -inf, -9.871, -12.8, -9.354]Step 1369 1 visits [1.0, 479.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2359 q_vals: [-10.713, -7.186, -12.8, -inf, -9.871, -12.8, -9.354]Step 1370 1 visits [1.0, 480.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2362 q_vals: [-10.713, -7.188, -12.8, -inf, -9.871, -12.8, -9.354]Step 1371 1 visits [1.0, 481.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2363 q_vals: [-10.713, -7.186, -12.8, -inf, -9.871, -12.8, -9.354]Step 1372 1 visits [1.0, 482.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2364 q_vals: [-10.713, -7.186, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2369, "number_of_timesteps": 43294, "per_episode_reward": 13.07, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.2142857142857153},
Step 1373 1 visits [1.0, 483.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2369 q_vals: [-10.713, -7.185, -12.8, -inf, -9.871, -12.8, -9.354]Step 1374 1 visits [1.0, 484.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2369 q_vals: [-10.713, -7.185, -12.8, -inf, -9.871, -12.8, -9.354]Step 1375 1 visits [1.0, 485.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2369 q_vals: [-10.713, -7.197, -12.8, -inf, -9.871, -12.8, -9.354]Step 1376 1 visits [1.0, 486.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2375 q_vals: [-10.713, -7.2, -12.8, -inf, -9.871, -12.8, -9.354]Step 1377 1 visits [1.0, 487.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2375 q_vals: [-10.713, -7.198, -12.8, -inf, -9.871, -12.8, -9.354]Step 1378 1 visits [1.0, 488.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2376 q_vals: [-10.713, -7.21, -12.8, -inf, -9.871, -12.8, -9.354]Step 1379 1 visits [1.0, 489.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2378 q_vals: [-10.713, -7.209, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2380, "number_of_timesteps": 43472, "per_episode_reward": 13.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 1380 1 visits [1.0, 490.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2380 q_vals: [-10.713, -7.208, -12.8, -inf, -9.871, -12.8, -9.354]Step 1381 1 visits [1.0, 491.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2381 q_vals: [-10.713, -7.194, -12.8, -inf, -9.871, -12.8, -9.354]Step 1382 1 visits [1.0, 492.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2383 q_vals: [-10.713, -7.198, -12.8, -inf, -9.871, -12.8, -9.354]Step 1383 1 visits [1.0, 493.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2385 q_vals: [-10.713, -7.196, -12.8, -inf, -9.871, -12.8, -9.354]Step 1384 1 visits [1.0, 494.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2387 q_vals: [-10.713, -7.202, -12.8, -inf, -9.871, -12.8, -9.354]Step 1385 1 visits [1.0, 495.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2388 q_vals: [-10.713, -7.2, -12.8, -inf, -9.871, -12.8, -9.354]Step 1386 1 visits [1.0, 496.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2388 q_vals: [-10.713, -7.2, -12.8, -inf, -9.871, -12.8, -9.354]{"total_number_of_episodes": 2390, "number_of_timesteps": 43632, "per_episode_reward": 13.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
Step 1387 1 visits [1.0, 497.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2390 q_vals: [-10.713, -7.204, -12.8, -inf, -9.871, -12.8, -9.354]Step 1388 1 visits [1.0, 498.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2392 q_vals: [-10.713, -7.208, -12.8, -inf, -9.871, -12.8, -9.354]Step 1389 1 visits [1.0, 499.0, 1.0, 500.0, 2.0, 1.0, 5.0]  episode_count: 2393 q_vals: [-10.713, -7.21, -12.8, -inf, -9.871, -12.8, -9.354]Step 1390 1 visits [0.0, 500.0, 0.0, 500.0, 0.0, 0.0, 0.0]  episode_count: 2394 q_vals: [0.0, -inf, 0.0, -inf, 0.0, 0.0, 0.0]Step 1391 0 visits [1.0, 500.0, 0.0, 500.0, 0.0, 0.0, 0.0]  episode_count: 2395 q_vals: [-7.246, -inf, 0.0, -inf, 0.0, 0.0, 0.0]Step 1392 2 visits [1.0, 500.0, 1.0, 500.0, 0.0, 0.0, 0.0]  episode_count: 2399 q_vals: [-7.246, -inf, 0.0, -inf, 0.0, 0.0, 0.0]{"total_number_of_episodes": 2400, "number_of_timesteps": 43886, "per_episode_reward": 11.14, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 2.142857142857144},
Step 1393 4 visits [1.0, 500.0, 1.0, 500.0, 1.0, 0.0, 0.0]  episode_count: 2400 q_vals: [-7.246, -inf, 0.0, -inf, -8.758, 0.0, 0.0]Step 1394 5 visits [1.0, 500.0, 1.0, 500.0, 1.0, 1.0, 0.0]  episode_count: 2401 q_vals: [-7.246, -inf, 0.0, -inf, -8.758, 0.0, 0.0]Step 1395 6 visits [1.0, 500.0, 1.0, 500.0, 1.0, 1.0, 1.0]  episode_count: 2403 q_vals: [-7.246, -inf, 0.0, -inf, -8.758, 0.0, -15.0]Step 1396 2 visits [1.0, 500.0, 2.0, 500.0, 1.0, 1.0, 1.0]  episode_count: 2406 q_vals: [-7.246, -inf, 0.0, -inf, -8.758, 0.0, -15.0]Step 1397 5 visits [1.0, 500.0, 2.0, 500.0, 1.0, 2.0, 1.0]  episode_count: 2409 q_vals: [-7.246, -inf, 0.0, -inf, -8.758, -4.898, -15.0]{"total_number_of_episodes": 2410, "number_of_timesteps": 44049, "per_episode_reward": 11.14, "episode_reward_trend_value": -0.02142857142857143, "biggest_recent_change": 2.142857142857144},
Step 1398 2 visits [1.0, 500.0, 3.0, 500.0, 1.0, 2.0, 1.0]  episode_count: 2410 q_vals: [-7.246, -inf, -2.629, -inf, -8.758, -4.898, -15.0]Step 1399 2 visits [1.0, 500.0, 4.0, 500.0, 1.0, 2.0, 1.0]  episode_count: 2412 q_vals: [-7.246, -inf, -1.972, -inf, -8.758, -4.898, -15.0]Step 1400 2 visits [1.0, 500.0, 5.0, 500.0, 1.0, 2.0, 1.0]  episode_count: 2414 q_vals: [-7.246, -inf, -3.414, -inf, -8.758, -4.898, -15.0]Step 1401 2 visits [1.0, 500.0, 6.0, 500.0, 1.0, 2.0, 1.0]  episode_count: 2416 q_vals: [-7.246, -inf, -5.345, -inf, -8.758, -4.898, -15.0]Step 1402 5 visits [1.0, 500.0, 6.0, 500.0, 1.0, 3.0, 1.0]  episode_count: 2417 q_vals: [-7.246, -inf, -5.345, -inf, -8.758, -3.265, -15.0]Step 1403 5 visits [1.0, 500.0, 6.0, 500.0, 1.0, 4.0, 1.0]  episode_count: 2418 q_vals: [-7.246, -inf, -5.345, -inf, -8.758, -2.449, -15.0]Step 1404 5 visits [1.0, 500.0, 6.0, 500.0, 1.0, 5.0, 1.0]  episode_count: 2419 q_vals: [-7.246, -inf, -5.345, -inf, -8.758, -3.419, -15.0]{"total_number_of_episodes": 2420, "number_of_timesteps": 44216, "per_episode_reward": 11.14, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 2.142857142857144},
Step 1405 5 visits [1.0, 500.0, 6.0, 500.0, 1.0, 6.0, 1.0]  episode_count: 2420 q_vals: [-7.246, -inf, -5.345, -inf, -8.758, -4.488, -15.0]Step 1406 5 visits [1.0, 500.0, 6.0, 500.0, 1.0, 7.0, 1.0]  episode_count: 2422 q_vals: [-7.246, -inf, -5.345, -inf, -8.758, -4.869, -15.0]Step 1407 5 visits [1.0, 500.0, 6.0, 500.0, 1.0, 8.0, 1.0]  episode_count: 2425 q_vals: [-7.246, -inf, -5.345, -inf, -8.758, -5.412, -15.0]Step 1408 2 visits [1.0, 500.0, 7.0, 500.0, 1.0, 8.0, 1.0]  episode_count: 2426 q_vals: [-7.246, -inf, -4.582, -inf, -8.758, -5.412, -15.0]Step 1409 2 visits [1.0, 500.0, 8.0, 500.0, 1.0, 8.0, 1.0]  episode_count: 2427 q_vals: [-7.246, -inf, -4.986, -inf, -8.758, -5.412, -15.0]Step 1410 2 visits [1.0, 500.0, 9.0, 500.0, 1.0, 8.0, 1.0]  episode_count: 2429 q_vals: [-7.246, -inf, -5.505, -inf, -8.758, -5.412, -15.0]{"total_number_of_episodes": 2430, "number_of_timesteps": 44399, "per_episode_reward": 11.14, "episode_reward_trend_value": -0.02301587301587301, "biggest_recent_change": 2.142857142857144},
Step 1411 5 visits [1.0, 500.0, 9.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2430 q_vals: [-7.246, -inf, -5.505, -inf, -8.758, -6.477, -15.0]Step 1412 2 visits [1.0, 500.0, 10.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2431 q_vals: [-7.246, -inf, -4.955, -inf, -8.758, -6.477, -15.0]Step 1413 2 visits [1.0, 500.0, 11.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2434 q_vals: [-7.246, -inf, -4.504, -inf, -8.758, -6.477, -15.0]Step 1414 2 visits [1.0, 500.0, 12.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2435 q_vals: [-7.246, -inf, -4.129, -inf, -8.758, -6.477, -15.0]Step 1415 2 visits [1.0, 500.0, 13.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2437 q_vals: [-7.246, -inf, -4.386, -inf, -8.758, -6.477, -15.0]Step 1416 2 visits [1.0, 500.0, 14.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2438 q_vals: [-7.246, -inf, -4.619, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2442, "number_of_timesteps": 44666, "per_episode_reward": 11.14, "episode_reward_trend_value": -0.02301587301587301, "biggest_recent_change": 2.142857142857144},
Step 1417 2 visits [1.0, 500.0, 15.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2442 q_vals: [-7.246, -inf, -4.796, -inf, -8.758, -6.477, -15.0]Step 1418 2 visits [1.0, 500.0, 16.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2442 q_vals: [-7.246, -inf, -4.496, -inf, -8.758, -6.477, -15.0]Step 1419 2 visits [1.0, 500.0, 17.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2444 q_vals: [-7.246, -inf, -4.232, -inf, -8.758, -6.477, -15.0]Step 1420 2 visits [1.0, 500.0, 18.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2446 q_vals: [-7.246, -inf, -4.401, -inf, -8.758, -6.477, -15.0]Step 1421 2 visits [1.0, 500.0, 19.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2449 q_vals: [-7.246, -inf, -4.169, -inf, -8.758, -6.477, -15.0]Step 1422 2 visits [1.0, 500.0, 20.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2450 q_vals: [-7.246, -inf, -3.961, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2452, "number_of_timesteps": 44802, "per_episode_reward": 11.14, "episode_reward_trend_value": -0.02142857142857143, "biggest_recent_change": 2.142857142857144},
Step 1423 2 visits [1.0, 500.0, 21.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2452 q_vals: [-7.246, -inf, -4.101, -inf, -8.758, -6.477, -15.0]Step 1424 2 visits [1.0, 500.0, 22.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2454 q_vals: [-7.246, -inf, -4.316, -inf, -8.758, -6.477, -15.0]Step 1425 2 visits [1.0, 500.0, 23.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2456 q_vals: [-7.246, -inf, -4.446, -inf, -8.758, -6.477, -15.0]Step 1426 2 visits [1.0, 500.0, 24.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2456 q_vals: [-7.246, -inf, -4.261, -inf, -8.758, -6.477, -15.0]Step 1427 2 visits [1.0, 500.0, 25.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2458 q_vals: [-7.246, -inf, -4.69, -inf, -8.758, -6.477, -15.0]Step 1428 2 visits [1.0, 500.0, 26.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2460 q_vals: [-7.246, -inf, -4.51, -inf, -8.758, -6.477, -15.0]Step 1429 2 visits [1.0, 500.0, 27.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2461 q_vals: [-7.246, -inf, -4.343, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2462, "number_of_timesteps": 45026, "per_episode_reward": 11.14, "episode_reward_trend_value": -0.02142857142857143, "biggest_recent_change": 2.142857142857144},
Step 1430 2 visits [1.0, 500.0, 28.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2462 q_vals: [-7.246, -inf, -4.444, -inf, -8.758, -6.477, -15.0]Step 1431 2 visits [1.0, 500.0, 29.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2465 q_vals: [-7.246, -inf, -4.291, -inf, -8.758, -6.477, -15.0]Step 1432 2 visits [1.0, 500.0, 30.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2467 q_vals: [-7.246, -inf, -4.648, -inf, -8.758, -6.477, -15.0]Step 1433 2 visits [1.0, 500.0, 31.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2467 q_vals: [-7.246, -inf, -4.918, -inf, -8.758, -6.477, -15.0]Step 1434 2 visits [1.0, 500.0, 32.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2469 q_vals: [-7.246, -inf, -4.764, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2472, "number_of_timesteps": 45236, "per_episode_reward": 11.14, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 2.142857142857144},
Step 1435 2 visits [1.0, 500.0, 33.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2472 q_vals: [-7.246, -inf, -4.827, -inf, -8.758, -6.477, -15.0]Step 1436 2 visits [1.0, 500.0, 34.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2473 q_vals: [-7.246, -inf, -4.685, -inf, -8.758, -6.477, -15.0]Step 1437 2 visits [1.0, 500.0, 35.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2474 q_vals: [-7.246, -inf, -4.98, -inf, -8.758, -6.477, -15.0]Step 1438 2 visits [1.0, 500.0, 36.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2476 q_vals: [-7.246, -inf, -5.16, -inf, -8.758, -6.477, -15.0]Step 1439 2 visits [1.0, 500.0, 37.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2476 q_vals: [-7.246, -inf, -5.244, -inf, -8.758, -6.477, -15.0]Step 1440 2 visits [1.0, 500.0, 38.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2477 q_vals: [-7.246, -inf, -5.291, -inf, -8.758, -6.477, -15.0]Step 1441 2 visits [1.0, 500.0, 39.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2479 q_vals: [-7.246, -inf, -5.369, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2482, "number_of_timesteps": 45461, "per_episode_reward": 11.14, "episode_reward_trend_value": -0.023809523809523826, "biggest_recent_change": 2.142857142857144},
Step 1442 2 visits [1.0, 500.0, 40.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2482 q_vals: [-7.246, -inf, -5.234, -inf, -8.758, -6.477, -15.0]Step 1443 2 visits [1.0, 500.0, 41.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2483 q_vals: [-7.246, -inf, -5.311, -inf, -8.758, -6.477, -15.0]Step 1444 2 visits [1.0, 500.0, 42.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2487 q_vals: [-7.246, -inf, -5.184, -inf, -8.758, -6.477, -15.0]Step 1445 2 visits [1.0, 500.0, 43.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2489 q_vals: [-7.246, -inf, -5.236, -inf, -8.758, -6.477, -15.0]Step 1446 2 visits [1.0, 500.0, 44.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2490 q_vals: [-7.246, -inf, -5.309, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2492, "number_of_timesteps": 45609, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1447 2 visits [1.0, 500.0, 45.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2492 q_vals: [-7.246, -inf, -5.524, -inf, -8.758, -6.477, -15.0]Step 1448 2 visits [1.0, 500.0, 46.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2496 q_vals: [-7.246, -inf, -5.404, -inf, -8.758, -6.477, -15.0]Step 1449 2 visits [1.0, 500.0, 47.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2496 q_vals: [-7.246, -inf, -5.502, -inf, -8.758, -6.477, -15.0]Step 1450 2 visits [1.0, 500.0, 48.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2499 q_vals: [-7.246, -inf, -5.596, -inf, -8.758, -6.477, -15.0]Step 1451 0 visits [2.0, 500.0, 48.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2500 q_vals: [-3.623, -inf, -5.596, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2503, "number_of_timesteps": 45782, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1452 0 visits [3.0, 500.0, 48.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2503 q_vals: [-4.844, -inf, -5.596, -inf, -8.758, -6.477, -15.0]Step 1453 0 visits [4.0, 500.0, 48.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2505 q_vals: [-3.633, -inf, -5.596, -inf, -8.758, -6.477, -15.0]Step 1454 0 visits [5.0, 500.0, 48.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2507 q_vals: [-4.802, -inf, -5.596, -inf, -8.758, -6.477, -15.0]Step 1455 0 visits [6.0, 500.0, 48.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2510 q_vals: [-5.261, -inf, -5.596, -inf, -8.758, -6.477, -15.0]Step 1456 0 visits [7.0, 500.0, 48.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2512 q_vals: [-5.878, -inf, -5.596, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2514, "number_of_timesteps": 45929, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1457 0 visits [8.0, 500.0, 48.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2514 q_vals: [-6.385, -inf, -5.596, -inf, -8.758, -6.477, -15.0]Step 1458 2 visits [8.0, 500.0, 49.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2516 q_vals: [-6.385, -inf, -5.482, -inf, -8.758, -6.477, -15.0]Step 1459 2 visits [8.0, 500.0, 50.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2517 q_vals: [-6.385, -inf, -5.516, -inf, -8.758, -6.477, -15.0]Step 1460 2 visits [8.0, 500.0, 51.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2518 q_vals: [-6.385, -inf, -5.606, -inf, -8.758, -6.477, -15.0]Step 1461 2 visits [8.0, 500.0, 52.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2520 q_vals: [-6.385, -inf, -5.631, -inf, -8.758, -6.477, -15.0]Step 1462 2 visits [8.0, 500.0, 53.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2522 q_vals: [-6.385, -inf, -5.656, -inf, -8.758, -6.477, -15.0]Step 1463 2 visits [8.0, 500.0, 54.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2523 q_vals: [-6.385, -inf, -5.783, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2525, "number_of_timesteps": 46150, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1464 2 visits [8.0, 500.0, 55.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2525 q_vals: [-6.385, -inf, -5.678, -inf, -8.758, -6.477, -15.0]Step 1465 2 visits [8.0, 500.0, 56.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2528 q_vals: [-6.385, -inf, -5.576, -inf, -8.758, -6.477, -15.0]Step 1466 2 visits [8.0, 500.0, 57.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2530 q_vals: [-6.385, -inf, -5.479, -inf, -8.758, -6.477, -15.0]Step 1467 2 visits [8.0, 500.0, 58.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2531 q_vals: [-6.385, -inf, -5.499, -inf, -8.758, -6.477, -15.0]Step 1468 2 visits [8.0, 500.0, 59.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2534 q_vals: [-6.385, -inf, -5.549, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2536, "number_of_timesteps": 46314, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1469 2 visits [8.0, 500.0, 60.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2536 q_vals: [-6.385, -inf, -5.601, -inf, -8.758, -6.477, -15.0]Step 1470 2 visits [8.0, 500.0, 61.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2537 q_vals: [-6.385, -inf, -5.509, -inf, -8.758, -6.477, -15.0]Step 1471 2 visits [8.0, 500.0, 62.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2539 q_vals: [-6.385, -inf, -5.42, -inf, -8.758, -6.477, -15.0]Step 1472 2 visits [8.0, 500.0, 63.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2543 q_vals: [-6.385, -inf, -5.572, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2546, "number_of_timesteps": 46460, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1473 2 visits [8.0, 500.0, 64.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2546 q_vals: [-6.385, -inf, -5.485, -inf, -8.758, -6.477, -15.0]Step 1474 2 visits [8.0, 500.0, 65.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2548 q_vals: [-6.385, -inf, -5.513, -inf, -8.758, -6.477, -15.0]Step 1475 2 visits [8.0, 500.0, 66.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2550 q_vals: [-6.385, -inf, -5.553, -inf, -8.758, -6.477, -15.0]Step 1476 2 visits [8.0, 500.0, 67.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2554 q_vals: [-6.385, -inf, -5.47, -inf, -8.758, -6.477, -15.0]Step 1477 2 visits [8.0, 500.0, 68.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2554 q_vals: [-6.385, -inf, -5.389, -inf, -8.758, -6.477, -15.0]Step 1478 2 visits [8.0, 500.0, 69.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2555 q_vals: [-6.385, -inf, -5.529, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2560, "number_of_timesteps": 46643, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1479 2 visits [8.0, 500.0, 70.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2560 q_vals: [-6.385, -inf, -5.549, -inf, -8.758, -6.477, -15.0]Step 1480 2 visits [8.0, 500.0, 71.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2561 q_vals: [-6.385, -inf, -5.568, -inf, -8.758, -6.477, -15.0]Step 1481 2 visits [8.0, 500.0, 72.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2564 q_vals: [-6.385, -inf, -5.491, -inf, -8.758, -6.477, -15.0]Step 1482 2 visits [8.0, 500.0, 73.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2566 q_vals: [-6.385, -inf, -5.415, -inf, -8.758, -6.477, -15.0]Step 1483 2 visits [8.0, 500.0, 74.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2569 q_vals: [-6.385, -inf, -5.439, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2570, "number_of_timesteps": 46781, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1484 2 visits [8.0, 500.0, 75.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2570 q_vals: [-6.385, -inf, -5.458, -inf, -8.758, -6.477, -15.0]Step 1485 2 visits [8.0, 500.0, 76.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2575 q_vals: [-6.385, -inf, -5.512, -inf, -8.758, -6.477, -15.0]Step 1486 2 visits [8.0, 500.0, 77.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2575 q_vals: [-6.385, -inf, -5.533, -inf, -8.758, -6.477, -15.0]Step 1487 2 visits [8.0, 500.0, 78.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2576 q_vals: [-6.385, -inf, -5.551, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2580, "number_of_timesteps": 46910, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1488 2 visits [8.0, 500.0, 79.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2580 q_vals: [-6.385, -inf, -5.481, -inf, -8.758, -6.477, -15.0]Step 1489 2 visits [8.0, 500.0, 80.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2582 q_vals: [-6.385, -inf, -5.512, -inf, -8.758, -6.477, -15.0]Step 1490 2 visits [8.0, 500.0, 81.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2582 q_vals: [-6.385, -inf, -5.444, -inf, -8.758, -6.477, -15.0]Step 1491 2 visits [8.0, 500.0, 82.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2583 q_vals: [-6.385, -inf, -5.378, -inf, -8.758, -6.477, -15.0]Step 1492 2 visits [8.0, 500.0, 83.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2586 q_vals: [-6.385, -inf, -5.493, -inf, -8.758, -6.477, -15.0]Step 1493 2 visits [8.0, 500.0, 84.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2586 q_vals: [-6.385, -inf, -5.428, -inf, -8.758, -6.477, -15.0]Step 1494 2 visits [8.0, 500.0, 85.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2588 q_vals: [-6.385, -inf, -5.364, -inf, -8.758, -6.477, -15.0]Step 1495 2 visits [8.0, 500.0, 86.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2589 q_vals: [-6.385, -inf, -5.302, -inf, -8.758, -6.477, -15.0]Step 1496 2 visits [8.0, 500.0, 87.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2589 q_vals: [-6.385, -inf, -5.338, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2592, "number_of_timesteps": 47109, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1497 2 visits [8.0, 500.0, 88.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2592 q_vals: [-6.385, -inf, -5.354, -inf, -8.758, -6.477, -15.0]Step 1498 2 visits [8.0, 500.0, 89.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2594 q_vals: [-6.385, -inf, -5.373, -inf, -8.758, -6.477, -15.0]Step 1499 2 visits [8.0, 500.0, 90.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2596 q_vals: [-6.385, -inf, -5.399, -inf, -8.758, -6.477, -15.0]Step 1500 2 visits [8.0, 500.0, 91.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2598 q_vals: [-6.385, -inf, -5.339, -inf, -8.758, -6.477, -15.0]Step 1501 2 visits [8.0, 500.0, 92.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2600 q_vals: [-6.385, -inf, -5.37, -inf, -8.758, -6.477, -15.0]Step 1502 2 visits [8.0, 500.0, 93.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2601 q_vals: [-6.385, -inf, -5.395, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2603, "number_of_timesteps": 47368, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1503 2 visits [8.0, 500.0, 94.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2603 q_vals: [-6.385, -inf, -5.338, -inf, -8.758, -6.477, -15.0]Step 1504 2 visits [8.0, 500.0, 95.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2604 q_vals: [-6.385, -inf, -5.373, -inf, -8.758, -6.477, -15.0]Step 1505 2 visits [8.0, 500.0, 96.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2608 q_vals: [-6.385, -inf, -5.317, -inf, -8.758, -6.477, -15.0]Step 1506 2 visits [8.0, 500.0, 97.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2610 q_vals: [-6.385, -inf, -5.347, -inf, -8.758, -6.477, -15.0]Step 1507 2 visits [8.0, 500.0, 98.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2610 q_vals: [-6.385, -inf, -5.385, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2614, "number_of_timesteps": 47537, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1508 2 visits [8.0, 500.0, 99.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2614 q_vals: [-6.385, -inf, -5.418, -inf, -8.758, -6.477, -15.0]Step 1509 2 visits [8.0, 500.0, 100.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2615 q_vals: [-6.385, -inf, -5.439, -inf, -8.758, -6.477, -15.0]Step 1510 2 visits [8.0, 500.0, 101.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2615 q_vals: [-6.385, -inf, -5.452, -inf, -8.758, -6.477, -15.0]Step 1511 2 visits [8.0, 500.0, 102.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2618 q_vals: [-6.385, -inf, -5.469, -inf, -8.758, -6.477, -15.0]Step 1512 2 visits [8.0, 500.0, 103.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2619 q_vals: [-6.385, -inf, -5.484, -inf, -8.758, -6.477, -15.0]Step 1513 2 visits [8.0, 500.0, 104.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2623 q_vals: [-6.385, -inf, -5.502, -inf, -8.758, -6.477, -15.0]Step 1514 2 visits [8.0, 500.0, 105.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2623 q_vals: [-6.385, -inf, -5.515, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2625, "number_of_timesteps": 47733, "per_episode_reward": 10.93, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.14285714285714235},
Step 1515 2 visits [8.0, 500.0, 106.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2625 q_vals: [-6.385, -inf, -5.548, -inf, -8.758, -6.477, -15.0]Step 1516 2 visits [8.0, 500.0, 107.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2625 q_vals: [-6.385, -inf, -5.496, -inf, -8.758, -6.477, -15.0]Step 1517 2 visits [8.0, 500.0, 108.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2625 q_vals: [-6.385, -inf, -5.445, -inf, -8.758, -6.477, -15.0]Step 1518 2 visits [8.0, 500.0, 109.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2626 q_vals: [-6.385, -inf, -5.395, -inf, -8.758, -6.477, -15.0]Step 1519 2 visits [8.0, 500.0, 110.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2627 q_vals: [-6.385, -inf, -5.408, -inf, -8.758, -6.477, -15.0]Step 1520 2 visits [8.0, 500.0, 111.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2629 q_vals: [-6.385, -inf, -5.419, -inf, -8.758, -6.477, -15.0]Step 1521 2 visits [8.0, 500.0, 112.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2630 q_vals: [-6.385, -inf, -5.429, -inf, -8.758, -6.477, -15.0]Step 1522 2 visits [8.0, 500.0, 113.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2631 q_vals: [-6.385, -inf, -5.381, -inf, -8.758, -6.477, -15.0]Step 1523 2 visits [8.0, 500.0, 114.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2634 q_vals: [-6.385, -inf, -5.392, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2636, "number_of_timesteps": 48000, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1524 2 visits [8.0, 500.0, 115.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2636 q_vals: [-6.385, -inf, -5.404, -inf, -8.758, -6.477, -15.0]Step 1525 2 visits [8.0, 500.0, 116.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2637 q_vals: [-6.385, -inf, -5.415, -inf, -8.758, -6.477, -15.0]Step 1526 2 visits [8.0, 500.0, 117.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2638 q_vals: [-6.385, -inf, -5.434, -inf, -8.758, -6.477, -15.0]Step 1527 2 visits [8.0, 500.0, 118.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2641 q_vals: [-6.385, -inf, -5.388, -inf, -8.758, -6.477, -15.0]Step 1528 2 visits [8.0, 500.0, 119.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2642 q_vals: [-6.385, -inf, -5.442, -inf, -8.758, -6.477, -15.0]Step 1529 2 visits [8.0, 500.0, 120.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2642 q_vals: [-6.385, -inf, -5.521, -inf, -8.758, -6.477, -15.0]Step 1530 2 visits [8.0, 500.0, 121.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2644 q_vals: [-6.385, -inf, -5.55, -inf, -8.758, -6.477, -15.0]Step 1531 2 visits [8.0, 500.0, 122.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2645 q_vals: [-6.385, -inf, -5.504, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2646, "number_of_timesteps": 48241, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1532 2 visits [8.0, 500.0, 123.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2646 q_vals: [-6.385, -inf, -5.46, -inf, -8.758, -6.477, -15.0]Step 1533 2 visits [8.0, 500.0, 124.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2648 q_vals: [-6.385, -inf, -5.498, -inf, -8.758, -6.477, -15.0]Step 1534 2 visits [8.0, 500.0, 125.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2648 q_vals: [-6.385, -inf, -5.515, -inf, -8.758, -6.477, -15.0]Step 1535 2 visits [8.0, 500.0, 126.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2652 q_vals: [-6.385, -inf, -5.472, -inf, -8.758, -6.477, -15.0]Step 1536 2 visits [8.0, 500.0, 127.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2653 q_vals: [-6.385, -inf, -5.473, -inf, -8.758, -6.477, -15.0]Step 1537 2 visits [8.0, 500.0, 128.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2655 q_vals: [-6.385, -inf, -5.507, -inf, -8.758, -6.477, -15.0]Step 1538 2 visits [8.0, 500.0, 129.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2655 q_vals: [-6.385, -inf, -5.515, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2658, "number_of_timesteps": 48485, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1539 2 visits [8.0, 500.0, 130.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2658 q_vals: [-6.385, -inf, -5.533, -inf, -8.758, -6.477, -15.0]Step 1540 2 visits [8.0, 500.0, 131.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2658 q_vals: [-6.385, -inf, -5.54, -inf, -8.758, -6.477, -15.0]Step 1541 2 visits [8.0, 500.0, 132.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2661 q_vals: [-6.385, -inf, -5.498, -inf, -8.758, -6.477, -15.0]Step 1542 2 visits [8.0, 500.0, 133.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2662 q_vals: [-6.385, -inf, -5.457, -inf, -8.758, -6.477, -15.0]Step 1543 2 visits [8.0, 500.0, 134.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2662 q_vals: [-6.385, -inf, -5.416, -inf, -8.758, -6.477, -15.0]Step 1544 2 visits [8.0, 500.0, 135.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2663 q_vals: [-6.385, -inf, -5.376, -inf, -8.758, -6.477, -15.0]Step 1545 2 visits [8.0, 500.0, 136.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2663 q_vals: [-6.385, -inf, -5.337, -inf, -8.758, -6.477, -15.0]Step 1546 2 visits [8.0, 500.0, 137.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2665 q_vals: [-6.385, -inf, -5.298, -inf, -8.758, -6.477, -15.0]Step 1547 2 visits [8.0, 500.0, 138.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2667 q_vals: [-6.385, -inf, -5.313, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2670, "number_of_timesteps": 48836, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1548 2 visits [8.0, 500.0, 139.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2670 q_vals: [-6.385, -inf, -5.321, -inf, -8.758, -6.477, -15.0]Step 1549 2 visits [8.0, 500.0, 140.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2672 q_vals: [-6.385, -inf, -5.283, -inf, -8.758, -6.477, -15.0]Step 1550 2 visits [8.0, 500.0, 141.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2673 q_vals: [-6.385, -inf, -5.291, -inf, -8.758, -6.477, -15.0]Step 1551 2 visits [8.0, 500.0, 142.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2675 q_vals: [-6.385, -inf, -5.254, -inf, -8.758, -6.477, -15.0]Step 1552 2 visits [8.0, 500.0, 143.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2676 q_vals: [-6.385, -inf, -5.262, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2680, "number_of_timesteps": 48977, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
Step 1553 2 visits [8.0, 500.0, 144.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2680 q_vals: [-6.385, -inf, -5.225, -inf, -8.758, -6.477, -15.0]Step 1554 2 visits [8.0, 500.0, 145.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2681 q_vals: [-6.385, -inf, -5.235, -inf, -8.758, -6.477, -15.0]Step 1555 2 visits [8.0, 500.0, 146.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2682 q_vals: [-6.385, -inf, -5.251, -inf, -8.758, -6.477, -15.0]Step 1556 2 visits [8.0, 500.0, 147.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2684 q_vals: [-6.385, -inf, -5.317, -inf, -8.758, -6.477, -15.0]Step 1557 2 visits [8.0, 500.0, 148.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2686 q_vals: [-6.385, -inf, -5.324, -inf, -8.758, -6.477, -15.0]Step 1558 2 visits [8.0, 500.0, 149.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2687 q_vals: [-6.385, -inf, -5.331, -inf, -8.758, -6.477, -15.0]Step 1559 2 visits [8.0, 500.0, 150.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2689 q_vals: [-6.385, -inf, -5.296, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2692, "number_of_timesteps": 49192, "per_episode_reward": 11.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
Step 1560 2 visits [8.0, 500.0, 151.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2692 q_vals: [-6.385, -inf, -5.303, -inf, -8.758, -6.477, -15.0]Step 1561 2 visits [8.0, 500.0, 152.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2693 q_vals: [-6.385, -inf, -5.311, -inf, -8.758, -6.477, -15.0]Step 1562 2 visits [8.0, 500.0, 153.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2696 q_vals: [-6.385, -inf, -5.374, -inf, -8.758, -6.477, -15.0]Step 1563 2 visits [8.0, 500.0, 154.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2699 q_vals: [-6.385, -inf, -5.381, -inf, -8.758, -6.477, -15.0]Step 1564 2 visits [8.0, 500.0, 155.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2701 q_vals: [-6.385, -inf, -5.443, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2704, "number_of_timesteps": 49363, "per_episode_reward": 10.93, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.21428571428571352},
Step 1565 2 visits [8.0, 500.0, 156.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2704 q_vals: [-6.385, -inf, -5.408, -inf, -8.758, -6.477, -15.0]Step 1566 2 visits [8.0, 500.0, 157.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2707 q_vals: [-6.385, -inf, -5.414, -inf, -8.758, -6.477, -15.0]Step 1567 2 visits [8.0, 500.0, 158.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2709 q_vals: [-6.385, -inf, -5.38, -inf, -8.758, -6.477, -15.0]Step 1568 2 visits [8.0, 500.0, 159.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2712 q_vals: [-6.385, -inf, -5.346, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2714, "number_of_timesteps": 49472, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571352},
Step 1569 2 visits [8.0, 500.0, 160.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2714 q_vals: [-6.385, -inf, -5.356, -inf, -8.758, -6.477, -15.0]Step 1570 2 visits [8.0, 500.0, 161.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2718 q_vals: [-6.385, -inf, -5.362, -inf, -8.758, -6.477, -15.0]Step 1571 2 visits [8.0, 500.0, 162.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2720 q_vals: [-6.385, -inf, -5.368, -inf, -8.758, -6.477, -15.0]Step 1572 2 visits [8.0, 500.0, 163.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2722 q_vals: [-6.385, -inf, -5.375, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2725, "number_of_timesteps": 49600, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.21428571428571352},
Step 1573 2 visits [8.0, 500.0, 164.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2725 q_vals: [-6.385, -inf, -5.343, -inf, -8.758, -6.477, -15.0]Step 1574 2 visits [8.0, 500.0, 165.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2727 q_vals: [-6.385, -inf, -5.353, -inf, -8.758, -6.477, -15.0]Step 1575 2 visits [8.0, 500.0, 166.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2731 q_vals: [-6.385, -inf, -5.321, -inf, -8.758, -6.477, -15.0]Step 1576 2 visits [8.0, 500.0, 167.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2732 q_vals: [-6.385, -inf, -5.289, -inf, -8.758, -6.477, -15.0]Step 1577 2 visits [8.0, 500.0, 168.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2734 q_vals: [-6.385, -inf, -5.295, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2738, "number_of_timesteps": 49753, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.21428571428571352},
Step 1578 2 visits [8.0, 500.0, 169.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2738 q_vals: [-6.385, -inf, -5.263, -inf, -8.758, -6.477, -15.0]Step 1579 2 visits [8.0, 500.0, 170.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2739 q_vals: [-6.385, -inf, -5.232, -inf, -8.758, -6.477, -15.0]Step 1580 2 visits [8.0, 500.0, 171.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2742 q_vals: [-6.385, -inf, -5.27, -inf, -8.758, -6.477, -15.0]Step 1581 2 visits [8.0, 500.0, 172.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2745 q_vals: [-6.385, -inf, -5.277, -inf, -8.758, -6.477, -15.0]Step 1582 2 visits [8.0, 500.0, 173.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2746 q_vals: [-6.385, -inf, -5.283, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2749, "number_of_timesteps": 49893, "per_episode_reward": 10.86, "episode_reward_trend_value": -0.0031746031746031633, "biggest_recent_change": 0.21428571428571352},
Step 1583 2 visits [8.0, 500.0, 174.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2749 q_vals: [-6.385, -inf, -5.253, -inf, -8.758, -6.477, -15.0]Step 1584 2 visits [8.0, 500.0, 175.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2752 q_vals: [-6.385, -inf, -5.259, -inf, -8.758, -6.477, -15.0]Step 1585 2 visits [8.0, 500.0, 176.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2753 q_vals: [-6.385, -inf, -5.262, -inf, -8.758, -6.477, -15.0]Step 1586 2 visits [8.0, 500.0, 177.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2756 q_vals: [-6.385, -inf, -5.269, -inf, -8.758, -6.477, -15.0]Step 1587 2 visits [8.0, 500.0, 178.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2757 q_vals: [-6.385, -inf, -5.24, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2760, "number_of_timesteps": 50046, "per_episode_reward": 10.79, "episode_reward_trend_value": -0.0023809523809523725, "biggest_recent_change": 0.21428571428571352},
Step 1588 2 visits [8.0, 500.0, 179.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2760 q_vals: [-6.385, -inf, -5.264, -inf, -8.758, -6.477, -15.0]Step 1589 2 visits [8.0, 500.0, 180.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2762 q_vals: [-6.385, -inf, -5.275, -inf, -8.758, -6.477, -15.0]Step 1590 2 visits [8.0, 500.0, 181.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2763 q_vals: [-6.385, -inf, -5.245, -inf, -8.758, -6.477, -15.0]Step 1591 2 visits [8.0, 500.0, 182.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2764 q_vals: [-6.385, -inf, -5.256, -inf, -8.758, -6.477, -15.0]Step 1592 2 visits [8.0, 500.0, 183.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2766 q_vals: [-6.385, -inf, -5.262, -inf, -8.758, -6.477, -15.0]Step 1593 2 visits [8.0, 500.0, 184.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2767 q_vals: [-6.385, -inf, -5.233, -inf, -8.758, -6.477, -15.0]Step 1594 2 visits [8.0, 500.0, 185.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2769 q_vals: [-6.385, -inf, -5.242, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2773, "number_of_timesteps": 50282, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.004761904761904764, "biggest_recent_change": 0.21428571428571352},
Step 1595 2 visits [8.0, 500.0, 186.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2773 q_vals: [-6.385, -inf, -5.214, -inf, -8.758, -6.477, -15.0]Step 1596 2 visits [8.0, 500.0, 187.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2774 q_vals: [-6.385, -inf, -5.186, -inf, -8.758, -6.477, -15.0]Step 1597 2 visits [8.0, 500.0, 188.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2774 q_vals: [-6.385, -inf, -5.158, -inf, -8.758, -6.477, -15.0]Step 1598 2 visits [8.0, 500.0, 189.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2777 q_vals: [-6.385, -inf, -5.165, -inf, -8.758, -6.477, -15.0]Step 1599 2 visits [8.0, 500.0, 190.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2777 q_vals: [-6.385, -inf, -5.172, -inf, -8.758, -6.477, -15.0]Step 1600 2 visits [8.0, 500.0, 191.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2778 q_vals: [-6.385, -inf, -5.145, -inf, -8.758, -6.477, -15.0]Step 1601 2 visits [8.0, 500.0, 192.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2780 q_vals: [-6.385, -inf, -5.149, -inf, -8.758, -6.477, -15.0]Step 1602 2 visits [8.0, 500.0, 193.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2781 q_vals: [-6.385, -inf, -5.159, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2783, "number_of_timesteps": 50489, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.21428571428571352},
Step 1603 2 visits [8.0, 500.0, 194.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2783 q_vals: [-6.385, -inf, -5.162, -inf, -8.758, -6.477, -15.0]Step 1604 2 visits [8.0, 500.0, 195.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2785 q_vals: [-6.385, -inf, -5.135, -inf, -8.758, -6.477, -15.0]Step 1605 2 visits [8.0, 500.0, 196.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2786 q_vals: [-6.385, -inf, -5.109, -inf, -8.758, -6.477, -15.0]Step 1606 2 visits [8.0, 500.0, 197.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2787 q_vals: [-6.385, -inf, -5.117, -inf, -8.758, -6.477, -15.0]Step 1607 2 visits [8.0, 500.0, 198.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2788 q_vals: [-6.385, -inf, -5.135, -inf, -8.758, -6.477, -15.0]Step 1608 2 visits [8.0, 500.0, 199.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2790 q_vals: [-6.385, -inf, -5.109, -inf, -8.758, -6.477, -15.0]Step 1609 2 visits [8.0, 500.0, 200.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2790 q_vals: [-6.385, -inf, -5.083, -inf, -8.758, -6.477, -15.0]Step 1610 2 visits [8.0, 500.0, 201.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2792 q_vals: [-6.385, -inf, -5.058, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2796, "number_of_timesteps": 50799, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.004761904761904764, "biggest_recent_change": 0.21428571428571352},
Step 1611 2 visits [8.0, 500.0, 202.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2796 q_vals: [-6.385, -inf, -5.033, -inf, -8.758, -6.477, -15.0]Step 1612 2 visits [8.0, 500.0, 203.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2798 q_vals: [-6.385, -inf, -5.008, -inf, -8.758, -6.477, -15.0]Step 1613 2 visits [8.0, 500.0, 204.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2798 q_vals: [-6.385, -inf, -4.984, -inf, -8.758, -6.477, -15.0]Step 1614 2 visits [8.0, 500.0, 205.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2800 q_vals: [-6.385, -inf, -5.032, -inf, -8.758, -6.477, -15.0]Step 1615 2 visits [8.0, 500.0, 206.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2801 q_vals: [-6.385, -inf, -5.008, -inf, -8.758, -6.477, -15.0]Step 1616 2 visits [8.0, 500.0, 207.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2803 q_vals: [-6.385, -inf, -4.984, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2808, "number_of_timesteps": 51002, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
Step 1617 2 visits [8.0, 500.0, 208.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2808 q_vals: [-6.385, -inf, -4.996, -inf, -8.758, -6.477, -15.0]Step 1618 2 visits [8.0, 500.0, 209.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2808 q_vals: [-6.385, -inf, -4.972, -inf, -8.758, -6.477, -15.0]Step 1619 2 visits [8.0, 500.0, 210.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2808 q_vals: [-6.385, -inf, -4.978, -inf, -8.758, -6.477, -15.0]Step 1620 2 visits [8.0, 500.0, 211.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2810 q_vals: [-6.385, -inf, -4.988, -inf, -8.758, -6.477, -15.0]Step 1621 2 visits [8.0, 500.0, 212.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2812 q_vals: [-6.385, -inf, -4.993, -inf, -8.758, -6.477, -15.0]Step 1622 2 visits [8.0, 500.0, 213.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2813 q_vals: [-6.385, -inf, -5.002, -inf, -8.758, -6.477, -15.0]Step 1623 2 visits [8.0, 500.0, 214.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2813 q_vals: [-6.385, -inf, -4.979, -inf, -8.758, -6.477, -15.0]Step 1624 2 visits [8.0, 500.0, 215.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2814 q_vals: [-6.385, -inf, -4.956, -inf, -8.758, -6.477, -15.0]Step 1625 2 visits [8.0, 500.0, 216.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2817 q_vals: [-6.385, -inf, -4.933, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2818, "number_of_timesteps": 51215, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1626 2 visits [8.0, 500.0, 217.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2818 q_vals: [-6.385, -inf, -4.91, -inf, -8.758, -6.477, -15.0]Step 1627 2 visits [8.0, 500.0, 218.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2820 q_vals: [-6.385, -inf, -4.911, -inf, -8.758, -6.477, -15.0]Step 1628 2 visits [8.0, 500.0, 219.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2821 q_vals: [-6.385, -inf, -4.923, -inf, -8.758, -6.477, -15.0]Step 1629 2 visits [8.0, 500.0, 220.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2822 q_vals: [-6.385, -inf, -4.969, -inf, -8.758, -6.477, -15.0]Step 1630 2 visits [8.0, 500.0, 221.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2824 q_vals: [-6.385, -inf, -4.976, -inf, -8.758, -6.477, -15.0]Step 1631 2 visits [8.0, 500.0, 222.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2826 q_vals: [-6.385, -inf, -4.953, -inf, -8.758, -6.477, -15.0]Step 1632 2 visits [8.0, 500.0, 223.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2827 q_vals: [-6.385, -inf, -4.965, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2829, "number_of_timesteps": 51449, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1633 2 visits [8.0, 500.0, 224.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2829 q_vals: [-6.385, -inf, -4.977, -inf, -8.758, -6.477, -15.0]Step 1634 2 visits [8.0, 500.0, 225.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2832 q_vals: [-6.385, -inf, -4.955, -inf, -8.758, -6.477, -15.0]Step 1635 2 visits [8.0, 500.0, 226.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2834 q_vals: [-6.385, -inf, -4.978, -inf, -8.758, -6.477, -15.0]Step 1636 2 visits [8.0, 500.0, 227.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2836 q_vals: [-6.385, -inf, -4.956, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2839, "number_of_timesteps": 51603, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1637 2 visits [8.0, 500.0, 228.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2839 q_vals: [-6.385, -inf, -4.935, -inf, -8.758, -6.477, -15.0]Step 1638 2 visits [8.0, 500.0, 229.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2840 q_vals: [-6.385, -inf, -4.913, -inf, -8.758, -6.477, -15.0]Step 1639 2 visits [8.0, 500.0, 230.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2845 q_vals: [-6.385, -inf, -4.892, -inf, -8.758, -6.477, -15.0]Step 1640 2 visits [8.0, 500.0, 231.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2845 q_vals: [-6.385, -inf, -4.87, -inf, -8.758, -6.477, -15.0]Step 1641 2 visits [8.0, 500.0, 232.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2846 q_vals: [-6.385, -inf, -4.876, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2850, "number_of_timesteps": 51783, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
Step 1642 2 visits [8.0, 500.0, 233.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2850 q_vals: [-6.385, -inf, -4.855, -inf, -8.758, -6.477, -15.0]Step 1643 2 visits [8.0, 500.0, 234.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2850 q_vals: [-6.385, -inf, -4.898, -inf, -8.758, -6.477, -15.0]Step 1644 2 visits [8.0, 500.0, 235.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2852 q_vals: [-6.385, -inf, -4.922, -inf, -8.758, -6.477, -15.0]Step 1645 2 visits [8.0, 500.0, 236.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2855 q_vals: [-6.385, -inf, -4.94, -inf, -8.758, -6.477, -15.0]Step 1646 2 visits [8.0, 500.0, 237.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2857 q_vals: [-6.385, -inf, -4.983, -inf, -8.758, -6.477, -15.0]Step 1647 2 visits [8.0, 500.0, 238.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2857 q_vals: [-6.385, -inf, -4.962, -inf, -8.758, -6.477, -15.0]Step 1648 2 visits [8.0, 500.0, 239.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2859 q_vals: [-6.385, -inf, -4.969, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2861, "number_of_timesteps": 51973, "per_episode_reward": 10.71, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
Step 1649 2 visits [8.0, 500.0, 240.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2861 q_vals: [-6.385, -inf, -4.949, -inf, -8.758, -6.477, -15.0]Step 1650 2 visits [8.0, 500.0, 241.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2864 q_vals: [-6.385, -inf, -4.96, -inf, -8.758, -6.477, -15.0]Step 1651 2 visits [8.0, 500.0, 242.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2865 q_vals: [-6.385, -inf, -4.939, -inf, -8.758, -6.477, -15.0]Step 1652 2 visits [8.0, 500.0, 243.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2866 q_vals: [-6.385, -inf, -4.951, -inf, -8.758, -6.477, -15.0]Step 1653 2 visits [8.0, 500.0, 244.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2869 q_vals: [-6.385, -inf, -4.96, -inf, -8.758, -6.477, -15.0]Step 1654 2 visits [8.0, 500.0, 245.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2869 q_vals: [-6.385, -inf, -4.939, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2871, "number_of_timesteps": 52154, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1655 2 visits [8.0, 500.0, 246.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2871 q_vals: [-6.385, -inf, -4.919, -inf, -8.758, -6.477, -15.0]Step 1656 2 visits [8.0, 500.0, 247.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2873 q_vals: [-6.385, -inf, -4.899, -inf, -8.758, -6.477, -15.0]Step 1657 2 visits [8.0, 500.0, 248.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2874 q_vals: [-6.385, -inf, -4.88, -inf, -8.758, -6.477, -15.0]Step 1658 2 visits [8.0, 500.0, 249.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2877 q_vals: [-6.385, -inf, -4.86, -inf, -8.758, -6.477, -15.0]Step 1659 2 visits [8.0, 500.0, 250.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2878 q_vals: [-6.385, -inf, -4.873, -inf, -8.758, -6.477, -15.0]Step 1660 2 visits [8.0, 500.0, 251.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2878 q_vals: [-6.385, -inf, -4.879, -inf, -8.758, -6.477, -15.0]Step 1661 2 visits [8.0, 500.0, 252.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2880 q_vals: [-6.385, -inf, -4.86, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2883, "number_of_timesteps": 52391, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1662 2 visits [8.0, 500.0, 253.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2883 q_vals: [-6.385, -inf, -4.841, -inf, -8.758, -6.477, -15.0]Step 1663 2 visits [8.0, 500.0, 254.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2885 q_vals: [-6.385, -inf, -4.846, -inf, -8.758, -6.477, -15.0]Step 1664 2 visits [8.0, 500.0, 255.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2888 q_vals: [-6.385, -inf, -4.849, -inf, -8.758, -6.477, -15.0]Step 1665 2 visits [8.0, 500.0, 256.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2888 q_vals: [-6.385, -inf, -4.889, -inf, -8.758, -6.477, -15.0]Step 1666 2 visits [8.0, 500.0, 257.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2891 q_vals: [-6.385, -inf, -4.895, -inf, -8.758, -6.477, -15.0]Step 1667 2 visits [8.0, 500.0, 258.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2892 q_vals: [-6.385, -inf, -4.898, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2894, "number_of_timesteps": 52577, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1668 2 visits [8.0, 500.0, 259.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2894 q_vals: [-6.385, -inf, -4.88, -inf, -8.758, -6.477, -15.0]Step 1669 2 visits [8.0, 500.0, 260.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2895 q_vals: [-6.385, -inf, -4.89, -inf, -8.758, -6.477, -15.0]Step 1670 2 visits [8.0, 500.0, 261.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2897 q_vals: [-6.385, -inf, -4.899, -inf, -8.758, -6.477, -15.0]Step 1671 2 visits [8.0, 500.0, 262.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2899 q_vals: [-6.385, -inf, -4.881, -inf, -8.758, -6.477, -15.0]Step 1672 2 visits [8.0, 500.0, 263.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2900 q_vals: [-6.385, -inf, -4.888, -inf, -8.758, -6.477, -15.0]Step 1673 2 visits [8.0, 500.0, 264.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2903 q_vals: [-6.385, -inf, -4.869, -inf, -8.758, -6.477, -15.0]Step 1674 2 visits [8.0, 500.0, 265.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2903 q_vals: [-6.385, -inf, -4.851, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2905, "number_of_timesteps": 52783, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1675 2 visits [8.0, 500.0, 266.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2905 q_vals: [-6.385, -inf, -4.853, -inf, -8.758, -6.477, -15.0]Step 1676 2 visits [8.0, 500.0, 267.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2905 q_vals: [-6.385, -inf, -4.834, -inf, -8.758, -6.477, -15.0]Step 1677 2 visits [8.0, 500.0, 268.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2908 q_vals: [-6.385, -inf, -4.816, -inf, -8.758, -6.477, -15.0]Step 1678 2 visits [8.0, 500.0, 269.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2910 q_vals: [-6.385, -inf, -4.799, -inf, -8.758, -6.477, -15.0]Step 1679 2 visits [8.0, 500.0, 270.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2911 q_vals: [-6.385, -inf, -4.804, -inf, -8.758, -6.477, -15.0]Step 1680 2 visits [8.0, 500.0, 271.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2913 q_vals: [-6.385, -inf, -4.786, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2916, "number_of_timesteps": 53008, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1681 2 visits [8.0, 500.0, 272.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2916 q_vals: [-6.385, -inf, -4.769, -inf, -8.758, -6.477, -15.0]Step 1682 2 visits [8.0, 500.0, 273.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2919 q_vals: [-6.385, -inf, -4.751, -inf, -8.758, -6.477, -15.0]Step 1683 2 visits [8.0, 500.0, 274.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2921 q_vals: [-6.385, -inf, -4.759, -inf, -8.758, -6.477, -15.0]Step 1684 2 visits [8.0, 500.0, 275.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2923 q_vals: [-6.385, -inf, -4.742, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2926, "number_of_timesteps": 53138, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1685 2 visits [8.0, 500.0, 276.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2926 q_vals: [-6.385, -inf, -4.747, -inf, -8.758, -6.477, -15.0]Step 1686 2 visits [8.0, 500.0, 277.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2927 q_vals: [-6.385, -inf, -4.784, -inf, -8.758, -6.477, -15.0]Step 1687 2 visits [8.0, 500.0, 278.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2930 q_vals: [-6.385, -inf, -4.766, -inf, -8.758, -6.477, -15.0]Step 1688 2 visits [8.0, 500.0, 279.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2932 q_vals: [-6.385, -inf, -4.776, -inf, -8.758, -6.477, -15.0]Step 1689 2 visits [8.0, 500.0, 280.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2934 q_vals: [-6.385, -inf, -4.759, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2938, "number_of_timesteps": 53293, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1690 2 visits [8.0, 500.0, 281.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2938 q_vals: [-6.385, -inf, -4.742, -inf, -8.758, -6.477, -15.0]Step 1691 2 visits [8.0, 500.0, 282.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2939 q_vals: [-6.385, -inf, -4.778, -inf, -8.758, -6.477, -15.0]Step 1692 2 visits [8.0, 500.0, 283.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2942 q_vals: [-6.385, -inf, -4.794, -inf, -8.758, -6.477, -15.0]Step 1693 2 visits [8.0, 500.0, 284.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2944 q_vals: [-6.385, -inf, -4.777, -inf, -8.758, -6.477, -15.0]Step 1694 2 visits [8.0, 500.0, 285.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2945 q_vals: [-6.385, -inf, -4.784, -inf, -8.758, -6.477, -15.0]Step 1695 2 visits [8.0, 500.0, 286.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2947 q_vals: [-6.385, -inf, -4.767, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2950, "number_of_timesteps": 53459, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1696 2 visits [8.0, 500.0, 287.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2950 q_vals: [-6.385, -inf, -4.771, -inf, -8.758, -6.477, -15.0]Step 1697 2 visits [8.0, 500.0, 288.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2952 q_vals: [-6.385, -inf, -4.775, -inf, -8.758, -6.477, -15.0]Step 1698 2 visits [8.0, 500.0, 289.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2953 q_vals: [-6.385, -inf, -4.759, -inf, -8.758, -6.477, -15.0]Step 1699 2 visits [8.0, 500.0, 290.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2955 q_vals: [-6.385, -inf, -4.743, -inf, -8.758, -6.477, -15.0]Step 1700 2 visits [8.0, 500.0, 291.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2958 q_vals: [-6.385, -inf, -4.726, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2960, "number_of_timesteps": 53599, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1701 2 visits [8.0, 500.0, 292.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2960 q_vals: [-6.385, -inf, -4.73, -inf, -8.758, -6.477, -15.0]Step 1702 2 visits [8.0, 500.0, 293.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2962 q_vals: [-6.385, -inf, -4.735, -inf, -8.758, -6.477, -15.0]Step 1703 2 visits [8.0, 500.0, 294.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2965 q_vals: [-6.385, -inf, -4.719, -inf, -8.758, -6.477, -15.0]Step 1704 2 visits [8.0, 500.0, 295.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2967 q_vals: [-6.385, -inf, -4.703, -inf, -8.758, -6.477, -15.0]Step 1705 2 visits [8.0, 500.0, 296.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2969 q_vals: [-6.385, -inf, -4.687, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2971, "number_of_timesteps": 53754, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1706 2 visits [8.0, 500.0, 297.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2971 q_vals: [-6.385, -inf, -4.671, -inf, -8.758, -6.477, -15.0]Step 1707 2 visits [8.0, 500.0, 298.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2973 q_vals: [-6.385, -inf, -4.679, -inf, -8.758, -6.477, -15.0]Step 1708 2 visits [8.0, 500.0, 299.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2976 q_vals: [-6.385, -inf, -4.682, -inf, -8.758, -6.477, -15.0]Step 1709 2 visits [8.0, 500.0, 300.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2978 q_vals: [-6.385, -inf, -4.667, -inf, -8.758, -6.477, -15.0]Step 1710 2 visits [8.0, 500.0, 301.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2980 q_vals: [-6.385, -inf, -4.651, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2983, "number_of_timesteps": 53912, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1711 2 visits [8.0, 500.0, 302.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2983 q_vals: [-6.385, -inf, -4.654, -inf, -8.758, -6.477, -15.0]Step 1712 2 visits [8.0, 500.0, 303.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2984 q_vals: [-6.385, -inf, -4.639, -inf, -8.758, -6.477, -15.0]Step 1713 2 visits [8.0, 500.0, 304.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2985 q_vals: [-6.385, -inf, -4.624, -inf, -8.758, -6.477, -15.0]Step 1714 2 visits [8.0, 500.0, 305.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2990 q_vals: [-6.385, -inf, -4.627, -inf, -8.758, -6.477, -15.0]Step 1715 2 visits [8.0, 500.0, 306.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2990 q_vals: [-6.385, -inf, -4.631, -inf, -8.758, -6.477, -15.0]Step 1716 2 visits [8.0, 500.0, 307.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2992 q_vals: [-6.385, -inf, -4.625, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 2995, "number_of_timesteps": 54092, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1717 2 visits [8.0, 500.0, 308.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2995 q_vals: [-6.385, -inf, -4.64, -inf, -8.758, -6.477, -15.0]Step 1718 2 visits [8.0, 500.0, 309.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2996 q_vals: [-6.385, -inf, -4.646, -inf, -8.758, -6.477, -15.0]Step 1719 2 visits [8.0, 500.0, 310.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2996 q_vals: [-6.385, -inf, -4.631, -inf, -8.758, -6.477, -15.0]Step 1720 2 visits [8.0, 500.0, 311.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 2998 q_vals: [-6.385, -inf, -4.638, -inf, -8.758, -6.477, -15.0]Step 1721 2 visits [8.0, 500.0, 312.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3001 q_vals: [-6.385, -inf, -4.623, -inf, -8.758, -6.477, -15.0]Step 1722 2 visits [8.0, 500.0, 313.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3003 q_vals: [-6.385, -inf, -4.631, -inf, -8.758, -6.477, -15.0]Step 1723 2 visits [8.0, 500.0, 314.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3004 q_vals: [-6.385, -inf, -4.64, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3007, "number_of_timesteps": 54313, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1724 2 visits [8.0, 500.0, 315.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3007 q_vals: [-6.385, -inf, -4.648, -inf, -8.758, -6.477, -15.0]Step 1725 2 visits [8.0, 500.0, 316.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3008 q_vals: [-6.385, -inf, -4.657, -inf, -8.758, -6.477, -15.0]Step 1726 2 visits [8.0, 500.0, 317.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3010 q_vals: [-6.385, -inf, -4.661, -inf, -8.758, -6.477, -15.0]Step 1727 2 visits [8.0, 500.0, 318.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3011 q_vals: [-6.385, -inf, -4.647, -inf, -8.758, -6.477, -15.0]Step 1728 2 visits [8.0, 500.0, 319.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3015 q_vals: [-6.385, -inf, -4.65, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3017, "number_of_timesteps": 54480, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1729 2 visits [8.0, 500.0, 320.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3017 q_vals: [-6.385, -inf, -4.635, -inf, -8.758, -6.477, -15.0]Step 1730 2 visits [8.0, 500.0, 321.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3019 q_vals: [-6.385, -inf, -4.639, -inf, -8.758, -6.477, -15.0]Step 1731 2 visits [8.0, 500.0, 322.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3020 q_vals: [-6.385, -inf, -4.625, -inf, -8.758, -6.477, -15.0]Step 1732 2 visits [8.0, 500.0, 323.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3021 q_vals: [-6.385, -inf, -4.611, -inf, -8.758, -6.477, -15.0]Step 1733 2 visits [8.0, 500.0, 324.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3022 q_vals: [-6.385, -inf, -4.614, -inf, -8.758, -6.477, -15.0]Step 1734 2 visits [8.0, 500.0, 325.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3024 q_vals: [-6.385, -inf, -4.618, -inf, -8.758, -6.477, -15.0]Step 1735 2 visits [8.0, 500.0, 326.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3026 q_vals: [-6.385, -inf, -4.604, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3029, "number_of_timesteps": 54711, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1736 2 visits [8.0, 500.0, 327.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3029 q_vals: [-6.385, -inf, -4.608, -inf, -8.758, -6.477, -15.0]Step 1737 2 visits [8.0, 500.0, 328.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3029 q_vals: [-6.385, -inf, -4.594, -inf, -8.758, -6.477, -15.0]Step 1738 2 visits [8.0, 500.0, 329.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3030 q_vals: [-6.385, -inf, -4.603, -inf, -8.758, -6.477, -15.0]Step 1739 2 visits [8.0, 500.0, 330.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3031 q_vals: [-6.385, -inf, -4.611, -inf, -8.758, -6.477, -15.0]Step 1740 2 visits [8.0, 500.0, 331.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3033 q_vals: [-6.385, -inf, -4.622, -inf, -8.758, -6.477, -15.0]Step 1741 2 visits [8.0, 500.0, 332.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3034 q_vals: [-6.385, -inf, -4.653, -inf, -8.758, -6.477, -15.0]Step 1742 2 visits [8.0, 500.0, 333.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3038 q_vals: [-6.385, -inf, -4.656, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3040, "number_of_timesteps": 54927, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1743 2 visits [8.0, 500.0, 334.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3040 q_vals: [-6.385, -inf, -4.642, -inf, -8.758, -6.477, -15.0]Step 1744 2 visits [8.0, 500.0, 335.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3041 q_vals: [-6.385, -inf, -4.628, -inf, -8.758, -6.477, -15.0]Step 1745 2 visits [8.0, 500.0, 336.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3041 q_vals: [-6.385, -inf, -4.642, -inf, -8.758, -6.477, -15.0]Step 1746 2 visits [8.0, 500.0, 337.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3043 q_vals: [-6.385, -inf, -4.628, -inf, -8.758, -6.477, -15.0]Step 1747 2 visits [8.0, 500.0, 338.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3045 q_vals: [-6.385, -inf, -4.632, -inf, -8.758, -6.477, -15.0]Step 1748 2 visits [8.0, 500.0, 339.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3045 q_vals: [-6.385, -inf, -4.618, -inf, -8.758, -6.477, -15.0]Step 1749 2 visits [8.0, 500.0, 340.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3049 q_vals: [-6.385, -inf, -4.622, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3050, "number_of_timesteps": 55128, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1750 2 visits [8.0, 500.0, 341.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3050 q_vals: [-6.385, -inf, -4.626, -inf, -8.758, -6.477, -15.0]Step 1751 2 visits [8.0, 500.0, 342.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3050 q_vals: [-6.385, -inf, -4.636, -inf, -8.758, -6.477, -15.0]Step 1752 2 visits [8.0, 500.0, 343.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3052 q_vals: [-6.385, -inf, -4.639, -inf, -8.758, -6.477, -15.0]Step 1753 2 visits [8.0, 500.0, 344.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3053 q_vals: [-6.385, -inf, -4.645, -inf, -8.758, -6.477, -15.0]Step 1754 2 visits [8.0, 500.0, 345.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3055 q_vals: [-6.385, -inf, -4.631, -inf, -8.758, -6.477, -15.0]Step 1755 2 visits [8.0, 500.0, 346.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3056 q_vals: [-6.385, -inf, -4.633, -inf, -8.758, -6.477, -15.0]Step 1756 2 visits [8.0, 500.0, 347.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3057 q_vals: [-6.385, -inf, -4.62, -inf, -8.758, -6.477, -15.0]Step 1757 2 visits [8.0, 500.0, 348.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3058 q_vals: [-6.385, -inf, -4.623, -inf, -8.758, -6.477, -15.0]Step 1758 2 visits [8.0, 500.0, 349.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3059 q_vals: [-6.385, -inf, -4.61, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3060, "number_of_timesteps": 55348, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1759 2 visits [8.0, 500.0, 350.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3060 q_vals: [-6.385, -inf, -4.597, -inf, -8.758, -6.477, -15.0]Step 1760 2 visits [8.0, 500.0, 351.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3061 q_vals: [-6.385, -inf, -4.584, -inf, -8.758, -6.477, -15.0]Step 1761 2 visits [8.0, 500.0, 352.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3062 q_vals: [-6.385, -inf, -4.591, -inf, -8.758, -6.477, -15.0]Step 1762 2 visits [8.0, 500.0, 353.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3063 q_vals: [-6.385, -inf, -4.578, -inf, -8.758, -6.477, -15.0]Step 1763 2 visits [8.0, 500.0, 354.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3065 q_vals: [-6.385, -inf, -4.58, -inf, -8.758, -6.477, -15.0]Step 1764 2 visits [8.0, 500.0, 355.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3068 q_vals: [-6.385, -inf, -4.568, -inf, -8.758, -6.477, -15.0]Step 1765 2 visits [8.0, 500.0, 356.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3068 q_vals: [-6.385, -inf, -4.572, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3071, "number_of_timesteps": 55655, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1766 2 visits [8.0, 500.0, 357.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3071 q_vals: [-6.385, -inf, -4.559, -inf, -8.758, -6.477, -15.0]Step 1767 2 visits [8.0, 500.0, 358.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3074 q_vals: [-6.385, -inf, -4.562, -inf, -8.758, -6.477, -15.0]Step 1768 2 visits [8.0, 500.0, 359.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3074 q_vals: [-6.385, -inf, -4.549, -inf, -8.758, -6.477, -15.0]Step 1769 2 visits [8.0, 500.0, 360.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3079 q_vals: [-6.385, -inf, -4.554, -inf, -8.758, -6.477, -15.0]Step 1770 2 visits [8.0, 500.0, 361.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3080 q_vals: [-6.385, -inf, -4.556, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3083, "number_of_timesteps": 55814, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1771 2 visits [8.0, 500.0, 362.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3083 q_vals: [-6.385, -inf, -4.565, -inf, -8.758, -6.477, -15.0]Step 1772 2 visits [8.0, 500.0, 363.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3086 q_vals: [-6.385, -inf, -4.57, -inf, -8.758, -6.477, -15.0]Step 1773 2 visits [8.0, 500.0, 364.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3088 q_vals: [-6.385, -inf, -4.558, -inf, -8.758, -6.477, -15.0]Step 1774 2 visits [8.0, 500.0, 365.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3091 q_vals: [-6.385, -inf, -4.561, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3093, "number_of_timesteps": 55929, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1775 2 visits [8.0, 500.0, 366.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3093 q_vals: [-6.385, -inf, -4.564, -inf, -8.758, -6.477, -15.0]Step 1776 2 visits [8.0, 500.0, 367.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3096 q_vals: [-6.385, -inf, -4.593, -inf, -8.758, -6.477, -15.0]Step 1777 2 visits [8.0, 500.0, 368.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3098 q_vals: [-6.385, -inf, -4.595, -inf, -8.758, -6.477, -15.0]Step 1778 2 visits [8.0, 500.0, 369.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3101 q_vals: [-6.385, -inf, -4.582, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3103, "number_of_timesteps": 56049, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1779 2 visits [8.0, 500.0, 370.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3103 q_vals: [-6.385, -inf, -4.587, -inf, -8.758, -6.477, -15.0]Step 1780 2 visits [8.0, 500.0, 371.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3105 q_vals: [-6.385, -inf, -4.575, -inf, -8.758, -6.477, -15.0]Step 1781 2 visits [8.0, 500.0, 372.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3107 q_vals: [-6.385, -inf, -4.58, -inf, -8.758, -6.477, -15.0]Step 1782 2 visits [8.0, 500.0, 373.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3110 q_vals: [-6.385, -inf, -4.585, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3113, "number_of_timesteps": 56192, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1783 2 visits [8.0, 500.0, 374.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3113 q_vals: [-6.385, -inf, -4.573, -inf, -8.758, -6.477, -15.0]Step 1784 2 visits [8.0, 500.0, 375.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3116 q_vals: [-6.385, -inf, -4.582, -inf, -8.758, -6.477, -15.0]Step 1785 2 visits [8.0, 500.0, 376.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3117 q_vals: [-6.385, -inf, -4.57, -inf, -8.758, -6.477, -15.0]Step 1786 2 visits [8.0, 500.0, 377.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3119 q_vals: [-6.385, -inf, -4.575, -inf, -8.758, -6.477, -15.0]Step 1787 2 visits [8.0, 500.0, 378.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3122 q_vals: [-6.385, -inf, -4.562, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3126, "number_of_timesteps": 56351, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1788 2 visits [8.0, 500.0, 379.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3126 q_vals: [-6.385, -inf, -4.568, -inf, -8.758, -6.477, -15.0]Step 1789 2 visits [8.0, 500.0, 380.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3127 q_vals: [-6.385, -inf, -4.571, -inf, -8.758, -6.477, -15.0]Step 1790 2 visits [8.0, 500.0, 381.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3129 q_vals: [-6.385, -inf, -4.559, -inf, -8.758, -6.477, -15.0]Step 1791 2 visits [8.0, 500.0, 382.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3133 q_vals: [-6.385, -inf, -4.561, -inf, -8.758, -6.477, -15.0]Step 1792 2 visits [8.0, 500.0, 383.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3134 q_vals: [-6.385, -inf, -4.568, -inf, -8.758, -6.477, -15.0]Step 1793 2 visits [8.0, 500.0, 384.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3135 q_vals: [-6.385, -inf, -4.595, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3138, "number_of_timesteps": 56501, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1794 2 visits [8.0, 500.0, 385.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3138 q_vals: [-6.385, -inf, -4.598, -inf, -8.758, -6.477, -15.0]Step 1795 2 visits [8.0, 500.0, 386.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3139 q_vals: [-6.385, -inf, -4.624, -inf, -8.758, -6.477, -15.0]Step 1796 2 visits [8.0, 500.0, 387.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3141 q_vals: [-6.385, -inf, -4.627, -inf, -8.758, -6.477, -15.0]Step 1797 2 visits [8.0, 500.0, 388.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3144 q_vals: [-6.385, -inf, -4.615, -inf, -8.758, -6.477, -15.0]Step 1798 2 visits [8.0, 500.0, 389.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3146 q_vals: [-6.385, -inf, -4.603, -inf, -8.758, -6.477, -15.0]Step 1799 2 visits [8.0, 500.0, 390.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3147 q_vals: [-6.385, -inf, -4.605, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3151, "number_of_timesteps": 56707, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1800 2 visits [8.0, 500.0, 391.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3151 q_vals: [-6.385, -inf, -4.594, -inf, -8.758, -6.477, -15.0]Step 1801 2 visits [8.0, 500.0, 392.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3152 q_vals: [-6.385, -inf, -4.582, -inf, -8.758, -6.477, -15.0]Step 1802 2 visits [8.0, 500.0, 393.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3153 q_vals: [-6.385, -inf, -4.586, -inf, -8.758, -6.477, -15.0]Step 1803 2 visits [8.0, 500.0, 394.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3153 q_vals: [-6.385, -inf, -4.574, -inf, -8.758, -6.477, -15.0]Step 1804 2 visits [8.0, 500.0, 395.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3156 q_vals: [-6.385, -inf, -4.583, -inf, -8.758, -6.477, -15.0]Step 1805 2 visits [8.0, 500.0, 396.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3157 q_vals: [-6.385, -inf, -4.571, -inf, -8.758, -6.477, -15.0]Step 1806 2 visits [8.0, 500.0, 397.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3157 q_vals: [-6.385, -inf, -4.597, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3161, "number_of_timesteps": 56896, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1807 2 visits [8.0, 500.0, 398.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3161 q_vals: [-6.385, -inf, -4.6, -inf, -8.758, -6.477, -15.0]Step 1808 2 visits [8.0, 500.0, 399.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3163 q_vals: [-6.385, -inf, -4.608, -inf, -8.758, -6.477, -15.0]Step 1809 2 visits [8.0, 500.0, 400.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3165 q_vals: [-6.385, -inf, -4.597, -inf, -8.758, -6.477, -15.0]Step 1810 2 visits [8.0, 500.0, 401.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3167 q_vals: [-6.385, -inf, -4.607, -inf, -8.758, -6.477, -15.0]Step 1811 2 visits [8.0, 500.0, 402.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3168 q_vals: [-6.385, -inf, -4.609, -inf, -8.758, -6.477, -15.0]Step 1812 2 visits [8.0, 500.0, 403.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3169 q_vals: [-6.385, -inf, -4.598, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3171, "number_of_timesteps": 57046, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1813 2 visits [8.0, 500.0, 404.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3171 q_vals: [-6.385, -inf, -4.604, -inf, -8.758, -6.477, -15.0]Step 1814 2 visits [8.0, 500.0, 405.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3174 q_vals: [-6.385, -inf, -4.598, -inf, -8.758, -6.477, -15.0]Step 1815 2 visits [8.0, 500.0, 406.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3176 q_vals: [-6.385, -inf, -4.6, -inf, -8.758, -6.477, -15.0]Step 1816 2 visits [8.0, 500.0, 407.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3177 q_vals: [-6.385, -inf, -4.601, -inf, -8.758, -6.477, -15.0]Step 1817 2 visits [8.0, 500.0, 408.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3178 q_vals: [-6.385, -inf, -4.603, -inf, -8.758, -6.477, -15.0]Step 1818 2 visits [8.0, 500.0, 409.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3179 q_vals: [-6.385, -inf, -4.606, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3182, "number_of_timesteps": 57264, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1819 2 visits [8.0, 500.0, 410.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3182 q_vals: [-6.385, -inf, -4.594, -inf, -8.758, -6.477, -15.0]Step 1820 2 visits [8.0, 500.0, 411.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3183 q_vals: [-6.385, -inf, -4.597, -inf, -8.758, -6.477, -15.0]Step 1821 2 visits [8.0, 500.0, 412.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3183 q_vals: [-6.385, -inf, -4.586, -inf, -8.758, -6.477, -15.0]Step 1822 2 visits [8.0, 500.0, 413.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3184 q_vals: [-6.385, -inf, -4.575, -inf, -8.758, -6.477, -15.0]Step 1823 2 visits [8.0, 500.0, 414.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3185 q_vals: [-6.385, -inf, -4.6, -inf, -8.758, -6.477, -15.0]Step 1824 2 visits [8.0, 500.0, 415.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3186 q_vals: [-6.385, -inf, -4.603, -inf, -8.758, -6.477, -15.0]Step 1825 2 visits [8.0, 500.0, 416.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3189 q_vals: [-6.385, -inf, -4.613, -inf, -8.758, -6.477, -15.0]Step 1826 2 visits [8.0, 500.0, 417.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3189 q_vals: [-6.385, -inf, -4.616, -inf, -8.758, -6.477, -15.0]Step 1827 2 visits [8.0, 500.0, 418.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3189 q_vals: [-6.385, -inf, -4.605, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3193, "number_of_timesteps": 57541, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1828 2 visits [8.0, 500.0, 419.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3193 q_vals: [-6.385, -inf, -4.607, -inf, -8.758, -6.477, -15.0]Step 1829 2 visits [8.0, 500.0, 420.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3193 q_vals: [-6.385, -inf, -4.596, -inf, -8.758, -6.477, -15.0]Step 1830 2 visits [8.0, 500.0, 421.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3195 q_vals: [-6.385, -inf, -4.585, -inf, -8.758, -6.477, -15.0]Step 1831 2 visits [8.0, 500.0, 422.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3197 q_vals: [-6.385, -inf, -4.574, -inf, -8.758, -6.477, -15.0]Step 1832 2 visits [8.0, 500.0, 423.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3198 q_vals: [-6.385, -inf, -4.577, -inf, -8.758, -6.477, -15.0]Step 1833 2 visits [8.0, 500.0, 424.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3200 q_vals: [-6.385, -inf, -4.566, -inf, -8.758, -6.477, -15.0]Step 1834 2 visits [8.0, 500.0, 425.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3200 q_vals: [-6.385, -inf, -4.567, -inf, -8.758, -6.477, -15.0]Step 1835 2 visits [8.0, 500.0, 426.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3201 q_vals: [-6.385, -inf, -4.557, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3203, "number_of_timesteps": 57768, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1836 2 visits [8.0, 500.0, 427.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3203 q_vals: [-6.385, -inf, -4.563, -inf, -8.758, -6.477, -15.0]Step 1837 2 visits [8.0, 500.0, 428.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3204 q_vals: [-6.385, -inf, -4.568, -inf, -8.758, -6.477, -15.0]Step 1838 2 visits [8.0, 500.0, 429.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3206 q_vals: [-6.385, -inf, -4.558, -inf, -8.758, -6.477, -15.0]Step 1839 2 visits [8.0, 500.0, 430.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3207 q_vals: [-6.385, -inf, -4.582, -inf, -8.758, -6.477, -15.0]Step 1840 2 visits [8.0, 500.0, 431.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3209 q_vals: [-6.385, -inf, -4.571, -inf, -8.758, -6.477, -15.0]Step 1841 2 visits [8.0, 500.0, 432.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3210 q_vals: [-6.385, -inf, -4.561, -inf, -8.758, -6.477, -15.0]Step 1842 2 visits [8.0, 500.0, 433.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3211 q_vals: [-6.385, -inf, -4.585, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3214, "number_of_timesteps": 58023, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1843 2 visits [8.0, 500.0, 434.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3214 q_vals: [-6.385, -inf, -4.587, -inf, -8.758, -6.477, -15.0]Step 1844 2 visits [8.0, 500.0, 435.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3215 q_vals: [-6.385, -inf, -4.611, -inf, -8.758, -6.477, -15.0]Step 1845 2 visits [8.0, 500.0, 436.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3216 q_vals: [-6.385, -inf, -4.6, -inf, -8.758, -6.477, -15.0]Step 1846 2 visits [8.0, 500.0, 437.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3218 q_vals: [-6.385, -inf, -4.603, -inf, -8.758, -6.477, -15.0]Step 1847 2 visits [8.0, 500.0, 438.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3219 q_vals: [-6.385, -inf, -4.593, -inf, -8.758, -6.477, -15.0]Step 1848 2 visits [8.0, 500.0, 439.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3221 q_vals: [-6.385, -inf, -4.598, -inf, -8.758, -6.477, -15.0]Step 1849 2 visits [8.0, 500.0, 440.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3221 q_vals: [-6.385, -inf, -4.6, -inf, -8.758, -6.477, -15.0]Step 1850 2 visits [8.0, 500.0, 441.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3222 q_vals: [-6.385, -inf, -4.589, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3226, "number_of_timesteps": 58277, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1851 2 visits [8.0, 500.0, 442.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3226 q_vals: [-6.385, -inf, -4.579, -inf, -8.758, -6.477, -15.0]Step 1852 2 visits [8.0, 500.0, 443.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3226 q_vals: [-6.385, -inf, -4.603, -inf, -8.758, -6.477, -15.0]Step 1853 2 visits [8.0, 500.0, 444.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3229 q_vals: [-6.385, -inf, -4.604, -inf, -8.758, -6.477, -15.0]Step 1854 2 visits [8.0, 500.0, 445.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3231 q_vals: [-6.385, -inf, -4.593, -inf, -8.758, -6.477, -15.0]Step 1855 2 visits [8.0, 500.0, 446.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3232 q_vals: [-6.385, -inf, -4.617, -inf, -8.758, -6.477, -15.0]Step 1856 2 visits [8.0, 500.0, 447.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3235 q_vals: [-6.385, -inf, -4.606, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3237, "number_of_timesteps": 58466, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1857 2 visits [8.0, 500.0, 448.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3237 q_vals: [-6.385, -inf, -4.596, -inf, -8.758, -6.477, -15.0]Step 1858 2 visits [8.0, 500.0, 449.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3237 q_vals: [-6.385, -inf, -4.6, -inf, -8.758, -6.477, -15.0]Step 1859 2 visits [8.0, 500.0, 450.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3241 q_vals: [-6.385, -inf, -4.589, -inf, -8.758, -6.477, -15.0]Step 1860 2 visits [8.0, 500.0, 451.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3241 q_vals: [-6.385, -inf, -4.59, -inf, -8.758, -6.477, -15.0]Step 1861 2 visits [8.0, 500.0, 452.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3243 q_vals: [-6.385, -inf, -4.58, -inf, -8.758, -6.477, -15.0]Step 1862 2 visits [8.0, 500.0, 453.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3244 q_vals: [-6.385, -inf, -4.585, -inf, -8.758, -6.477, -15.0]Step 1863 2 visits [8.0, 500.0, 454.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3246 q_vals: [-6.385, -inf, -4.589, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3248, "number_of_timesteps": 58656, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1864 2 visits [8.0, 500.0, 455.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3248 q_vals: [-6.385, -inf, -4.579, -inf, -8.758, -6.477, -15.0]Step 1865 2 visits [8.0, 500.0, 456.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3249 q_vals: [-6.385, -inf, -4.569, -inf, -8.758, -6.477, -15.0]Step 1866 2 visits [8.0, 500.0, 457.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3251 q_vals: [-6.385, -inf, -4.591, -inf, -8.758, -6.477, -15.0]Step 1867 2 visits [8.0, 500.0, 458.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3253 q_vals: [-6.385, -inf, -4.595, -inf, -8.758, -6.477, -15.0]Step 1868 2 visits [8.0, 500.0, 459.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3255 q_vals: [-6.385, -inf, -4.6, -inf, -8.758, -6.477, -15.0]Step 1869 2 visits [8.0, 500.0, 460.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3255 q_vals: [-6.385, -inf, -4.59, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3258, "number_of_timesteps": 58844, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1870 2 visits [8.0, 500.0, 461.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3258 q_vals: [-6.385, -inf, -4.591, -inf, -8.758, -6.477, -15.0]Step 1871 2 visits [8.0, 500.0, 462.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3260 q_vals: [-6.385, -inf, -4.614, -inf, -8.758, -6.477, -15.0]Step 1872 2 visits [8.0, 500.0, 463.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3262 q_vals: [-6.385, -inf, -4.604, -inf, -8.758, -6.477, -15.0]Step 1873 2 visits [8.0, 500.0, 464.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3264 q_vals: [-6.385, -inf, -4.605, -inf, -8.758, -6.477, -15.0]Step 1874 2 visits [8.0, 500.0, 465.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3267 q_vals: [-6.385, -inf, -4.606, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3270, "number_of_timesteps": 59050, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1875 2 visits [8.0, 500.0, 466.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3270 q_vals: [-6.385, -inf, -4.61, -inf, -8.758, -6.477, -15.0]Step 1876 2 visits [8.0, 500.0, 467.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3270 q_vals: [-6.385, -inf, -4.6, -inf, -8.758, -6.477, -15.0]Step 1877 2 visits [8.0, 500.0, 468.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3272 q_vals: [-6.385, -inf, -4.59, -inf, -8.758, -6.477, -15.0]Step 1878 2 visits [8.0, 500.0, 469.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3274 q_vals: [-6.385, -inf, -4.593, -inf, -8.758, -6.477, -15.0]Step 1879 2 visits [8.0, 500.0, 470.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3276 q_vals: [-6.385, -inf, -4.595, -inf, -8.758, -6.477, -15.0]Step 1880 2 visits [8.0, 500.0, 471.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3277 q_vals: [-6.385, -inf, -4.597, -inf, -8.758, -6.477, -15.0]Step 1881 2 visits [8.0, 500.0, 472.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3279 q_vals: [-6.385, -inf, -4.587, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3282, "number_of_timesteps": 59253, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1882 2 visits [8.0, 500.0, 473.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3282 q_vals: [-6.385, -inf, -4.577, -inf, -8.758, -6.477, -15.0]Step 1883 2 visits [8.0, 500.0, 474.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3283 q_vals: [-6.385, -inf, -4.578, -inf, -8.758, -6.477, -15.0]Step 1884 2 visits [8.0, 500.0, 475.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3287 q_vals: [-6.385, -inf, -4.58, -inf, -8.758, -6.477, -15.0]Step 1885 2 visits [8.0, 500.0, 476.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3288 q_vals: [-6.385, -inf, -4.581, -inf, -8.758, -6.477, -15.0]Step 1886 2 visits [8.0, 500.0, 477.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3290 q_vals: [-6.385, -inf, -4.603, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3295, "number_of_timesteps": 59432, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1887 2 visits [8.0, 500.0, 478.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3295 q_vals: [-6.385, -inf, -4.606, -inf, -8.758, -6.477, -15.0]Step 1888 2 visits [8.0, 500.0, 479.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3295 q_vals: [-6.385, -inf, -4.607, -inf, -8.758, -6.477, -15.0]Step 1889 2 visits [8.0, 500.0, 480.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3298 q_vals: [-6.385, -inf, -4.598, -inf, -8.758, -6.477, -15.0]Step 1890 2 visits [8.0, 500.0, 481.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3299 q_vals: [-6.385, -inf, -4.598, -inf, -8.758, -6.477, -15.0]Step 1891 2 visits [8.0, 500.0, 482.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3300 q_vals: [-6.385, -inf, -4.599, -inf, -8.758, -6.477, -15.0]Step 1892 2 visits [8.0, 500.0, 483.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3304 q_vals: [-6.385, -inf, -4.6, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3305, "number_of_timesteps": 59592, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1893 2 visits [8.0, 500.0, 484.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3305 q_vals: [-6.385, -inf, -4.604, -inf, -8.758, -6.477, -15.0]Step 1894 2 visits [8.0, 500.0, 485.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3307 q_vals: [-6.385, -inf, -4.595, -inf, -8.758, -6.477, -15.0]Step 1895 2 visits [8.0, 500.0, 486.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3310 q_vals: [-6.385, -inf, -4.598, -inf, -8.758, -6.477, -15.0]Step 1896 2 visits [8.0, 500.0, 487.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3311 q_vals: [-6.385, -inf, -4.588, -inf, -8.758, -6.477, -15.0]Step 1897 2 visits [8.0, 500.0, 488.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3313 q_vals: [-6.385, -inf, -4.61, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3317, "number_of_timesteps": 59761, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1898 2 visits [8.0, 500.0, 489.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3317 q_vals: [-6.385, -inf, -4.614, -inf, -8.758, -6.477, -15.0]Step 1899 2 visits [8.0, 500.0, 490.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3318 q_vals: [-6.385, -inf, -4.605, -inf, -8.758, -6.477, -15.0]Step 1900 2 visits [8.0, 500.0, 491.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3320 q_vals: [-6.385, -inf, -4.606, -inf, -8.758, -6.477, -15.0]Step 1901 2 visits [8.0, 500.0, 492.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3323 q_vals: [-6.385, -inf, -4.609, -inf, -8.758, -6.477, -15.0]Step 1902 2 visits [8.0, 500.0, 493.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3325 q_vals: [-6.385, -inf, -4.613, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3327, "number_of_timesteps": 59909, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1903 2 visits [8.0, 500.0, 494.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3327 q_vals: [-6.385, -inf, -4.616, -inf, -8.758, -6.477, -15.0]Step 1904 2 visits [8.0, 500.0, 495.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3329 q_vals: [-6.385, -inf, -4.607, -inf, -8.758, -6.477, -15.0]Step 1905 2 visits [8.0, 500.0, 496.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3332 q_vals: [-6.385, -inf, -4.597, -inf, -8.758, -6.477, -15.0]Step 1906 2 visits [8.0, 500.0, 497.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3334 q_vals: [-6.385, -inf, -4.588, -inf, -8.758, -6.477, -15.0]Step 1907 2 visits [8.0, 500.0, 498.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3334 q_vals: [-6.385, -inf, -4.589, -inf, -8.758, -6.477, -15.0]{"total_number_of_episodes": 3337, "number_of_timesteps": 60042, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1908 2 visits [8.0, 500.0, 499.0, 500.0, 1.0, 9.0, 1.0]  episode_count: 3337 q_vals: [-6.385, -inf, -4.58, -inf, -8.758, -6.477, -15.0]Step 1909 2 visits [0.0, 500.0, 500.0, 500.0, 0.0, 0.0, 0.0]  episode_count: 3340 q_vals: [0.0, -inf, -inf, -inf, 0.0, 0.0, 0.0]{"total_number_of_episodes": 3348, "number_of_timesteps": 60231, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 3361, "number_of_timesteps": 60384, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 3372, "number_of_timesteps": 60519, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 3382, "number_of_timesteps": 60653, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 3392, "number_of_timesteps": 60780, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 3404, "number_of_timesteps": 60942, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 3416, "number_of_timesteps": 61089, "per_episode_reward": 8.57, "episode_reward_trend_value": -0.0238095238095238, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 3428, "number_of_timesteps": 61239, "per_episode_reward": 8.5, "episode_reward_trend_value": -0.024603174603174592, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 3438, "number_of_timesteps": 61352, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.025396825396825383, "biggest_recent_change": 2.1428571428571423},
{"total_number_of_episodes": 3449, "number_of_timesteps": 61486, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 3459, "number_of_timesteps": 61621, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 3469, "number_of_timesteps": 61727, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 3480, "number_of_timesteps": 61841, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 3490, "number_of_timesteps": 61951, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 3501, "number_of_timesteps": 62068, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 3511, "number_of_timesteps": 62186, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 3523, "number_of_timesteps": 62333, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 3535, "number_of_timesteps": 62480, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3545, "number_of_timesteps": 62607, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3557, "number_of_timesteps": 62800, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3568, "number_of_timesteps": 62930, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3578, "number_of_timesteps": 63106, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3588, "number_of_timesteps": 63260, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3599, "number_of_timesteps": 63468, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3610, "number_of_timesteps": 63605, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3622, "number_of_timesteps": 63785, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3634, "number_of_timesteps": 63936, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3645, "number_of_timesteps": 64065, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3656, "number_of_timesteps": 64233, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3666, "number_of_timesteps": 64378, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3676, "number_of_timesteps": 64550, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3688, "number_of_timesteps": 64721, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3698, "number_of_timesteps": 64863, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3710, "number_of_timesteps": 65041, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3720, "number_of_timesteps": 65170, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3730, "number_of_timesteps": 65331, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3741, "number_of_timesteps": 65563, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3752, "number_of_timesteps": 65786, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3763, "number_of_timesteps": 66031, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3773, "number_of_timesteps": 66292, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3784, "number_of_timesteps": 66462, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3794, "number_of_timesteps": 66649, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3804, "number_of_timesteps": 66890, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3816, "number_of_timesteps": 67118, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3827, "number_of_timesteps": 67254, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3839, "number_of_timesteps": 67433, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3850, "number_of_timesteps": 67614, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3860, "number_of_timesteps": 67782, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3870, "number_of_timesteps": 67965, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3881, "number_of_timesteps": 68182, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3892, "number_of_timesteps": 68415, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3902, "number_of_timesteps": 68644, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3912, "number_of_timesteps": 68836, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3923, "number_of_timesteps": 69013, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3934, "number_of_timesteps": 69224, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3944, "number_of_timesteps": 69414, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3956, "number_of_timesteps": 69637, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 3967, "number_of_timesteps": 69815, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3977, "number_of_timesteps": 69964, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 3987, "number_of_timesteps": 70111, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4002, "number_of_timesteps": 70299, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4012, "number_of_timesteps": 70411, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4022, "number_of_timesteps": 70535, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4032, "number_of_timesteps": 70663, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4042, "number_of_timesteps": 70785, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 4053, "number_of_timesteps": 70919, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 4065, "number_of_timesteps": 71083, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 4076, "number_of_timesteps": 71282, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 4087, "number_of_timesteps": 71429, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 4097, "number_of_timesteps": 71560, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 4110, "number_of_timesteps": 71754, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 4122, "number_of_timesteps": 71892, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 4133, "number_of_timesteps": 72048, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 4144, "number_of_timesteps": 72214, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4154, "number_of_timesteps": 72444, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4165, "number_of_timesteps": 72672, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4176, "number_of_timesteps": 72911, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4186, "number_of_timesteps": 73064, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4197, "number_of_timesteps": 73253, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4210, "number_of_timesteps": 73455, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4222, "number_of_timesteps": 73588, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4233, "number_of_timesteps": 73716, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4245, "number_of_timesteps": 73849, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4259, "number_of_timesteps": 74021, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4270, "number_of_timesteps": 74151, "per_episode_reward": 8.21, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 4280, "number_of_timesteps": 74294, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 4291, "number_of_timesteps": 74436, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 4302, "number_of_timesteps": 74619, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 4312, "number_of_timesteps": 74748, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 4322, "number_of_timesteps": 74900, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 4333, "number_of_timesteps": 75085, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 4344, "number_of_timesteps": 75302, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 4355, "number_of_timesteps": 75507, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 4367, "number_of_timesteps": 75736, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 4377, "number_of_timesteps": 75891, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4387, "number_of_timesteps": 76012, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4398, "number_of_timesteps": 76163, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4408, "number_of_timesteps": 76331, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4418, "number_of_timesteps": 76540, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4428, "number_of_timesteps": 76683, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4442, "number_of_timesteps": 76876, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4454, "number_of_timesteps": 77017, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4464, "number_of_timesteps": 77126, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4475, "number_of_timesteps": 77260, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4485, "number_of_timesteps": 77431, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4497, "number_of_timesteps": 77614, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4508, "number_of_timesteps": 77762, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4518, "number_of_timesteps": 77931, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4528, "number_of_timesteps": 78108, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4539, "number_of_timesteps": 78320, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4549, "number_of_timesteps": 78471, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4560, "number_of_timesteps": 78647, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4570, "number_of_timesteps": 78803, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4581, "number_of_timesteps": 78998, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4591, "number_of_timesteps": 79184, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4604, "number_of_timesteps": 79456, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4614, "number_of_timesteps": 79564, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4626, "number_of_timesteps": 79715, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4637, "number_of_timesteps": 79849, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4647, "number_of_timesteps": 79994, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4657, "number_of_timesteps": 80193, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4668, "number_of_timesteps": 80477, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4679, "number_of_timesteps": 80710, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4690, "number_of_timesteps": 80953, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4703, "number_of_timesteps": 81291, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4713, "number_of_timesteps": 81515, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4724, "number_of_timesteps": 81750, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4734, "number_of_timesteps": 81947, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4745, "number_of_timesteps": 82237, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4755, "number_of_timesteps": 82423, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4765, "number_of_timesteps": 82593, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4779, "number_of_timesteps": 82887, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4789, "number_of_timesteps": 82999, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4801, "number_of_timesteps": 83176, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4812, "number_of_timesteps": 83408, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4822, "number_of_timesteps": 83586, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4832, "number_of_timesteps": 83827, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4843, "number_of_timesteps": 84002, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4853, "number_of_timesteps": 84196, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4863, "number_of_timesteps": 84347, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4874, "number_of_timesteps": 84471, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4886, "number_of_timesteps": 84627, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4897, "number_of_timesteps": 84770, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4909, "number_of_timesteps": 84915, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4919, "number_of_timesteps": 85094, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4930, "number_of_timesteps": 85283, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4941, "number_of_timesteps": 85560, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4951, "number_of_timesteps": 85863, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4961, "number_of_timesteps": 86008, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4971, "number_of_timesteps": 86167, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4981, "number_of_timesteps": 86299, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 4993, "number_of_timesteps": 86492, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5003, "number_of_timesteps": 86628, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5013, "number_of_timesteps": 86776, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5024, "number_of_timesteps": 86902, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5034, "number_of_timesteps": 87065, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5045, "number_of_timesteps": 87277, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5056, "number_of_timesteps": 87493, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 5067, "number_of_timesteps": 87714, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 5077, "number_of_timesteps": 87843, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 5089, "number_of_timesteps": 88043, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 5100, "number_of_timesteps": 88205, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 5110, "number_of_timesteps": 88349, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 5121, "number_of_timesteps": 88547, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 5131, "number_of_timesteps": 88715, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 5143, "number_of_timesteps": 88882, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 5154, "number_of_timesteps": 89066, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 5165, "number_of_timesteps": 89290, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 5175, "number_of_timesteps": 89456, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 5185, "number_of_timesteps": 89635, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 5195, "number_of_timesteps": 89817, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 5206, "number_of_timesteps": 90074, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 5217, "number_of_timesteps": 90231, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 5227, "number_of_timesteps": 90466, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 5237, "number_of_timesteps": 90666, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 5247, "number_of_timesteps": 90853, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 5257, "number_of_timesteps": 91052, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5267, "number_of_timesteps": 91259, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5277, "number_of_timesteps": 91405, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5287, "number_of_timesteps": 91571, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5299, "number_of_timesteps": 91745, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5310, "number_of_timesteps": 91897, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5320, "number_of_timesteps": 92063, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5330, "number_of_timesteps": 92322, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5340, "number_of_timesteps": 92510, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5354, "number_of_timesteps": 92743, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5367, "number_of_timesteps": 92950, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5380, "number_of_timesteps": 93156, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5390, "number_of_timesteps": 93282, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5401, "number_of_timesteps": 93487, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5411, "number_of_timesteps": 93649, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5422, "number_of_timesteps": 93809, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5432, "number_of_timesteps": 94071, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5442, "number_of_timesteps": 94286, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5452, "number_of_timesteps": 94464, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5462, "number_of_timesteps": 94630, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5473, "number_of_timesteps": 94865, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5483, "number_of_timesteps": 95007, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5496, "number_of_timesteps": 95185, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5506, "number_of_timesteps": 95323, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5516, "number_of_timesteps": 95449, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5526, "number_of_timesteps": 95626, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5536, "number_of_timesteps": 95826, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5549, "number_of_timesteps": 96103, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5559, "number_of_timesteps": 96242, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5569, "number_of_timesteps": 96433, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5579, "number_of_timesteps": 96650, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5589, "number_of_timesteps": 96909, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5599, "number_of_timesteps": 97117, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5612, "number_of_timesteps": 97387, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5623, "number_of_timesteps": 97574, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5633, "number_of_timesteps": 97788, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5644, "number_of_timesteps": 97999, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5655, "number_of_timesteps": 98225, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5668, "number_of_timesteps": 98512, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5678, "number_of_timesteps": 98675, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5689, "number_of_timesteps": 98945, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5699, "number_of_timesteps": 99199, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5709, "number_of_timesteps": 99415, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5719, "number_of_timesteps": 99588, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5730, "number_of_timesteps": 99770, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5743, "number_of_timesteps": 100055, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5755, "number_of_timesteps": 100288, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5765, "number_of_timesteps": 100482, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5775, "number_of_timesteps": 100742, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5785, "number_of_timesteps": 100922, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5797, "number_of_timesteps": 101110, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5808, "number_of_timesteps": 101264, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5820, "number_of_timesteps": 101459, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5830, "number_of_timesteps": 101613, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5840, "number_of_timesteps": 101755, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5852, "number_of_timesteps": 101898, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5862, "number_of_timesteps": 102060, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5872, "number_of_timesteps": 102271, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5883, "number_of_timesteps": 102491, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5895, "number_of_timesteps": 102743, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5905, "number_of_timesteps": 102922, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5915, "number_of_timesteps": 103195, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5925, "number_of_timesteps": 103392, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5936, "number_of_timesteps": 103604, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5946, "number_of_timesteps": 103833, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5958, "number_of_timesteps": 104125, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5968, "number_of_timesteps": 104300, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5980, "number_of_timesteps": 104538, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5991, "number_of_timesteps": 104747, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6002, "number_of_timesteps": 105031, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6014, "number_of_timesteps": 105286, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6025, "number_of_timesteps": 105469, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6035, "number_of_timesteps": 105672, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6045, "number_of_timesteps": 105821, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6057, "number_of_timesteps": 106021, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6067, "number_of_timesteps": 106247, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6077, "number_of_timesteps": 106527, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6087, "number_of_timesteps": 106689, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6097, "number_of_timesteps": 106831, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6107, "number_of_timesteps": 107032, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6118, "number_of_timesteps": 107250, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6128, "number_of_timesteps": 107469, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6138, "number_of_timesteps": 107701, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6148, "number_of_timesteps": 107957, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6158, "number_of_timesteps": 108156, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6170, "number_of_timesteps": 108369, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6180, "number_of_timesteps": 108494, "per_episode_reward": 8.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6191, "number_of_timesteps": 108649, "per_episode_reward": 8.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6202, "number_of_timesteps": 108840, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6212, "number_of_timesteps": 109072, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6222, "number_of_timesteps": 109303, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6234, "number_of_timesteps": 109573, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6245, "number_of_timesteps": 109762, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6257, "number_of_timesteps": 110010, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6268, "number_of_timesteps": 110180, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6278, "number_of_timesteps": 110340, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6288, "number_of_timesteps": 110479, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6299, "number_of_timesteps": 110623, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6310, "number_of_timesteps": 110785, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6320, "number_of_timesteps": 110927, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6331, "number_of_timesteps": 111101, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6341, "number_of_timesteps": 111292, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6352, "number_of_timesteps": 111485, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6362, "number_of_timesteps": 111700, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6372, "number_of_timesteps": 111854, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6382, "number_of_timesteps": 112037, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6395, "number_of_timesteps": 112269, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6405, "number_of_timesteps": 112463, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6416, "number_of_timesteps": 112639, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6426, "number_of_timesteps": 112908, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6436, "number_of_timesteps": 113099, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6447, "number_of_timesteps": 113269, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6457, "number_of_timesteps": 113470, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6468, "number_of_timesteps": 113711, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6478, "number_of_timesteps": 113877, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6489, "number_of_timesteps": 114148, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6501, "number_of_timesteps": 114415, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6511, "number_of_timesteps": 114668, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6523, "number_of_timesteps": 114932, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6535, "number_of_timesteps": 115154, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6546, "number_of_timesteps": 115355, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6556, "number_of_timesteps": 115518, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6566, "number_of_timesteps": 115667, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6577, "number_of_timesteps": 115909, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6588, "number_of_timesteps": 116089, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6599, "number_of_timesteps": 116291, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6611, "number_of_timesteps": 116525, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6622, "number_of_timesteps": 116706, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6632, "number_of_timesteps": 116965, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6643, "number_of_timesteps": 117171, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6653, "number_of_timesteps": 117318, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6664, "number_of_timesteps": 117483, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6675, "number_of_timesteps": 117795, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6685, "number_of_timesteps": 118014, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6696, "number_of_timesteps": 118319, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6707, "number_of_timesteps": 118504, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6719, "number_of_timesteps": 118661, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6731, "number_of_timesteps": 118807, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6741, "number_of_timesteps": 118972, "per_episode_reward": 8.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6751, "number_of_timesteps": 119229, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 6761, "number_of_timesteps": 119409, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6773, "number_of_timesteps": 119660, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6783, "number_of_timesteps": 119847, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6795, "number_of_timesteps": 120032, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6806, "number_of_timesteps": 120260, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6816, "number_of_timesteps": 120393, "per_episode_reward": 8.5, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6827, "number_of_timesteps": 120587, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6839, "number_of_timesteps": 120834, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6850, "number_of_timesteps": 121046, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6863, "number_of_timesteps": 121270, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6874, "number_of_timesteps": 121455, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6885, "number_of_timesteps": 121613, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6895, "number_of_timesteps": 121787, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6907, "number_of_timesteps": 122022, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6917, "number_of_timesteps": 122260, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 6929, "number_of_timesteps": 122449, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6939, "number_of_timesteps": 122599, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6949, "number_of_timesteps": 122760, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6959, "number_of_timesteps": 122980, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6971, "number_of_timesteps": 123328, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6981, "number_of_timesteps": 123531, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6993, "number_of_timesteps": 123759, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7003, "number_of_timesteps": 123934, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7014, "number_of_timesteps": 124126, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7024, "number_of_timesteps": 124323, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7034, "number_of_timesteps": 124516, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7044, "number_of_timesteps": 124741, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7055, "number_of_timesteps": 124919, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7066, "number_of_timesteps": 125164, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7076, "number_of_timesteps": 125410, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7087, "number_of_timesteps": 125671, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7098, "number_of_timesteps": 125851, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7108, "number_of_timesteps": 126035, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7118, "number_of_timesteps": 126181, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7128, "number_of_timesteps": 126353, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7138, "number_of_timesteps": 126494, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7148, "number_of_timesteps": 126631, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7158, "number_of_timesteps": 126769, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7170, "number_of_timesteps": 127015, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7182, "number_of_timesteps": 127197, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7193, "number_of_timesteps": 127401, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7203, "number_of_timesteps": 127592, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7214, "number_of_timesteps": 127808, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7225, "number_of_timesteps": 128038, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7236, "number_of_timesteps": 128225, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7246, "number_of_timesteps": 128415, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7256, "number_of_timesteps": 128573, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7269, "number_of_timesteps": 128887, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7282, "number_of_timesteps": 129027, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7292, "number_of_timesteps": 129135, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7305, "number_of_timesteps": 129278, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7316, "number_of_timesteps": 129421, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7326, "number_of_timesteps": 129555, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7338, "number_of_timesteps": 129693, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7348, "number_of_timesteps": 129799, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7360, "number_of_timesteps": 129929, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7370, "number_of_timesteps": 130037, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7381, "number_of_timesteps": 130161, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7394, "number_of_timesteps": 130319, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7404, "number_of_timesteps": 130465, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7414, "number_of_timesteps": 130590, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7424, "number_of_timesteps": 130714, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7437, "number_of_timesteps": 130886, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7448, "number_of_timesteps": 131062, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7459, "number_of_timesteps": 131233, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7471, "number_of_timesteps": 131471, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7481, "number_of_timesteps": 131662, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 7491, "number_of_timesteps": 131852, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7504, "number_of_timesteps": 132093, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7516, "number_of_timesteps": 132266, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7527, "number_of_timesteps": 132428, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7537, "number_of_timesteps": 132571, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7548, "number_of_timesteps": 132727, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7559, "number_of_timesteps": 132886, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7571, "number_of_timesteps": 133076, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7582, "number_of_timesteps": 133204, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7594, "number_of_timesteps": 133392, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7606, "number_of_timesteps": 133547, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7616, "number_of_timesteps": 133703, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7627, "number_of_timesteps": 133852, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7638, "number_of_timesteps": 134055, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7650, "number_of_timesteps": 134314, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7660, "number_of_timesteps": 134486, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7670, "number_of_timesteps": 134667, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7680, "number_of_timesteps": 134828, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7690, "number_of_timesteps": 134994, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7701, "number_of_timesteps": 135189, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7711, "number_of_timesteps": 135363, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7721, "number_of_timesteps": 135527, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7732, "number_of_timesteps": 135732, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7744, "number_of_timesteps": 135919, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7754, "number_of_timesteps": 136092, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7764, "number_of_timesteps": 136250, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7774, "number_of_timesteps": 136493, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7784, "number_of_timesteps": 136734, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7795, "number_of_timesteps": 136942, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7806, "number_of_timesteps": 137169, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7817, "number_of_timesteps": 137404, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7828, "number_of_timesteps": 137620, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7839, "number_of_timesteps": 137796, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7850, "number_of_timesteps": 137953, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7860, "number_of_timesteps": 138096, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7873, "number_of_timesteps": 138298, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7883, "number_of_timesteps": 138468, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7893, "number_of_timesteps": 138591, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7903, "number_of_timesteps": 138779, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7914, "number_of_timesteps": 139029, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7924, "number_of_timesteps": 139226, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7935, "number_of_timesteps": 139448, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7946, "number_of_timesteps": 139629, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7956, "number_of_timesteps": 139812, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7967, "number_of_timesteps": 139962, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7977, "number_of_timesteps": 140092, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7987, "number_of_timesteps": 140251, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7998, "number_of_timesteps": 140396, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8009, "number_of_timesteps": 140535, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8020, "number_of_timesteps": 140751, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8032, "number_of_timesteps": 141003, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8042, "number_of_timesteps": 141188, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8054, "number_of_timesteps": 141417, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8065, "number_of_timesteps": 141654, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8075, "number_of_timesteps": 141861, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8088, "number_of_timesteps": 142080, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8099, "number_of_timesteps": 142285, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8109, "number_of_timesteps": 142499, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8119, "number_of_timesteps": 142658, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8131, "number_of_timesteps": 142847, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8142, "number_of_timesteps": 143031, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8153, "number_of_timesteps": 143256, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8165, "number_of_timesteps": 143541, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8178, "number_of_timesteps": 143809, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8190, "number_of_timesteps": 143983, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8200, "number_of_timesteps": 144135, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8212, "number_of_timesteps": 144350, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8224, "number_of_timesteps": 144552, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8234, "number_of_timesteps": 144731, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8244, "number_of_timesteps": 144892, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8256, "number_of_timesteps": 145093, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8267, "number_of_timesteps": 145270, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8277, "number_of_timesteps": 145428, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8288, "number_of_timesteps": 145610, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8298, "number_of_timesteps": 145785, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8309, "number_of_timesteps": 145956, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8319, "number_of_timesteps": 146165, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8329, "number_of_timesteps": 146389, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8339, "number_of_timesteps": 146576, "per_episode_reward": 8.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8349, "number_of_timesteps": 146759, "per_episode_reward": 8.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8361, "number_of_timesteps": 146960, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8373, "number_of_timesteps": 147138, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8383, "number_of_timesteps": 147294, "per_episode_reward": 8.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8394, "number_of_timesteps": 147488, "per_episode_reward": 8.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8404, "number_of_timesteps": 147663, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8414, "number_of_timesteps": 147856, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8425, "number_of_timesteps": 148054, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8435, "number_of_timesteps": 148221, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8446, "number_of_timesteps": 148406, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8456, "number_of_timesteps": 148635, "per_episode_reward": 8.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8466, "number_of_timesteps": 148858, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8477, "number_of_timesteps": 149130, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8487, "number_of_timesteps": 149393, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8500, "number_of_timesteps": 149611, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8510, "number_of_timesteps": 149775, "per_episode_reward": 8.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8523, "number_of_timesteps": 150026, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8534, "number_of_timesteps": 150216, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8546, "number_of_timesteps": 150398, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8556, "number_of_timesteps": 150581, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8569, "number_of_timesteps": 150773, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 8579, "number_of_timesteps": 150931, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8589, "number_of_timesteps": 151117, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8602, "number_of_timesteps": 151402, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8613, "number_of_timesteps": 151612, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 8623, "number_of_timesteps": 151795, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8633, "number_of_timesteps": 151985, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8644, "number_of_timesteps": 152240, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8656, "number_of_timesteps": 152480, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8666, "number_of_timesteps": 152731, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8676, "number_of_timesteps": 152939, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8686, "number_of_timesteps": 153186, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8697, "number_of_timesteps": 153392, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8707, "number_of_timesteps": 153611, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8718, "number_of_timesteps": 153792, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8729, "number_of_timesteps": 153951, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8740, "number_of_timesteps": 154128, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8750, "number_of_timesteps": 154275, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8760, "number_of_timesteps": 154403, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8770, "number_of_timesteps": 154582, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8781, "number_of_timesteps": 154820, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8791, "number_of_timesteps": 155000, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8803, "number_of_timesteps": 155185, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8814, "number_of_timesteps": 155326, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8824, "number_of_timesteps": 155478, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8834, "number_of_timesteps": 155654, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8845, "number_of_timesteps": 155838, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8856, "number_of_timesteps": 156049, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8869, "number_of_timesteps": 156252, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8880, "number_of_timesteps": 156519, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8892, "number_of_timesteps": 156792, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8902, "number_of_timesteps": 156986, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8912, "number_of_timesteps": 157139, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8923, "number_of_timesteps": 157378, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8933, "number_of_timesteps": 157625, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8943, "number_of_timesteps": 157797, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8953, "number_of_timesteps": 157961, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8964, "number_of_timesteps": 158137, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8976, "number_of_timesteps": 158364, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8987, "number_of_timesteps": 158529, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8997, "number_of_timesteps": 158687, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9008, "number_of_timesteps": 158802, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9019, "number_of_timesteps": 158931, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9031, "number_of_timesteps": 159069, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9041, "number_of_timesteps": 159201, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9052, "number_of_timesteps": 159369, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9063, "number_of_timesteps": 159601, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9073, "number_of_timesteps": 159890, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9084, "number_of_timesteps": 160106, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9097, "number_of_timesteps": 160393, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9108, "number_of_timesteps": 160610, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9120, "number_of_timesteps": 160927, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9130, "number_of_timesteps": 161084, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9140, "number_of_timesteps": 161310, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9152, "number_of_timesteps": 161503, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9162, "number_of_timesteps": 161649, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9173, "number_of_timesteps": 161842, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9183, "number_of_timesteps": 162085, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9193, "number_of_timesteps": 162323, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9203, "number_of_timesteps": 162529, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9214, "number_of_timesteps": 162745, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9224, "number_of_timesteps": 162865, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9235, "number_of_timesteps": 163056, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9245, "number_of_timesteps": 163175, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9256, "number_of_timesteps": 163305, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9267, "number_of_timesteps": 163423, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9277, "number_of_timesteps": 163535, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9289, "number_of_timesteps": 163668, "per_episode_reward": 8.5, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9299, "number_of_timesteps": 163779, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9312, "number_of_timesteps": 163922, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9324, "number_of_timesteps": 164062, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9337, "number_of_timesteps": 164196, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9348, "number_of_timesteps": 164309, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9360, "number_of_timesteps": 164437, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9374, "number_of_timesteps": 164574, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9386, "number_of_timesteps": 164686, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9398, "number_of_timesteps": 164808, "per_episode_reward": 8.43, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9409, "number_of_timesteps": 164929, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9421, "number_of_timesteps": 165048, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9431, "number_of_timesteps": 165150, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9441, "number_of_timesteps": 165266, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9453, "number_of_timesteps": 165381, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9463, "number_of_timesteps": 165478, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9477, "number_of_timesteps": 165616, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9491, "number_of_timesteps": 165756, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9503, "number_of_timesteps": 165871, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9514, "number_of_timesteps": 165994, "per_episode_reward": 8.36, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9525, "number_of_timesteps": 166113, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9536, "number_of_timesteps": 166225, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9547, "number_of_timesteps": 166355, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9561, "number_of_timesteps": 166500, "per_episode_reward": 8.29, "episode_reward_trend_value": -0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9571, "number_of_timesteps": 166605, "per_episode_reward": 8.21, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9581, "number_of_timesteps": 166723, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9591, "number_of_timesteps": 166847, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9601, "number_of_timesteps": 167015, "per_episode_reward": 8.21, "episode_reward_trend_value": -0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9611, "number_of_timesteps": 167209, "per_episode_reward": 8.21, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9621, "number_of_timesteps": 167491, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9632, "number_of_timesteps": 167699, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9642, "number_of_timesteps": 167904, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9652, "number_of_timesteps": 168074, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9662, "number_of_timesteps": 168273, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9675, "number_of_timesteps": 168467, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9686, "number_of_timesteps": 168631, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9696, "number_of_timesteps": 168802, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9708, "number_of_timesteps": 169043, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9720, "number_of_timesteps": 169248, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9731, "number_of_timesteps": 169431, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9742, "number_of_timesteps": 169621, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9752, "number_of_timesteps": 169769, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9762, "number_of_timesteps": 169959, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9772, "number_of_timesteps": 170158, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9782, "number_of_timesteps": 170348, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9795, "number_of_timesteps": 170545, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9805, "number_of_timesteps": 170667, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9816, "number_of_timesteps": 170831, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9827, "number_of_timesteps": 170966, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9838, "number_of_timesteps": 171125, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9848, "number_of_timesteps": 171300, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 9858, "number_of_timesteps": 171427, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9868, "number_of_timesteps": 171545, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 9879, "number_of_timesteps": 171669, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9892, "number_of_timesteps": 171828, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9905, "number_of_timesteps": 172002, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9915, "number_of_timesteps": 172115, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9927, "number_of_timesteps": 172258, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 9939, "number_of_timesteps": 172400, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9951, "number_of_timesteps": 172549, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9963, "number_of_timesteps": 172700, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9973, "number_of_timesteps": 172829, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9983, "number_of_timesteps": 172960, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9993, "number_of_timesteps": 173096, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10003, "number_of_timesteps": 173284, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10013, "number_of_timesteps": 173462, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10025, "number_of_timesteps": 173736, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10035, "number_of_timesteps": 173868, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10046, "number_of_timesteps": 174025, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10056, "number_of_timesteps": 174180, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10066, "number_of_timesteps": 174360, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10079, "number_of_timesteps": 174566, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10090, "number_of_timesteps": 174741, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10101, "number_of_timesteps": 174909, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10111, "number_of_timesteps": 175059, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10121, "number_of_timesteps": 175201, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10131, "number_of_timesteps": 175441, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10141, "number_of_timesteps": 175601, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10153, "number_of_timesteps": 175825, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10165, "number_of_timesteps": 176162, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10175, "number_of_timesteps": 176371, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10188, "number_of_timesteps": 176554, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10199, "number_of_timesteps": 176730, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10209, "number_of_timesteps": 176881, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10220, "number_of_timesteps": 177056, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10231, "number_of_timesteps": 177223, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10241, "number_of_timesteps": 177368, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10253, "number_of_timesteps": 177560, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10263, "number_of_timesteps": 177704, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10275, "number_of_timesteps": 177869, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10285, "number_of_timesteps": 178002, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10295, "number_of_timesteps": 178110, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10305, "number_of_timesteps": 178226, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10318, "number_of_timesteps": 178375, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10329, "number_of_timesteps": 178568, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10341, "number_of_timesteps": 178772, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10352, "number_of_timesteps": 178936, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10362, "number_of_timesteps": 179106, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10373, "number_of_timesteps": 179285, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10383, "number_of_timesteps": 179419, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10393, "number_of_timesteps": 179594, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10406, "number_of_timesteps": 179789, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10417, "number_of_timesteps": 180016, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10427, "number_of_timesteps": 180212, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10437, "number_of_timesteps": 180452, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10448, "number_of_timesteps": 180664, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10458, "number_of_timesteps": 180846, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10469, "number_of_timesteps": 181098, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10480, "number_of_timesteps": 181334, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10491, "number_of_timesteps": 181565, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10502, "number_of_timesteps": 181714, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10512, "number_of_timesteps": 181827, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10525, "number_of_timesteps": 181983, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10537, "number_of_timesteps": 182127, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10548, "number_of_timesteps": 182292, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10558, "number_of_timesteps": 182404, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10570, "number_of_timesteps": 182588, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10580, "number_of_timesteps": 182750, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10590, "number_of_timesteps": 182918, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10600, "number_of_timesteps": 183134, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10610, "number_of_timesteps": 183362, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10621, "number_of_timesteps": 183541, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10631, "number_of_timesteps": 183743, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10641, "number_of_timesteps": 183875, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10651, "number_of_timesteps": 184033, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10661, "number_of_timesteps": 184255, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10673, "number_of_timesteps": 184493, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10683, "number_of_timesteps": 184719, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10693, "number_of_timesteps": 184868, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10704, "number_of_timesteps": 185029, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10714, "number_of_timesteps": 185181, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10724, "number_of_timesteps": 185366, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10735, "number_of_timesteps": 185592, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10748, "number_of_timesteps": 185774, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10758, "number_of_timesteps": 185936, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10768, "number_of_timesteps": 186160, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10782, "number_of_timesteps": 186534, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10794, "number_of_timesteps": 186754, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10806, "number_of_timesteps": 186948, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10816, "number_of_timesteps": 187094, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10827, "number_of_timesteps": 187297, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10839, "number_of_timesteps": 187513, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10849, "number_of_timesteps": 187681, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10861, "number_of_timesteps": 187991, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10873, "number_of_timesteps": 188183, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10883, "number_of_timesteps": 188416, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10893, "number_of_timesteps": 188640, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10906, "number_of_timesteps": 188844, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10918, "number_of_timesteps": 189069, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10928, "number_of_timesteps": 189211, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10938, "number_of_timesteps": 189434, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10948, "number_of_timesteps": 189645, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10958, "number_of_timesteps": 189863, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10968, "number_of_timesteps": 190023, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10978, "number_of_timesteps": 190158, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10988, "number_of_timesteps": 190377, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10998, "number_of_timesteps": 190619, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11008, "number_of_timesteps": 190878, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11018, "number_of_timesteps": 191042, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11029, "number_of_timesteps": 191251, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11039, "number_of_timesteps": 191442, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11050, "number_of_timesteps": 191638, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11060, "number_of_timesteps": 191819, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11071, "number_of_timesteps": 192028, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11081, "number_of_timesteps": 192281, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11093, "number_of_timesteps": 192604, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 11103, "number_of_timesteps": 192826, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11116, "number_of_timesteps": 193125, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11126, "number_of_timesteps": 193288, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11138, "number_of_timesteps": 193503, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11148, "number_of_timesteps": 193700, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11158, "number_of_timesteps": 193859, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11169, "number_of_timesteps": 194027, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11179, "number_of_timesteps": 194158, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11190, "number_of_timesteps": 194312, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11201, "number_of_timesteps": 194462, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 11213, "number_of_timesteps": 194629, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11224, "number_of_timesteps": 194797, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11235, "number_of_timesteps": 195010, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11246, "number_of_timesteps": 195257, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11256, "number_of_timesteps": 195443, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11270, "number_of_timesteps": 195742, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11281, "number_of_timesteps": 195944, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11292, "number_of_timesteps": 196129, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11302, "number_of_timesteps": 196315, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11312, "number_of_timesteps": 196495, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.14285714285714413},
{"total_number_of_episodes": 11323, "number_of_timesteps": 196759, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11333, "number_of_timesteps": 196930, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11344, "number_of_timesteps": 197122, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11355, "number_of_timesteps": 197356, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11365, "number_of_timesteps": 197553, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11375, "number_of_timesteps": 197761, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11385, "number_of_timesteps": 198004, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11395, "number_of_timesteps": 198140, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11406, "number_of_timesteps": 198314, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11420, "number_of_timesteps": 198518, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11430, "number_of_timesteps": 198638, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11440, "number_of_timesteps": 198781, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11454, "number_of_timesteps": 198955, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11465, "number_of_timesteps": 199087, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11476, "number_of_timesteps": 199232, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11486, "number_of_timesteps": 199361, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11496, "number_of_timesteps": 199487, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11507, "number_of_timesteps": 199653, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11517, "number_of_timesteps": 199847, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11528, "number_of_timesteps": 200073, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11541, "number_of_timesteps": 200269, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11551, "number_of_timesteps": 200417, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11562, "number_of_timesteps": 200572, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11572, "number_of_timesteps": 200757, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11582, "number_of_timesteps": 200920, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11592, "number_of_timesteps": 201141, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11602, "number_of_timesteps": 201279, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11612, "number_of_timesteps": 201468, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11622, "number_of_timesteps": 201625, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11634, "number_of_timesteps": 201818, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11644, "number_of_timesteps": 201974, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11655, "number_of_timesteps": 202193, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11667, "number_of_timesteps": 202376, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11678, "number_of_timesteps": 202546, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11690, "number_of_timesteps": 202792, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11701, "number_of_timesteps": 202981, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11712, "number_of_timesteps": 203265, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11723, "number_of_timesteps": 203497, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11734, "number_of_timesteps": 203808, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11744, "number_of_timesteps": 203991, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11754, "number_of_timesteps": 204126, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11764, "number_of_timesteps": 204301, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11774, "number_of_timesteps": 204486, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11785, "number_of_timesteps": 204679, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11795, "number_of_timesteps": 204856, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11805, "number_of_timesteps": 205008, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11816, "number_of_timesteps": 205220, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11826, "number_of_timesteps": 205371, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11836, "number_of_timesteps": 205527, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11846, "number_of_timesteps": 205679, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11856, "number_of_timesteps": 205842, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11867, "number_of_timesteps": 206018, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11877, "number_of_timesteps": 206237, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11888, "number_of_timesteps": 206453, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11901, "number_of_timesteps": 206675, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11913, "number_of_timesteps": 206827, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11923, "number_of_timesteps": 206960, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11933, "number_of_timesteps": 207078, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11943, "number_of_timesteps": 207238, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11954, "number_of_timesteps": 207399, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11965, "number_of_timesteps": 207557, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11978, "number_of_timesteps": 207712, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11989, "number_of_timesteps": 207847, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11999, "number_of_timesteps": 207968, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12009, "number_of_timesteps": 208110, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12021, "number_of_timesteps": 208275, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12031, "number_of_timesteps": 208394, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12041, "number_of_timesteps": 208522, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12051, "number_of_timesteps": 208637, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12062, "number_of_timesteps": 208771, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12073, "number_of_timesteps": 208926, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12083, "number_of_timesteps": 209081, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12093, "number_of_timesteps": 209249, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12103, "number_of_timesteps": 209483, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12114, "number_of_timesteps": 209708, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12125, "number_of_timesteps": 209927, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12136, "number_of_timesteps": 210108, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12147, "number_of_timesteps": 210354, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12158, "number_of_timesteps": 210659, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12168, "number_of_timesteps": 210834, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12179, "number_of_timesteps": 211034, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12189, "number_of_timesteps": 211215, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12201, "number_of_timesteps": 211407, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12214, "number_of_timesteps": 211599, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12224, "number_of_timesteps": 211727, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12235, "number_of_timesteps": 211918, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12245, "number_of_timesteps": 212096, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12256, "number_of_timesteps": 212308, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12266, "number_of_timesteps": 212493, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12276, "number_of_timesteps": 212660, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12286, "number_of_timesteps": 212836, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12299, "number_of_timesteps": 213007, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12310, "number_of_timesteps": 213147, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12321, "number_of_timesteps": 213359, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12332, "number_of_timesteps": 213673, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12345, "number_of_timesteps": 213889, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12357, "number_of_timesteps": 214069, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12367, "number_of_timesteps": 214209, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12378, "number_of_timesteps": 214448, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12388, "number_of_timesteps": 214612, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12398, "number_of_timesteps": 214770, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12410, "number_of_timesteps": 214917, "per_episode_reward": 8.21, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12420, "number_of_timesteps": 215057, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12431, "number_of_timesteps": 215194, "per_episode_reward": 8.21, "episode_reward_trend_value": -0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12442, "number_of_timesteps": 215312, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12453, "number_of_timesteps": 215433, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12464, "number_of_timesteps": 215553, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12476, "number_of_timesteps": 215704, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12487, "number_of_timesteps": 215829, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12497, "number_of_timesteps": 215949, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 12508, "number_of_timesteps": 216059, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12519, "number_of_timesteps": 216184, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12529, "number_of_timesteps": 216295, "per_episode_reward": 8.14, "episode_reward_trend_value": -0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 12541, "number_of_timesteps": 216429, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12551, "number_of_timesteps": 216540, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12561, "number_of_timesteps": 216660, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12571, "number_of_timesteps": 216774, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12583, "number_of_timesteps": 216905, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12593, "number_of_timesteps": 217023, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12603, "number_of_timesteps": 217138, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12614, "number_of_timesteps": 217266, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12628, "number_of_timesteps": 217415, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12638, "number_of_timesteps": 217546, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12648, "number_of_timesteps": 217689, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12660, "number_of_timesteps": 217851, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12670, "number_of_timesteps": 218002, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12680, "number_of_timesteps": 218203, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12690, "number_of_timesteps": 218490, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12702, "number_of_timesteps": 218761, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12712, "number_of_timesteps": 218938, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12723, "number_of_timesteps": 219106, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12736, "number_of_timesteps": 219288, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12746, "number_of_timesteps": 219408, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12756, "number_of_timesteps": 219549, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12768, "number_of_timesteps": 219700, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12779, "number_of_timesteps": 219826, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12792, "number_of_timesteps": 219968, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12802, "number_of_timesteps": 220075, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12812, "number_of_timesteps": 220199, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12822, "number_of_timesteps": 220352, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12832, "number_of_timesteps": 220505, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12843, "number_of_timesteps": 220738, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12853, "number_of_timesteps": 220935, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12865, "number_of_timesteps": 221153, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12875, "number_of_timesteps": 221411, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12886, "number_of_timesteps": 221733, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12898, "number_of_timesteps": 221990, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12908, "number_of_timesteps": 222204, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12919, "number_of_timesteps": 222383, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12929, "number_of_timesteps": 222532, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12942, "number_of_timesteps": 222776, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12952, "number_of_timesteps": 222926, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12964, "number_of_timesteps": 223147, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12974, "number_of_timesteps": 223258, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12986, "number_of_timesteps": 223405, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12996, "number_of_timesteps": 223516, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13008, "number_of_timesteps": 223638, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13018, "number_of_timesteps": 223749, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13029, "number_of_timesteps": 223879, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13039, "number_of_timesteps": 224009, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13049, "number_of_timesteps": 224143, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13060, "number_of_timesteps": 224348, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13071, "number_of_timesteps": 224528, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13081, "number_of_timesteps": 224638, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13093, "number_of_timesteps": 224815, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13106, "number_of_timesteps": 225010, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13117, "number_of_timesteps": 225180, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13127, "number_of_timesteps": 225355, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13138, "number_of_timesteps": 225522, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13148, "number_of_timesteps": 225682, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13160, "number_of_timesteps": 225885, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13171, "number_of_timesteps": 226036, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13181, "number_of_timesteps": 226168, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13192, "number_of_timesteps": 226349, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13202, "number_of_timesteps": 226471, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13213, "number_of_timesteps": 226609, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13223, "number_of_timesteps": 226739, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13233, "number_of_timesteps": 226999, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13243, "number_of_timesteps": 227262, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13255, "number_of_timesteps": 227585, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13266, "number_of_timesteps": 227834, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13276, "number_of_timesteps": 228022, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13288, "number_of_timesteps": 228253, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13298, "number_of_timesteps": 228417, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13308, "number_of_timesteps": 228578, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13318, "number_of_timesteps": 228761, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13330, "number_of_timesteps": 228983, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13340, "number_of_timesteps": 229155, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13350, "number_of_timesteps": 229363, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13360, "number_of_timesteps": 229531, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13370, "number_of_timesteps": 229696, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13380, "number_of_timesteps": 229890, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13391, "number_of_timesteps": 230141, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13403, "number_of_timesteps": 230362, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13415, "number_of_timesteps": 230555, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13425, "number_of_timesteps": 230693, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13436, "number_of_timesteps": 230884, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13447, "number_of_timesteps": 231132, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13458, "number_of_timesteps": 231330, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13469, "number_of_timesteps": 231560, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13480, "number_of_timesteps": 231778, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13490, "number_of_timesteps": 232020, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13501, "number_of_timesteps": 232247, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13511, "number_of_timesteps": 232401, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13522, "number_of_timesteps": 232572, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13533, "number_of_timesteps": 232740, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13543, "number_of_timesteps": 232911, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13553, "number_of_timesteps": 233084, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13563, "number_of_timesteps": 233238, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13573, "number_of_timesteps": 233392, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13583, "number_of_timesteps": 233533, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13594, "number_of_timesteps": 233698, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13606, "number_of_timesteps": 233860, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13618, "number_of_timesteps": 234041, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13628, "number_of_timesteps": 234270, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13638, "number_of_timesteps": 234455, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13649, "number_of_timesteps": 234776, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13661, "number_of_timesteps": 235049, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13673, "number_of_timesteps": 235247, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13684, "number_of_timesteps": 235399, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13694, "number_of_timesteps": 235554, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13705, "number_of_timesteps": 235796, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13715, "number_of_timesteps": 235995, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13726, "number_of_timesteps": 236244, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13736, "number_of_timesteps": 236433, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13746, "number_of_timesteps": 236678, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13758, "number_of_timesteps": 236862, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13769, "number_of_timesteps": 237037, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13783, "number_of_timesteps": 237287, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13793, "number_of_timesteps": 237484, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13803, "number_of_timesteps": 237645, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13815, "number_of_timesteps": 237859, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13827, "number_of_timesteps": 238051, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13837, "number_of_timesteps": 238212, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13849, "number_of_timesteps": 238418, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13863, "number_of_timesteps": 238652, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13873, "number_of_timesteps": 238808, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13883, "number_of_timesteps": 238945, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13893, "number_of_timesteps": 239057, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13903, "number_of_timesteps": 239193, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13914, "number_of_timesteps": 239332, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13924, "number_of_timesteps": 239606, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13935, "number_of_timesteps": 239836, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13945, "number_of_timesteps": 240051, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13955, "number_of_timesteps": 240256, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13966, "number_of_timesteps": 240445, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13976, "number_of_timesteps": 240689, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13986, "number_of_timesteps": 240878, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13996, "number_of_timesteps": 241055, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14007, "number_of_timesteps": 241239, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14017, "number_of_timesteps": 241445, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14028, "number_of_timesteps": 241695, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14039, "number_of_timesteps": 241926, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14051, "number_of_timesteps": 242142, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14062, "number_of_timesteps": 242452, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14073, "number_of_timesteps": 242720, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14084, "number_of_timesteps": 242970, "per_episode_reward": 8.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14094, "number_of_timesteps": 243235, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14104, "number_of_timesteps": 243515, "per_episode_reward": 8.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14114, "number_of_timesteps": 243790, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14124, "number_of_timesteps": 243963, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14134, "number_of_timesteps": 244216, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14144, "number_of_timesteps": 244459, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14156, "number_of_timesteps": 244740, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14166, "number_of_timesteps": 245024, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14177, "number_of_timesteps": 245315, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14187, "number_of_timesteps": 245506, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14197, "number_of_timesteps": 245726, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 14208, "number_of_timesteps": 245995, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14218, "number_of_timesteps": 246216, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14228, "number_of_timesteps": 246478, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14239, "number_of_timesteps": 246772, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14251, "number_of_timesteps": 247068, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14261, "number_of_timesteps": 247347, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14271, "number_of_timesteps": 247601, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14284, "number_of_timesteps": 247892, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14294, "number_of_timesteps": 248063, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14305, "number_of_timesteps": 248268, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14315, "number_of_timesteps": 248504, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14325, "number_of_timesteps": 248770, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14335, "number_of_timesteps": 249027, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14345, "number_of_timesteps": 249372, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14355, "number_of_timesteps": 249600, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14365, "number_of_timesteps": 249920, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14375, "number_of_timesteps": 250176, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14385, "number_of_timesteps": 250437, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14395, "number_of_timesteps": 250691, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14405, "number_of_timesteps": 250920, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14416, "number_of_timesteps": 251219, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14426, "number_of_timesteps": 251456, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14436, "number_of_timesteps": 251639, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14447, "number_of_timesteps": 252033, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14457, "number_of_timesteps": 252299, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14467, "number_of_timesteps": 252848, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14479, "number_of_timesteps": 253247, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14490, "number_of_timesteps": 253553, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14502, "number_of_timesteps": 253901, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14512, "number_of_timesteps": 254121, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14525, "number_of_timesteps": 254559, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14535, "number_of_timesteps": 254778, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14547, "number_of_timesteps": 255127, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14557, "number_of_timesteps": 255488, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14567, "number_of_timesteps": 255823, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14577, "number_of_timesteps": 256150, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14588, "number_of_timesteps": 256510, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14598, "number_of_timesteps": 256929, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14608, "number_of_timesteps": 257268, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14619, "number_of_timesteps": 257734, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14629, "number_of_timesteps": 258006, "per_episode_reward": 8.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14639, "number_of_timesteps": 258414, "per_episode_reward": 8.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14650, "number_of_timesteps": 258833, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14660, "number_of_timesteps": 259161, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14670, "number_of_timesteps": 259500, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14680, "number_of_timesteps": 259821, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14690, "number_of_timesteps": 260119, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14700, "number_of_timesteps": 260644, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14710, "number_of_timesteps": 261064, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14720, "number_of_timesteps": 261430, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14730, "number_of_timesteps": 261873, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 14740, "number_of_timesteps": 262264, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14750, "number_of_timesteps": 262764, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14761, "number_of_timesteps": 263226, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14771, "number_of_timesteps": 263728, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14781, "number_of_timesteps": 263967, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14794, "number_of_timesteps": 264559, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14804, "number_of_timesteps": 264866, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14816, "number_of_timesteps": 265483, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14827, "number_of_timesteps": 265913, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14837, "number_of_timesteps": 266264, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14848, "number_of_timesteps": 266599, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14858, "number_of_timesteps": 266784, "per_episode_reward": 8.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14868, "number_of_timesteps": 267060, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 14878, "number_of_timesteps": 267579, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 14888, "number_of_timesteps": 268015, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 14898, "number_of_timesteps": 268519, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 14908, "number_of_timesteps": 269376, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 14919, "number_of_timesteps": 269792, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 14929, "number_of_timesteps": 270479, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 14939, "number_of_timesteps": 271127, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 14949, "number_of_timesteps": 271798, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 14960, "number_of_timesteps": 272467, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14970, "number_of_timesteps": 273086, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14980, "number_of_timesteps": 273746, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 14990, "number_of_timesteps": 274146, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15001, "number_of_timesteps": 274742, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15012, "number_of_timesteps": 275417, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15022, "number_of_timesteps": 276245, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15032, "number_of_timesteps": 276688, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15042, "number_of_timesteps": 277384, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15052, "number_of_timesteps": 278191, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15063, "number_of_timesteps": 279194, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15073, "number_of_timesteps": 279784, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15083, "number_of_timesteps": 280923, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15093, "number_of_timesteps": 281639, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15103, "number_of_timesteps": 282498, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15114, "number_of_timesteps": 283460, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15124, "number_of_timesteps": 284251, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15135, "number_of_timesteps": 285080, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15145, "number_of_timesteps": 286456, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15155, "number_of_timesteps": 287630, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15167, "number_of_timesteps": 288810, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15177, "number_of_timesteps": 289746, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15187, "number_of_timesteps": 290991, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15197, "number_of_timesteps": 292623, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15207, "number_of_timesteps": 294040, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15217, "number_of_timesteps": 295129, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15227, "number_of_timesteps": 296550, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15238, "number_of_timesteps": 298602, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15248, "number_of_timesteps": 300118, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15259, "number_of_timesteps": 302357, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15269, "number_of_timesteps": 304752, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15279, "number_of_timesteps": 307118, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15289, "number_of_timesteps": 308817, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15299, "number_of_timesteps": 311426, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15309, "number_of_timesteps": 313384, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15319, "number_of_timesteps": 315274, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15329, "number_of_timesteps": 316846, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15339, "number_of_timesteps": 318524, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15349, "number_of_timesteps": 319534, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15359, "number_of_timesteps": 321497, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15369, "number_of_timesteps": 324298, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15379, "number_of_timesteps": 325824, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15389, "number_of_timesteps": 327537, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15399, "number_of_timesteps": 329743, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15409, "number_of_timesteps": 331383, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15419, "number_of_timesteps": 332957, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15429, "number_of_timesteps": 334351, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15439, "number_of_timesteps": 335414, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15449, "number_of_timesteps": 336163, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15460, "number_of_timesteps": 337300, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15470, "number_of_timesteps": 337890, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15480, "number_of_timesteps": 338633, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15490, "number_of_timesteps": 340327, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15500, "number_of_timesteps": 341424, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15510, "number_of_timesteps": 342415, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15522, "number_of_timesteps": 343365, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15533, "number_of_timesteps": 343633, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15543, "number_of_timesteps": 344067, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15554, "number_of_timesteps": 344423, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15565, "number_of_timesteps": 344820, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15575, "number_of_timesteps": 345107, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15585, "number_of_timesteps": 345355, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15595, "number_of_timesteps": 345714, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15605, "number_of_timesteps": 346492, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15615, "number_of_timesteps": 347841, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15625, "number_of_timesteps": 348580, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15635, "number_of_timesteps": 349579, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15645, "number_of_timesteps": 351147, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15655, "number_of_timesteps": 352744, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15665, "number_of_timesteps": 354990, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15675, "number_of_timesteps": 356448, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15685, "number_of_timesteps": 357586, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15695, "number_of_timesteps": 358635, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15705, "number_of_timesteps": 359918, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15715, "number_of_timesteps": 361745, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15725, "number_of_timesteps": 363523, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15735, "number_of_timesteps": 364946, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15745, "number_of_timesteps": 366747, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15755, "number_of_timesteps": 367999, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15765, "number_of_timesteps": 369891, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15775, "number_of_timesteps": 371548, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15785, "number_of_timesteps": 372794, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15795, "number_of_timesteps": 374081, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15805, "number_of_timesteps": 375036, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15815, "number_of_timesteps": 375899, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15825, "number_of_timesteps": 376996, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15835, "number_of_timesteps": 378510, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15845, "number_of_timesteps": 380366, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15855, "number_of_timesteps": 382243, "per_episode_reward": 8.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15866, "number_of_timesteps": 384017, "per_episode_reward": 8.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15876, "number_of_timesteps": 385360, "per_episode_reward": 8.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15886, "number_of_timesteps": 386343, "per_episode_reward": 8.79, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15896, "number_of_timesteps": 387101, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15906, "number_of_timesteps": 388194, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15916, "number_of_timesteps": 389502, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15926, "number_of_timesteps": 390963, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15937, "number_of_timesteps": 392652, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15947, "number_of_timesteps": 394298, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.003174603174603183, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15957, "number_of_timesteps": 396040, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0023809523809523924, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15967, "number_of_timesteps": 397927, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 15977, "number_of_timesteps": 399728, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 15987, "number_of_timesteps": 401614, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15997, "number_of_timesteps": 403366, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16009, "number_of_timesteps": 405521, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16019, "number_of_timesteps": 406450, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16029, "number_of_timesteps": 407387, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16040, "number_of_timesteps": 407920, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16051, "number_of_timesteps": 408423, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16061, "number_of_timesteps": 408907, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16071, "number_of_timesteps": 409673, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16081, "number_of_timesteps": 410595, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16092, "number_of_timesteps": 412312, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16102, "number_of_timesteps": 413924, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16112, "number_of_timesteps": 415199, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16123, "number_of_timesteps": 416379, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16133, "number_of_timesteps": 417816, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16143, "number_of_timesteps": 419357, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16153, "number_of_timesteps": 420600, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16163, "number_of_timesteps": 421897, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16173, "number_of_timesteps": 422999, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16184, "number_of_timesteps": 424577, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16195, "number_of_timesteps": 425969, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16205, "number_of_timesteps": 427085, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16215, "number_of_timesteps": 428206, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16226, "number_of_timesteps": 429307, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16237, "number_of_timesteps": 430593, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16247, "number_of_timesteps": 431976, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16257, "number_of_timesteps": 433433, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16267, "number_of_timesteps": 434828, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16277, "number_of_timesteps": 436183, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16287, "number_of_timesteps": 437740, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16297, "number_of_timesteps": 439072, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16308, "number_of_timesteps": 440398, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16318, "number_of_timesteps": 442788, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16328, "number_of_timesteps": 444804, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16339, "number_of_timesteps": 447752, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16349, "number_of_timesteps": 449906, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16359, "number_of_timesteps": 451806, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16369, "number_of_timesteps": 453520, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16379, "number_of_timesteps": 454855, "per_episode_reward": 8.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16389, "number_of_timesteps": 456223, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16399, "number_of_timesteps": 457903, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16409, "number_of_timesteps": 459291, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16419, "number_of_timesteps": 460155, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16429, "number_of_timesteps": 461372, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16439, "number_of_timesteps": 462808, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16449, "number_of_timesteps": 464690, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16460, "number_of_timesteps": 467207, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16471, "number_of_timesteps": 469811, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16481, "number_of_timesteps": 472577, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16491, "number_of_timesteps": 476270, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16501, "number_of_timesteps": 479489, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16512, "number_of_timesteps": 483364, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16522, "number_of_timesteps": 485030, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16533, "number_of_timesteps": 486264, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16543, "number_of_timesteps": 487660, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16553, "number_of_timesteps": 490564, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16563, "number_of_timesteps": 492910, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16573, "number_of_timesteps": 496575, "per_episode_reward": 9.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16583, "number_of_timesteps": 500963, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16593, "number_of_timesteps": 505616, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16603, "number_of_timesteps": 509517, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16613, "number_of_timesteps": 514408, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16623, "number_of_timesteps": 519214, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16633, "number_of_timesteps": 524214, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16643, "number_of_timesteps": 528542, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16654, "number_of_timesteps": 530554, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16665, "number_of_timesteps": 530972, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 16675, "number_of_timesteps": 531154, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16686, "number_of_timesteps": 531301, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16699, "number_of_timesteps": 531448, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16711, "number_of_timesteps": 531572, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16721, "number_of_timesteps": 531707, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16731, "number_of_timesteps": 531853, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16741, "number_of_timesteps": 532265, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16751, "number_of_timesteps": 533018, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16762, "number_of_timesteps": 534586, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16773, "number_of_timesteps": 535205, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16783, "number_of_timesteps": 535844, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16794, "number_of_timesteps": 536041, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16804, "number_of_timesteps": 536318, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16814, "number_of_timesteps": 536796, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16825, "number_of_timesteps": 539322, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16835, "number_of_timesteps": 540596, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16845, "number_of_timesteps": 541353, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16855, "number_of_timesteps": 542569, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16865, "number_of_timesteps": 544242, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16875, "number_of_timesteps": 545421, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16885, "number_of_timesteps": 546683, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16895, "number_of_timesteps": 548978, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16905, "number_of_timesteps": 550123, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16916, "number_of_timesteps": 552392, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16926, "number_of_timesteps": 556212, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16936, "number_of_timesteps": 559526, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16946, "number_of_timesteps": 562883, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16956, "number_of_timesteps": 564976, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16966, "number_of_timesteps": 567072, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16976, "number_of_timesteps": 569091, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16986, "number_of_timesteps": 570166, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 16997, "number_of_timesteps": 571051, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17007, "number_of_timesteps": 571488, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17020, "number_of_timesteps": 571774, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17031, "number_of_timesteps": 571999, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17041, "number_of_timesteps": 573420, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17051, "number_of_timesteps": 577133, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17061, "number_of_timesteps": 579237, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17071, "number_of_timesteps": 582621, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17081, "number_of_timesteps": 586492, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17091, "number_of_timesteps": 589252, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17101, "number_of_timesteps": 590564, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17112, "number_of_timesteps": 592938, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17122, "number_of_timesteps": 596062, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17132, "number_of_timesteps": 598745, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17142, "number_of_timesteps": 601470, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17152, "number_of_timesteps": 604404, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17163, "number_of_timesteps": 606176, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17173, "number_of_timesteps": 607624, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17183, "number_of_timesteps": 611316, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17193, "number_of_timesteps": 612431, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17203, "number_of_timesteps": 613453, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17213, "number_of_timesteps": 616320, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17223, "number_of_timesteps": 621320, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17233, "number_of_timesteps": 626320, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17243, "number_of_timesteps": 630364, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17253, "number_of_timesteps": 633277, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17263, "number_of_timesteps": 635739, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17273, "number_of_timesteps": 637181, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17283, "number_of_timesteps": 639731, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17293, "number_of_timesteps": 644731, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17303, "number_of_timesteps": 649731, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17313, "number_of_timesteps": 654731, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17323, "number_of_timesteps": 659396, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17333, "number_of_timesteps": 664396, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17343, "number_of_timesteps": 669396, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17353, "number_of_timesteps": 674396, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17363, "number_of_timesteps": 679396, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17373, "number_of_timesteps": 684396, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17383, "number_of_timesteps": 689396, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17393, "number_of_timesteps": 694189, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17403, "number_of_timesteps": 699146, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17413, "number_of_timesteps": 704146, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17423, "number_of_timesteps": 709146, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17433, "number_of_timesteps": 714146, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17443, "number_of_timesteps": 718541, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17453, "number_of_timesteps": 722938, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17463, "number_of_timesteps": 727048, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17473, "number_of_timesteps": 731259, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17483, "number_of_timesteps": 735584, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17493, "number_of_timesteps": 739436, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17503, "number_of_timesteps": 744355, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17513, "number_of_timesteps": 749355, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17523, "number_of_timesteps": 754355, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17533, "number_of_timesteps": 759355, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17543, "number_of_timesteps": 764244, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17553, "number_of_timesteps": 769244, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17563, "number_of_timesteps": 773979, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17573, "number_of_timesteps": 778979, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17583, "number_of_timesteps": 783979, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17593, "number_of_timesteps": 788979, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17603, "number_of_timesteps": 793979, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17613, "number_of_timesteps": 798979, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17623, "number_of_timesteps": 803918, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17633, "number_of_timesteps": 808419, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17643, "number_of_timesteps": 813419, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17653, "number_of_timesteps": 817966, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17663, "number_of_timesteps": 822817, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17673, "number_of_timesteps": 827817, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17683, "number_of_timesteps": 832817, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17693, "number_of_timesteps": 837389, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17703, "number_of_timesteps": 842389, "per_episode_reward": 9.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17713, "number_of_timesteps": 847389, "per_episode_reward": 9.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 17723, "number_of_timesteps": 852389, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17733, "number_of_timesteps": 857389, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17743, "number_of_timesteps": 862389, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17753, "number_of_timesteps": 867389, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17763, "number_of_timesteps": 872356, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17773, "number_of_timesteps": 877356, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17783, "number_of_timesteps": 882356, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17793, "number_of_timesteps": 887279, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17803, "number_of_timesteps": 892279, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 17813, "number_of_timesteps": 897279, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17823, "number_of_timesteps": 902279, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17833, "number_of_timesteps": 907279, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17843, "number_of_timesteps": 912279, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17853, "number_of_timesteps": 917279, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17863, "number_of_timesteps": 922279, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17873, "number_of_timesteps": 927279, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17883, "number_of_timesteps": 932279, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17894, "number_of_timesteps": 937408, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17904, "number_of_timesteps": 942408, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17915, "number_of_timesteps": 947908, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17925, "number_of_timesteps": 952908, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17936, "number_of_timesteps": 958408, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17946, "number_of_timesteps": 963187, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17956, "number_of_timesteps": 968187, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17966, "number_of_timesteps": 973187, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17976, "number_of_timesteps": 978187, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17986, "number_of_timesteps": 983187, "per_episode_reward": 9.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 17996, "number_of_timesteps": 988187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18006, "number_of_timesteps": 993187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18016, "number_of_timesteps": 998187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18026, "number_of_timesteps": 1003187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18036, "number_of_timesteps": 1008187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18046, "number_of_timesteps": 1013187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18056, "number_of_timesteps": 1018187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18066, "number_of_timesteps": 1023187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18076, "number_of_timesteps": 1028187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 18086, "number_of_timesteps": 1033187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18096, "number_of_timesteps": 1038187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18106, "number_of_timesteps": 1043187, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18116, "number_of_timesteps": 1048036, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18126, "number_of_timesteps": 1053036, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18136, "number_of_timesteps": 1058036, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18146, "number_of_timesteps": 1063036, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18156, "number_of_timesteps": 1068036, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18166, "number_of_timesteps": 1073036, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18176, "number_of_timesteps": 1078036, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18186, "number_of_timesteps": 1083036, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18196, "number_of_timesteps": 1088036, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18206, "number_of_timesteps": 1093036, "per_episode_reward": 9.43, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18216, "number_of_timesteps": 1098036, "per_episode_reward": 9.5, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18226, "number_of_timesteps": 1103036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18236, "number_of_timesteps": 1108036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18246, "number_of_timesteps": 1113036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18256, "number_of_timesteps": 1118036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18266, "number_of_timesteps": 1123036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18276, "number_of_timesteps": 1128036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18286, "number_of_timesteps": 1133036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18296, "number_of_timesteps": 1138036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18306, "number_of_timesteps": 1143036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18316, "number_of_timesteps": 1148036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18326, "number_of_timesteps": 1153036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18336, "number_of_timesteps": 1158036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18346, "number_of_timesteps": 1163036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18356, "number_of_timesteps": 1168036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18366, "number_of_timesteps": 1173036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18376, "number_of_timesteps": 1178036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18386, "number_of_timesteps": 1183036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18396, "number_of_timesteps": 1188036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18406, "number_of_timesteps": 1193036, "per_episode_reward": 9.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18416, "number_of_timesteps": 1198036, "per_episode_reward": 9.64, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18426, "number_of_timesteps": 1203036, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18436, "number_of_timesteps": 1207496, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18446, "number_of_timesteps": 1212496, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18456, "number_of_timesteps": 1217064, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18466, "number_of_timesteps": 1222064, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18476, "number_of_timesteps": 1227064, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18486, "number_of_timesteps": 1232064, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18496, "number_of_timesteps": 1237064, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18506, "number_of_timesteps": 1242064, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 18516, "number_of_timesteps": 1246671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18526, "number_of_timesteps": 1251671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18536, "number_of_timesteps": 1256671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18546, "number_of_timesteps": 1261671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18556, "number_of_timesteps": 1266671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18566, "number_of_timesteps": 1271671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18576, "number_of_timesteps": 1276671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18586, "number_of_timesteps": 1281671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18596, "number_of_timesteps": 1286671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18606, "number_of_timesteps": 1291671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18616, "number_of_timesteps": 1296671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18626, "number_of_timesteps": 1301671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18636, "number_of_timesteps": 1306671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18646, "number_of_timesteps": 1311671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18656, "number_of_timesteps": 1316671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18666, "number_of_timesteps": 1321671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18676, "number_of_timesteps": 1326671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18686, "number_of_timesteps": 1331671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18696, "number_of_timesteps": 1336671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18706, "number_of_timesteps": 1341671, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18716, "number_of_timesteps": 1346479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18726, "number_of_timesteps": 1351479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18736, "number_of_timesteps": 1356479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18746, "number_of_timesteps": 1361479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18756, "number_of_timesteps": 1366479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18766, "number_of_timesteps": 1371479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18776, "number_of_timesteps": 1376479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18786, "number_of_timesteps": 1381479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18796, "number_of_timesteps": 1386479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18806, "number_of_timesteps": 1391479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18816, "number_of_timesteps": 1396479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18826, "number_of_timesteps": 1401479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18836, "number_of_timesteps": 1406479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18846, "number_of_timesteps": 1411479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18856, "number_of_timesteps": 1416479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18866, "number_of_timesteps": 1421479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18876, "number_of_timesteps": 1426479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18886, "number_of_timesteps": 1431479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18896, "number_of_timesteps": 1436479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18906, "number_of_timesteps": 1441479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18916, "number_of_timesteps": 1446479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18926, "number_of_timesteps": 1451479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18936, "number_of_timesteps": 1456479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18946, "number_of_timesteps": 1461479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18956, "number_of_timesteps": 1466479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18966, "number_of_timesteps": 1471479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18976, "number_of_timesteps": 1476479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18986, "number_of_timesteps": 1481479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 18996, "number_of_timesteps": 1486479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19006, "number_of_timesteps": 1491479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19016, "number_of_timesteps": 1496479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19026, "number_of_timesteps": 1501479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19036, "number_of_timesteps": 1506479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19046, "number_of_timesteps": 1511479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19056, "number_of_timesteps": 1516479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19066, "number_of_timesteps": 1521479, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19076, "number_of_timesteps": 1526343, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19086, "number_of_timesteps": 1531343, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19096, "number_of_timesteps": 1536343, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19106, "number_of_timesteps": 1541343, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19116, "number_of_timesteps": 1546343, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19126, "number_of_timesteps": 1551343, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19136, "number_of_timesteps": 1556343, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19146, "number_of_timesteps": 1560905, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19156, "number_of_timesteps": 1565905, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19166, "number_of_timesteps": 1570905, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19176, "number_of_timesteps": 1575905, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19186, "number_of_timesteps": 1580905, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19196, "number_of_timesteps": 1585905, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19206, "number_of_timesteps": 1590905, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19216, "number_of_timesteps": 1595905, "per_episode_reward": 9.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19226, "number_of_timesteps": 1600905, "per_episode_reward": 9.79, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19236, "number_of_timesteps": 1605905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19246, "number_of_timesteps": 1610905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19256, "number_of_timesteps": 1615905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19266, "number_of_timesteps": 1620905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19276, "number_of_timesteps": 1625905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19286, "number_of_timesteps": 1630905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19296, "number_of_timesteps": 1635905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19306, "number_of_timesteps": 1640905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19316, "number_of_timesteps": 1645905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19326, "number_of_timesteps": 1650905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19336, "number_of_timesteps": 1655905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19346, "number_of_timesteps": 1660905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19356, "number_of_timesteps": 1665905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19366, "number_of_timesteps": 1670905, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19376, "number_of_timesteps": 1675530, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19386, "number_of_timesteps": 1680530, "per_episode_reward": 9.86, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19396, "number_of_timesteps": 1685530, "per_episode_reward": 9.93, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19406, "number_of_timesteps": 1690530, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19416, "number_of_timesteps": 1695530, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19426, "number_of_timesteps": 1700530, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19436, "number_of_timesteps": 1705530, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19446, "number_of_timesteps": 1710254, "per_episode_reward": 10.07, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19456, "number_of_timesteps": 1715254, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19466, "number_of_timesteps": 1720254, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19476, "number_of_timesteps": 1724975, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19486, "number_of_timesteps": 1729975, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19496, "number_of_timesteps": 1734975, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19506, "number_of_timesteps": 1739727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19516, "number_of_timesteps": 1744727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19526, "number_of_timesteps": 1749727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19536, "number_of_timesteps": 1754727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19546, "number_of_timesteps": 1759727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19556, "number_of_timesteps": 1764727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19566, "number_of_timesteps": 1769727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19576, "number_of_timesteps": 1774727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19586, "number_of_timesteps": 1779727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19596, "number_of_timesteps": 1784727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19606, "number_of_timesteps": 1789727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19616, "number_of_timesteps": 1794727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19626, "number_of_timesteps": 1799727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19636, "number_of_timesteps": 1804727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19646, "number_of_timesteps": 1809727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19656, "number_of_timesteps": 1814727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19666, "number_of_timesteps": 1819727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19676, "number_of_timesteps": 1824727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19686, "number_of_timesteps": 1829727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19696, "number_of_timesteps": 1834727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19706, "number_of_timesteps": 1839727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19716, "number_of_timesteps": 1844727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19726, "number_of_timesteps": 1849727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19736, "number_of_timesteps": 1854727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19746, "number_of_timesteps": 1859727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19756, "number_of_timesteps": 1864727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19766, "number_of_timesteps": 1869727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19776, "number_of_timesteps": 1874727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19786, "number_of_timesteps": 1879727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19796, "number_of_timesteps": 1884727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19806, "number_of_timesteps": 1889727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19816, "number_of_timesteps": 1894727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19826, "number_of_timesteps": 1899727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19836, "number_of_timesteps": 1904727, "per_episode_reward": 10.14, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19846, "number_of_timesteps": 1909727, "per_episode_reward": 10.21, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 19856, "number_of_timesteps": 1914727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19866, "number_of_timesteps": 1919727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19876, "number_of_timesteps": 1924727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19886, "number_of_timesteps": 1929727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19896, "number_of_timesteps": 1934727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19906, "number_of_timesteps": 1939727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19916, "number_of_timesteps": 1944727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19926, "number_of_timesteps": 1949727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0015873015873016014, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19936, "number_of_timesteps": 1954727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0007936507936508106, "biggest_recent_change": 0.07142857142857295},
{"total_number_of_episodes": 19946, "number_of_timesteps": 1959727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19956, "number_of_timesteps": 1964727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19966, "number_of_timesteps": 1969727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19976, "number_of_timesteps": 1974727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19986, "number_of_timesteps": 1979727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 19996, "number_of_timesteps": 1984727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20006, "number_of_timesteps": 1989727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20016, "number_of_timesteps": 1994727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20026, "number_of_timesteps": 1999727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20036, "number_of_timesteps": 2004727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20046, "number_of_timesteps": 2009727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20056, "number_of_timesteps": 2014727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20066, "number_of_timesteps": 2019727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20076, "number_of_timesteps": 2024727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20086, "number_of_timesteps": 2029727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20096, "number_of_timesteps": 2034727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20106, "number_of_timesteps": 2039727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20116, "number_of_timesteps": 2044727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20126, "number_of_timesteps": 2049727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20136, "number_of_timesteps": 2054727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20146, "number_of_timesteps": 2059727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20156, "number_of_timesteps": 2064727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20166, "number_of_timesteps": 2069727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20176, "number_of_timesteps": 2074727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20186, "number_of_timesteps": 2079727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20196, "number_of_timesteps": 2084727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20206, "number_of_timesteps": 2089727, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20216, "number_of_timesteps": 2094281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20226, "number_of_timesteps": 2099281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20236, "number_of_timesteps": 2104281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20246, "number_of_timesteps": 2109281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20256, "number_of_timesteps": 2114281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20266, "number_of_timesteps": 2119281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20276, "number_of_timesteps": 2124281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20286, "number_of_timesteps": 2129281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20296, "number_of_timesteps": 2134281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20306, "number_of_timesteps": 2139281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20316, "number_of_timesteps": 2144281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20326, "number_of_timesteps": 2149281, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20336, "number_of_timesteps": 2153914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20346, "number_of_timesteps": 2158914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20356, "number_of_timesteps": 2163914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20366, "number_of_timesteps": 2168914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20376, "number_of_timesteps": 2173914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20386, "number_of_timesteps": 2178914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20396, "number_of_timesteps": 2183914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20406, "number_of_timesteps": 2188914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20416, "number_of_timesteps": 2193914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20426, "number_of_timesteps": 2198914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20436, "number_of_timesteps": 2203914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20446, "number_of_timesteps": 2208914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20456, "number_of_timesteps": 2213914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20466, "number_of_timesteps": 2218914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20476, "number_of_timesteps": 2223914, "per_episode_reward": 10.29, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20486, "number_of_timesteps": 2228914, "per_episode_reward": 10.36, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20496, "number_of_timesteps": 2233914, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20506, "number_of_timesteps": 2238914, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20516, "number_of_timesteps": 2243914, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20526, "number_of_timesteps": 2248914, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20536, "number_of_timesteps": 2253914, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20546, "number_of_timesteps": 2258914, "per_episode_reward": 10.43, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20556, "number_of_timesteps": 2263914, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20566, "number_of_timesteps": 2268914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0031746031746031633, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20576, "number_of_timesteps": 2273914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0023809523809523725, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20586, "number_of_timesteps": 2278914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20596, "number_of_timesteps": 2283914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20606, "number_of_timesteps": 2288914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20616, "number_of_timesteps": 2293914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20626, "number_of_timesteps": 2298914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20636, "number_of_timesteps": 2303914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20646, "number_of_timesteps": 2308914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0007936507936507908, "biggest_recent_change": 0.07142857142857117},
{"total_number_of_episodes": 20656, "number_of_timesteps": 2313914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20666, "number_of_timesteps": 2318914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20676, "number_of_timesteps": 2323914, "per_episode_reward": 10.57, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20686, "number_of_timesteps": 2328914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20696, "number_of_timesteps": 2333914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20706, "number_of_timesteps": 2338914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20716, "number_of_timesteps": 2343914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20726, "number_of_timesteps": 2348914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20736, "number_of_timesteps": 2353914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20746, "number_of_timesteps": 2358914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20756, "number_of_timesteps": 2363914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20766, "number_of_timesteps": 2368914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0015873015873015817, "biggest_recent_change": 0.14285714285714235},
{"total_number_of_episodes": 20776, "number_of_timesteps": 2373914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20786, "number_of_timesteps": 2378914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20796, "number_of_timesteps": 2383914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20806, "number_of_timesteps": 2388914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20816, "number_of_timesteps": 2393914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20826, "number_of_timesteps": 2398914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20836, "number_of_timesteps": 2403914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20846, "number_of_timesteps": 2408914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20856, "number_of_timesteps": 2413914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20866, "number_of_timesteps": 2418914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20876, "number_of_timesteps": 2423914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20886, "number_of_timesteps": 2428914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20896, "number_of_timesteps": 2433914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20906, "number_of_timesteps": 2438914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20916, "number_of_timesteps": 2443914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20926, "number_of_timesteps": 2448914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20936, "number_of_timesteps": 2453914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20946, "number_of_timesteps": 2458914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20956, "number_of_timesteps": 2463914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
[starting run_func()]
[starting train_loop()]
exited at update_barrier.wait(): 6, error = 
None
[starting run_func()]
[starting train_loop()]
exited at update_barrier.wait(): 3, error = 
None
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
exited at all_updated_barrier.wait(): 5, error = 
None
[starting run_func()]
[starting train_loop()]
exited at all_updated_barrier.wait(): 4, error = 
None
{"total_number_of_episodes": 20966, "number_of_timesteps": 2468914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20976, "number_of_timesteps": 2473914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20986, "number_of_timesteps": 2478914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 20996, "number_of_timesteps": 2483914, "per_episode_reward": 10.71, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
exited at update_barrier.wait(): 0, error = 
None
[starting run_func()]
[starting train_loop()]
exited at all_updated_barrier.wait(): 1, error = 
None
[done calling async_.run_async()]
final_eval: {'number_of_steps': 125000, 'number_of_episodes': None, 'mean': 500.0, 'median': 500.0, 'stdev': 0.0}
logs/comparisons/cartpole__atk=none__def=ucb.log fitness_value = 10.714285714285714
