config = {
    "evaluation": {
        "enabled": True, 
        "number_of_episodes_before_eval": 130, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": 125000, 
            "number_of_episodes": None, 
        }, 
    }, 
    "verbose": True, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "expected_number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": {
        0: 0.1, 
        1: 0.08, 
        2: 0.063, 
        3: 0.05, 
        4: 0.04, 
        5: 0.032, 
        6: 0.025, 
        7: 0.02, 
        8: 0.016, 
        9: 0.012, 
        10: 0.01, 
        11: 0.008, 
        12: 0.0063, 
        13: 0.005, 
        14: 0.004, 
        15: 0.0032, 
        16: 0.0025, 
        17: 0.002, 
        18: 0.0016, 
        19: 0.0012, 
        20: 0.001, 
        21: 0.0008, 
        22: 0.00063, 
        23: 0.0005, 
        24: 0.0004, 
        25: 0.00032, 
        26: 0.00025, 
        27: 0.0002, 
        28: 0.00016, 
        29: 0.00012, 
        30: 1e-05, 
        31: 8e-06, 
        32: 6.3e-06, 
        33: 5e-06, 
        34: 4e-06, 
        35: 3.2e-06, 
        36: 2.5e-06, 
        37: 2e-06, 
        38: 1.6e-06, 
        39: 1.2e-06, 
    }, 
    "defense_method": "softmax", 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": {0: 0, }, 
    "value_trend_lookback_size": 10, 
    "env_config": {
        "permaban_threshold": 1000, 
        "env_name": "CartPole-v1", 
        "learning_rate": 0.001, 
        "beta": 2e-05, 
        "t_max": 5, 
        "activation": 1, 
        "hidden_size": 64, 
        "variance_scaling_factor": 1, 
    }, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0, 
        "min_number_of_episodes": 30, 
        "thresholds": {}, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": {0: 0, 1: 1, 2: 2, }, }, 
            "sequential_options": {
                "t_max": {0: 3, 1: 5, 2: 10, 3: 20, 4: 30, 5: 50, }, 
                "hidden_size": {0: 16, 1: 32, 2: 64, 3: 128, }, 
                "learning_rate": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
                "beta": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
                "beta": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 21000, }, 
}
args = {
    "processes": 10, 
    "env": "CartPole-v1", 
    "seed": 898071839, 
    "outdir": "results", 
    "t_max": 5, 
    "beta": 2e-05, 
    "profile": False, 
    "steps": 21000, 
    "max_frames": (108000, ), 
    "lr": 0.001, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 1000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 1, 
}
[starting outer_training_function()]
[starting middle_training_function()]
[about to call async_.run_async()]
[starting run_func()]
[starting inner_training_loop()]
[starting run_func()]
[starting inner_training_loop()]
[starting run_func()]
[starting run_func()]
[starting inner_training_loop()]
[starting inner_training_loop()]
[starting run_func()]
[starting inner_training_loop()]
[starting run_func()]
[starting inner_training_loop()]
[starting run_func()]
[starting run_func()]
[starting inner_training_loop()]
[starting inner_training_loop()]
[starting run_func()]
[starting inner_training_loop()]
[starting run_func()]
[starting inner_training_loop()]
{"step": 0, "successfully_filtered": 0, "filter_choice": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "process_temp_banned_count": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "q_vals": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
{"step": 1, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0], "q_vals": [0.0, 0.0, -1.972, 0.0, 0.0, 0.0, 0.0, 0.0, -1.739, -1.739]}
{"step": 2, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0], "q_vals": [0.0, 0.0, -3.17, 0.0, 0.0, 0.0, 0.0, 0.0, -2.794, -2.794]}
{"step": 3, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0], "q_vals": [0.0, 0.0, -4.784, 0.0, 0.0, 0.0, 0.0, 0.0, -4.218, -4.218]}
{"step": 4, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0, 5.0], "q_vals": [0.0, 0.0, -8.075, 0.0, 0.0, 0.0, 0.0, 0.0, -7.12, -7.12]}
{"step": 5, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 6.0, 6.0], "q_vals": [0.0, 0.0, -7.391, 0.0, 0.0, 0.0, 0.0, 0.0, -6.516, -6.516]}
{"step": 6, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 7.0, 1.0, 1.0, 1.0, 1.0, 1.0, 7.0, 7.0], "q_vals": [0.0, 0.0, -6.335, 0.0, 0.0, 0.0, 0.0, 0.0, -6.448, -6.448]}
{"step": 7, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 8.0, 8.0], "q_vals": [0.0, 0.0, -6.057, 0.0, 0.0, 0.0, 0.0, 0.0, -6.095, -6.095]}
{"step": 8, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 9.0, 1.0, 1.0, 1.0, 1.0, 1.0, 9.0, 9.0], "q_vals": [0.0, 0.0, -5.829, 0.0, 0.0, 0.0, 0.0, 0.0, -5.81, -5.81]}
{"step": 9, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 10.0, 1.0, 1.0, 1.0, 1.0, 1.0, 10.0, 10.0], "q_vals": [0.0, 0.0, -5.663, 0.0, 0.0, 0.0, 0.0, 0.0, -5.597, -5.597]}
{"step": 10, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 11.0, 1.0, 1.0, 1.0, 1.0, 1.0, 11.0, 11.0], "q_vals": [0.0, 0.0, -5.682, 0.0, 0.0, 0.0, 0.0, 0.0, -5.558, -5.558]}
{"step": 11, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 12.0, 1.0, 1.0, 1.0, 1.0, 1.0, 12.0, 12.0], "q_vals": [0.0, 0.0, -5.208, 0.0, 0.0, 0.0, 0.0, 0.0, -5.095, -5.095]}
{"step": 12, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 13.0, 1.0, 1.0, 1.0, 1.0, 1.0, 13.0, 13.0], "q_vals": [0.0, 0.0, -4.808, 0.0, 0.0, 0.0, 0.0, 0.0, -5.214, -5.214]}
{"step": 13, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 14.0, 1.0, 1.0, 1.0, 1.0, 1.0, 14.0, 14.0], "q_vals": [0.0, 0.0, -4.464, 0.0, 0.0, 0.0, 0.0, 0.0, -5.302, -5.302]}
{"step": 14, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 15.0, 1.0, 1.0, 1.0, 1.0, 1.0, 15.0, 15.0], "q_vals": [0.0, 0.0, -4.341, 0.0, 0.0, 0.0, 0.0, 0.0, -5.102, -5.102]}
{"step": 15, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 16.0, 1.0, 1.0, 1.0, 1.0, 1.0, 16.0, 16.0], "q_vals": [0.0, 0.0, -4.07, 0.0, 0.0, 0.0, 0.0, 0.0, -4.784, -4.784]}
{"number_of_episodes": 31, "number_of_timesteps": 672, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 16, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 17.0, 1.0, 1.0, 1.0, 1.0, 1.0, 17.0, 17.0], "q_vals": [0.0, 0.0, -3.868, 0.0, 0.0, 0.0, 0.0, 0.0, -4.535, -4.535]}
{"number_of_episodes": 35, "number_of_timesteps": 736, "per_episode_reward": 22.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 17, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 18.0, 1.0, 1.0, 1.0, 1.0, 1.0, 18.0, 18.0], "q_vals": [0.0, 0.0, -3.653, 0.0, 0.0, 0.0, 0.0, 0.0, -4.283, -4.283]}
{"number_of_episodes": 38, "number_of_timesteps": 777, "per_episode_reward": 22.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 18, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 19.0, 1.0, 1.0, 1.0, 1.0, 1.0, 19.0, 19.0], "q_vals": [0.0, 0.0, -3.461, 0.0, 0.0, 0.0, 0.0, 0.0, -4.27, -4.27]}
{"step": 19, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 20.0, 1.0, 1.0, 1.0, 1.0, 1.0, 20.0, 20.0], "q_vals": [0.0, 0.0, -3.288, 0.0, 0.0, 0.0, 0.0, 0.0, -4.056, -4.056]}
{"number_of_episodes": 42, "number_of_timesteps": 833, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 20, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 21.0, 1.0, 1.0, 1.0, 1.0, 1.0, 21.0, 21.0], "q_vals": [0.0, 0.0, -3.286, 0.0, 0.0, 0.0, 0.0, 0.0, -3.999, -3.999]}
{"number_of_episodes": 47, "number_of_timesteps": 910, "per_episode_reward": 17.8, "episode_reward_trend_value": -0.45, "biggest_recent_change": NaN},
{"step": 21, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 22.0, 1.0, 1.0, 1.0, 1.0, 1.0, 22.0, 22.0], "q_vals": [0.0, 0.0, -3.137, 0.0, 0.0, 0.0, 0.0, 0.0, -3.818, -3.818]}
{"step": 22, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 23.0, 1.0, 1.0, 1.0, 1.0, 1.0, 23.0, 23.0], "q_vals": [0.0, 0.0, -3.0, 0.0, 0.0, 0.0, 0.0, 0.0, -3.674, -3.674]}
{"number_of_episodes": 50, "number_of_timesteps": 978, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.4800000000000001, "biggest_recent_change": NaN},
{"step": 23, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 24.0, 1.0, 1.0, 1.0, 1.0, 1.0, 24.0, 24.0], "q_vals": [0.0, 0.0, -3.039, 0.0, 0.0, 0.0, 0.0, 0.0, -3.666, -3.666]}
{"number_of_episodes": 54, "number_of_timesteps": 1039, "per_episode_reward": 17.8, "episode_reward_trend_value": -0.41999999999999993, "biggest_recent_change": NaN},
{"step": 24, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 25.0, 1.0, 1.0, 1.0, 1.0, 1.0, 25.0, 25.0], "q_vals": [0.0, 0.0, -2.917, 0.0, 0.0, 0.0, 0.0, 0.0, -3.778, -3.778]}
{"number_of_episodes": 55, "number_of_timesteps": 1057, "per_episode_reward": 17.75, "episode_reward_trend_value": -0.15500000000000008, "biggest_recent_change": NaN},
{"step": 25, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 26.0, 1.0, 1.0, 1.0, 1.0, 1.0, 26.0, 26.0], "q_vals": [0.0, 0.0, -2.981, 0.0, 0.0, 0.0, 0.0, 0.0, -3.788, -3.788]}
{"number_of_episodes": 58, "number_of_timesteps": 1092, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 26, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 27.0, 1.0, 1.0, 1.0, 1.0, 1.0, 27.0, 27.0], "q_vals": [0.0, 0.0, -3.02, 0.0, 0.0, 0.0, 0.0, 0.0, -3.779, -3.779]}
{"number_of_episodes": 59, "number_of_timesteps": 1111, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 27, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 28.0, 1.0, 1.0, 1.0, 1.0, 1.0, 28.0, 28.0], "q_vals": [0.0, 0.0, -3.398, 0.0, 0.0, 0.0, 0.0, 0.0, -4.072, -4.072]}
{"step": 28, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 29.0, 1.0, 1.0, 1.0, 1.0, 1.0, 29.0, 29.0], "q_vals": [0.0, 0.0, -3.49, 0.0, 0.0, 0.0, 0.0, 0.0, -4.116, -4.116]}
{"number_of_episodes": 63, "number_of_timesteps": 1177, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.24749999999999997, "biggest_recent_change": NaN},
{"step": 29, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 30.0, 1.0, 1.0, 1.0, 1.0, 1.0, 30.0, 30.0], "q_vals": [0.0, 0.0, -3.374, 0.0, 0.0, 0.0, 0.0, 0.0, -3.979, -3.979]}
{"step": 30, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 31.0, 1.0, 1.0, 1.0, 1.0, 1.0, 31.0, 31.0], "q_vals": [0.0, 0.0, -3.592, 0.0, 0.0, 0.0, 0.0, 0.0, -4.139, -4.139]}
{"number_of_episodes": 68, "number_of_timesteps": 1342, "per_episode_reward": 18.85, "episode_reward_trend_value": -0.19749999999999995, "biggest_recent_change": NaN},
{"step": 31, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 32.0, 1.0, 1.0, 1.0, 1.0, 1.0, 32.0, 32.0], "q_vals": [0.0, 0.0, -3.59, 0.0, 0.0, 0.0, 0.0, 0.0, -4.107, -4.107]}
{"step": 32, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 33.0, 1.0, 1.0, 1.0, 1.0, 1.0, 33.0, 33.0], "q_vals": [0.0, 0.0, -3.481, 0.0, 0.0, 0.0, 0.0, 0.0, -3.982, -3.982]}
{"number_of_episodes": 77, "number_of_timesteps": 1485, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 33, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 34.0, 1.0, 1.0, 1.0, 1.0, 1.0, 34.0, 34.0], "q_vals": [0.0, 0.0, -3.378, 0.0, 0.0, 0.0, 0.0, 0.0, -3.865, -3.865]}
{"number_of_episodes": 78, "number_of_timesteps": 1496, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 34, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 35.0, 1.0, 1.0, 1.0, 1.0, 1.0, 35.0, 35.0], "q_vals": [0.0, 0.0, -3.62, 0.0, 0.0, 0.0, 0.0, 0.0, -4.053, -4.053]}
{"step": 35, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 36.0, 1.0, 1.0, 1.0, 1.0, 1.0, 36.0, 36.0], "q_vals": [0.0, 0.0, -3.899, 0.0, 0.0, 0.0, 0.0, 0.0, -4.275, -4.275]}
{"number_of_episodes": 82, "number_of_timesteps": 1549, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 36, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 37.0, 1.0, 1.0, 1.0, 1.0, 1.0, 37.0, 37.0], "q_vals": [0.0, 0.0, -3.886, 0.0, 0.0, 0.0, 0.0, 0.0, -4.241, -4.241]}
{"step": 37, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 38.0, 1.0, 1.0, 1.0, 1.0, 1.0, 38.0, 38.0], "q_vals": [0.0, 0.0, -3.914, 0.0, 0.0, 0.0, 0.0, 0.0, -4.244, -4.244]}
{"step": 38, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 39.0, 1.0, 1.0, 1.0, 1.0, 1.0, 39.0, 39.0], "q_vals": [0.0, 0.0, -4.249, 0.0, 0.0, 0.0, 0.0, 0.0, -4.519, -4.519]}
{"number_of_episodes": 88, "number_of_timesteps": 1665, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.10500000000000007, "biggest_recent_change": NaN},
{"step": 39, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 40.0, 40.0], "q_vals": [0.0, 0.0, -4.278, 0.0, 0.0, 0.0, 0.0, 0.0, -4.525, -4.525]}
{"number_of_episodes": 92, "number_of_timesteps": 1724, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.08499999999999978, "biggest_recent_change": NaN},
{"step": 40, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 41.0, 1.0, 1.0, 1.0, 1.0, 1.0, 41.0, 41.0], "q_vals": [0.0, 0.0, -4.278, 0.0, 0.0, 0.0, 0.0, 0.0, -4.506, -4.506]}
{"number_of_episodes": 93, "number_of_timesteps": 1763, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.21333333333333343, "biggest_recent_change": NaN},
{"step": 41, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 42.0, 1.0, 1.0, 1.0, 1.0, 1.0, 42.0, 42.0], "q_vals": [0.0, 0.0, -4.316, 0.0, 0.0, 0.0, 0.0, 0.0, -4.522, -4.522]}
{"number_of_episodes": 97, "number_of_timesteps": 1839, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.2800000000000001, "biggest_recent_change": NaN},
{"step": 42, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 43.0, 1.0, 1.0, 1.0, 1.0, 1.0, 43.0, 43.0], "q_vals": [0.0, 0.0, -4.215, 0.0, 0.0, 0.0, 0.0, 0.0, -4.5, -4.5]}
{"number_of_episodes": 99, "number_of_timesteps": 1880, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.0375, "biggest_recent_change": NaN},
{"step": 43, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 44.0, 1.0, 1.0, 1.0, 1.0, 1.0, 44.0, 44.0], "q_vals": [0.0, 0.0, -4.238, 0.0, 0.0, 0.0, 0.0, 0.0, -4.502, -4.502]}
{"step": 44, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 45.0, 1.0, 1.0, 1.0, 1.0, 1.0, 45.0, 45.0], "q_vals": [0.0, 0.0, -4.26, 0.0, 0.0, 0.0, 0.0, 0.0, -4.505, -4.505]}
{"step": 45, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 46.0, 1.0, 1.0, 1.0, 1.0, 1.0, 46.0, 46.0], "q_vals": [0.0, 0.0, -4.168, 0.0, 0.0, 0.0, 0.0, 0.0, -4.487, -4.487]}
{"number_of_episodes": 107, "number_of_timesteps": 1999, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.1349999999999998, "biggest_recent_change": NaN},
{"step": 46, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 47.0, 1.0, 1.0, 1.0, 1.0, 1.0, 47.0, 47.0], "q_vals": [0.0, 0.0, -4.079, 0.0, 0.0, 0.0, 0.0, 0.0, -4.392, -4.392]}
{"number_of_episodes": 111, "number_of_timesteps": 2057, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.20166666666666672, "biggest_recent_change": NaN},
{"step": 47, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 48.0, 1.0, 1.0, 1.0, 1.0, 1.0, 48.0, 48.0], "q_vals": [0.0, 0.0, -3.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.39, -4.39]}
{"number_of_episodes": 112, "number_of_timesteps": 2067, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.075, "biggest_recent_change": NaN},
{"step": 48, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 49.0, 1.0, 1.0, 1.0, 1.0, 1.0, 49.0, 49.0], "q_vals": [0.0, 0.0, -4.052, 0.0, 0.0, 0.0, 0.0, 0.0, -4.424, -4.424]}
{"number_of_episodes": 112, "number_of_timesteps": 2067, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.16000000000000014, "biggest_recent_change": NaN},
{"step": 49, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 50.0, 1.0, 1.0, 1.0, 1.0, 1.0, 50.0, 50.0], "q_vals": [0.0, 0.0, -4.072, 0.0, 0.0, 0.0, 0.0, 0.0, -4.424, -4.424]}
{"number_of_episodes": 119, "number_of_timesteps": 2197, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.2200000000000001, "biggest_recent_change": NaN},
{"step": 50, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 51.0, 1.0, 1.0, 1.0, 1.0, 1.0, 51.0, 51.0], "q_vals": [0.0, 0.0, -4.186, 0.0, 0.0, 0.0, 0.0, 0.0, -4.508, -4.508]}
{"number_of_episodes": 121, "number_of_timesteps": 2235, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.09499999999999993, "biggest_recent_change": NaN},
{"step": 51, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 52.0, 1.0, 1.0, 1.0, 1.0, 1.0, 52.0, 52.0], "q_vals": [0.0, 0.0, -4.105, 0.0, 0.0, 0.0, 0.0, 0.0, -4.422, -4.422]}
{"step": 52, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 53.0, 1.0, 1.0, 1.0, 1.0, 1.0, 53.0, 53.0], "q_vals": [0.0, 0.0, -4.028, 0.0, 0.0, 0.0, 0.0, 0.0, -4.338, -4.338]}
{"step": 53, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 54.0, 1.0, 1.0, 1.0, 1.0, 1.0, 54.0, 54.0], "q_vals": [0.0, 0.0, -4.145, 0.0, 0.0, 0.0, 0.0, 0.0, -4.427, -4.427]}
{"step": 54, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 55.0, 1.0, 1.0, 1.0, 1.0, 1.0, 55.0, 55.0], "q_vals": [0.0, 0.0, -4.377, 0.0, 0.0, 0.0, 0.0, 0.0, -4.617, -4.617]}
{"number_of_episodes": 127, "number_of_timesteps": 2364, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.04499999999999999, "biggest_recent_change": NaN},
{"step": 55, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 56.0, 1.0, 1.0, 1.0, 1.0, 1.0, 56.0, 56.0], "q_vals": [0.0, 0.0, -4.392, 0.0, 0.0, 0.0, 0.0, 0.0, -4.617, -4.617]}
{"eval_score": 16.9, "number_of_episodes": 130}
{"number_of_episodes": 130, "number_of_timesteps": 2437, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.04833333333333331, "biggest_recent_change": NaN},
{"step": 56, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 57.0, 1.0, 1.0, 1.0, 1.0, 1.0, 57.0, 57.0], "q_vals": [0.0, 0.0, -4.416, 0.0, 0.0, 0.0, 0.0, 0.0, -4.625, -4.625]}
{"number_of_episodes": 132, "number_of_timesteps": 2485, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.16875, "biggest_recent_change": NaN},
{"step": 57, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 58.0, 1.0, 1.0, 1.0, 1.0, 1.0, 58.0, 58.0], "q_vals": [0.0, 0.0, -4.443, 0.0, 0.0, 0.0, 0.0, 0.0, -4.636, -4.636]}
{"number_of_episodes": 132, "number_of_timesteps": 2485, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.04499999999999993, "biggest_recent_change": NaN},
{"step": 58, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 59.0, 1.0, 1.0, 1.0, 1.0, 1.0, 59.0, 59.0], "q_vals": [0.0, 0.0, -4.368, 0.0, 0.0, 0.0, 0.0, 0.0, -4.558, -4.558]}
{"step": 59, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 60.0, 1.0, 1.0, 1.0, 1.0, 1.0, 60.0, 60.0], "q_vals": [0.0, 0.0, -4.381, 0.0, 0.0, 0.0, 0.0, 0.0, -4.557, -4.557]}
{"number_of_episodes": 137, "number_of_timesteps": 2571, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.022499999999999964, "biggest_recent_change": NaN},
{"step": 60, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 61.0, 1.0, 1.0, 1.0, 1.0, 1.0, 61.0, 61.0], "q_vals": [0.0, 0.0, -4.408, 0.0, 0.0, 0.0, 0.0, 0.0, -4.57, -4.57]}
{"number_of_episodes": 140, "number_of_timesteps": 2643, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.13875, "biggest_recent_change": NaN},
{"step": 61, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 62.0, 1.0, 1.0, 1.0, 1.0, 1.0, 62.0, 62.0], "q_vals": [0.0, 0.0, -4.336, 0.0, 0.0, 0.0, 0.0, 0.0, -4.552, -4.552]}
{"number_of_episodes": 143, "number_of_timesteps": 2741, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.06500000000000003, "biggest_recent_change": NaN},
{"step": 62, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 63.0, 1.0, 1.0, 1.0, 1.0, 1.0, 63.0, 63.0], "q_vals": [0.0, 0.0, -4.422, 0.0, 0.0, 0.0, 0.0, 0.0, -4.616, -4.616]}
{"number_of_episodes": 144, "number_of_timesteps": 2758, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.15, "biggest_recent_change": NaN},
{"step": 63, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 64.0, 1.0, 1.0, 1.0, 1.0, 1.0, 64.0, 64.0], "q_vals": [0.0, 0.0, -4.432, 0.0, 0.0, 0.0, 0.0, 0.0, -4.614, -4.614]}
{"number_of_episodes": 145, "number_of_timesteps": 2769, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.027499999999999948, "biggest_recent_change": NaN},
{"step": 64, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 65.0, 1.0, 1.0, 1.0, 1.0, 1.0, 65.0, 65.0], "q_vals": [0.0, 0.0, -4.364, 0.0, 0.0, 0.0, 0.0, 0.0, -4.543, -4.543]}
{"number_of_episodes": 146, "number_of_timesteps": 2783, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.131, "biggest_recent_change": NaN},
{"step": 65, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 66.0, 1.0, 1.0, 1.0, 1.0, 1.0, 66.0, 66.0], "q_vals": [0.0, 0.0, -4.372, 0.0, 0.0, 0.0, 0.0, 0.0, -4.539, -4.539]}
{"step": 66, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 67.0, 1.0, 1.0, 1.0, 1.0, 1.0, 67.0, 67.0], "q_vals": [0.0, 0.0, -4.371, 0.0, 0.0, 0.0, 0.0, 0.0, -4.528, -4.528]}
{"number_of_episodes": 149, "number_of_timesteps": 2856, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 67, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 68.0, 1.0, 1.0, 1.0, 1.0, 1.0, 68.0, 68.0], "q_vals": [0.0, 0.0, -4.307, 0.0, 0.0, 0.0, 0.0, 0.0, -4.462, -4.462]}
{"number_of_episodes": 153, "number_of_timesteps": 2977, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.008999999999999985, "biggest_recent_change": NaN},
{"step": 68, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 69.0, 1.0, 1.0, 1.0, 1.0, 1.0, 69.0, 69.0], "q_vals": [0.0, 0.0, -4.304, 0.0, 0.0, 0.0, 0.0, 0.0, -4.45, -4.45]}
{"number_of_episodes": 157, "number_of_timesteps": 3082, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.08333333333333334, "biggest_recent_change": NaN},
{"step": 69, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 70.0, 1.0, 1.0, 1.0, 1.0, 1.0, 70.0, 70.0], "q_vals": [0.0, 0.0, -4.3, 0.0, 0.0, 0.0, 0.0, 0.0, -4.437, -4.437]}
{"step": 70, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 71.0, 1.0, 1.0, 1.0, 1.0, 1.0, 71.0, 71.0], "q_vals": [0.0, 0.0, -4.309, 0.0, 0.0, 0.0, 0.0, 0.0, -4.435, -4.435]}
{"step": 71, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 72.0, 1.0, 1.0, 1.0, 1.0, 1.0, 72.0, 72.0], "q_vals": [0.0, 0.0, -4.281, 0.0, 0.0, 0.0, 0.0, 0.0, -4.402, -4.402]}
{"number_of_episodes": 165, "number_of_timesteps": 3215, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.030000000000000072, "biggest_recent_change": NaN},
{"step": 72, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 73.0, 1.0, 1.0, 1.0, 1.0, 1.0, 73.0, 73.0], "q_vals": [0.0, 0.0, -4.439, 0.0, 0.0, 0.0, 0.0, 0.0, -4.532, -4.532]}
{"step": 73, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 74.0, 1.0, 1.0, 1.0, 1.0, 1.0, 74.0, 74.0], "q_vals": [0.0, 0.0, -4.536, 0.0, 0.0, 0.0, 0.0, 0.0, -4.61, -4.61]}
{"number_of_episodes": 167, "number_of_timesteps": 3251, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.005000000000000071, "biggest_recent_change": NaN},
{"step": 74, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 75.0, 1.0, 1.0, 1.0, 1.0, 1.0, 75.0, 75.0], "q_vals": [0.0, 0.0, -4.476, 0.0, 0.0, 0.0, 0.0, 0.0, -4.548, -4.548]}
{"number_of_episodes": 168, "number_of_timesteps": 3277, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.10166666666666668, "biggest_recent_change": NaN},
{"step": 75, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 76.0, 1.0, 1.0, 1.0, 1.0, 1.0, 76.0, 76.0], "q_vals": [0.0, 0.0, -4.477, 0.0, 0.0, 0.0, 0.0, 0.0, -4.542, -4.542]}
{"number_of_episodes": 172, "number_of_timesteps": 3369, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.021250000000000036, "biggest_recent_change": NaN},
{"step": 76, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 77.0, 1.0, 1.0, 1.0, 1.0, 1.0, 77.0, 77.0], "q_vals": [0.0, 0.0, -4.485, 0.0, 0.0, 0.0, 0.0, 0.0, -4.541, -4.541]}
{"step": 77, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 78.0, 1.0, 1.0, 1.0, 1.0, 1.0, 78.0, 78.0], "q_vals": [0.0, 0.0, -4.427, 0.0, 0.0, 0.0, 0.0, 0.0, -4.482, -4.482]}
{"number_of_episodes": 176, "number_of_timesteps": 3448, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.10600000000000001, "biggest_recent_change": NaN},
{"step": 78, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 79.0, 1.0, 1.0, 1.0, 1.0, 1.0, 79.0, 79.0], "q_vals": [0.0, 0.0, -4.371, 0.0, 0.0, 0.0, 0.0, 0.0, -4.506, -4.506]}
{"number_of_episodes": 178, "number_of_timesteps": 3474, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.06749999999999998, "biggest_recent_change": NaN},
{"step": 79, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 80.0, 1.0, 1.0, 1.0, 1.0, 1.0, 80.0, 80.0], "q_vals": [0.0, 0.0, -4.394, 0.0, 0.0, 0.0, 0.0, 0.0, -4.518, -4.518]}
{"step": 80, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 81.0, 1.0, 1.0, 1.0, 1.0, 1.0, 81.0, 81.0], "q_vals": [0.0, 0.0, -4.399, 0.0, 0.0, 0.0, 0.0, 0.0, -4.515, -4.515]}
{"number_of_episodes": 184, "number_of_timesteps": 3581, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.02000000000000005, "biggest_recent_change": NaN},
{"step": 81, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 82.0, 1.0, 1.0, 1.0, 1.0, 1.0, 82.0, 82.0], "q_vals": [0.0, 0.0, -4.534, 0.0, 0.0, 0.0, 0.0, 0.0, -4.626, -4.626]}
{"number_of_episodes": 186, "number_of_timesteps": 3617, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.1866666666666667, "biggest_recent_change": NaN},
{"step": 82, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 83.0, 1.0, 1.0, 1.0, 1.0, 1.0, 83.0, 83.0], "q_vals": [0.0, 0.0, -4.479, 0.0, 0.0, 0.0, 0.0, 0.0, -4.57, -4.57]}
{"number_of_episodes": 187, "number_of_timesteps": 3628, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.036666666666666715, "biggest_recent_change": NaN},
{"step": 83, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 84.0, 1.0, 1.0, 1.0, 1.0, 1.0, 84.0, 84.0], "q_vals": [0.0, 0.0, -4.542, 0.0, 0.0, 0.0, 0.0, 0.0, -4.618, -4.618]}
{"number_of_episodes": 190, "number_of_timesteps": 3691, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.007499999999999929, "biggest_recent_change": NaN},
{"step": 84, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 85.0, 1.0, 1.0, 1.0, 1.0, 1.0, 85.0, 85.0], "q_vals": [0.0, 0.0, -4.488, 0.0, 0.0, 0.0, 0.0, 0.0, -4.563, -4.563]}
{"number_of_episodes": 194, "number_of_timesteps": 3797, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.022500000000000055, "biggest_recent_change": NaN},
{"step": 85, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 86.0, 1.0, 1.0, 1.0, 1.0, 1.0, 86.0, 86.0], "q_vals": [0.0, 0.0, -4.648, 0.0, 0.0, 0.0, 0.0, 0.0, -4.697, -4.697]}
{"number_of_episodes": 194, "number_of_timesteps": 3797, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.05800000000000004, "biggest_recent_change": NaN},
{"step": 86, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 87.0, 1.0, 1.0, 1.0, 1.0, 1.0, 87.0, 87.0], "q_vals": [0.0, 0.0, -4.65, 0.0, 0.0, 0.0, 0.0, 0.0, -4.692, -4.692]}
{"number_of_episodes": 197, "number_of_timesteps": 3836, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.03125, "biggest_recent_change": NaN},
{"step": 87, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 88.0, 1.0, 1.0, 1.0, 1.0, 1.0, 88.0, 88.0], "q_vals": [0.0, 0.0, -4.766, 0.0, 0.0, 0.0, 0.0, 0.0, -4.788, -4.788]}
{"step": 88, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 89.0, 1.0, 1.0, 1.0, 1.0, 1.0, 89.0, 89.0], "q_vals": [0.0, 0.0, -4.83, 0.0, 0.0, 0.0, 0.0, 0.0, -4.837, -4.837]}
{"step": 89, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 90.0, 1.0, 1.0, 1.0, 1.0, 1.0, 90.0, 90.0], "q_vals": [0.0, 0.0, -5.006, 0.0, 0.0, 0.0, 0.0, 0.0, -4.986, -4.986]}
{"number_of_episodes": 205, "number_of_timesteps": 4021, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.1375, "biggest_recent_change": NaN},
{"step": 90, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 91.0, 1.0, 1.0, 1.0, 1.0, 1.0, 91.0, 91.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.932, -4.932]}
{"number_of_episodes": 207, "number_of_timesteps": 4056, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.016000000000000014, "biggest_recent_change": NaN},
{"step": 91, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 92.0, 1.0, 1.0, 1.0, 1.0, 1.0, 92.0, 92.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.925, -4.925]}
{"number_of_episodes": 209, "number_of_timesteps": 4078, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.02, "biggest_recent_change": NaN},
{"step": 92, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 93.0, 1.0, 1.0, 1.0, 1.0, 1.0, 93.0, 93.0], "q_vals": [0.0, 0.0, -5.014, 0.0, 0.0, 0.0, 0.0, 0.0, -4.975, -4.975]}
{"step": 93, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 94.0, 1.0, 1.0, 1.0, 1.0, 1.0, 94.0, 94.0], "q_vals": [0.0, 0.0, -5.015, 0.0, 0.0, 0.0, 0.0, 0.0, -4.969, -4.969]}
{"number_of_episodes": 213, "number_of_timesteps": 4155, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.011000000000000013, "biggest_recent_change": NaN},
{"step": 94, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 95.0, 1.0, 1.0, 1.0, 1.0, 1.0, 95.0, 95.0], "q_vals": [0.0, 0.0, -5.069, 0.0, 0.0, 0.0, 0.0, 0.0, -5.011, -5.011]}
{"step": 95, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 96.0, 1.0, 1.0, 1.0, 1.0, 1.0, 96.0, 96.0], "q_vals": [0.0, 0.0, -5.137, 0.0, 0.0, 0.0, 0.0, 0.0, -5.066, -5.066]}
{"number_of_episodes": 218, "number_of_timesteps": 4258, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.11100000000000002, "biggest_recent_change": NaN},
{"step": 96, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 97.0, 1.0, 1.0, 1.0, 1.0, 1.0, 97.0, 97.0], "q_vals": [0.0, 0.0, -5.084, 0.0, 0.0, 0.0, 0.0, 0.0, -5.013, -5.013]}
{"number_of_episodes": 222, "number_of_timesteps": 4308, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.01583333333333332, "biggest_recent_change": NaN},
{"step": 97, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 98.0, 1.0, 1.0, 1.0, 1.0, 1.0, 98.0, 98.0], "q_vals": [0.0, 0.0, -5.079, 0.0, 0.0, 0.0, 0.0, 0.0, -5.004, -5.004]}
{"number_of_episodes": 224, "number_of_timesteps": 4351, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.08785714285714288, "biggest_recent_change": NaN},
{"step": 98, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 99.0, 1.0, 1.0, 1.0, 1.0, 1.0, 99.0, 99.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.988, -4.988]}
{"step": 99, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 100.0, 1.0, 1.0, 1.0, 1.0, 1.0, 100.0, 100.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.938, -4.938]}
{"number_of_episodes": 227, "number_of_timesteps": 4404, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.013999999999999985, "biggest_recent_change": NaN},
{"step": 100, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 101.0, 1.0, 1.0, 1.0, 1.0, 1.0, 101.0, 101.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"step": 101, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 102.0, 1.0, 1.0, 1.0, 1.0, 1.0, 102.0, 102.0], "q_vals": [0.0, 0.0, -4.94, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"number_of_episodes": 232, "number_of_timesteps": 4524, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.09250000000000001, "biggest_recent_change": NaN},
{"step": 102, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 103.0, 1.0, 1.0, 1.0, 1.0, 1.0, 103.0, 103.0], "q_vals": [0.0, 0.0, -4.892, 0.0, 0.0, 0.0, 0.0, 0.0, -4.813, -4.813]}
{"step": 103, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 104.0, 1.0, 1.0, 1.0, 1.0, 1.0, 104.0, 104.0], "q_vals": [0.0, 0.0, -4.845, 0.0, 0.0, 0.0, 0.0, 0.0, -4.767, -4.767]}
{"number_of_episodes": 236, "number_of_timesteps": 4622, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.07562500000000001, "biggest_recent_change": NaN},
{"step": 104, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 105.0, 1.0, 1.0, 1.0, 1.0, 1.0, 105.0, 105.0], "q_vals": [0.0, 0.0, -4.851, 0.0, 0.0, 0.0, 0.0, 0.0, -4.767, -4.767]}
{"step": 105, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 106.0, 1.0, 1.0, 1.0, 1.0, 1.0, 106.0, 106.0], "q_vals": [0.0, 0.0, -4.805, 0.0, 0.0, 0.0, 0.0, 0.0, -4.722, -4.722]}
{"number_of_episodes": 240, "number_of_timesteps": 4695, "per_episode_reward": 16.9, "episode_reward_trend_value": -0.011666666666666714, "biggest_recent_change": NaN},
{"step": 106, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 107.0, 1.0, 1.0, 1.0, 1.0, 1.0, 107.0, 107.0], "q_vals": [0.0, 0.0, -4.869, 0.0, 0.0, 0.0, 0.0, 0.0, -4.775, -4.775]}
{"number_of_episodes": 242, "number_of_timesteps": 4736, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.006666666666666643, "biggest_recent_change": NaN},
{"step": 107, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 108.0, 1.0, 1.0, 1.0, 1.0, 1.0, 108.0, 108.0], "q_vals": [0.0, 0.0, -4.824, 0.0, 0.0, 0.0, 0.0, 0.0, -4.73, -4.73]}
{"number_of_episodes": 245, "number_of_timesteps": 4794, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.038333333333333344, "biggest_recent_change": NaN},
{"step": 108, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 109.0, 1.0, 1.0, 1.0, 1.0, 1.0, 109.0, 109.0], "q_vals": [0.0, 0.0, -4.826, 0.0, 0.0, 0.0, 0.0, 0.0, -4.727, -4.727]}
{"step": 109, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 110.0, 1.0, 1.0, 1.0, 1.0, 1.0, 110.0, 110.0], "q_vals": [0.0, 0.0, -4.934, 0.0, 0.0, 0.0, 0.0, 0.0, -4.819, -4.819]}
{"number_of_episodes": 248, "number_of_timesteps": 4854, "per_episode_reward": 16.95, "episode_reward_trend_value": -0.005833333333333357, "biggest_recent_change": NaN},
{"step": 110, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 111.0, 1.0, 1.0, 1.0, 1.0, 1.0, 111.0, 111.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.856, -4.856]}
{"number_of_episodes": 250, "number_of_timesteps": 4919, "per_episode_reward": 16.9, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": NaN},
{"step": 111, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 112.0, 1.0, 1.0, 1.0, 1.0, 1.0, 112.0, 112.0], "q_vals": [0.0, 0.0, -4.977, 0.0, 0.0, 0.0, 0.0, 0.0, -4.848, -4.848]}
{"number_of_episodes": 254, "number_of_timesteps": 5019, "per_episode_reward": 16.95, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": NaN},
{"step": 112, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 113.0, 1.0, 1.0, 1.0, 1.0, 1.0, 113.0, 113.0], "q_vals": [0.0, 0.0, -4.933, 0.0, 0.0, 0.0, 0.0, 0.0, -4.805, -4.805]}
{"number_of_episodes": 256, "number_of_timesteps": 5054, "per_episode_reward": 16.9, "episode_reward_trend_value": -0.007142857142857143, "biggest_recent_change": NaN},
{"step": 113, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 114.0, 1.0, 1.0, 1.0, 1.0, 1.0, 114.0, 114.0], "q_vals": [0.0, 0.0, -4.89, 0.0, 0.0, 0.0, 0.0, 0.0, -4.763, -4.763]}
{"step": 114, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 115.0, 1.0, 1.0, 1.0, 1.0, 1.0, 115.0, 115.0], "q_vals": [0.0, 0.0, -4.848, 0.0, 0.0, 0.0, 0.0, 0.0, -4.722, -4.722]}
{"number_of_episodes": 257, "number_of_timesteps": 5067, "per_episode_reward": 16.85, "episode_reward_trend_value": -0.03499999999999999, "biggest_recent_change": NaN},
{"step": 115, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 116.0, 1.0, 1.0, 1.0, 1.0, 1.0, 116.0, 116.0], "q_vals": [0.0, 0.0, -4.828, 0.0, 0.0, 0.0, 0.0, 0.0, -4.701, -4.701]}
{"eval_score": 20.9, "number_of_episodes": 264}
{"number_of_episodes": 264, "number_of_timesteps": 5194, "per_episode_reward": 16.95, "episode_reward_trend_value": -0.007857142857142866, "biggest_recent_change": NaN},
{"step": 116, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 117.0, 1.0, 1.0, 1.0, 1.0, 1.0, 117.0, 117.0], "q_vals": [0.0, 0.0, -4.835, 0.0, 0.0, 0.0, 0.0, 0.0, -4.703, -4.703]}
{"number_of_episodes": 264, "number_of_timesteps": 5194, "per_episode_reward": 16.95, "episode_reward_trend_value": 0.00625, "biggest_recent_change": NaN},
{"step": 117, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 118.0, 1.0, 1.0, 1.0, 1.0, 1.0, 118.0, 118.0], "q_vals": [0.0, 0.0, -4.794, 0.0, 0.0, 0.0, 0.0, 0.0, -4.663, -4.663]}
{"step": 118, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 119.0, 1.0, 1.0, 1.0, 1.0, 1.0, 119.0, 119.0], "q_vals": [0.0, 0.0, -4.791, 0.0, 0.0, 0.0, 0.0, 0.0, -4.657, -4.657]}
{"step": 119, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 120.0, 1.0, 1.0, 1.0, 1.0, 1.0, 120.0, 120.0], "q_vals": [0.0, 0.0, -4.777, 0.0, 0.0, 0.0, 0.0, 0.0, -4.641, -4.641]}
{"number_of_episodes": 270, "number_of_timesteps": 5324, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.06444444444444444, "biggest_recent_change": 4.800000000000001},
{"step": 120, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 121.0, 1.0, 1.0, 1.0, 1.0, 1.0, 121.0, 121.0], "q_vals": [0.0, 0.0, -4.791, 0.0, 0.0, 0.0, 0.0, 0.0, -4.65, -4.65]}
{"step": 121, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 122.0, 1.0, 1.0, 1.0, 1.0, 1.0, 122.0, 122.0], "q_vals": [0.0, 0.0, -4.801, 0.0, 0.0, 0.0, 0.0, 0.0, -4.656, -4.656]}
{"number_of_episodes": 274, "number_of_timesteps": 5411, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.00625, "biggest_recent_change": NaN},
{"step": 122, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 123.0, 1.0, 1.0, 1.0, 1.0, 1.0, 123.0, 123.0], "q_vals": [0.0, 0.0, -4.8, 0.0, 0.0, 0.0, 0.0, 0.0, -4.651, -4.651]}
{"number_of_episodes": 277, "number_of_timesteps": 5500, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.007000000000000029, "biggest_recent_change": NaN},
{"step": 123, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 124.0, 1.0, 1.0, 1.0, 1.0, 1.0, 124.0, 124.0], "q_vals": [0.0, 0.0, -4.761, 0.0, 0.0, 0.0, 0.0, 0.0, -4.613, -4.613]}
{"number_of_episodes": 279, "number_of_timesteps": 5528, "per_episode_reward": 17.05, "episode_reward_trend_value": -0.0043749999999999735, "biggest_recent_change": NaN},
{"step": 124, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 125.0, 1.0, 1.0, 1.0, 1.0, 1.0, 125.0, 125.0], "q_vals": [0.0, 0.0, -4.723, 0.0, 0.0, 0.0, 0.0, 0.0, -4.576, -4.576]}
{"step": 125, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 126.0, 1.0, 1.0, 1.0, 1.0, 1.0, 126.0, 126.0], "q_vals": [0.0, 0.0, -4.685, 0.0, 0.0, 0.0, 0.0, 0.0, -4.54, -4.54]}
{"number_of_episodes": 283, "number_of_timesteps": 5590, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.08333333333333334, "biggest_recent_change": NaN},
{"step": 126, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 127.0, 1.0, 1.0, 1.0, 1.0, 1.0, 127.0, 127.0], "q_vals": [0.0, 0.0, -4.649, 0.0, 0.0, 0.0, 0.0, 0.0, -4.534, -4.534]}
{"step": 127, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 128.0, 1.0, 1.0, 1.0, 1.0, 1.0, 128.0, 128.0], "q_vals": [0.0, 0.0, -4.612, 0.0, 0.0, 0.0, 0.0, 0.0, -4.499, -4.499]}
{"number_of_episodes": 287, "number_of_timesteps": 5684, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.0014285714285713982, "biggest_recent_change": NaN},
{"step": 128, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 129.0, 1.0, 1.0, 1.0, 1.0, 1.0, 129.0, 129.0], "q_vals": [0.0, 0.0, -4.625, 0.0, 0.0, 0.0, 0.0, 0.0, -4.507, -4.507]}
{"number_of_episodes": 288, "number_of_timesteps": 5701, "per_episode_reward": 17.15, "episode_reward_trend_value": -0.006428571428571469, "biggest_recent_change": NaN},
{"step": 129, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 130.0, 1.0, 1.0, 1.0, 1.0, 1.0, 130.0, 130.0], "q_vals": [0.0, 0.0, -4.677, 0.0, 0.0, 0.0, 0.0, 0.0, -4.549, -4.549]}
{"number_of_episodes": 292, "number_of_timesteps": 5782, "per_episode_reward": 17.25, "episode_reward_trend_value": -0.07214285714285715, "biggest_recent_change": NaN},
{"step": 130, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 131.0, 1.0, 1.0, 1.0, 1.0, 1.0, 131.0, 131.0], "q_vals": [0.0, 0.0, -4.641, 0.0, 0.0, 0.0, 0.0, 0.0, -4.514, -4.514]}
{"number_of_episodes": 293, "number_of_timesteps": 5816, "per_episode_reward": 17.25, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 2.450000000000003},
{"step": 131, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 132.0, 1.0, 1.0, 1.0, 1.0, 1.0, 132.0, 132.0], "q_vals": [0.0, 0.0, -4.636, 0.0, 0.0, 0.0, 0.0, 0.0, -4.507, -4.507]}
{"number_of_episodes": 294, "number_of_timesteps": 5861, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.010000000000000024, "biggest_recent_change": NaN},
{"step": 132, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 133.0, 1.0, 1.0, 1.0, 1.0, 1.0, 133.0, 133.0], "q_vals": [0.0, 0.0, -4.601, 0.0, 0.0, 0.0, 0.0, 0.0, -4.473, -4.473]}
{"number_of_episodes": 298, "number_of_timesteps": 5927, "per_episode_reward": 17.3, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 1.3499999999999979},
{"step": 133, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 134.0, 1.0, 1.0, 1.0, 1.0, 1.0, 134.0, 134.0], "q_vals": [0.0, 0.0, -4.567, 0.0, 0.0, 0.0, 0.0, 0.0, -4.44, -4.44]}
{"number_of_episodes": 302, "number_of_timesteps": 6012, "per_episode_reward": 17.3, "episode_reward_trend_value": -0.0625, "biggest_recent_change": NaN},
{"step": 134, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 135.0, 1.0, 1.0, 1.0, 1.0, 1.0, 135.0, 135.0], "q_vals": [0.0, 0.0, -4.533, 0.0, 0.0, 0.0, 0.0, 0.0, -4.407, -4.407]}
{"step": 135, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 136.0, 1.0, 1.0, 1.0, 1.0, 1.0, 136.0, 136.0], "q_vals": [0.0, 0.0, -4.5, 0.0, 0.0, 0.0, 0.0, 0.0, -4.374, -4.374]}
{"number_of_episodes": 305, "number_of_timesteps": 6055, "per_episode_reward": 17.2, "episode_reward_trend_value": -0.026250000000000016, "biggest_recent_change": NaN},
{"step": 136, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 137.0, 1.0, 1.0, 1.0, 1.0, 1.0, 137.0, 137.0], "q_vals": [0.0, 0.0, -4.496, 0.0, 0.0, 0.0, 0.0, 0.0, -4.368, -4.368]}
{"number_of_episodes": 310, "number_of_timesteps": 6161, "per_episode_reward": 17.25, "episode_reward_trend_value": -0.0007142857142857244, "biggest_recent_change": NaN},
{"step": 137, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 138.0, 1.0, 1.0, 1.0, 1.0, 1.0, 138.0, 138.0], "q_vals": [0.0, 0.0, -4.549, 0.0, 0.0, 0.0, 0.0, 0.0, -4.412, -4.412]}
{"number_of_episodes": 312, "number_of_timesteps": 6194, "per_episode_reward": 17.25, "episode_reward_trend_value": -0.004375000000000018, "biggest_recent_change": NaN},
{"step": 138, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 139.0, 1.0, 1.0, 1.0, 1.0, 1.0, 139.0, 139.0], "q_vals": [0.0, 0.0, -4.587, 0.0, 0.0, 0.0, 0.0, 0.0, -4.443, -4.443]}
{"number_of_episodes": 313, "number_of_timesteps": 6214, "per_episode_reward": 17.3, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 1.0500000000000007},
{"step": 139, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 140.0, 1.0, 1.0, 1.0, 1.0, 1.0, 140.0, 140.0], "q_vals": [0.0, 0.0, -4.589, 0.0, 0.0, 0.0, 0.0, 0.0, -4.441, -4.441]}
{"step": 140, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 141.0, 1.0, 1.0, 1.0, 1.0, 1.0, 141.0, 141.0], "q_vals": [0.0, 0.0, -4.652, 0.0, 0.0, 0.0, 0.0, 0.0, -4.494, -4.494]}
{"number_of_episodes": 318, "number_of_timesteps": 6302, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.05499999999999999, "biggest_recent_change": 4.5},
{"step": 141, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 142.0, 1.0, 1.0, 1.0, 1.0, 1.0, 142.0, 142.0], "q_vals": [0.0, 0.0, -4.619, 0.0, 0.0, 0.0, 0.0, 0.0, -4.462, -4.462]}
{"step": 142, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 143.0, 1.0, 1.0, 1.0, 1.0, 1.0, 143.0, 143.0], "q_vals": [0.0, 0.0, -4.587, 0.0, 0.0, 0.0, 0.0, 0.0, -4.431, -4.431]}
{"number_of_episodes": 326, "number_of_timesteps": 6429, "per_episode_reward": 17.2, "episode_reward_trend_value": -0.0012500000000000178, "biggest_recent_change": NaN},
{"step": 143, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 144.0, 1.0, 1.0, 1.0, 1.0, 1.0, 144.0, 144.0], "q_vals": [0.0, 0.0, -4.634, 0.0, 0.0, 0.0, 0.0, 0.0, -4.47, -4.47]}
{"number_of_episodes": 328, "number_of_timesteps": 6449, "per_episode_reward": 17.15, "episode_reward_trend_value": 0.006428571428571418, "biggest_recent_change": NaN},
{"step": 144, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 145.0, 1.0, 1.0, 1.0, 1.0, 1.0, 145.0, 145.0], "q_vals": [0.0, 0.0, -4.602, 0.0, 0.0, 0.0, 0.0, 0.0, -4.44, -4.44]}
{"step": 145, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 146.0, 1.0, 1.0, 1.0, 1.0, 1.0, 146.0, 146.0], "q_vals": [0.0, 0.0, -4.64, 0.0, 0.0, 0.0, 0.0, 0.0, -4.471, -4.471]}
{"number_of_episodes": 332, "number_of_timesteps": 6507, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.0012499999999999734, "biggest_recent_change": NaN},
{"step": 146, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 147.0, 1.0, 1.0, 1.0, 1.0, 1.0, 147.0, 147.0], "q_vals": [0.0, 0.0, -4.626, 0.0, 0.0, 0.0, 0.0, 0.0, -4.455, -4.455]}
{"step": 147, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 148.0, 1.0, 1.0, 1.0, 1.0, 1.0, 148.0, 148.0], "q_vals": [0.0, 0.0, -4.684, 0.0, 0.0, 0.0, 0.0, 0.0, -4.504, -4.504]}
{"number_of_episodes": 337, "number_of_timesteps": 6608, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 1.6000000000000014},
{"step": 148, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 149.0, 1.0, 1.0, 1.0, 1.0, 1.0, 149.0, 149.0], "q_vals": [0.0, 0.0, -4.766, 0.0, 0.0, 0.0, 0.0, 0.0, -4.573, -4.573]}
{"number_of_episodes": 339, "number_of_timesteps": 6663, "per_episode_reward": 17.15, "episode_reward_trend_value": -0.005000000000000031, "biggest_recent_change": 2.200000000000001},
{"step": 149, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 150.0, 1.0, 1.0, 1.0, 1.0, 1.0, 150.0, 150.0], "q_vals": [0.0, 0.0, -4.842, 0.0, 0.0, 0.0, 0.0, 0.0, -4.638, -4.638]}
{"number_of_episodes": 341, "number_of_timesteps": 6695, "per_episode_reward": 17.2, "episode_reward_trend_value": -0.023333333333333352, "biggest_recent_change": 1.5500000000000007},
{"step": 150, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 151.0, 1.0, 1.0, 1.0, 1.0, 1.0, 151.0, 151.0], "q_vals": [0.0, 0.0, -4.854, 0.0, 0.0, 0.0, 0.0, 0.0, -4.646, -4.646]}
{"step": 151, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 152.0, 1.0, 1.0, 1.0, 1.0, 1.0, 152.0, 152.0], "q_vals": [0.0, 0.0, -4.935, 0.0, 0.0, 0.0, 0.0, 0.0, -4.715, -4.715]}
{"step": 152, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 153.0, 1.0, 1.0, 1.0, 1.0, 1.0, 153.0, 153.0], "q_vals": [0.0, 0.0, -4.93, 0.0, 0.0, 0.0, 0.0, 0.0, -4.709, -4.709]}
{"number_of_episodes": 350, "number_of_timesteps": 6861, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.6500000000000021},
{"step": 153, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 154.0, 1.0, 1.0, 1.0, 1.0, 1.0, 154.0, 154.0], "q_vals": [0.0, 0.0, -4.898, 0.0, 0.0, 0.0, 0.0, 0.0, -4.678, -4.678]}
{"number_of_episodes": 352, "number_of_timesteps": 6884, "per_episode_reward": 17.25, "episode_reward_trend_value": -0.01777777777777779, "biggest_recent_change": 2.450000000000003},
{"step": 154, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 155.0, 1.0, 1.0, 1.0, 1.0, 1.0, 155.0, 155.0], "q_vals": [0.0, 0.0, -4.903, 0.0, 0.0, 0.0, 0.0, 0.0, -4.68, -4.68]}
{"step": 155, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 156.0, 1.0, 1.0, 1.0, 1.0, 1.0, 156.0, 156.0], "q_vals": [0.0, 0.0, -4.871, 0.0, 0.0, 0.0, 0.0, 0.0, -4.65, -4.65]}
{"number_of_episodes": 358, "number_of_timesteps": 6989, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.06999999999999998, "biggest_recent_change": NaN},
{"step": 156, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 157.0, 1.0, 1.0, 1.0, 1.0, 1.0, 157.0, 157.0], "q_vals": [0.0, 0.0, -4.84, 0.0, 0.0, 0.0, 0.0, 0.0, -4.646, -4.646]}
{"step": 157, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 158.0, 1.0, 1.0, 1.0, 1.0, 1.0, 158.0, 158.0], "q_vals": [0.0, 0.0, -4.81, 0.0, 0.0, 0.0, 0.0, 0.0, -4.643, -4.643]}
{"number_of_episodes": 360, "number_of_timesteps": 7038, "per_episode_reward": 17.15, "episode_reward_trend_value": -0.002222222222222254, "biggest_recent_change": 0.6500000000000021},
{"step": 158, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 159.0, 1.0, 1.0, 1.0, 1.0, 1.0, 159.0, 159.0], "q_vals": [0.0, 0.0, -4.779, 0.0, 0.0, 0.0, 0.0, 0.0, -4.614, -4.614]}
{"number_of_episodes": 364, "number_of_timesteps": 7103, "per_episode_reward": 17.05, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 1.4499999999999993},
{"step": 159, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 160.0, 1.0, 1.0, 1.0, 1.0, 1.0, 160.0, 160.0], "q_vals": [0.0, 0.0, -4.788, 0.0, 0.0, 0.0, 0.0, 0.0, -4.619, -4.619]}
{"number_of_episodes": 365, "number_of_timesteps": 7120, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.011666666666666676, "biggest_recent_change": 0.5500000000000007},
{"step": 160, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 161.0, 1.0, 1.0, 1.0, 1.0, 1.0, 161.0, 161.0], "q_vals": [0.0, 0.0, -4.758, 0.0, 0.0, 0.0, 0.0, 0.0, -4.59, -4.59]}
{"step": 161, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 162.0, 1.0, 1.0, 1.0, 1.0, 1.0, 162.0, 162.0], "q_vals": [0.0, 0.0, -4.729, 0.0, 0.0, 0.0, 0.0, 0.0, -4.562, -4.562]}
{"step": 162, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 163.0, 1.0, 1.0, 1.0, 1.0, 1.0, 163.0, 163.0], "q_vals": [0.0, 0.0, -4.7, 0.0, 0.0, 0.0, 0.0, 0.0, -4.534, -4.534]}
{"number_of_episodes": 372, "number_of_timesteps": 7305, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.004375000000000018, "biggest_recent_change": NaN},
{"step": 163, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 164.0, 1.0, 1.0, 1.0, 1.0, 1.0, 164.0, 164.0], "q_vals": [0.0, 0.0, -4.671, 0.0, 0.0, 0.0, 0.0, 0.0, -4.506, -4.506]}
{"step": 164, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 165.0, 1.0, 1.0, 1.0, 1.0, 1.0, 165.0, 165.0], "q_vals": [0.0, 0.0, -4.643, 0.0, 0.0, 0.0, 0.0, 0.0, -4.479, -4.479]}
{"number_of_episodes": 376, "number_of_timesteps": 7401, "per_episode_reward": 17.15, "episode_reward_trend_value": 0.00777777777777777, "biggest_recent_change": 0.6999999999999993},
{"step": 165, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 166.0, 1.0, 1.0, 1.0, 1.0, 1.0, 166.0, 166.0], "q_vals": [0.0, 0.0, -4.651, 0.0, 0.0, 0.0, 0.0, 0.0, -4.484, -4.484]}
{"number_of_episodes": 377, "number_of_timesteps": 7412, "per_episode_reward": 17.15, "episode_reward_trend_value": 0.008333333333333333, "biggest_recent_change": 0.4499999999999993},
{"step": 166, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 167.0, 1.0, 1.0, 1.0, 1.0, 1.0, 167.0, 167.0], "q_vals": [0.0, 0.0, -4.647, 0.0, 0.0, 0.0, 0.0, 0.0, -4.478, -4.478]}
{"number_of_episodes": 379, "number_of_timesteps": 7450, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.015000000000000017, "biggest_recent_change": 1.0},
{"step": 167, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 168.0, 1.0, 1.0, 1.0, 1.0, 1.0, 168.0, 168.0], "q_vals": [0.0, 0.0, -4.68, 0.0, 0.0, 0.0, 0.0, 0.0, -4.506, -4.506]}
{"number_of_episodes": 381, "number_of_timesteps": 7485, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.5},
{"step": 168, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 169.0, 1.0, 1.0, 1.0, 1.0, 1.0, 169.0, 169.0], "q_vals": [0.0, 0.0, -4.653, 0.0, 0.0, 0.0, 0.0, 0.0, -4.479, -4.479]}
{"number_of_episodes": 385, "number_of_timesteps": 7596, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.8499999999999979},
{"step": 169, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 170.0, 1.0, 1.0, 1.0, 1.0, 1.0, 170.0, 170.0], "q_vals": [0.0, 0.0, -4.654, 0.0, 0.0, 0.0, 0.0, 0.0, -4.478, -4.478]}
{"number_of_episodes": 387, "number_of_timesteps": 7623, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.013333333333333326, "biggest_recent_change": 0.4499999999999993},
{"step": 170, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 171.0, 1.0, 1.0, 1.0, 1.0, 1.0, 171.0, 171.0], "q_vals": [0.0, 0.0, -4.659, 0.0, 0.0, 0.0, 0.0, 0.0, -4.48, -4.48]}
{"number_of_episodes": 388, "number_of_timesteps": 7636, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.019444444444444445, "biggest_recent_change": 0.5500000000000007},
{"step": 171, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 172.0, 1.0, 1.0, 1.0, 1.0, 1.0, 172.0, 172.0], "q_vals": [0.0, 0.0, -4.632, 0.0, 0.0, 0.0, 0.0, 0.0, -4.454, -4.454]}
{"eval_score": 17.4, "number_of_episodes": 391}
{"number_of_episodes": 391, "number_of_timesteps": 7693, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.061249999999999985, "biggest_recent_change": NaN},
{"step": 172, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 173.0, 1.0, 1.0, 1.0, 1.0, 1.0, 173.0, 173.0], "q_vals": [0.0, 0.0, -4.605, 0.0, 0.0, 0.0, 0.0, 0.0, -4.454, -4.454]}
{"number_of_episodes": 394, "number_of_timesteps": 7744, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.5},
{"step": 173, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 174.0, 1.0, 1.0, 1.0, 1.0, 1.0, 174.0, 174.0], "q_vals": [0.0, 0.0, -4.579, 0.0, 0.0, 0.0, 0.0, 0.0, -4.428, -4.428]}
{"number_of_episodes": 394, "number_of_timesteps": 7744, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.3500000000000014},
{"step": 174, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 175.0, 1.0, 1.0, 1.0, 1.0, 1.0, 175.0, 175.0], "q_vals": [0.0, 0.0, -4.616, 0.0, 0.0, 0.0, 0.0, 0.0, -4.459, -4.459]}
{"step": 175, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 176.0, 1.0, 1.0, 1.0, 1.0, 1.0, 176.0, 176.0], "q_vals": [0.0, 0.0, -4.589, 0.0, 0.0, 0.0, 0.0, 0.0, -4.433, -4.433]}
{"number_of_episodes": 401, "number_of_timesteps": 7894, "per_episode_reward": 17.15, "episode_reward_trend_value": -0.05388888888888891, "biggest_recent_change": 4.199999999999999},
{"step": 176, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 177.0, 1.0, 1.0, 1.0, 1.0, 1.0, 177.0, 177.0], "q_vals": [0.0, 0.0, -4.563, 0.0, 0.0, 0.0, 0.0, 0.0, -4.438, -4.438]}
{"number_of_episodes": 403, "number_of_timesteps": 7959, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.021111111111111115, "biggest_recent_change": 0.9000000000000004},
{"step": 177, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 178.0, 1.0, 1.0, 1.0, 1.0, 1.0, 178.0, 178.0], "q_vals": [0.0, 0.0, -4.594, 0.0, 0.0, 0.0, 0.0, 0.0, -4.463, -4.463]}
{"number_of_episodes": 406, "number_of_timesteps": 8003, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.01111111111111111, "biggest_recent_change": 0.6000000000000014},
{"step": 178, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 179.0, 1.0, 1.0, 1.0, 1.0, 1.0, 179.0, 179.0], "q_vals": [0.0, 0.0, -4.607, 0.0, 0.0, 0.0, 0.0, 0.0, -4.472, -4.472]}
{"step": 179, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 180.0, 1.0, 1.0, 1.0, 1.0, 1.0, 180.0, 180.0], "q_vals": [0.0, 0.0, -4.646, 0.0, 0.0, 0.0, 0.0, 0.0, -4.504, -4.504]}
{"number_of_episodes": 411, "number_of_timesteps": 8081, "per_episode_reward": 17.15, "episode_reward_trend_value": 0.009999999999999985, "biggest_recent_change": 0.4499999999999993},
{"step": 180, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 181.0, 1.0, 1.0, 1.0, 1.0, 1.0, 181.0, 181.0], "q_vals": [0.0, 0.0, -4.643, 0.0, 0.0, 0.0, 0.0, 0.0, -4.499, -4.499]}
{"number_of_episodes": 412, "number_of_timesteps": 8100, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"step": 181, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 182.0, 1.0, 1.0, 1.0, 1.0, 1.0, 182.0, 182.0], "q_vals": [0.0, 0.0, -4.617, 0.0, 0.0, 0.0, 0.0, 0.0, -4.474, -4.474]}
{"number_of_episodes": 416, "number_of_timesteps": 8176, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.5},
{"step": 182, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 183.0, 1.0, 1.0, 1.0, 1.0, 1.0, 183.0, 183.0], "q_vals": [0.0, 0.0, -4.592, 0.0, 0.0, 0.0, 0.0, 0.0, -4.45, -4.45]}
{"number_of_episodes": 417, "number_of_timesteps": 8200, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.3500000000000014},
{"step": 183, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 184.0, 1.0, 1.0, 1.0, 1.0, 1.0, 184.0, 184.0], "q_vals": [0.0, 0.0, -4.629, 0.0, 0.0, 0.0, 0.0, 0.0, -4.48, -4.48]}
{"number_of_episodes": 419, "number_of_timesteps": 8239, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.01388888888888889, "biggest_recent_change": 0.3999999999999986},
{"step": 184, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 185.0, 1.0, 1.0, 1.0, 1.0, 1.0, 185.0, 185.0], "q_vals": [0.0, 0.0, -4.604, 0.0, 0.0, 0.0, 0.0, 0.0, -4.456, -4.456]}
{"step": 185, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 186.0, 1.0, 1.0, 1.0, 1.0, 1.0, 186.0, 186.0], "q_vals": [0.0, 0.0, -4.579, 0.0, 0.0, 0.0, 0.0, 0.0, -4.432, -4.432]}
{"number_of_episodes": 425, "number_of_timesteps": 8346, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.012222222222222199, "biggest_recent_change": 0.29999999999999716},
{"step": 186, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 187.0, 1.0, 1.0, 1.0, 1.0, 1.0, 187.0, 187.0], "q_vals": [0.0, 0.0, -4.611, 0.0, 0.0, 0.0, 0.0, 0.0, -4.458, -4.458]}
{"number_of_episodes": 427, "number_of_timesteps": 8369, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 1.4000000000000021},
{"step": 187, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 188.0, 1.0, 1.0, 1.0, 1.0, 1.0, 188.0, 188.0], "q_vals": [0.0, 0.0, -4.587, 0.0, 0.0, 0.0, 0.0, 0.0, -4.466, -4.466]}
{"number_of_episodes": 430, "number_of_timesteps": 8429, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.00777777777777777, "biggest_recent_change": 0.25},
{"step": 188, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 189.0, 1.0, 1.0, 1.0, 1.0, 1.0, 189.0, 189.0], "q_vals": [0.0, 0.0, -4.603, 0.0, 0.0, 0.0, 0.0, 0.0, -4.478, -4.478]}
{"number_of_episodes": 434, "number_of_timesteps": 8503, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.6999999999999993},
{"step": 189, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 190.0, 1.0, 1.0, 1.0, 1.0, 1.0, 190.0, 190.0], "q_vals": [0.0, 0.0, -4.614, 0.0, 0.0, 0.0, 0.0, 0.0, -4.485, -4.485]}
{"number_of_episodes": 436, "number_of_timesteps": 8529, "per_episode_reward": 17.25, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.5},
{"step": 190, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 191.0, 1.0, 1.0, 1.0, 1.0, 1.0, 191.0, 191.0], "q_vals": [0.0, 0.0, -4.589, 0.0, 0.0, 0.0, 0.0, 0.0, -4.461, -4.461]}
{"number_of_episodes": 438, "number_of_timesteps": 8549, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.008888888888888896, "biggest_recent_change": 0.3500000000000014},
{"step": 191, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 192.0, 1.0, 1.0, 1.0, 1.0, 1.0, 192.0, 192.0], "q_vals": [0.0, 0.0, -4.628, 0.0, 0.0, 0.0, 0.0, 0.0, -4.494, -4.494]}
{"step": 192, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 193.0, 1.0, 1.0, 1.0, 1.0, 1.0, 193.0, 193.0], "q_vals": [0.0, 0.0, -4.655, 0.0, 0.0, 0.0, 0.0, 0.0, -4.515, -4.515]}
{"number_of_episodes": 446, "number_of_timesteps": 8689, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 193, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 194.0, 1.0, 1.0, 1.0, 1.0, 1.0, 194.0, 194.0], "q_vals": [0.0, 0.0, -4.654, 0.0, 0.0, 0.0, 0.0, 0.0, -4.512, -4.512]}
{"step": 194, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 195.0, 1.0, 1.0, 1.0, 1.0, 1.0, 195.0, 195.0], "q_vals": [0.0, 0.0, -4.653, 0.0, 0.0, 0.0, 0.0, 0.0, -4.509, -4.509]}
{"number_of_episodes": 449, "number_of_timesteps": 8725, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.6000000000000014},
{"step": 195, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 196.0, 1.0, 1.0, 1.0, 1.0, 1.0, 196.0, 196.0], "q_vals": [0.0, 0.0, -4.666, 0.0, 0.0, 0.0, 0.0, 0.0, -4.519, -4.519]}
{"number_of_episodes": 451, "number_of_timesteps": 8767, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.34999999999999787},
{"step": 196, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 197.0, 1.0, 1.0, 1.0, 1.0, 1.0, 197.0, 197.0], "q_vals": [0.0, 0.0, -4.715, 0.0, 0.0, 0.0, 0.0, 0.0, -4.559, -4.559]}
{"number_of_episodes": 454, "number_of_timesteps": 8817, "per_episode_reward": 16.95, "episode_reward_trend_value": 0.007222222222222206, "biggest_recent_change": 0.3999999999999986},
{"step": 197, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 198.0, 1.0, 1.0, 1.0, 1.0, 1.0, 198.0, 198.0], "q_vals": [0.0, 0.0, -4.691, 0.0, 0.0, 0.0, 0.0, 0.0, -4.536, -4.536]}
{"number_of_episodes": 458, "number_of_timesteps": 8903, "per_episode_reward": 17.05, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.20000000000000284},
{"step": 198, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 199.0, 1.0, 1.0, 1.0, 1.0, 1.0, 199.0, 199.0], "q_vals": [0.0, 0.0, -4.667, 0.0, 0.0, 0.0, 0.0, 0.0, -4.513, -4.513]}
{"number_of_episodes": 461, "number_of_timesteps": 8941, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.3999999999999986},
{"step": 199, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 200.0, 1.0, 1.0, 1.0, 1.0, 1.0, 200.0, 200.0], "q_vals": [0.0, 0.0, -4.644, 0.0, 0.0, 0.0, 0.0, 0.0, -4.491, -4.491]}
{"step": 200, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 201.0, 1.0, 1.0, 1.0, 1.0, 1.0, 201.0, 201.0], "q_vals": [0.0, 0.0, -4.621, 0.0, 0.0, 0.0, 0.0, 0.0, -4.468, -4.468]}
{"step": 201, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 202.0, 1.0, 1.0, 1.0, 1.0, 1.0, 202.0, 202.0], "q_vals": [0.0, 0.0, -4.598, 0.0, 0.0, 0.0, 0.0, 0.0, -4.446, -4.446]}
{"number_of_episodes": 471, "number_of_timesteps": 9063, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.3999999999999986},
{"step": 202, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 203.0, 1.0, 1.0, 1.0, 1.0, 1.0, 203.0, 203.0], "q_vals": [0.0, 0.0, -4.599, 0.0, 0.0, 0.0, 0.0, 0.0, -4.446, -4.446]}
{"number_of_episodes": 475, "number_of_timesteps": 9125, "per_episode_reward": 16.85, "episode_reward_trend_value": 0.008888888888888896, "biggest_recent_change": 0.5999999999999979},
{"step": 203, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 204.0, 1.0, 1.0, 1.0, 1.0, 1.0, 204.0, 204.0], "q_vals": [0.0, 0.0, -4.608, 0.0, 0.0, 0.0, 0.0, 0.0, -4.452, -4.452]}
{"step": 204, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 205.0, 1.0, 1.0, 1.0, 1.0, 1.0, 205.0, 205.0], "q_vals": [0.0, 0.0, -4.613, 0.0, 0.0, 0.0, 0.0, 0.0, -4.454, -4.454]}
{"number_of_episodes": 481, "number_of_timesteps": 9204, "per_episode_reward": 16.85, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.5},
{"step": 205, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 206.0, 1.0, 1.0, 1.0, 1.0, 1.0, 206.0, 206.0], "q_vals": [0.0, 0.0, -4.59, 0.0, 0.0, 0.0, 0.0, 0.0, -4.452, -4.452]}
{"number_of_episodes": 482, "number_of_timesteps": 9216, "per_episode_reward": 16.85, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.6500000000000021},
{"step": 206, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 207.0, 1.0, 1.0, 1.0, 1.0, 1.0, 207.0, 207.0], "q_vals": [0.0, 0.0, -4.601, 0.0, 0.0, 0.0, 0.0, 0.0, -4.459, -4.459]}
{"number_of_episodes": 485, "number_of_timesteps": 9271, "per_episode_reward": 16.9, "episode_reward_trend_value": -0.004444444444444468, "biggest_recent_change": 0.20000000000000284},
{"step": 207, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 208.0, 1.0, 1.0, 1.0, 1.0, 1.0, 208.0, 208.0], "q_vals": [0.0, 0.0, -4.579, 0.0, 0.0, 0.0, 0.0, 0.0, -4.438, -4.438]}
{"number_of_episodes": 489, "number_of_timesteps": 9333, "per_episode_reward": 16.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.3500000000000014},
{"step": 208, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 209.0, 1.0, 1.0, 1.0, 1.0, 1.0, 209.0, 209.0], "q_vals": [0.0, 0.0, -4.557, 0.0, 0.0, 0.0, 0.0, 0.0, -4.417, -4.417]}
{"number_of_episodes": 493, "number_of_timesteps": 9390, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.3999999999999986},
{"step": 209, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 210.0, 1.0, 1.0, 1.0, 1.0, 1.0, 210.0, 210.0], "q_vals": [0.0, 0.0, -4.564, 0.0, 0.0, 0.0, 0.0, 0.0, -4.421, -4.421]}
{"step": 210, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 211.0, 1.0, 1.0, 1.0, 1.0, 1.0, 211.0, 211.0], "q_vals": [0.0, 0.0, -4.564, 0.0, 0.0, 0.0, 0.0, 0.0, -4.419, -4.419]}
{"number_of_episodes": 498, "number_of_timesteps": 9472, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.3999999999999986},
{"step": 211, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 212.0, 1.0, 1.0, 1.0, 1.0, 1.0, 212.0, 212.0], "q_vals": [0.0, 0.0, -4.563, 0.0, 0.0, 0.0, 0.0, 0.0, -4.416, -4.416]}
{"number_of_episodes": 500, "number_of_timesteps": 9502, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.6000000000000014},
{"step": 212, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 213.0, 1.0, 1.0, 1.0, 1.0, 1.0, 213.0, 213.0], "q_vals": [0.0, 0.0, -4.564, 0.0, 0.0, 0.0, 0.0, 0.0, -4.415, -4.415]}
{"number_of_episodes": 500, "number_of_timesteps": 9502, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.008888888888888896, "biggest_recent_change": 0.5},
{"step": 213, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 214.0, 1.0, 1.0, 1.0, 1.0, 1.0, 214.0, 214.0], "q_vals": [0.0, 0.0, -4.543, 0.0, 0.0, 0.0, 0.0, 0.0, -4.417, -4.417]}
{"number_of_episodes": 502, "number_of_timesteps": 9538, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.20000000000000284},
{"step": 214, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 215.0, 1.0, 1.0, 1.0, 1.0, 1.0, 215.0, 215.0], "q_vals": [0.0, 0.0, -4.522, 0.0, 0.0, 0.0, 0.0, 0.0, -4.397, -4.397]}
{"number_of_episodes": 506, "number_of_timesteps": 9626, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.4499999999999993},
{"step": 215, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 216.0, 1.0, 1.0, 1.0, 1.0, 1.0, 216.0, 216.0], "q_vals": [0.0, 0.0, -4.549, 0.0, 0.0, 0.0, 0.0, 0.0, -4.419, -4.419]}
{"step": 216, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 217.0, 1.0, 1.0, 1.0, 1.0, 1.0, 217.0, 217.0], "q_vals": [0.0, 0.0, -4.528, 0.0, 0.0, 0.0, 0.0, 0.0, -4.415, -4.415]}
{"number_of_episodes": 510, "number_of_timesteps": 9730, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.5},
{"step": 217, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 218.0, 1.0, 1.0, 1.0, 1.0, 1.0, 218.0, 218.0], "q_vals": [0.0, 0.0, -4.507, 0.0, 0.0, 0.0, 0.0, 0.0, -4.413, -4.413]}
{"number_of_episodes": 512, "number_of_timesteps": 9761, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.34999999999999787},
{"step": 218, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 219.0, 1.0, 1.0, 1.0, 1.0, 1.0, 219.0, 219.0], "q_vals": [0.0, 0.0, -4.545, 0.0, 0.0, 0.0, 0.0, 0.0, -4.444, -4.444]}
{"number_of_episodes": 514, "number_of_timesteps": 9785, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.6000000000000014},
{"step": 219, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 220.0, 1.0, 1.0, 1.0, 1.0, 1.0, 220.0, 220.0], "q_vals": [0.0, 0.0, -4.546, 0.0, 0.0, 0.0, 0.0, 0.0, -4.443, -4.443]}
{"number_of_episodes": 517, "number_of_timesteps": 9860, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.3999999999999986},
{"step": 220, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 221.0, 1.0, 1.0, 1.0, 1.0, 1.0, 221.0, 221.0], "q_vals": [0.0, 0.0, -4.556, 0.0, 0.0, 0.0, 0.0, 0.0, -4.449, -4.449]}
{"eval_score": 18.6, "number_of_episodes": 522}
{"number_of_episodes": 522, "number_of_timesteps": 9947, "per_episode_reward": 16.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.34999999999999787},
{"step": 221, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 222.0, 1.0, 1.0, 1.0, 1.0, 1.0, 222.0, 222.0], "q_vals": [0.0, 0.0, -4.592, 0.0, 0.0, 0.0, 0.0, 0.0, -4.48, -4.48]}
{"step": 222, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 223.0, 1.0, 1.0, 1.0, 1.0, 1.0, 223.0, 223.0], "q_vals": [0.0, 0.0, -4.596, 0.0, 0.0, 0.0, 0.0, 0.0, -4.481, -4.481]}
{"step": 223, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 224.0, 1.0, 1.0, 1.0, 1.0, 1.0, 224.0, 224.0], "q_vals": [0.0, 0.0, -4.601, 0.0, 0.0, 0.0, 0.0, 0.0, -4.483, -4.483]}
{"number_of_episodes": 532, "number_of_timesteps": 10083, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.20000000000000284},
{"step": 224, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 225.0, 1.0, 1.0, 1.0, 1.0, 1.0, 225.0, 225.0], "q_vals": [0.0, 0.0, -4.58, 0.0, 0.0, 0.0, 0.0, 0.0, -4.463, -4.463]}
{"step": 225, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 226.0, 1.0, 1.0, 1.0, 1.0, 1.0, 226.0, 226.0], "q_vals": [0.0, 0.0, -4.56, 0.0, 0.0, 0.0, 0.0, 0.0, -4.443, -4.443]}
{"number_of_episodes": 536, "number_of_timesteps": 10136, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.5},
{"step": 226, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 227.0, 1.0, 1.0, 1.0, 1.0, 1.0, 227.0, 227.0], "q_vals": [0.0, 0.0, -4.54, 0.0, 0.0, 0.0, 0.0, 0.0, -4.442, -4.442]}
{"number_of_episodes": 539, "number_of_timesteps": 10178, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.4499999999999993},
{"step": 227, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 228.0, 1.0, 1.0, 1.0, 1.0, 1.0, 228.0, 228.0], "q_vals": [0.0, 0.0, -4.575, 0.0, 0.0, 0.0, 0.0, 0.0, -4.472, -4.472]}
{"step": 228, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 229.0, 1.0, 1.0, 1.0, 1.0, 1.0, 229.0, 229.0], "q_vals": [0.0, 0.0, -4.603, 0.0, 0.0, 0.0, 0.0, 0.0, -4.494, -4.494]}
{"number_of_episodes": 543, "number_of_timesteps": 10240, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.3999999999999986},
{"step": 229, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 230.0, 1.0, 1.0, 1.0, 1.0, 1.0, 230.0, 230.0], "q_vals": [0.0, 0.0, -4.601, 0.0, 0.0, 0.0, 0.0, 0.0, -4.49, -4.49]}
{"number_of_episodes": 546, "number_of_timesteps": 10296, "per_episode_reward": 16.65, "episode_reward_trend_value": 0.010555555555555547, "biggest_recent_change": 0.45000000000000107},
{"step": 230, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 231.0, 1.0, 1.0, 1.0, 1.0, 1.0, 231.0, 231.0], "q_vals": [0.0, 0.0, -4.602, 0.0, 0.0, 0.0, 0.0, 0.0, -4.489, -4.489]}
{"number_of_episodes": 549, "number_of_timesteps": 10353, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.3500000000000014},
{"step": 231, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 232.0, 1.0, 1.0, 1.0, 1.0, 1.0, 232.0, 232.0], "q_vals": [0.0, 0.0, -4.599, 0.0, 0.0, 0.0, 0.0, 0.0, -4.485, -4.485]}
{"number_of_episodes": 552, "number_of_timesteps": 10401, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.3500000000000014},
{"step": 232, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 233.0, 1.0, 1.0, 1.0, 1.0, 1.0, 233.0, 233.0], "q_vals": [0.0, 0.0, -4.579, 0.0, 0.0, 0.0, 0.0, 0.0, -4.466, -4.466]}
{"number_of_episodes": 552, "number_of_timesteps": 10401, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.3999999999999986},
{"step": 233, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 234.0, 1.0, 1.0, 1.0, 1.0, 1.0, 234.0, 234.0], "q_vals": [0.0, 0.0, -4.581, 0.0, 0.0, 0.0, 0.0, 0.0, -4.465, -4.465]}
{"number_of_episodes": 553, "number_of_timesteps": 10414, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.34999999999999787},
{"step": 234, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 235.0, 1.0, 1.0, 1.0, 1.0, 1.0, 235.0, 235.0], "q_vals": [0.0, 0.0, -4.607, 0.0, 0.0, 0.0, 0.0, 0.0, -4.487, -4.487]}
{"step": 235, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 236.0, 1.0, 1.0, 1.0, 1.0, 1.0, 236.0, 236.0], "q_vals": [0.0, 0.0, -4.616, 0.0, 0.0, 0.0, 0.0, 0.0, -4.492, -4.492]}
{"number_of_episodes": 562, "number_of_timesteps": 10606, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.4499999999999993},
{"step": 236, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 237.0, 1.0, 1.0, 1.0, 1.0, 1.0, 237.0, 237.0], "q_vals": [0.0, 0.0, -4.666, 0.0, 0.0, 0.0, 0.0, 0.0, -4.535, -4.535]}
{"number_of_episodes": 563, "number_of_timesteps": 10616, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.5},
{"step": 237, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 238.0, 1.0, 1.0, 1.0, 1.0, 1.0, 238.0, 238.0], "q_vals": [0.0, 0.0, -4.647, 0.0, 0.0, 0.0, 0.0, 0.0, -4.532, -4.532]}
{"number_of_episodes": 566, "number_of_timesteps": 10653, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.002222222222222254, "biggest_recent_change": 0.3500000000000014},
{"step": 238, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 239.0, 1.0, 1.0, 1.0, 1.0, 1.0, 239.0, 239.0], "q_vals": [0.0, 0.0, -4.651, 0.0, 0.0, 0.0, 0.0, 0.0, -4.533, -4.533]}
{"step": 239, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 240.0, 1.0, 1.0, 1.0, 1.0, 1.0, 240.0, 240.0], "q_vals": [0.0, 0.0, -4.685, 0.0, 0.0, 0.0, 0.0, 0.0, -4.562, -4.562]}
{"step": 240, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 241.0, 1.0, 1.0, 1.0, 1.0, 1.0, 241.0, 241.0], "q_vals": [0.0, 0.0, -4.69, 0.0, 0.0, 0.0, 0.0, 0.0, -4.564, -4.564]}
{"number_of_episodes": 572, "number_of_timesteps": 10754, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.3500000000000014},
{"step": 241, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 242.0, 1.0, 1.0, 1.0, 1.0, 1.0, 242.0, 242.0], "q_vals": [0.0, 0.0, -4.671, 0.0, 0.0, 0.0, 0.0, 0.0, -4.546, -4.546]}
{"number_of_episodes": 575, "number_of_timesteps": 10797, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.4499999999999993},
{"step": 242, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 243.0, 1.0, 1.0, 1.0, 1.0, 1.0, 243.0, 243.0], "q_vals": [0.0, 0.0, -4.698, 0.0, 0.0, 0.0, 0.0, 0.0, -4.568, -4.568]}
{"number_of_episodes": 579, "number_of_timesteps": 10854, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.005000000000000031, "biggest_recent_change": 0.5},
{"step": 243, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 244.0, 1.0, 1.0, 1.0, 1.0, 1.0, 244.0, 244.0], "q_vals": [0.0, 0.0, -4.679, 0.0, 0.0, 0.0, 0.0, 0.0, -4.57, -4.57]}
{"step": 244, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 245.0, 1.0, 1.0, 1.0, 1.0, 1.0, 245.0, 245.0], "q_vals": [0.0, 0.0, -4.66, 0.0, 0.0, 0.0, 0.0, 0.0, -4.561, -4.561]}
{"number_of_episodes": 583, "number_of_timesteps": 10949, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.007777777777777789, "biggest_recent_change": 0.45000000000000107},
{"step": 245, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 246.0, 1.0, 1.0, 1.0, 1.0, 1.0, 246.0, 246.0], "q_vals": [0.0, 0.0, -4.673, 0.0, 0.0, 0.0, 0.0, 0.0, -4.571, -4.571]}
{"number_of_episodes": 587, "number_of_timesteps": 11030, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.4499999999999993},
{"step": 246, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 247.0, 1.0, 1.0, 1.0, 1.0, 1.0, 247.0, 247.0], "q_vals": [0.0, 0.0, -4.654, 0.0, 0.0, 0.0, 0.0, 0.0, -4.552, -4.552]}
{"step": 247, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 248.0, 1.0, 1.0, 1.0, 1.0, 1.0, 248.0, 248.0], "q_vals": [0.0, 0.0, -4.635, 0.0, 0.0, 0.0, 0.0, 0.0, -4.534, -4.534]}
{"number_of_episodes": 590, "number_of_timesteps": 11082, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.3999999999999986},
{"step": 248, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 249.0, 1.0, 1.0, 1.0, 1.0, 1.0, 249.0, 249.0], "q_vals": [0.0, 0.0, -4.632, 0.0, 0.0, 0.0, 0.0, 0.0, -4.53, -4.53]}
{"number_of_episodes": 594, "number_of_timesteps": 11159, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.006666666666666643, "biggest_recent_change": 0.3500000000000014},
{"step": 249, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 250.0, 1.0, 1.0, 1.0, 1.0, 1.0, 250.0, 250.0], "q_vals": [0.0, 0.0, -4.631, 0.0, 0.0, 0.0, 0.0, 0.0, -4.527, -4.527]}
{"number_of_episodes": 596, "number_of_timesteps": 11214, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.006111111111111079, "biggest_recent_change": 0.34999999999999787},
{"step": 250, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 251.0, 1.0, 1.0, 1.0, 1.0, 1.0, 251.0, 251.0], "q_vals": [0.0, 0.0, -4.661, 0.0, 0.0, 0.0, 0.0, 0.0, -4.552, -4.552]}
{"number_of_episodes": 598, "number_of_timesteps": 11247, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.5},
{"step": 251, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 252.0, 1.0, 1.0, 1.0, 1.0, 1.0, 252.0, 252.0], "q_vals": [0.0, 0.0, -4.643, 0.0, 0.0, 0.0, 0.0, 0.0, -4.557, -4.557]}
{"number_of_episodes": 600, "number_of_timesteps": 11277, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.4499999999999993},
{"step": 252, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 253.0, 1.0, 1.0, 1.0, 1.0, 1.0, 253.0, 253.0], "q_vals": [0.0, 0.0, -4.649, 0.0, 0.0, 0.0, 0.0, 0.0, -4.561, -4.561]}
{"number_of_episodes": 606, "number_of_timesteps": 11386, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.4499999999999993},
{"step": 253, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 254.0, 1.0, 1.0, 1.0, 1.0, 1.0, 254.0, 254.0], "q_vals": [0.0, 0.0, -4.647, 0.0, 0.0, 0.0, 0.0, 0.0, -4.557, -4.557]}
{"number_of_episodes": 606, "number_of_timesteps": 11386, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.006111111111111079, "biggest_recent_change": 0.1999999999999993},
{"step": 254, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 255.0, 1.0, 1.0, 1.0, 1.0, 1.0, 255.0, 255.0], "q_vals": [0.0, 0.0, -4.629, 0.0, 0.0, 0.0, 0.0, 0.0, -4.539, -4.539]}
{"step": 255, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 256.0, 1.0, 1.0, 1.0, 1.0, 1.0, 256.0, 256.0], "q_vals": [0.0, 0.0, -4.625, 0.0, 0.0, 0.0, 0.0, 0.0, -4.534, -4.534]}
{"number_of_episodes": 612, "number_of_timesteps": 11494, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.4499999999999993},
{"step": 256, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 257.0, 1.0, 1.0, 1.0, 1.0, 1.0, 257.0, 257.0], "q_vals": [0.0, 0.0, -4.647, 0.0, 0.0, 0.0, 0.0, 0.0, -4.552, -4.552]}
{"number_of_episodes": 616, "number_of_timesteps": 11582, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.0038888888888888654, "biggest_recent_change": 0.3999999999999986},
{"step": 257, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 258.0, 1.0, 1.0, 1.0, 1.0, 1.0, 258.0, 258.0], "q_vals": [0.0, 0.0, -4.648, 0.0, 0.0, 0.0, 0.0, 0.0, -4.551, -4.551]}
{"number_of_episodes": 617, "number_of_timesteps": 11591, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.0038888888888888654, "biggest_recent_change": 0.4499999999999993},
{"step": 258, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 259.0, 1.0, 1.0, 1.0, 1.0, 1.0, 259.0, 259.0], "q_vals": [0.0, 0.0, -4.63, 0.0, 0.0, 0.0, 0.0, 0.0, -4.533, -4.533]}
{"number_of_episodes": 619, "number_of_timesteps": 11614, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.3999999999999986},
{"step": 259, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 260.0, 1.0, 1.0, 1.0, 1.0, 1.0, 260.0, 260.0], "q_vals": [0.0, 0.0, -4.636, 0.0, 0.0, 0.0, 0.0, 0.0, -4.537, -4.537]}
{"step": 260, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 261.0, 1.0, 1.0, 1.0, 1.0, 1.0, 261.0, 261.0], "q_vals": [0.0, 0.0, -4.64, 0.0, 0.0, 0.0, 0.0, 0.0, -4.539, -4.539]}
{"number_of_episodes": 624, "number_of_timesteps": 11703, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.4499999999999993},
{"step": 261, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 262.0, 1.0, 1.0, 1.0, 1.0, 1.0, 262.0, 262.0], "q_vals": [0.0, 0.0, -4.661, 0.0, 0.0, 0.0, 0.0, 0.0, -4.556, -4.556]}
{"number_of_episodes": 627, "number_of_timesteps": 11751, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.3999999999999986},
{"step": 262, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 263.0, 1.0, 1.0, 1.0, 1.0, 1.0, 263.0, 263.0], "q_vals": [0.0, 0.0, -4.672, 0.0, 0.0, 0.0, 0.0, 0.0, -4.564, -4.564]}
{"number_of_episodes": 628, "number_of_timesteps": 11771, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.34999999999999787},
{"step": 263, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 264.0, 1.0, 1.0, 1.0, 1.0, 1.0, 264.0, 264.0], "q_vals": [0.0, 0.0, -4.719, 0.0, 0.0, 0.0, 0.0, 0.0, -4.603, -4.603]}
{"number_of_episodes": 631, "number_of_timesteps": 11803, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 264, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 265.0, 1.0, 1.0, 1.0, 1.0, 1.0, 265.0, 265.0], "q_vals": [0.0, 0.0, -4.701, 0.0, 0.0, 0.0, 0.0, 0.0, -4.586, -4.586]}
{"step": 265, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 266.0, 1.0, 1.0, 1.0, 1.0, 1.0, 266.0, 266.0], "q_vals": [0.0, 0.0, -4.683, 0.0, 0.0, 0.0, 0.0, 0.0, -4.569, -4.569]}
{"step": 266, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 267.0, 1.0, 1.0, 1.0, 1.0, 1.0, 267.0, 267.0], "q_vals": [0.0, 0.0, -4.666, 0.0, 0.0, 0.0, 0.0, 0.0, -4.551, -4.551]}
{"number_of_episodes": 641, "number_of_timesteps": 12010, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.3999999999999986},
{"step": 267, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 268.0, 1.0, 1.0, 1.0, 1.0, 1.0, 268.0, 268.0], "q_vals": [0.0, 0.0, -4.672, 0.0, 0.0, 0.0, 0.0, 0.0, -4.556, -4.556]}
{"number_of_episodes": 644, "number_of_timesteps": 12047, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.3500000000000014},
{"step": 268, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 269.0, 1.0, 1.0, 1.0, 1.0, 1.0, 269.0, 269.0], "q_vals": [0.0, 0.0, -4.671, 0.0, 0.0, 0.0, 0.0, 0.0, -4.553, -4.553]}
{"number_of_episodes": 647, "number_of_timesteps": 12100, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"step": 269, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 270.0, 1.0, 1.0, 1.0, 1.0, 1.0, 270.0, 270.0], "q_vals": [0.0, 0.0, -4.654, 0.0, 0.0, 0.0, 0.0, 0.0, -4.536, -4.536]}
{"eval_score": 15.4, "number_of_episodes": 650}
{"number_of_episodes": 650, "number_of_timesteps": 12139, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.3500000000000014},
{"step": 270, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 271.0, 1.0, 1.0, 1.0, 1.0, 1.0, 271.0, 271.0], "q_vals": [0.0, 0.0, -4.636, 0.0, 0.0, 0.0, 0.0, 0.0, -4.519, -4.519]}
{"number_of_episodes": 653, "number_of_timesteps": 12188, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.5},
{"step": 271, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 272.0, 1.0, 1.0, 1.0, 1.0, 1.0, 272.0, 272.0], "q_vals": [0.0, 0.0, -4.619, 0.0, 0.0, 0.0, 0.0, 0.0, -4.504, -4.504]}
{"number_of_episodes": 657, "number_of_timesteps": 12240, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.4499999999999993},
{"step": 272, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 273.0, 1.0, 1.0, 1.0, 1.0, 1.0, 273.0, 273.0], "q_vals": [0.0, 0.0, -4.66, 0.0, 0.0, 0.0, 0.0, 0.0, -4.538, -4.538]}
{"number_of_episodes": 658, "number_of_timesteps": 12251, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.3500000000000014},
{"step": 273, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 274.0, 1.0, 1.0, 1.0, 1.0, 1.0, 274.0, 274.0], "q_vals": [0.0, 0.0, -4.666, 0.0, 0.0, 0.0, 0.0, 0.0, -4.542, -4.542]}
{"step": 274, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 275.0, 1.0, 1.0, 1.0, 1.0, 1.0, 275.0, 275.0], "q_vals": [0.0, 0.0, -4.692, 0.0, 0.0, 0.0, 0.0, 0.0, -4.564, -4.564]}
{"number_of_episodes": 665, "number_of_timesteps": 12348, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.3999999999999986},
{"step": 275, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 276.0, 1.0, 1.0, 1.0, 1.0, 1.0, 276.0, 276.0], "q_vals": [0.0, 0.0, -4.691, 0.0, 0.0, 0.0, 0.0, 0.0, -4.561, -4.561]}
{"step": 276, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 277.0, 1.0, 1.0, 1.0, 1.0, 1.0, 277.0, 277.0], "q_vals": [0.0, 0.0, -4.703, 0.0, 0.0, 0.0, 0.0, 0.0, -4.57, -4.57]}
{"number_of_episodes": 671, "number_of_timesteps": 12446, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"step": 277, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 278.0, 1.0, 1.0, 1.0, 1.0, 1.0, 278.0, 278.0], "q_vals": [0.0, 0.0, -4.708, 0.0, 0.0, 0.0, 0.0, 0.0, -4.573, -4.573]}
{"step": 278, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 279.0, 1.0, 1.0, 1.0, 1.0, 1.0, 279.0, 279.0], "q_vals": [0.0, 0.0, -4.708, 0.0, 0.0, 0.0, 0.0, 0.0, -4.571, -4.571]}
{"number_of_episodes": 677, "number_of_timesteps": 12529, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.4499999999999993},
{"step": 279, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 280.0, 1.0, 1.0, 1.0, 1.0, 1.0, 280.0, 280.0], "q_vals": [0.0, 0.0, -4.729, 0.0, 0.0, 0.0, 0.0, 0.0, -4.588, -4.588]}
{"number_of_episodes": 679, "number_of_timesteps": 12556, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.3500000000000014},
{"step": 280, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 281.0, 1.0, 1.0, 1.0, 1.0, 1.0, 281.0, 281.0], "q_vals": [0.0, 0.0, -4.712, 0.0, 0.0, 0.0, 0.0, 0.0, -4.572, -4.572]}
{"step": 281, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 282.0, 1.0, 1.0, 1.0, 1.0, 1.0, 282.0, 282.0], "q_vals": [0.0, 0.0, -4.695, 0.0, 0.0, 0.0, 0.0, 0.0, -4.556, -4.556]}
{"step": 282, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 283.0, 1.0, 1.0, 1.0, 1.0, 1.0, 283.0, 283.0], "q_vals": [0.0, 0.0, -4.718, 0.0, 0.0, 0.0, 0.0, 0.0, -4.574, -4.574]}
{"number_of_episodes": 689, "number_of_timesteps": 12713, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.009999999999999985, "biggest_recent_change": 0.3999999999999986},
{"step": 283, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 284.0, 1.0, 1.0, 1.0, 1.0, 1.0, 284.0, 284.0], "q_vals": [0.0, 0.0, -4.725, 0.0, 0.0, 0.0, 0.0, 0.0, -4.579, -4.579]}
{"number_of_episodes": 691, "number_of_timesteps": 12734, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3500000000000014},
{"step": 284, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 285.0, 1.0, 1.0, 1.0, 1.0, 1.0, 285.0, 285.0], "q_vals": [0.0, 0.0, -4.708, 0.0, 0.0, 0.0, 0.0, 0.0, -4.563, -4.563]}
{"number_of_episodes": 694, "number_of_timesteps": 12781, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.008888888888888858, "biggest_recent_change": 0.3999999999999986},
{"step": 285, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 286.0, 1.0, 1.0, 1.0, 1.0, 1.0, 286.0, 286.0], "q_vals": [0.0, 0.0, -4.714, 0.0, 0.0, 0.0, 0.0, 0.0, -4.566, -4.566]}
{"number_of_episodes": 697, "number_of_timesteps": 12818, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.008888888888888858, "biggest_recent_change": 0.34999999999999787},
{"step": 286, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 287.0, 1.0, 1.0, 1.0, 1.0, 1.0, 287.0, 287.0], "q_vals": [0.0, 0.0, -4.736, 0.0, 0.0, 0.0, 0.0, 0.0, -4.584, -4.584]}
{"number_of_episodes": 700, "number_of_timesteps": 12857, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.012777777777777801, "biggest_recent_change": 0.5},
{"step": 287, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 288.0, 1.0, 1.0, 1.0, 1.0, 1.0, 288.0, 288.0], "q_vals": [0.0, 0.0, -4.719, 0.0, 0.0, 0.0, 0.0, 0.0, -4.587, -4.587]}
{"number_of_episodes": 703, "number_of_timesteps": 12905, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.3999999999999986},
{"step": 288, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 289.0, 1.0, 1.0, 1.0, 1.0, 1.0, 289.0, 289.0], "q_vals": [0.0, 0.0, -4.722, 0.0, 0.0, 0.0, 0.0, 0.0, -4.589, -4.589]}
{"step": 289, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 290.0, 1.0, 1.0, 1.0, 1.0, 1.0, 290.0, 290.0], "q_vals": [0.0, 0.0, -4.723, 0.0, 0.0, 0.0, 0.0, 0.0, -4.588, -4.588]}
{"number_of_episodes": 708, "number_of_timesteps": 12965, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.013333333333333326, "biggest_recent_change": 0.3500000000000014},
{"step": 290, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 291.0, 1.0, 1.0, 1.0, 1.0, 1.0, 291.0, 291.0], "q_vals": [0.0, 0.0, -4.707, 0.0, 0.0, 0.0, 0.0, 0.0, -4.572, -4.572]}
{"number_of_episodes": 713, "number_of_timesteps": 13060, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.34999999999999787},
{"step": 291, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 292.0, 1.0, 1.0, 1.0, 1.0, 1.0, 292.0, 292.0], "q_vals": [0.0, 0.0, -4.741, 0.0, 0.0, 0.0, 0.0, 0.0, -4.601, -4.601]}
{"step": 292, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 293.0, 1.0, 1.0, 1.0, 1.0, 1.0, 293.0, 293.0], "q_vals": [0.0, 0.0, -4.775, 0.0, 0.0, 0.0, 0.0, 0.0, -4.63, -4.63]}
{"step": 293, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 294.0, 1.0, 1.0, 1.0, 1.0, 1.0, 294.0, 294.0], "q_vals": [0.0, 0.0, -4.776, 0.0, 0.0, 0.0, 0.0, 0.0, -4.629, -4.629]}
{"number_of_episodes": 722, "number_of_timesteps": 13200, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.009999999999999985, "biggest_recent_change": 0.5500000000000007},
{"step": 294, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 295.0, 1.0, 1.0, 1.0, 1.0, 1.0, 295.0, 295.0], "q_vals": [0.0, 0.0, -4.76, 0.0, 0.0, 0.0, 0.0, 0.0, -4.613, -4.613]}
{"number_of_episodes": 725, "number_of_timesteps": 13242, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.013333333333333326, "biggest_recent_change": 0.4499999999999993},
{"step": 295, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 296.0, 1.0, 1.0, 1.0, 1.0, 1.0, 296.0, 296.0], "q_vals": [0.0, 0.0, -4.744, 0.0, 0.0, 0.0, 0.0, 0.0, -4.598, -4.598]}
{"number_of_episodes": 726, "number_of_timesteps": 13254, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.34999999999999787},
{"step": 296, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 297.0, 1.0, 1.0, 1.0, 1.0, 1.0, 297.0, 297.0], "q_vals": [0.0, 0.0, -4.735, 0.0, 0.0, 0.0, 0.0, 0.0, -4.588, -4.588]}
{"number_of_episodes": 732, "number_of_timesteps": 13325, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.016111111111111125, "biggest_recent_change": 0.5000000000000018},
{"step": 297, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 298.0, 1.0, 1.0, 1.0, 1.0, 1.0, 298.0, 298.0], "q_vals": [0.0, 0.0, -4.754, 0.0, 0.0, 0.0, 0.0, 0.0, -4.604, -4.604]}
{"step": 298, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 299.0, 1.0, 1.0, 1.0, 1.0, 1.0, 299.0, 299.0], "q_vals": [0.0, 0.0, -4.738, 0.0, 0.0, 0.0, 0.0, 0.0, -4.588, -4.588]}
{"number_of_episodes": 734, "number_of_timesteps": 13351, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.016111111111111125, "biggest_recent_change": 0.5999999999999996},
{"step": 299, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 300.0, 1.0, 1.0, 1.0, 1.0, 1.0, 300.0, 300.0], "q_vals": [0.0, 0.0, -4.741, 0.0, 0.0, 0.0, 0.0, 0.0, -4.59, -4.59]}
{"number_of_episodes": 739, "number_of_timesteps": 13414, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.011666666666666676, "biggest_recent_change": 0.3999999999999986},
{"step": 300, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 301.0, 1.0, 1.0, 1.0, 1.0, 1.0, 301.0, 301.0], "q_vals": [0.0, 0.0, -4.726, 0.0, 0.0, 0.0, 0.0, 0.0, -4.577, -4.577]}
{"number_of_episodes": 742, "number_of_timesteps": 13480, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.013333333333333345, "biggest_recent_change": 0.5500000000000007},
{"step": 301, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 302.0, 1.0, 1.0, 1.0, 1.0, 1.0, 302.0, 302.0], "q_vals": [0.0, 0.0, -4.71, 0.0, 0.0, 0.0, 0.0, 0.0, -4.562, -4.562]}
{"step": 302, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 303.0, 1.0, 1.0, 1.0, 1.0, 1.0, 303.0, 303.0], "q_vals": [0.0, 0.0, -4.694, 0.0, 0.0, 0.0, 0.0, 0.0, -4.547, -4.547]}
{"number_of_episodes": 746, "number_of_timesteps": 13555, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 0.5000000000000018},
{"step": 303, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 304.0, 1.0, 1.0, 1.0, 1.0, 1.0, 304.0, 304.0], "q_vals": [0.0, 0.0, -4.693, 0.0, 0.0, 0.0, 0.0, 0.0, -4.544, -4.544]}
{"number_of_episodes": 747, "number_of_timesteps": 13572, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.008888888888888877, "biggest_recent_change": 0.34999999999999787},
{"step": 304, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 305.0, 1.0, 1.0, 1.0, 1.0, 1.0, 305.0, 305.0], "q_vals": [0.0, 0.0, -4.722, 0.0, 0.0, 0.0, 0.0, 0.0, -4.568, -4.568]}
{"number_of_episodes": 749, "number_of_timesteps": 13612, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.016666666666666646, "biggest_recent_change": 0.5000000000000018},
{"step": 305, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 306.0, 1.0, 1.0, 1.0, 1.0, 1.0, 306.0, 306.0], "q_vals": [0.0, 0.0, -4.724, 0.0, 0.0, 0.0, 0.0, 0.0, -4.569, -4.569]}
{"step": 306, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 307.0, 1.0, 1.0, 1.0, 1.0, 1.0, 307.0, 307.0], "q_vals": [0.0, 0.0, -4.725, 0.0, 0.0, 0.0, 0.0, 0.0, -4.569, -4.569]}
{"step": 307, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 308.0, 1.0, 1.0, 1.0, 1.0, 1.0, 308.0, 308.0], "q_vals": [0.0, 0.0, -4.739, 0.0, 0.0, 0.0, 0.0, 0.0, -4.58, -4.58]}
{"number_of_episodes": 758, "number_of_timesteps": 13776, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.016111111111111125, "biggest_recent_change": 0.5500000000000007},
{"step": 308, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 309.0, 1.0, 1.0, 1.0, 1.0, 1.0, 309.0, 309.0], "q_vals": [0.0, 0.0, -4.723, 0.0, 0.0, 0.0, 0.0, 0.0, -4.565, -4.565]}
{"number_of_episodes": 762, "number_of_timesteps": 13855, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.012777777777777782, "biggest_recent_change": 0.5000000000000018},
{"step": 309, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 310.0, 1.0, 1.0, 1.0, 1.0, 1.0, 310.0, 310.0], "q_vals": [0.0, 0.0, -4.762, 0.0, 0.0, 0.0, 0.0, 0.0, -4.597, -4.597]}
{"step": 310, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 311.0, 1.0, 1.0, 1.0, 1.0, 1.0, 311.0, 311.0], "q_vals": [0.0, 0.0, -4.787, 0.0, 0.0, 0.0, 0.0, 0.0, -4.618, -4.618]}
{"number_of_episodes": 768, "number_of_timesteps": 13930, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.013888888888888909, "biggest_recent_change": 0.3999999999999986},
{"step": 311, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 312.0, 1.0, 1.0, 1.0, 1.0, 1.0, 312.0, 312.0], "q_vals": [0.0, 0.0, -4.785, 0.0, 0.0, 0.0, 0.0, 0.0, -4.615, -4.615]}
{"number_of_episodes": 772, "number_of_timesteps": 13984, "per_episode_reward": 15.85, "episode_reward_trend_value": -0.014444444444444432, "biggest_recent_change": 0.5000000000000018},
{"step": 312, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 313.0, 1.0, 1.0, 1.0, 1.0, 1.0, 313.0, 313.0], "q_vals": [0.0, 0.0, -4.79, 0.0, 0.0, 0.0, 0.0, 0.0, -4.619, -4.619]}
{"number_of_episodes": 773, "number_of_timesteps": 13993, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.011666666666666676, "biggest_recent_change": 0.5000000000000018},
{"step": 313, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 314.0, 1.0, 1.0, 1.0, 1.0, 1.0, 314.0, 314.0], "q_vals": [0.0, 0.0, -4.797, 0.0, 0.0, 0.0, 0.0, 0.0, -4.623, -4.623]}
{"number_of_episodes": 776, "number_of_timesteps": 14029, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 0.34999999999999787},
{"step": 314, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 315.0, 1.0, 1.0, 1.0, 1.0, 1.0, 315.0, 315.0], "q_vals": [0.0, 0.0, -4.828, 0.0, 0.0, 0.0, 0.0, 0.0, -4.649, -4.649]}
{"step": 315, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 316.0, 1.0, 1.0, 1.0, 1.0, 1.0, 316.0, 316.0], "q_vals": [0.0, 0.0, -4.83, 0.0, 0.0, 0.0, 0.0, 0.0, -4.65, -4.65]}
{"eval_score": 15.0, "number_of_episodes": 782}
{"number_of_episodes": 782, "number_of_timesteps": 14136, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.018333333333333337, "biggest_recent_change": 0.45000000000000107},
{"step": 316, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 317.0, 1.0, 1.0, 1.0, 1.0, 1.0, 317.0, 317.0], "q_vals": [0.0, 0.0, -4.815, 0.0, 0.0, 0.0, 0.0, 0.0, -4.635, -4.635]}
{"step": 317, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 318.0, 1.0, 1.0, 1.0, 1.0, 1.0, 318.0, 318.0], "q_vals": [0.0, 0.0, -4.8, 0.0, 0.0, 0.0, 0.0, 0.0, -4.621, -4.621]}
{"number_of_episodes": 787, "number_of_timesteps": 14193, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.01777777777777779, "biggest_recent_change": 0.5999999999999996},
{"step": 318, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 319.0, 1.0, 1.0, 1.0, 1.0, 1.0, 319.0, 319.0], "q_vals": [0.0, 0.0, -4.806, 0.0, 0.0, 0.0, 0.0, 0.0, -4.625, -4.625]}
{"step": 319, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 320.0, 1.0, 1.0, 1.0, 1.0, 1.0, 320.0, 320.0], "q_vals": [0.0, 0.0, -4.792, 0.0, 0.0, 0.0, 0.0, 0.0, -4.612, -4.612]}
{"number_of_episodes": 795, "number_of_timesteps": 14320, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.01722222222222221, "biggest_recent_change": 0.5500000000000007},
{"step": 320, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 321.0, 1.0, 1.0, 1.0, 1.0, 1.0, 321.0, 321.0], "q_vals": [0.0, 0.0, -4.777, 0.0, 0.0, 0.0, 0.0, 0.0, -4.597, -4.597]}
{"number_of_episodes": 798, "number_of_timesteps": 14358, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.012777777777777782, "biggest_recent_change": 0.3999999999999986},
{"step": 321, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 322.0, 1.0, 1.0, 1.0, 1.0, 1.0, 322.0, 322.0], "q_vals": [0.0, 0.0, -4.762, 0.0, 0.0, 0.0, 0.0, 0.0, -4.6, -4.6]}
{"step": 322, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 323.0, 1.0, 1.0, 1.0, 1.0, 1.0, 323.0, 323.0], "q_vals": [0.0, 0.0, -4.748, 0.0, 0.0, 0.0, 0.0, 0.0, -4.598, -4.598]}
{"number_of_episodes": 805, "number_of_timesteps": 14455, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.012222222222222218, "biggest_recent_change": 0.5999999999999996},
{"step": 323, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 324.0, 1.0, 1.0, 1.0, 1.0, 1.0, 324.0, 324.0], "q_vals": [0.0, 0.0, -4.752, 0.0, 0.0, 0.0, 0.0, 0.0, -4.601, -4.601]}
{"number_of_episodes": 808, "number_of_timesteps": 14489, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.01111111111111113, "biggest_recent_change": 0.34999999999999787},
{"step": 324, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 325.0, 1.0, 1.0, 1.0, 1.0, 1.0, 325.0, 325.0], "q_vals": [0.0, 0.0, -4.758, 0.0, 0.0, 0.0, 0.0, 0.0, -4.605, -4.605]}
{"number_of_episodes": 811, "number_of_timesteps": 14544, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.01777777777777779, "biggest_recent_change": 0.3500000000000014},
{"step": 325, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 326.0, 1.0, 1.0, 1.0, 1.0, 1.0, 326.0, 326.0], "q_vals": [0.0, 0.0, -4.743, 0.0, 0.0, 0.0, 0.0, 0.0, -4.591, -4.591]}
{"number_of_episodes": 815, "number_of_timesteps": 14594, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 0.45000000000000107},
{"step": 326, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 327.0, 1.0, 1.0, 1.0, 1.0, 1.0, 327.0, 327.0], "q_vals": [0.0, 0.0, -4.729, 0.0, 0.0, 0.0, 0.0, 0.0, -4.577, -4.577]}
{"number_of_episodes": 820, "number_of_timesteps": 14657, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.3999999999999986},
{"step": 327, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 328.0, 1.0, 1.0, 1.0, 1.0, 1.0, 328.0, 328.0], "q_vals": [0.0, 0.0, -4.714, 0.0, 0.0, 0.0, 0.0, 0.0, -4.581, -4.581]}
{"number_of_episodes": 822, "number_of_timesteps": 14678, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.01444444444444445, "biggest_recent_change": 0.5000000000000018},
{"step": 328, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 329.0, 1.0, 1.0, 1.0, 1.0, 1.0, 329.0, 329.0], "q_vals": [0.0, 0.0, -4.753, 0.0, 0.0, 0.0, 0.0, 0.0, -4.614, -4.614]}
{"number_of_episodes": 825, "number_of_timesteps": 14709, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.02166666666666666, "biggest_recent_change": 0.5000000000000018},
{"step": 329, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 330.0, 1.0, 1.0, 1.0, 1.0, 1.0, 330.0, 330.0], "q_vals": [0.0, 0.0, -4.754, 0.0, 0.0, 0.0, 0.0, 0.0, -4.613, -4.613]}
{"number_of_episodes": 828, "number_of_timesteps": 14741, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 0.5999999999999996},
{"step": 330, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 331.0, 1.0, 1.0, 1.0, 1.0, 1.0, 331.0, 331.0], "q_vals": [0.0, 0.0, -4.758, 0.0, 0.0, 0.0, 0.0, 0.0, -4.616, -4.616]}
{"number_of_episodes": 830, "number_of_timesteps": 14773, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 0.5000000000000018},
{"step": 331, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 332.0, 1.0, 1.0, 1.0, 1.0, 1.0, 332.0, 332.0], "q_vals": [0.0, 0.0, -4.752, 0.0, 0.0, 0.0, 0.0, 0.0, -4.609, -4.609]}
{"number_of_episodes": 837, "number_of_timesteps": 14880, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.020555555555555553, "biggest_recent_change": 0.4499999999999993},
{"step": 332, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 333.0, 1.0, 1.0, 1.0, 1.0, 1.0, 333.0, 333.0], "q_vals": [0.0, 0.0, -4.756, 0.0, 0.0, 0.0, 0.0, 0.0, -4.611, -4.611]}
{"step": 333, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 334.0, 1.0, 1.0, 1.0, 1.0, 1.0, 334.0, 334.0], "q_vals": [0.0, 0.0, -4.757, 0.0, 0.0, 0.0, 0.0, 0.0, -4.611, -4.611]}
{"number_of_episodes": 842, "number_of_timesteps": 14930, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.019999999999999987, "biggest_recent_change": 0.5000000000000018},
{"step": 334, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 335.0, 1.0, 1.0, 1.0, 1.0, 1.0, 335.0, 335.0], "q_vals": [0.0, 0.0, -4.757, 0.0, 0.0, 0.0, 0.0, 0.0, -4.61, -4.61]}
{"number_of_episodes": 847, "number_of_timesteps": 15004, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.016666666666666646, "biggest_recent_change": 0.45000000000000107},
{"step": 335, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 336.0, 1.0, 1.0, 1.0, 1.0, 1.0, 336.0, 336.0], "q_vals": [0.0, 0.0, -4.743, 0.0, 0.0, 0.0, 0.0, 0.0, -4.596, -4.596]}
{"step": 336, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 337.0, 1.0, 1.0, 1.0, 1.0, 1.0, 337.0, 337.0], "q_vals": [0.0, 0.0, -4.729, 0.0, 0.0, 0.0, 0.0, 0.0, -4.583, -4.583]}
{"number_of_episodes": 853, "number_of_timesteps": 15077, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.013333333333333345, "biggest_recent_change": 0.34999999999999787},
{"step": 337, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 338.0, 1.0, 1.0, 1.0, 1.0, 1.0, 338.0, 338.0], "q_vals": [0.0, 0.0, -4.761, 0.0, 0.0, 0.0, 0.0, 0.0, -4.609, -4.609]}
{"number_of_episodes": 856, "number_of_timesteps": 15126, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.016111111111111125, "biggest_recent_change": 0.5000000000000018},
{"step": 338, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 339.0, 1.0, 1.0, 1.0, 1.0, 1.0, 339.0, 339.0], "q_vals": [0.0, 0.0, -4.799, 0.0, 0.0, 0.0, 0.0, 0.0, -4.642, -4.642]}
{"number_of_episodes": 862, "number_of_timesteps": 15204, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.018333333333333337, "biggest_recent_change": 0.5500000000000007},
{"step": 339, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 340.0, 1.0, 1.0, 1.0, 1.0, 1.0, 340.0, 340.0], "q_vals": [0.0, 0.0, -4.785, 0.0, 0.0, 0.0, 0.0, 0.0, -4.628, -4.628]}
{"number_of_episodes": 863, "number_of_timesteps": 15216, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.01722222222222221, "biggest_recent_change": 0.3500000000000014},
{"step": 340, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 341.0, 1.0, 1.0, 1.0, 1.0, 1.0, 341.0, 341.0], "q_vals": [0.0, 0.0, -4.771, 0.0, 0.0, 0.0, 0.0, 0.0, -4.615, -4.615]}
{"number_of_episodes": 868, "number_of_timesteps": 15270, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.016111111111111125, "biggest_recent_change": 0.4499999999999993},
{"step": 341, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 342.0, 1.0, 1.0, 1.0, 1.0, 1.0, 342.0, 342.0], "q_vals": [0.0, 0.0, -4.771, 0.0, 0.0, 0.0, 0.0, 0.0, -4.613, -4.613]}
{"step": 342, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 343.0, 1.0, 1.0, 1.0, 1.0, 1.0, 343.0, 343.0], "q_vals": [0.0, 0.0, -4.757, 0.0, 0.0, 0.0, 0.0, 0.0, -4.6, -4.6]}
{"number_of_episodes": 874, "number_of_timesteps": 15345, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.021111111111111094, "biggest_recent_change": 0.5500000000000007},
{"step": 343, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 344.0, 1.0, 1.0, 1.0, 1.0, 1.0, 344.0, 344.0], "q_vals": [0.0, 0.0, -4.743, 0.0, 0.0, 0.0, 0.0, 0.0, -4.586, -4.586]}
{"number_of_episodes": 878, "number_of_timesteps": 15390, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.45000000000000107},
{"step": 344, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 345.0, 1.0, 1.0, 1.0, 1.0, 1.0, 345.0, 345.0], "q_vals": [0.0, 0.0, -4.729, 0.0, 0.0, 0.0, 0.0, 0.0, -4.573, -4.573]}
{"number_of_episodes": 881, "number_of_timesteps": 15425, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.015000000000000017, "biggest_recent_change": 0.34999999999999787},
{"step": 345, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 346.0, 1.0, 1.0, 1.0, 1.0, 1.0, 346.0, 346.0], "q_vals": [0.0, 0.0, -4.765, 0.0, 0.0, 0.0, 0.0, 0.0, -4.603, -4.603]}
{"step": 346, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 347.0, 1.0, 1.0, 1.0, 1.0, 1.0, 347.0, 347.0], "q_vals": [0.0, 0.0, -4.751, 0.0, 0.0, 0.0, 0.0, 0.0, -4.59, -4.59]}
{"number_of_episodes": 888, "number_of_timesteps": 15507, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.020555555555555553, "biggest_recent_change": 0.5500000000000007},
{"step": 347, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 348.0, 1.0, 1.0, 1.0, 1.0, 1.0, 348.0, 348.0], "q_vals": [0.0, 0.0, -4.737, 0.0, 0.0, 0.0, 0.0, 0.0, -4.577, -4.577]}
{"number_of_episodes": 889, "number_of_timesteps": 15538, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.016666666666666646, "biggest_recent_change": 0.5000000000000018},
{"step": 348, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 349.0, 1.0, 1.0, 1.0, 1.0, 1.0, 349.0, 349.0], "q_vals": [0.0, 0.0, -4.77, 0.0, 0.0, 0.0, 0.0, 0.0, -4.605, -4.605]}
{"number_of_episodes": 891, "number_of_timesteps": 15560, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.0188888888888889, "biggest_recent_change": 0.5000000000000018},
{"step": 349, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 350.0, 1.0, 1.0, 1.0, 1.0, 1.0, 350.0, 350.0], "q_vals": [0.0, 0.0, -4.776, 0.0, 0.0, 0.0, 0.0, 0.0, -4.609, -4.609]}
{"step": 350, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 351.0, 1.0, 1.0, 1.0, 1.0, 1.0, 351.0, 351.0], "q_vals": [0.0, 0.0, -4.794, 0.0, 0.0, 0.0, 0.0, 0.0, -4.623, -4.623]}
{"number_of_episodes": 899, "number_of_timesteps": 15669, "per_episode_reward": 15.05, "episode_reward_trend_value": -0.017777777777777753, "biggest_recent_change": 0.4499999999999993},
{"step": 351, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 352.0, 1.0, 1.0, 1.0, 1.0, 1.0, 352.0, 352.0], "q_vals": [0.0, 0.0, -4.798, 0.0, 0.0, 0.0, 0.0, 0.0, -4.626, -4.626]}
{"number_of_episodes": 901, "number_of_timesteps": 15717, "per_episode_reward": 15.05, "episode_reward_trend_value": -0.01833333333333332, "biggest_recent_change": 0.4499999999999993},
{"step": 352, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 353.0, 1.0, 1.0, 1.0, 1.0, 1.0, 353.0, 353.0], "q_vals": [0.0, 0.0, -4.785, 0.0, 0.0, 0.0, 0.0, 0.0, -4.62, -4.62]}
{"step": 353, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 354.0, 1.0, 1.0, 1.0, 1.0, 1.0, 354.0, 354.0], "q_vals": [0.0, 0.0, -4.771, 0.0, 0.0, 0.0, 0.0, 0.0, -4.619, -4.619]}
{"step": 354, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 355.0, 1.0, 1.0, 1.0, 1.0, 1.0, 355.0, 355.0], "q_vals": [0.0, 0.0, -4.758, 0.0, 0.0, 0.0, 0.0, 0.0, -4.624, -4.624]}
{"eval_score": 12.1, "number_of_episodes": 911}
{"number_of_episodes": 911, "number_of_timesteps": 15853, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.021111111111111115, "biggest_recent_change": 0.5000000000000018},
{"step": 355, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 356.0, 1.0, 1.0, 1.0, 1.0, 1.0, 356.0, 356.0], "q_vals": [0.0, 0.0, -4.761, 0.0, 0.0, 0.0, 0.0, 0.0, -4.626, -4.626]}
{"number_of_episodes": 914, "number_of_timesteps": 15892, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.019444444444444424, "biggest_recent_change": 0.5999999999999996},
{"step": 356, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 357.0, 1.0, 1.0, 1.0, 1.0, 1.0, 357.0, 357.0], "q_vals": [0.0, 0.0, -4.761, 0.0, 0.0, 0.0, 0.0, 0.0, -4.624, -4.624]}
{"number_of_episodes": 918, "number_of_timesteps": 15966, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.019444444444444424, "biggest_recent_change": 0.4499999999999993},
{"step": 357, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 358.0, 1.0, 1.0, 1.0, 1.0, 1.0, 358.0, 358.0], "q_vals": [0.0, 0.0, -4.748, 0.0, 0.0, 0.0, 0.0, 0.0, -4.622, -4.622]}
{"number_of_episodes": 920, "number_of_timesteps": 15988, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0188888888888889, "biggest_recent_change": 0.5000000000000018},
{"step": 358, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 359.0, 1.0, 1.0, 1.0, 1.0, 1.0, 359.0, 359.0], "q_vals": [0.0, 0.0, -4.768, 0.0, 0.0, 0.0, 0.0, 0.0, -4.639, -4.639]}
{"number_of_episodes": 921, "number_of_timesteps": 15997, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.021111111111111115, "biggest_recent_change": 0.5000000000000018},
{"step": 359, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 360.0, 1.0, 1.0, 1.0, 1.0, 1.0, 360.0, 360.0], "q_vals": [0.0, 0.0, -4.773, 0.0, 0.0, 0.0, 0.0, 0.0, -4.642, -4.642]}
{"step": 360, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 361.0, 1.0, 1.0, 1.0, 1.0, 1.0, 361.0, 361.0], "q_vals": [0.0, 0.0, -4.793, 0.0, 0.0, 0.0, 0.0, 0.0, -4.658, -4.658]}
{"step": 361, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 362.0, 1.0, 1.0, 1.0, 1.0, 1.0, 362.0, 362.0], "q_vals": [0.0, 0.0, -4.795, 0.0, 0.0, 0.0, 0.0, 0.0, -4.659, -4.659]}
{"number_of_episodes": 934, "number_of_timesteps": 16190, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.019444444444444466, "biggest_recent_change": 0.5000000000000018},
{"step": 362, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 363.0, 1.0, 1.0, 1.0, 1.0, 1.0, 363.0, 363.0], "q_vals": [0.0, 0.0, -4.797, 0.0, 0.0, 0.0, 0.0, 0.0, -4.66, -4.66]}
{"number_of_episodes": 936, "number_of_timesteps": 16211, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.020555555555555532, "biggest_recent_change": 0.4499999999999993},
{"step": 363, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 364.0, 1.0, 1.0, 1.0, 1.0, 1.0, 364.0, 364.0], "q_vals": [0.0, 0.0, -4.784, 0.0, 0.0, 0.0, 0.0, 0.0, -4.663, -4.663]}
{"number_of_episodes": 940, "number_of_timesteps": 16260, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.019444444444444445, "biggest_recent_change": 0.4499999999999993},
{"step": 364, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 365.0, 1.0, 1.0, 1.0, 1.0, 1.0, 365.0, 365.0], "q_vals": [0.0, 0.0, -4.783, 0.0, 0.0, 0.0, 0.0, 0.0, -4.661, -4.661]}
{"number_of_episodes": 944, "number_of_timesteps": 16320, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.019999999999999987, "biggest_recent_change": 0.5999999999999996},
{"step": 365, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 366.0, 1.0, 1.0, 1.0, 1.0, 1.0, 366.0, 366.0], "q_vals": [0.0, 0.0, -4.787, 0.0, 0.0, 0.0, 0.0, 0.0, -4.663, -4.663]}
{"number_of_episodes": 947, "number_of_timesteps": 16362, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.019444444444444466, "biggest_recent_change": 0.4499999999999993},
{"step": 366, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 367.0, 1.0, 1.0, 1.0, 1.0, 1.0, 367.0, 367.0], "q_vals": [0.0, 0.0, -4.774, 0.0, 0.0, 0.0, 0.0, 0.0, -4.667, -4.667]}
{"number_of_episodes": 950, "number_of_timesteps": 16405, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.021666666666666678, "biggest_recent_change": 0.45000000000000107},
{"step": 367, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 368.0, 1.0, 1.0, 1.0, 1.0, 1.0, 368.0, 368.0], "q_vals": [0.0, 0.0, -4.761, 0.0, 0.0, 0.0, 0.0, 0.0, -4.655, -4.655]}
{"number_of_episodes": 954, "number_of_timesteps": 16448, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.018333333333333337, "biggest_recent_change": 0.5000000000000018},
{"step": 368, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 369.0, 1.0, 1.0, 1.0, 1.0, 1.0, 369.0, 369.0], "q_vals": [0.0, 0.0, -4.765, 0.0, 0.0, 0.0, 0.0, 0.0, -4.657, -4.657]}
{"number_of_episodes": 960, "number_of_timesteps": 16520, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.0188888888888889, "biggest_recent_change": 0.5500000000000007},
{"step": 369, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 370.0, 1.0, 1.0, 1.0, 1.0, 1.0, 370.0, 370.0], "q_vals": [0.0, 0.0, -4.752, 0.0, 0.0, 0.0, 0.0, 0.0, -4.644, -4.644]}
{"step": 370, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 371.0, 1.0, 1.0, 1.0, 1.0, 1.0, 371.0, 371.0], "q_vals": [0.0, 0.0, -4.752, 0.0, 0.0, 0.0, 0.0, 0.0, -4.643, -4.643]}
{"number_of_episodes": 964, "number_of_timesteps": 16561, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 0.5999999999999996},
{"step": 371, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 372.0, 1.0, 1.0, 1.0, 1.0, 1.0, 372.0, 372.0], "q_vals": [0.0, 0.0, -4.752, 0.0, 0.0, 0.0, 0.0, 0.0, -4.642, -4.642]}
{"number_of_episodes": 970, "number_of_timesteps": 16637, "per_episode_reward": 14.75, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 0.5000000000000018},
{"step": 372, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 373.0, 1.0, 1.0, 1.0, 1.0, 1.0, 373.0, 373.0], "q_vals": [0.0, 0.0, -4.775, 0.0, 0.0, 0.0, 0.0, 0.0, -4.661, -4.661]}
{"number_of_episodes": 973, "number_of_timesteps": 16669, "per_episode_reward": 14.75, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 0.4499999999999993},
{"step": 373, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 374.0, 1.0, 1.0, 1.0, 1.0, 1.0, 374.0, 374.0], "q_vals": [0.0, 0.0, -4.762, 0.0, 0.0, 0.0, 0.0, 0.0, -4.651, -4.651]}
{"number_of_episodes": 977, "number_of_timesteps": 16710, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.018333333333333358, "biggest_recent_change": 0.5000000000000018},
{"step": 374, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 375.0, 1.0, 1.0, 1.0, 1.0, 1.0, 375.0, 375.0], "q_vals": [0.0, 0.0, -4.761, 0.0, 0.0, 0.0, 0.0, 0.0, -4.649, -4.649]}
{"number_of_episodes": 980, "number_of_timesteps": 16747, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.021111111111111136, "biggest_recent_change": 0.5500000000000007},
{"step": 375, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 376.0, 1.0, 1.0, 1.0, 1.0, 1.0, 376.0, 376.0], "q_vals": [0.0, 0.0, -4.749, 0.0, 0.0, 0.0, 0.0, 0.0, -4.637, -4.637]}
{"number_of_episodes": 984, "number_of_timesteps": 16789, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.4499999999999993},
{"step": 376, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 377.0, 1.0, 1.0, 1.0, 1.0, 1.0, 377.0, 377.0], "q_vals": [0.0, 0.0, -4.736, 0.0, 0.0, 0.0, 0.0, 0.0, -4.641, -4.641]}
{"number_of_episodes": 988, "number_of_timesteps": 16842, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.019444444444444445, "biggest_recent_change": 0.5},
{"step": 377, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 378.0, 1.0, 1.0, 1.0, 1.0, 1.0, 378.0, 378.0], "q_vals": [0.0, 0.0, -4.749, 0.0, 0.0, 0.0, 0.0, 0.0, -4.651, -4.651]}
{"number_of_episodes": 991, "number_of_timesteps": 16871, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.02166666666666666, "biggest_recent_change": 0.7000000000000011},
{"step": 378, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 379.0, 1.0, 1.0, 1.0, 1.0, 1.0, 379.0, 379.0], "q_vals": [0.0, 0.0, -4.752, 0.0, 0.0, 0.0, 0.0, 0.0, -4.653, -4.653]}
{"number_of_episodes": 994, "number_of_timesteps": 16901, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.021111111111111136, "biggest_recent_change": 0.4499999999999993},
{"step": 379, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 380.0, 1.0, 1.0, 1.0, 1.0, 1.0, 380.0, 380.0], "q_vals": [0.0, 0.0, -4.756, 0.0, 0.0, 0.0, 0.0, 0.0, -4.656, -4.656]}
{"step": 380, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 381.0, 1.0, 1.0, 1.0, 1.0, 1.0, 381.0, 381.0], "q_vals": [0.0, 0.0, -4.756, 0.0, 0.0, 0.0, 0.0, 0.0, -4.654, -4.654]}
{"number_of_episodes": 1002, "number_of_timesteps": 17008, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.021111111111111115, "biggest_recent_change": 0.5999999999999996},
{"step": 381, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 382.0, 1.0, 1.0, 1.0, 1.0, 1.0, 382.0, 382.0], "q_vals": [0.0, 0.0, -4.76, 0.0, 0.0, 0.0, 0.0, 0.0, -4.657, -4.657]}
{"number_of_episodes": 1005, "number_of_timesteps": 17039, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.012777777777777782, "biggest_recent_change": 0.4499999999999993},
{"step": 382, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 383.0, 1.0, 1.0, 1.0, 1.0, 1.0, 383.0, 383.0], "q_vals": [0.0, 0.0, -4.748, 0.0, 0.0, 0.0, 0.0, 0.0, -4.657, -4.657]}
{"number_of_episodes": 1008, "number_of_timesteps": 17079, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.020555555555555532, "biggest_recent_change": 0.5},
{"step": 383, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 384.0, 1.0, 1.0, 1.0, 1.0, 1.0, 384.0, 384.0], "q_vals": [0.0, 0.0, -4.788, 0.0, 0.0, 0.0, 0.0, 0.0, -4.691, -4.691]}
{"number_of_episodes": 1011, "number_of_timesteps": 17114, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.026111111111111085, "biggest_recent_change": 0.8499999999999996},
{"step": 384, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 385.0, 1.0, 1.0, 1.0, 1.0, 1.0, 385.0, 385.0], "q_vals": [0.0, 0.0, -4.775, 0.0, 0.0, 0.0, 0.0, 0.0, -4.679, -4.679]}
{"step": 385, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 386.0, 1.0, 1.0, 1.0, 1.0, 1.0, 386.0, 386.0], "q_vals": [0.0, 0.0, -4.8, 0.0, 0.0, 0.0, 0.0, 0.0, -4.699, -4.699]}
{"number_of_episodes": 1020, "number_of_timesteps": 17241, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.01722222222222223, "biggest_recent_change": 0.5},
{"step": 386, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 387.0, 1.0, 1.0, 1.0, 1.0, 1.0, 387.0, 387.0], "q_vals": [0.0, 0.0, -4.828, 0.0, 0.0, 0.0, 0.0, 0.0, -4.723, -4.723]}
{"step": 387, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 388.0, 1.0, 1.0, 1.0, 1.0, 1.0, 388.0, 388.0], "q_vals": [0.0, 0.0, -4.842, 0.0, 0.0, 0.0, 0.0, 0.0, -4.734, -4.734]}
{"number_of_episodes": 1027, "number_of_timesteps": 17320, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.014999999999999996, "biggest_recent_change": 0.40000000000000036},
{"step": 388, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 389.0, 1.0, 1.0, 1.0, 1.0, 1.0, 389.0, 389.0], "q_vals": [0.0, 0.0, -4.847, 0.0, 0.0, 0.0, 0.0, 0.0, -4.737, -4.737]}
{"number_of_episodes": 1031, "number_of_timesteps": 17369, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 0.5000000000000018},
{"step": 389, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 390.0, 1.0, 1.0, 1.0, 1.0, 1.0, 390.0, 390.0], "q_vals": [0.0, 0.0, -4.868, 0.0, 0.0, 0.0, 0.0, 0.0, -4.754, -4.754]}
{"number_of_episodes": 1035, "number_of_timesteps": 17410, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.02333333333333331, "biggest_recent_change": 0.8499999999999996},
{"step": 390, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 391.0, 1.0, 1.0, 1.0, 1.0, 1.0, 391.0, 391.0], "q_vals": [0.0, 0.0, -4.856, 0.0, 0.0, 0.0, 0.0, 0.0, -4.742, -4.742]}
{"number_of_episodes": 1039, "number_of_timesteps": 17455, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.02166666666666666, "biggest_recent_change": 0.5999999999999996},
{"step": 391, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 392.0, 1.0, 1.0, 1.0, 1.0, 1.0, 392.0, 392.0], "q_vals": [0.0, 0.0, -4.859, 0.0, 0.0, 0.0, 0.0, 0.0, -4.744, -4.744]}
{"eval_score": 11.8, "number_of_episodes": 1043}
{"step": 392, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 393.0, 1.0, 1.0, 1.0, 1.0, 1.0, 393.0, 393.0], "q_vals": [0.0, 0.0, -4.846, 0.0, 0.0, 0.0, 0.0, 0.0, -4.732, -4.732]}
{"number_of_episodes": 1045, "number_of_timesteps": 17520, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.8499999999999996},
{"step": 393, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 394.0, 1.0, 1.0, 1.0, 1.0, 1.0, 394.0, 394.0], "q_vals": [0.0, 0.0, -4.834, 0.0, 0.0, 0.0, 0.0, 0.0, -4.72, -4.72]}
{"number_of_episodes": 1050, "number_of_timesteps": 17580, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.012222222222222218, "biggest_recent_change": 0.4499999999999993},
{"step": 394, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 395.0, 1.0, 1.0, 1.0, 1.0, 1.0, 395.0, 395.0], "q_vals": [0.0, 0.0, -4.822, 0.0, 0.0, 0.0, 0.0, 0.0, -4.721, -4.721]}
{"number_of_episodes": 1054, "number_of_timesteps": 17628, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.011666666666666655, "biggest_recent_change": 0.3000000000000007},
{"step": 395, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 396.0, 1.0, 1.0, 1.0, 1.0, 1.0, 396.0, 396.0], "q_vals": [0.0, 0.0, -4.825, 0.0, 0.0, 0.0, 0.0, 0.0, -4.723, -4.723]}
{"number_of_episodes": 1056, "number_of_timesteps": 17647, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 0.5},
{"step": 396, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 397.0, 1.0, 1.0, 1.0, 1.0, 1.0, 397.0, 397.0], "q_vals": [0.0, 0.0, -4.82, 0.0, 0.0, 0.0, 0.0, 0.0, -4.717, -4.717]}
{"number_of_episodes": 1063, "number_of_timesteps": 17731, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.023888888888888894, "biggest_recent_change": 0.7000000000000011},
{"step": 397, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 398.0, 1.0, 1.0, 1.0, 1.0, 1.0, 398.0, 398.0], "q_vals": [0.0, 0.0, -4.823, 0.0, 0.0, 0.0, 0.0, 0.0, -4.719, -4.719]}
{"number_of_episodes": 1066, "number_of_timesteps": 17765, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.024444444444444456, "biggest_recent_change": 0.45000000000000107},
{"step": 398, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 399.0, 1.0, 1.0, 1.0, 1.0, 1.0, 399.0, 399.0], "q_vals": [0.0, 0.0, -4.811, 0.0, 0.0, 0.0, 0.0, 0.0, -4.707, -4.707]}
{"number_of_episodes": 1068, "number_of_timesteps": 17784, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.022777777777777765, "biggest_recent_change": 0.8499999999999996},
{"step": 399, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 400.0, 1.0, 1.0, 1.0, 1.0, 1.0, 400.0, 400.0], "q_vals": [0.0, 0.0, -4.799, 0.0, 0.0, 0.0, 0.0, 0.0, -4.696, -4.696]}
{"step": 400, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 401.0, 1.0, 1.0, 1.0, 1.0, 1.0, 401.0, 401.0], "q_vals": [0.0, 0.0, -4.787, 0.0, 0.0, 0.0, 0.0, 0.0, -4.684, -4.684]}
{"number_of_episodes": 1077, "number_of_timesteps": 17888, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.024444444444444456, "biggest_recent_change": 0.7000000000000011},
{"step": 401, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 402.0, 1.0, 1.0, 1.0, 1.0, 1.0, 402.0, 402.0], "q_vals": [0.0, 0.0, -4.792, 0.0, 0.0, 0.0, 0.0, 0.0, -4.687, -4.687]}
{"number_of_episodes": 1080, "number_of_timesteps": 17920, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.016111111111111104, "biggest_recent_change": 0.4499999999999993},
{"step": 402, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 403.0, 1.0, 1.0, 1.0, 1.0, 1.0, 403.0, 403.0], "q_vals": [0.0, 0.0, -4.796, 0.0, 0.0, 0.0, 0.0, 0.0, -4.69, -4.69]}
{"number_of_episodes": 1085, "number_of_timesteps": 17979, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.023333333333333327, "biggest_recent_change": 0.4499999999999993},
{"step": 403, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 404.0, 1.0, 1.0, 1.0, 1.0, 1.0, 404.0, 404.0], "q_vals": [0.0, 0.0, -4.8, 0.0, 0.0, 0.0, 0.0, 0.0, -4.692, -4.692]}
{"number_of_episodes": 1087, "number_of_timesteps": 18002, "per_episode_reward": 14.35, "episode_reward_trend_value": -0.024444444444444456, "biggest_recent_change": 0.7000000000000011},
{"step": 404, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 405.0, 1.0, 1.0, 1.0, 1.0, 1.0, 405.0, 405.0], "q_vals": [0.0, 0.0, -4.816, 0.0, 0.0, 0.0, 0.0, 0.0, -4.704, -4.704]}
{"number_of_episodes": 1093, "number_of_timesteps": 18065, "per_episode_reward": 14.35, "episode_reward_trend_value": -0.0188888888888889, "biggest_recent_change": 0.34999999999999964},
{"step": 405, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 406.0, 1.0, 1.0, 1.0, 1.0, 1.0, 406.0, 406.0], "q_vals": [0.0, 0.0, -4.804, 0.0, 0.0, 0.0, 0.0, 0.0, -4.693, -4.693]}
{"number_of_episodes": 1097, "number_of_timesteps": 18107, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.025, "biggest_recent_change": 0.45000000000000107},
{"step": 406, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 407.0, 1.0, 1.0, 1.0, 1.0, 1.0, 407.0, 407.0], "q_vals": [0.0, 0.0, -4.792, 0.0, 0.0, 0.0, 0.0, 0.0, -4.681, -4.681]}
{"number_of_episodes": 1100, "number_of_timesteps": 18135, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.02333333333333331, "biggest_recent_change": 0.4499999999999993},
{"step": 407, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 408.0, 1.0, 1.0, 1.0, 1.0, 1.0, 408.0, 408.0], "q_vals": [0.0, 0.0, -4.793, 0.0, 0.0, 0.0, 0.0, 0.0, -4.681, -4.681]}
{"number_of_episodes": 1102, "number_of_timesteps": 18159, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.02333333333333331, "biggest_recent_change": 0.8499999999999996},
{"step": 408, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 409.0, 1.0, 1.0, 1.0, 1.0, 1.0, 409.0, 409.0], "q_vals": [0.0, 0.0, -4.781, 0.0, 0.0, 0.0, 0.0, 0.0, -4.67, -4.67]}
{"number_of_episodes": 1107, "number_of_timesteps": 18231, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 0.45000000000000107},
{"step": 409, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 410.0, 1.0, 1.0, 1.0, 1.0, 1.0, 410.0, 410.0], "q_vals": [0.0, 0.0, -4.811, 0.0, 0.0, 0.0, 0.0, 0.0, -4.695, -4.695]}
{"step": 410, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 411.0, 1.0, 1.0, 1.0, 1.0, 1.0, 411.0, 411.0], "q_vals": [0.0, 0.0, -4.8, 0.0, 0.0, 0.0, 0.0, 0.0, -4.684, -4.684]}
{"step": 411, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 412.0, 1.0, 1.0, 1.0, 1.0, 1.0, 412.0, 412.0], "q_vals": [0.0, 0.0, -4.821, 0.0, 0.0, 0.0, 0.0, 0.0, -4.701, -4.701]}
{"step": 412, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 413.0, 1.0, 1.0, 1.0, 1.0, 1.0, 413.0, 413.0], "q_vals": [0.0, 0.0, -4.846, 0.0, 0.0, 0.0, 0.0, 0.0, -4.723, -4.723]}
{"number_of_episodes": 1122, "number_of_timesteps": 18412, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.02166666666666666, "biggest_recent_change": 0.4499999999999993},
{"step": 413, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 414.0, 1.0, 1.0, 1.0, 1.0, 1.0, 414.0, 414.0], "q_vals": [0.0, 0.0, -4.851, 0.0, 0.0, 0.0, 0.0, 0.0, -4.725, -4.725]}
{"number_of_episodes": 1125, "number_of_timesteps": 18446, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.014999999999999996, "biggest_recent_change": 0.4499999999999993},
{"step": 414, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 415.0, 1.0, 1.0, 1.0, 1.0, 1.0, 415.0, 415.0], "q_vals": [0.0, 0.0, -4.839, 0.0, 0.0, 0.0, 0.0, 0.0, -4.726, -4.726]}
{"number_of_episodes": 1128, "number_of_timesteps": 18479, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.026111111111111106, "biggest_recent_change": 0.45000000000000107},
{"step": 415, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 416.0, 1.0, 1.0, 1.0, 1.0, 1.0, 416.0, 416.0], "q_vals": [0.0, 0.0, -4.827, 0.0, 0.0, 0.0, 0.0, 0.0, -4.714, -4.714]}
{"number_of_episodes": 1134, "number_of_timesteps": 18542, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.021111111111111115, "biggest_recent_change": 0.45000000000000107},
{"step": 416, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 417.0, 1.0, 1.0, 1.0, 1.0, 1.0, 417.0, 417.0], "q_vals": [0.0, 0.0, -4.853, 0.0, 0.0, 0.0, 0.0, 0.0, -4.736, -4.736]}
{"number_of_episodes": 1136, "number_of_timesteps": 18571, "per_episode_reward": 14.05, "episode_reward_trend_value": -0.019999999999999987, "biggest_recent_change": 0.4499999999999993},
{"step": 417, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 418.0, 1.0, 1.0, 1.0, 1.0, 1.0, 418.0, 418.0], "q_vals": [0.0, 0.0, -4.856, 0.0, 0.0, 0.0, 0.0, 0.0, -4.738, -4.738]}
{"number_of_episodes": 1140, "number_of_timesteps": 18615, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.011666666666666676, "biggest_recent_change": 0.34999999999999964},
{"step": 418, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 419.0, 1.0, 1.0, 1.0, 1.0, 1.0, 419.0, 419.0], "q_vals": [0.0, 0.0, -4.845, 0.0, 0.0, 0.0, 0.0, 0.0, -4.741, -4.741]}
{"number_of_episodes": 1143, "number_of_timesteps": 18649, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.5},
{"step": 419, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 420.0, 1.0, 1.0, 1.0, 1.0, 1.0, 420.0, 420.0], "q_vals": [0.0, 0.0, -4.852, 0.0, 0.0, 0.0, 0.0, 0.0, -4.747, -4.747]}
{"number_of_episodes": 1146, "number_of_timesteps": 18686, "per_episode_reward": 13.85, "episode_reward_trend_value": -0.027222222222222238, "biggest_recent_change": 0.8499999999999996},
{"step": 420, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 421.0, 1.0, 1.0, 1.0, 1.0, 1.0, 421.0, 421.0], "q_vals": [0.0, 0.0, -4.841, 0.0, 0.0, 0.0, 0.0, 0.0, -4.736, -4.736]}
{"step": 421, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 422.0, 1.0, 1.0, 1.0, 1.0, 1.0, 422.0, 422.0], "q_vals": [0.0, 0.0, -4.829, 0.0, 0.0, 0.0, 0.0, 0.0, -4.724, -4.724]}
{"number_of_episodes": 1153, "number_of_timesteps": 18782, "per_episode_reward": 13.85, "episode_reward_trend_value": -0.01722222222222223, "biggest_recent_change": 0.34999999999999964},
{"step": 422, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 423.0, 1.0, 1.0, 1.0, 1.0, 1.0, 423.0, 423.0], "q_vals": [0.0, 0.0, -4.824, 0.0, 0.0, 0.0, 0.0, 0.0, -4.719, -4.719]}
{"number_of_episodes": 1157, "number_of_timesteps": 18827, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.023888888888888894, "biggest_recent_change": 0.8499999999999996},
{"step": 423, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 424.0, 1.0, 1.0, 1.0, 1.0, 1.0, 424.0, 424.0], "q_vals": [0.0, 0.0, -4.813, 0.0, 0.0, 0.0, 0.0, 0.0, -4.708, -4.708]}
{"number_of_episodes": 1162, "number_of_timesteps": 18886, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.02166666666666666, "biggest_recent_change": 0.5},
{"step": 424, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 425.0, 1.0, 1.0, 1.0, 1.0, 1.0, 425.0, 425.0], "q_vals": [0.0, 0.0, -4.839, 0.0, 0.0, 0.0, 0.0, 0.0, -4.73, -4.73]}
{"number_of_episodes": 1164, "number_of_timesteps": 18920, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.34999999999999964},
{"step": 425, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 426.0, 1.0, 1.0, 1.0, 1.0, 1.0, 426.0, 426.0], "q_vals": [0.0, 0.0, -4.827, 0.0, 0.0, 0.0, 0.0, 0.0, -4.732, -4.732]}
{"number_of_episodes": 1168, "number_of_timesteps": 18967, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.027777777777777755, "biggest_recent_change": 0.7000000000000011},
{"step": 426, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 427.0, 1.0, 1.0, 1.0, 1.0, 1.0, 427.0, 427.0], "q_vals": [0.0, 0.0, -4.832, 0.0, 0.0, 0.0, 0.0, 0.0, -4.735, -4.735]}
{"eval_score": 10.9, "number_of_episodes": 1173}
{"number_of_episodes": 1173, "number_of_timesteps": 19024, "per_episode_reward": 13.8, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 0.34999999999999964},
{"step": 427, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 428.0, 1.0, 1.0, 1.0, 1.0, 1.0, 428.0, 428.0], "q_vals": [0.0, 0.0, -4.836, 0.0, 0.0, 0.0, 0.0, 0.0, -4.737, -4.737]}
{"number_of_episodes": 1174, "number_of_timesteps": 19041, "per_episode_reward": 13.8, "episode_reward_trend_value": -0.014444444444444432, "biggest_recent_change": 0.5},
{"step": 428, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 429.0, 1.0, 1.0, 1.0, 1.0, 1.0, 429.0, 429.0], "q_vals": [0.0, 0.0, -4.838, 0.0, 0.0, 0.0, 0.0, 0.0, -4.738, -4.738]}
{"number_of_episodes": 1180, "number_of_timesteps": 19110, "per_episode_reward": 13.75, "episode_reward_trend_value": -0.023888888888888894, "biggest_recent_change": 0.45000000000000107},
{"step": 429, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 430.0, 1.0, 1.0, 1.0, 1.0, 1.0, 430.0, 430.0], "q_vals": [0.0, 0.0, -4.86, 0.0, 0.0, 0.0, 0.0, 0.0, -4.756, -4.756]}
{"number_of_episodes": 1184, "number_of_timesteps": 19154, "per_episode_reward": 13.65, "episode_reward_trend_value": -0.012777777777777782, "biggest_recent_change": 0.34999999999999964},
{"step": 430, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 431.0, 1.0, 1.0, 1.0, 1.0, 1.0, 431.0, 431.0], "q_vals": [0.0, 0.0, -4.849, 0.0, 0.0, 0.0, 0.0, 0.0, -4.755, -4.755]}
{"number_of_episodes": 1187, "number_of_timesteps": 19181, "per_episode_reward": 13.65, "episode_reward_trend_value": -0.026666666666666672, "biggest_recent_change": 0.5},
{"step": 431, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 432.0, 1.0, 1.0, 1.0, 1.0, 1.0, 432.0, 432.0], "q_vals": [0.0, 0.0, -4.838, 0.0, 0.0, 0.0, 0.0, 0.0, -4.744, -4.744]}
{"number_of_episodes": 1190, "number_of_timesteps": 19215, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.016111111111111125, "biggest_recent_change": 0.29999999999999893},
{"step": 432, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 433.0, 1.0, 1.0, 1.0, 1.0, 1.0, 433.0, 433.0], "q_vals": [0.0, 0.0, -4.838, 0.0, 0.0, 0.0, 0.0, 0.0, -4.743, -4.743]}
{"number_of_episodes": 1195, "number_of_timesteps": 19278, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.020555555555555553, "biggest_recent_change": 0.3000000000000007},
{"step": 433, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 434.0, 1.0, 1.0, 1.0, 1.0, 1.0, 434.0, 434.0], "q_vals": [0.0, 0.0, -4.868, 0.0, 0.0, 0.0, 0.0, 0.0, -4.769, -4.769]}
{"number_of_episodes": 1196, "number_of_timesteps": 19298, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.025, "biggest_recent_change": 0.75},
{"step": 434, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 435.0, 1.0, 1.0, 1.0, 1.0, 1.0, 435.0, 435.0], "q_vals": [0.0, 0.0, -4.857, 0.0, 0.0, 0.0, 0.0, 0.0, -4.758, -4.758]}
{"number_of_episodes": 1200, "number_of_timesteps": 19350, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 0.5},
{"step": 435, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 436.0, 1.0, 1.0, 1.0, 1.0, 1.0, 436.0, 436.0], "q_vals": [0.0, 0.0, -4.846, 0.0, 0.0, 0.0, 0.0, 0.0, -4.747, -4.747]}
{"number_of_episodes": 1205, "number_of_timesteps": 19410, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.01444444444444445, "biggest_recent_change": 0.5},
{"step": 436, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 437.0, 1.0, 1.0, 1.0, 1.0, 1.0, 437.0, 437.0], "q_vals": [0.0, 0.0, -4.846, 0.0, 0.0, 0.0, 0.0, 0.0, -4.746, -4.746]}
{"number_of_episodes": 1207, "number_of_timesteps": 19436, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.34999999999999964},
{"step": 437, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 438.0, 1.0, 1.0, 1.0, 1.0, 1.0, 438.0, 438.0], "q_vals": [0.0, 0.0, -4.835, 0.0, 0.0, 0.0, 0.0, 0.0, -4.744, -4.744]}
{"number_of_episodes": 1211, "number_of_timesteps": 19482, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.013333333333333345, "biggest_recent_change": 0.29999999999999893},
{"step": 438, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 439.0, 1.0, 1.0, 1.0, 1.0, 1.0, 439.0, 439.0], "q_vals": [0.0, 0.0, -4.838, 0.0, 0.0, 0.0, 0.0, 0.0, -4.746, -4.746]}
{"step": 439, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 440.0, 1.0, 1.0, 1.0, 1.0, 1.0, 440.0, 440.0], "q_vals": [0.0, 0.0, -4.827, 0.0, 0.0, 0.0, 0.0, 0.0, -4.749, -4.749]}
{"number_of_episodes": 1218, "number_of_timesteps": 19571, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.021111111111111115, "biggest_recent_change": 0.8000000000000007},
{"step": 440, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 441.0, 1.0, 1.0, 1.0, 1.0, 1.0, 441.0, 441.0], "q_vals": [0.0, 0.0, -4.83, 0.0, 0.0, 0.0, 0.0, 0.0, -4.751, -4.751]}
{"number_of_episodes": 1221, "number_of_timesteps": 19612, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.030555555555555575, "biggest_recent_change": 0.7000000000000011},
{"step": 441, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 442.0, 1.0, 1.0, 1.0, 1.0, 1.0, 442.0, 442.0], "q_vals": [0.0, 0.0, -4.833, 0.0, 0.0, 0.0, 0.0, 0.0, -4.752, -4.752]}
{"number_of_episodes": 1226, "number_of_timesteps": 19671, "per_episode_reward": 13.55, "episode_reward_trend_value": -0.025555555555555543, "biggest_recent_change": 0.75},
{"step": 442, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 443.0, 1.0, 1.0, 1.0, 1.0, 1.0, 443.0, 443.0], "q_vals": [0.0, 0.0, -4.823, 0.0, 0.0, 0.0, 0.0, 0.0, -4.742, -4.742]}
{"number_of_episodes": 1229, "number_of_timesteps": 19700, "per_episode_reward": 13.55, "episode_reward_trend_value": -0.013333333333333326, "biggest_recent_change": 0.34999999999999964},
{"step": 443, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 444.0, 1.0, 1.0, 1.0, 1.0, 1.0, 444.0, 444.0], "q_vals": [0.0, 0.0, -4.812, 0.0, 0.0, 0.0, 0.0, 0.0, -4.74, -4.74]}
{"number_of_episodes": 1230, "number_of_timesteps": 19710, "per_episode_reward": 13.5, "episode_reward_trend_value": -0.023888888888888894, "biggest_recent_change": 0.5},
{"step": 444, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 445.0, 1.0, 1.0, 1.0, 1.0, 1.0, 445.0, 445.0], "q_vals": [0.0, 0.0, -4.801, 0.0, 0.0, 0.0, 0.0, 0.0, -4.73, -4.73]}
{"step": 445, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 446.0, 1.0, 1.0, 1.0, 1.0, 1.0, 446.0, 446.0], "q_vals": [0.0, 0.0, -4.79, 0.0, 0.0, 0.0, 0.0, 0.0, -4.72, -4.72]}
{"number_of_episodes": 1238, "number_of_timesteps": 19832, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.025, "biggest_recent_change": 0.8000000000000007},
{"step": 446, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 447.0, 1.0, 1.0, 1.0, 1.0, 1.0, 447.0, 447.0], "q_vals": [0.0, 0.0, -4.795, 0.0, 0.0, 0.0, 0.0, 0.0, -4.723, -4.723]}
{"step": 447, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 448.0, 1.0, 1.0, 1.0, 1.0, 1.0, 448.0, 448.0], "q_vals": [0.0, 0.0, -4.805, 0.0, 0.0, 0.0, 0.0, 0.0, -4.731, -4.731]}
{"number_of_episodes": 1242, "number_of_timesteps": 19873, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.025555555555555543, "biggest_recent_change": 0.8499999999999996},
{"step": 448, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 449.0, 1.0, 1.0, 1.0, 1.0, 1.0, 449.0, 449.0], "q_vals": [0.0, 0.0, -4.794, 0.0, 0.0, 0.0, 0.0, 0.0, -4.72, -4.72]}
{"number_of_episodes": 1249, "number_of_timesteps": 19997, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.02166666666666666, "biggest_recent_change": 0.8000000000000007},
{"step": 449, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 450.0, 1.0, 1.0, 1.0, 1.0, 1.0, 450.0, 450.0], "q_vals": [0.0, 0.0, -4.794, 0.0, 0.0, 0.0, 0.0, 0.0, -4.719, -4.719]}
{"number_of_episodes": 1251, "number_of_timesteps": 20015, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.014444444444444432, "biggest_recent_change": 0.34999999999999964},
{"step": 450, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 451.0, 1.0, 1.0, 1.0, 1.0, 1.0, 451.0, 451.0], "q_vals": [0.0, 0.0, -4.784, 0.0, 0.0, 0.0, 0.0, 0.0, -4.72, -4.72]}
{"number_of_episodes": 1254, "number_of_timesteps": 20048, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 0.3000000000000007},
{"step": 451, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 452.0, 1.0, 1.0, 1.0, 1.0, 1.0, 452.0, 452.0], "q_vals": [0.0, 0.0, -4.796, 0.0, 0.0, 0.0, 0.0, 0.0, -4.73, -4.73]}
{"number_of_episodes": 1258, "number_of_timesteps": 20095, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.75},
{"step": 452, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 453.0, 1.0, 1.0, 1.0, 1.0, 1.0, 453.0, 453.0], "q_vals": [0.0, 0.0, -4.785, 0.0, 0.0, 0.0, 0.0, 0.0, -4.72, -4.72]}
{"number_of_episodes": 1260, "number_of_timesteps": 20124, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.8000000000000007},
{"step": 453, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 454.0, 1.0, 1.0, 1.0, 1.0, 1.0, 454.0, 454.0], "q_vals": [0.0, 0.0, -4.792, 0.0, 0.0, 0.0, 0.0, 0.0, -4.724, -4.724]}
{"number_of_episodes": 1265, "number_of_timesteps": 20197, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.027222222222222214, "biggest_recent_change": 0.7000000000000011},
{"step": 454, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 455.0, 1.0, 1.0, 1.0, 1.0, 1.0, 455.0, 455.0], "q_vals": [0.0, 0.0, -4.791, 0.0, 0.0, 0.0, 0.0, 0.0, -4.723, -4.723]}
{"number_of_episodes": 1266, "number_of_timesteps": 20208, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.025555555555555543, "biggest_recent_change": 0.5},
{"step": 455, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 456.0, 1.0, 1.0, 1.0, 1.0, 1.0, 456.0, 456.0], "q_vals": [0.0, 0.0, -4.809, 0.0, 0.0, 0.0, 0.0, 0.0, -4.737, -4.737]}
{"number_of_episodes": 1268, "number_of_timesteps": 20245, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.019444444444444445, "biggest_recent_change": 0.3000000000000007},
{"step": 456, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 457.0, 1.0, 1.0, 1.0, 1.0, 1.0, 457.0, 457.0], "q_vals": [0.0, 0.0, -4.83, 0.0, 0.0, 0.0, 0.0, 0.0, -4.755, -4.755]}
{"number_of_episodes": 1271, "number_of_timesteps": 20285, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 0.5},
{"step": 457, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 458.0, 1.0, 1.0, 1.0, 1.0, 1.0, 458.0, 458.0], "q_vals": [0.0, 0.0, -4.819, 0.0, 0.0, 0.0, 0.0, 0.0, -4.744, -4.744]}
{"step": 458, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 459.0, 1.0, 1.0, 1.0, 1.0, 1.0, 459.0, 459.0], "q_vals": [0.0, 0.0, -4.842, 0.0, 0.0, 0.0, 0.0, 0.0, -4.763, -4.763]}
{"number_of_episodes": 1276, "number_of_timesteps": 20370, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.016111111111111104, "biggest_recent_change": 0.8000000000000007},
{"step": 459, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 460.0, 1.0, 1.0, 1.0, 1.0, 1.0, 460.0, 460.0], "q_vals": [0.0, 0.0, -4.842, 0.0, 0.0, 0.0, 0.0, 0.0, -4.762, -4.762]}
{"step": 460, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 461.0, 1.0, 1.0, 1.0, 1.0, 1.0, 461.0, 461.0], "q_vals": [0.0, 0.0, -4.849, 0.0, 0.0, 0.0, 0.0, 0.0, -4.768, -4.768]}
{"number_of_episodes": 1282, "number_of_timesteps": 20460, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.026666666666666672, "biggest_recent_change": 0.7000000000000011},
{"step": 461, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 462.0, 1.0, 1.0, 1.0, 1.0, 1.0, 462.0, 462.0], "q_vals": [0.0, 0.0, -4.859, 0.0, 0.0, 0.0, 0.0, 0.0, -4.775, -4.775]}
{"number_of_episodes": 1283, "number_of_timesteps": 20473, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.3000000000000007},
{"step": 462, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 463.0, 1.0, 1.0, 1.0, 1.0, 1.0, 463.0, 463.0], "q_vals": [0.0, 0.0, -4.876, 0.0, 0.0, 0.0, 0.0, 0.0, -4.789, -4.789]}
{"number_of_episodes": 1286, "number_of_timesteps": 20524, "per_episode_reward": 13.45, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 0.5},
{"step": 463, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 464.0, 1.0, 1.0, 1.0, 1.0, 1.0, 464.0, 464.0], "q_vals": [0.0, 0.0, -4.865, 0.0, 0.0, 0.0, 0.0, 0.0, -4.779, -4.779]}
{"number_of_episodes": 1289, "number_of_timesteps": 20594, "per_episode_reward": 13.45, "episode_reward_trend_value": -0.023888888888888894, "biggest_recent_change": 0.5},
{"step": 464, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 465.0, 1.0, 1.0, 1.0, 1.0, 1.0, 465.0, 465.0], "q_vals": [0.0, 0.0, -4.889, 0.0, 0.0, 0.0, 0.0, 0.0, -4.798, -4.798]}
{"number_of_episodes": 1293, "number_of_timesteps": 20657, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.014444444444444432, "biggest_recent_change": 0.29999999999999893},
{"step": 465, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 466.0, 1.0, 1.0, 1.0, 1.0, 1.0, 466.0, 466.0], "q_vals": [0.0, 0.0, -4.892, 0.0, 0.0, 0.0, 0.0, 0.0, -4.8, -4.8]}
{"number_of_episodes": 1296, "number_of_timesteps": 20701, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 0.8499999999999996},
{"step": 466, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 467.0, 1.0, 1.0, 1.0, 1.0, 1.0, 467.0, 467.0], "q_vals": [0.0, 0.0, -4.881, 0.0, 0.0, 0.0, 0.0, 0.0, -4.789, -4.789]}
{"number_of_episodes": 1299, "number_of_timesteps": 20733, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 0.5},
{"step": 467, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 468.0, 1.0, 1.0, 1.0, 1.0, 1.0, 468.0, 468.0], "q_vals": [0.0, 0.0, -4.915, 0.0, 0.0, 0.0, 0.0, 0.0, -4.818, -4.818]}
{"eval_score": 14.3, "number_of_episodes": 1304}
{"number_of_episodes": 1304, "number_of_timesteps": 20827, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.5},
{"step": 468, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 469.0, 1.0, 1.0, 1.0, 1.0, 1.0, 469.0, 469.0], "q_vals": [0.0, 0.0, -4.915, 0.0, 0.0, 0.0, 0.0, 0.0, -4.817, -4.817]}
{"step": 469, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 470.0, 1.0, 1.0, 1.0, 1.0, 1.0, 470.0, 470.0], "q_vals": [0.0, 0.0, -4.941, 0.0, 0.0, 0.0, 0.0, 0.0, -4.839, -4.839]}
{"number_of_episodes": 1309, "number_of_timesteps": 20890, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.014999999999999996, "biggest_recent_change": 0.3000000000000007},
{"step": 470, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 471.0, 1.0, 1.0, 1.0, 1.0, 1.0, 471.0, 471.0], "q_vals": [0.0, 0.0, -4.957, 0.0, 0.0, 0.0, 0.0, 0.0, -4.852, -4.852]}
{"step": 471, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 472.0, 1.0, 1.0, 1.0, 1.0, 1.0, 472.0, 472.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.861, -4.861]}
{"number_of_episodes": 1317, "number_of_timesteps": 20987, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.34999999999999964},
{"step": 472, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 473.0, 1.0, 1.0, 1.0, 1.0, 1.0, 473.0, 473.0], "q_vals": [0.0, 0.0, -4.958, 0.0, 0.0, 0.0, 0.0, 0.0, -4.862, -4.862]}
{"number_of_episodes": 1319, "number_of_timesteps": 21009, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 0.7000000000000011},
{"step": 473, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 474.0, 1.0, 1.0, 1.0, 1.0, 1.0, 474.0, 474.0], "q_vals": [0.0, 0.0, -4.957, 0.0, 0.0, 0.0, 0.0, 0.0, -4.861, -4.861]}
{"number_of_episodes": 1323, "number_of_timesteps": 21069, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 0.8000000000000007},
{"step": 474, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 475.0, 1.0, 1.0, 1.0, 1.0, 1.0, 475.0, 475.0], "q_vals": [0.0, 0.0, -4.958, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"number_of_episodes": 1327, "number_of_timesteps": 21128, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 0.75},
{"step": 475, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 476.0, 1.0, 1.0, 1.0, 1.0, 1.0, 476.0, 476.0], "q_vals": [0.0, 0.0, -4.948, 0.0, 0.0, 0.0, 0.0, 0.0, -4.85, -4.85]}
{"number_of_episodes": 1330, "number_of_timesteps": 21160, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.012222222222222218, "biggest_recent_change": 0.34999999999999964},
{"step": 476, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 477.0, 1.0, 1.0, 1.0, 1.0, 1.0, 477.0, 477.0], "q_vals": [0.0, 0.0, -4.938, 0.0, 0.0, 0.0, 0.0, 0.0, -4.842, -4.842]}
{"number_of_episodes": 1335, "number_of_timesteps": 21211, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.012777777777777782, "biggest_recent_change": 0.5},
{"step": 477, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 478.0, 1.0, 1.0, 1.0, 1.0, 1.0, 478.0, 478.0], "q_vals": [0.0, 0.0, -4.927, 0.0, 0.0, 0.0, 0.0, 0.0, -4.832, -4.832]}
{"number_of_episodes": 1336, "number_of_timesteps": 21220, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.012777777777777782, "biggest_recent_change": 0.3000000000000007},
{"step": 478, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 479.0, 1.0, 1.0, 1.0, 1.0, 1.0, 479.0, 479.0], "q_vals": [0.0, 0.0, -4.953, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"step": 479, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 480.0, 1.0, 1.0, 1.0, 1.0, 1.0, 480.0, 480.0], "q_vals": [0.0, 0.0, -4.943, 0.0, 0.0, 0.0, 0.0, 0.0, -4.844, -4.844]}
{"number_of_episodes": 1345, "number_of_timesteps": 21353, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.016111111111111104, "biggest_recent_change": 0.5},
{"step": 480, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 481.0, 1.0, 1.0, 1.0, 1.0, 1.0, 481.0, 481.0], "q_vals": [0.0, 0.0, -4.932, 0.0, 0.0, 0.0, 0.0, 0.0, -4.834, -4.834]}
{"number_of_episodes": 1346, "number_of_timesteps": 21372, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.25},
{"step": 481, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 482.0, 1.0, 1.0, 1.0, 1.0, 1.0, 482.0, 482.0], "q_vals": [0.0, 0.0, -4.962, 0.0, 0.0, 0.0, 0.0, 0.0, -4.859, -4.859]}
{"number_of_episodes": 1351, "number_of_timesteps": 21427, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.8000000000000007},
{"step": 482, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 483.0, 1.0, 1.0, 1.0, 1.0, 1.0, 483.0, 483.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"number_of_episodes": 1355, "number_of_timesteps": 21476, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.016111111111111104, "biggest_recent_change": 0.5},
{"step": 483, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 484.0, 1.0, 1.0, 1.0, 1.0, 1.0, 484.0, 484.0], "q_vals": [0.0, 0.0, -4.97, 0.0, 0.0, 0.0, 0.0, 0.0, -4.864, -4.864]}
{"step": 484, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 485.0, 1.0, 1.0, 1.0, 1.0, 1.0, 485.0, 485.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.862, -4.862]}
{"number_of_episodes": 1361, "number_of_timesteps": 21547, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.014444444444444432, "biggest_recent_change": 0.4499999999999993},
{"step": 485, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 486.0, 1.0, 1.0, 1.0, 1.0, 1.0, 486.0, 486.0], "q_vals": [0.0, 0.0, -4.971, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"number_of_episodes": 1364, "number_of_timesteps": 21593, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.021111111111111115, "biggest_recent_change": 0.75},
{"step": 486, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 487.0, 1.0, 1.0, 1.0, 1.0, 1.0, 487.0, 487.0], "q_vals": [0.0, 0.0, -4.961, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 1367, "number_of_timesteps": 21638, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.012222222222222218, "biggest_recent_change": 0.8000000000000007},
{"step": 487, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 488.0, 1.0, 1.0, 1.0, 1.0, 1.0, 488.0, 488.0], "q_vals": [0.0, 0.0, -4.962, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 1370, "number_of_timesteps": 21676, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.25},
{"step": 488, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 489.0, 1.0, 1.0, 1.0, 1.0, 1.0, 489.0, 489.0], "q_vals": [0.0, 0.0, -4.952, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"number_of_episodes": 1373, "number_of_timesteps": 21720, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.25},
{"step": 489, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 490.0, 1.0, 1.0, 1.0, 1.0, 1.0, 490.0, 490.0], "q_vals": [0.0, 0.0, -4.977, 0.0, 0.0, 0.0, 0.0, 0.0, -4.876, -4.876]}
{"step": 490, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 491.0, 1.0, 1.0, 1.0, 1.0, 1.0, 491.0, 491.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"number_of_episodes": 1379, "number_of_timesteps": 21808, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.20000000000000107},
{"step": 491, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 492.0, 1.0, 1.0, 1.0, 1.0, 1.0, 492.0, 492.0], "q_vals": [0.0, 0.0, -4.966, 0.0, 0.0, 0.0, 0.0, 0.0, -4.876, -4.876]}
{"number_of_episodes": 1382, "number_of_timesteps": 21854, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.5},
{"step": 492, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 493.0, 1.0, 1.0, 1.0, 1.0, 1.0, 493.0, 493.0], "q_vals": [0.0, 0.0, -4.956, 0.0, 0.0, 0.0, 0.0, 0.0, -4.867, -4.867]}
{"number_of_episodes": 1385, "number_of_timesteps": 21905, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.019444444444444445, "biggest_recent_change": 0.75},
{"step": 493, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 494.0, 1.0, 1.0, 1.0, 1.0, 1.0, 494.0, 494.0], "q_vals": [0.0, 0.0, -4.946, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"number_of_episodes": 1391, "number_of_timesteps": 21975, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.016111111111111104, "biggest_recent_change": 0.5},
{"step": 494, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 495.0, 1.0, 1.0, 1.0, 1.0, 1.0, 495.0, 495.0], "q_vals": [0.0, 0.0, -4.948, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 1392, "number_of_timesteps": 21984, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.4499999999999993},
{"step": 495, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 496.0, 1.0, 1.0, 1.0, 1.0, 1.0, 496.0, 496.0], "q_vals": [0.0, 0.0, -4.939, 0.0, 0.0, 0.0, 0.0, 0.0, -4.849, -4.849]}
{"number_of_episodes": 1395, "number_of_timesteps": 22026, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.8000000000000007},
{"step": 496, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 497.0, 1.0, 1.0, 1.0, 1.0, 1.0, 497.0, 497.0], "q_vals": [0.0, 0.0, -4.931, 0.0, 0.0, 0.0, 0.0, 0.0, -4.841, -4.841]}
{"number_of_episodes": 1399, "number_of_timesteps": 22080, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.25},
{"step": 497, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 498.0, 1.0, 1.0, 1.0, 1.0, 1.0, 498.0, 498.0], "q_vals": [0.0, 0.0, -4.921, 0.0, 0.0, 0.0, 0.0, 0.0, -4.842, -4.842]}
{"step": 498, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 499.0, 1.0, 1.0, 1.0, 1.0, 1.0, 499.0, 499.0], "q_vals": [0.0, 0.0, -4.923, 0.0, 0.0, 0.0, 0.0, 0.0, -4.843, -4.843]}
{"number_of_episodes": 1407, "number_of_timesteps": 22182, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 499, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0, 500.0], "q_vals": [0.0, 0.0, -4.924, 0.0, 0.0, 0.0, 0.0, 0.0, -4.842, -4.842]}
{"number_of_episodes": 1410, "number_of_timesteps": 22216, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.20000000000000107},
{"step": 500, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 501.0, 1.0, 1.0, 1.0, 1.0, 1.0, 501.0, 501.0], "q_vals": [0.0, 0.0, -4.925, 0.0, 0.0, 0.0, 0.0, 0.0, -4.842, -4.842]}
{"number_of_episodes": 1411, "number_of_timesteps": 22230, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.012777777777777782, "biggest_recent_change": 0.5},
{"step": 501, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 502.0, 1.0, 1.0, 1.0, 1.0, 1.0, 502.0, 502.0], "q_vals": [0.0, 0.0, -4.915, 0.0, 0.0, 0.0, 0.0, 0.0, -4.833, -4.833]}
{"number_of_episodes": 1416, "number_of_timesteps": 22299, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.014444444444444432, "biggest_recent_change": 0.5},
{"step": 502, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 503.0, 1.0, 1.0, 1.0, 1.0, 1.0, 503.0, 503.0], "q_vals": [0.0, 0.0, -4.914, 0.0, 0.0, 0.0, 0.0, 0.0, -4.83, -4.83]}
{"number_of_episodes": 1421, "number_of_timesteps": 22370, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.019999999999999987, "biggest_recent_change": 0.5},
{"step": 503, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 504.0, 1.0, 1.0, 1.0, 1.0, 1.0, 504.0, 504.0], "q_vals": [0.0, 0.0, -4.941, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"number_of_episodes": 1422, "number_of_timesteps": 22380, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.20000000000000107},
{"step": 504, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 505.0, 1.0, 1.0, 1.0, 1.0, 1.0, 505.0, 505.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"step": 505, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 506.0, 1.0, 1.0, 1.0, 1.0, 1.0, 506.0, 506.0], "q_vals": [0.0, 0.0, -4.944, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"number_of_episodes": 1429, "number_of_timesteps": 22461, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.5},
{"step": 506, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 507.0, 1.0, 1.0, 1.0, 1.0, 1.0, 507.0, 507.0], "q_vals": [0.0, 0.0, -4.934, 0.0, 0.0, 0.0, 0.0, 0.0, -4.845, -4.845]}
{"eval_score": 12.7, "number_of_episodes": 1434}
{"number_of_episodes": 1434, "number_of_timesteps": 22511, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 507, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 508.0, 1.0, 1.0, 1.0, 1.0, 1.0, 508.0, 508.0], "q_vals": [0.0, 0.0, -4.934, 0.0, 0.0, 0.0, 0.0, 0.0, -4.844, -4.844]}
{"number_of_episodes": 1435, "number_of_timesteps": 22526, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 508, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 509.0, 1.0, 1.0, 1.0, 1.0, 1.0, 509.0, 509.0], "q_vals": [0.0, 0.0, -4.957, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"step": 509, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 510.0, 1.0, 1.0, 1.0, 1.0, 1.0, 510.0, 510.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"number_of_episodes": 1443, "number_of_timesteps": 22658, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.013333333333333326, "biggest_recent_change": 0.5},
{"step": 510, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 511.0, 1.0, 1.0, 1.0, 1.0, 1.0, 511.0, 511.0], "q_vals": [0.0, 0.0, -4.966, 0.0, 0.0, 0.0, 0.0, 0.0, -4.869, -4.869]}
{"number_of_episodes": 1445, "number_of_timesteps": 22686, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 511, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 512.0, 1.0, 1.0, 1.0, 1.0, 1.0, 512.0, 512.0], "q_vals": [0.0, 0.0, -4.968, 0.0, 0.0, 0.0, 0.0, 0.0, -4.87, -4.87]}
{"step": 512, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 513.0, 1.0, 1.0, 1.0, 1.0, 1.0, 513.0, 513.0], "q_vals": [0.0, 0.0, -4.971, 0.0, 0.0, 0.0, 0.0, 0.0, -4.871, -4.871]}
{"number_of_episodes": 1451, "number_of_timesteps": 22754, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 0.5},
{"step": 513, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 514.0, 1.0, 1.0, 1.0, 1.0, 1.0, 514.0, 514.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 1453, "number_of_timesteps": 22782, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.75},
{"step": 514, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 515.0, 1.0, 1.0, 1.0, 1.0, 1.0, 515.0, 515.0], "q_vals": [0.0, 0.0, -4.983, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"number_of_episodes": 1458, "number_of_timesteps": 22842, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 515, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 516.0, 1.0, 1.0, 1.0, 1.0, 1.0, 516.0, 516.0], "q_vals": [0.0, 0.0, -4.973, 0.0, 0.0, 0.0, 0.0, 0.0, -4.877, -4.877]}
{"number_of_episodes": 1461, "number_of_timesteps": 22900, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 516, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 517.0, 1.0, 1.0, 1.0, 1.0, 1.0, 517.0, 517.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"step": 517, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 518.0, 1.0, 1.0, 1.0, 1.0, 1.0, 518.0, 518.0], "q_vals": [0.0, 0.0, -4.966, 0.0, 0.0, 0.0, 0.0, 0.0, -4.87, -4.87]}
{"number_of_episodes": 1466, "number_of_timesteps": 22972, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.5},
{"step": 518, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 519.0, 1.0, 1.0, 1.0, 1.0, 1.0, 519.0, 519.0], "q_vals": [0.0, 0.0, -4.958, 0.0, 0.0, 0.0, 0.0, 0.0, -4.862, -4.862]}
{"number_of_episodes": 1469, "number_of_timesteps": 23012, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.012222222222222218, "biggest_recent_change": 0.5},
{"step": 519, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 520.0, 1.0, 1.0, 1.0, 1.0, 1.0, 520.0, 520.0], "q_vals": [0.0, 0.0, -4.949, 0.0, 0.0, 0.0, 0.0, 0.0, -4.852, -4.852]}
{"number_of_episodes": 1473, "number_of_timesteps": 23091, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.20000000000000107},
{"step": 520, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 521.0, 1.0, 1.0, 1.0, 1.0, 1.0, 521.0, 521.0], "q_vals": [0.0, 0.0, -4.949, 0.0, 0.0, 0.0, 0.0, 0.0, -4.851, -4.851]}
{"number_of_episodes": 1476, "number_of_timesteps": 23144, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.013333333333333326, "biggest_recent_change": 0.5},
{"step": 521, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 522.0, 1.0, 1.0, 1.0, 1.0, 1.0, 522.0, 522.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.869, -4.869]}
{"number_of_episodes": 1478, "number_of_timesteps": 23167, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 522, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 523.0, 1.0, 1.0, 1.0, 1.0, 1.0, 523.0, 523.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.868, -4.868]}
{"step": 523, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 524.0, 1.0, 1.0, 1.0, 1.0, 1.0, 524.0, 524.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.875, -4.875]}
{"step": 524, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 525.0, 1.0, 1.0, 1.0, 1.0, 1.0, 525.0, 525.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.885, -4.885]}
{"number_of_episodes": 1488, "number_of_timesteps": 23333, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.012222222222222218, "biggest_recent_change": 0.4499999999999993},
{"step": 525, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 526.0, 1.0, 1.0, 1.0, 1.0, 1.0, 526.0, 526.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.883, -4.883]}
{"number_of_episodes": 1490, "number_of_timesteps": 23353, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.013333333333333326, "biggest_recent_change": 0.5},
{"step": 526, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 527.0, 1.0, 1.0, 1.0, 1.0, 1.0, 527.0, 527.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 1496, "number_of_timesteps": 23437, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 527, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 528.0, 1.0, 1.0, 1.0, 1.0, 1.0, 528.0, 528.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 1498, "number_of_timesteps": 23463, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.20000000000000107},
{"step": 528, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 529.0, 1.0, 1.0, 1.0, 1.0, 1.0, 529.0, 529.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"step": 529, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 530.0, 1.0, 1.0, 1.0, 1.0, 1.0, 530.0, 530.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"number_of_episodes": 1505, "number_of_timesteps": 23544, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.011666666666666655, "biggest_recent_change": 0.4499999999999993},
{"step": 530, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 531.0, 1.0, 1.0, 1.0, 1.0, 1.0, 531.0, 531.0], "q_vals": [0.0, 0.0, -4.983, 0.0, 0.0, 0.0, 0.0, 0.0, -4.872, -4.872]}
{"number_of_episodes": 1509, "number_of_timesteps": 23595, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 531, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 532.0, 1.0, 1.0, 1.0, 1.0, 1.0, 532.0, 532.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.882, -4.882]}
{"step": 532, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 533.0, 1.0, 1.0, 1.0, 1.0, 1.0, 533.0, 533.0], "q_vals": [0.0, 0.0, -4.996, 0.0, 0.0, 0.0, 0.0, 0.0, -4.882, -4.882]}
{"number_of_episodes": 1513, "number_of_timesteps": 23638, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.012222222222222218, "biggest_recent_change": 0.5},
{"step": 533, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 534.0, 1.0, 1.0, 1.0, 1.0, 1.0, 534.0, 534.0], "q_vals": [0.0, 0.0, -5.008, 0.0, 0.0, 0.0, 0.0, 0.0, -4.892, -4.892]}
{"number_of_episodes": 1514, "number_of_timesteps": 23653, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 534, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 535.0, 1.0, 1.0, 1.0, 1.0, 1.0, 535.0, 535.0], "q_vals": [0.0, 0.0, -4.999, 0.0, 0.0, 0.0, 0.0, 0.0, -4.891, -4.891]}
{"step": 535, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 536.0, 1.0, 1.0, 1.0, 1.0, 1.0, 536.0, 536.0], "q_vals": [0.0, 0.0, -5.011, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"number_of_episodes": 1521, "number_of_timesteps": 23774, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.5},
{"step": 536, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 537.0, 1.0, 1.0, 1.0, 1.0, 1.0, 537.0, 537.0], "q_vals": [0.0, 0.0, -5.002, 0.0, 0.0, 0.0, 0.0, 0.0, -4.892, -4.892]}
{"number_of_episodes": 1524, "number_of_timesteps": 23852, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.3000000000000007},
{"step": 537, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 538.0, 1.0, 1.0, 1.0, 1.0, 1.0, 538.0, 538.0], "q_vals": [0.0, 0.0, -4.998, 0.0, 0.0, 0.0, 0.0, 0.0, -4.887, -4.887]}
{"number_of_episodes": 1527, "number_of_timesteps": 23895, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 538, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 539.0, 1.0, 1.0, 1.0, 1.0, 1.0, 539.0, 539.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.896, -4.896]}
{"number_of_episodes": 1529, "number_of_timesteps": 23922, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.5},
{"step": 539, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 540.0, 1.0, 1.0, 1.0, 1.0, 1.0, 540.0, 540.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.886, -4.886]}
{"number_of_episodes": 1532, "number_of_timesteps": 23967, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 540, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 541.0, 1.0, 1.0, 1.0, 1.0, 1.0, 541.0, 541.0], "q_vals": [0.0, 0.0, -4.978, 0.0, 0.0, 0.0, 0.0, 0.0, -4.885, -4.885]}
{"step": 541, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 542.0, 1.0, 1.0, 1.0, 1.0, 1.0, 542.0, 542.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.883, -4.883]}
{"number_of_episodes": 1539, "number_of_timesteps": 24079, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.5},
{"step": 542, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 543.0, 1.0, 1.0, 1.0, 1.0, 1.0, 543.0, 543.0], "q_vals": [0.0, 0.0, -4.96, 0.0, 0.0, 0.0, 0.0, 0.0, -4.874, -4.874]}
{"number_of_episodes": 1542, "number_of_timesteps": 24115, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 543, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 544.0, 1.0, 1.0, 1.0, 1.0, 1.0, 544.0, 544.0], "q_vals": [0.0, 0.0, -4.964, 0.0, 0.0, 0.0, 0.0, 0.0, -4.877, -4.877]}
{"number_of_episodes": 1544, "number_of_timesteps": 24141, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 544, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 545.0, 1.0, 1.0, 1.0, 1.0, 1.0, 545.0, 545.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.897, -4.897]}
{"number_of_episodes": 1547, "number_of_timesteps": 24186, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 545, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 546.0, 1.0, 1.0, 1.0, 1.0, 1.0, 546.0, 546.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.9, -4.9]}
{"number_of_episodes": 1552, "number_of_timesteps": 24264, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 0.75},
{"step": 546, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 547.0, 1.0, 1.0, 1.0, 1.0, 1.0, 547.0, 547.0], "q_vals": [0.0, 0.0, -4.983, 0.0, 0.0, 0.0, 0.0, 0.0, -4.891, -4.891]}
{"step": 547, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 548.0, 1.0, 1.0, 1.0, 1.0, 1.0, 548.0, 548.0], "q_vals": [0.0, 0.0, -4.974, 0.0, 0.0, 0.0, 0.0, 0.0, -4.882, -4.882]}
{"number_of_episodes": 1558, "number_of_timesteps": 24342, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 548, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 549.0, 1.0, 1.0, 1.0, 1.0, 1.0, 549.0, 549.0], "q_vals": [0.0, 0.0, -4.974, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 1559, "number_of_timesteps": 24353, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.012222222222222218, "biggest_recent_change": 0.5},
{"step": 549, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 550.0, 1.0, 1.0, 1.0, 1.0, 1.0, 550.0, 550.0], "q_vals": [0.0, 0.0, -4.973, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"eval_score": 13.4, "number_of_episodes": 1564}
{"number_of_episodes": 1564, "number_of_timesteps": 24420, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 550, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 551.0, 1.0, 1.0, 1.0, 1.0, 1.0, 551.0, 551.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"number_of_episodes": 1565, "number_of_timesteps": 24433, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 551, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 552.0, 1.0, 1.0, 1.0, 1.0, 1.0, 552.0, 552.0], "q_vals": [0.0, 0.0, -4.963, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"number_of_episodes": 1566, "number_of_timesteps": 24448, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"step": 552, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 553.0, 1.0, 1.0, 1.0, 1.0, 1.0, 553.0, 553.0], "q_vals": [0.0, 0.0, -4.964, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"step": 553, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 554.0, 1.0, 1.0, 1.0, 1.0, 1.0, 554.0, 554.0], "q_vals": [0.0, 0.0, -4.963, 0.0, 0.0, 0.0, 0.0, 0.0, -4.877, -4.877]}
{"number_of_episodes": 1571, "number_of_timesteps": 24545, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 554, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 555.0, 1.0, 1.0, 1.0, 1.0, 1.0, 555.0, 555.0], "q_vals": [0.0, 0.0, -4.958, 0.0, 0.0, 0.0, 0.0, 0.0, -4.872, -4.872]}
{"number_of_episodes": 1578, "number_of_timesteps": 24675, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.5},
{"step": 555, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 556.0, 1.0, 1.0, 1.0, 1.0, 1.0, 556.0, 556.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 1580, "number_of_timesteps": 24696, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.011666666666666655, "biggest_recent_change": 0.75},
{"step": 556, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 557.0, 1.0, 1.0, 1.0, 1.0, 1.0, 557.0, 557.0], "q_vals": [0.0, 0.0, -4.96, 0.0, 0.0, 0.0, 0.0, 0.0, -4.872, -4.872]}
{"number_of_episodes": 1583, "number_of_timesteps": 24730, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 557, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 558.0, 1.0, 1.0, 1.0, 1.0, 1.0, 558.0, 558.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"number_of_episodes": 1586, "number_of_timesteps": 24770, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.5},
{"step": 558, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 559.0, 1.0, 1.0, 1.0, 1.0, 1.0, 559.0, 559.0], "q_vals": [0.0, 0.0, -4.943, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"step": 559, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 560.0, 1.0, 1.0, 1.0, 1.0, 1.0, 560.0, 560.0], "q_vals": [0.0, 0.0, -4.934, 0.0, 0.0, 0.0, 0.0, 0.0, -4.846, -4.846]}
{"step": 560, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 561.0, 1.0, 1.0, 1.0, 1.0, 1.0, 561.0, 561.0], "q_vals": [0.0, 0.0, -4.925, 0.0, 0.0, 0.0, 0.0, 0.0, -4.837, -4.837]}
{"number_of_episodes": 1593, "number_of_timesteps": 24875, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 561, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 562.0, 1.0, 1.0, 1.0, 1.0, 1.0, 562.0, 562.0], "q_vals": [0.0, 0.0, -4.916, 0.0, 0.0, 0.0, 0.0, 0.0, -4.829, -4.829]}
{"step": 562, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 563.0, 1.0, 1.0, 1.0, 1.0, 1.0, 563.0, 563.0], "q_vals": [0.0, 0.0, -4.907, 0.0, 0.0, 0.0, 0.0, 0.0, -4.82, -4.82]}
{"number_of_episodes": 1599, "number_of_timesteps": 24972, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 563, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 564.0, 1.0, 1.0, 1.0, 1.0, 1.0, 564.0, 564.0], "q_vals": [0.0, 0.0, -4.912, 0.0, 0.0, 0.0, 0.0, 0.0, -4.823, -4.823]}
{"number_of_episodes": 1601, "number_of_timesteps": 25005, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 564, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 565.0, 1.0, 1.0, 1.0, 1.0, 1.0, 565.0, 565.0], "q_vals": [0.0, 0.0, -4.912, 0.0, 0.0, 0.0, 0.0, 0.0, -4.822, -4.822]}
{"number_of_episodes": 1605, "number_of_timesteps": 25064, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 565, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 566.0, 1.0, 1.0, 1.0, 1.0, 1.0, 566.0, 566.0], "q_vals": [0.0, 0.0, -4.903, 0.0, 0.0, 0.0, 0.0, 0.0, -4.823, -4.823]}
{"number_of_episodes": 1605, "number_of_timesteps": 25064, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 566, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 567.0, 1.0, 1.0, 1.0, 1.0, 1.0, 567.0, 567.0], "q_vals": [0.0, 0.0, -4.895, 0.0, 0.0, 0.0, 0.0, 0.0, -4.815, -4.815]}
{"number_of_episodes": 1611, "number_of_timesteps": 25169, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 567, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 568.0, 1.0, 1.0, 1.0, 1.0, 1.0, 568.0, 568.0], "q_vals": [0.0, 0.0, -4.906, 0.0, 0.0, 0.0, 0.0, 0.0, -4.824, -4.824]}
{"step": 568, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 569.0, 1.0, 1.0, 1.0, 1.0, 1.0, 569.0, 569.0], "q_vals": [0.0, 0.0, -4.927, 0.0, 0.0, 0.0, 0.0, 0.0, -4.841, -4.841]}
{"number_of_episodes": 1616, "number_of_timesteps": 25256, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 569, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 570.0, 1.0, 1.0, 1.0, 1.0, 1.0, 570.0, 570.0], "q_vals": [0.0, 0.0, -4.927, 0.0, 0.0, 0.0, 0.0, 0.0, -4.841, -4.841]}
{"step": 570, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 571.0, 1.0, 1.0, 1.0, 1.0, 1.0, 571.0, 571.0], "q_vals": [0.0, 0.0, -4.945, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"step": 571, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 572.0, 1.0, 1.0, 1.0, 1.0, 1.0, 572.0, 572.0], "q_vals": [0.0, 0.0, -4.946, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"number_of_episodes": 1626, "number_of_timesteps": 25391, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 572, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 573.0, 1.0, 1.0, 1.0, 1.0, 1.0, 573.0, 573.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.847, -4.847]}
{"number_of_episodes": 1630, "number_of_timesteps": 25439, "per_episode_reward": 13.25, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.1999999999999993},
{"step": 573, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 574.0, 1.0, 1.0, 1.0, 1.0, 1.0, 574.0, 574.0], "q_vals": [0.0, 0.0, -4.938, 0.0, 0.0, 0.0, 0.0, 0.0, -4.847, -4.847]}
{"number_of_episodes": 1634, "number_of_timesteps": 25491, "per_episode_reward": 13.25, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 574, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 575.0, 1.0, 1.0, 1.0, 1.0, 1.0, 575.0, 575.0], "q_vals": [0.0, 0.0, -4.938, 0.0, 0.0, 0.0, 0.0, 0.0, -4.846, -4.846]}
{"number_of_episodes": 1635, "number_of_timesteps": 25510, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 575, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 576.0, 1.0, 1.0, 1.0, 1.0, 1.0, 576.0, 576.0], "q_vals": [0.0, 0.0, -4.941, 0.0, 0.0, 0.0, 0.0, 0.0, -4.848, -4.848]}
{"number_of_episodes": 1641, "number_of_timesteps": 25574, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 576, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 577.0, 1.0, 1.0, 1.0, 1.0, 1.0, 577.0, 577.0], "q_vals": [0.0, 0.0, -4.94, 0.0, 0.0, 0.0, 0.0, 0.0, -4.846, -4.846]}
{"number_of_episodes": 1644, "number_of_timesteps": 25624, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 577, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 578.0, 1.0, 1.0, 1.0, 1.0, 1.0, 578.0, 578.0], "q_vals": [0.0, 0.0, -4.939, 0.0, 0.0, 0.0, 0.0, 0.0, -4.844, -4.844]}
{"step": 578, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 579.0, 1.0, 1.0, 1.0, 1.0, 1.0, 579.0, 579.0], "q_vals": [0.0, 0.0, -4.939, 0.0, 0.0, 0.0, 0.0, 0.0, -4.843, -4.843]}
{"step": 579, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 580.0, 1.0, 1.0, 1.0, 1.0, 1.0, 580.0, 580.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.845, -4.845]}
{"number_of_episodes": 1653, "number_of_timesteps": 25755, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 580, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 581.0, 1.0, 1.0, 1.0, 1.0, 1.0, 581.0, 581.0], "q_vals": [0.0, 0.0, -4.956, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"number_of_episodes": 1656, "number_of_timesteps": 25798, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 581, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 582.0, 1.0, 1.0, 1.0, 1.0, 1.0, 582.0, 582.0], "q_vals": [0.0, 0.0, -4.948, 0.0, 0.0, 0.0, 0.0, 0.0, -4.849, -4.849]}
{"number_of_episodes": 1658, "number_of_timesteps": 25822, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
{"step": 582, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 583.0, 1.0, 1.0, 1.0, 1.0, 1.0, 583.0, 583.0], "q_vals": [0.0, 0.0, -4.947, 0.0, 0.0, 0.0, 0.0, 0.0, -4.847, -4.847]}
{"step": 583, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 584.0, 1.0, 1.0, 1.0, 1.0, 1.0, 584.0, 584.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.849, -4.849]}
{"number_of_episodes": 1664, "number_of_timesteps": 25915, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 584, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 585.0, 1.0, 1.0, 1.0, 1.0, 1.0, 585.0, 585.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.85, -4.85]}
{"step": 585, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 586.0, 1.0, 1.0, 1.0, 1.0, 1.0, 586.0, 586.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.849, -4.849]}
{"number_of_episodes": 1672, "number_of_timesteps": 26032, "per_episode_reward": 13.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 586, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 587.0, 1.0, 1.0, 1.0, 1.0, 1.0, 587.0, 587.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.856, -4.856]}
{"step": 587, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 588.0, 1.0, 1.0, 1.0, 1.0, 1.0, 588.0, 588.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"number_of_episodes": 1678, "number_of_timesteps": 26094, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 588, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 589.0, 1.0, 1.0, 1.0, 1.0, 1.0, 589.0, 589.0], "q_vals": [0.0, 0.0, -4.943, 0.0, 0.0, 0.0, 0.0, 0.0, -4.852, -4.852]}
{"number_of_episodes": 1682, "number_of_timesteps": 26147, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 589, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 590.0, 1.0, 1.0, 1.0, 1.0, 1.0, 590.0, 590.0], "q_vals": [0.0, 0.0, -4.944, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"step": 590, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 591.0, 1.0, 1.0, 1.0, 1.0, 1.0, 591.0, 591.0], "q_vals": [0.0, 0.0, -4.945, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"eval_score": 12.7, "number_of_episodes": 1690}
{"number_of_episodes": 1690, "number_of_timesteps": 26250, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 591, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 592.0, 1.0, 1.0, 1.0, 1.0, 1.0, 592.0, 592.0], "q_vals": [0.0, 0.0, -4.966, 0.0, 0.0, 0.0, 0.0, 0.0, -4.87, -4.87]}
{"number_of_episodes": 1694, "number_of_timesteps": 26293, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 592, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 593.0, 1.0, 1.0, 1.0, 1.0, 1.0, 593.0, 593.0], "q_vals": [0.0, 0.0, -4.987, 0.0, 0.0, 0.0, 0.0, 0.0, -4.888, -4.888]}
{"step": 593, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 594.0, 1.0, 1.0, 1.0, 1.0, 1.0, 594.0, 594.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.882, -4.882]}
{"number_of_episodes": 1701, "number_of_timesteps": 26374, "per_episode_reward": 13.25, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 594, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 595.0, 1.0, 1.0, 1.0, 1.0, 1.0, 595.0, 595.0], "q_vals": [0.0, 0.0, -4.983, 0.0, 0.0, 0.0, 0.0, 0.0, -4.883, -4.883]}
{"step": 595, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 596.0, 1.0, 1.0, 1.0, 1.0, 1.0, 596.0, 596.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.88, -4.88]}
{"number_of_episodes": 1710, "number_of_timesteps": 26481, "per_episode_reward": 13.15, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 596, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 597.0, 1.0, 1.0, 1.0, 1.0, 1.0, 597.0, 597.0], "q_vals": [0.0, 0.0, -4.982, 0.0, 0.0, 0.0, 0.0, 0.0, -4.88, -4.88]}
{"number_of_episodes": 1711, "number_of_timesteps": 26491, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.25},
{"step": 597, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 598.0, 1.0, 1.0, 1.0, 1.0, 1.0, 598.0, 598.0], "q_vals": [0.0, 0.0, -4.973, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"step": 598, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 599.0, 1.0, 1.0, 1.0, 1.0, 1.0, 599.0, 599.0], "q_vals": [0.0, 0.0, -4.965, 0.0, 0.0, 0.0, 0.0, 0.0, -4.88, -4.88]}
{"number_of_episodes": 1718, "number_of_timesteps": 26576, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 599, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 600.0, 1.0, 1.0, 1.0, 1.0, 1.0, 600.0, 600.0], "q_vals": [0.0, 0.0, -4.968, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"step": 600, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 601.0, 1.0, 1.0, 1.0, 1.0, 1.0, 601.0, 601.0], "q_vals": [0.0, 0.0, -4.96, 0.0, 0.0, 0.0, 0.0, 0.0, -4.883, -4.883]}
{"number_of_episodes": 1724, "number_of_timesteps": 26665, "per_episode_reward": 13.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.15000000000000036},
{"step": 601, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 602.0, 1.0, 1.0, 1.0, 1.0, 1.0, 602.0, 602.0], "q_vals": [0.0, 0.0, -4.952, 0.0, 0.0, 0.0, 0.0, 0.0, -4.875, -4.875]}
{"number_of_episodes": 1728, "number_of_timesteps": 26727, "per_episode_reward": 13.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 602, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 603.0, 1.0, 1.0, 1.0, 1.0, 1.0, 603.0, 603.0], "q_vals": [0.0, 0.0, -4.955, 0.0, 0.0, 0.0, 0.0, 0.0, -4.877, -4.877]}
{"number_of_episodes": 1731, "number_of_timesteps": 26766, "per_episode_reward": 13.15, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 603, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 604.0, 1.0, 1.0, 1.0, 1.0, 1.0, 604.0, 604.0], "q_vals": [0.0, 0.0, -4.947, 0.0, 0.0, 0.0, 0.0, 0.0, -4.869, -4.869]}
{"step": 604, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 605.0, 1.0, 1.0, 1.0, 1.0, 1.0, 605.0, 605.0], "q_vals": [0.0, 0.0, -4.939, 0.0, 0.0, 0.0, 0.0, 0.0, -4.861, -4.861]}
{"number_of_episodes": 1738, "number_of_timesteps": 26840, "per_episode_reward": 13.15, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 605, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 606.0, 1.0, 1.0, 1.0, 1.0, 1.0, 606.0, 606.0], "q_vals": [0.0, 0.0, -4.941, 0.0, 0.0, 0.0, 0.0, 0.0, -4.862, -4.862]}
{"number_of_episodes": 1744, "number_of_timesteps": 26915, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 606, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 607.0, 1.0, 1.0, 1.0, 1.0, 1.0, 607.0, 607.0], "q_vals": [0.0, 0.0, -4.943, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"number_of_episodes": 1745, "number_of_timesteps": 26926, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.25},
{"step": 607, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 608.0, 1.0, 1.0, 1.0, 1.0, 1.0, 608.0, 608.0], "q_vals": [0.0, 0.0, -4.935, 0.0, 0.0, 0.0, 0.0, 0.0, -4.865, -4.865]}
{"number_of_episodes": 1751, "number_of_timesteps": 26996, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 608, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 609.0, 1.0, 1.0, 1.0, 1.0, 1.0, 609.0, 609.0], "q_vals": [0.0, 0.0, -4.948, 0.0, 0.0, 0.0, 0.0, 0.0, -4.875, -4.875]}
{"number_of_episodes": 1755, "number_of_timesteps": 27039, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.25},
{"step": 609, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 610.0, 1.0, 1.0, 1.0, 1.0, 1.0, 610.0, 610.0], "q_vals": [0.0, 0.0, -4.94, 0.0, 0.0, 0.0, 0.0, 0.0, -4.877, -4.877]}
{"number_of_episodes": 1755, "number_of_timesteps": 27039, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 610, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 611.0, 1.0, 1.0, 1.0, 1.0, 1.0, 611.0, 611.0], "q_vals": [0.0, 0.0, -4.956, 0.0, 0.0, 0.0, 0.0, 0.0, -4.891, -4.891]}
{"number_of_episodes": 1761, "number_of_timesteps": 27111, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.14999999999999858},
{"step": 611, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 612.0, 1.0, 1.0, 1.0, 1.0, 1.0, 612.0, 612.0], "q_vals": [0.0, 0.0, -4.948, 0.0, 0.0, 0.0, 0.0, 0.0, -4.883, -4.883]}
{"number_of_episodes": 1764, "number_of_timesteps": 27159, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 612, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 613.0, 1.0, 1.0, 1.0, 1.0, 1.0, 613.0, 613.0], "q_vals": [0.0, 0.0, -4.95, 0.0, 0.0, 0.0, 0.0, 0.0, -4.883, -4.883]}
{"step": 613, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 614.0, 1.0, 1.0, 1.0, 1.0, 1.0, 614.0, 614.0], "q_vals": [0.0, 0.0, -4.95, 0.0, 0.0, 0.0, 0.0, 0.0, -4.883, -4.883]}
{"number_of_episodes": 1773, "number_of_timesteps": 27267, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 614, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 615.0, 1.0, 1.0, 1.0, 1.0, 1.0, 615.0, 615.0], "q_vals": [0.0, 0.0, -4.968, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 1774, "number_of_timesteps": 27278, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 615, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 616.0, 1.0, 1.0, 1.0, 1.0, 1.0, 616.0, 616.0], "q_vals": [0.0, 0.0, -4.96, 0.0, 0.0, 0.0, 0.0, 0.0, -4.89, -4.89]}
{"number_of_episodes": 1778, "number_of_timesteps": 27320, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.25},
{"step": 616, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 617.0, 1.0, 1.0, 1.0, 1.0, 1.0, 617.0, 617.0], "q_vals": [0.0, 0.0, -4.958, 0.0, 0.0, 0.0, 0.0, 0.0, -4.888, -4.888]}
{"number_of_episodes": 1783, "number_of_timesteps": 27383, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.25},
{"step": 617, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 618.0, 1.0, 1.0, 1.0, 1.0, 1.0, 618.0, 618.0], "q_vals": [0.0, 0.0, -4.95, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 1785, "number_of_timesteps": 27412, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.20000000000000107},
{"step": 618, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 619.0, 1.0, 1.0, 1.0, 1.0, 1.0, 619.0, 619.0], "q_vals": [0.0, 0.0, -4.946, 0.0, 0.0, 0.0, 0.0, 0.0, -4.884, -4.884]}
{"number_of_episodes": 1791, "number_of_timesteps": 27479, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 619, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 620.0, 1.0, 1.0, 1.0, 1.0, 1.0, 620.0, 620.0], "q_vals": [0.0, 0.0, -4.944, 0.0, 0.0, 0.0, 0.0, 0.0, -4.882, -4.882]}
{"number_of_episodes": 1794, "number_of_timesteps": 27513, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.29999999999999893},
{"step": 620, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 621.0, 1.0, 1.0, 1.0, 1.0, 1.0, 621.0, 621.0], "q_vals": [0.0, 0.0, -4.936, 0.0, 0.0, 0.0, 0.0, 0.0, -4.874, -4.874]}
{"number_of_episodes": 1796, "number_of_timesteps": 27536, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.14999999999999858},
{"step": 621, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 622.0, 1.0, 1.0, 1.0, 1.0, 1.0, 622.0, 622.0], "q_vals": [0.0, 0.0, -4.928, 0.0, 0.0, 0.0, 0.0, 0.0, -4.866, -4.866]}
{"step": 622, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 623.0, 1.0, 1.0, 1.0, 1.0, 1.0, 623.0, 623.0], "q_vals": [0.0, 0.0, -4.92, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 1804, "number_of_timesteps": 27636, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.29999999999999893},
{"step": 623, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 624.0, 1.0, 1.0, 1.0, 1.0, 1.0, 624.0, 624.0], "q_vals": [0.0, 0.0, -4.912, 0.0, 0.0, 0.0, 0.0, 0.0, -4.851, -4.851]}
{"number_of_episodes": 1808, "number_of_timesteps": 27683, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 624, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 625.0, 1.0, 1.0, 1.0, 1.0, 1.0, 625.0, 625.0], "q_vals": [0.0, 0.0, -4.917, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"number_of_episodes": 1811, "number_of_timesteps": 27723, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 625, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 626.0, 1.0, 1.0, 1.0, 1.0, 1.0, 626.0, 626.0], "q_vals": [0.0, 0.0, -4.917, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"step": 626, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 627.0, 1.0, 1.0, 1.0, 1.0, 1.0, 627.0, 627.0], "q_vals": [0.0, 0.0, -4.918, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"number_of_episodes": 1819, "number_of_timesteps": 27817, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.25},
{"step": 627, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 628.0, 1.0, 1.0, 1.0, 1.0, 1.0, 628.0, 628.0], "q_vals": [0.0, 0.0, -4.921, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"eval_score": 14.5, "number_of_episodes": 1821}
{"number_of_episodes": 1821, "number_of_timesteps": 27840, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.25},
{"step": 628, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 629.0, 1.0, 1.0, 1.0, 1.0, 1.0, 629.0, 629.0], "q_vals": [0.0, 0.0, -4.914, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"step": 629, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 630.0, 1.0, 1.0, 1.0, 1.0, 1.0, 630.0, 630.0], "q_vals": [0.0, 0.0, -4.915, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 1831, "number_of_timesteps": 27953, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.15000000000000036},
{"step": 630, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 631.0, 1.0, 1.0, 1.0, 1.0, 1.0, 631.0, 631.0], "q_vals": [0.0, 0.0, -4.916, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 1832, "number_of_timesteps": 27963, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.29999999999999893},
{"step": 631, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 632.0, 1.0, 1.0, 1.0, 1.0, 1.0, 632.0, 632.0], "q_vals": [0.0, 0.0, -4.908, 0.0, 0.0, 0.0, 0.0, 0.0, -4.85, -4.85]}
{"number_of_episodes": 1837, "number_of_timesteps": 28024, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 632, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 633.0, 1.0, 1.0, 1.0, 1.0, 1.0, 633.0, 633.0], "q_vals": [0.0, 0.0, -4.911, 0.0, 0.0, 0.0, 0.0, 0.0, -4.852, -4.852]}
{"number_of_episodes": 1840, "number_of_timesteps": 28060, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 633, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 634.0, 1.0, 1.0, 1.0, 1.0, 1.0, 634.0, 634.0], "q_vals": [0.0, 0.0, -4.924, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"number_of_episodes": 1843, "number_of_timesteps": 28099, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 634, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 635.0, 1.0, 1.0, 1.0, 1.0, 1.0, 635.0, 635.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.873, -4.873]}
{"number_of_episodes": 1845, "number_of_timesteps": 28134, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.29999999999999893},
{"step": 635, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 636.0, 1.0, 1.0, 1.0, 1.0, 1.0, 636.0, 636.0], "q_vals": [0.0, 0.0, -4.929, 0.0, 0.0, 0.0, 0.0, 0.0, -4.866, -4.866]}
{"step": 636, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 637.0, 1.0, 1.0, 1.0, 1.0, 1.0, 637.0, 637.0], "q_vals": [0.0, 0.0, -4.922, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"step": 637, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 638.0, 1.0, 1.0, 1.0, 1.0, 1.0, 638.0, 638.0], "q_vals": [0.0, 0.0, -4.914, 0.0, 0.0, 0.0, 0.0, 0.0, -4.85, -4.85]}
{"number_of_episodes": 1855, "number_of_timesteps": 28270, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 638, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 639.0, 1.0, 1.0, 1.0, 1.0, 1.0, 639.0, 639.0], "q_vals": [0.0, 0.0, -4.906, 0.0, 0.0, 0.0, 0.0, 0.0, -4.843, -4.843]}
{"number_of_episodes": 1859, "number_of_timesteps": 28318, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 639, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 640.0, 1.0, 1.0, 1.0, 1.0, 1.0, 640.0, 640.0], "q_vals": [0.0, 0.0, -4.921, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"number_of_episodes": 1865, "number_of_timesteps": 28409, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.25},
{"step": 640, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 641.0, 1.0, 1.0, 1.0, 1.0, 1.0, 641.0, 641.0], "q_vals": [0.0, 0.0, -4.923, 0.0, 0.0, 0.0, 0.0, 0.0, -4.856, -4.856]}
{"step": 641, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 642.0, 1.0, 1.0, 1.0, 1.0, 1.0, 642.0, 642.0], "q_vals": [0.0, 0.0, -4.921, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"number_of_episodes": 1871, "number_of_timesteps": 28466, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 642, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 643.0, 1.0, 1.0, 1.0, 1.0, 1.0, 643.0, 643.0], "q_vals": [0.0, 0.0, -4.922, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"number_of_episodes": 1875, "number_of_timesteps": 28513, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 643, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 644.0, 1.0, 1.0, 1.0, 1.0, 1.0, 644.0, 644.0], "q_vals": [0.0, 0.0, -4.925, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"number_of_episodes": 1878, "number_of_timesteps": 28546, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.29999999999999893},
{"step": 644, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 645.0, 1.0, 1.0, 1.0, 1.0, 1.0, 645.0, 645.0], "q_vals": [0.0, 0.0, -4.917, 0.0, 0.0, 0.0, 0.0, 0.0, -4.848, -4.848]}
{"number_of_episodes": 1883, "number_of_timesteps": 28614, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 645, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 646.0, 1.0, 1.0, 1.0, 1.0, 1.0, 646.0, 646.0], "q_vals": [0.0, 0.0, -4.934, 0.0, 0.0, 0.0, 0.0, 0.0, -4.862, -4.862]}
{"number_of_episodes": 1888, "number_of_timesteps": 28671, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 646, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 647.0, 1.0, 1.0, 1.0, 1.0, 1.0, 647.0, 647.0], "q_vals": [0.0, 0.0, -4.927, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"number_of_episodes": 1890, "number_of_timesteps": 28688, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 647, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 648.0, 1.0, 1.0, 1.0, 1.0, 1.0, 648.0, 648.0], "q_vals": [0.0, 0.0, -4.93, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"number_of_episodes": 1895, "number_of_timesteps": 28742, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 648, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 649.0, 1.0, 1.0, 1.0, 1.0, 1.0, 649.0, 649.0], "q_vals": [0.0, 0.0, -4.923, 0.0, 0.0, 0.0, 0.0, 0.0, -4.859, -4.859]}
{"number_of_episodes": 1898, "number_of_timesteps": 28781, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 649, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 650.0, 1.0, 1.0, 1.0, 1.0, 1.0, 650.0, 650.0], "q_vals": [0.0, 0.0, -4.925, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"number_of_episodes": 1900, "number_of_timesteps": 28806, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 650, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 651.0, 1.0, 1.0, 1.0, 1.0, 1.0, 651.0, 651.0], "q_vals": [0.0, 0.0, -4.917, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"step": 651, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 652.0, 1.0, 1.0, 1.0, 1.0, 1.0, 652.0, 652.0], "q_vals": [0.0, 0.0, -4.918, 0.0, 0.0, 0.0, 0.0, 0.0, -4.852, -4.852]}
{"number_of_episodes": 1909, "number_of_timesteps": 28914, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 652, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 653.0, 1.0, 1.0, 1.0, 1.0, 1.0, 653.0, 653.0], "q_vals": [0.0, 0.0, -4.91, 0.0, 0.0, 0.0, 0.0, 0.0, -4.846, -4.846]}
{"step": 653, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 654.0, 1.0, 1.0, 1.0, 1.0, 1.0, 654.0, 654.0], "q_vals": [0.0, 0.0, -4.903, 0.0, 0.0, 0.0, 0.0, 0.0, -4.846, -4.846]}
{"number_of_episodes": 1918, "number_of_timesteps": 29014, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 654, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 655.0, 1.0, 1.0, 1.0, 1.0, 1.0, 655.0, 655.0], "q_vals": [0.0, 0.0, -4.904, 0.0, 0.0, 0.0, 0.0, 0.0, -4.847, -4.847]}
{"number_of_episodes": 1921, "number_of_timesteps": 29047, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 655, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 656.0, 1.0, 1.0, 1.0, 1.0, 1.0, 656.0, 656.0], "q_vals": [0.0, 0.0, -4.906, 0.0, 0.0, 0.0, 0.0, 0.0, -4.848, -4.848]}
{"number_of_episodes": 1924, "number_of_timesteps": 29089, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 656, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 657.0, 1.0, 1.0, 1.0, 1.0, 1.0, 657.0, 657.0], "q_vals": [0.0, 0.0, -4.921, 0.0, 0.0, 0.0, 0.0, 0.0, -4.859, -4.859]}
{"number_of_episodes": 1929, "number_of_timesteps": 29151, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 657, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 658.0, 1.0, 1.0, 1.0, 1.0, 1.0, 658.0, 658.0], "q_vals": [0.0, 0.0, -4.923, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"number_of_episodes": 1931, "number_of_timesteps": 29169, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.29999999999999893},
{"step": 658, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 659.0, 1.0, 1.0, 1.0, 1.0, 1.0, 659.0, 659.0], "q_vals": [0.0, 0.0, -4.915, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"step": 659, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 660.0, 1.0, 1.0, 1.0, 1.0, 1.0, 660.0, 660.0], "q_vals": [0.0, 0.0, -4.916, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 1940, "number_of_timesteps": 29286, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 660, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 661.0, 1.0, 1.0, 1.0, 1.0, 1.0, 661.0, 661.0], "q_vals": [0.0, 0.0, -4.909, 0.0, 0.0, 0.0, 0.0, 0.0, -4.846, -4.846]}
{"step": 661, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 662.0, 1.0, 1.0, 1.0, 1.0, 1.0, 662.0, 662.0], "q_vals": [0.0, 0.0, -4.902, 0.0, 0.0, 0.0, 0.0, 0.0, -4.839, -4.839]}
{"step": 662, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 663.0, 1.0, 1.0, 1.0, 1.0, 1.0, 663.0, 663.0], "q_vals": [0.0, 0.0, -4.894, 0.0, 0.0, 0.0, 0.0, 0.0, -4.831, -4.831]}
{"step": 663, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 664.0, 1.0, 1.0, 1.0, 1.0, 1.0, 664.0, 664.0], "q_vals": [0.0, 0.0, -4.887, 0.0, 0.0, 0.0, 0.0, 0.0, -4.824, -4.824]}
{"eval_score": 13.0, "number_of_episodes": 1950}
{"number_of_episodes": 1950, "number_of_timesteps": 29411, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 664, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 665.0, 1.0, 1.0, 1.0, 1.0, 1.0, 665.0, 665.0], "q_vals": [0.0, 0.0, -4.887, 0.0, 0.0, 0.0, 0.0, 0.0, -4.823, -4.823]}
{"number_of_episodes": 1957, "number_of_timesteps": 29521, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 665, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 666.0, 1.0, 1.0, 1.0, 1.0, 1.0, 666.0, 666.0], "q_vals": [0.0, 0.0, -4.887, 0.0, 0.0, 0.0, 0.0, 0.0, -4.823, -4.823]}
{"number_of_episodes": 1959, "number_of_timesteps": 29548, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.29999999999999893},
{"step": 666, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 667.0, 1.0, 1.0, 1.0, 1.0, 1.0, 667.0, 667.0], "q_vals": [0.0, 0.0, -4.88, 0.0, 0.0, 0.0, 0.0, 0.0, -4.816, -4.816]}
{"number_of_episodes": 1962, "number_of_timesteps": 29580, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 667, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 668.0, 1.0, 1.0, 1.0, 1.0, 1.0, 668.0, 668.0], "q_vals": [0.0, 0.0, -4.873, 0.0, 0.0, 0.0, 0.0, 0.0, -4.815, -4.815]}
{"number_of_episodes": 1968, "number_of_timesteps": 29655, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 668, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 669.0, 1.0, 1.0, 1.0, 1.0, 1.0, 669.0, 669.0], "q_vals": [0.0, 0.0, -4.884, 0.0, 0.0, 0.0, 0.0, 0.0, -4.824, -4.824]}
{"step": 669, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 670.0, 1.0, 1.0, 1.0, 1.0, 1.0, 670.0, 670.0], "q_vals": [0.0, 0.0, -4.876, 0.0, 0.0, 0.0, 0.0, 0.0, -4.819, -4.819]}
{"number_of_episodes": 1972, "number_of_timesteps": 29708, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.29999999999999893},
{"step": 670, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 671.0, 1.0, 1.0, 1.0, 1.0, 1.0, 671.0, 671.0], "q_vals": [0.0, 0.0, -4.869, 0.0, 0.0, 0.0, 0.0, 0.0, -4.812, -4.812]}
{"number_of_episodes": 1978, "number_of_timesteps": 29787, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 671, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 672.0, 1.0, 1.0, 1.0, 1.0, 1.0, 672.0, 672.0], "q_vals": [0.0, 0.0, -4.869, 0.0, 0.0, 0.0, 0.0, 0.0, -4.812, -4.812]}
{"number_of_episodes": 1980, "number_of_timesteps": 29805, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 672, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 673.0, 1.0, 1.0, 1.0, 1.0, 1.0, 673.0, 673.0], "q_vals": [0.0, 0.0, -4.862, 0.0, 0.0, 0.0, 0.0, 0.0, -4.805, -4.805]}
{"step": 673, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 674.0, 1.0, 1.0, 1.0, 1.0, 1.0, 674.0, 674.0], "q_vals": [0.0, 0.0, -4.855, 0.0, 0.0, 0.0, 0.0, 0.0, -4.797, -4.797]}
{"number_of_episodes": 1988, "number_of_timesteps": 29909, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 674, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 675.0, 1.0, 1.0, 1.0, 1.0, 1.0, 675.0, 675.0], "q_vals": [0.0, 0.0, -4.856, 0.0, 0.0, 0.0, 0.0, 0.0, -4.798, -4.798]}
{"number_of_episodes": 1991, "number_of_timesteps": 29950, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 675, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 676.0, 1.0, 1.0, 1.0, 1.0, 1.0, 676.0, 676.0], "q_vals": [0.0, 0.0, -4.86, 0.0, 0.0, 0.0, 0.0, 0.0, -4.801, -4.801]}
{"number_of_episodes": 1994, "number_of_timesteps": 29983, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 676, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 677.0, 1.0, 1.0, 1.0, 1.0, 1.0, 677.0, 677.0], "q_vals": [0.0, 0.0, -4.863, 0.0, 0.0, 0.0, 0.0, 0.0, -4.802, -4.802]}
{"number_of_episodes": 1997, "number_of_timesteps": 30021, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 677, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 678.0, 1.0, 1.0, 1.0, 1.0, 1.0, 678.0, 678.0], "q_vals": [0.0, 0.0, -4.856, 0.0, 0.0, 0.0, 0.0, 0.0, -4.795, -4.795]}
{"number_of_episodes": 2001, "number_of_timesteps": 30077, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 678, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 679.0, 1.0, 1.0, 1.0, 1.0, 1.0, 679.0, 679.0], "q_vals": [0.0, 0.0, -4.849, 0.0, 0.0, 0.0, 0.0, 0.0, -4.797, -4.797]}
{"number_of_episodes": 2005, "number_of_timesteps": 30123, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 679, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 680.0, 1.0, 1.0, 1.0, 1.0, 1.0, 680.0, 680.0], "q_vals": [0.0, 0.0, -4.85, 0.0, 0.0, 0.0, 0.0, 0.0, -4.797, -4.797]}
{"step": 680, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 681.0, 1.0, 1.0, 1.0, 1.0, 1.0, 681.0, 681.0], "q_vals": [0.0, 0.0, -4.843, 0.0, 0.0, 0.0, 0.0, 0.0, -4.799, -4.799]}
{"number_of_episodes": 2010, "number_of_timesteps": 30182, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 681, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 682.0, 1.0, 1.0, 1.0, 1.0, 1.0, 682.0, 682.0], "q_vals": [0.0, 0.0, -4.847, 0.0, 0.0, 0.0, 0.0, 0.0, -4.802, -4.802]}
{"number_of_episodes": 2016, "number_of_timesteps": 30262, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.20000000000000107},
{"step": 682, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 683.0, 1.0, 1.0, 1.0, 1.0, 1.0, 683.0, 683.0], "q_vals": [0.0, 0.0, -4.859, 0.0, 0.0, 0.0, 0.0, 0.0, -4.812, -4.812]}
{"step": 683, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 684.0, 1.0, 1.0, 1.0, 1.0, 1.0, 684.0, 684.0], "q_vals": [0.0, 0.0, -4.871, 0.0, 0.0, 0.0, 0.0, 0.0, -4.822, -4.822]}
{"number_of_episodes": 2023, "number_of_timesteps": 30336, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.25},
{"step": 684, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 685.0, 1.0, 1.0, 1.0, 1.0, 1.0, 685.0, 685.0], "q_vals": [0.0, 0.0, -4.874, 0.0, 0.0, 0.0, 0.0, 0.0, -4.824, -4.824]}
{"number_of_episodes": 2027, "number_of_timesteps": 30382, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 685, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 686.0, 1.0, 1.0, 1.0, 1.0, 1.0, 686.0, 686.0], "q_vals": [0.0, 0.0, -4.867, 0.0, 0.0, 0.0, 0.0, 0.0, -4.817, -4.817]}
{"number_of_episodes": 2032, "number_of_timesteps": 30443, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 686, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 687.0, 1.0, 1.0, 1.0, 1.0, 1.0, 687.0, 687.0], "q_vals": [0.0, 0.0, -4.86, 0.0, 0.0, 0.0, 0.0, 0.0, -4.81, -4.81]}
{"number_of_episodes": 2035, "number_of_timesteps": 30473, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.29999999999999893},
{"step": 687, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 688.0, 1.0, 1.0, 1.0, 1.0, 1.0, 688.0, 688.0], "q_vals": [0.0, 0.0, -4.853, 0.0, 0.0, 0.0, 0.0, 0.0, -4.803, -4.803]}
{"step": 688, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 689.0, 1.0, 1.0, 1.0, 1.0, 1.0, 689.0, 689.0], "q_vals": [0.0, 0.0, -4.846, 0.0, 0.0, 0.0, 0.0, 0.0, -4.796, -4.796]}
{"number_of_episodes": 2042, "number_of_timesteps": 30557, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.20000000000000107},
{"step": 689, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 690.0, 1.0, 1.0, 1.0, 1.0, 1.0, 690.0, 690.0], "q_vals": [0.0, 0.0, -4.859, 0.0, 0.0, 0.0, 0.0, 0.0, -4.807, -4.807]}
{"number_of_episodes": 2048, "number_of_timesteps": 30628, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 690, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 691.0, 1.0, 1.0, 1.0, 1.0, 1.0, 691.0, 691.0], "q_vals": [0.0, 0.0, -4.852, 0.0, 0.0, 0.0, 0.0, 0.0, -4.8, -4.8]}
{"number_of_episodes": 2051, "number_of_timesteps": 30660, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 691, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 692.0, 1.0, 1.0, 1.0, 1.0, 1.0, 692.0, 692.0], "q_vals": [0.0, 0.0, -4.858, 0.0, 0.0, 0.0, 0.0, 0.0, -4.804, -4.804]}
{"number_of_episodes": 2056, "number_of_timesteps": 30707, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 692, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 693.0, 1.0, 1.0, 1.0, 1.0, 1.0, 693.0, 693.0], "q_vals": [0.0, 0.0, -4.856, 0.0, 0.0, 0.0, 0.0, 0.0, -4.802, -4.802]}
{"number_of_episodes": 2060, "number_of_timesteps": 30748, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 693, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 694.0, 1.0, 1.0, 1.0, 1.0, 1.0, 694.0, 694.0], "q_vals": [0.0, 0.0, -4.849, 0.0, 0.0, 0.0, 0.0, 0.0, -4.804, -4.804]}
{"number_of_episodes": 2062, "number_of_timesteps": 30771, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.20000000000000107},
{"step": 694, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 695.0, 1.0, 1.0, 1.0, 1.0, 1.0, 695.0, 695.0], "q_vals": [0.0, 0.0, -4.843, 0.0, 0.0, 0.0, 0.0, 0.0, -4.798, -4.798]}
{"number_of_episodes": 2068, "number_of_timesteps": 30835, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 695, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 696.0, 1.0, 1.0, 1.0, 1.0, 1.0, 696.0, 696.0], "q_vals": [0.0, 0.0, -4.836, 0.0, 0.0, 0.0, 0.0, 0.0, -4.791, -4.791]}
{"step": 696, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 697.0, 1.0, 1.0, 1.0, 1.0, 1.0, 697.0, 697.0], "q_vals": [0.0, 0.0, -4.842, 0.0, 0.0, 0.0, 0.0, 0.0, -4.795, -4.795]}
{"number_of_episodes": 2074, "number_of_timesteps": 30904, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 697, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 698.0, 1.0, 1.0, 1.0, 1.0, 1.0, 698.0, 698.0], "q_vals": [0.0, 0.0, -4.835, 0.0, 0.0, 0.0, 0.0, 0.0, -4.797, -4.797]}
{"number_of_episodes": 2077, "number_of_timesteps": 30941, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 698, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 699.0, 1.0, 1.0, 1.0, 1.0, 1.0, 699.0, 699.0], "q_vals": [0.0, 0.0, -4.837, 0.0, 0.0, 0.0, 0.0, 0.0, -4.798, -4.798]}
{"eval_score": 12.9, "number_of_episodes": 2081}
{"number_of_episodes": 2081, "number_of_timesteps": 30989, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 699, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 700.0, 1.0, 1.0, 1.0, 1.0, 1.0, 700.0, 700.0], "q_vals": [0.0, 0.0, -4.839, 0.0, 0.0, 0.0, 0.0, 0.0, -4.799, -4.799]}
{"number_of_episodes": 2085, "number_of_timesteps": 31041, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
{"step": 700, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 701.0, 1.0, 1.0, 1.0, 1.0, 1.0, 701.0, 701.0], "q_vals": [0.0, 0.0, -4.832, 0.0, 0.0, 0.0, 0.0, 0.0, -4.792, -4.792]}
{"number_of_episodes": 2088, "number_of_timesteps": 31073, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 701, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 702.0, 1.0, 1.0, 1.0, 1.0, 1.0, 702.0, 702.0], "q_vals": [0.0, 0.0, -4.825, 0.0, 0.0, 0.0, 0.0, 0.0, -4.785, -4.785]}
{"step": 702, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 703.0, 1.0, 1.0, 1.0, 1.0, 1.0, 703.0, 703.0], "q_vals": [0.0, 0.0, -4.818, 0.0, 0.0, 0.0, 0.0, 0.0, -4.778, -4.778]}
{"number_of_episodes": 2095, "number_of_timesteps": 31154, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 703, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 704.0, 1.0, 1.0, 1.0, 1.0, 1.0, 704.0, 704.0], "q_vals": [0.0, 0.0, -4.82, 0.0, 0.0, 0.0, 0.0, 0.0, -4.779, -4.779]}
{"number_of_episodes": 2099, "number_of_timesteps": 31212, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 704, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 705.0, 1.0, 1.0, 1.0, 1.0, 1.0, 705.0, 705.0], "q_vals": [0.0, 0.0, -4.813, 0.0, 0.0, 0.0, 0.0, 0.0, -4.779, -4.779]}
{"step": 705, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 706.0, 1.0, 1.0, 1.0, 1.0, 1.0, 706.0, 706.0], "q_vals": [0.0, 0.0, -4.813, 0.0, 0.0, 0.0, 0.0, 0.0, -4.778, -4.778]}
{"number_of_episodes": 2105, "number_of_timesteps": 31282, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 706, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 707.0, 1.0, 1.0, 1.0, 1.0, 1.0, 707.0, 707.0], "q_vals": [0.0, 0.0, -4.807, 0.0, 0.0, 0.0, 0.0, 0.0, -4.772, -4.772]}
{"number_of_episodes": 2111, "number_of_timesteps": 31356, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 707, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 708.0, 1.0, 1.0, 1.0, 1.0, 1.0, 708.0, 708.0], "q_vals": [0.0, 0.0, -4.822, 0.0, 0.0, 0.0, 0.0, 0.0, -4.784, -4.784]}
{"number_of_episodes": 2114, "number_of_timesteps": 31387, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.20000000000000107},
{"step": 708, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 709.0, 1.0, 1.0, 1.0, 1.0, 1.0, 709.0, 709.0], "q_vals": [0.0, 0.0, -4.837, 0.0, 0.0, 0.0, 0.0, 0.0, -4.797, -4.797]}
{"number_of_episodes": 2118, "number_of_timesteps": 31430, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
{"step": 709, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 710.0, 1.0, 1.0, 1.0, 1.0, 1.0, 710.0, 710.0], "q_vals": [0.0, 0.0, -4.838, 0.0, 0.0, 0.0, 0.0, 0.0, -4.797, -4.797]}
{"step": 710, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 711.0, 1.0, 1.0, 1.0, 1.0, 1.0, 711.0, 711.0], "q_vals": [0.0, 0.0, -4.837, 0.0, 0.0, 0.0, 0.0, 0.0, -4.795, -4.795]}
{"number_of_episodes": 2124, "number_of_timesteps": 31503, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 711, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 712.0, 1.0, 1.0, 1.0, 1.0, 1.0, 712.0, 712.0], "q_vals": [0.0, 0.0, -4.852, 0.0, 0.0, 0.0, 0.0, 0.0, -4.807, -4.807]}
{"step": 712, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 713.0, 1.0, 1.0, 1.0, 1.0, 1.0, 713.0, 713.0], "q_vals": [0.0, 0.0, -4.867, 0.0, 0.0, 0.0, 0.0, 0.0, -4.821, -4.821]}
{"number_of_episodes": 2131, "number_of_timesteps": 31613, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 713, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 714.0, 1.0, 1.0, 1.0, 1.0, 1.0, 714.0, 714.0], "q_vals": [0.0, 0.0, -4.869, 0.0, 0.0, 0.0, 0.0, 0.0, -4.821, -4.821]}
{"number_of_episodes": 2133, "number_of_timesteps": 31638, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 714, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 715.0, 1.0, 1.0, 1.0, 1.0, 1.0, 715.0, 715.0], "q_vals": [0.0, 0.0, -4.872, 0.0, 0.0, 0.0, 0.0, 0.0, -4.823, -4.823]}
{"step": 715, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 716.0, 1.0, 1.0, 1.0, 1.0, 1.0, 716.0, 716.0], "q_vals": [0.0, 0.0, -4.878, 0.0, 0.0, 0.0, 0.0, 0.0, -4.828, -4.828]}
{"step": 716, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 717.0, 1.0, 1.0, 1.0, 1.0, 1.0, 717.0, 717.0], "q_vals": [0.0, 0.0, -4.881, 0.0, 0.0, 0.0, 0.0, 0.0, -4.83, -4.83]}
{"number_of_episodes": 2141, "number_of_timesteps": 31738, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.20000000000000107},
{"step": 717, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 718.0, 1.0, 1.0, 1.0, 1.0, 1.0, 718.0, 718.0], "q_vals": [0.0, 0.0, -4.896, 0.0, 0.0, 0.0, 0.0, 0.0, -4.842, -4.842]}
{"number_of_episodes": 2145, "number_of_timesteps": 31812, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 718, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 719.0, 1.0, 1.0, 1.0, 1.0, 1.0, 719.0, 719.0], "q_vals": [0.0, 0.0, -4.896, 0.0, 0.0, 0.0, 0.0, 0.0, -4.842, -4.842]}
{"number_of_episodes": 2149, "number_of_timesteps": 31863, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.25},
{"step": 719, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 720.0, 1.0, 1.0, 1.0, 1.0, 1.0, 720.0, 720.0], "q_vals": [0.0, 0.0, -4.896, 0.0, 0.0, 0.0, 0.0, 0.0, -4.841, -4.841]}
{"step": 720, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 721.0, 1.0, 1.0, 1.0, 1.0, 1.0, 721.0, 721.0], "q_vals": [0.0, 0.0, -4.898, 0.0, 0.0, 0.0, 0.0, 0.0, -4.842, -4.842]}
{"number_of_episodes": 2155, "number_of_timesteps": 31954, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 721, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 722.0, 1.0, 1.0, 1.0, 1.0, 1.0, 722.0, 722.0], "q_vals": [0.0, 0.0, -4.9, 0.0, 0.0, 0.0, 0.0, 0.0, -4.842, -4.842]}
{"step": 722, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 723.0, 1.0, 1.0, 1.0, 1.0, 1.0, 723.0, 723.0], "q_vals": [0.0, 0.0, -4.9, 0.0, 0.0, 0.0, 0.0, 0.0, -4.842, -4.842]}
{"number_of_episodes": 2162, "number_of_timesteps": 32046, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.25},
{"step": 723, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 724.0, 1.0, 1.0, 1.0, 1.0, 1.0, 724.0, 724.0], "q_vals": [0.0, 0.0, -4.902, 0.0, 0.0, 0.0, 0.0, 0.0, -4.844, -4.844]}
{"number_of_episodes": 2165, "number_of_timesteps": 32086, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.1999999999999993},
{"step": 724, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 725.0, 1.0, 1.0, 1.0, 1.0, 1.0, 725.0, 725.0], "q_vals": [0.0, 0.0, -4.896, 0.0, 0.0, 0.0, 0.0, 0.0, -4.837, -4.837]}
{"number_of_episodes": 2169, "number_of_timesteps": 32130, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 725, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 726.0, 1.0, 1.0, 1.0, 1.0, 1.0, 726.0, 726.0], "q_vals": [0.0, 0.0, -4.889, 0.0, 0.0, 0.0, 0.0, 0.0, -4.83, -4.83]}
{"step": 726, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 727.0, 1.0, 1.0, 1.0, 1.0, 1.0, 727.0, 727.0], "q_vals": [0.0, 0.0, -4.892, 0.0, 0.0, 0.0, 0.0, 0.0, -4.832, -4.832]}
{"number_of_episodes": 2176, "number_of_timesteps": 32216, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.1999999999999993},
{"step": 727, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 728.0, 1.0, 1.0, 1.0, 1.0, 1.0, 728.0, 728.0], "q_vals": [0.0, 0.0, -4.888, 0.0, 0.0, 0.0, 0.0, 0.0, -4.828, -4.828]}
{"step": 728, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 729.0, 1.0, 1.0, 1.0, 1.0, 1.0, 729.0, 729.0], "q_vals": [0.0, 0.0, -4.901, 0.0, 0.0, 0.0, 0.0, 0.0, -4.839, -4.839]}
{"number_of_episodes": 2181, "number_of_timesteps": 32286, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 729, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 730.0, 1.0, 1.0, 1.0, 1.0, 1.0, 730.0, 730.0], "q_vals": [0.0, 0.0, -4.904, 0.0, 0.0, 0.0, 0.0, 0.0, -4.841, -4.841]}
{"number_of_episodes": 2186, "number_of_timesteps": 32348, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 730, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 731.0, 1.0, 1.0, 1.0, 1.0, 1.0, 731.0, 731.0], "q_vals": [0.0, 0.0, -4.9, 0.0, 0.0, 0.0, 0.0, 0.0, -4.836, -4.836]}
{"number_of_episodes": 2190, "number_of_timesteps": 32403, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.3000000000000007},
{"step": 731, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 732.0, 1.0, 1.0, 1.0, 1.0, 1.0, 732.0, 732.0], "q_vals": [0.0, 0.0, -4.893, 0.0, 0.0, 0.0, 0.0, 0.0, -4.836, -4.836]}
{"number_of_episodes": 2194, "number_of_timesteps": 32446, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.20000000000000107},
{"step": 732, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 733.0, 1.0, 1.0, 1.0, 1.0, 1.0, 733.0, 733.0], "q_vals": [0.0, 0.0, -4.886, 0.0, 0.0, 0.0, 0.0, 0.0, -4.83, -4.83]}
{"number_of_episodes": 2197, "number_of_timesteps": 32476, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
{"step": 733, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 734.0, 1.0, 1.0, 1.0, 1.0, 1.0, 734.0, 734.0], "q_vals": [0.0, 0.0, -4.889, 0.0, 0.0, 0.0, 0.0, 0.0, -4.831, -4.831]}
{"number_of_episodes": 2203, "number_of_timesteps": 32543, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 734, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 735.0, 1.0, 1.0, 1.0, 1.0, 1.0, 735.0, 735.0], "q_vals": [0.0, 0.0, -4.907, 0.0, 0.0, 0.0, 0.0, 0.0, -4.846, -4.846]}
{"number_of_episodes": 2205, "number_of_timesteps": 32564, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 735, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 736.0, 1.0, 1.0, 1.0, 1.0, 1.0, 736.0, 736.0], "q_vals": [0.0, 0.0, -4.907, 0.0, 0.0, 0.0, 0.0, 0.0, -4.846, -4.846]}
{"step": 736, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 737.0, 1.0, 1.0, 1.0, 1.0, 1.0, 737.0, 737.0], "q_vals": [0.0, 0.0, -4.91, 0.0, 0.0, 0.0, 0.0, 0.0, -4.847, -4.847]}
{"eval_score": 11.8, "number_of_episodes": 2212}
{"number_of_episodes": 2212, "number_of_timesteps": 32645, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.20000000000000107},
{"step": 737, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 738.0, 1.0, 1.0, 1.0, 1.0, 1.0, 738.0, 738.0], "q_vals": [0.0, 0.0, -4.903, 0.0, 0.0, 0.0, 0.0, 0.0, -4.841, -4.841]}
{"number_of_episodes": 2217, "number_of_timesteps": 32711, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.25},
{"step": 738, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 739.0, 1.0, 1.0, 1.0, 1.0, 1.0, 739.0, 739.0], "q_vals": [0.0, 0.0, -4.903, 0.0, 0.0, 0.0, 0.0, 0.0, -4.84, -4.84]}
{"step": 739, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 740.0, 1.0, 1.0, 1.0, 1.0, 1.0, 740.0, 740.0], "q_vals": [0.0, 0.0, -4.904, 0.0, 0.0, 0.0, 0.0, 0.0, -4.84, -4.84]}
{"number_of_episodes": 2224, "number_of_timesteps": 32789, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 740, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 741.0, 1.0, 1.0, 1.0, 1.0, 1.0, 741.0, 741.0], "q_vals": [0.0, 0.0, -4.897, 0.0, 0.0, 0.0, 0.0, 0.0, -4.834, -4.834]}
{"step": 741, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 742.0, 1.0, 1.0, 1.0, 1.0, 1.0, 742.0, 742.0], "q_vals": [0.0, 0.0, -4.891, 0.0, 0.0, 0.0, 0.0, 0.0, -4.827, -4.827]}
{"number_of_episodes": 2232, "number_of_timesteps": 32882, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.3000000000000007},
{"step": 742, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 743.0, 1.0, 1.0, 1.0, 1.0, 1.0, 743.0, 743.0], "q_vals": [0.0, 0.0, -4.884, 0.0, 0.0, 0.0, 0.0, 0.0, -4.822, -4.822]}
{"number_of_episodes": 2236, "number_of_timesteps": 32929, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 743, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 744.0, 1.0, 1.0, 1.0, 1.0, 1.0, 744.0, 744.0], "q_vals": [0.0, 0.0, -4.9, 0.0, 0.0, 0.0, 0.0, 0.0, -4.835, -4.835]}
{"number_of_episodes": 2238, "number_of_timesteps": 32952, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 744, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 745.0, 1.0, 1.0, 1.0, 1.0, 1.0, 745.0, 745.0], "q_vals": [0.0, 0.0, -4.904, 0.0, 0.0, 0.0, 0.0, 0.0, -4.838, -4.838]}
{"number_of_episodes": 2244, "number_of_timesteps": 33014, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.20000000000000107},
{"step": 745, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 746.0, 1.0, 1.0, 1.0, 1.0, 1.0, 746.0, 746.0], "q_vals": [0.0, 0.0, -4.898, 0.0, 0.0, 0.0, 0.0, 0.0, -4.832, -4.832]}
{"number_of_episodes": 2247, "number_of_timesteps": 33061, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 746, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 747.0, 1.0, 1.0, 1.0, 1.0, 1.0, 747.0, 747.0], "q_vals": [0.0, 0.0, -4.891, 0.0, 0.0, 0.0, 0.0, 0.0, -4.825, -4.825]}
{"number_of_episodes": 2248, "number_of_timesteps": 33071, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 747, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 748.0, 1.0, 1.0, 1.0, 1.0, 1.0, 748.0, 748.0], "q_vals": [0.0, 0.0, -4.89, 0.0, 0.0, 0.0, 0.0, 0.0, -4.823, -4.823]}
{"number_of_episodes": 2252, "number_of_timesteps": 33123, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.20000000000000107},
{"step": 748, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 749.0, 1.0, 1.0, 1.0, 1.0, 1.0, 749.0, 749.0], "q_vals": [0.0, 0.0, -4.902, 0.0, 0.0, 0.0, 0.0, 0.0, -4.834, -4.834]}
{"number_of_episodes": 2256, "number_of_timesteps": 33182, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.20000000000000107},
{"step": 749, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 750.0, 1.0, 1.0, 1.0, 1.0, 1.0, 750.0, 750.0], "q_vals": [0.0, 0.0, -4.896, 0.0, 0.0, 0.0, 0.0, 0.0, -4.827, -4.827]}
{"number_of_episodes": 2260, "number_of_timesteps": 33238, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 750, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 751.0, 1.0, 1.0, 1.0, 1.0, 1.0, 751.0, 751.0], "q_vals": [0.0, 0.0, -4.891, 0.0, 0.0, 0.0, 0.0, 0.0, -4.822, -4.822]}
{"step": 751, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 752.0, 1.0, 1.0, 1.0, 1.0, 1.0, 752.0, 752.0], "q_vals": [0.0, 0.0, -4.891, 0.0, 0.0, 0.0, 0.0, 0.0, -4.821, -4.821]}
{"number_of_episodes": 2267, "number_of_timesteps": 33316, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.25},
{"step": 752, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 753.0, 1.0, 1.0, 1.0, 1.0, 1.0, 753.0, 753.0], "q_vals": [0.0, 0.0, -4.891, 0.0, 0.0, 0.0, 0.0, 0.0, -4.821, -4.821]}
{"number_of_episodes": 2270, "number_of_timesteps": 33369, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 753, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 754.0, 1.0, 1.0, 1.0, 1.0, 1.0, 754.0, 754.0], "q_vals": [0.0, 0.0, -4.903, 0.0, 0.0, 0.0, 0.0, 0.0, -4.831, -4.831]}
{"number_of_episodes": 2274, "number_of_timesteps": 33413, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 754, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 755.0, 1.0, 1.0, 1.0, 1.0, 1.0, 755.0, 755.0], "q_vals": [0.0, 0.0, -4.903, 0.0, 0.0, 0.0, 0.0, 0.0, -4.83, -4.83]}
{"number_of_episodes": 2278, "number_of_timesteps": 33462, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3000000000000007},
{"step": 755, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 756.0, 1.0, 1.0, 1.0, 1.0, 1.0, 756.0, 756.0], "q_vals": [0.0, 0.0, -4.906, 0.0, 0.0, 0.0, 0.0, 0.0, -4.832, -4.832]}
{"number_of_episodes": 2280, "number_of_timesteps": 33486, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 756, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 757.0, 1.0, 1.0, 1.0, 1.0, 1.0, 757.0, 757.0], "q_vals": [0.0, 0.0, -4.907, 0.0, 0.0, 0.0, 0.0, 0.0, -4.832, -4.832]}
{"step": 757, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 758.0, 1.0, 1.0, 1.0, 1.0, 1.0, 758.0, 758.0], "q_vals": [0.0, 0.0, -4.908, 0.0, 0.0, 0.0, 0.0, 0.0, -4.833, -4.833]}
{"number_of_episodes": 2287, "number_of_timesteps": 33583, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 758, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 759.0, 1.0, 1.0, 1.0, 1.0, 1.0, 759.0, 759.0], "q_vals": [0.0, 0.0, -4.902, 0.0, 0.0, 0.0, 0.0, 0.0, -4.826, -4.826]}
{"number_of_episodes": 2290, "number_of_timesteps": 33615, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
{"step": 759, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 760.0, 1.0, 1.0, 1.0, 1.0, 1.0, 760.0, 760.0], "q_vals": [0.0, 0.0, -4.905, 0.0, 0.0, 0.0, 0.0, 0.0, -4.829, -4.829]}
{"number_of_episodes": 2291, "number_of_timesteps": 33625, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 760, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 761.0, 1.0, 1.0, 1.0, 1.0, 1.0, 761.0, 761.0], "q_vals": [0.0, 0.0, -4.915, 0.0, 0.0, 0.0, 0.0, 0.0, -4.837, -4.837]}
{"number_of_episodes": 2295, "number_of_timesteps": 33695, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 761, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 762.0, 1.0, 1.0, 1.0, 1.0, 1.0, 762.0, 762.0], "q_vals": [0.0, 0.0, -4.924, 0.0, 0.0, 0.0, 0.0, 0.0, -4.844, -4.844]}
{"step": 762, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 763.0, 1.0, 1.0, 1.0, 1.0, 1.0, 763.0, 763.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"step": 763, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 764.0, 1.0, 1.0, 1.0, 1.0, 1.0, 764.0, 764.0], "q_vals": [0.0, 0.0, -4.938, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"number_of_episodes": 2305, "number_of_timesteps": 33845, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.25},
{"step": 764, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 765.0, 1.0, 1.0, 1.0, 1.0, 1.0, 765.0, 765.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"number_of_episodes": 2307, "number_of_timesteps": 33869, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
{"step": 765, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 766.0, 1.0, 1.0, 1.0, 1.0, 1.0, 766.0, 766.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 2312, "number_of_timesteps": 33935, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 766, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 767.0, 1.0, 1.0, 1.0, 1.0, 1.0, 767.0, 767.0], "q_vals": [0.0, 0.0, -4.938, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 2315, "number_of_timesteps": 33971, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 767, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 768.0, 1.0, 1.0, 1.0, 1.0, 1.0, 768.0, 768.0], "q_vals": [0.0, 0.0, -4.953, 0.0, 0.0, 0.0, 0.0, 0.0, -4.865, -4.865]}
{"number_of_episodes": 2318, "number_of_timesteps": 34005, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 768, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 769.0, 1.0, 1.0, 1.0, 1.0, 1.0, 769.0, 769.0], "q_vals": [0.0, 0.0, -4.946, 0.0, 0.0, 0.0, 0.0, 0.0, -4.859, -4.859]}
{"number_of_episodes": 2323, "number_of_timesteps": 34063, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.3000000000000007},
{"step": 769, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 770.0, 1.0, 1.0, 1.0, 1.0, 1.0, 770.0, 770.0], "q_vals": [0.0, 0.0, -4.94, 0.0, 0.0, 0.0, 0.0, 0.0, -4.861, -4.861]}
{"number_of_episodes": 2324, "number_of_timesteps": 34078, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 770, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 771.0, 1.0, 1.0, 1.0, 1.0, 1.0, 771.0, 771.0], "q_vals": [0.0, 0.0, -4.933, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"number_of_episodes": 2328, "number_of_timesteps": 34132, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 771, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 772.0, 1.0, 1.0, 1.0, 1.0, 1.0, 772.0, 772.0], "q_vals": [0.0, 0.0, -4.927, 0.0, 0.0, 0.0, 0.0, 0.0, -4.848, -4.848]}
{"step": 772, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 773.0, 1.0, 1.0, 1.0, 1.0, 1.0, 773.0, 773.0], "q_vals": [0.0, 0.0, -4.921, 0.0, 0.0, 0.0, 0.0, 0.0, -4.85, -4.85]}
{"number_of_episodes": 2332, "number_of_timesteps": 34179, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 773, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 774.0, 1.0, 1.0, 1.0, 1.0, 1.0, 774.0, 774.0], "q_vals": [0.0, 0.0, -4.917, 0.0, 0.0, 0.0, 0.0, 0.0, -4.846, -4.846]}
{"number_of_episodes": 2339, "number_of_timesteps": 34273, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.3000000000000007},
{"step": 774, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 775.0, 1.0, 1.0, 1.0, 1.0, 1.0, 775.0, 775.0], "q_vals": [0.0, 0.0, -4.911, 0.0, 0.0, 0.0, 0.0, 0.0, -4.845, -4.845]}
{"step": 775, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 776.0, 1.0, 1.0, 1.0, 1.0, 1.0, 776.0, 776.0], "q_vals": [0.0, 0.0, -4.911, 0.0, 0.0, 0.0, 0.0, 0.0, -4.845, -4.845]}
{"eval_score": 16.6, "number_of_episodes": 2342}
{"number_of_episodes": 2342, "number_of_timesteps": 34306, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"step": 776, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 777.0, 1.0, 1.0, 1.0, 1.0, 1.0, 777.0, 777.0], "q_vals": [0.0, 0.0, -4.904, 0.0, 0.0, 0.0, 0.0, 0.0, -4.839, -4.839]}
{"number_of_episodes": 2346, "number_of_timesteps": 34364, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 777, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 778.0, 1.0, 1.0, 1.0, 1.0, 1.0, 778.0, 778.0], "q_vals": [0.0, 0.0, -4.904, 0.0, 0.0, 0.0, 0.0, 0.0, -4.838, -4.838]}
{"step": 778, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 779.0, 1.0, 1.0, 1.0, 1.0, 1.0, 779.0, 779.0], "q_vals": [0.0, 0.0, -4.907, 0.0, 0.0, 0.0, 0.0, 0.0, -4.839, -4.839]}
{"number_of_episodes": 2352, "number_of_timesteps": 34468, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 779, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 780.0, 1.0, 1.0, 1.0, 1.0, 1.0, 780.0, 780.0], "q_vals": [0.0, 0.0, -4.907, 0.0, 0.0, 0.0, 0.0, 0.0, -4.839, -4.839]}
{"number_of_episodes": 2355, "number_of_timesteps": 34518, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 780, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 781.0, 1.0, 1.0, 1.0, 1.0, 1.0, 781.0, 781.0], "q_vals": [0.0, 0.0, -4.901, 0.0, 0.0, 0.0, 0.0, 0.0, -4.833, -4.833]}
{"step": 781, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 782.0, 1.0, 1.0, 1.0, 1.0, 1.0, 782.0, 782.0], "q_vals": [0.0, 0.0, -4.894, 0.0, 0.0, 0.0, 0.0, 0.0, -4.826, -4.826]}
{"number_of_episodes": 2364, "number_of_timesteps": 34635, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 782, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 783.0, 1.0, 1.0, 1.0, 1.0, 1.0, 783.0, 783.0], "q_vals": [0.0, 0.0, -4.904, 0.0, 0.0, 0.0, 0.0, 0.0, -4.834, -4.834]}
{"number_of_episodes": 2365, "number_of_timesteps": 34651, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.3000000000000007},
{"step": 783, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 784.0, 1.0, 1.0, 1.0, 1.0, 1.0, 784.0, 784.0], "q_vals": [0.0, 0.0, -4.898, 0.0, 0.0, 0.0, 0.0, 0.0, -4.834, -4.834]}
{"number_of_episodes": 2367, "number_of_timesteps": 34673, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 784, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 785.0, 1.0, 1.0, 1.0, 1.0, 1.0, 785.0, 785.0], "q_vals": [0.0, 0.0, -4.898, 0.0, 0.0, 0.0, 0.0, 0.0, -4.833, -4.833]}
{"number_of_episodes": 2372, "number_of_timesteps": 34745, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 785, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 786.0, 1.0, 1.0, 1.0, 1.0, 1.0, 786.0, 786.0], "q_vals": [0.0, 0.0, -4.907, 0.0, 0.0, 0.0, 0.0, 0.0, -4.84, -4.84]}
{"step": 786, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 787.0, 1.0, 1.0, 1.0, 1.0, 1.0, 787.0, 787.0], "q_vals": [0.0, 0.0, -4.931, 0.0, 0.0, 0.0, 0.0, 0.0, -4.861, -4.861]}
{"number_of_episodes": 2379, "number_of_timesteps": 34830, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 787, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 788.0, 1.0, 1.0, 1.0, 1.0, 1.0, 788.0, 788.0], "q_vals": [0.0, 0.0, -4.945, 0.0, 0.0, 0.0, 0.0, 0.0, -4.873, -4.873]}
{"number_of_episodes": 2381, "number_of_timesteps": 34854, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 788, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 789.0, 1.0, 1.0, 1.0, 1.0, 1.0, 789.0, 789.0], "q_vals": [0.0, 0.0, -4.939, 0.0, 0.0, 0.0, 0.0, 0.0, -4.867, -4.867]}
{"number_of_episodes": 2386, "number_of_timesteps": 34913, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"step": 789, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 790.0, 1.0, 1.0, 1.0, 1.0, 1.0, 790.0, 790.0], "q_vals": [0.0, 0.0, -4.933, 0.0, 0.0, 0.0, 0.0, 0.0, -4.861, -4.861]}
{"step": 790, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 791.0, 1.0, 1.0, 1.0, 1.0, 1.0, 791.0, 791.0], "q_vals": [0.0, 0.0, -4.927, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"number_of_episodes": 2393, "number_of_timesteps": 35010, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 791, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 792.0, 1.0, 1.0, 1.0, 1.0, 1.0, 792.0, 792.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"number_of_episodes": 2397, "number_of_timesteps": 35059, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 792, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 793.0, 1.0, 1.0, 1.0, 1.0, 1.0, 793.0, 793.0], "q_vals": [0.0, 0.0, -4.939, 0.0, 0.0, 0.0, 0.0, 0.0, -4.864, -4.864]}
{"number_of_episodes": 2402, "number_of_timesteps": 35117, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 793, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 794.0, 1.0, 1.0, 1.0, 1.0, 1.0, 794.0, 794.0], "q_vals": [0.0, 0.0, -4.933, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 2406, "number_of_timesteps": 35156, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 794, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 795.0, 1.0, 1.0, 1.0, 1.0, 1.0, 795.0, 795.0], "q_vals": [0.0, 0.0, -4.936, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"number_of_episodes": 2407, "number_of_timesteps": 35168, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 795, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 796.0, 1.0, 1.0, 1.0, 1.0, 1.0, 796.0, 796.0], "q_vals": [0.0, 0.0, -4.948, 0.0, 0.0, 0.0, 0.0, 0.0, -4.871, -4.871]}
{"step": 796, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 797.0, 1.0, 1.0, 1.0, 1.0, 1.0, 797.0, 797.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.872, -4.872]}
{"number_of_episodes": 2415, "number_of_timesteps": 35263, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 797, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 798.0, 1.0, 1.0, 1.0, 1.0, 1.0, 798.0, 798.0], "q_vals": [0.0, 0.0, -4.944, 0.0, 0.0, 0.0, 0.0, 0.0, -4.866, -4.866]}
{"number_of_episodes": 2418, "number_of_timesteps": 35291, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 798, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 799.0, 1.0, 1.0, 1.0, 1.0, 1.0, 799.0, 799.0], "q_vals": [0.0, 0.0, -4.945, 0.0, 0.0, 0.0, 0.0, 0.0, -4.866, -4.866]}
{"step": 799, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 800.0, 1.0, 1.0, 1.0, 1.0, 1.0, 800.0, 800.0], "q_vals": [0.0, 0.0, -4.948, 0.0, 0.0, 0.0, 0.0, 0.0, -4.867, -4.867]}
{"number_of_episodes": 2424, "number_of_timesteps": 35393, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.3000000000000007},
{"step": 800, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 801.0, 1.0, 1.0, 1.0, 1.0, 1.0, 801.0, 801.0], "q_vals": [0.0, 0.0, -4.941, 0.0, 0.0, 0.0, 0.0, 0.0, -4.868, -4.868]}
{"number_of_episodes": 2429, "number_of_timesteps": 35454, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 801, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 802.0, 1.0, 1.0, 1.0, 1.0, 1.0, 802.0, 802.0], "q_vals": [0.0, 0.0, -4.943, 0.0, 0.0, 0.0, 0.0, 0.0, -4.869, -4.869]}
{"number_of_episodes": 2433, "number_of_timesteps": 35512, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 802, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 803.0, 1.0, 1.0, 1.0, 1.0, 1.0, 803.0, 803.0], "q_vals": [0.0, 0.0, -4.957, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 2436, "number_of_timesteps": 35540, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 803, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 804.0, 1.0, 1.0, 1.0, 1.0, 1.0, 804.0, 804.0], "q_vals": [0.0, 0.0, -4.962, 0.0, 0.0, 0.0, 0.0, 0.0, -4.885, -4.885]}
{"step": 804, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 805.0, 1.0, 1.0, 1.0, 1.0, 1.0, 805.0, 805.0], "q_vals": [0.0, 0.0, -4.977, 0.0, 0.0, 0.0, 0.0, 0.0, -4.897, -4.897]}
{"number_of_episodes": 2443, "number_of_timesteps": 35616, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
{"step": 805, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 806.0, 1.0, 1.0, 1.0, 1.0, 1.0, 806.0, 806.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 2450, "number_of_timesteps": 35690, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 806, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 807.0, 1.0, 1.0, 1.0, 1.0, 1.0, 807.0, 807.0], "q_vals": [0.0, 0.0, -4.98, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 2451, "number_of_timesteps": 35706, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 807, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 808.0, 1.0, 1.0, 1.0, 1.0, 1.0, 808.0, 808.0], "q_vals": [0.0, 0.0, -4.993, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"number_of_episodes": 2456, "number_of_timesteps": 35758, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.1999999999999993},
{"step": 808, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 809.0, 1.0, 1.0, 1.0, 1.0, 1.0, 809.0, 809.0], "q_vals": [0.0, 0.0, -4.987, 0.0, 0.0, 0.0, 0.0, 0.0, -4.903, -4.903]}
{"number_of_episodes": 2461, "number_of_timesteps": 35820, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 809, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 810.0, 1.0, 1.0, 1.0, 1.0, 1.0, 810.0, 810.0], "q_vals": [0.0, 0.0, -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.915, -4.915]}
{"number_of_episodes": 2463, "number_of_timesteps": 35839, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.3000000000000007},
{"step": 810, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 811.0, 1.0, 1.0, 1.0, 1.0, 1.0, 811.0, 811.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.915, -4.915]}
{"number_of_episodes": 2466, "number_of_timesteps": 35872, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"step": 811, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 812.0, 1.0, 1.0, 1.0, 1.0, 1.0, 812.0, 812.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"eval_score": 12.9, "number_of_episodes": 2472}
{"number_of_episodes": 2472, "number_of_timesteps": 35953, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 812, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 813.0, 1.0, 1.0, 1.0, 1.0, 1.0, 813.0, 813.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"step": 813, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 814.0, 1.0, 1.0, 1.0, 1.0, 1.0, 814.0, 814.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.908, -4.908]}
{"number_of_episodes": 2477, "number_of_timesteps": 36013, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 814, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 815.0, 1.0, 1.0, 1.0, 1.0, 1.0, 815.0, 815.0], "q_vals": [0.0, 0.0, -4.983, 0.0, 0.0, 0.0, 0.0, 0.0, -4.902, -4.902]}
{"step": 815, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 816.0, 1.0, 1.0, 1.0, 1.0, 1.0, 816.0, 816.0], "q_vals": [0.0, 0.0, -4.978, 0.0, 0.0, 0.0, 0.0, 0.0, -4.897, -4.897]}
{"number_of_episodes": 2484, "number_of_timesteps": 36108, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 816, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 817.0, 1.0, 1.0, 1.0, 1.0, 1.0, 817.0, 817.0], "q_vals": [0.0, 0.0, -4.977, 0.0, 0.0, 0.0, 0.0, 0.0, -4.896, -4.896]}
{"step": 817, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 818.0, 1.0, 1.0, 1.0, 1.0, 1.0, 818.0, 818.0], "q_vals": [0.0, 0.0, -4.978, 0.0, 0.0, 0.0, 0.0, 0.0, -4.896, -4.896]}
{"number_of_episodes": 2493, "number_of_timesteps": 36215, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.20000000000000107},
{"step": 818, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 819.0, 1.0, 1.0, 1.0, 1.0, 1.0, 819.0, 819.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.89, -4.89]}
{"number_of_episodes": 2495, "number_of_timesteps": 36237, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"step": 819, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 820.0, 1.0, 1.0, 1.0, 1.0, 1.0, 820.0, 820.0], "q_vals": [0.0, 0.0, -4.966, 0.0, 0.0, 0.0, 0.0, 0.0, -4.884, -4.884]}
{"number_of_episodes": 2501, "number_of_timesteps": 36297, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 820, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 821.0, 1.0, 1.0, 1.0, 1.0, 1.0, 821.0, 821.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 2502, "number_of_timesteps": 36308, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3000000000000007},
{"step": 821, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 822.0, 1.0, 1.0, 1.0, 1.0, 1.0, 822.0, 822.0], "q_vals": [0.0, 0.0, -4.973, 0.0, 0.0, 0.0, 0.0, 0.0, -4.894, -4.894]}
{"number_of_episodes": 2504, "number_of_timesteps": 36336, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.3000000000000007},
{"step": 822, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 823.0, 1.0, 1.0, 1.0, 1.0, 1.0, 823.0, 823.0], "q_vals": [0.0, 0.0, -4.974, 0.0, 0.0, 0.0, 0.0, 0.0, -4.894, -4.894]}
{"number_of_episodes": 2508, "number_of_timesteps": 36403, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 823, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 824.0, 1.0, 1.0, 1.0, 1.0, 1.0, 824.0, 824.0], "q_vals": [0.0, 0.0, -4.974, 0.0, 0.0, 0.0, 0.0, 0.0, -4.894, -4.894]}
{"step": 824, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 825.0, 1.0, 1.0, 1.0, 1.0, 1.0, 825.0, 825.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 2514, "number_of_timesteps": 36491, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 825, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 826.0, 1.0, 1.0, 1.0, 1.0, 1.0, 826.0, 826.0], "q_vals": [0.0, 0.0, -4.97, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 2518, "number_of_timesteps": 36550, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 826, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 827.0, 1.0, 1.0, 1.0, 1.0, 1.0, 827.0, 827.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.888, -4.888]}
{"number_of_episodes": 2521, "number_of_timesteps": 36587, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 827, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 828.0, 1.0, 1.0, 1.0, 1.0, 1.0, 828.0, 828.0], "q_vals": [0.0, 0.0, -4.971, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 2522, "number_of_timesteps": 36603, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 828, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 829.0, 1.0, 1.0, 1.0, 1.0, 1.0, 829.0, 829.0], "q_vals": [0.0, 0.0, -4.973, 0.0, 0.0, 0.0, 0.0, 0.0, -4.89, -4.89]}
{"number_of_episodes": 2526, "number_of_timesteps": 36666, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 829, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 830.0, 1.0, 1.0, 1.0, 1.0, 1.0, 830.0, 830.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.884, -4.884]}
{"step": 830, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 831.0, 1.0, 1.0, 1.0, 1.0, 1.0, 831.0, 831.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.884, -4.884]}
{"number_of_episodes": 2533, "number_of_timesteps": 36768, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 831, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 832.0, 1.0, 1.0, 1.0, 1.0, 1.0, 832.0, 832.0], "q_vals": [0.0, 0.0, -4.961, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"number_of_episodes": 2535, "number_of_timesteps": 36799, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 832, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 833.0, 1.0, 1.0, 1.0, 1.0, 1.0, 833.0, 833.0], "q_vals": [0.0, 0.0, -4.962, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"number_of_episodes": 2539, "number_of_timesteps": 36848, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 833, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 834.0, 1.0, 1.0, 1.0, 1.0, 1.0, 834.0, 834.0], "q_vals": [0.0, 0.0, -4.973, 0.0, 0.0, 0.0, 0.0, 0.0, -4.887, -4.887]}
{"step": 834, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 835.0, 1.0, 1.0, 1.0, 1.0, 1.0, 835.0, 835.0], "q_vals": [0.0, 0.0, -4.97, 0.0, 0.0, 0.0, 0.0, 0.0, -4.884, -4.884]}
{"number_of_episodes": 2545, "number_of_timesteps": 36942, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.20000000000000107},
{"step": 835, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 836.0, 1.0, 1.0, 1.0, 1.0, 1.0, 836.0, 836.0], "q_vals": [0.0, 0.0, -4.964, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"number_of_episodes": 2546, "number_of_timesteps": 36953, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 836, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 837.0, 1.0, 1.0, 1.0, 1.0, 1.0, 837.0, 837.0], "q_vals": [0.0, 0.0, -4.958, 0.0, 0.0, 0.0, 0.0, 0.0, -4.872, -4.872]}
{"number_of_episodes": 2550, "number_of_timesteps": 37007, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.3000000000000007},
{"step": 837, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 838.0, 1.0, 1.0, 1.0, 1.0, 1.0, 838.0, 838.0], "q_vals": [0.0, 0.0, -4.96, 0.0, 0.0, 0.0, 0.0, 0.0, -4.873, -4.873]}
{"number_of_episodes": 2553, "number_of_timesteps": 37059, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 838, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 839.0, 1.0, 1.0, 1.0, 1.0, 1.0, 839.0, 839.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.886, -4.886]}
{"number_of_episodes": 2555, "number_of_timesteps": 37086, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 839, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 840.0, 1.0, 1.0, 1.0, 1.0, 1.0, 840.0, 840.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 2561, "number_of_timesteps": 37159, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 840, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 841.0, 1.0, 1.0, 1.0, 1.0, 1.0, 841.0, 841.0], "q_vals": [0.0, 0.0, -4.973, 0.0, 0.0, 0.0, 0.0, 0.0, -4.883, -4.883]}
{"number_of_episodes": 2563, "number_of_timesteps": 37211, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 841, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 842.0, 1.0, 1.0, 1.0, 1.0, 1.0, 842.0, 842.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.877, -4.877]}
{"number_of_episodes": 2564, "number_of_timesteps": 37222, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.3000000000000007},
{"step": 842, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 843.0, 1.0, 1.0, 1.0, 1.0, 1.0, 843.0, 843.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.877, -4.877]}
{"step": 843, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 844.0, 1.0, 1.0, 1.0, 1.0, 1.0, 844.0, 844.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"step": 844, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 845.0, 1.0, 1.0, 1.0, 1.0, 1.0, 845.0, 845.0], "q_vals": [0.0, 0.0, -4.971, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"number_of_episodes": 2576, "number_of_timesteps": 37382, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 845, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 846.0, 1.0, 1.0, 1.0, 1.0, 1.0, 846.0, 846.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.885, -4.885]}
{"number_of_episodes": 2580, "number_of_timesteps": 37433, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 846, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 847.0, 1.0, 1.0, 1.0, 1.0, 1.0, 847.0, 847.0], "q_vals": [0.0, 0.0, -4.973, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"step": 847, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 848.0, 1.0, 1.0, 1.0, 1.0, 1.0, 848.0, 848.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.873, -4.873]}
{"step": 848, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 849.0, 1.0, 1.0, 1.0, 1.0, 1.0, 849.0, 849.0], "q_vals": [0.0, 0.0, -4.98, 0.0, 0.0, 0.0, 0.0, 0.0, -4.884, -4.884]}
{"number_of_episodes": 2589, "number_of_timesteps": 37545, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.3000000000000007},
{"step": 849, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 850.0, 1.0, 1.0, 1.0, 1.0, 1.0, 850.0, 850.0], "q_vals": [0.0, 0.0, -4.982, 0.0, 0.0, 0.0, 0.0, 0.0, -4.885, -4.885]}
{"step": 850, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 851.0, 1.0, 1.0, 1.0, 1.0, 1.0, 851.0, 851.0], "q_vals": [0.0, 0.0, -4.983, 0.0, 0.0, 0.0, 0.0, 0.0, -4.886, -4.886]}
{"number_of_episodes": 2596, "number_of_timesteps": 37650, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 851, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 852.0, 1.0, 1.0, 1.0, 1.0, 1.0, 852.0, 852.0], "q_vals": [0.0, 0.0, -4.983, 0.0, 0.0, 0.0, 0.0, 0.0, -4.885, -4.885]}
{"step": 852, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 853.0, 1.0, 1.0, 1.0, 1.0, 1.0, 853.0, 853.0], "q_vals": [0.0, 0.0, -4.985, 0.0, 0.0, 0.0, 0.0, 0.0, -4.886, -4.886]}
{"eval_score": 14.2, "number_of_episodes": 2600}
{"number_of_episodes": 2600, "number_of_timesteps": 37711, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.20000000000000107},
{"step": 853, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 854.0, 1.0, 1.0, 1.0, 1.0, 1.0, 854.0, 854.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"step": 854, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 855.0, 1.0, 1.0, 1.0, 1.0, 1.0, 855.0, 855.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.88, -4.88]}
{"number_of_episodes": 2608, "number_of_timesteps": 37813, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 855, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 856.0, 1.0, 1.0, 1.0, 1.0, 1.0, 856.0, 856.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 2610, "number_of_timesteps": 37854, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 856, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 857.0, 1.0, 1.0, 1.0, 1.0, 1.0, 857.0, 857.0], "q_vals": [0.0, 0.0, -4.993, 0.0, 0.0, 0.0, 0.0, 0.0, -4.891, -4.891]}
{"step": 857, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 858.0, 1.0, 1.0, 1.0, 1.0, 1.0, 858.0, 858.0], "q_vals": [0.0, 0.0, -4.993, 0.0, 0.0, 0.0, 0.0, 0.0, -4.891, -4.891]}
{"number_of_episodes": 2617, "number_of_timesteps": 37939, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3000000000000007},
{"step": 858, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 859.0, 1.0, 1.0, 1.0, 1.0, 1.0, 859.0, 859.0], "q_vals": [0.0, 0.0, -4.996, 0.0, 0.0, 0.0, 0.0, 0.0, -4.893, -4.893]}
{"number_of_episodes": 2619, "number_of_timesteps": 37958, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 859, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 860.0, 1.0, 1.0, 1.0, 1.0, 1.0, 860.0, 860.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.887, -4.887]}
{"step": 860, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 861.0, 1.0, 1.0, 1.0, 1.0, 1.0, 861.0, 861.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.888, -4.888]}
{"number_of_episodes": 2626, "number_of_timesteps": 38083, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 861, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 862.0, 1.0, 1.0, 1.0, 1.0, 1.0, 862.0, 862.0], "q_vals": [0.0, 0.0, -4.993, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 2627, "number_of_timesteps": 38122, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 862, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 863.0, 1.0, 1.0, 1.0, 1.0, 1.0, 863.0, 863.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.891, -4.891]}
{"number_of_episodes": 2632, "number_of_timesteps": 38193, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 863, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 864.0, 1.0, 1.0, 1.0, 1.0, 1.0, 864.0, 864.0], "q_vals": [0.0, 0.0, -5.005, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 2634, "number_of_timesteps": 38215, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 864, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 865.0, 1.0, 1.0, 1.0, 1.0, 1.0, 865.0, 865.0], "q_vals": [0.0, 0.0, -5.007, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 2638, "number_of_timesteps": 38278, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 865, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 866.0, 1.0, 1.0, 1.0, 1.0, 1.0, 866.0, 866.0], "q_vals": [0.0, 0.0, -5.03, 0.0, 0.0, 0.0, 0.0, 0.0, -4.918, -4.918]}
{"number_of_episodes": 2640, "number_of_timesteps": 38305, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 866, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 867.0, 1.0, 1.0, 1.0, 1.0, 1.0, 867.0, 867.0], "q_vals": [0.0, 0.0, -5.024, 0.0, 0.0, 0.0, 0.0, 0.0, -4.913, -4.913]}
{"number_of_episodes": 2644, "number_of_timesteps": 38369, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 867, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 868.0, 1.0, 1.0, 1.0, 1.0, 1.0, 868.0, 868.0], "q_vals": [0.0, 0.0, -5.023, 0.0, 0.0, 0.0, 0.0, 0.0, -4.912, -4.912]}
{"step": 868, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 869.0, 1.0, 1.0, 1.0, 1.0, 1.0, 869.0, 869.0], "q_vals": [0.0, 0.0, -5.024, 0.0, 0.0, 0.0, 0.0, 0.0, -4.912, -4.912]}
{"number_of_episodes": 2649, "number_of_timesteps": 38447, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.3000000000000007},
{"step": 869, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 870.0, 1.0, 1.0, 1.0, 1.0, 1.0, 870.0, 870.0], "q_vals": [0.0, 0.0, -5.025, 0.0, 0.0, 0.0, 0.0, 0.0, -4.912, -4.912]}
{"number_of_episodes": 2650, "number_of_timesteps": 38468, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 870, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 871.0, 1.0, 1.0, 1.0, 1.0, 1.0, 871.0, 871.0], "q_vals": [0.0, 0.0, -5.026, 0.0, 0.0, 0.0, 0.0, 0.0, -4.912, -4.912]}
{"number_of_episodes": 2652, "number_of_timesteps": 38495, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 871, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 872.0, 1.0, 1.0, 1.0, 1.0, 1.0, 872.0, 872.0], "q_vals": [0.0, 0.0, -5.028, 0.0, 0.0, 0.0, 0.0, 0.0, -4.914, -4.914]}
{"number_of_episodes": 2656, "number_of_timesteps": 38559, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 872, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 873.0, 1.0, 1.0, 1.0, 1.0, 1.0, 873.0, 873.0], "q_vals": [0.0, 0.0, -5.022, 0.0, 0.0, 0.0, 0.0, 0.0, -4.908, -4.908]}
{"number_of_episodes": 2658, "number_of_timesteps": 38606, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 873, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 874.0, 1.0, 1.0, 1.0, 1.0, 1.0, 874.0, 874.0], "q_vals": [0.0, 0.0, -5.022, 0.0, 0.0, 0.0, 0.0, 0.0, -4.907, -4.907]}
{"number_of_episodes": 2661, "number_of_timesteps": 38664, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 874, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 875.0, 1.0, 1.0, 1.0, 1.0, 1.0, 875.0, 875.0], "q_vals": [0.0, 0.0, -5.033, 0.0, 0.0, 0.0, 0.0, 0.0, -4.916, -4.916]}
{"number_of_episodes": 2662, "number_of_timesteps": 38677, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.3000000000000007},
{"step": 875, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 876.0, 1.0, 1.0, 1.0, 1.0, 1.0, 876.0, 876.0], "q_vals": [0.0, 0.0, -5.033, 0.0, 0.0, 0.0, 0.0, 0.0, -4.916, -4.916]}
{"number_of_episodes": 2666, "number_of_timesteps": 38741, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.3000000000000007},
{"step": 876, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 877.0, 1.0, 1.0, 1.0, 1.0, 1.0, 877.0, 877.0], "q_vals": [0.0, 0.0, -5.027, 0.0, 0.0, 0.0, 0.0, 0.0, -4.915, -4.915]}
{"number_of_episodes": 2670, "number_of_timesteps": 38815, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 877, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 878.0, 1.0, 1.0, 1.0, 1.0, 1.0, 878.0, 878.0], "q_vals": [0.0, 0.0, -5.022, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"number_of_episodes": 2672, "number_of_timesteps": 38843, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 878, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 879.0, 1.0, 1.0, 1.0, 1.0, 1.0, 879.0, 879.0], "q_vals": [0.0, 0.0, -5.024, 0.0, 0.0, 0.0, 0.0, 0.0, -4.911, -4.911]}
{"number_of_episodes": 2674, "number_of_timesteps": 38866, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 879, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 880.0, 1.0, 1.0, 1.0, 1.0, 1.0, 880.0, 880.0], "q_vals": [0.0, 0.0, -5.024, 0.0, 0.0, 0.0, 0.0, 0.0, -4.91, -4.91]}
{"number_of_episodes": 2676, "number_of_timesteps": 38898, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.25},
{"step": 880, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 881.0, 1.0, 1.0, 1.0, 1.0, 1.0, 881.0, 881.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"number_of_episodes": 2680, "number_of_timesteps": 38964, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 881, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 882.0, 1.0, 1.0, 1.0, 1.0, 1.0, 882.0, 882.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.908, -4.908]}
{"step": 882, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 883.0, 1.0, 1.0, 1.0, 1.0, 1.0, 883.0, 883.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.91, -4.91]}
{"step": 883, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 884.0, 1.0, 1.0, 1.0, 1.0, 1.0, 884.0, 884.0], "q_vals": [0.0, 0.0, -5.006, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"number_of_episodes": 2688, "number_of_timesteps": 39105, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
{"step": 884, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 885.0, 1.0, 1.0, 1.0, 1.0, 1.0, 885.0, 885.0], "q_vals": [0.0, 0.0, -5.001, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 2692, "number_of_timesteps": 39171, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.25},
{"step": 885, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 886.0, 1.0, 1.0, 1.0, 1.0, 1.0, 886.0, 886.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.896, -4.896]}
{"number_of_episodes": 2694, "number_of_timesteps": 39189, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 886, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 887.0, 1.0, 1.0, 1.0, 1.0, 1.0, 887.0, 887.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 2697, "number_of_timesteps": 39229, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.3000000000000007},
{"step": 887, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 888.0, 1.0, 1.0, 1.0, 1.0, 1.0, 888.0, 888.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.896, -4.896]}
{"step": 888, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 889.0, 1.0, 1.0, 1.0, 1.0, 1.0, 889.0, 889.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 2705, "number_of_timesteps": 39365, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 889, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 890.0, 1.0, 1.0, 1.0, 1.0, 1.0, 890.0, 890.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 2705, "number_of_timesteps": 39365, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.25},
{"step": 890, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 891.0, 1.0, 1.0, 1.0, 1.0, 1.0, 891.0, 891.0], "q_vals": [0.0, 0.0, -4.993, 0.0, 0.0, 0.0, 0.0, 0.0, -4.891, -4.891]}
{"step": 891, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 892.0, 1.0, 1.0, 1.0, 1.0, 1.0, 892.0, 892.0], "q_vals": [0.0, 0.0, -5.004, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"number_of_episodes": 2714, "number_of_timesteps": 39474, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.29999999999999893},
{"step": 892, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 893.0, 1.0, 1.0, 1.0, 1.0, 1.0, 893.0, 893.0], "q_vals": [0.0, 0.0, -5.004, 0.0, 0.0, 0.0, 0.0, 0.0, -4.9, -4.9]}
{"number_of_episodes": 2715, "number_of_timesteps": 39484, "per_episode_reward": 12.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
{"step": 893, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 894.0, 1.0, 1.0, 1.0, 1.0, 1.0, 894.0, 894.0], "q_vals": [0.0, 0.0, -5.005, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"step": 894, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 895.0, 1.0, 1.0, 1.0, 1.0, 1.0, 895.0, 895.0], "q_vals": [0.0, 0.0, -5.002, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 2721, "number_of_timesteps": 39587, "per_episode_reward": 12.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.1999999999999993},
{"step": 895, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 896.0, 1.0, 1.0, 1.0, 1.0, 1.0, 896.0, 896.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.892, -4.892]}
{"number_of_episodes": 2725, "number_of_timesteps": 39642, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 896, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 897.0, 1.0, 1.0, 1.0, 1.0, 1.0, 897.0, 897.0], "q_vals": [0.0, 0.0, -5.013, 0.0, 0.0, 0.0, 0.0, 0.0, -4.906, -4.906]}
{"number_of_episodes": 2727, "number_of_timesteps": 39679, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 897, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 898.0, 1.0, 1.0, 1.0, 1.0, 1.0, 898.0, 898.0], "q_vals": [0.0, 0.0, -5.007, 0.0, 0.0, 0.0, 0.0, 0.0, -4.9, -4.9]}
{"eval_score": 16.3, "number_of_episodes": 2732}
{"number_of_episodes": 2732, "number_of_timesteps": 39743, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 898, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 899.0, 1.0, 1.0, 1.0, 1.0, 1.0, 899.0, 899.0], "q_vals": [0.0, 0.0, -5.007, 0.0, 0.0, 0.0, 0.0, 0.0, -4.9, -4.9]}
{"number_of_episodes": 2735, "number_of_timesteps": 39779, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 899, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 900.0, 1.0, 1.0, 1.0, 1.0, 1.0, 900.0, 900.0], "q_vals": [0.0, 0.0, -5.002, 0.0, 0.0, 0.0, 0.0, 0.0, -4.894, -4.894]}
{"step": 900, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 901.0, 1.0, 1.0, 1.0, 1.0, 1.0, 901.0, 901.0], "q_vals": [0.0, 0.0, -5.003, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 2738, "number_of_timesteps": 39818, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.25},
{"step": 901, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 902.0, 1.0, 1.0, 1.0, 1.0, 1.0, 902.0, 902.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.896, -4.896]}
{"number_of_episodes": 2741, "number_of_timesteps": 39876, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 902, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 903.0, 1.0, 1.0, 1.0, 1.0, 1.0, 903.0, 903.0], "q_vals": [0.0, 0.0, -5.009, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"number_of_episodes": 2744, "number_of_timesteps": 39930, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 903, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 904.0, 1.0, 1.0, 1.0, 1.0, 1.0, 904.0, 904.0], "q_vals": [0.0, 0.0, -5.011, 0.0, 0.0, 0.0, 0.0, 0.0, -4.906, -4.906]}
{"number_of_episodes": 2746, "number_of_timesteps": 39968, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 904, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 905.0, 1.0, 1.0, 1.0, 1.0, 1.0, 905.0, 905.0], "q_vals": [0.0, 0.0, -5.011, 0.0, 0.0, 0.0, 0.0, 0.0, -4.906, -4.906]}
{"number_of_episodes": 2748, "number_of_timesteps": 40011, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 905, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 906.0, 1.0, 1.0, 1.0, 1.0, 1.0, 906.0, 906.0], "q_vals": [0.0, 0.0, -5.006, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"step": 906, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 907.0, 1.0, 1.0, 1.0, 1.0, 1.0, 907.0, 907.0], "q_vals": [0.0, 0.0, -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 2754, "number_of_timesteps": 40123, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.25},
{"step": 907, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 908.0, 1.0, 1.0, 1.0, 1.0, 1.0, 908.0, 908.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.91, -4.91]}
{"number_of_episodes": 2755, "number_of_timesteps": 40147, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 908, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 909.0, 1.0, 1.0, 1.0, 1.0, 1.0, 909.0, 909.0], "q_vals": [0.0, 0.0, -5.028, 0.0, 0.0, 0.0, 0.0, 0.0, -4.919, -4.919]}
{"step": 909, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 910.0, 1.0, 1.0, 1.0, 1.0, 1.0, 910.0, 910.0], "q_vals": [0.0, 0.0, -5.026, 0.0, 0.0, 0.0, 0.0, 0.0, -4.916, -4.916]}
{"number_of_episodes": 2761, "number_of_timesteps": 40248, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.25},
{"step": 910, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 911.0, 1.0, 1.0, 1.0, 1.0, 1.0, 911.0, 911.0], "q_vals": [0.0, 0.0, -5.02, 0.0, 0.0, 0.0, 0.0, 0.0, -4.915, -4.915]}
{"step": 911, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 912.0, 1.0, 1.0, 1.0, 1.0, 1.0, 912.0, 912.0], "q_vals": [0.0, 0.0, -5.015, 0.0, 0.0, 0.0, 0.0, 0.0, -4.916, -4.916]}
{"number_of_episodes": 2767, "number_of_timesteps": 40360, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.14999999999999858},
{"step": 912, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 913.0, 1.0, 1.0, 1.0, 1.0, 1.0, 913.0, 913.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.919, -4.919]}
{"number_of_episodes": 2770, "number_of_timesteps": 40393, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 913, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 914.0, 1.0, 1.0, 1.0, 1.0, 1.0, 914.0, 914.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.918, -4.918]}
{"number_of_episodes": 2774, "number_of_timesteps": 40459, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.25},
{"step": 914, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 915.0, 1.0, 1.0, 1.0, 1.0, 1.0, 915.0, 915.0], "q_vals": [0.0, 0.0, -5.013, 0.0, 0.0, 0.0, 0.0, 0.0, -4.917, -4.917]}
{"step": 915, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 916.0, 1.0, 1.0, 1.0, 1.0, 1.0, 916.0, 916.0], "q_vals": [0.0, 0.0, -5.013, 0.0, 0.0, 0.0, 0.0, 0.0, -4.917, -4.917]}
{"number_of_episodes": 2779, "number_of_timesteps": 40519, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"step": 916, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 917.0, 1.0, 1.0, 1.0, 1.0, 1.0, 917.0, 917.0], "q_vals": [0.0, 0.0, -5.008, 0.0, 0.0, 0.0, 0.0, 0.0, -4.912, -4.912]}
{"step": 917, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 918.0, 1.0, 1.0, 1.0, 1.0, 1.0, 918.0, 918.0], "q_vals": [0.0, 0.0, -5.007, 0.0, 0.0, 0.0, 0.0, 0.0, -4.91, -4.91]}
{"number_of_episodes": 2784, "number_of_timesteps": 40581, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.25},
{"step": 918, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 919.0, 1.0, 1.0, 1.0, 1.0, 1.0, 919.0, 919.0], "q_vals": [0.0, 0.0, -5.02, 0.0, 0.0, 0.0, 0.0, 0.0, -4.921, -4.921]}
{"number_of_episodes": 2788, "number_of_timesteps": 40650, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 919, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 920.0, 1.0, 1.0, 1.0, 1.0, 1.0, 920.0, 920.0], "q_vals": [0.0, 0.0, -5.019, 0.0, 0.0, 0.0, 0.0, 0.0, -4.92, -4.92]}
{"number_of_episodes": 2791, "number_of_timesteps": 40690, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 920, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 921.0, 1.0, 1.0, 1.0, 1.0, 1.0, 921.0, 921.0], "q_vals": [0.0, 0.0, -5.021, 0.0, 0.0, 0.0, 0.0, 0.0, -4.921, -4.921]}
{"number_of_episodes": 2793, "number_of_timesteps": 40748, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 921, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 922.0, 1.0, 1.0, 1.0, 1.0, 1.0, 922.0, 922.0], "q_vals": [0.0, 0.0, -5.024, 0.0, 0.0, 0.0, 0.0, 0.0, -4.923, -4.923]}
{"number_of_episodes": 2797, "number_of_timesteps": 40805, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 922, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 923.0, 1.0, 1.0, 1.0, 1.0, 1.0, 923.0, 923.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.918, -4.918]}
{"number_of_episodes": 2801, "number_of_timesteps": 40855, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.25},
{"step": 923, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 924.0, 1.0, 1.0, 1.0, 1.0, 1.0, 924.0, 924.0], "q_vals": [0.0, 0.0, -5.03, 0.0, 0.0, 0.0, 0.0, 0.0, -4.928, -4.928]}
{"number_of_episodes": 2802, "number_of_timesteps": 40876, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 924, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 925.0, 1.0, 1.0, 1.0, 1.0, 1.0, 925.0, 925.0], "q_vals": [0.0, 0.0, -5.027, 0.0, 0.0, 0.0, 0.0, 0.0, -4.924, -4.924]}
{"number_of_episodes": 2806, "number_of_timesteps": 40930, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.25},
{"step": 925, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 926.0, 1.0, 1.0, 1.0, 1.0, 1.0, 926.0, 926.0], "q_vals": [0.0, 0.0, -5.022, 0.0, 0.0, 0.0, 0.0, 0.0, -4.925, -4.925]}
{"number_of_episodes": 2809, "number_of_timesteps": 40971, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 926, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 927.0, 1.0, 1.0, 1.0, 1.0, 1.0, 927.0, 927.0], "q_vals": [0.0, 0.0, -5.023, 0.0, 0.0, 0.0, 0.0, 0.0, -4.925, -4.925]}
{"number_of_episodes": 2810, "number_of_timesteps": 40996, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 927, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 928.0, 1.0, 1.0, 1.0, 1.0, 1.0, 928.0, 928.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.92, -4.92]}
{"step": 928, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 929.0, 1.0, 1.0, 1.0, 1.0, 1.0, 929.0, 929.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.922, -4.922]}
{"number_of_episodes": 2815, "number_of_timesteps": 41086, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"step": 929, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 930.0, 1.0, 1.0, 1.0, 1.0, 1.0, 930.0, 930.0], "q_vals": [0.0, 0.0, -5.023, 0.0, 0.0, 0.0, 0.0, 0.0, -4.931, -4.931]}
{"number_of_episodes": 2818, "number_of_timesteps": 41127, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.25},
{"step": 930, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 931.0, 1.0, 1.0, 1.0, 1.0, 1.0, 931.0, 931.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.931, -4.931]}
{"number_of_episodes": 2821, "number_of_timesteps": 41181, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 931, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 932.0, 1.0, 1.0, 1.0, 1.0, 1.0, 932.0, 932.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.925, -4.925]}
{"step": 932, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 933.0, 1.0, 1.0, 1.0, 1.0, 1.0, 933.0, 933.0], "q_vals": [0.0, 0.0, -5.006, 0.0, 0.0, 0.0, 0.0, 0.0, -4.92, -4.92]}
{"number_of_episodes": 2829, "number_of_timesteps": 41309, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 933, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 934.0, 1.0, 1.0, 1.0, 1.0, 1.0, 934.0, 934.0], "q_vals": [0.0, 0.0, -5.001, 0.0, 0.0, 0.0, 0.0, 0.0, -4.915, -4.915]}
{"step": 934, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 935.0, 1.0, 1.0, 1.0, 1.0, 1.0, 935.0, 935.0], "q_vals": [0.0, 0.0, -4.996, 0.0, 0.0, 0.0, 0.0, 0.0, -4.91, -4.91]}
{"number_of_episodes": 2834, "number_of_timesteps": 41376, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 935, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 936.0, 1.0, 1.0, 1.0, 1.0, 1.0, 936.0, 936.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.91, -4.91]}
{"step": 936, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 937.0, 1.0, 1.0, 1.0, 1.0, 1.0, 937.0, 937.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"step": 937, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 938.0, 1.0, 1.0, 1.0, 1.0, 1.0, 938.0, 938.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.903, -4.903]}
{"number_of_episodes": 2842, "number_of_timesteps": 41500, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.25},
{"step": 938, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 939.0, 1.0, 1.0, 1.0, 1.0, 1.0, 939.0, 939.0], "q_vals": [0.0, 0.0, -4.985, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"number_of_episodes": 2846, "number_of_timesteps": 41559, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.25},
{"step": 939, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 940.0, 1.0, 1.0, 1.0, 1.0, 1.0, 940.0, 940.0], "q_vals": [0.0, 0.0, -4.993, 0.0, 0.0, 0.0, 0.0, 0.0, -4.912, -4.912]}
{"number_of_episodes": 2849, "number_of_timesteps": 41607, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 940, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 941.0, 1.0, 1.0, 1.0, 1.0, 1.0, 941.0, 941.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.911, -4.911]}
{"number_of_episodes": 2850, "number_of_timesteps": 41620, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 941, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 942.0, 1.0, 1.0, 1.0, 1.0, 1.0, 942.0, 942.0], "q_vals": [0.0, 0.0, -4.993, 0.0, 0.0, 0.0, 0.0, 0.0, -4.911, -4.911]}
{"number_of_episodes": 2851, "number_of_timesteps": 41632, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 942, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 943.0, 1.0, 1.0, 1.0, 1.0, 1.0, 943.0, 943.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"number_of_episodes": 2856, "number_of_timesteps": 41721, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.25},
{"step": 943, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 944.0, 1.0, 1.0, 1.0, 1.0, 1.0, 944.0, 944.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.91, -4.91]}
{"number_of_episodes": 2858, "number_of_timesteps": 41753, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 944, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 945.0, 1.0, 1.0, 1.0, 1.0, 1.0, 945.0, 945.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"eval_score": 18.9, "number_of_episodes": 2861}
{"number_of_episodes": 2861, "number_of_timesteps": 41829, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 945, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 946.0, 1.0, 1.0, 1.0, 1.0, 1.0, 946.0, 946.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"number_of_episodes": 2862, "number_of_timesteps": 41841, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 946, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 947.0, 1.0, 1.0, 1.0, 1.0, 1.0, 947.0, 947.0], "q_vals": [0.0, 0.0, -4.983, 0.0, 0.0, 0.0, 0.0, 0.0, -4.903, -4.903]}
{"number_of_episodes": 2863, "number_of_timesteps": 41857, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 947, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 948.0, 1.0, 1.0, 1.0, 1.0, 1.0, 948.0, 948.0], "q_vals": [0.0, 0.0, -4.978, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 2863, "number_of_timesteps": 41857, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 948, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 949.0, 1.0, 1.0, 1.0, 1.0, 1.0, 949.0, 949.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 2866, "number_of_timesteps": 41911, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 949, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 950.0, 1.0, 1.0, 1.0, 1.0, 1.0, 950.0, 950.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.897, -4.897]}
{"step": 950, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 951.0, 1.0, 1.0, 1.0, 1.0, 1.0, 951.0, 951.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 2872, "number_of_timesteps": 42082, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 951, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 952.0, 1.0, 1.0, 1.0, 1.0, 1.0, 952.0, 952.0], "q_vals": [0.0, 0.0, -4.974, 0.0, 0.0, 0.0, 0.0, 0.0, -4.897, -4.897]}
{"number_of_episodes": 2877, "number_of_timesteps": 42175, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 952, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 953.0, 1.0, 1.0, 1.0, 1.0, 1.0, 953.0, 953.0], "q_vals": [0.0, 0.0, -4.98, 0.0, 0.0, 0.0, 0.0, 0.0, -4.902, -4.902]}
{"number_of_episodes": 2877, "number_of_timesteps": 42175, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 953, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 954.0, 1.0, 1.0, 1.0, 1.0, 1.0, 954.0, 954.0], "q_vals": [0.0, 0.0, -4.984, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"step": 954, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 955.0, 1.0, 1.0, 1.0, 1.0, 1.0, 955.0, 955.0], "q_vals": [0.0, 0.0, -4.987, 0.0, 0.0, 0.0, 0.0, 0.0, -4.907, -4.907]}
{"number_of_episodes": 2883, "number_of_timesteps": 42256, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 955, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 956.0, 1.0, 1.0, 1.0, 1.0, 1.0, 956.0, 956.0], "q_vals": [0.0, 0.0, -4.986, 0.0, 0.0, 0.0, 0.0, 0.0, -4.906, -4.906]}
{"number_of_episodes": 2884, "number_of_timesteps": 42282, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.1999999999999993},
{"step": 956, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 957.0, 1.0, 1.0, 1.0, 1.0, 1.0, 957.0, 957.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"step": 957, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 958.0, 1.0, 1.0, 1.0, 1.0, 1.0, 958.0, 958.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.9, -4.9]}
{"number_of_episodes": 2888, "number_of_timesteps": 42330, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 958, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 959.0, 1.0, 1.0, 1.0, 1.0, 1.0, 959.0, 959.0], "q_vals": [0.0, 0.0, -4.98, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 2893, "number_of_timesteps": 42463, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 959, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 960.0, 1.0, 1.0, 1.0, 1.0, 1.0, 960.0, 960.0], "q_vals": [0.0, 0.0, -4.98, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 2893, "number_of_timesteps": 42463, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.25},
{"step": 960, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 961.0, 1.0, 1.0, 1.0, 1.0, 1.0, 961.0, 961.0], "q_vals": [0.0, 0.0, -4.993, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"step": 961, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 962.0, 1.0, 1.0, 1.0, 1.0, 1.0, 962.0, 962.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.907, -4.907]}
{"step": 962, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 963.0, 1.0, 1.0, 1.0, 1.0, 1.0, 963.0, 963.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.907, -4.907]}
{"number_of_episodes": 2902, "number_of_timesteps": 42616, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 963, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 964.0, 1.0, 1.0, 1.0, 1.0, 1.0, 964.0, 964.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.906, -4.906]}
{"number_of_episodes": 2904, "number_of_timesteps": 42654, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 964, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 965.0, 1.0, 1.0, 1.0, 1.0, 1.0, 965.0, 965.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"number_of_episodes": 2908, "number_of_timesteps": 42727, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.25},
{"step": 965, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 966.0, 1.0, 1.0, 1.0, 1.0, 1.0, 966.0, 966.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.91, -4.91]}
{"step": 966, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 967.0, 1.0, 1.0, 1.0, 1.0, 1.0, 967.0, 967.0], "q_vals": [0.0, 0.0, -4.999, 0.0, 0.0, 0.0, 0.0, 0.0, -4.911, -4.911]}
{"number_of_episodes": 2913, "number_of_timesteps": 42804, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 967, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 968.0, 1.0, 1.0, 1.0, 1.0, 1.0, 968.0, 968.0], "q_vals": [0.0, 0.0, -4.999, 0.0, 0.0, 0.0, 0.0, 0.0, -4.911, -4.911]}
{"number_of_episodes": 2916, "number_of_timesteps": 42854, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.20000000000000107},
{"step": 968, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 969.0, 1.0, 1.0, 1.0, 1.0, 1.0, 969.0, 969.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.906, -4.906]}
{"number_of_episodes": 2918, "number_of_timesteps": 42876, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 969, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 970.0, 1.0, 1.0, 1.0, 1.0, 1.0, 970.0, 970.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"number_of_episodes": 2922, "number_of_timesteps": 42958, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.15000000000000036},
{"step": 970, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 971.0, 1.0, 1.0, 1.0, 1.0, 1.0, 971.0, 971.0], "q_vals": [0.0, 0.0, -4.999, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"number_of_episodes": 2924, "number_of_timesteps": 42984, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 971, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 972.0, 1.0, 1.0, 1.0, 1.0, 1.0, 972.0, 972.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"number_of_episodes": 2926, "number_of_timesteps": 43021, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 972, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 973.0, 1.0, 1.0, 1.0, 1.0, 1.0, 973.0, 973.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"step": 973, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 974.0, 1.0, 1.0, 1.0, 1.0, 1.0, 974.0, 974.0], "q_vals": [0.0, 0.0, -4.984, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 2932, "number_of_timesteps": 43110, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 974, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 975.0, 1.0, 1.0, 1.0, 1.0, 1.0, 975.0, 975.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"number_of_episodes": 2935, "number_of_timesteps": 43174, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.005000000000000012, "biggest_recent_change": 0.1999999999999993},
{"step": 975, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 976.0, 1.0, 1.0, 1.0, 1.0, 1.0, 976.0, 976.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"number_of_episodes": 2939, "number_of_timesteps": 43232, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 976, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 977.0, 1.0, 1.0, 1.0, 1.0, 1.0, 977.0, 977.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.903, -4.903]}
{"number_of_episodes": 2942, "number_of_timesteps": 43266, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 977, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 978.0, 1.0, 1.0, 1.0, 1.0, 1.0, 978.0, 978.0], "q_vals": [0.0, 0.0, -4.985, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 2943, "number_of_timesteps": 43279, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 978, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 979.0, 1.0, 1.0, 1.0, 1.0, 1.0, 979.0, 979.0], "q_vals": [0.0, 0.0, -4.982, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 2948, "number_of_timesteps": 43356, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.25},
{"step": 979, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 980.0, 1.0, 1.0, 1.0, 1.0, 1.0, 980.0, 980.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.903, -4.903]}
{"number_of_episodes": 2949, "number_of_timesteps": 43374, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.005000000000000012, "biggest_recent_change": 0.1999999999999993},
{"step": 980, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 981.0, 1.0, 1.0, 1.0, 1.0, 1.0, 981.0, 981.0], "q_vals": [0.0, 0.0, -4.986, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 2953, "number_of_timesteps": 43437, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 981, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 982.0, 1.0, 1.0, 1.0, 1.0, 1.0, 982.0, 982.0], "q_vals": [0.0, 0.0, -4.982, 0.0, 0.0, 0.0, 0.0, 0.0, -4.894, -4.894]}
{"step": 982, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 983.0, 1.0, 1.0, 1.0, 1.0, 1.0, 983.0, 983.0], "q_vals": [0.0, 0.0, -4.982, 0.0, 0.0, 0.0, 0.0, 0.0, -4.893, -4.893]}
{"number_of_episodes": 2960, "number_of_timesteps": 43520, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.20000000000000107},
{"step": 983, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 984.0, 1.0, 1.0, 1.0, 1.0, 1.0, 984.0, 984.0], "q_vals": [0.0, 0.0, -4.977, 0.0, 0.0, 0.0, 0.0, 0.0, -4.888, -4.888]}
{"number_of_episodes": 2962, "number_of_timesteps": 43556, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 984, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 985.0, 1.0, 1.0, 1.0, 1.0, 1.0, 985.0, 985.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.883, -4.883]}
{"number_of_episodes": 2965, "number_of_timesteps": 43599, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 985, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 986.0, 1.0, 1.0, 1.0, 1.0, 1.0, 986.0, 986.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"number_of_episodes": 2967, "number_of_timesteps": 43625, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 986, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 987.0, 1.0, 1.0, 1.0, 1.0, 1.0, 987.0, 987.0], "q_vals": [0.0, 0.0, -4.966, 0.0, 0.0, 0.0, 0.0, 0.0, -4.877, -4.877]}
{"step": 987, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 988.0, 1.0, 1.0, 1.0, 1.0, 1.0, 988.0, 988.0], "q_vals": [0.0, 0.0, -4.961, 0.0, 0.0, 0.0, 0.0, 0.0, -4.872, -4.872]}
{"number_of_episodes": 2972, "number_of_timesteps": 43705, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 988, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 989.0, 1.0, 1.0, 1.0, 1.0, 1.0, 989.0, 989.0], "q_vals": [0.0, 0.0, -4.956, 0.0, 0.0, 0.0, 0.0, 0.0, -4.871, -4.871]}
{"number_of_episodes": 2976, "number_of_timesteps": 43775, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.20000000000000107},
{"step": 989, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 990.0, 1.0, 1.0, 1.0, 1.0, 1.0, 990.0, 990.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.866, -4.866]}
{"number_of_episodes": 2980, "number_of_timesteps": 43848, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 990, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 991.0, 1.0, 1.0, 1.0, 1.0, 1.0, 991.0, 991.0], "q_vals": [0.0, 0.0, -4.953, 0.0, 0.0, 0.0, 0.0, 0.0, -4.867, -4.867]}
{"number_of_episodes": 2982, "number_of_timesteps": 43869, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 991, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 992.0, 1.0, 1.0, 1.0, 1.0, 1.0, 992.0, 992.0], "q_vals": [0.0, 0.0, -4.952, 0.0, 0.0, 0.0, 0.0, 0.0, -4.866, -4.866]}
{"step": 992, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 993.0, 1.0, 1.0, 1.0, 1.0, 1.0, 993.0, 993.0], "q_vals": [0.0, 0.0, -4.948, 0.0, 0.0, 0.0, 0.0, 0.0, -4.862, -4.862]}
{"number_of_episodes": 2989, "number_of_timesteps": 43980, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 993, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 994.0, 1.0, 1.0, 1.0, 1.0, 1.0, 994.0, 994.0], "q_vals": [0.0, 0.0, -4.943, 0.0, 0.0, 0.0, 0.0, 0.0, -4.861, -4.861]}
{"eval_score": 13.8, "number_of_episodes": 2991}
{"step": 994, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 995.0, 1.0, 1.0, 1.0, 1.0, 1.0, 995.0, 995.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"number_of_episodes": 2992, "number_of_timesteps": 44030, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 995, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 996.0, 1.0, 1.0, 1.0, 1.0, 1.0, 996.0, 996.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.859, -4.859]}
{"step": 996, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 997.0, 1.0, 1.0, 1.0, 1.0, 1.0, 997.0, 997.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.859, -4.859]}
{"number_of_episodes": 2998, "number_of_timesteps": 44115, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 997, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 998.0, 1.0, 1.0, 1.0, 1.0, 1.0, 998.0, 998.0], "q_vals": [0.0, 0.0, -4.94, 0.0, 0.0, 0.0, 0.0, 0.0, -4.856, -4.856]}
{"number_of_episodes": 3002, "number_of_timesteps": 44182, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.09999999999999964},
{"step": 998, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 999.0, 1.0, 1.0, 1.0, 1.0, 1.0, 999.0, 999.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.866, -4.866]}
{"number_of_episodes": 3004, "number_of_timesteps": 44217, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 999, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1000.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1000.0, 1000.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.865, -4.865]}
{"step": 1000, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1001.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1001.0, 1001.0], "q_vals": [0.0, 0.0, -4.96, 0.0, 0.0, 0.0, 0.0, 0.0, -4.872, -4.872]}
{"number_of_episodes": 3010, "number_of_timesteps": 44303, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.20000000000000107},
{"step": 1001, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1002.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1002.0, 1002.0], "q_vals": [0.0, 0.0, -4.955, 0.0, 0.0, 0.0, 0.0, 0.0, -4.867, -4.867]}
{"number_of_episodes": 3011, "number_of_timesteps": 44333, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1002, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1003.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1003.0, 1003.0], "q_vals": [0.0, 0.0, -4.955, 0.0, 0.0, 0.0, 0.0, 0.0, -4.867, -4.867]}
{"step": 1003, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1004.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1004.0, 1004.0], "q_vals": [0.0, 0.0, -4.95, 0.0, 0.0, 0.0, 0.0, 0.0, -4.862, -4.862]}
{"number_of_episodes": 3018, "number_of_timesteps": 44450, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 1004, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1005.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1005.0, 1005.0], "q_vals": [0.0, 0.0, -4.945, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 3020, "number_of_timesteps": 44484, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1005, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1006.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1006.0, 1006.0], "q_vals": [0.0, 0.0, -4.947, 0.0, 0.0, 0.0, 0.0, 0.0, -4.859, -4.859]}
{"number_of_episodes": 3023, "number_of_timesteps": 44535, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1006, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1007.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1007.0, 1007.0], "q_vals": [0.0, 0.0, -4.947, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 3028, "number_of_timesteps": 44614, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1007, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1008.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1008.0, 1008.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.859, -4.859]}
{"number_of_episodes": 3030, "number_of_timesteps": 44641, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 1008, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1009.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1009.0, 1009.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.866, -4.866]}
{"number_of_episodes": 3033, "number_of_timesteps": 44670, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1009, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1010.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1010.0, 1010.0], "q_vals": [0.0, 0.0, -4.951, 0.0, 0.0, 0.0, 0.0, 0.0, -4.865, -4.865]}
{"step": 1010, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1011.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1011.0, 1011.0], "q_vals": [0.0, 0.0, -4.946, 0.0, 0.0, 0.0, 0.0, 0.0, -4.865, -4.865]}
{"number_of_episodes": 3038, "number_of_timesteps": 44737, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.1999999999999993},
{"step": 1011, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1012.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1012.0, 1012.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"number_of_episodes": 3043, "number_of_timesteps": 44823, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.20000000000000107},
{"step": 1012, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1013.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1013.0, 1013.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"number_of_episodes": 3045, "number_of_timesteps": 44843, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1013, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1014.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1014.0, 1014.0], "q_vals": [0.0, 0.0, -4.944, 0.0, 0.0, 0.0, 0.0, 0.0, -4.861, -4.861]}
{"step": 1014, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1015.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1015.0, 1015.0], "q_vals": [0.0, 0.0, -4.939, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"step": 1015, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1016.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1016.0, 1016.0], "q_vals": [0.0, 0.0, -4.935, 0.0, 0.0, 0.0, 0.0, 0.0, -4.852, -4.852]}
{"number_of_episodes": 3055, "number_of_timesteps": 44998, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1016, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1017.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1017.0, 1017.0], "q_vals": [0.0, 0.0, -4.941, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"number_of_episodes": 3057, "number_of_timesteps": 45021, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 1017, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1018.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1018.0, 1018.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"number_of_episodes": 3062, "number_of_timesteps": 45085, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.20000000000000107},
{"step": 1018, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1019.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1019.0, 1019.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"step": 1019, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1020.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1020.0, 1020.0], "q_vals": [0.0, 0.0, -4.944, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 3067, "number_of_timesteps": 45145, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"step": 1020, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1021.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1021.0, 1021.0], "q_vals": [0.0, 0.0, -4.944, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"number_of_episodes": 3072, "number_of_timesteps": 45221, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.1999999999999993},
{"step": 1021, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1022.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1022.0, 1022.0], "q_vals": [0.0, 0.0, -4.939, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 3073, "number_of_timesteps": 45232, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1022, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1023.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1023.0, 1023.0], "q_vals": [0.0, 0.0, -4.934, 0.0, 0.0, 0.0, 0.0, 0.0, -4.848, -4.848]}
{"number_of_episodes": 3078, "number_of_timesteps": 45293, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1023, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1024.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1024.0, 1024.0], "q_vals": [0.0, 0.0, -4.936, 0.0, 0.0, 0.0, 0.0, 0.0, -4.849, -4.849]}
{"step": 1024, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1025.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1025.0, 1025.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.85, -4.85]}
{"number_of_episodes": 3082, "number_of_timesteps": 45353, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1025, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1026.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1026.0, 1026.0], "q_vals": [0.0, 0.0, -4.936, 0.0, 0.0, 0.0, 0.0, 0.0, -4.848, -4.848]}
{"number_of_episodes": 3085, "number_of_timesteps": 45390, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1026, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1027.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1027.0, 1027.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.849, -4.849]}
{"number_of_episodes": 3088, "number_of_timesteps": 45446, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1027, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1028.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1028.0, 1028.0], "q_vals": [0.0, 0.0, -4.932, 0.0, 0.0, 0.0, 0.0, 0.0, -4.844, -4.844]}
{"number_of_episodes": 3093, "number_of_timesteps": 45536, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1028, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1029.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1029.0, 1029.0], "q_vals": [0.0, 0.0, -4.928, 0.0, 0.0, 0.0, 0.0, 0.0, -4.839, -4.839]}
{"number_of_episodes": 3096, "number_of_timesteps": 45569, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 1029, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1030.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1030.0, 1030.0], "q_vals": [0.0, 0.0, -4.927, 0.0, 0.0, 0.0, 0.0, 0.0, -4.839, -4.839]}
{"number_of_episodes": 3098, "number_of_timesteps": 45591, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
{"step": 1030, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1031.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1031.0, 1031.0], "q_vals": [0.0, 0.0, -4.927, 0.0, 0.0, 0.0, 0.0, 0.0, -4.838, -4.838]}
{"step": 1031, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1032.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1032.0, 1032.0], "q_vals": [0.0, 0.0, -4.929, 0.0, 0.0, 0.0, 0.0, 0.0, -4.839, -4.839]}
{"number_of_episodes": 3104, "number_of_timesteps": 45680, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1032, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1033.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1033.0, 1033.0], "q_vals": [0.0, 0.0, -4.925, 0.0, 0.0, 0.0, 0.0, 0.0, -4.835, -4.835]}
{"number_of_episodes": 3108, "number_of_timesteps": 45744, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1033, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1034.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1034.0, 1034.0], "q_vals": [0.0, 0.0, -4.935, 0.0, 0.0, 0.0, 0.0, 0.0, -4.844, -4.844]}
{"step": 1034, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1035.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1035.0, 1035.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.849, -4.849]}
{"number_of_episodes": 3114, "number_of_timesteps": 45818, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 1035, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1036.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1036.0, 1036.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.844, -4.844]}
{"number_of_episodes": 3119, "number_of_timesteps": 45882, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 1036, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1037.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1037.0, 1037.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.844, -4.844]}
{"eval_score": 14.9, "number_of_episodes": 3120}
{"number_of_episodes": 3120, "number_of_timesteps": 45894, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 1037, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1038.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1038.0, 1038.0], "q_vals": [0.0, 0.0, -4.948, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 3126, "number_of_timesteps": 45971, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.20000000000000107},
{"step": 1038, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1039.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1039.0, 1039.0], "q_vals": [0.0, 0.0, -4.944, 0.0, 0.0, 0.0, 0.0, 0.0, -4.849, -4.849]}
{"number_of_episodes": 3130, "number_of_timesteps": 46018, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 1039, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1040.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1040.0, 1040.0], "q_vals": [0.0, 0.0, -4.943, 0.0, 0.0, 0.0, 0.0, 0.0, -4.847, -4.847]}
{"number_of_episodes": 3132, "number_of_timesteps": 46036, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1040, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1041.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1041.0, 1041.0], "q_vals": [0.0, 0.0, -4.945, 0.0, 0.0, 0.0, 0.0, 0.0, -4.849, -4.849]}
{"number_of_episodes": 3135, "number_of_timesteps": 46068, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1041, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1042.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1042.0, 1042.0], "q_vals": [0.0, 0.0, -4.94, 0.0, 0.0, 0.0, 0.0, 0.0, -4.848, -4.848]}
{"number_of_episodes": 3137, "number_of_timesteps": 46096, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.20000000000000107},
{"step": 1042, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1043.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1043.0, 1043.0], "q_vals": [0.0, 0.0, -4.935, 0.0, 0.0, 0.0, 0.0, 0.0, -4.843, -4.843]}
{"number_of_episodes": 3139, "number_of_timesteps": 46132, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1043, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1044.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1044.0, 1044.0], "q_vals": [0.0, 0.0, -4.936, 0.0, 0.0, 0.0, 0.0, 0.0, -4.844, -4.844]}
{"step": 1044, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1045.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1045.0, 1045.0], "q_vals": [0.0, 0.0, -4.945, 0.0, 0.0, 0.0, 0.0, 0.0, -4.851, -4.851]}
{"number_of_episodes": 3146, "number_of_timesteps": 46238, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1045, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1046.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1046.0, 1046.0], "q_vals": [0.0, 0.0, -4.945, 0.0, 0.0, 0.0, 0.0, 0.0, -4.85, -4.85]}
{"number_of_episodes": 3148, "number_of_timesteps": 46285, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1046, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1047.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1047.0, 1047.0], "q_vals": [0.0, 0.0, -4.947, 0.0, 0.0, 0.0, 0.0, 0.0, -4.852, -4.852]}
{"number_of_episodes": 3152, "number_of_timesteps": 46350, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.20000000000000107},
{"step": 1047, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1048.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1048.0, 1048.0], "q_vals": [0.0, 0.0, -4.942, 0.0, 0.0, 0.0, 0.0, 0.0, -4.847, -4.847]}
{"number_of_episodes": 3155, "number_of_timesteps": 46390, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
{"step": 1048, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1049.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1049.0, 1049.0], "q_vals": [0.0, 0.0, -4.938, 0.0, 0.0, 0.0, 0.0, 0.0, -4.843, -4.843]}
{"number_of_episodes": 3158, "number_of_timesteps": 46421, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1049, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1050.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1050.0, 1050.0], "q_vals": [0.0, 0.0, -4.933, 0.0, 0.0, 0.0, 0.0, 0.0, -4.844, -4.844]}
{"step": 1050, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1051.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1051.0, 1051.0], "q_vals": [0.0, 0.0, -4.928, 0.0, 0.0, 0.0, 0.0, 0.0, -4.842, -4.842]}
{"number_of_episodes": 3165, "number_of_timesteps": 46523, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1051, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1052.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1052.0, 1052.0], "q_vals": [0.0, 0.0, -4.937, 0.0, 0.0, 0.0, 0.0, 0.0, -4.849, -4.849]}
{"step": 1052, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1053.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1053.0, 1053.0], "q_vals": [0.0, 0.0, -4.948, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 3171, "number_of_timesteps": 46613, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.14999999999999858},
{"step": 1053, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1054.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1054.0, 1054.0], "q_vals": [0.0, 0.0, -4.943, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 3174, "number_of_timesteps": 46662, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1054, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1055.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1055.0, 1055.0], "q_vals": [0.0, 0.0, -4.938, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 3176, "number_of_timesteps": 46693, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1055, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1056.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1056.0, 1056.0], "q_vals": [0.0, 0.0, -4.944, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"step": 1056, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1057.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1057.0, 1057.0], "q_vals": [0.0, 0.0, -4.94, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 3183, "number_of_timesteps": 46785, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1057, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1058.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1058.0, 1058.0], "q_vals": [0.0, 0.0, -4.948, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"step": 1058, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1059.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1059.0, 1059.0], "q_vals": [0.0, 0.0, -4.961, 0.0, 0.0, 0.0, 0.0, 0.0, -4.871, -4.871]}
{"number_of_episodes": 3188, "number_of_timesteps": 46852, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1059, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1060.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1060.0, 1060.0], "q_vals": [0.0, 0.0, -4.962, 0.0, 0.0, 0.0, 0.0, 0.0, -4.872, -4.872]}
{"step": 1060, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1061.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1061.0, 1061.0], "q_vals": [0.0, 0.0, -4.965, 0.0, 0.0, 0.0, 0.0, 0.0, -4.873, -4.873]}
{"number_of_episodes": 3195, "number_of_timesteps": 46954, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1061, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1062.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1062.0, 1062.0], "q_vals": [0.0, 0.0, -4.966, 0.0, 0.0, 0.0, 0.0, 0.0, -4.874, -4.874]}
{"number_of_episodes": 3197, "number_of_timesteps": 46993, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
{"step": 1062, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1063.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1063.0, 1063.0], "q_vals": [0.0, 0.0, -4.962, 0.0, 0.0, 0.0, 0.0, 0.0, -4.87, -4.87]}
{"number_of_episodes": 3201, "number_of_timesteps": 47039, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
{"step": 1063, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1064.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1064.0, 1064.0], "q_vals": [0.0, 0.0, -4.957, 0.0, 0.0, 0.0, 0.0, 0.0, -4.865, -4.865]}
{"number_of_episodes": 3202, "number_of_timesteps": 47051, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1064, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1065.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1065.0, 1065.0], "q_vals": [0.0, 0.0, -4.968, 0.0, 0.0, 0.0, 0.0, 0.0, -4.874, -4.874]}
{"step": 1065, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1066.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1066.0, 1066.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 3208, "number_of_timesteps": 47158, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"step": 1066, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1067.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1067.0, 1067.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 3209, "number_of_timesteps": 47177, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1067, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1068.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1068.0, 1068.0], "q_vals": [0.0, 0.0, -4.974, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"number_of_episodes": 3211, "number_of_timesteps": 47215, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1068, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1069.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1069.0, 1069.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.873, -4.873]}
{"number_of_episodes": 3214, "number_of_timesteps": 47257, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1069, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1070.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1070.0, 1070.0], "q_vals": [0.0, 0.0, -4.964, 0.0, 0.0, 0.0, 0.0, 0.0, -4.869, -4.869]}
{"number_of_episodes": 3216, "number_of_timesteps": 47316, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1070, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1071.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1071.0, 1071.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.875, -4.875]}
{"step": 1071, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1072.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1072.0, 1072.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.87, -4.87]}
{"number_of_episodes": 3225, "number_of_timesteps": 47485, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1072, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1073.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1073.0, 1073.0], "q_vals": [0.0, 0.0, -4.968, 0.0, 0.0, 0.0, 0.0, 0.0, -4.871, -4.871]}
{"step": 1073, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1074.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1074.0, 1074.0], "q_vals": [0.0, 0.0, -4.965, 0.0, 0.0, 0.0, 0.0, 0.0, -4.868, -4.868]}
{"number_of_episodes": 3229, "number_of_timesteps": 47541, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"step": 1074, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1075.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1075.0, 1075.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.873, -4.873]}
{"number_of_episodes": 3232, "number_of_timesteps": 47582, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1075, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1076.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1076.0, 1076.0], "q_vals": [0.0, 0.0, -4.974, 0.0, 0.0, 0.0, 0.0, 0.0, -4.875, -4.875]}
{"step": 1076, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1077.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1077.0, 1077.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.887, -4.887]}
{"step": 1077, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1078.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1078.0, 1078.0], "q_vals": [0.0, 0.0, -4.985, 0.0, 0.0, 0.0, 0.0, 0.0, -4.884, -4.884]}
{"number_of_episodes": 3242, "number_of_timesteps": 47741, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1078, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1079.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1079.0, 1079.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"step": 1079, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1080.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1080.0, 1080.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.875, -4.875]}
{"number_of_episodes": 3248, "number_of_timesteps": 47812, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1080, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1081.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1081.0, 1081.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.87, -4.87]}
{"eval_score": 14.2, "number_of_episodes": 3251}
{"number_of_episodes": 3251, "number_of_timesteps": 47851, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1081, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1082.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1082.0, 1082.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.87, -4.87]}
{"number_of_episodes": 3251, "number_of_timesteps": 47851, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"step": 1082, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1083.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1083.0, 1083.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.87, -4.87]}
{"number_of_episodes": 3257, "number_of_timesteps": 47936, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1083, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1084.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1084.0, 1084.0], "q_vals": [0.0, 0.0, -4.978, 0.0, 0.0, 0.0, 0.0, 0.0, -4.875, -4.875]}
{"number_of_episodes": 3259, "number_of_timesteps": 47965, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1084, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1085.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1085.0, 1085.0], "q_vals": [0.0, 0.0, -4.98, 0.0, 0.0, 0.0, 0.0, 0.0, -4.876, -4.876]}
{"number_of_episodes": 3261, "number_of_timesteps": 47984, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1085, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1086.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1086.0, 1086.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.872, -4.872]}
{"number_of_episodes": 3266, "number_of_timesteps": 48075, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1086, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1087.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1087.0, 1087.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.871, -4.871]}
{"step": 1087, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1088.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1088.0, 1088.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.871, -4.871]}
{"number_of_episodes": 3269, "number_of_timesteps": 48121, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 1088, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1089.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1089.0, 1089.0], "q_vals": [0.0, 0.0, -4.971, 0.0, 0.0, 0.0, 0.0, 0.0, -4.869, -4.869]}
{"number_of_episodes": 3274, "number_of_timesteps": 48199, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1089, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1090.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1090.0, 1090.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.865, -4.865]}
{"number_of_episodes": 3278, "number_of_timesteps": 48261, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1090, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1091.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1091.0, 1091.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.866, -4.866]}
{"step": 1091, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1092.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1092.0, 1092.0], "q_vals": [0.0, 0.0, -4.964, 0.0, 0.0, 0.0, 0.0, 0.0, -4.861, -4.861]}
{"number_of_episodes": 3283, "number_of_timesteps": 48317, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"step": 1092, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1093.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1093.0, 1093.0], "q_vals": [0.0, 0.0, -4.96, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"step": 1093, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1094.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1094.0, 1094.0], "q_vals": [0.0, 0.0, -4.96, 0.0, 0.0, 0.0, 0.0, 0.0, -4.856, -4.856]}
{"number_of_episodes": 3288, "number_of_timesteps": 48381, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1094, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1095.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1095.0, 1095.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"number_of_episodes": 3291, "number_of_timesteps": 48450, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1095, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1096.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1096.0, 1096.0], "q_vals": [0.0, 0.0, -4.975, 0.0, 0.0, 0.0, 0.0, 0.0, -4.869, -4.869]}
{"number_of_episodes": 3294, "number_of_timesteps": 48497, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1096, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1097.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1097.0, 1097.0], "q_vals": [0.0, 0.0, -4.975, 0.0, 0.0, 0.0, 0.0, 0.0, -4.869, -4.869]}
{"step": 1097, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1098.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1098.0, 1098.0], "q_vals": [0.0, 0.0, -4.986, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"step": 1098, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1099.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1099.0, 1099.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 3304, "number_of_timesteps": 48641, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1099, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1100.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1100.0, 1100.0], "q_vals": [0.0, 0.0, -4.986, 0.0, 0.0, 0.0, 0.0, 0.0, -4.877, -4.877]}
{"number_of_episodes": 3306, "number_of_timesteps": 48672, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1100, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1101.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1101.0, 1101.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"number_of_episodes": 3307, "number_of_timesteps": 48692, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1101, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1102.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1102.0, 1102.0], "q_vals": [0.0, 0.0, -4.987, 0.0, 0.0, 0.0, 0.0, 0.0, -4.878, -4.878]}
{"number_of_episodes": 3312, "number_of_timesteps": 48763, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1102, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1103.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1103.0, 1103.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 3315, "number_of_timesteps": 48828, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1103, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1104.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1104.0, 1104.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.877, -4.877]}
{"number_of_episodes": 3317, "number_of_timesteps": 48851, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1104, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1105.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1105.0, 1105.0], "q_vals": [0.0, 0.0, -4.983, 0.0, 0.0, 0.0, 0.0, 0.0, -4.872, -4.872]}
{"step": 1105, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1106.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1106.0, 1106.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"step": 1106, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1107.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1107.0, 1107.0], "q_vals": [0.0, 0.0, -4.987, 0.0, 0.0, 0.0, 0.0, 0.0, -4.875, -4.875]}
{"number_of_episodes": 3325, "number_of_timesteps": 48984, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1107, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1108.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1108.0, 1108.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.875, -4.875]}
{"number_of_episodes": 3327, "number_of_timesteps": 49009, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1108, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1109.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1109.0, 1109.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.876, -4.876]}
{"step": 1109, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1110.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1110.0, 1110.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.876, -4.876]}
{"step": 1110, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1111.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1111.0, 1111.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.875, -4.875]}
{"number_of_episodes": 3336, "number_of_timesteps": 49151, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1111, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1112.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1112.0, 1112.0], "q_vals": [0.0, 0.0, -4.985, 0.0, 0.0, 0.0, 0.0, 0.0, -4.876, -4.876]}
{"number_of_episodes": 3341, "number_of_timesteps": 49216, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1112, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1113.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1113.0, 1113.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.872, -4.872]}
{"number_of_episodes": 3342, "number_of_timesteps": 49225, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1113, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1114.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1114.0, 1114.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.867, -4.867]}
{"number_of_episodes": 3347, "number_of_timesteps": 49314, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1114, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1115.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1115.0, 1115.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"number_of_episodes": 3349, "number_of_timesteps": 49340, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 1115, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1116.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1116.0, 1116.0], "q_vals": [0.0, 0.0, -4.974, 0.0, 0.0, 0.0, 0.0, 0.0, -4.864, -4.864]}
{"number_of_episodes": 3353, "number_of_timesteps": 49397, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1116, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1117.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1117.0, 1117.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"step": 1117, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1118.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1118.0, 1118.0], "q_vals": [0.0, 0.0, -4.97, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"number_of_episodes": 3357, "number_of_timesteps": 49445, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1118, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1119.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1119.0, 1119.0], "q_vals": [0.0, 0.0, -4.974, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"number_of_episodes": 3362, "number_of_timesteps": 49528, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1119, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1120.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1120.0, 1120.0], "q_vals": [0.0, 0.0, -4.974, 0.0, 0.0, 0.0, 0.0, 0.0, -4.862, -4.862]}
{"number_of_episodes": 3364, "number_of_timesteps": 49556, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1120, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1121.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1121.0, 1121.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.869, -4.869]}
{"number_of_episodes": 3367, "number_of_timesteps": 49592, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1121, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1122.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1122.0, 1122.0], "q_vals": [0.0, 0.0, -4.977, 0.0, 0.0, 0.0, 0.0, 0.0, -4.864, -4.864]}
{"number_of_episodes": 3370, "number_of_timesteps": 49629, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1122, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1123.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1123.0, 1123.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"step": 1123, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1124.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1124.0, 1124.0], "q_vals": [0.0, 0.0, -4.968, 0.0, 0.0, 0.0, 0.0, 0.0, -4.856, -4.856]}
{"step": 1124, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1125.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1125.0, 1125.0], "q_vals": [0.0, 0.0, -4.964, 0.0, 0.0, 0.0, 0.0, 0.0, -4.851, -4.851]}
{"number_of_episodes": 3379, "number_of_timesteps": 49777, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 1125, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1126.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1126.0, 1126.0], "q_vals": [0.0, 0.0, -4.96, 0.0, 0.0, 0.0, 0.0, 0.0, -4.848, -4.848]}
{"eval_score": 21.6, "number_of_episodes": 3383}
{"number_of_episodes": 3383, "number_of_timesteps": 49834, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1126, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1127.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1127.0, 1127.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"number_of_episodes": 3383, "number_of_timesteps": 49834, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1127, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1128.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1128.0, 1128.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 3390, "number_of_timesteps": 49939, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1128, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1129.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1129.0, 1129.0], "q_vals": [0.0, 0.0, -4.962, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"step": 1129, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1130.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1130.0, 1130.0], "q_vals": [0.0, 0.0, -4.958, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 3396, "number_of_timesteps": 50008, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1130, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1131.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1131.0, 1131.0], "q_vals": [0.0, 0.0, -4.959, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 3399, "number_of_timesteps": 50041, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1131, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1132.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1132.0, 1132.0], "q_vals": [0.0, 0.0, -4.964, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"step": 1132, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1133.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1133.0, 1133.0], "q_vals": [0.0, 0.0, -4.971, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"number_of_episodes": 3405, "number_of_timesteps": 50119, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1133, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1134.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1134.0, 1134.0], "q_vals": [0.0, 0.0, -4.971, 0.0, 0.0, 0.0, 0.0, 0.0, -4.862, -4.862]}
{"number_of_episodes": 3406, "number_of_timesteps": 50132, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"step": 1134, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1135.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1135.0, 1135.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 3411, "number_of_timesteps": 50202, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"step": 1135, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1136.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1136.0, 1136.0], "q_vals": [0.0, 0.0, -4.962, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 3415, "number_of_timesteps": 50286, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1136, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1137.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1137.0, 1137.0], "q_vals": [0.0, 0.0, -4.963, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 3419, "number_of_timesteps": 50331, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"step": 1137, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1138.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1138.0, 1138.0], "q_vals": [0.0, 0.0, -4.97, 0.0, 0.0, 0.0, 0.0, 0.0, -4.864, -4.864]}
{"number_of_episodes": 3422, "number_of_timesteps": 50365, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1138, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1139.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1139.0, 1139.0], "q_vals": [0.0, 0.0, -4.966, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"number_of_episodes": 3428, "number_of_timesteps": 50433, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
{"step": 1139, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1140.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1140.0, 1140.0], "q_vals": [0.0, 0.0, -4.966, 0.0, 0.0, 0.0, 0.0, 0.0, -4.859, -4.859]}
{"number_of_episodes": 3428, "number_of_timesteps": 50433, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1140, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1141.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1141.0, 1141.0], "q_vals": [0.0, 0.0, -4.966, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"step": 1141, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1142.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1142.0, 1142.0], "q_vals": [0.0, 0.0, -4.963, 0.0, 0.0, 0.0, 0.0, 0.0, -4.856, -4.856]}
{"number_of_episodes": 3438, "number_of_timesteps": 50574, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1142, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1143.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1143.0, 1143.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.861, -4.861]}
{"number_of_episodes": 3439, "number_of_timesteps": 50583, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"step": 1143, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1144.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1144.0, 1144.0], "q_vals": [0.0, 0.0, -4.965, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"number_of_episodes": 3441, "number_of_timesteps": 50602, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1144, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1145.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1145.0, 1145.0], "q_vals": [0.0, 0.0, -4.961, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"number_of_episodes": 3446, "number_of_timesteps": 50663, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1145, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1146.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1146.0, 1146.0], "q_vals": [0.0, 0.0, -4.956, 0.0, 0.0, 0.0, 0.0, 0.0, -4.852, -4.852]}
{"number_of_episodes": 3449, "number_of_timesteps": 50705, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1146, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1147.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1147.0, 1147.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.862, -4.862]}
{"step": 1147, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1148.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1148.0, 1148.0], "q_vals": [0.0, 0.0, -4.963, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 3454, "number_of_timesteps": 50779, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 1148, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1149.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1149.0, 1149.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.865, -4.865]}
{"step": 1149, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1150.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1150.0, 1150.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.871, -4.871]}
{"number_of_episodes": 3461, "number_of_timesteps": 50876, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
{"step": 1150, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1151.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1151.0, 1151.0], "q_vals": [0.0, 0.0, -4.975, 0.0, 0.0, 0.0, 0.0, 0.0, -4.867, -4.867]}
{"number_of_episodes": 3465, "number_of_timesteps": 50936, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1151, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1152.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1152.0, 1152.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.867, -4.867]}
{"number_of_episodes": 3468, "number_of_timesteps": 50978, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1152, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1153.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1153.0, 1153.0], "q_vals": [0.0, 0.0, -4.977, 0.0, 0.0, 0.0, 0.0, 0.0, -4.868, -4.868]}
{"step": 1153, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1154.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1154.0, 1154.0], "q_vals": [0.0, 0.0, -4.977, 0.0, 0.0, 0.0, 0.0, 0.0, -4.867, -4.867]}
{"number_of_episodes": 3476, "number_of_timesteps": 51064, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1154, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1155.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1155.0, 1155.0], "q_vals": [0.0, 0.0, -4.973, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"step": 1155, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1156.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1156.0, 1156.0], "q_vals": [0.0, 0.0, -4.968, 0.0, 0.0, 0.0, 0.0, 0.0, -4.859, -4.859]}
{"step": 1156, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1157.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1157.0, 1157.0], "q_vals": [0.0, 0.0, -4.964, 0.0, 0.0, 0.0, 0.0, 0.0, -4.855, -4.855]}
{"number_of_episodes": 3484, "number_of_timesteps": 51157, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
{"step": 1157, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1158.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1158.0, 1158.0], "q_vals": [0.0, 0.0, -4.963, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"step": 1158, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1159.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1159.0, 1159.0], "q_vals": [0.0, 0.0, -4.963, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 3493, "number_of_timesteps": 51315, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 1159, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1160.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1160.0, 1160.0], "q_vals": [0.0, 0.0, -4.959, 0.0, 0.0, 0.0, 0.0, 0.0, -4.849, -4.849]}
{"number_of_episodes": 3493, "number_of_timesteps": 51315, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1160, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1161.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1161.0, 1161.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"number_of_episodes": 3496, "number_of_timesteps": 51353, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1161, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1162.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1162.0, 1162.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"step": 1162, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1163.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1163.0, 1163.0], "q_vals": [0.0, 0.0, -4.971, 0.0, 0.0, 0.0, 0.0, 0.0, -4.858, -4.858]}
{"number_of_episodes": 3503, "number_of_timesteps": 51451, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
{"step": 1163, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1164.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1164.0, 1164.0], "q_vals": [0.0, 0.0, -4.98, 0.0, 0.0, 0.0, 0.0, 0.0, -4.866, -4.866]}
{"number_of_episodes": 3506, "number_of_timesteps": 51487, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1164, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1165.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1165.0, 1165.0], "q_vals": [0.0, 0.0, -4.976, 0.0, 0.0, 0.0, 0.0, 0.0, -4.865, -4.865]}
{"number_of_episodes": 3509, "number_of_timesteps": 51546, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1165, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1166.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1166.0, 1166.0], "q_vals": [0.0, 0.0, -4.972, 0.0, 0.0, 0.0, 0.0, 0.0, -4.861, -4.861]}
{"eval_score": 13.3, "number_of_episodes": 3513}
{"number_of_episodes": 3513, "number_of_timesteps": 51598, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
{"step": 1166, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1167.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1167.0, 1167.0], "q_vals": [0.0, 0.0, -4.967, 0.0, 0.0, 0.0, 0.0, 0.0, -4.857, -4.857]}
{"step": 1167, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1168.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1168.0, 1168.0], "q_vals": [0.0, 0.0, -4.963, 0.0, 0.0, 0.0, 0.0, 0.0, -4.852, -4.852]}
{"number_of_episodes": 3520, "number_of_timesteps": 51694, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"step": 1168, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1169.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1169.0, 1169.0], "q_vals": [0.0, 0.0, -4.965, 0.0, 0.0, 0.0, 0.0, 0.0, -4.853, -4.853]}
{"number_of_episodes": 3525, "number_of_timesteps": 51750, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
{"step": 1169, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1170.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1170.0, 1170.0], "q_vals": [0.0, 0.0, -4.966, 0.0, 0.0, 0.0, 0.0, 0.0, -4.854, -4.854]}
{"number_of_episodes": 3527, "number_of_timesteps": 51773, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1170, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1171.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1171.0, 1171.0], "q_vals": [0.0, 0.0, -4.973, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"step": 1171, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1172.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1172.0, 1172.0], "q_vals": [0.0, 0.0, -4.973, 0.0, 0.0, 0.0, 0.0, 0.0, -4.86, -4.86]}
{"number_of_episodes": 3535, "number_of_timesteps": 51880, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.15000000000000036},
{"step": 1172, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1173.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1173.0, 1173.0], "q_vals": [0.0, 0.0, -4.969, 0.0, 0.0, 0.0, 0.0, 0.0, -4.856, -4.856]}
{"step": 1173, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1174.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1174.0, 1174.0], "q_vals": [0.0, 0.0, -4.978, 0.0, 0.0, 0.0, 0.0, 0.0, -4.863, -4.863]}
{"number_of_episodes": 3541, "number_of_timesteps": 51961, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 1174, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1175.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1175.0, 1175.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.864, -4.864]}
{"number_of_episodes": 3544, "number_of_timesteps": 52001, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 1175, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1176.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1176.0, 1176.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.874, -4.874]}
{"number_of_episodes": 3546, "number_of_timesteps": 52032, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 1176, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1177.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1177.0, 1177.0], "q_vals": [0.0, 0.0, -4.987, 0.0, 0.0, 0.0, 0.0, 0.0, -4.87, -4.87]}
{"step": 1177, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1178.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1178.0, 1178.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.877, -4.877]}
{"number_of_episodes": 3553, "number_of_timesteps": 52111, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1178, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1179.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1179.0, 1179.0], "q_vals": [0.0, 0.0, -4.998, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"number_of_episodes": 3557, "number_of_timesteps": 52168, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1179, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1180.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1180.0, 1180.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"number_of_episodes": 3562, "number_of_timesteps": 52234, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 1180, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1181.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1181.0, 1181.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.875, -4.875]}
{"number_of_episodes": 3564, "number_of_timesteps": 52254, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.15000000000000036},
{"step": 1181, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1182.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1182.0, 1182.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.874, -4.874]}
{"number_of_episodes": 3570, "number_of_timesteps": 52330, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1182, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1183.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1183.0, 1183.0], "q_vals": [0.0, 0.0, -4.985, 0.0, 0.0, 0.0, 0.0, 0.0, -4.874, -4.874]}
{"number_of_episodes": 3573, "number_of_timesteps": 52369, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1183, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1184.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1184.0, 1184.0], "q_vals": [0.0, 0.0, -4.996, 0.0, 0.0, 0.0, 0.0, 0.0, -4.884, -4.884]}
{"number_of_episodes": 3575, "number_of_timesteps": 52391, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1184, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1185.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1185.0, 1185.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.882, -4.882]}
{"number_of_episodes": 3580, "number_of_timesteps": 52454, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.15000000000000036},
{"step": 1185, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1186.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1186.0, 1186.0], "q_vals": [0.0, 0.0, -5.006, 0.0, 0.0, 0.0, 0.0, 0.0, -4.891, -4.891]}
{"number_of_episodes": 3581, "number_of_timesteps": 52465, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 1186, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1187.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1187.0, 1187.0], "q_vals": [0.0, 0.0, -5.001, 0.0, 0.0, 0.0, 0.0, 0.0, -4.887, -4.887]}
{"number_of_episodes": 3586, "number_of_timesteps": 52517, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1187, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1188.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1188.0, 1188.0], "q_vals": [0.0, 0.0, -5.01, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 3590, "number_of_timesteps": 52588, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 1188, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1189.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1189.0, 1189.0], "q_vals": [0.0, 0.0, -5.024, 0.0, 0.0, 0.0, 0.0, 0.0, -4.906, -4.906]}
{"number_of_episodes": 3593, "number_of_timesteps": 52625, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 1189, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1190.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1190.0, 1190.0], "q_vals": [0.0, 0.0, -5.02, 0.0, 0.0, 0.0, 0.0, 0.0, -4.902, -4.902]}
{"number_of_episodes": 3597, "number_of_timesteps": 52669, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1190, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1191.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1191.0, 1191.0], "q_vals": [0.0, 0.0, -5.016, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 3602, "number_of_timesteps": 52732, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1191, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1192.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1192.0, 1192.0], "q_vals": [0.0, 0.0, -5.011, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 3605, "number_of_timesteps": 52764, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1192, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1193.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1193.0, 1193.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"step": 1193, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1194.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1194.0, 1194.0], "q_vals": [0.0, 0.0, -5.008, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 3612, "number_of_timesteps": 52846, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1194, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1195.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1195.0, 1195.0], "q_vals": [0.0, 0.0, -5.003, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"step": 1195, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1196.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1196.0, 1196.0], "q_vals": [0.0, 0.0, -4.999, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 3619, "number_of_timesteps": 52932, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1196, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1197.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1197.0, 1197.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 3623, "number_of_timesteps": 52981, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1197, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1198.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1198.0, 1198.0], "q_vals": [0.0, 0.0, -4.996, 0.0, 0.0, 0.0, 0.0, 0.0, -4.896, -4.896]}
{"number_of_episodes": 3627, "number_of_timesteps": 53030, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1198, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1199.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1199.0, 1199.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.892, -4.892]}
{"number_of_episodes": 3631, "number_of_timesteps": 53073, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1199, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1200.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1200.0, 1200.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.887, -4.887]}
{"number_of_episodes": 3633, "number_of_timesteps": 53096, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1200, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1201.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1201.0, 1201.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.888, -4.888]}
{"number_of_episodes": 3635, "number_of_timesteps": 53116, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1201, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1202.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1202.0, 1202.0], "q_vals": [0.0, 0.0, -4.985, 0.0, 0.0, 0.0, 0.0, 0.0, -4.884, -4.884]}
{"eval_score": 11.8, "number_of_episodes": 3641}
{"number_of_episodes": 3641, "number_of_timesteps": 53199, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1202, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1203.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1203.0, 1203.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.88, -4.88]}
{"number_of_episodes": 3643, "number_of_timesteps": 53219, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
{"step": 1203, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1204.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1204.0, 1204.0], "q_vals": [0.0, 0.0, -4.982, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"step": 1204, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1205.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1205.0, 1205.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.88, -4.88]}
{"step": 1205, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1206.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1206.0, 1206.0], "q_vals": [0.0, 0.0, -4.983, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 3653, "number_of_timesteps": 53345, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1206, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1207.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1207.0, 1207.0], "q_vals": [0.0, 0.0, -4.985, 0.0, 0.0, 0.0, 0.0, 0.0, -4.882, -4.882]}
{"number_of_episodes": 3657, "number_of_timesteps": 53396, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1207, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1208.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1208.0, 1208.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.883, -4.883]}
{"number_of_episodes": 3659, "number_of_timesteps": 53421, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1208, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1209.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1209.0, 1209.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 3663, "number_of_timesteps": 53483, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1209, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1210.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1210.0, 1210.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.89, -4.89]}
{"number_of_episodes": 3665, "number_of_timesteps": 53509, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1210, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1211.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1211.0, 1211.0], "q_vals": [0.0, 0.0, -4.985, 0.0, 0.0, 0.0, 0.0, 0.0, -4.886, -4.886]}
{"number_of_episodes": 3669, "number_of_timesteps": 53579, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1211, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1212.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1212.0, 1212.0], "q_vals": [0.0, 0.0, -4.983, 0.0, 0.0, 0.0, 0.0, 0.0, -4.883, -4.883]}
{"step": 1212, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1213.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1213.0, 1213.0], "q_vals": [0.0, 0.0, -4.979, 0.0, 0.0, 0.0, 0.0, 0.0, -4.879, -4.879]}
{"number_of_episodes": 3675, "number_of_timesteps": 53661, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1213, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1214.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1214.0, 1214.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 3679, "number_of_timesteps": 53710, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1214, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1215.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1215.0, 1215.0], "q_vals": [0.0, 0.0, -4.986, 0.0, 0.0, 0.0, 0.0, 0.0, -4.885, -4.885]}
{"number_of_episodes": 3684, "number_of_timesteps": 53765, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1215, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1216.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1216.0, 1216.0], "q_vals": [0.0, 0.0, -4.982, 0.0, 0.0, 0.0, 0.0, 0.0, -4.881, -4.881]}
{"number_of_episodes": 3687, "number_of_timesteps": 53794, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1216, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1217.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1217.0, 1217.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.887, -4.887]}
{"step": 1217, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1218.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1218.0, 1218.0], "q_vals": [0.0, 0.0, -4.999, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"step": 1218, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1219.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1219.0, 1219.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.891, -4.891]}
{"number_of_episodes": 3697, "number_of_timesteps": 53906, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1219, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1220.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1220.0, 1220.0], "q_vals": [0.0, 0.0, -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 3699, "number_of_timesteps": 53944, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1220, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1221.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1221.0, 1221.0], "q_vals": [0.0, 0.0, -5.01, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"number_of_episodes": 3703, "number_of_timesteps": 53999, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1221, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1222.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1222.0, 1222.0], "q_vals": [0.0, 0.0, -5.006, 0.0, 0.0, 0.0, 0.0, 0.0, -4.9, -4.9]}
{"step": 1222, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1223.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1223.0, 1223.0], "q_vals": [0.0, 0.0, -5.002, 0.0, 0.0, 0.0, 0.0, 0.0, -4.896, -4.896]}
{"number_of_episodes": 3710, "number_of_timesteps": 54080, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1223, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1224.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1224.0, 1224.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.892, -4.892]}
{"number_of_episodes": 3714, "number_of_timesteps": 54130, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1224, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1225.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1225.0, 1225.0], "q_vals": [0.0, 0.0, -4.999, 0.0, 0.0, 0.0, 0.0, 0.0, -4.892, -4.892]}
{"number_of_episodes": 3718, "number_of_timesteps": 54174, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1225, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1226.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1226.0, 1226.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.89, -4.89]}
{"number_of_episodes": 3721, "number_of_timesteps": 54203, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1226, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1227.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1227.0, 1227.0], "q_vals": [0.0, 0.0, -4.998, 0.0, 0.0, 0.0, 0.0, 0.0, -4.892, -4.892]}
{"number_of_episodes": 3727, "number_of_timesteps": 54277, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1227, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1228.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1228.0, 1228.0], "q_vals": [0.0, 0.0, -4.999, 0.0, 0.0, 0.0, 0.0, 0.0, -4.893, -4.893]}
{"number_of_episodes": 3729, "number_of_timesteps": 54297, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1228, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1229.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1229.0, 1229.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 3733, "number_of_timesteps": 54339, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1229, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1230.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1230.0, 1230.0], "q_vals": [0.0, 0.0, -5.002, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 3739, "number_of_timesteps": 54412, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1230, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1231.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1231.0, 1231.0], "q_vals": [0.0, 0.0, -4.998, 0.0, 0.0, 0.0, 0.0, 0.0, -4.891, -4.891]}
{"number_of_episodes": 3741, "number_of_timesteps": 54430, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1231, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1232.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1232.0, 1232.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.892, -4.892]}
{"number_of_episodes": 3745, "number_of_timesteps": 54475, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1232, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1233.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1233.0, 1233.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.893, -4.893]}
{"number_of_episodes": 3747, "number_of_timesteps": 54499, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1233, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1234.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1234.0, 1234.0], "q_vals": [0.0, 0.0, -4.998, 0.0, 0.0, 0.0, 0.0, 0.0, -4.894, -4.894]}
{"step": 1234, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1235.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1235.0, 1235.0], "q_vals": [0.0, 0.0, -4.999, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"number_of_episodes": 3757, "number_of_timesteps": 54626, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1235, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1236.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1236.0, 1236.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.891, -4.891]}
{"number_of_episodes": 3758, "number_of_timesteps": 54636, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1236, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1237.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1237.0, 1237.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.892, -4.892]}
{"step": 1237, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1238.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1238.0, 1238.0], "q_vals": [0.0, 0.0, -4.993, 0.0, 0.0, 0.0, 0.0, 0.0, -4.888, -4.888]}
{"number_of_episodes": 3767, "number_of_timesteps": 54739, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1238, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1239.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1239.0, 1239.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.886, -4.886]}
{"eval_score": 11.9, "number_of_episodes": 3772}
{"number_of_episodes": 3772, "number_of_timesteps": 54795, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1239, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1240.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1240.0, 1240.0], "q_vals": [0.0, 0.0, -4.985, 0.0, 0.0, 0.0, 0.0, 0.0, -4.882, -4.882]}
{"step": 1240, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1241.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1241.0, 1241.0], "q_vals": [0.0, 0.0, -4.981, 0.0, 0.0, 0.0, 0.0, 0.0, -4.884, -4.884]}
{"number_of_episodes": 3778, "number_of_timesteps": 54850, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1241, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1242.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1242.0, 1242.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.893, -4.893]}
{"number_of_episodes": 3783, "number_of_timesteps": 54911, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1242, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1243.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1243.0, 1243.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.893, -4.893]}
{"number_of_episodes": 3787, "number_of_timesteps": 54955, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1243, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1244.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1244.0, 1244.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 3791, "number_of_timesteps": 54995, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1244, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1245.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1245.0, 1245.0], "q_vals": [0.0, 0.0, -4.998, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 3794, "number_of_timesteps": 55028, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1245, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1246.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1246.0, 1246.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.894, -4.894]}
{"number_of_episodes": 3798, "number_of_timesteps": 55078, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1246, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1247.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1247.0, 1247.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.894, -4.894]}
{"number_of_episodes": 3803, "number_of_timesteps": 55138, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1247, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1248.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1248.0, 1248.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.895, -4.895]}
{"step": 1248, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1249.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1249.0, 1249.0], "q_vals": [0.0, 0.0, -4.988, 0.0, 0.0, 0.0, 0.0, 0.0, -4.896, -4.896]}
{"number_of_episodes": 3810, "number_of_timesteps": 55212, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1249, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1250.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1250.0, 1250.0], "q_vals": [0.0, 0.0, -4.984, 0.0, 0.0, 0.0, 0.0, 0.0, -4.892, -4.892]}
{"number_of_episodes": 3813, "number_of_timesteps": 55247, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1250, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1251.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1251.0, 1251.0], "q_vals": [0.0, 0.0, -4.98, 0.0, 0.0, 0.0, 0.0, 0.0, -4.888, -4.888]}
{"number_of_episodes": 3817, "number_of_timesteps": 55298, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1251, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1252.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1252.0, 1252.0], "q_vals": [0.0, 0.0, -4.982, 0.0, 0.0, 0.0, 0.0, 0.0, -4.889, -4.889]}
{"number_of_episodes": 3818, "number_of_timesteps": 55310, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1252, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1253.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1253.0, 1253.0], "q_vals": [0.0, 0.0, -4.984, 0.0, 0.0, 0.0, 0.0, 0.0, -4.89, -4.89]}
{"number_of_episodes": 3824, "number_of_timesteps": 55390, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1253, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1254.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1254.0, 1254.0], "q_vals": [0.0, 0.0, -4.98, 0.0, 0.0, 0.0, 0.0, 0.0, -4.886, -4.886]}
{"number_of_episodes": 3828, "number_of_timesteps": 55444, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1254, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1255.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1255.0, 1255.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.896, -4.896]}
{"number_of_episodes": 3830, "number_of_timesteps": 55461, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1255, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1256.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1256.0, 1256.0], "q_vals": [0.0, 0.0, -5.001, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"number_of_episodes": 3834, "number_of_timesteps": 55505, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1256, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1257.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1257.0, 1257.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.9, -4.9]}
{"number_of_episodes": 3840, "number_of_timesteps": 55574, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1257, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1258.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1258.0, 1258.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.9, -4.9]}
{"number_of_episodes": 3841, "number_of_timesteps": 55583, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1258, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1259.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1259.0, 1259.0], "q_vals": [0.0, 0.0, -5.007, 0.0, 0.0, 0.0, 0.0, 0.0, -4.908, -4.908]}
{"number_of_episodes": 3845, "number_of_timesteps": 55631, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1259, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1260.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1260.0, 1260.0], "q_vals": [0.0, 0.0, -5.007, 0.0, 0.0, 0.0, 0.0, 0.0, -4.908, -4.908]}
{"number_of_episodes": 3849, "number_of_timesteps": 55690, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1260, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1261.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1261.0, 1261.0], "q_vals": [0.0, 0.0, -5.003, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"number_of_episodes": 3853, "number_of_timesteps": 55739, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1261, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1262.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1262.0, 1262.0], "q_vals": [0.0, 0.0, -5.011, 0.0, 0.0, 0.0, 0.0, 0.0, -4.91, -4.91]}
{"number_of_episodes": 3856, "number_of_timesteps": 55772, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1262, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1263.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1263.0, 1263.0], "q_vals": [0.0, 0.0, -5.007, 0.0, 0.0, 0.0, 0.0, 0.0, -4.907, -4.907]}
{"number_of_episodes": 3859, "number_of_timesteps": 55803, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1263, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1264.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1264.0, 1264.0], "q_vals": [0.0, 0.0, -5.007, 0.0, 0.0, 0.0, 0.0, 0.0, -4.906, -4.906]}
{"number_of_episodes": 3864, "number_of_timesteps": 55871, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1264, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1265.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1265.0, 1265.0], "q_vals": [0.0, 0.0, -5.014, 0.0, 0.0, 0.0, 0.0, 0.0, -4.912, -4.912]}
{"step": 1265, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1266.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1266.0, 1266.0], "q_vals": [0.0, 0.0, -5.024, 0.0, 0.0, 0.0, 0.0, 0.0, -4.92, -4.92]}
{"number_of_episodes": 3872, "number_of_timesteps": 55967, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1266, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1267.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1267.0, 1267.0], "q_vals": [0.0, 0.0, -5.025, 0.0, 0.0, 0.0, 0.0, 0.0, -4.921, -4.921]}
{"number_of_episodes": 3874, "number_of_timesteps": 55990, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1267, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1268.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1268.0, 1268.0], "q_vals": [0.0, 0.0, -5.021, 0.0, 0.0, 0.0, 0.0, 0.0, -4.924, -4.924]}
{"step": 1268, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1269.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1269.0, 1269.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.92, -4.92]}
{"number_of_episodes": 3883, "number_of_timesteps": 56088, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1269, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1270.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1270.0, 1270.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.919, -4.919]}
{"number_of_episodes": 3884, "number_of_timesteps": 56101, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1270, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1271.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1271.0, 1271.0], "q_vals": [0.0, 0.0, -5.019, 0.0, 0.0, 0.0, 0.0, 0.0, -4.921, -4.921]}
{"step": 1271, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1272.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1272.0, 1272.0], "q_vals": [0.0, 0.0, -5.029, 0.0, 0.0, 0.0, 0.0, 0.0, -4.929, -4.929]}
{"number_of_episodes": 3893, "number_of_timesteps": 56201, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1272, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1273.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1273.0, 1273.0], "q_vals": [0.0, 0.0, -5.025, 0.0, 0.0, 0.0, 0.0, 0.0, -4.93, -4.93]}
{"number_of_episodes": 3898, "number_of_timesteps": 56258, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1273, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1274.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1274.0, 1274.0], "q_vals": [0.0, 0.0, -5.021, 0.0, 0.0, 0.0, 0.0, 0.0, -4.926, -4.926]}
{"eval_score": 12.4, "number_of_episodes": 3902}
{"number_of_episodes": 3902, "number_of_timesteps": 56305, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1274, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1275.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1275.0, 1275.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.922, -4.922]}
{"number_of_episodes": 3904, "number_of_timesteps": 56326, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1275, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1276.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1276.0, 1276.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.923, -4.923]}
{"number_of_episodes": 3909, "number_of_timesteps": 56383, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1276, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1277.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1277.0, 1277.0], "q_vals": [0.0, 0.0, -5.026, 0.0, 0.0, 0.0, 0.0, 0.0, -4.929, -4.929]}
{"number_of_episodes": 3913, "number_of_timesteps": 56430, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1277, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1278.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1278.0, 1278.0], "q_vals": [0.0, 0.0, -5.022, 0.0, 0.0, 0.0, 0.0, 0.0, -4.929, -4.929]}
{"number_of_episodes": 3916, "number_of_timesteps": 56460, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1278, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1279.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1279.0, 1279.0], "q_vals": [0.0, 0.0, -5.031, 0.0, 0.0, 0.0, 0.0, 0.0, -4.936, -4.936]}
{"number_of_episodes": 3920, "number_of_timesteps": 56502, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1279, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1280.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1280.0, 1280.0], "q_vals": [0.0, 0.0, -5.04, 0.0, 0.0, 0.0, 0.0, 0.0, -4.944, -4.944]}
{"number_of_episodes": 3925, "number_of_timesteps": 56558, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1280, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1281.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1281.0, 1281.0], "q_vals": [0.0, 0.0, -5.04, 0.0, 0.0, 0.0, 0.0, 0.0, -4.944, -4.944]}
{"number_of_episodes": 3928, "number_of_timesteps": 56590, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1281, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1282.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1282.0, 1282.0], "q_vals": [0.0, 0.0, -5.039, 0.0, 0.0, 0.0, 0.0, 0.0, -4.943, -4.943]}
{"number_of_episodes": 3932, "number_of_timesteps": 56632, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1282, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1283.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1283.0, 1283.0], "q_vals": [0.0, 0.0, -5.04, 0.0, 0.0, 0.0, 0.0, 0.0, -4.943, -4.943]}
{"number_of_episodes": 3936, "number_of_timesteps": 56671, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1283, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1284.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1284.0, 1284.0], "q_vals": [0.0, 0.0, -5.049, 0.0, 0.0, 0.0, 0.0, 0.0, -4.951, -4.951]}
{"number_of_episodes": 3937, "number_of_timesteps": 56683, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1284, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1285.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1285.0, 1285.0], "q_vals": [0.0, 0.0, -5.045, 0.0, 0.0, 0.0, 0.0, 0.0, -4.947, -4.947]}
{"number_of_episodes": 3941, "number_of_timesteps": 56732, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1285, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1286.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1286.0, 1286.0], "q_vals": [0.0, 0.0, -5.055, 0.0, 0.0, 0.0, 0.0, 0.0, -4.955, -4.955]}
{"number_of_episodes": 3944, "number_of_timesteps": 56781, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1286, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1287.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1287.0, 1287.0], "q_vals": [0.0, 0.0, -5.056, 0.0, 0.0, 0.0, 0.0, 0.0, -4.955, -4.955]}
{"number_of_episodes": 3948, "number_of_timesteps": 56848, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 1287, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1288.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1288.0, 1288.0], "q_vals": [0.0, 0.0, -5.052, 0.0, 0.0, 0.0, 0.0, 0.0, -4.956, -4.956]}
{"step": 1288, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1289.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1289.0, 1289.0], "q_vals": [0.0, 0.0, -5.052, 0.0, 0.0, 0.0, 0.0, 0.0, -4.956, -4.956]}
{"number_of_episodes": 3956, "number_of_timesteps": 56931, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1289, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1290.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1290.0, 1290.0], "q_vals": [0.0, 0.0, -5.048, 0.0, 0.0, 0.0, 0.0, 0.0, -4.952, -4.952]}
{"step": 1290, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1291.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1291.0, 1291.0], "q_vals": [0.0, 0.0, -5.044, 0.0, 0.0, 0.0, 0.0, 0.0, -4.948, -4.948]}
{"number_of_episodes": 3962, "number_of_timesteps": 57005, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1291, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1292.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1292.0, 1292.0], "q_vals": [0.0, 0.0, -5.041, 0.0, 0.0, 0.0, 0.0, 0.0, -4.948, -4.948]}
{"step": 1292, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1293.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1293.0, 1293.0], "q_vals": [0.0, 0.0, -5.037, 0.0, 0.0, 0.0, 0.0, 0.0, -4.948, -4.948]}
{"number_of_episodes": 3967, "number_of_timesteps": 57072, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1293, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1294.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1294.0, 1294.0], "q_vals": [0.0, 0.0, -5.05, 0.0, 0.0, 0.0, 0.0, 0.0, -4.959, -4.959]}
{"number_of_episodes": 3972, "number_of_timesteps": 57129, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1294, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1295.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1295.0, 1295.0], "q_vals": [0.0, 0.0, -5.049, 0.0, 0.0, 0.0, 0.0, 0.0, -4.958, -4.958]}
{"number_of_episodes": 3974, "number_of_timesteps": 57152, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1295, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1296.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1296.0, 1296.0], "q_vals": [0.0, 0.0, -5.045, 0.0, 0.0, 0.0, 0.0, 0.0, -4.954, -4.954]}
{"number_of_episodes": 3978, "number_of_timesteps": 57228, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1296, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1297.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1297.0, 1297.0], "q_vals": [0.0, 0.0, -5.041, 0.0, 0.0, 0.0, 0.0, 0.0, -4.954, -4.954]}
{"number_of_episodes": 3981, "number_of_timesteps": 57264, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1297, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1298.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1298.0, 1298.0], "q_vals": [0.0, 0.0, -5.048, 0.0, 0.0, 0.0, 0.0, 0.0, -4.959, -4.959]}
{"number_of_episodes": 3984, "number_of_timesteps": 57296, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1298, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1299.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1299.0, 1299.0], "q_vals": [0.0, 0.0, -5.044, 0.0, 0.0, 0.0, 0.0, 0.0, -4.956, -4.956]}
{"step": 1299, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1300.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1300.0, 1300.0], "q_vals": [0.0, 0.0, -5.05, 0.0, 0.0, 0.0, 0.0, 0.0, -4.96, -4.96]}
{"number_of_episodes": 3990, "number_of_timesteps": 57367, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1300, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1301.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1301.0, 1301.0], "q_vals": [0.0, 0.0, -5.05, 0.0, 0.0, 0.0, 0.0, 0.0, -4.96, -4.96]}
{"number_of_episodes": 3994, "number_of_timesteps": 57434, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1301, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1302.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1302.0, 1302.0], "q_vals": [0.0, 0.0, -5.05, 0.0, 0.0, 0.0, 0.0, 0.0, -4.959, -4.959]}
{"number_of_episodes": 3995, "number_of_timesteps": 57444, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"step": 1302, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1303.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1303.0, 1303.0], "q_vals": [0.0, 0.0, -5.051, 0.0, 0.0, 0.0, 0.0, 0.0, -4.96, -4.96]}
{"number_of_episodes": 3998, "number_of_timesteps": 57491, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1303, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1304.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1304.0, 1304.0], "q_vals": [0.0, 0.0, -5.047, 0.0, 0.0, 0.0, 0.0, 0.0, -4.958, -4.958]}
{"number_of_episodes": 4003, "number_of_timesteps": 57558, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1304, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1305.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1305.0, 1305.0], "q_vals": [0.0, 0.0, -5.055, 0.0, 0.0, 0.0, 0.0, 0.0, -4.964, -4.964]}
{"step": 1305, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1306.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1306.0, 1306.0], "q_vals": [0.0, 0.0, -5.055, 0.0, 0.0, 0.0, 0.0, 0.0, -4.964, -4.964]}
{"number_of_episodes": 4008, "number_of_timesteps": 57643, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1306, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1307.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1307.0, 1307.0], "q_vals": [0.0, 0.0, -5.051, 0.0, 0.0, 0.0, 0.0, 0.0, -4.96, -4.96]}
{"number_of_episodes": 4012, "number_of_timesteps": 57696, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1307, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1308.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1308.0, 1308.0], "q_vals": [0.0, 0.0, -5.047, 0.0, 0.0, 0.0, 0.0, 0.0, -4.961, -4.961]}
{"number_of_episodes": 4017, "number_of_timesteps": 57754, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"step": 1308, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1309.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1309.0, 1309.0], "q_vals": [0.0, 0.0, -5.049, 0.0, 0.0, 0.0, 0.0, 0.0, -4.962, -4.962]}
{"number_of_episodes": 4021, "number_of_timesteps": 57795, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1309, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1310.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1310.0, 1310.0], "q_vals": [0.0, 0.0, -5.06, 0.0, 0.0, 0.0, 0.0, 0.0, -4.971, -4.971]}
{"number_of_episodes": 4025, "number_of_timesteps": 57836, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1310, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1311.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1311.0, 1311.0], "q_vals": [0.0, 0.0, -5.06, 0.0, 0.0, 0.0, 0.0, 0.0, -4.971, -4.971]}
{"number_of_episodes": 4026, "number_of_timesteps": 57851, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"step": 1311, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1312.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1312.0, 1312.0], "q_vals": [0.0, 0.0, -5.061, 0.0, 0.0, 0.0, 0.0, 0.0, -4.971, -4.971]}
{"eval_score": 14.1, "number_of_episodes": 4030}
{"number_of_episodes": 4030, "number_of_timesteps": 57903, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1312, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1313.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1313.0, 1313.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.971, -4.971]}
{"number_of_episodes": 4034, "number_of_timesteps": 57957, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1313, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1314.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1314.0, 1314.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.972, -4.972]}
{"number_of_episodes": 4035, "number_of_timesteps": 57975, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1314, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1315.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1315.0, 1315.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.971, -4.971]}
{"number_of_episodes": 4040, "number_of_timesteps": 58047, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"step": 1315, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1316.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1316.0, 1316.0], "q_vals": [0.0, 0.0, -5.058, 0.0, 0.0, 0.0, 0.0, 0.0, -4.967, -4.967]}
{"number_of_episodes": 4045, "number_of_timesteps": 58118, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1316, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1317.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1317.0, 1317.0], "q_vals": [0.0, 0.0, -5.054, 0.0, 0.0, 0.0, 0.0, 0.0, -4.968, -4.968]}
{"number_of_episodes": 4047, "number_of_timesteps": 58137, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1317, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1318.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1318.0, 1318.0], "q_vals": [0.0, 0.0, -5.052, 0.0, 0.0, 0.0, 0.0, 0.0, -4.966, -4.966]}
{"number_of_episodes": 4050, "number_of_timesteps": 58173, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1318, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1319.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1319.0, 1319.0], "q_vals": [0.0, 0.0, -5.054, 0.0, 0.0, 0.0, 0.0, 0.0, -4.967, -4.967]}
{"number_of_episodes": 4057, "number_of_timesteps": 58256, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1319, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1320.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1320.0, 1320.0], "q_vals": [0.0, 0.0, -5.054, 0.0, 0.0, 0.0, 0.0, 0.0, -4.966, -4.966]}
{"number_of_episodes": 4059, "number_of_timesteps": 58274, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1320, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1321.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1321.0, 1321.0], "q_vals": [0.0, 0.0, -5.05, 0.0, 0.0, 0.0, 0.0, 0.0, -4.963, -4.963]}
{"step": 1321, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1322.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1322.0, 1322.0], "q_vals": [0.0, 0.0, -5.046, 0.0, 0.0, 0.0, 0.0, 0.0, -4.959, -4.959]}
{"step": 1322, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1323.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1323.0, 1323.0], "q_vals": [0.0, 0.0, -5.042, 0.0, 0.0, 0.0, 0.0, 0.0, -4.955, -4.955]}
{"number_of_episodes": 4070, "number_of_timesteps": 58396, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1323, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1324.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1324.0, 1324.0], "q_vals": [0.0, 0.0, -5.043, 0.0, 0.0, 0.0, 0.0, 0.0, -4.956, -4.956]}
{"number_of_episodes": 4073, "number_of_timesteps": 58452, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"step": 1324, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1325.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1325.0, 1325.0], "q_vals": [0.0, 0.0, -5.043, 0.0, 0.0, 0.0, 0.0, 0.0, -4.955, -4.955]}
{"number_of_episodes": 4078, "number_of_timesteps": 58508, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"step": 1325, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1326.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1326.0, 1326.0], "q_vals": [0.0, 0.0, -5.039, 0.0, 0.0, 0.0, 0.0, 0.0, -4.951, -4.951]}
{"number_of_episodes": 4080, "number_of_timesteps": 58529, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1326, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1327.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1327.0, 1327.0], "q_vals": [0.0, 0.0, -5.035, 0.0, 0.0, 0.0, 0.0, 0.0, -4.952, -4.952]}
{"number_of_episodes": 4084, "number_of_timesteps": 58583, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1327, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1328.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1328.0, 1328.0], "q_vals": [0.0, 0.0, -5.035, 0.0, 0.0, 0.0, 0.0, 0.0, -4.952, -4.952]}
{"number_of_episodes": 4089, "number_of_timesteps": 58639, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1328, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1329.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1329.0, 1329.0], "q_vals": [0.0, 0.0, -5.032, 0.0, 0.0, 0.0, 0.0, 0.0, -4.948, -4.948]}
{"number_of_episodes": 4091, "number_of_timesteps": 58664, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1329, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1330.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1330.0, 1330.0], "q_vals": [0.0, 0.0, -5.033, 0.0, 0.0, 0.0, 0.0, 0.0, -4.949, -4.949]}
{"number_of_episodes": 4094, "number_of_timesteps": 58696, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1330, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1331.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1331.0, 1331.0], "q_vals": [0.0, 0.0, -5.035, 0.0, 0.0, 0.0, 0.0, 0.0, -4.95, -4.95]}
{"number_of_episodes": 4099, "number_of_timesteps": 58763, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1331, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1332.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1332.0, 1332.0], "q_vals": [0.0, 0.0, -5.031, 0.0, 0.0, 0.0, 0.0, 0.0, -4.947, -4.947]}
{"number_of_episodes": 4103, "number_of_timesteps": 58809, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1332, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1333.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1333.0, 1333.0], "q_vals": [0.0, 0.0, -5.038, 0.0, 0.0, 0.0, 0.0, 0.0, -4.952, -4.952]}
{"number_of_episodes": 4105, "number_of_timesteps": 58827, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1333, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1334.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1334.0, 1334.0], "q_vals": [0.0, 0.0, -5.038, 0.0, 0.0, 0.0, 0.0, 0.0, -4.952, -4.952]}
{"number_of_episodes": 4109, "number_of_timesteps": 58879, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1334, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1335.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1335.0, 1335.0], "q_vals": [0.0, 0.0, -5.04, 0.0, 0.0, 0.0, 0.0, 0.0, -4.953, -4.953]}
{"number_of_episodes": 4113, "number_of_timesteps": 58924, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"step": 1335, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1336.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1336.0, 1336.0], "q_vals": [0.0, 0.0, -5.04, 0.0, 0.0, 0.0, 0.0, 0.0, -4.952, -4.952]}
{"step": 1336, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1337.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1337.0, 1337.0], "q_vals": [0.0, 0.0, -5.041, 0.0, 0.0, 0.0, 0.0, 0.0, -4.953, -4.953]}
{"number_of_episodes": 4120, "number_of_timesteps": 59019, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1337, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1338.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1338.0, 1338.0], "q_vals": [0.0, 0.0, -5.037, 0.0, 0.0, 0.0, 0.0, 0.0, -4.956, -4.956]}
{"number_of_episodes": 4123, "number_of_timesteps": 59057, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
{"step": 1338, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1339.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1339.0, 1339.0], "q_vals": [0.0, 0.0, -5.048, 0.0, 0.0, 0.0, 0.0, 0.0, -4.965, -4.965]}
{"number_of_episodes": 4127, "number_of_timesteps": 59100, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1339, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1340.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1340.0, 1340.0], "q_vals": [0.0, 0.0, -5.048, 0.0, 0.0, 0.0, 0.0, 0.0, -4.964, -4.964]}
{"step": 1340, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1341.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1341.0, 1341.0], "q_vals": [0.0, 0.0, -5.048, 0.0, 0.0, 0.0, 0.0, 0.0, -4.964, -4.964]}
{"number_of_episodes": 4132, "number_of_timesteps": 59174, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1341, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1342.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1342.0, 1342.0], "q_vals": [0.0, 0.0, -5.049, 0.0, 0.0, 0.0, 0.0, 0.0, -4.964, -4.964]}
{"number_of_episodes": 4136, "number_of_timesteps": 59227, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1342, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1343.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1343.0, 1343.0], "q_vals": [0.0, 0.0, -5.049, 0.0, 0.0, 0.0, 0.0, 0.0, -4.964, -4.964]}
{"number_of_episodes": 4138, "number_of_timesteps": 59256, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1343, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1344.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1344.0, 1344.0], "q_vals": [0.0, 0.0, -5.046, 0.0, 0.0, 0.0, 0.0, 0.0, -4.961, -4.961]}
{"number_of_episodes": 4140, "number_of_timesteps": 59282, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1344, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1345.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1345.0, 1345.0], "q_vals": [0.0, 0.0, -5.042, 0.0, 0.0, 0.0, 0.0, 0.0, -4.962, -4.962]}
{"number_of_episodes": 4145, "number_of_timesteps": 59346, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
{"step": 1345, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1346.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1346.0, 1346.0], "q_vals": [0.0, 0.0, -5.048, 0.0, 0.0, 0.0, 0.0, 0.0, -4.967, -4.967]}
{"step": 1346, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1347.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1347.0, 1347.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"number_of_episodes": 4151, "number_of_timesteps": 59445, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1347, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1348.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1348.0, 1348.0], "q_vals": [0.0, 0.0, -5.063, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"number_of_episodes": 4155, "number_of_timesteps": 59497, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1348, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1349.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1349.0, 1349.0], "q_vals": [0.0, 0.0, -5.063, 0.0, 0.0, 0.0, 0.0, 0.0, -4.978, -4.978]}
{"number_of_episodes": 4157, "number_of_timesteps": 59526, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1349, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1350.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1350.0, 1350.0], "q_vals": [0.0, 0.0, -5.059, 0.0, 0.0, 0.0, 0.0, 0.0, -4.975, -4.975]}
{"eval_score": 13.6, "number_of_episodes": 4161}
{"number_of_episodes": 4161, "number_of_timesteps": 59586, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1350, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1351.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1351.0, 1351.0], "q_vals": [0.0, 0.0, -5.059, 0.0, 0.0, 0.0, 0.0, 0.0, -4.975, -4.975]}
{"number_of_episodes": 4164, "number_of_timesteps": 59619, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1351, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1352.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1352.0, 1352.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.976, -4.976]}
{"number_of_episodes": 4165, "number_of_timesteps": 59639, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1352, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1353.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1353.0, 1353.0], "q_vals": [0.0, 0.0, -5.063, 0.0, 0.0, 0.0, 0.0, 0.0, -4.977, -4.977]}
{"number_of_episodes": 4167, "number_of_timesteps": 59664, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1353, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1354.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1354.0, 1354.0], "q_vals": [0.0, 0.0, -5.059, 0.0, 0.0, 0.0, 0.0, 0.0, -4.974, -4.974]}
{"step": 1354, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1355.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1355.0, 1355.0], "q_vals": [0.0, 0.0, -5.061, 0.0, 0.0, 0.0, 0.0, 0.0, -4.975, -4.975]}
{"number_of_episodes": 4175, "number_of_timesteps": 59801, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1355, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1356.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1356.0, 1356.0], "q_vals": [0.0, 0.0, -5.059, 0.0, 0.0, 0.0, 0.0, 0.0, -4.973, -4.973]}
{"number_of_episodes": 4178, "number_of_timesteps": 59842, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1356, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1357.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1357.0, 1357.0], "q_vals": [0.0, 0.0, -5.055, 0.0, 0.0, 0.0, 0.0, 0.0, -4.969, -4.969]}
{"number_of_episodes": 4181, "number_of_timesteps": 59880, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1357, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1358.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1358.0, 1358.0], "q_vals": [0.0, 0.0, -5.063, 0.0, 0.0, 0.0, 0.0, 0.0, -4.975, -4.975]}
{"number_of_episodes": 4183, "number_of_timesteps": 59915, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1358, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1359.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1359.0, 1359.0], "q_vals": [0.0, 0.0, -5.064, 0.0, 0.0, 0.0, 0.0, 0.0, -4.976, -4.976]}
{"number_of_episodes": 4189, "number_of_timesteps": 59994, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1359, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1360.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1360.0, 1360.0], "q_vals": [0.0, 0.0, -5.06, 0.0, 0.0, 0.0, 0.0, 0.0, -4.972, -4.972]}
{"number_of_episodes": 4190, "number_of_timesteps": 60008, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1360, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1361.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1361.0, 1361.0], "q_vals": [0.0, 0.0, -5.057, 0.0, 0.0, 0.0, 0.0, 0.0, -4.969, -4.969]}
{"number_of_episodes": 4195, "number_of_timesteps": 60080, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1361, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1362.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1362.0, 1362.0], "q_vals": [0.0, 0.0, -5.054, 0.0, 0.0, 0.0, 0.0, 0.0, -4.966, -4.966]}
{"number_of_episodes": 4198, "number_of_timesteps": 60114, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1362, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1363.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1363.0, 1363.0], "q_vals": [0.0, 0.0, -5.059, 0.0, 0.0, 0.0, 0.0, 0.0, -4.97, -4.97]}
{"number_of_episodes": 4200, "number_of_timesteps": 60143, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1363, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1364.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1364.0, 1364.0], "q_vals": [0.0, 0.0, -5.066, 0.0, 0.0, 0.0, 0.0, 0.0, -4.976, -4.976]}
{"number_of_episodes": 4204, "number_of_timesteps": 60184, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1364, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1365.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1365.0, 1365.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.972, -4.972]}
{"number_of_episodes": 4207, "number_of_timesteps": 60232, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1365, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1366.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1366.0, 1366.0], "q_vals": [0.0, 0.0, -5.058, 0.0, 0.0, 0.0, 0.0, 0.0, -4.968, -4.968]}
{"step": 1366, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1367.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1367.0, 1367.0], "q_vals": [0.0, 0.0, -5.055, 0.0, 0.0, 0.0, 0.0, 0.0, -4.965, -4.965]}
{"number_of_episodes": 4212, "number_of_timesteps": 60312, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1367, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1368.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1368.0, 1368.0], "q_vals": [0.0, 0.0, -5.051, 0.0, 0.0, 0.0, 0.0, 0.0, -4.961, -4.961]}
{"number_of_episodes": 4213, "number_of_timesteps": 60326, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1368, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1369.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1369.0, 1369.0], "q_vals": [0.0, 0.0, -5.052, 0.0, 0.0, 0.0, 0.0, 0.0, -4.961, -4.961]}
{"step": 1369, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1370.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1370.0, 1370.0], "q_vals": [0.0, 0.0, -5.048, 0.0, 0.0, 0.0, 0.0, 0.0, -4.958, -4.958]}
{"number_of_episodes": 4220, "number_of_timesteps": 60438, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1370, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1371.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1371.0, 1371.0], "q_vals": [0.0, 0.0, -5.048, 0.0, 0.0, 0.0, 0.0, 0.0, -4.957, -4.957]}
{"number_of_episodes": 4222, "number_of_timesteps": 60462, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1371, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1372.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1372.0, 1372.0], "q_vals": [0.0, 0.0, -5.044, 0.0, 0.0, 0.0, 0.0, 0.0, -4.957, -4.957]}
{"number_of_episodes": 4228, "number_of_timesteps": 60573, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1372, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1373.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1373.0, 1373.0], "q_vals": [0.0, 0.0, -5.05, 0.0, 0.0, 0.0, 0.0, 0.0, -4.962, -4.962]}
{"step": 1373, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1374.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1374.0, 1374.0], "q_vals": [0.0, 0.0, -5.06, 0.0, 0.0, 0.0, 0.0, 0.0, -4.971, -4.971]}
{"number_of_episodes": 4231, "number_of_timesteps": 60607, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1374, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1375.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1375.0, 1375.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.971, -4.971]}
{"number_of_episodes": 4235, "number_of_timesteps": 60655, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1375, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1376.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1376.0, 1376.0], "q_vals": [0.0, 0.0, -5.058, 0.0, 0.0, 0.0, 0.0, 0.0, -4.968, -4.968]}
{"step": 1376, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1377.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1377.0, 1377.0], "q_vals": [0.0, 0.0, -5.058, 0.0, 0.0, 0.0, 0.0, 0.0, -4.968, -4.968]}
{"number_of_episodes": 4239, "number_of_timesteps": 60705, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1377, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1378.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1378.0, 1378.0], "q_vals": [0.0, 0.0, -5.059, 0.0, 0.0, 0.0, 0.0, 0.0, -4.968, -4.968]}
{"number_of_episodes": 4244, "number_of_timesteps": 60807, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1378, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1379.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1379.0, 1379.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.976, -4.976]}
{"step": 1379, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1380.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1380.0, 1380.0], "q_vals": [0.0, 0.0, -5.079, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"number_of_episodes": 4249, "number_of_timesteps": 60865, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1380, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1381.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1381.0, 1381.0], "q_vals": [0.0, 0.0, -5.075, 0.0, 0.0, 0.0, 0.0, 0.0, -4.981, -4.981]}
{"number_of_episodes": 4252, "number_of_timesteps": 60913, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1381, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1382.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1382.0, 1382.0], "q_vals": [0.0, 0.0, -5.076, 0.0, 0.0, 0.0, 0.0, 0.0, -4.982, -4.982]}
{"number_of_episodes": 4256, "number_of_timesteps": 60982, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1382, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1383.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1383.0, 1383.0], "q_vals": [0.0, 0.0, -5.073, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"step": 1383, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1384.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1384.0, 1384.0], "q_vals": [0.0, 0.0, -5.069, 0.0, 0.0, 0.0, 0.0, 0.0, -4.975, -4.975]}
{"number_of_episodes": 4262, "number_of_timesteps": 61047, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1384, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1385.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1385.0, 1385.0], "q_vals": [0.0, 0.0, -5.069, 0.0, 0.0, 0.0, 0.0, 0.0, -4.975, -4.975]}
{"number_of_episodes": 4264, "number_of_timesteps": 61071, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1385, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1386.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1386.0, 1386.0], "q_vals": [0.0, 0.0, -5.066, 0.0, 0.0, 0.0, 0.0, 0.0, -4.971, -4.971]}
{"number_of_episodes": 4267, "number_of_timesteps": 61120, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1386, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1387.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1387.0, 1387.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.968, -4.968]}
{"step": 1387, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1388.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1388.0, 1388.0], "q_vals": [0.0, 0.0, -5.059, 0.0, 0.0, 0.0, 0.0, 0.0, -4.964, -4.964]}
{"number_of_episodes": 4275, "number_of_timesteps": 61248, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1388, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1389.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1389.0, 1389.0], "q_vals": [0.0, 0.0, -5.055, 0.0, 0.0, 0.0, 0.0, 0.0, -4.964, -4.964]}
{"number_of_episodes": 4278, "number_of_timesteps": 61280, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.14999999999999858},
{"step": 1389, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1390.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1390.0, 1390.0], "q_vals": [0.0, 0.0, -5.063, 0.0, 0.0, 0.0, 0.0, 0.0, -4.971, -4.971]}
{"number_of_episodes": 4281, "number_of_timesteps": 61321, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1390, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1391.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1391.0, 1391.0], "q_vals": [0.0, 0.0, -5.069, 0.0, 0.0, 0.0, 0.0, 0.0, -4.975, -4.975]}
{"number_of_episodes": 4284, "number_of_timesteps": 61360, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1391, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1392.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1392.0, 1392.0], "q_vals": [0.0, 0.0, -5.069, 0.0, 0.0, 0.0, 0.0, 0.0, -4.975, -4.975]}
{"number_of_episodes": 4289, "number_of_timesteps": 61425, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1392, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1393.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1393.0, 1393.0], "q_vals": [0.0, 0.0, -5.069, 0.0, 0.0, 0.0, 0.0, 0.0, -4.975, -4.975]}
{"eval_score": 14.7, "number_of_episodes": 4291}
{"number_of_episodes": 4291, "number_of_timesteps": 61446, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1393, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1394.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1394.0, 1394.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.982, -4.982]}
{"number_of_episodes": 4298, "number_of_timesteps": 61522, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.14999999999999858},
{"step": 1394, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1395.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1395.0, 1395.0], "q_vals": [0.0, 0.0, -5.076, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"step": 1395, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1396.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1396.0, 1396.0], "q_vals": [0.0, 0.0, -5.08, 0.0, 0.0, 0.0, 0.0, 0.0, -4.984, -4.984]}
{"number_of_episodes": 4303, "number_of_timesteps": 61583, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1396, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1397.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1397.0, 1397.0], "q_vals": [0.0, 0.0, -5.077, 0.0, 0.0, 0.0, 0.0, 0.0, -4.984, -4.984]}
{"number_of_episodes": 4308, "number_of_timesteps": 61644, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1397, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1398.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1398.0, 1398.0], "q_vals": [0.0, 0.0, -5.077, 0.0, 0.0, 0.0, 0.0, 0.0, -4.984, -4.984]}
{"step": 1398, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1399.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1399.0, 1399.0], "q_vals": [0.0, 0.0, -5.077, 0.0, 0.0, 0.0, 0.0, 0.0, -4.984, -4.984]}
{"number_of_episodes": 4313, "number_of_timesteps": 61703, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 1399, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1400.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1400.0, 1400.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"number_of_episodes": 4316, "number_of_timesteps": 61737, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1400, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1401.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1401.0, 1401.0], "q_vals": [0.0, 0.0, -5.075, 0.0, 0.0, 0.0, 0.0, 0.0, -4.981, -4.981]}
{"step": 1401, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1402.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1402.0, 1402.0], "q_vals": [0.0, 0.0, -5.075, 0.0, 0.0, 0.0, 0.0, 0.0, -4.981, -4.981]}
{"number_of_episodes": 4323, "number_of_timesteps": 61835, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1402, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1403.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1403.0, 1403.0], "q_vals": [0.0, 0.0, -5.076, 0.0, 0.0, 0.0, 0.0, 0.0, -4.982, -4.982]}
{"number_of_episodes": 4326, "number_of_timesteps": 61894, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
{"step": 1403, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1404.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1404.0, 1404.0], "q_vals": [0.0, 0.0, -5.092, 0.0, 0.0, 0.0, 0.0, 0.0, -4.995, -4.995]}
{"number_of_episodes": 4329, "number_of_timesteps": 61928, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1404, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1405.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1405.0, 1405.0], "q_vals": [0.0, 0.0, -5.089, 0.0, 0.0, 0.0, 0.0, 0.0, -4.993, -4.993]}
{"number_of_episodes": 4332, "number_of_timesteps": 61964, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1405, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1406.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1406.0, 1406.0], "q_vals": [0.0, 0.0, -5.086, 0.0, 0.0, 0.0, 0.0, 0.0, -4.993, -4.993]}
{"number_of_episodes": 4335, "number_of_timesteps": 62009, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1406, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1407.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1407.0, 1407.0], "q_vals": [0.0, 0.0, -5.082, 0.0, 0.0, 0.0, 0.0, 0.0, -4.989, -4.989]}
{"step": 1407, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1408.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1408.0, 1408.0], "q_vals": [0.0, 0.0, -5.079, 0.0, 0.0, 0.0, 0.0, 0.0, -4.986, -4.986]}
{"number_of_episodes": 4339, "number_of_timesteps": 62074, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1408, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1409.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1409.0, 1409.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"step": 1409, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1410.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1410.0, 1410.0], "q_vals": [0.0, 0.0, -5.079, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"number_of_episodes": 4347, "number_of_timesteps": 62193, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1410, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1411.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1411.0, 1411.0], "q_vals": [0.0, 0.0, -5.079, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"number_of_episodes": 4353, "number_of_timesteps": 62259, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1411, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1412.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1412.0, 1412.0], "q_vals": [0.0, 0.0, -5.088, 0.0, 0.0, 0.0, 0.0, 0.0, -4.992, -4.992]}
{"step": 1412, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1413.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1413.0, 1413.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -4.997, -4.997]}
{"step": 1413, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1414.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1414.0, 1414.0], "q_vals": [0.0, 0.0, -5.098, 0.0, 0.0, 0.0, 0.0, 0.0, -5.001, -5.001]}
{"number_of_episodes": 4362, "number_of_timesteps": 62383, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1414, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1415.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1415.0, 1415.0], "q_vals": [0.0, 0.0, -5.106, 0.0, 0.0, 0.0, 0.0, 0.0, -5.008, -5.008]}
{"number_of_episodes": 4363, "number_of_timesteps": 62401, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
{"step": 1415, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1416.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1416.0, 1416.0], "q_vals": [0.0, 0.0, -5.103, 0.0, 0.0, 0.0, 0.0, 0.0, -5.004, -5.004]}
{"number_of_episodes": 4367, "number_of_timesteps": 62448, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1416, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1417.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1417.0, 1417.0], "q_vals": [0.0, 0.0, -5.099, 0.0, 0.0, 0.0, 0.0, 0.0, -5.001, -5.001]}
{"number_of_episodes": 4371, "number_of_timesteps": 62507, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1417, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1418.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1418.0, 1418.0], "q_vals": [0.0, 0.0, -5.099, 0.0, 0.0, 0.0, 0.0, 0.0, -5.001, -5.001]}
{"number_of_episodes": 4375, "number_of_timesteps": 62565, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1418, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1419.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1419.0, 1419.0], "q_vals": [0.0, 0.0, -5.096, 0.0, 0.0, 0.0, 0.0, 0.0, -4.997, -4.997]}
{"step": 1419, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1420.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1420.0, 1420.0], "q_vals": [0.0, 0.0, -5.092, 0.0, 0.0, 0.0, 0.0, 0.0, -4.994, -4.994]}
{"number_of_episodes": 4381, "number_of_timesteps": 62642, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1420, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1421.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1421.0, 1421.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -4.993, -4.993]}
{"step": 1421, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1422.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1422.0, 1422.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -4.993, -4.993]}
{"number_of_episodes": 4387, "number_of_timesteps": 62707, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"step": 1422, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1423.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1423.0, 1423.0], "q_vals": [0.0, 0.0, -5.095, 0.0, 0.0, 0.0, 0.0, 0.0, -4.995, -4.995]}
{"number_of_episodes": 4389, "number_of_timesteps": 62727, "per_episode_reward": 12.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
{"step": 1423, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1424.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1424.0, 1424.0], "q_vals": [0.0, 0.0, -5.098, 0.0, 0.0, 0.0, 0.0, 0.0, -4.997, -4.997]}
{"number_of_episodes": 4393, "number_of_timesteps": 62783, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1424, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1425.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1425.0, 1425.0], "q_vals": [0.0, 0.0, -5.098, 0.0, 0.0, 0.0, 0.0, 0.0, -4.997, -4.997]}
{"step": 1425, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1426.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1426.0, 1426.0], "q_vals": [0.0, 0.0, -5.099, 0.0, 0.0, 0.0, 0.0, 0.0, -4.998, -4.998]}
{"number_of_episodes": 4398, "number_of_timesteps": 62901, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1426, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1427.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1427.0, 1427.0], "q_vals": [0.0, 0.0, -5.096, 0.0, 0.0, 0.0, 0.0, 0.0, -4.994, -4.994]}
{"number_of_episodes": 4402, "number_of_timesteps": 62954, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1427, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1428.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1428.0, 1428.0], "q_vals": [0.0, 0.0, -5.092, 0.0, 0.0, 0.0, 0.0, 0.0, -4.994, -4.994]}
{"step": 1428, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1429.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1429.0, 1429.0], "q_vals": [0.0, 0.0, -5.089, 0.0, 0.0, 0.0, 0.0, 0.0, -4.991, -4.991]}
{"step": 1429, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1430.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1430.0, 1430.0], "q_vals": [0.0, 0.0, -5.085, 0.0, 0.0, 0.0, 0.0, 0.0, -4.992, -4.992]}
{"number_of_episodes": 4410, "number_of_timesteps": 63065, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1430, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1431.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1431.0, 1431.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -4.999, -4.999]}
{"number_of_episodes": 4413, "number_of_timesteps": 63107, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1431, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1432.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1432.0, 1432.0], "q_vals": [0.0, 0.0, -5.089, 0.0, 0.0, 0.0, 0.0, 0.0, -4.995, -4.995]}
{"number_of_episodes": 4417, "number_of_timesteps": 63162, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 1432, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1433.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1433.0, 1433.0], "q_vals": [0.0, 0.0, -5.089, 0.0, 0.0, 0.0, 0.0, 0.0, -4.994, -4.994]}
{"step": 1433, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1434.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1434.0, 1434.0], "q_vals": [0.0, 0.0, -5.094, 0.0, 0.0, 0.0, 0.0, 0.0, -4.998, -4.998]}
{"step": 1434, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1435.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1435.0, 1435.0], "q_vals": [0.0, 0.0, -5.094, 0.0, 0.0, 0.0, 0.0, 0.0, -4.998, -4.998]}
{"eval_score": 20.0, "number_of_episodes": 4424}
{"number_of_episodes": 4424, "number_of_timesteps": 63259, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1435, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1436.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1436.0, 1436.0], "q_vals": [0.0, 0.0, -5.094, 0.0, 0.0, 0.0, 0.0, 0.0, -4.998, -4.998]}
{"number_of_episodes": 4426, "number_of_timesteps": 63309, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1436, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1437.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1437.0, 1437.0], "q_vals": [0.0, 0.0, -5.102, 0.0, 0.0, 0.0, 0.0, 0.0, -5.005, -5.005]}
{"number_of_episodes": 4427, "number_of_timesteps": 63343, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1437, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1438.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1438.0, 1438.0], "q_vals": [0.0, 0.0, -5.103, 0.0, 0.0, 0.0, 0.0, 0.0, -5.005, -5.005]}
{"number_of_episodes": 4430, "number_of_timesteps": 63396, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1438, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1439.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1439.0, 1439.0], "q_vals": [0.0, 0.0, -5.099, 0.0, 0.0, 0.0, 0.0, 0.0, -5.001, -5.001]}
{"step": 1439, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1440.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1440.0, 1440.0], "q_vals": [0.0, 0.0, -5.096, 0.0, 0.0, 0.0, 0.0, 0.0, -4.998, -4.998]}
{"number_of_episodes": 4436, "number_of_timesteps": 63483, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1440, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1441.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1441.0, 1441.0], "q_vals": [0.0, 0.0, -5.096, 0.0, 0.0, 0.0, 0.0, 0.0, -4.997, -4.997]}
{"number_of_episodes": 4439, "number_of_timesteps": 63521, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1441, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1442.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1442.0, 1442.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -4.995, -4.995]}
{"step": 1442, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1443.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1443.0, 1443.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -4.995, -4.995]}
{"number_of_episodes": 4444, "number_of_timesteps": 63611, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1443, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1444.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1444.0, 1444.0], "q_vals": [0.0, 0.0, -5.09, 0.0, 0.0, 0.0, 0.0, 0.0, -4.994, -4.994]}
{"number_of_episodes": 4445, "number_of_timesteps": 63636, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"step": 1444, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1445.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1445.0, 1445.0], "q_vals": [0.0, 0.0, -5.086, 0.0, 0.0, 0.0, 0.0, 0.0, -4.991, -4.991]}
{"step": 1445, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1446.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1446.0, 1446.0], "q_vals": [0.0, 0.0, -5.087, 0.0, 0.0, 0.0, 0.0, 0.0, -4.991, -4.991]}
{"number_of_episodes": 4450, "number_of_timesteps": 63746, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1446, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1447.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1447.0, 1447.0], "q_vals": [0.0, 0.0, -5.088, 0.0, 0.0, 0.0, 0.0, 0.0, -4.991, -4.991]}
{"number_of_episodes": 4453, "number_of_timesteps": 63810, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1447, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1448.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1448.0, 1448.0], "q_vals": [0.0, 0.0, -5.09, 0.0, 0.0, 0.0, 0.0, 0.0, -4.993, -4.993]}
{"number_of_episodes": 4459, "number_of_timesteps": 63917, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.15000000000000036},
{"step": 1448, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1449.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1449.0, 1449.0], "q_vals": [0.0, 0.0, -5.086, 0.0, 0.0, 0.0, 0.0, 0.0, -4.99, -4.99]}
{"number_of_episodes": 4461, "number_of_timesteps": 63939, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1449, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1450.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1450.0, 1450.0], "q_vals": [0.0, 0.0, -5.088, 0.0, 0.0, 0.0, 0.0, 0.0, -4.99, -4.99]}
{"number_of_episodes": 4465, "number_of_timesteps": 63982, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 1450, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1451.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1451.0, 1451.0], "q_vals": [0.0, 0.0, -5.084, 0.0, 0.0, 0.0, 0.0, 0.0, -4.99, -4.99]}
{"number_of_episodes": 4466, "number_of_timesteps": 63997, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 1451, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1452.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1452.0, 1452.0], "q_vals": [0.0, 0.0, -5.081, 0.0, 0.0, 0.0, 0.0, 0.0, -4.987, -4.987]}
{"step": 1452, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1453.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1453.0, 1453.0], "q_vals": [0.0, 0.0, -5.077, 0.0, 0.0, 0.0, 0.0, 0.0, -4.983, -4.983]}
{"number_of_episodes": 4475, "number_of_timesteps": 64136, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 1453, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1454.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1454.0, 1454.0], "q_vals": [0.0, 0.0, -5.074, 0.0, 0.0, 0.0, 0.0, 0.0, -4.984, -4.984]}
{"number_of_episodes": 4475, "number_of_timesteps": 64136, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1454, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1455.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1455.0, 1455.0], "q_vals": [0.0, 0.0, -5.074, 0.0, 0.0, 0.0, 0.0, 0.0, -4.984, -4.984]}
{"number_of_episodes": 4478, "number_of_timesteps": 64179, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1455, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1456.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1456.0, 1456.0], "q_vals": [0.0, 0.0, -5.082, 0.0, 0.0, 0.0, 0.0, 0.0, -4.99, -4.99]}
{"number_of_episodes": 4483, "number_of_timesteps": 64247, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1456, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1457.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1457.0, 1457.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.987, -4.987]}
{"step": 1457, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1458.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1458.0, 1458.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.986, -4.986]}
{"number_of_episodes": 4489, "number_of_timesteps": 64329, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1458, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1459.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1459.0, 1459.0], "q_vals": [0.0, 0.0, -5.079, 0.0, 0.0, 0.0, 0.0, 0.0, -4.987, -4.987]}
{"step": 1459, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1460.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1460.0, 1460.0], "q_vals": [0.0, 0.0, -5.081, 0.0, 0.0, 0.0, 0.0, 0.0, -4.988, -4.988]}
{"number_of_episodes": 4494, "number_of_timesteps": 64410, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1460, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1461.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1461.0, 1461.0], "q_vals": [0.0, 0.0, -5.081, 0.0, 0.0, 0.0, 0.0, 0.0, -4.988, -4.988]}
{"number_of_episodes": 4498, "number_of_timesteps": 64457, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
{"step": 1461, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1462.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1462.0, 1462.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"step": 1462, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1463.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1463.0, 1463.0], "q_vals": [0.0, 0.0, -5.074, 0.0, 0.0, 0.0, 0.0, 0.0, -4.986, -4.986]}
{"number_of_episodes": 4505, "number_of_timesteps": 64549, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1463, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1464.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1464.0, 1464.0], "q_vals": [0.0, 0.0, -5.076, 0.0, 0.0, 0.0, 0.0, 0.0, -4.987, -4.987]}
{"number_of_episodes": 4507, "number_of_timesteps": 64571, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1464, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1465.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1465.0, 1465.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.988, -4.988]}
{"number_of_episodes": 4511, "number_of_timesteps": 64639, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1465, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1466.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1466.0, 1466.0], "q_vals": [0.0, 0.0, -5.074, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"step": 1466, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1467.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1467.0, 1467.0], "q_vals": [0.0, 0.0, -5.075, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"number_of_episodes": 4515, "number_of_timesteps": 64696, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1467, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1468.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1468.0, 1468.0], "q_vals": [0.0, 0.0, -5.073, 0.0, 0.0, 0.0, 0.0, 0.0, -4.983, -4.983]}
{"step": 1468, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1469.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1469.0, 1469.0], "q_vals": [0.0, 0.0, -5.073, 0.0, 0.0, 0.0, 0.0, 0.0, -4.983, -4.983]}
{"number_of_episodes": 4523, "number_of_timesteps": 64833, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1469, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1470.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1470.0, 1470.0], "q_vals": [0.0, 0.0, -5.07, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"number_of_episodes": 4526, "number_of_timesteps": 64867, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1470, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1471.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1471.0, 1471.0], "q_vals": [0.0, 0.0, -5.069, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"number_of_episodes": 4528, "number_of_timesteps": 64896, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1471, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1472.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1472.0, 1472.0], "q_vals": [0.0, 0.0, -5.077, 0.0, 0.0, 0.0, 0.0, 0.0, -4.986, -4.986]}
{"number_of_episodes": 4533, "number_of_timesteps": 64959, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1472, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1473.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1473.0, 1473.0], "q_vals": [0.0, 0.0, -5.083, 0.0, 0.0, 0.0, 0.0, 0.0, -4.99, -4.99]}
{"number_of_episodes": 4536, "number_of_timesteps": 65012, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1473, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1474.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1474.0, 1474.0], "q_vals": [0.0, 0.0, -5.079, 0.0, 0.0, 0.0, 0.0, 0.0, -4.99, -4.99]}
{"number_of_episodes": 4537, "number_of_timesteps": 65030, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1474, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1475.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1475.0, 1475.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.989, -4.989]}
{"number_of_episodes": 4542, "number_of_timesteps": 65093, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1475, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1476.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1476.0, 1476.0], "q_vals": [0.0, 0.0, -5.075, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"number_of_episodes": 4544, "number_of_timesteps": 65130, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1476, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1477.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1477.0, 1477.0], "q_vals": [0.0, 0.0, -5.075, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"number_of_episodes": 4547, "number_of_timesteps": 65180, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1477, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1478.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1478.0, 1478.0], "q_vals": [0.0, 0.0, -5.081, 0.0, 0.0, 0.0, 0.0, 0.0, -4.99, -4.99]}
{"number_of_episodes": 4549, "number_of_timesteps": 65213, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 1478, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1479.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1479.0, 1479.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.987, -4.987]}
{"eval_score": 18.4, "number_of_episodes": 4553}
{"step": 1479, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1480.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1480.0, 1480.0], "q_vals": [0.0, 0.0, -5.083, 0.0, 0.0, 0.0, 0.0, 0.0, -4.991, -4.991]}
{"number_of_episodes": 4556, "number_of_timesteps": 65327, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1480, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1481.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1481.0, 1481.0], "q_vals": [0.0, 0.0, -5.084, 0.0, 0.0, 0.0, 0.0, 0.0, -4.992, -4.992]}
{"number_of_episodes": 4558, "number_of_timesteps": 65356, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1481, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1482.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1482.0, 1482.0], "q_vals": [0.0, 0.0, -5.084, 0.0, 0.0, 0.0, 0.0, 0.0, -4.992, -4.992]}
{"step": 1482, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1483.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1483.0, 1483.0], "q_vals": [0.0, 0.0, -5.084, 0.0, 0.0, 0.0, 0.0, 0.0, -4.991, -4.991]}
{"number_of_episodes": 4565, "number_of_timesteps": 65443, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1483, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1484.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1484.0, 1484.0], "q_vals": [0.0, 0.0, -5.081, 0.0, 0.0, 0.0, 0.0, 0.0, -4.991, -4.991]}
{"step": 1484, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1485.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1485.0, 1485.0], "q_vals": [0.0, 0.0, -5.082, 0.0, 0.0, 0.0, 0.0, 0.0, -4.991, -4.991]}
{"number_of_episodes": 4568, "number_of_timesteps": 65493, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1485, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1486.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1486.0, 1486.0], "q_vals": [0.0, 0.0, -5.081, 0.0, 0.0, 0.0, 0.0, 0.0, -4.991, -4.991]}
{"number_of_episodes": 4572, "number_of_timesteps": 65548, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1486, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1487.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1487.0, 1487.0], "q_vals": [0.0, 0.0, -5.082, 0.0, 0.0, 0.0, 0.0, 0.0, -4.991, -4.991]}
{"step": 1487, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1488.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1488.0, 1488.0], "q_vals": [0.0, 0.0, -5.083, 0.0, 0.0, 0.0, 0.0, 0.0, -4.991, -4.991]}
{"number_of_episodes": 4579, "number_of_timesteps": 65673, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1488, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1489.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1489.0, 1489.0], "q_vals": [0.0, 0.0, -5.079, 0.0, 0.0, 0.0, 0.0, 0.0, -4.992, -4.992]}
{"number_of_episodes": 4581, "number_of_timesteps": 65721, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1489, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1490.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1490.0, 1490.0], "q_vals": [0.0, 0.0, -5.085, 0.0, 0.0, 0.0, 0.0, 0.0, -4.997, -4.997]}
{"number_of_episodes": 4583, "number_of_timesteps": 65743, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1490, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1491.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1491.0, 1491.0], "q_vals": [0.0, 0.0, -5.082, 0.0, 0.0, 0.0, 0.0, 0.0, -4.993, -4.993]}
{"number_of_episodes": 4587, "number_of_timesteps": 65798, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
{"step": 1491, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1492.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1492.0, 1492.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.99, -4.99]}
{"number_of_episodes": 4588, "number_of_timesteps": 65814, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1492, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1493.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1493.0, 1493.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.99, -4.99]}
{"step": 1493, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1494.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1494.0, 1494.0], "q_vals": [0.0, 0.0, -5.082, 0.0, 0.0, 0.0, 0.0, 0.0, -4.993, -4.993]}
{"step": 1494, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1495.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1495.0, 1495.0], "q_vals": [0.0, 0.0, -5.084, 0.0, 0.0, 0.0, 0.0, 0.0, -4.994, -4.994]}
{"number_of_episodes": 4596, "number_of_timesteps": 65948, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1495, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1496.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1496.0, 1496.0], "q_vals": [0.0, 0.0, -5.086, 0.0, 0.0, 0.0, 0.0, 0.0, -4.995, -4.995]}
{"number_of_episodes": 4601, "number_of_timesteps": 66046, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 1496, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1497.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1497.0, 1497.0], "q_vals": [0.0, 0.0, -5.082, 0.0, 0.0, 0.0, 0.0, 0.0, -4.992, -4.992]}
{"number_of_episodes": 4602, "number_of_timesteps": 66057, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1497, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1498.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1498.0, 1498.0], "q_vals": [0.0, 0.0, -5.083, 0.0, 0.0, 0.0, 0.0, 0.0, -4.992, -4.992]}
{"step": 1498, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1499.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1499.0, 1499.0], "q_vals": [0.0, 0.0, -5.088, 0.0, 0.0, 0.0, 0.0, 0.0, -4.996, -4.996]}
{"number_of_episodes": 4606, "number_of_timesteps": 66126, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1499, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1500.0, 1500.0], "q_vals": [0.0, 0.0, -5.084, 0.0, 0.0, 0.0, 0.0, 0.0, -4.996, -4.996]}
{"number_of_episodes": 4611, "number_of_timesteps": 66221, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
{"step": 1500, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1501.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1501.0, 1501.0], "q_vals": [0.0, 0.0, -5.089, 0.0, 0.0, 0.0, 0.0, 0.0, -4.999, -4.999]}
{"step": 1501, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1502.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1502.0, 1502.0], "q_vals": [0.0, 0.0, -5.095, 0.0, 0.0, 0.0, 0.0, 0.0, -5.004, -5.004]}
{"number_of_episodes": 4616, "number_of_timesteps": 66295, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1502, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1503.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1503.0, 1503.0], "q_vals": [0.0, 0.0, -5.094, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"number_of_episodes": 4618, "number_of_timesteps": 66325, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1503, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1504.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1504.0, 1504.0], "q_vals": [0.0, 0.0, -5.091, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"step": 1504, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1505.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1505.0, 1505.0], "q_vals": [0.0, 0.0, -5.09, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"number_of_episodes": 4622, "number_of_timesteps": 66389, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 1505, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1506.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1506.0, 1506.0], "q_vals": [0.0, 0.0, -5.087, 0.0, 0.0, 0.0, 0.0, 0.0, -4.999, -4.999]}
{"number_of_episodes": 4623, "number_of_timesteps": 66402, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1506, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1507.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1507.0, 1507.0], "q_vals": [0.0, 0.0, -5.084, 0.0, 0.0, 0.0, 0.0, 0.0, -4.996, -4.996]}
{"step": 1507, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1508.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1508.0, 1508.0], "q_vals": [0.0, 0.0, -5.08, 0.0, 0.0, 0.0, 0.0, 0.0, -4.995, -4.995]}
{"number_of_episodes": 4629, "number_of_timesteps": 66534, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1508, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1509.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1509.0, 1509.0], "q_vals": [0.0, 0.0, -5.08, 0.0, 0.0, 0.0, 0.0, 0.0, -4.995, -4.995]}
{"number_of_episodes": 4631, "number_of_timesteps": 66568, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1509, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1510.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1510.0, 1510.0], "q_vals": [0.0, 0.0, -5.085, 0.0, 0.0, 0.0, 0.0, 0.0, -4.999, -4.999]}
{"step": 1510, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1511.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1511.0, 1511.0], "q_vals": [0.0, 0.0, -5.091, 0.0, 0.0, 0.0, 0.0, 0.0, -5.004, -5.004]}
{"number_of_episodes": 4635, "number_of_timesteps": 66651, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.15000000000000036},
{"step": 1511, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1512.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1512.0, 1512.0], "q_vals": [0.0, 0.0, -5.088, 0.0, 0.0, 0.0, 0.0, 0.0, -5.0, -5.0]}
{"number_of_episodes": 4638, "number_of_timesteps": 66709, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1512, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1513.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1513.0, 1513.0], "q_vals": [0.0, 0.0, -5.085, 0.0, 0.0, 0.0, 0.0, 0.0, -5.001, -5.001]}
{"number_of_episodes": 4641, "number_of_timesteps": 66798, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
{"step": 1513, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1514.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1514.0, 1514.0], "q_vals": [0.0, 0.0, -5.089, 0.0, 0.0, 0.0, 0.0, 0.0, -5.005, -5.005]}
{"number_of_episodes": 4647, "number_of_timesteps": 66882, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1514, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1515.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1515.0, 1515.0], "q_vals": [0.0, 0.0, -5.086, 0.0, 0.0, 0.0, 0.0, 0.0, -5.002, -5.002]}
{"step": 1515, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1516.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1516.0, 1516.0], "q_vals": [0.0, 0.0, -5.083, 0.0, 0.0, 0.0, 0.0, 0.0, -4.998, -4.998]}
{"number_of_episodes": 4650, "number_of_timesteps": 66919, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1516, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1517.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1517.0, 1517.0], "q_vals": [0.0, 0.0, -5.084, 0.0, 0.0, 0.0, 0.0, 0.0, -4.999, -4.999]}
{"number_of_episodes": 4654, "number_of_timesteps": 66970, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1517, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1518.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1518.0, 1518.0], "q_vals": [0.0, 0.0, -5.088, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"number_of_episodes": 4656, "number_of_timesteps": 67010, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1518, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1519.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1519.0, 1519.0], "q_vals": [0.0, 0.0, -5.087, 0.0, 0.0, 0.0, 0.0, 0.0, -5.001, -5.001]}
{"step": 1519, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1520.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1520.0, 1520.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -5.006, -5.006]}
{"number_of_episodes": 4661, "number_of_timesteps": 67094, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1520, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1521.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1521.0, 1521.0], "q_vals": [0.0, 0.0, -5.089, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"step": 1521, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1522.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1522.0, 1522.0], "q_vals": [0.0, 0.0, -5.095, 0.0, 0.0, 0.0, 0.0, 0.0, -5.007, -5.007]}
{"number_of_episodes": 4664, "number_of_timesteps": 67152, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1522, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1523.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1523.0, 1523.0], "q_vals": [0.0, 0.0, -5.094, 0.0, 0.0, 0.0, 0.0, 0.0, -5.006, -5.006]}
{"number_of_episodes": 4667, "number_of_timesteps": 67210, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"step": 1523, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1524.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1524.0, 1524.0], "q_vals": [0.0, 0.0, -5.091, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"number_of_episodes": 4668, "number_of_timesteps": 67236, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1524, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1525.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1525.0, 1525.0], "q_vals": [0.0, 0.0, -5.091, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"number_of_episodes": 4671, "number_of_timesteps": 67303, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1525, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1526.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1526.0, 1526.0], "q_vals": [0.0, 0.0, -5.099, 0.0, 0.0, 0.0, 0.0, 0.0, -5.009, -5.009]}
{"number_of_episodes": 4674, "number_of_timesteps": 67345, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1526, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1527.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1527.0, 1527.0], "q_vals": [0.0, 0.0, -5.102, 0.0, 0.0, 0.0, 0.0, 0.0, -5.012, -5.012]}
{"number_of_episodes": 4675, "number_of_timesteps": 67355, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1527, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1528.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1528.0, 1528.0], "q_vals": [0.0, 0.0, -5.103, 0.0, 0.0, 0.0, 0.0, 0.0, -5.012, -5.012]}
{"number_of_episodes": 4677, "number_of_timesteps": 67385, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1528, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1529.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1529.0, 1529.0], "q_vals": [0.0, 0.0, -5.1, 0.0, 0.0, 0.0, 0.0, 0.0, -5.009, -5.009]}
{"eval_score": 17.9, "number_of_episodes": 4681}
{"number_of_episodes": 4681, "number_of_timesteps": 67504, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1529, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1530.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1530.0, 1530.0], "q_vals": [0.0, 0.0, -5.105, 0.0, 0.0, 0.0, 0.0, 0.0, -5.013, -5.013]}
{"number_of_episodes": 4681, "number_of_timesteps": 67504, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1530, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1531.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1531.0, 1531.0], "q_vals": [0.0, 0.0, -5.105, 0.0, 0.0, 0.0, 0.0, 0.0, -5.013, -5.013]}
{"number_of_episodes": 4683, "number_of_timesteps": 67556, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1531, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1532.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1532.0, 1532.0], "q_vals": [0.0, 0.0, -5.102, 0.0, 0.0, 0.0, 0.0, 0.0, -5.014, -5.014]}
{"step": 1532, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1533.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1533.0, 1533.0], "q_vals": [0.0, 0.0, -5.106, 0.0, 0.0, 0.0, 0.0, 0.0, -5.017, -5.017]}
{"number_of_episodes": 4690, "number_of_timesteps": 67710, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 1533, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1534.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1534.0, 1534.0], "q_vals": [0.0, 0.0, -5.103, 0.0, 0.0, 0.0, 0.0, 0.0, -5.014, -5.014]}
{"number_of_episodes": 4692, "number_of_timesteps": 67754, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1534, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1535.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1535.0, 1535.0], "q_vals": [0.0, 0.0, -5.107, 0.0, 0.0, 0.0, 0.0, 0.0, -5.017, -5.017]}
{"number_of_episodes": 4694, "number_of_timesteps": 67785, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1535, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1536.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1536.0, 1536.0], "q_vals": [0.0, 0.0, -5.103, 0.0, 0.0, 0.0, 0.0, 0.0, -5.015, -5.015]}
{"number_of_episodes": 4696, "number_of_timesteps": 67806, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"step": 1536, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1537.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1537.0, 1537.0], "q_vals": [0.0, 0.0, -5.104, 0.0, 0.0, 0.0, 0.0, 0.0, -5.015, -5.015]}
{"step": 1537, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1538.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1538.0, 1538.0], "q_vals": [0.0, 0.0, -5.1, 0.0, 0.0, 0.0, 0.0, 0.0, -5.014, -5.014]}
{"step": 1538, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1539.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1539.0, 1539.0], "q_vals": [0.0, 0.0, -5.097, 0.0, 0.0, 0.0, 0.0, 0.0, -5.015, -5.015]}
{"step": 1539, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1540.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1540.0, 1540.0], "q_vals": [0.0, 0.0, -5.094, 0.0, 0.0, 0.0, 0.0, 0.0, -5.015, -5.015]}
{"number_of_episodes": 4701, "number_of_timesteps": 67913, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1540, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1541.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1541.0, 1541.0], "q_vals": [0.0, 0.0, -5.094, 0.0, 0.0, 0.0, 0.0, 0.0, -5.015, -5.015]}
{"number_of_episodes": 4706, "number_of_timesteps": 68010, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
{"step": 1541, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1542.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1542.0, 1542.0], "q_vals": [0.0, 0.0, -5.098, 0.0, 0.0, 0.0, 0.0, 0.0, -5.018, -5.018]}
{"step": 1542, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1543.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1543.0, 1543.0], "q_vals": [0.0, 0.0, -5.098, 0.0, 0.0, 0.0, 0.0, 0.0, -5.018, -5.018]}
{"number_of_episodes": 4707, "number_of_timesteps": 68027, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"step": 1543, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1544.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1544.0, 1544.0], "q_vals": [0.0, 0.0, -5.095, 0.0, 0.0, 0.0, 0.0, 0.0, -5.015, -5.015]}
{"number_of_episodes": 4710, "number_of_timesteps": 68153, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1544, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1545.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1545.0, 1545.0], "q_vals": [0.0, 0.0, -5.095, 0.0, 0.0, 0.0, 0.0, 0.0, -5.015, -5.015]}
{"step": 1545, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1546.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1546.0, 1546.0], "q_vals": [0.0, 0.0, -5.099, 0.0, 0.0, 0.0, 0.0, 0.0, -5.018, -5.018]}
{"step": 1546, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1547.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1547.0, 1547.0], "q_vals": [0.0, 0.0, -5.099, 0.0, 0.0, 0.0, 0.0, 0.0, -5.017, -5.017]}
{"step": 1547, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1548.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1548.0, 1548.0], "q_vals": [0.0, 0.0, -5.098, 0.0, 0.0, 0.0, 0.0, 0.0, -5.017, -5.017]}
{"number_of_episodes": 4719, "number_of_timesteps": 68340, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1548, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1549.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1549.0, 1549.0], "q_vals": [0.0, 0.0, -5.1, 0.0, 0.0, 0.0, 0.0, 0.0, -5.018, -5.018]}
{"number_of_episodes": 4723, "number_of_timesteps": 68419, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1549, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1550.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1550.0, 1550.0], "q_vals": [0.0, 0.0, -5.106, 0.0, 0.0, 0.0, 0.0, 0.0, -5.023, -5.023]}
{"number_of_episodes": 4725, "number_of_timesteps": 68447, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1550, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1551.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1551.0, 1551.0], "q_vals": [0.0, 0.0, -5.106, 0.0, 0.0, 0.0, 0.0, 0.0, -5.022, -5.022]}
{"step": 1551, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1552.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1552.0, 1552.0], "q_vals": [0.0, 0.0, -5.113, 0.0, 0.0, 0.0, 0.0, 0.0, -5.028, -5.028]}
{"number_of_episodes": 4731, "number_of_timesteps": 68577, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"step": 1552, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1553.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1553.0, 1553.0], "q_vals": [0.0, 0.0, -5.109, 0.0, 0.0, 0.0, 0.0, 0.0, -5.025, -5.025]}
{"number_of_episodes": 4733, "number_of_timesteps": 68603, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.15000000000000036},
{"step": 1553, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1554.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1554.0, 1554.0], "q_vals": [0.0, 0.0, -5.106, 0.0, 0.0, 0.0, 0.0, 0.0, -5.021, -5.021]}
{"number_of_episodes": 4733, "number_of_timesteps": 68603, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1554, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1555.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1555.0, 1555.0], "q_vals": [0.0, 0.0, -5.106, 0.0, 0.0, 0.0, 0.0, 0.0, -5.021, -5.021]}
{"step": 1555, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1556.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1556.0, 1556.0], "q_vals": [0.0, 0.0, -5.103, 0.0, 0.0, 0.0, 0.0, 0.0, -5.018, -5.018]}
{"number_of_episodes": 4739, "number_of_timesteps": 68719, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1556, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1557.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1557.0, 1557.0], "q_vals": [0.0, 0.0, -5.102, 0.0, 0.0, 0.0, 0.0, 0.0, -5.017, -5.017]}
{"number_of_episodes": 4741, "number_of_timesteps": 68758, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"step": 1557, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1558.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1558.0, 1558.0], "q_vals": [0.0, 0.0, -5.099, 0.0, 0.0, 0.0, 0.0, 0.0, -5.014, -5.014]}
{"number_of_episodes": 4742, "number_of_timesteps": 68809, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1558, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1559.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1559.0, 1559.0], "q_vals": [0.0, 0.0, -5.104, 0.0, 0.0, 0.0, 0.0, 0.0, -5.018, -5.018]}
{"number_of_episodes": 4743, "number_of_timesteps": 68822, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1559, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1560.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1560.0, 1560.0], "q_vals": [0.0, 0.0, -5.103, 0.0, 0.0, 0.0, 0.0, 0.0, -5.017, -5.017]}
{"step": 1560, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1561.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1561.0, 1561.0], "q_vals": [0.0, 0.0, -5.104, 0.0, 0.0, 0.0, 0.0, 0.0, -5.017, -5.017]}
{"step": 1561, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1562.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1562.0, 1562.0], "q_vals": [0.0, 0.0, -5.102, 0.0, 0.0, 0.0, 0.0, 0.0, -5.015, -5.015]}
{"step": 1562, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1563.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1563.0, 1563.0], "q_vals": [0.0, 0.0, -5.102, 0.0, 0.0, 0.0, 0.0, 0.0, -5.014, -5.014]}
{"number_of_episodes": 4750, "number_of_timesteps": 68960, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1563, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1564.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1564.0, 1564.0], "q_vals": [0.0, 0.0, -5.098, 0.0, 0.0, 0.0, 0.0, 0.0, -5.014, -5.014]}
{"step": 1564, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1565.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1565.0, 1565.0], "q_vals": [0.0, 0.0, -5.095, 0.0, 0.0, 0.0, 0.0, 0.0, -5.014, -5.014]}
{"number_of_episodes": 4757, "number_of_timesteps": 69163, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1565, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1566.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1566.0, 1566.0], "q_vals": [0.0, 0.0, -5.096, 0.0, 0.0, 0.0, 0.0, 0.0, -5.014, -5.014]}
{"number_of_episodes": 4759, "number_of_timesteps": 69222, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 1566, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1567.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1567.0, 1567.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -5.011, -5.011]}
{"number_of_episodes": 4762, "number_of_timesteps": 69261, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1567, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1568.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1568.0, 1568.0], "q_vals": [0.0, 0.0, -5.096, 0.0, 0.0, 0.0, 0.0, 0.0, -5.014, -5.014]}
{"step": 1568, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1569.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1569.0, 1569.0], "q_vals": [0.0, 0.0, -5.104, 0.0, 0.0, 0.0, 0.0, 0.0, -5.021, -5.021]}
{"number_of_episodes": 4768, "number_of_timesteps": 69362, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
{"step": 1569, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1570.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1570.0, 1570.0], "q_vals": [0.0, 0.0, -5.101, 0.0, 0.0, 0.0, 0.0, 0.0, -5.018, -5.018]}
{"number_of_episodes": 4770, "number_of_timesteps": 69384, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 1570, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1571.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1571.0, 1571.0], "q_vals": [0.0, 0.0, -5.098, 0.0, 0.0, 0.0, 0.0, 0.0, -5.014, -5.014]}
{"number_of_episodes": 4772, "number_of_timesteps": 69410, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1571, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1572.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1572.0, 1572.0], "q_vals": [0.0, 0.0, -5.098, 0.0, 0.0, 0.0, 0.0, 0.0, -5.014, -5.014]}
{"number_of_episodes": 4776, "number_of_timesteps": 69492, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1572, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1573.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1573.0, 1573.0], "q_vals": [0.0, 0.0, -5.097, 0.0, 0.0, 0.0, 0.0, 0.0, -5.013, -5.013]}
{"step": 1573, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1574.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1574.0, 1574.0], "q_vals": [0.0, 0.0, -5.094, 0.0, 0.0, 0.0, 0.0, 0.0, -5.01, -5.01]}
{"number_of_episodes": 4779, "number_of_timesteps": 69541, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1574, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1575.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1575.0, 1575.0], "q_vals": [0.0, 0.0, -5.09, 0.0, 0.0, 0.0, 0.0, 0.0, -5.007, -5.007]}
{"number_of_episodes": 4779, "number_of_timesteps": 69541, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1575, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1576.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1576.0, 1576.0], "q_vals": [0.0, 0.0, -5.09, 0.0, 0.0, 0.0, 0.0, 0.0, -5.006, -5.006]}
{"number_of_episodes": 4785, "number_of_timesteps": 69674, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1576, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1577.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1577.0, 1577.0], "q_vals": [0.0, 0.0, -5.094, 0.0, 0.0, 0.0, 0.0, 0.0, -5.009, -5.009]}
{"number_of_episodes": 4786, "number_of_timesteps": 69686, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 1577, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1578.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1578.0, 1578.0], "q_vals": [0.0, 0.0, -5.091, 0.0, 0.0, 0.0, 0.0, 0.0, -5.006, -5.006]}
{"number_of_episodes": 4787, "number_of_timesteps": 69695, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1578, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1579.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1579.0, 1579.0], "q_vals": [0.0, 0.0, -5.091, 0.0, 0.0, 0.0, 0.0, 0.0, -5.006, -5.006]}
{"step": 1579, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1580.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1580.0, 1580.0], "q_vals": [0.0, 0.0, -5.088, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"number_of_episodes": 4794, "number_of_timesteps": 69859, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1580, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1581.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1581.0, 1581.0], "q_vals": [0.0, 0.0, -5.087, 0.0, 0.0, 0.0, 0.0, 0.0, -5.002, -5.002]}
{"number_of_episodes": 4796, "number_of_timesteps": 69908, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1581, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1582.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1582.0, 1582.0], "q_vals": [0.0, 0.0, -5.084, 0.0, 0.0, 0.0, 0.0, 0.0, -4.999, -4.999]}
{"number_of_episodes": 4797, "number_of_timesteps": 69917, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 1582, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1583.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1583.0, 1583.0], "q_vals": [0.0, 0.0, -5.081, 0.0, 0.0, 0.0, 0.0, 0.0, -4.996, -4.996]}
{"number_of_episodes": 4800, "number_of_timesteps": 69965, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1583, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1584.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1584.0, 1584.0], "q_vals": [0.0, 0.0, -5.081, 0.0, 0.0, 0.0, 0.0, 0.0, -4.995, -4.995]}
{"number_of_episodes": 4804, "number_of_timesteps": 70030, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1584, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1585.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1585.0, 1585.0], "q_vals": [0.0, 0.0, -5.086, 0.0, 0.0, 0.0, 0.0, 0.0, -5.0, -5.0]}
{"number_of_episodes": 4805, "number_of_timesteps": 70056, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1585, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1586.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1586.0, 1586.0], "q_vals": [0.0, 0.0, -5.092, 0.0, 0.0, 0.0, 0.0, 0.0, -5.004, -5.004]}
{"step": 1586, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1587.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1587.0, 1587.0], "q_vals": [0.0, 0.0, -5.1, 0.0, 0.0, 0.0, 0.0, 0.0, -5.011, -5.011]}
{"number_of_episodes": 4809, "number_of_timesteps": 70111, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1587, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1588.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1588.0, 1588.0], "q_vals": [0.0, 0.0, -5.096, 0.0, 0.0, 0.0, 0.0, 0.0, -5.01, -5.01]}
{"eval_score": 14.6, "number_of_episodes": 4814}
{"number_of_episodes": 4814, "number_of_timesteps": 70203, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 1588, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1589.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1589.0, 1589.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -5.007, -5.007]}
{"number_of_episodes": 4816, "number_of_timesteps": 70254, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1589, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1590.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1590.0, 1590.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -5.006, -5.006]}
{"number_of_episodes": 4818, "number_of_timesteps": 70276, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1590, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1591.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1591.0, 1591.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -5.006, -5.006]}
{"number_of_episodes": 4820, "number_of_timesteps": 70305, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1591, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1592.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1592.0, 1592.0], "q_vals": [0.0, 0.0, -5.096, 0.0, 0.0, 0.0, 0.0, 0.0, -5.009, -5.009]}
{"number_of_episodes": 4822, "number_of_timesteps": 70338, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1592, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1593.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1593.0, 1593.0], "q_vals": [0.0, 0.0, -5.101, 0.0, 0.0, 0.0, 0.0, 0.0, -5.012, -5.012]}
{"number_of_episodes": 4823, "number_of_timesteps": 70354, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1593, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1594.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1594.0, 1594.0], "q_vals": [0.0, 0.0, -5.097, 0.0, 0.0, 0.0, 0.0, 0.0, -5.009, -5.009]}
{"number_of_episodes": 4828, "number_of_timesteps": 70458, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1594, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1595.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1595.0, 1595.0], "q_vals": [0.0, 0.0, -5.094, 0.0, 0.0, 0.0, 0.0, 0.0, -5.006, -5.006]}
{"step": 1595, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1596.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1596.0, 1596.0], "q_vals": [0.0, 0.0, -5.091, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"number_of_episodes": 4832, "number_of_timesteps": 70522, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1596, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1597.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1597.0, 1597.0], "q_vals": [0.0, 0.0, -5.092, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"number_of_episodes": 4834, "number_of_timesteps": 70553, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
{"step": 1597, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1598.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1598.0, 1598.0], "q_vals": [0.0, 0.0, -5.089, 0.0, 0.0, 0.0, 0.0, 0.0, -5.0, -5.0]}
{"step": 1598, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1599.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1599.0, 1599.0], "q_vals": [0.0, 0.0, -5.092, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"number_of_episodes": 4838, "number_of_timesteps": 70622, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 1599, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1600.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1600.0, 1600.0], "q_vals": [0.0, 0.0, -5.092, 0.0, 0.0, 0.0, 0.0, 0.0, -5.002, -5.002]}
{"number_of_episodes": 4840, "number_of_timesteps": 70710, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1600, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1601.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1601.0, 1601.0], "q_vals": [0.0, 0.0, -5.096, 0.0, 0.0, 0.0, 0.0, 0.0, -5.006, -5.006]}
{"number_of_episodes": 4842, "number_of_timesteps": 70744, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1601, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1602.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1602.0, 1602.0], "q_vals": [0.0, 0.0, -5.093, 0.0, 0.0, 0.0, 0.0, 0.0, -5.006, -5.006]}
{"number_of_episodes": 4845, "number_of_timesteps": 70820, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1602, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1603.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1603.0, 1603.0], "q_vals": [0.0, 0.0, -5.091, 0.0, 0.0, 0.0, 0.0, 0.0, -5.004, -5.004]}
{"step": 1603, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1604.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1604.0, 1604.0], "q_vals": [0.0, 0.0, -5.091, 0.0, 0.0, 0.0, 0.0, 0.0, -5.003, -5.003]}
{"number_of_episodes": 4849, "number_of_timesteps": 70909, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 1604, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1605.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1605.0, 1605.0], "q_vals": [0.0, 0.0, -5.09, 0.0, 0.0, 0.0, 0.0, 0.0, -5.002, -5.002]}
{"step": 1605, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1606.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1606.0, 1606.0], "q_vals": [0.0, 0.0, -5.089, 0.0, 0.0, 0.0, 0.0, 0.0, -5.001, -5.001]}
{"number_of_episodes": 4854, "number_of_timesteps": 70990, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1606, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1607.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1607.0, 1607.0], "q_vals": [0.0, 0.0, -5.086, 0.0, 0.0, 0.0, 0.0, 0.0, -4.998, -4.998]}
{"number_of_episodes": 4857, "number_of_timesteps": 71039, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1607, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1608.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1608.0, 1608.0], "q_vals": [0.0, 0.0, -5.083, 0.0, 0.0, 0.0, 0.0, 0.0, -4.997, -4.997]}
{"number_of_episodes": 4860, "number_of_timesteps": 71108, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1608, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1609.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1609.0, 1609.0], "q_vals": [0.0, 0.0, -5.083, 0.0, 0.0, 0.0, 0.0, 0.0, -4.996, -4.996]}
{"number_of_episodes": 4860, "number_of_timesteps": 71108, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1609, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1610.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1610.0, 1610.0], "q_vals": [0.0, 0.0, -5.079, 0.0, 0.0, 0.0, 0.0, 0.0, -4.993, -4.993]}
{"number_of_episodes": 4863, "number_of_timesteps": 71170, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1610, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1611.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1611.0, 1611.0], "q_vals": [0.0, 0.0, -5.083, 0.0, 0.0, 0.0, 0.0, 0.0, -4.996, -4.996]}
{"step": 1611, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1612.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1612.0, 1612.0], "q_vals": [0.0, 0.0, -5.09, 0.0, 0.0, 0.0, 0.0, 0.0, -5.002, -5.002]}
{"number_of_episodes": 4866, "number_of_timesteps": 71224, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1612, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1613.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1613.0, 1613.0], "q_vals": [0.0, 0.0, -5.09, 0.0, 0.0, 0.0, 0.0, 0.0, -5.002, -5.002]}
{"number_of_episodes": 4867, "number_of_timesteps": 71237, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1613, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1614.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1614.0, 1614.0], "q_vals": [0.0, 0.0, -5.087, 0.0, 0.0, 0.0, 0.0, 0.0, -4.999, -4.999]}
{"number_of_episodes": 4872, "number_of_timesteps": 71349, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1614, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1615.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1615.0, 1615.0], "q_vals": [0.0, 0.0, -5.088, 0.0, 0.0, 0.0, 0.0, 0.0, -4.999, -4.999]}
{"step": 1615, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1616.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1616.0, 1616.0], "q_vals": [0.0, 0.0, -5.085, 0.0, 0.0, 0.0, 0.0, 0.0, -4.996, -4.996]}
{"step": 1616, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1617.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1617.0, 1617.0], "q_vals": [0.0, 0.0, -5.085, 0.0, 0.0, 0.0, 0.0, 0.0, -4.996, -4.996]}
{"number_of_episodes": 4875, "number_of_timesteps": 71424, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1617, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1618.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1618.0, 1618.0], "q_vals": [0.0, 0.0, -5.081, 0.0, 0.0, 0.0, 0.0, 0.0, -4.993, -4.993]}
{"number_of_episodes": 4878, "number_of_timesteps": 71468, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1618, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1619.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1619.0, 1619.0], "q_vals": [0.0, 0.0, -5.085, 0.0, 0.0, 0.0, 0.0, 0.0, -4.995, -4.995]}
{"number_of_episodes": 4881, "number_of_timesteps": 71570, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1619, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1620.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1620.0, 1620.0], "q_vals": [0.0, 0.0, -5.086, 0.0, 0.0, 0.0, 0.0, 0.0, -4.996, -4.996]}
{"number_of_episodes": 4883, "number_of_timesteps": 71632, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1620, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1621.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1621.0, 1621.0], "q_vals": [0.0, 0.0, -5.086, 0.0, 0.0, 0.0, 0.0, 0.0, -4.995, -4.995]}
{"step": 1621, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1622.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1622.0, 1622.0], "q_vals": [0.0, 0.0, -5.083, 0.0, 0.0, 0.0, 0.0, 0.0, -4.992, -4.992]}
{"number_of_episodes": 4888, "number_of_timesteps": 71727, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1622, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1623.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1623.0, 1623.0], "q_vals": [0.0, 0.0, -5.079, 0.0, 0.0, 0.0, 0.0, 0.0, -4.989, -4.989]}
{"number_of_episodes": 4890, "number_of_timesteps": 71769, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 1623, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1624.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1624.0, 1624.0], "q_vals": [0.0, 0.0, -5.078, 0.0, 0.0, 0.0, 0.0, 0.0, -4.987, -4.987]}
{"number_of_episodes": 4894, "number_of_timesteps": 71819, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1624, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1625.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1625.0, 1625.0], "q_vals": [0.0, 0.0, -5.077, 0.0, 0.0, 0.0, 0.0, 0.0, -4.986, -4.986]}
{"number_of_episodes": 4894, "number_of_timesteps": 71819, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1625, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1626.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1626.0, 1626.0], "q_vals": [0.0, 0.0, -5.075, 0.0, 0.0, 0.0, 0.0, 0.0, -4.984, -4.984]}
{"number_of_episodes": 4896, "number_of_timesteps": 71858, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1626, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1627.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1627.0, 1627.0], "q_vals": [0.0, 0.0, -5.072, 0.0, 0.0, 0.0, 0.0, 0.0, -4.981, -4.981]}
{"step": 1627, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1628.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1628.0, 1628.0], "q_vals": [0.0, 0.0, -5.071, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"number_of_episodes": 4901, "number_of_timesteps": 71969, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1628, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1629.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1629.0, 1629.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.977, -4.977]}
{"step": 1629, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1630.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1630.0, 1630.0], "q_vals": [0.0, 0.0, -5.065, 0.0, 0.0, 0.0, 0.0, 0.0, -4.974, -4.974]}
{"step": 1630, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1631.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1631.0, 1631.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.971, -4.971]}
{"number_of_episodes": 4909, "number_of_timesteps": 72103, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1631, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1632.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1632.0, 1632.0], "q_vals": [0.0, 0.0, -5.061, 0.0, 0.0, 0.0, 0.0, 0.0, -4.97, -4.97]}
{"number_of_episodes": 4910, "number_of_timesteps": 72150, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1632, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1633.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1633.0, 1633.0], "q_vals": [0.0, 0.0, -5.061, 0.0, 0.0, 0.0, 0.0, 0.0, -4.97, -4.97]}
{"number_of_episodes": 4911, "number_of_timesteps": 72162, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1633, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1634.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1634.0, 1634.0], "q_vals": [0.0, 0.0, -5.058, 0.0, 0.0, 0.0, 0.0, 0.0, -4.967, -4.967]}
{"number_of_episodes": 4915, "number_of_timesteps": 72224, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1634, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1635.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1635.0, 1635.0], "q_vals": [0.0, 0.0, -5.055, 0.0, 0.0, 0.0, 0.0, 0.0, -4.966, -4.966]}
{"number_of_episodes": 4916, "number_of_timesteps": 72249, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1635, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1636.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1636.0, 1636.0], "q_vals": [0.0, 0.0, -5.059, 0.0, 0.0, 0.0, 0.0, 0.0, -4.97, -4.97]}
{"step": 1636, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1637.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1637.0, 1637.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.977, -4.977]}
{"number_of_episodes": 4918, "number_of_timesteps": 72344, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1637, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1638.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1638.0, 1638.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.976, -4.976]}
{"number_of_episodes": 4923, "number_of_timesteps": 72457, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1638, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1639.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1639.0, 1639.0], "q_vals": [0.0, 0.0, -5.064, 0.0, 0.0, 0.0, 0.0, 0.0, -4.973, -4.973]}
{"number_of_episodes": 4923, "number_of_timesteps": 72457, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1639, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1640.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1640.0, 1640.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.976, -4.976]}
{"step": 1640, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1641.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1641.0, 1641.0], "q_vals": [0.0, 0.0, -5.072, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"number_of_episodes": 4928, "number_of_timesteps": 72552, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1641, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1642.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1642.0, 1642.0], "q_vals": [0.0, 0.0, -5.073, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"number_of_episodes": 4930, "number_of_timesteps": 72611, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1642, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1643.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1643.0, 1643.0], "q_vals": [0.0, 0.0, -5.076, 0.0, 0.0, 0.0, 0.0, 0.0, -4.983, -4.983]}
{"step": 1643, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1644.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1644.0, 1644.0], "q_vals": [0.0, 0.0, -5.073, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"step": 1644, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1645.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1645.0, 1645.0], "q_vals": [0.0, 0.0, -5.074, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"number_of_episodes": 4936, "number_of_timesteps": 72735, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1645, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1646.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1646.0, 1646.0], "q_vals": [0.0, 0.0, -5.08, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"number_of_episodes": 4936, "number_of_timesteps": 72735, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1646, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1647.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1647.0, 1647.0], "q_vals": [0.0, 0.0, -5.077, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"number_of_episodes": 4936, "number_of_timesteps": 72735, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1647, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1648.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1648.0, 1648.0], "q_vals": [0.0, 0.0, -5.077, 0.0, 0.0, 0.0, 0.0, 0.0, -4.985, -4.985]}
{"step": 1648, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1649.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1649.0, 1649.0], "q_vals": [0.0, 0.0, -5.074, 0.0, 0.0, 0.0, 0.0, 0.0, -4.984, -4.984]}
{"eval_score": 21.1, "number_of_episodes": 4944}
{"number_of_episodes": 4944, "number_of_timesteps": 72945, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1649, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1650.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1650.0, 1650.0], "q_vals": [0.0, 0.0, -5.071, 0.0, 0.0, 0.0, 0.0, 0.0, -4.981, -4.981]}
{"step": 1650, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1651.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1651.0, 1651.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"number_of_episodes": 4947, "number_of_timesteps": 72995, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1651, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1652.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1652.0, 1652.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"number_of_episodes": 4951, "number_of_timesteps": 73043, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1652, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1653.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1653.0, 1653.0], "q_vals": [0.0, 0.0, -5.072, 0.0, 0.0, 0.0, 0.0, 0.0, -4.983, -4.983]}
{"number_of_episodes": 4953, "number_of_timesteps": 73115, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1653, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1654.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1654.0, 1654.0], "q_vals": [0.0, 0.0, -5.071, 0.0, 0.0, 0.0, 0.0, 0.0, -4.982, -4.982]}
{"number_of_episodes": 4957, "number_of_timesteps": 73191, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1654, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1655.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1655.0, 1655.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"number_of_episodes": 4960, "number_of_timesteps": 73237, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1655, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1656.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1656.0, 1656.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"number_of_episodes": 4963, "number_of_timesteps": 73270, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1656, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1657.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1657.0, 1657.0], "q_vals": [0.0, 0.0, -5.065, 0.0, 0.0, 0.0, 0.0, 0.0, -4.976, -4.976]}
{"number_of_episodes": 4964, "number_of_timesteps": 73283, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1657, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1658.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1658.0, 1658.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.973, -4.973]}
{"step": 1658, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1659.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1659.0, 1659.0], "q_vals": [0.0, 0.0, -5.059, 0.0, 0.0, 0.0, 0.0, 0.0, -4.97, -4.97]}
{"number_of_episodes": 4970, "number_of_timesteps": 73367, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1659, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1660.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1660.0, 1660.0], "q_vals": [0.0, 0.0, -5.056, 0.0, 0.0, 0.0, 0.0, 0.0, -4.969, -4.969]}
{"number_of_episodes": 4973, "number_of_timesteps": 73431, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1660, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1661.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1661.0, 1661.0], "q_vals": [0.0, 0.0, -5.06, 0.0, 0.0, 0.0, 0.0, 0.0, -4.973, -4.973]}
{"number_of_episodes": 4975, "number_of_timesteps": 73454, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1661, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1662.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1662.0, 1662.0], "q_vals": [0.0, 0.0, -5.061, 0.0, 0.0, 0.0, 0.0, 0.0, -4.973, -4.973]}
{"number_of_episodes": 4976, "number_of_timesteps": 73500, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1662, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1663.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1663.0, 1663.0], "q_vals": [0.0, 0.0, -5.061, 0.0, 0.0, 0.0, 0.0, 0.0, -4.973, -4.973]}
{"number_of_episodes": 4980, "number_of_timesteps": 73556, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1663, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1664.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1664.0, 1664.0], "q_vals": [0.0, 0.0, -5.058, 0.0, 0.0, 0.0, 0.0, 0.0, -4.97, -4.97]}
{"step": 1664, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1665.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1665.0, 1665.0], "q_vals": [0.0, 0.0, -5.061, 0.0, 0.0, 0.0, 0.0, 0.0, -4.973, -4.973]}
{"number_of_episodes": 4983, "number_of_timesteps": 73617, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1665, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1666.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1666.0, 1666.0], "q_vals": [0.0, 0.0, -5.061, 0.0, 0.0, 0.0, 0.0, 0.0, -4.972, -4.972]}
{"step": 1666, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1667.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1667.0, 1667.0], "q_vals": [0.0, 0.0, -5.058, 0.0, 0.0, 0.0, 0.0, 0.0, -4.969, -4.969]}
{"step": 1667, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1668.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1668.0, 1668.0], "q_vals": [0.0, 0.0, -5.058, 0.0, 0.0, 0.0, 0.0, 0.0, -4.968, -4.968]}
{"number_of_episodes": 4989, "number_of_timesteps": 73746, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1668, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1669.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1669.0, 1669.0], "q_vals": [0.0, 0.0, -5.065, 0.0, 0.0, 0.0, 0.0, 0.0, -4.974, -4.974]}
{"number_of_episodes": 4990, "number_of_timesteps": 73772, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1669, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1670.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1670.0, 1670.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.971, -4.971]}
{"step": 1670, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1671.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1671.0, 1671.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.977, -4.977]}
{"number_of_episodes": 4993, "number_of_timesteps": 73818, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1671, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1672.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1672.0, 1672.0], "q_vals": [0.0, 0.0, -5.069, 0.0, 0.0, 0.0, 0.0, 0.0, -4.977, -4.977]}
{"number_of_episodes": 4996, "number_of_timesteps": 73896, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1672, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1673.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1673.0, 1673.0], "q_vals": [0.0, 0.0, -5.066, 0.0, 0.0, 0.0, 0.0, 0.0, -4.974, -4.974]}
{"step": 1673, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1674.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1674.0, 1674.0], "q_vals": [0.0, 0.0, -5.069, 0.0, 0.0, 0.0, 0.0, 0.0, -4.977, -4.977]}
{"step": 1674, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1675.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1675.0, 1675.0], "q_vals": [0.0, 0.0, -5.07, 0.0, 0.0, 0.0, 0.0, 0.0, -4.977, -4.977]}
{"number_of_episodes": 5001, "number_of_timesteps": 74068, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1675, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1676.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1676.0, 1676.0], "q_vals": [0.0, 0.0, -5.074, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"step": 1676, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1677.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1677.0, 1677.0], "q_vals": [0.0, 0.0, -5.077, 0.0, 0.0, 0.0, 0.0, 0.0, -4.983, -4.983]}
{"number_of_episodes": 5005, "number_of_timesteps": 74175, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1677, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1678.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1678.0, 1678.0], "q_vals": [0.0, 0.0, -5.074, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"number_of_episodes": 5008, "number_of_timesteps": 74249, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1678, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1679.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1679.0, 1679.0], "q_vals": [0.0, 0.0, -5.073, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"number_of_episodes": 5008, "number_of_timesteps": 74249, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1679, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1680.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1680.0, 1680.0], "q_vals": [0.0, 0.0, -5.074, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"number_of_episodes": 5008, "number_of_timesteps": 74249, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1680, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1681.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1681.0, 1681.0], "q_vals": [0.0, 0.0, -5.071, 0.0, 0.0, 0.0, 0.0, 0.0, -4.977, -4.977]}
{"step": 1681, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1682.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1682.0, 1682.0], "q_vals": [0.0, 0.0, -5.068, 0.0, 0.0, 0.0, 0.0, 0.0, -4.976, -4.976]}
{"step": 1682, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1683.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1683.0, 1683.0], "q_vals": [0.0, 0.0, -5.067, 0.0, 0.0, 0.0, 0.0, 0.0, -4.976, -4.976]}
{"step": 1683, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1684.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1684.0, 1684.0], "q_vals": [0.0, 0.0, -5.064, 0.0, 0.0, 0.0, 0.0, 0.0, -4.976, -4.976]}
{"number_of_episodes": 5018, "number_of_timesteps": 74477, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1684, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1685.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1685.0, 1685.0], "q_vals": [0.0, 0.0, -5.07, 0.0, 0.0, 0.0, 0.0, 0.0, -4.981, -4.981]}
{"number_of_episodes": 5020, "number_of_timesteps": 74526, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1685, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1686.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1686.0, 1686.0], "q_vals": [0.0, 0.0, -5.074, 0.0, 0.0, 0.0, 0.0, 0.0, -4.984, -4.984]}
{"number_of_episodes": 5024, "number_of_timesteps": 74627, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1686, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1687.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1687.0, 1687.0], "q_vals": [0.0, 0.0, -5.071, 0.0, 0.0, 0.0, 0.0, 0.0, -4.982, -4.982]}
{"number_of_episodes": 5025, "number_of_timesteps": 74635, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1687, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1688.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1688.0, 1688.0], "q_vals": [0.0, 0.0, -5.071, 0.0, 0.0, 0.0, 0.0, 0.0, -4.981, -4.981]}
{"number_of_episodes": 5027, "number_of_timesteps": 74685, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1688, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1689.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1689.0, 1689.0], "q_vals": [0.0, 0.0, -5.071, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"step": 1689, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1690.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1690.0, 1690.0], "q_vals": [0.0, 0.0, -5.071, 0.0, 0.0, 0.0, 0.0, 0.0, -4.98, -4.98]}
{"number_of_episodes": 5031, "number_of_timesteps": 74755, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1690, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1691.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1691.0, 1691.0], "q_vals": [0.0, 0.0, -5.07, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"step": 1691, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1692.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1692.0, 1692.0], "q_vals": [0.0, 0.0, -5.07, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"number_of_episodes": 5035, "number_of_timesteps": 74853, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1692, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1693.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1693.0, 1693.0], "q_vals": [0.0, 0.0, -5.067, 0.0, 0.0, 0.0, 0.0, 0.0, -4.978, -4.978]}
{"step": 1693, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1694.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1694.0, 1694.0], "q_vals": [0.0, 0.0, -5.064, 0.0, 0.0, 0.0, 0.0, 0.0, -4.978, -4.978]}
{"number_of_episodes": 5038, "number_of_timesteps": 74923, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1694, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1695.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1695.0, 1695.0], "q_vals": [0.0, 0.0, -5.064, 0.0, 0.0, 0.0, 0.0, 0.0, -4.977, -4.977]}
{"step": 1695, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1696.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1696.0, 1696.0], "q_vals": [0.0, 0.0, -5.065, 0.0, 0.0, 0.0, 0.0, 0.0, -4.979, -4.979]}
{"number_of_episodes": 5040, "number_of_timesteps": 74991, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1696, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1697.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1697.0, 1697.0], "q_vals": [0.0, 0.0, -5.062, 0.0, 0.0, 0.0, 0.0, 0.0, -4.976, -4.976]}
{"number_of_episodes": 5044, "number_of_timesteps": 75079, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1697, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1698.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1698.0, 1698.0], "q_vals": [0.0, 0.0, -5.059, 0.0, 0.0, 0.0, 0.0, 0.0, -4.973, -4.973]}
{"number_of_episodes": 5046, "number_of_timesteps": 75149, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1698, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1699.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1699.0, 1699.0], "q_vals": [0.0, 0.0, -5.056, 0.0, 0.0, 0.0, 0.0, 0.0, -4.972, -4.972]}
{"step": 1699, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1700.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1700.0, 1700.0], "q_vals": [0.0, 0.0, -5.056, 0.0, 0.0, 0.0, 0.0, 0.0, -4.972, -4.972]}
{"step": 1700, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1701.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1701.0, 1701.0], "q_vals": [0.0, 0.0, -5.053, 0.0, 0.0, 0.0, 0.0, 0.0, -4.969, -4.969]}
{"step": 1701, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1702.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1702.0, 1702.0], "q_vals": [0.0, 0.0, -5.05, 0.0, 0.0, 0.0, 0.0, 0.0, -4.967, -4.967]}
{"step": 1702, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1703.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1703.0, 1703.0], "q_vals": [0.0, 0.0, -5.047, 0.0, 0.0, 0.0, 0.0, 0.0, -4.964, -4.964]}
{"number_of_episodes": 5054, "number_of_timesteps": 75333, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1703, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1704.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1704.0, 1704.0], "q_vals": [0.0, 0.0, -5.051, 0.0, 0.0, 0.0, 0.0, 0.0, -4.967, -4.967]}
{"number_of_episodes": 5058, "number_of_timesteps": 75415, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1704, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1705.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1705.0, 1705.0], "q_vals": [0.0, 0.0, -5.048, 0.0, 0.0, 0.0, 0.0, 0.0, -4.964, -4.964]}
{"number_of_episodes": 5059, "number_of_timesteps": 75459, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1705, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1706.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1706.0, 1706.0], "q_vals": [0.0, 0.0, -5.047, 0.0, 0.0, 0.0, 0.0, 0.0, -4.963, -4.963]}
{"number_of_episodes": 5061, "number_of_timesteps": 75506, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1706, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1707.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1707.0, 1707.0], "q_vals": [0.0, 0.0, -5.048, 0.0, 0.0, 0.0, 0.0, 0.0, -4.963, -4.963]}
{"number_of_episodes": 5062, "number_of_timesteps": 75521, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1707, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1708.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1708.0, 1708.0], "q_vals": [0.0, 0.0, -5.045, 0.0, 0.0, 0.0, 0.0, 0.0, -4.96, -4.96]}
{"step": 1708, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1709.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1709.0, 1709.0], "q_vals": [0.0, 0.0, -5.044, 0.0, 0.0, 0.0, 0.0, 0.0, -4.959, -4.959]}
{"number_of_episodes": 5066, "number_of_timesteps": 75627, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1709, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1710.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1710.0, 1710.0], "q_vals": [0.0, 0.0, -5.041, 0.0, 0.0, 0.0, 0.0, 0.0, -4.959, -4.959]}
{"eval_score": 20.9, "number_of_episodes": 5070}
{"number_of_episodes": 5070, "number_of_timesteps": 75684, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1710, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1711.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1711.0, 1711.0], "q_vals": [0.0, 0.0, -5.044, 0.0, 0.0, 0.0, 0.0, 0.0, -4.961, -4.961]}
{"step": 1711, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1712.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1712.0, 1712.0], "q_vals": [0.0, 0.0, -5.041, 0.0, 0.0, 0.0, 0.0, 0.0, -4.962, -4.962]}
{"step": 1712, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1713.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1713.0, 1713.0], "q_vals": [0.0, 0.0, -5.044, 0.0, 0.0, 0.0, 0.0, 0.0, -4.964, -4.964]}
{"number_of_episodes": 5076, "number_of_timesteps": 75838, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1713, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1714.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1714.0, 1714.0], "q_vals": [0.0, 0.0, -5.045, 0.0, 0.0, 0.0, 0.0, 0.0, -4.965, -4.965]}
{"number_of_episodes": 5078, "number_of_timesteps": 75913, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1714, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1715.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1715.0, 1715.0], "q_vals": [0.0, 0.0, -5.046, 0.0, 0.0, 0.0, 0.0, 0.0, -4.965, -4.965]}
{"number_of_episodes": 5080, "number_of_timesteps": 75945, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1715, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1716.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1716.0, 1716.0], "q_vals": [0.0, 0.0, -5.043, 0.0, 0.0, 0.0, 0.0, 0.0, -4.965, -4.965]}
{"step": 1716, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1717.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1717.0, 1717.0], "q_vals": [0.0, 0.0, -5.044, 0.0, 0.0, 0.0, 0.0, 0.0, -4.965, -4.965]}
{"number_of_episodes": 5084, "number_of_timesteps": 76012, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1717, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1718.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1718.0, 1718.0], "q_vals": [0.0, 0.0, -5.041, 0.0, 0.0, 0.0, 0.0, 0.0, -4.962, -4.962]}
{"number_of_episodes": 5087, "number_of_timesteps": 76086, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1718, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1719.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1719.0, 1719.0], "q_vals": [0.0, 0.0, -5.041, 0.0, 0.0, 0.0, 0.0, 0.0, -4.962, -4.962]}
{"number_of_episodes": 5089, "number_of_timesteps": 76115, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1719, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1720.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1720.0, 1720.0], "q_vals": [0.0, 0.0, -5.038, 0.0, 0.0, 0.0, 0.0, 0.0, -4.959, -4.959]}
{"number_of_episodes": 5090, "number_of_timesteps": 76135, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1720, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1721.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1721.0, 1721.0], "q_vals": [0.0, 0.0, -5.038, 0.0, 0.0, 0.0, 0.0, 0.0, -4.959, -4.959]}
{"step": 1721, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1722.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1722.0, 1722.0], "q_vals": [0.0, 0.0, -5.038, 0.0, 0.0, 0.0, 0.0, 0.0, -4.958, -4.958]}
{"step": 1722, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1723.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1723.0, 1723.0], "q_vals": [0.0, 0.0, -5.038, 0.0, 0.0, 0.0, 0.0, 0.0, -4.957, -4.957]}
{"number_of_episodes": 5095, "number_of_timesteps": 76240, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1723, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1724.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1724.0, 1724.0], "q_vals": [0.0, 0.0, -5.037, 0.0, 0.0, 0.0, 0.0, 0.0, -4.957, -4.957]}
{"number_of_episodes": 5096, "number_of_timesteps": 76270, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1724, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1725.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1725.0, 1725.0], "q_vals": [0.0, 0.0, -5.041, 0.0, 0.0, 0.0, 0.0, 0.0, -4.96, -4.96]}
{"step": 1725, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1726.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1726.0, 1726.0], "q_vals": [0.0, 0.0, -5.038, 0.0, 0.0, 0.0, 0.0, 0.0, -4.957, -4.957]}
{"number_of_episodes": 5100, "number_of_timesteps": 76408, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1726, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1727.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1727.0, 1727.0], "q_vals": [0.0, 0.0, -5.035, 0.0, 0.0, 0.0, 0.0, 0.0, -4.954, -4.954]}
{"number_of_episodes": 5102, "number_of_timesteps": 76438, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1727, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1728.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1728.0, 1728.0], "q_vals": [0.0, 0.0, -5.034, 0.0, 0.0, 0.0, 0.0, 0.0, -4.953, -4.953]}
{"number_of_episodes": 5104, "number_of_timesteps": 76495, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1728, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1729.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1729.0, 1729.0], "q_vals": [0.0, 0.0, -5.033, 0.0, 0.0, 0.0, 0.0, 0.0, -4.952, -4.952]}
{"step": 1729, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1730.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1730.0, 1730.0], "q_vals": [0.0, 0.0, -5.034, 0.0, 0.0, 0.0, 0.0, 0.0, -4.952, -4.952]}
{"number_of_episodes": 5106, "number_of_timesteps": 76530, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1730, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1731.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1731.0, 1731.0], "q_vals": [0.0, 0.0, -5.031, 0.0, 0.0, 0.0, 0.0, 0.0, -4.949, -4.949]}
{"number_of_episodes": 5107, "number_of_timesteps": 76547, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1731, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1732.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1732.0, 1732.0], "q_vals": [0.0, 0.0, -5.036, 0.0, 0.0, 0.0, 0.0, 0.0, -4.954, -4.954]}
{"number_of_episodes": 5110, "number_of_timesteps": 76617, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 1732, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1733.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1733.0, 1733.0], "q_vals": [0.0, 0.0, -5.036, 0.0, 0.0, 0.0, 0.0, 0.0, -4.953, -4.953]}
{"number_of_episodes": 5113, "number_of_timesteps": 76796, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1733, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1734.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1734.0, 1734.0], "q_vals": [0.0, 0.0, -5.036, 0.0, 0.0, 0.0, 0.0, 0.0, -4.953, -4.953]}
{"step": 1734, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1735.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1735.0, 1735.0], "q_vals": [0.0, 0.0, -5.036, 0.0, 0.0, 0.0, 0.0, 0.0, -4.952, -4.952]}
{"step": 1735, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1736.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1736.0, 1736.0], "q_vals": [0.0, 0.0, -5.036, 0.0, 0.0, 0.0, 0.0, 0.0, -4.952, -4.952]}
{"number_of_episodes": 5118, "number_of_timesteps": 76895, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1736, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1737.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1737.0, 1737.0], "q_vals": [0.0, 0.0, -5.033, 0.0, 0.0, 0.0, 0.0, 0.0, -4.951, -4.951]}
{"number_of_episodes": 5121, "number_of_timesteps": 76963, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1737, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1738.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1738.0, 1738.0], "q_vals": [0.0, 0.0, -5.03, 0.0, 0.0, 0.0, 0.0, 0.0, -4.949, -4.949]}
{"step": 1738, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1739.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1739.0, 1739.0], "q_vals": [0.0, 0.0, -5.027, 0.0, 0.0, 0.0, 0.0, 0.0, -4.948, -4.948]}
{"number_of_episodes": 5125, "number_of_timesteps": 77070, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1739, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1740.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1740.0, 1740.0], "q_vals": [0.0, 0.0, -5.03, 0.0, 0.0, 0.0, 0.0, 0.0, -4.95, -4.95]}
{"step": 1740, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1741.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1741.0, 1741.0], "q_vals": [0.0, 0.0, -5.027, 0.0, 0.0, 0.0, 0.0, 0.0, -4.947, -4.947]}
{"number_of_episodes": 5128, "number_of_timesteps": 77131, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"step": 1741, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1742.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1742.0, 1742.0], "q_vals": [0.0, 0.0, -5.028, 0.0, 0.0, 0.0, 0.0, 0.0, -4.947, -4.947]}
{"number_of_episodes": 5132, "number_of_timesteps": 77198, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1742, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1743.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1743.0, 1743.0], "q_vals": [0.0, 0.0, -5.027, 0.0, 0.0, 0.0, 0.0, 0.0, -4.947, -4.947]}
{"step": 1743, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1744.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1744.0, 1744.0], "q_vals": [0.0, 0.0, -5.027, 0.0, 0.0, 0.0, 0.0, 0.0, -4.946, -4.946]}
{"step": 1744, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1745.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1745.0, 1745.0], "q_vals": [0.0, 0.0, -5.026, 0.0, 0.0, 0.0, 0.0, 0.0, -4.945, -4.945]}
{"number_of_episodes": 5137, "number_of_timesteps": 77321, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1745, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1746.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1746.0, 1746.0], "q_vals": [0.0, 0.0, -5.023, 0.0, 0.0, 0.0, 0.0, 0.0, -4.943, -4.943]}
{"number_of_episodes": 5139, "number_of_timesteps": 77378, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1746, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1747.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1747.0, 1747.0], "q_vals": [0.0, 0.0, -5.02, 0.0, 0.0, 0.0, 0.0, 0.0, -4.94, -4.94]}
{"number_of_episodes": 5143, "number_of_timesteps": 77462, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1747, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1748.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1748.0, 1748.0], "q_vals": [0.0, 0.0, -5.023, 0.0, 0.0, 0.0, 0.0, 0.0, -4.943, -4.943]}
{"number_of_episodes": 5144, "number_of_timesteps": 77490, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 1748, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1749.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1749.0, 1749.0], "q_vals": [0.0, 0.0, -5.02, 0.0, 0.0, 0.0, 0.0, 0.0, -4.94, -4.94]}
{"number_of_episodes": 5144, "number_of_timesteps": 77490, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1749, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1750.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1750.0, 1750.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.937, -4.937]}
{"number_of_episodes": 5146, "number_of_timesteps": 77539, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1750, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1751.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1751.0, 1751.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.937, -4.937]}
{"step": 1751, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1752.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1752.0, 1752.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.937, -4.937]}
{"number_of_episodes": 5152, "number_of_timesteps": 77685, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1752, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1753.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1753.0, 1753.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.936, -4.936]}
{"number_of_episodes": 5154, "number_of_timesteps": 77726, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1753, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1754.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1754.0, 1754.0], "q_vals": [0.0, 0.0, -5.021, 0.0, 0.0, 0.0, 0.0, 0.0, -4.939, -4.939]}
{"number_of_episodes": 5157, "number_of_timesteps": 77780, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"step": 1754, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1755.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1755.0, 1755.0], "q_vals": [0.0, 0.0, -5.02, 0.0, 0.0, 0.0, 0.0, 0.0, -4.937, -4.937]}
{"step": 1755, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1756.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1756.0, 1756.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.936, -4.936]}
{"number_of_episodes": 5161, "number_of_timesteps": 77849, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1756, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1757.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1757.0, 1757.0], "q_vals": [0.0, 0.0, -5.016, 0.0, 0.0, 0.0, 0.0, 0.0, -4.936, -4.936]}
{"number_of_episodes": 5164, "number_of_timesteps": 77905, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1757, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1758.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1758.0, 1758.0], "q_vals": [0.0, 0.0, -5.016, 0.0, 0.0, 0.0, 0.0, 0.0, -4.935, -4.935]}
{"number_of_episodes": 5167, "number_of_timesteps": 77962, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1758, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1759.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1759.0, 1759.0], "q_vals": [0.0, 0.0, -5.016, 0.0, 0.0, 0.0, 0.0, 0.0, -4.936, -4.936]}
{"number_of_episodes": 5168, "number_of_timesteps": 77980, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1759, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1760.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1760.0, 1760.0], "q_vals": [0.0, 0.0, -5.016, 0.0, 0.0, 0.0, 0.0, 0.0, -4.935, -4.935]}
{"number_of_episodes": 5172, "number_of_timesteps": 78068, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1760, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1761.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1761.0, 1761.0], "q_vals": [0.0, 0.0, -5.013, 0.0, 0.0, 0.0, 0.0, 0.0, -4.932, -4.932]}
{"number_of_episodes": 5174, "number_of_timesteps": 78100, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1761, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1762.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1762.0, 1762.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.936, -4.936]}
{"number_of_episodes": 5177, "number_of_timesteps": 78150, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1762, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1763.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1763.0, 1763.0], "q_vals": [0.0, 0.0, -5.021, 0.0, 0.0, 0.0, 0.0, 0.0, -4.938, -4.938]}
{"step": 1763, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1764.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1764.0, 1764.0], "q_vals": [0.0, 0.0, -5.025, 0.0, 0.0, 0.0, 0.0, 0.0, -4.942, -4.942]}
{"number_of_episodes": 5181, "number_of_timesteps": 78200, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1764, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1765.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1765.0, 1765.0], "q_vals": [0.0, 0.0, -5.025, 0.0, 0.0, 0.0, 0.0, 0.0, -4.942, -4.942]}
{"number_of_episodes": 5183, "number_of_timesteps": 78245, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1765, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1766.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1766.0, 1766.0], "q_vals": [0.0, 0.0, -5.023, 0.0, 0.0, 0.0, 0.0, 0.0, -4.939, -4.939]}
{"number_of_episodes": 5184, "number_of_timesteps": 78270, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1766, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1767.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1767.0, 1767.0], "q_vals": [0.0, 0.0, -5.025, 0.0, 0.0, 0.0, 0.0, 0.0, -4.941, -4.941]}
{"number_of_episodes": 5189, "number_of_timesteps": 78383, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1767, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1768.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1768.0, 1768.0], "q_vals": [0.0, 0.0, -5.023, 0.0, 0.0, 0.0, 0.0, 0.0, -4.941, -4.941]}
{"number_of_episodes": 5189, "number_of_timesteps": 78383, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1768, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1769.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1769.0, 1769.0], "q_vals": [0.0, 0.0, -5.023, 0.0, 0.0, 0.0, 0.0, 0.0, -4.941, -4.941]}
{"step": 1769, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1770.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1770.0, 1770.0], "q_vals": [0.0, 0.0, -5.02, 0.0, 0.0, 0.0, 0.0, 0.0, -4.938, -4.938]}
{"number_of_episodes": 5193, "number_of_timesteps": 78451, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1770, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1771.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1771.0, 1771.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.935, -4.935]}
{"number_of_episodes": 5195, "number_of_timesteps": 78512, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1771, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1772.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1772.0, 1772.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.934, -4.934]}
{"step": 1772, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1773.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1773.0, 1773.0], "q_vals": [0.0, 0.0, -5.014, 0.0, 0.0, 0.0, 0.0, 0.0, -4.931, -4.931]}
{"number_of_episodes": 5199, "number_of_timesteps": 78606, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1773, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1774.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1774.0, 1774.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.934, -4.934]}
{"eval_score": 20.9, "number_of_episodes": 5201}
{"number_of_episodes": 5201, "number_of_timesteps": 78640, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1774, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1775.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1775.0, 1775.0], "q_vals": [0.0, 0.0, -5.014, 0.0, 0.0, 0.0, 0.0, 0.0, -4.933, -4.933]}
{"number_of_episodes": 5205, "number_of_timesteps": 78718, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 1775, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1776.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1776.0, 1776.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.931, -4.931]}
{"number_of_episodes": 5207, "number_of_timesteps": 78748, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1776, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1777.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1777.0, 1777.0], "q_vals": [0.0, 0.0, -5.016, 0.0, 0.0, 0.0, 0.0, 0.0, -4.934, -4.934]}
{"number_of_episodes": 5208, "number_of_timesteps": 78804, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1777, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1778.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1778.0, 1778.0], "q_vals": [0.0, 0.0, -5.014, 0.0, 0.0, 0.0, 0.0, 0.0, -4.932, -4.932]}
{"number_of_episodes": 5212, "number_of_timesteps": 78873, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1778, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1779.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1779.0, 1779.0], "q_vals": [0.0, 0.0, -5.011, 0.0, 0.0, 0.0, 0.0, 0.0, -4.932, -4.932]}
{"step": 1779, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1780.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1780.0, 1780.0], "q_vals": [0.0, 0.0, -5.008, 0.0, 0.0, 0.0, 0.0, 0.0, -4.929, -4.929]}
{"number_of_episodes": 5216, "number_of_timesteps": 78953, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1780, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1781.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1781.0, 1781.0], "q_vals": [0.0, 0.0, -5.008, 0.0, 0.0, 0.0, 0.0, 0.0, -4.929, -4.929]}
{"number_of_episodes": 5217, "number_of_timesteps": 78964, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 1781, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1782.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1782.0, 1782.0], "q_vals": [0.0, 0.0, -5.006, 0.0, 0.0, 0.0, 0.0, 0.0, -4.926, -4.926]}
{"step": 1782, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1783.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1783.0, 1783.0], "q_vals": [0.0, 0.0, -5.003, 0.0, 0.0, 0.0, 0.0, 0.0, -4.923, -4.923]}
{"step": 1783, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1784.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1784.0, 1784.0], "q_vals": [0.0, 0.0, -5.003, 0.0, 0.0, 0.0, 0.0, 0.0, -4.923, -4.923]}
{"step": 1784, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1785.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1785.0, 1785.0], "q_vals": [0.0, 0.0, -5.003, 0.0, 0.0, 0.0, 0.0, 0.0, -4.923, -4.923]}
{"number_of_episodes": 5222, "number_of_timesteps": 79067, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1785, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1786.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1786.0, 1786.0], "q_vals": [0.0, 0.0, -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.923, -4.923]}
{"number_of_episodes": 5223, "number_of_timesteps": 79097, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1786, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1787.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1787.0, 1787.0], "q_vals": [0.0, 0.0, -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.923, -4.923]}
{"step": 1787, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1788.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1788.0, 1788.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.92, -4.92]}
{"step": 1788, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1789.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1789.0, 1789.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.92, -4.92]}
{"number_of_episodes": 5230, "number_of_timesteps": 79362, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1789, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1790.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1790.0, 1790.0], "q_vals": [0.0, 0.0, -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.922, -4.922]}
{"step": 1790, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1791.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1791.0, 1791.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.921, -4.921]}
{"step": 1791, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1792.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1792.0, 1792.0], "q_vals": [0.0, 0.0, -5.004, 0.0, 0.0, 0.0, 0.0, 0.0, -4.926, -4.926]}
{"number_of_episodes": 5236, "number_of_timesteps": 79490, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1792, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1793.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1793.0, 1793.0], "q_vals": [0.0, 0.0, -5.007, 0.0, 0.0, 0.0, 0.0, 0.0, -4.929, -4.929]}
{"step": 1793, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1794.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1794.0, 1794.0], "q_vals": [0.0, 0.0, -5.011, 0.0, 0.0, 0.0, 0.0, 0.0, -4.932, -4.932]}
{"step": 1794, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1795.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1795.0, 1795.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.937, -4.937]}
{"number_of_episodes": 5239, "number_of_timesteps": 79531, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"step": 1795, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1796.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1796.0, 1796.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.938, -4.938]}
{"number_of_episodes": 5244, "number_of_timesteps": 79632, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1796, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1797.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1797.0, 1797.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.937, -4.937]}
{"step": 1797, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1798.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1798.0, 1798.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.937, -4.937]}
{"number_of_episodes": 5248, "number_of_timesteps": 79763, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1798, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1799.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1799.0, 1799.0], "q_vals": [0.0, 0.0, -5.015, 0.0, 0.0, 0.0, 0.0, 0.0, -4.937, -4.937]}
{"number_of_episodes": 5251, "number_of_timesteps": 79801, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1799, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1800.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1800.0, 1800.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.934, -4.934]}
{"number_of_episodes": 5253, "number_of_timesteps": 79874, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 1800, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1801.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1801.0, 1801.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.933, -4.933]}
{"number_of_episodes": 5253, "number_of_timesteps": 79874, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1801, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1802.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1802.0, 1802.0], "q_vals": [0.0, 0.0, -5.015, 0.0, 0.0, 0.0, 0.0, 0.0, -4.936, -4.936]}
{"step": 1802, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1803.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1803.0, 1803.0], "q_vals": [0.0, 0.0, -5.016, 0.0, 0.0, 0.0, 0.0, 0.0, -4.936, -4.936]}
{"number_of_episodes": 5259, "number_of_timesteps": 79982, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1803, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1804.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1804.0, 1804.0], "q_vals": [0.0, 0.0, -5.013, 0.0, 0.0, 0.0, 0.0, 0.0, -4.935, -4.935]}
{"number_of_episodes": 5261, "number_of_timesteps": 80021, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1804, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1805.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1805.0, 1805.0], "q_vals": [0.0, 0.0, -5.013, 0.0, 0.0, 0.0, 0.0, 0.0, -4.935, -4.935]}
{"number_of_episodes": 5263, "number_of_timesteps": 80051, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1805, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1806.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1806.0, 1806.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.939, -4.939]}
{"step": 1806, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1807.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1807.0, 1807.0], "q_vals": [0.0, 0.0, -5.021, 0.0, 0.0, 0.0, 0.0, 0.0, -4.941, -4.941]}
{"number_of_episodes": 5267, "number_of_timesteps": 80147, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1807, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1808.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1808.0, 1808.0], "q_vals": [0.0, 0.0, -5.02, 0.0, 0.0, 0.0, 0.0, 0.0, -4.941, -4.941]}
{"step": 1808, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1809.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1809.0, 1809.0], "q_vals": [0.0, 0.0, -5.026, 0.0, 0.0, 0.0, 0.0, 0.0, -4.945, -4.945]}
{"number_of_episodes": 5271, "number_of_timesteps": 80210, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1809, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1810.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1810.0, 1810.0], "q_vals": [0.0, 0.0, -5.023, 0.0, 0.0, 0.0, 0.0, 0.0, -4.945, -4.945]}
{"number_of_episodes": 5274, "number_of_timesteps": 80289, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 1810, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1811.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1811.0, 1811.0], "q_vals": [0.0, 0.0, -5.02, 0.0, 0.0, 0.0, 0.0, 0.0, -4.942, -4.942]}
{"number_of_episodes": 5278, "number_of_timesteps": 80417, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1811, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1812.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1812.0, 1812.0], "q_vals": [0.0, 0.0, -5.02, 0.0, 0.0, 0.0, 0.0, 0.0, -4.941, -4.941]}
{"number_of_episodes": 5279, "number_of_timesteps": 80426, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1812, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1813.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1813.0, 1813.0], "q_vals": [0.0, 0.0, -5.023, 0.0, 0.0, 0.0, 0.0, 0.0, -4.944, -4.944]}
{"number_of_episodes": 5280, "number_of_timesteps": 80445, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1813, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1814.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1814.0, 1814.0], "q_vals": [0.0, 0.0, -5.027, 0.0, 0.0, 0.0, 0.0, 0.0, -4.947, -4.947]}
{"step": 1814, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1815.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1815.0, 1815.0], "q_vals": [0.0, 0.0, -5.03, 0.0, 0.0, 0.0, 0.0, 0.0, -4.949, -4.949]}
{"number_of_episodes": 5284, "number_of_timesteps": 80538, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1815, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1816.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1816.0, 1816.0], "q_vals": [0.0, 0.0, -5.028, 0.0, 0.0, 0.0, 0.0, 0.0, -4.947, -4.947]}
{"number_of_episodes": 5286, "number_of_timesteps": 80588, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1816, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1817.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1817.0, 1817.0], "q_vals": [0.0, 0.0, -5.025, 0.0, 0.0, 0.0, 0.0, 0.0, -4.944, -4.944]}
{"step": 1817, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1818.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1818.0, 1818.0], "q_vals": [0.0, 0.0, -5.025, 0.0, 0.0, 0.0, 0.0, 0.0, -4.944, -4.944]}
{"number_of_episodes": 5291, "number_of_timesteps": 80694, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1818, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1819.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1819.0, 1819.0], "q_vals": [0.0, 0.0, -5.022, 0.0, 0.0, 0.0, 0.0, 0.0, -4.941, -4.941]}
{"number_of_episodes": 5293, "number_of_timesteps": 80729, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1819, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1820.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1820.0, 1820.0], "q_vals": [0.0, 0.0, -5.024, 0.0, 0.0, 0.0, 0.0, 0.0, -4.943, -4.943]}
{"number_of_episodes": 5296, "number_of_timesteps": 80777, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1820, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1821.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1821.0, 1821.0], "q_vals": [0.0, 0.0, -5.03, 0.0, 0.0, 0.0, 0.0, 0.0, -4.948, -4.948]}
{"number_of_episodes": 5299, "number_of_timesteps": 80825, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1821, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1822.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1822.0, 1822.0], "q_vals": [0.0, 0.0, -5.03, 0.0, 0.0, 0.0, 0.0, 0.0, -4.947, -4.947]}
{"number_of_episodes": 5300, "number_of_timesteps": 80844, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1822, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1823.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1823.0, 1823.0], "q_vals": [0.0, 0.0, -5.027, 0.0, 0.0, 0.0, 0.0, 0.0, -4.945, -4.945]}
{"number_of_episodes": 5303, "number_of_timesteps": 80898, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1823, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1824.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1824.0, 1824.0], "q_vals": [0.0, 0.0, -5.024, 0.0, 0.0, 0.0, 0.0, 0.0, -4.942, -4.942]}
{"number_of_episodes": 5308, "number_of_timesteps": 81024, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1824, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1825.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1825.0, 1825.0], "q_vals": [0.0, 0.0, -5.022, 0.0, 0.0, 0.0, 0.0, 0.0, -4.939, -4.939]}
{"step": 1825, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1826.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1826.0, 1826.0], "q_vals": [0.0, 0.0, -5.019, 0.0, 0.0, 0.0, 0.0, 0.0, -4.936, -4.936]}
{"step": 1826, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1827.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1827.0, 1827.0], "q_vals": [0.0, 0.0, -5.016, 0.0, 0.0, 0.0, 0.0, 0.0, -4.934, -4.934]}
{"number_of_episodes": 5316, "number_of_timesteps": 81138, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1827, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1828.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1828.0, 1828.0], "q_vals": [0.0, 0.0, -5.016, 0.0, 0.0, 0.0, 0.0, 0.0, -4.933, -4.933]}
{"number_of_episodes": 5316, "number_of_timesteps": 81138, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1828, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1829.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1829.0, 1829.0], "q_vals": [0.0, 0.0, -5.02, 0.0, 0.0, 0.0, 0.0, 0.0, -4.937, -4.937]}
{"number_of_episodes": 5316, "number_of_timesteps": 81138, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1829, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1830.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1830.0, 1830.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.935, -4.935]}
{"number_of_episodes": 5321, "number_of_timesteps": 81240, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 1830, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1831.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1831.0, 1831.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.935, -4.935]}
{"step": 1831, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1832.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1832.0, 1832.0], "q_vals": [0.0, 0.0, -5.019, 0.0, 0.0, 0.0, 0.0, 0.0, -4.935, -4.935]}
{"number_of_episodes": 5324, "number_of_timesteps": 81317, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 1832, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1833.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1833.0, 1833.0], "q_vals": [0.0, 0.0, -5.016, 0.0, 0.0, 0.0, 0.0, 0.0, -4.932, -4.932]}
{"step": 1833, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1834.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1834.0, 1834.0], "q_vals": [0.0, 0.0, -5.016, 0.0, 0.0, 0.0, 0.0, 0.0, -4.932, -4.932]}
{"eval_score": 18.8, "number_of_episodes": 5331}
{"number_of_episodes": 5331, "number_of_timesteps": 81458, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1834, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1835.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1835.0, 1835.0], "q_vals": [0.0, 0.0, -5.013, 0.0, 0.0, 0.0, 0.0, 0.0, -4.929, -4.929]}
{"number_of_episodes": 5334, "number_of_timesteps": 81496, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1835, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1836.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1836.0, 1836.0], "q_vals": [0.0, 0.0, -5.01, 0.0, 0.0, 0.0, 0.0, 0.0, -4.926, -4.926]}
{"number_of_episodes": 5335, "number_of_timesteps": 81510, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1836, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1837.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1837.0, 1837.0], "q_vals": [0.0, 0.0, -5.01, 0.0, 0.0, 0.0, 0.0, 0.0, -4.925, -4.925]}
{"number_of_episodes": 5339, "number_of_timesteps": 81588, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1837, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1838.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1838.0, 1838.0], "q_vals": [0.0, 0.0, -5.009, 0.0, 0.0, 0.0, 0.0, 0.0, -4.925, -4.925]}
{"number_of_episodes": 5341, "number_of_timesteps": 81619, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1838, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1839.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1839.0, 1839.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.927, -4.927]}
{"step": 1839, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1840.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1840.0, 1840.0], "q_vals": [0.0, 0.0, -5.014, 0.0, 0.0, 0.0, 0.0, 0.0, -4.928, -4.928]}
{"step": 1840, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1841.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1841.0, 1841.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.93, -4.93]}
{"number_of_episodes": 5349, "number_of_timesteps": 81769, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1841, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1842.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1842.0, 1842.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.931, -4.931]}
{"number_of_episodes": 5349, "number_of_timesteps": 81769, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1842, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1843.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1843.0, 1843.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.93, -4.93]}
{"step": 1843, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1844.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1844.0, 1844.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.93, -4.93]}
{"step": 1844, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1845.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1845.0, 1845.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.93, -4.93]}
{"number_of_episodes": 5355, "number_of_timesteps": 81869, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1845, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1846.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1846.0, 1846.0], "q_vals": [0.0, 0.0, -5.021, 0.0, 0.0, 0.0, 0.0, 0.0, -4.932, -4.932]}
{"number_of_episodes": 5359, "number_of_timesteps": 81981, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1846, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1847.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1847.0, 1847.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.93, -4.93]}
{"number_of_episodes": 5361, "number_of_timesteps": 82007, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1847, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1848.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1848.0, 1848.0], "q_vals": [0.0, 0.0, -5.015, 0.0, 0.0, 0.0, 0.0, 0.0, -4.927, -4.927]}
{"number_of_episodes": 5362, "number_of_timesteps": 82022, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1848, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1849.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1849.0, 1849.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.927, -4.927]}
{"number_of_episodes": 5364, "number_of_timesteps": 82047, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1849, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1850.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1850.0, 1850.0], "q_vals": [0.0, 0.0, -5.01, 0.0, 0.0, 0.0, 0.0, 0.0, -4.924, -4.924]}
{"number_of_episodes": 5367, "number_of_timesteps": 82120, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1850, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1851.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1851.0, 1851.0], "q_vals": [0.0, 0.0, -5.009, 0.0, 0.0, 0.0, 0.0, 0.0, -4.923, -4.923]}
{"step": 1851, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1852.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1852.0, 1852.0], "q_vals": [0.0, 0.0, -5.014, 0.0, 0.0, 0.0, 0.0, 0.0, -4.927, -4.927]}
{"step": 1852, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1853.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1853.0, 1853.0], "q_vals": [0.0, 0.0, -5.019, 0.0, 0.0, 0.0, 0.0, 0.0, -4.931, -4.931]}
{"number_of_episodes": 5375, "number_of_timesteps": 82320, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1853, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1854.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1854.0, 1854.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.931, -4.931]}
{"number_of_episodes": 5378, "number_of_timesteps": 82354, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1854, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1855.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1855.0, 1855.0], "q_vals": [0.0, 0.0, -5.021, 0.0, 0.0, 0.0, 0.0, 0.0, -4.933, -4.933]}
{"number_of_episodes": 5381, "number_of_timesteps": 82415, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1855, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1856.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1856.0, 1856.0], "q_vals": [0.0, 0.0, -5.019, 0.0, 0.0, 0.0, 0.0, 0.0, -4.93, -4.93]}
{"step": 1856, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1857.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1857.0, 1857.0], "q_vals": [0.0, 0.0, -5.022, 0.0, 0.0, 0.0, 0.0, 0.0, -4.932, -4.932]}
{"number_of_episodes": 5385, "number_of_timesteps": 82477, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1857, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1858.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1858.0, 1858.0], "q_vals": [0.0, 0.0, -5.019, 0.0, 0.0, 0.0, 0.0, 0.0, -4.93, -4.93]}
{"number_of_episodes": 5390, "number_of_timesteps": 82560, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1858, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1859.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1859.0, 1859.0], "q_vals": [0.0, 0.0, -5.019, 0.0, 0.0, 0.0, 0.0, 0.0, -4.93, -4.93]}
{"number_of_episodes": 5392, "number_of_timesteps": 82585, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1859, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1860.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1860.0, 1860.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.929, -4.929]}
{"number_of_episodes": 5394, "number_of_timesteps": 82625, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1860, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1861.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1861.0, 1861.0], "q_vals": [0.0, 0.0, -5.021, 0.0, 0.0, 0.0, 0.0, 0.0, -4.931, -4.931]}
{"number_of_episodes": 5397, "number_of_timesteps": 82672, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1861, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1862.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1862.0, 1862.0], "q_vals": [0.0, 0.0, -5.024, 0.0, 0.0, 0.0, 0.0, 0.0, -4.933, -4.933]}
{"step": 1862, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1863.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1863.0, 1863.0], "q_vals": [0.0, 0.0, -5.026, 0.0, 0.0, 0.0, 0.0, 0.0, -4.935, -4.935]}
{"number_of_episodes": 5401, "number_of_timesteps": 82724, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1863, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1864.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1864.0, 1864.0], "q_vals": [0.0, 0.0, -5.024, 0.0, 0.0, 0.0, 0.0, 0.0, -4.933, -4.933]}
{"step": 1864, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1865.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1865.0, 1865.0], "q_vals": [0.0, 0.0, -5.021, 0.0, 0.0, 0.0, 0.0, 0.0, -4.93, -4.93]}
{"number_of_episodes": 5404, "number_of_timesteps": 82782, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1865, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1866.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1866.0, 1866.0], "q_vals": [0.0, 0.0, -5.021, 0.0, 0.0, 0.0, 0.0, 0.0, -4.929, -4.929]}
{"number_of_episodes": 5407, "number_of_timesteps": 82843, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1866, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1867.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1867.0, 1867.0], "q_vals": [0.0, 0.0, -5.018, 0.0, 0.0, 0.0, 0.0, 0.0, -4.93, -4.93]}
{"number_of_episodes": 5410, "number_of_timesteps": 82927, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1867, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1868.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1868.0, 1868.0], "q_vals": [0.0, 0.0, -5.017, 0.0, 0.0, 0.0, 0.0, 0.0, -4.929, -4.929]}
{"number_of_episodes": 5412, "number_of_timesteps": 82986, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1868, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1869.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1869.0, 1869.0], "q_vals": [0.0, 0.0, -5.015, 0.0, 0.0, 0.0, 0.0, 0.0, -4.926, -4.926]}
{"number_of_episodes": 5415, "number_of_timesteps": 83045, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1869, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1870.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1870.0, 1870.0], "q_vals": [0.0, 0.0, -5.014, 0.0, 0.0, 0.0, 0.0, 0.0, -4.926, -4.926]}
{"number_of_episodes": 5415, "number_of_timesteps": 83045, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1870, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1871.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1871.0, 1871.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.923, -4.923]}
{"step": 1871, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1872.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1872.0, 1872.0], "q_vals": [0.0, 0.0, -5.009, 0.0, 0.0, 0.0, 0.0, 0.0, -4.92, -4.92]}
{"number_of_episodes": 5423, "number_of_timesteps": 83192, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1872, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1873.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1873.0, 1873.0], "q_vals": [0.0, 0.0, -5.009, 0.0, 0.0, 0.0, 0.0, 0.0, -4.92, -4.92]}
{"number_of_episodes": 5425, "number_of_timesteps": 83219, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1873, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1874.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1874.0, 1874.0], "q_vals": [0.0, 0.0, -5.006, 0.0, 0.0, 0.0, 0.0, 0.0, -4.919, -4.919]}
{"number_of_episodes": 5427, "number_of_timesteps": 83246, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1874, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1875.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1875.0, 1875.0], "q_vals": [0.0, 0.0, -5.003, 0.0, 0.0, 0.0, 0.0, 0.0, -4.917, -4.917]}
{"number_of_episodes": 5430, "number_of_timesteps": 83308, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1875, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1876.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1876.0, 1876.0], "q_vals": [0.0, 0.0, -5.001, 0.0, 0.0, 0.0, 0.0, 0.0, -4.914, -4.914]}
{"number_of_episodes": 5433, "number_of_timesteps": 83372, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1876, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1877.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1877.0, 1877.0], "q_vals": [0.0, 0.0, -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.913, -4.913]}
{"number_of_episodes": 5435, "number_of_timesteps": 83418, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1877, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1878.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1878.0, 1878.0], "q_vals": [0.0, 0.0, -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.913, -4.913]}
{"number_of_episodes": 5437, "number_of_timesteps": 83451, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1878, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1879.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1879.0, 1879.0], "q_vals": [0.0, 0.0, -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.912, -4.912]}
{"number_of_episodes": 5440, "number_of_timesteps": 83496, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1879, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1880.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1880.0, 1880.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"step": 1880, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1881.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1881.0, 1881.0], "q_vals": [0.0, 0.0, -4.998, 0.0, 0.0, 0.0, 0.0, 0.0, -4.91, -4.91]}
{"number_of_episodes": 5444, "number_of_timesteps": 83573, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1881, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1882.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1882.0, 1882.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"step": 1882, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1883.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1883.0, 1883.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.906, -4.906]}
{"number_of_episodes": 5451, "number_of_timesteps": 83697, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1883, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1884.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1884.0, 1884.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"number_of_episodes": 5453, "number_of_timesteps": 83731, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1884, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1885.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1885.0, 1885.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.903, -4.903]}
{"number_of_episodes": 5456, "number_of_timesteps": 83780, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1885, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1886.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1886.0, 1886.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.906, -4.906]}
{"number_of_episodes": 5458, "number_of_timesteps": 83816, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1886, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1887.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1887.0, 1887.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.908, -4.908]}
{"eval_score": 28.3, "number_of_episodes": 5461}
{"number_of_episodes": 5461, "number_of_timesteps": 83874, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1887, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1888.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1888.0, 1888.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.907, -4.907]}
{"number_of_episodes": 5463, "number_of_timesteps": 83901, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1888, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1889.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1889.0, 1889.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"number_of_episodes": 5464, "number_of_timesteps": 83914, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1889, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1890.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1890.0, 1890.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"step": 1890, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1891.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1891.0, 1891.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"number_of_episodes": 5468, "number_of_timesteps": 83991, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1891, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1892.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1892.0, 1892.0], "q_vals": [0.0, 0.0, -4.991, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"number_of_episodes": 5470, "number_of_timesteps": 84023, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1892, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1893.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1893.0, 1893.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"number_of_episodes": 5471, "number_of_timesteps": 84063, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1893, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1894.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1894.0, 1894.0], "q_vals": [0.0, 0.0, -4.998, 0.0, 0.0, 0.0, 0.0, 0.0, -4.907, -4.907]}
{"number_of_episodes": 5474, "number_of_timesteps": 84117, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1894, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1895.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1895.0, 1895.0], "q_vals": [0.0, 0.0, -4.996, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"number_of_episodes": 5476, "number_of_timesteps": 84160, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1895, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1896.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1896.0, 1896.0], "q_vals": [0.0, 0.0, -4.993, 0.0, 0.0, 0.0, 0.0, 0.0, -4.902, -4.902]}
{"step": 1896, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1897.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1897.0, 1897.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 5483, "number_of_timesteps": 84321, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1897, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1898.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1898.0, 1898.0], "q_vals": [0.0, 0.0, -4.993, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"step": 1898, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1899.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1899.0, 1899.0], "q_vals": [0.0, 0.0, -4.997, 0.0, 0.0, 0.0, 0.0, 0.0, -4.904, -4.904]}
{"number_of_episodes": 5487, "number_of_timesteps": 84380, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1899, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1900.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1900.0, 1900.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"number_of_episodes": 5487, "number_of_timesteps": 84380, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1900, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1901.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1901.0, 1901.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"number_of_episodes": 5490, "number_of_timesteps": 84430, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1901, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1902.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1902.0, 1902.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"number_of_episodes": 5494, "number_of_timesteps": 84508, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1902, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1903.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1903.0, 1903.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.901, -4.901]}
{"step": 1903, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1904.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1904.0, 1904.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 5499, "number_of_timesteps": 84655, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1904, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1905.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1905.0, 1905.0], "q_vals": [0.0, 0.0, -4.989, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"number_of_episodes": 5501, "number_of_timesteps": 84682, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1905, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1906.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1906.0, 1906.0], "q_vals": [0.0, 0.0, -4.987, 0.0, 0.0, 0.0, 0.0, 0.0, -4.896, -4.896]}
{"number_of_episodes": 5501, "number_of_timesteps": 84682, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1906, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1907.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1907.0, 1907.0], "q_vals": [0.0, 0.0, -4.99, 0.0, 0.0, 0.0, 0.0, 0.0, -4.898, -4.898]}
{"step": 1907, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1908.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1908.0, 1908.0], "q_vals": [0.0, 0.0, -4.994, 0.0, 0.0, 0.0, 0.0, 0.0, -4.902, -4.902]}
{"number_of_episodes": 5506, "number_of_timesteps": 84769, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1908, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1909.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1909.0, 1909.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 5511, "number_of_timesteps": 84911, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1909, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1910.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1910.0, 1910.0], "q_vals": [0.0, 0.0, -4.992, 0.0, 0.0, 0.0, 0.0, 0.0, -4.899, -4.899]}
{"number_of_episodes": 5511, "number_of_timesteps": 84911, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1910, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1911.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1911.0, 1911.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.902, -4.902]}
{"step": 1911, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1912.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1912.0, 1912.0], "q_vals": [0.0, 0.0, -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"number_of_episodes": 5519, "number_of_timesteps": 85010, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1912, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1913.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1913.0, 1913.0], "q_vals": [0.0, 0.0, -4.999, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"number_of_episodes": 5520, "number_of_timesteps": 85028, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1913, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1914.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1914.0, 1914.0], "q_vals": [0.0, 0.0, -5.001, 0.0, 0.0, 0.0, 0.0, 0.0, -4.906, -4.906]}
{"number_of_episodes": 5524, "number_of_timesteps": 85091, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1914, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1915.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1915.0, 1915.0], "q_vals": [0.0, 0.0, -4.998, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"step": 1915, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1916.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1916.0, 1916.0], "q_vals": [0.0, 0.0, -4.995, 0.0, 0.0, 0.0, 0.0, 0.0, -4.905, -4.905]}
{"number_of_episodes": 5530, "number_of_timesteps": 85176, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1916, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1917.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1917.0, 1917.0], "q_vals": [0.0, 0.0, -5.001, 0.0, 0.0, 0.0, 0.0, 0.0, -4.909, -4.909]}
{"number_of_episodes": 5535, "number_of_timesteps": 85250, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1917, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1918.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1918.0, 1918.0], "q_vals": [0.0, 0.0, -4.998, 0.0, 0.0, 0.0, 0.0, 0.0, -4.907, -4.907]}
{"number_of_episodes": 5538, "number_of_timesteps": 85288, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1918, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1919.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1919.0, 1919.0], "q_vals": [0.0, 0.0, -4.999, 0.0, 0.0, 0.0, 0.0, 0.0, -4.907, -4.907]}
{"step": 1919, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1920.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1920.0, 1920.0], "q_vals": [0.0, 0.0, -5.002, 0.0, 0.0, 0.0, 0.0, 0.0, -4.91, -4.91]}
{"number_of_episodes": 5543, "number_of_timesteps": 85364, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1920, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1921.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1921.0, 1921.0], "q_vals": [0.0, 0.0, -5.008, 0.0, 0.0, 0.0, 0.0, 0.0, -4.915, -4.915]}
{"step": 1921, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1922.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1922.0, 1922.0], "q_vals": [0.0, 0.0, -5.009, 0.0, 0.0, 0.0, 0.0, 0.0, -4.915, -4.915]}
{"number_of_episodes": 5548, "number_of_timesteps": 85442, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1922, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1923.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1923.0, 1923.0], "q_vals": [0.0, 0.0, -5.006, 0.0, 0.0, 0.0, 0.0, 0.0, -4.913, -4.913]}
{"step": 1923, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1924.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1924.0, 1924.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.918, -4.918]}
{"step": 1924, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1925.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1925.0, 1925.0], "q_vals": [0.0, 0.0, -5.009, 0.0, 0.0, 0.0, 0.0, 0.0, -4.915, -4.915]}
{"number_of_episodes": 5555, "number_of_timesteps": 85535, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1925, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1926.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1926.0, 1926.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.917, -4.917]}
{"number_of_episodes": 5558, "number_of_timesteps": 85584, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1926, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1927.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1927.0, 1927.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.917, -4.917]}
{"number_of_episodes": 5559, "number_of_timesteps": 85633, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1927, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1928.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1928.0, 1928.0], "q_vals": [0.0, 0.0, -5.013, 0.0, 0.0, 0.0, 0.0, 0.0, -4.917, -4.917]}
{"number_of_episodes": 5564, "number_of_timesteps": 85714, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1928, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1929.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1929.0, 1929.0], "q_vals": [0.0, 0.0, -5.012, 0.0, 0.0, 0.0, 0.0, 0.0, -4.917, -4.917]}
{"number_of_episodes": 5566, "number_of_timesteps": 85735, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1929, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1930.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1930.0, 1930.0], "q_vals": [0.0, 0.0, -5.01, 0.0, 0.0, 0.0, 0.0, 0.0, -4.914, -4.914]}
{"step": 1930, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1931.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1931.0, 1931.0], "q_vals": [0.0, 0.0, -5.01, 0.0, 0.0, 0.0, 0.0, 0.0, -4.914, -4.914]}
{"step": 1931, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1932.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1932.0, 1932.0], "q_vals": [0.0, 0.0, -5.008, 0.0, 0.0, 0.0, 0.0, 0.0, -4.912, -4.912]}
{"number_of_episodes": 5571, "number_of_timesteps": 85841, "per_episode_reward": 13.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1932, "successfully_filtered": 1, "filter_choice": [0, 0, 1, 0, 0, 0, 0, 0, 1, 1], "process_temp_banned_count": [1.0, 1.0, 1933.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1933.0, 1933.0], "q_vals": [0.0, 0.0, -5.008, 0.0, 0.0, 0.0, 0.0, 0.0, -4.912, -4.912]}
exited at individual_updates_contributed_barrier.wait(): 6, error = attempt to release recursive lock not owned by thread
None
exited at individual_updates_contributed_barrier.wait(): 2, error = attempt to release recursive lock not owned by thread
None
Traceback (most recent call last):
  File "/home/jeffhykin/repos/bizav/examples/atari/reproduction/a3c/comparison.py", line 79, in main
    fitness_values = [ float(train_a3c.outer_training_function(args)) for each in range(runs_for_comparison) ]
  File "/home/jeffhykin/repos/bizav/examples/atari/reproduction/a3c/comparison.py", line 79, in <listcomp>
    fitness_values = [ float(train_a3c.outer_training_function(args)) for each in range(runs_for_comparison) ]
  File "/home/jeffhykin/repos/bizav/examples/atari/reproduction/a3c/train_a3c.py", line 268, in outer_training_function
    experiments.middle_training_function(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 778, in middle_training_function
    async_.run_async(config.number_of_processes, run_func)
  File "/home/jeffhykin/repos/bizav/pfrl/utils/async_.py", line 28, in run_async
    each_process.join()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 47, in wait
    return self.poll(os.WNOHANG if timeout == 0.0 else 0)
  File "/usr/lib/python3.8/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
Process Process-6:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 769, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 745, in <lambda>
    f = lambda : inner_training_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 225, in inner_training_loop
    action = agent.act(observation)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 283, in act
    return self._act_train(obs)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 310, in _act_train
    pout, vout = self.model(statevar)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/nn/branched.py", line 30, in forward
    return tuple(mod(*args, **kwargs) for mod in self.child_modules)
  File "/home/jeffhykin/repos/bizav/pfrl/nn/branched.py", line 30, in <genexpr>
    return tuple(mod(*args, **kwargs) for mod in self.child_modules)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/policies/softmax_policy.py", line 7, in forward
    return torch.distributions.Categorical(logits=logits)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/distributions/categorical.py", line 64, in __init__
    super(Categorical, self).__init__(batch_shape, validate_args=validate_args)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/distributions/distribution.py", line 53, in __init__
    valid = constraint.check(value)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/distributions/constraints.py", line 214, in check
    result = result.all(-1)
KeyboardInterrupt
Process Process-9:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 769, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 745, in <lambda>
    f = lambda : inner_training_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 225, in inner_training_loop
    action = agent.act(observation)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 283, in act
    return self._act_train(obs)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 310, in _act_train
    pout, vout = self.model(statevar)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/nn/branched.py", line 30, in forward
    return tuple(mod(*args, **kwargs) for mod in self.child_modules)
  File "/home/jeffhykin/repos/bizav/pfrl/nn/branched.py", line 30, in <genexpr>
    return tuple(mod(*args, **kwargs) for mod in self.child_modules)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py", line 102, in forward
    def forward(self, input: Tensor) -> Tensor:
KeyboardInterrupt
Process Process-4:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 769, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 745, in <lambda>
    f = lambda : inner_training_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 245, in inner_training_loop
    individual_updates_contributed_barrier.wait()   # Wait for all agents to contribute their gradients to global model, the sync_updates() to step it's optimizer
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 268, in wait
    self._lock.acquire()
KeyboardInterrupt
Process Process-1:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 769, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 745, in <lambda>
    f = lambda : inner_training_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 249, in inner_training_loop
    agent.after_update()    # Each agent will download the global model after the optimizer steps
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 269, in after_update
    self.sync_parameters()
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 138, in sync_parameters
    copy_param.copy_param(target_link=self.model, source_link=self.shared_model)
  File "/home/jeffhykin/repos/bizav/pfrl/utils/copy_param.py", line 6, in copy_param
    target_link.load_state_dict(source_link.state_dict())
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1483, in load_state_dict
    load(self)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1481, in load
    load(child, prefix + name + '.')
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1477, in load
    module._load_from_state_dict(
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1400, in _load_from_state_dict
    is_param_lazy = torch.nn.parameter.is_lazy(param)
KeyboardInterrupt
Process Process-2:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 769, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 745, in <lambda>
    f = lambda : inner_training_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 232, in inner_training_loop
    agent.observe(observation, reward, done, reset)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 294, in observe
    self._observe_train(obs, reward, done, reset)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 351, in _observe_train
    self.update(statevar)
  File "/home/jeffhykin/repos/bizav/pfrl/agents/a3c.py", line 240, in update
    self.total_loss.backward()
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/jeffhykin/.local/lib/python3.8/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Process Process-8:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 769, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 745, in <lambda>
    f = lambda : inner_training_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 237, in inner_training_loop
    individual_updates_ready_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-10:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 769, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 745, in <lambda>
    f = lambda : inner_training_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 237, in inner_training_loop
    individual_updates_ready_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
Process Process-5:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 769, in run_func
    f()
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 745, in <lambda>
    f = lambda : inner_training_loop(
  File "/home/jeffhykin/repos/bizav/pfrl/experiments/train_agent_async.py", line 237, in inner_training_loop
    individual_updates_ready_barrier.wait()  # Wait for all agents to complete rollout, then run when_all_processes_are_updated()
  File "/usr/lib/python3.8/threading.py", line 619, in wait
    self._wait(timeout)
  File "/usr/lib/python3.8/threading.py", line 654, in _wait
    if not self._cond.wait_for(lambda : self._state != 0, timeout):
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 313, in wait_for
    self.wait(waittime)
  File "/usr/lib/python3.8/multiprocessing/synchronize.py", line 261, in wait
    return self._wait_semaphore.acquire(True, timeout)
KeyboardInterrupt
