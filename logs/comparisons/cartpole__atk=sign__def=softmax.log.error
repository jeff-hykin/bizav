config = {
    "evaluation": {
        "enabled": True, 
        "number_of_episodes_before_eval": 130, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": 125000, 
            "number_of_episodes": None, 
        }, 
    }, 
    "verbose": True, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "expected_number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": {
        0: 0.1, 
        1: 0.08, 
        2: 0.063, 
        3: 0.05, 
        4: 0.04, 
        5: 0.032, 
        6: 0.025, 
        7: 0.02, 
        8: 0.016, 
        9: 0.012, 
        10: 0.01, 
        11: 0.008, 
        12: 0.0063, 
        13: 0.005, 
        14: 0.004, 
        15: 0.0032, 
        16: 0.0025, 
        17: 0.002, 
        18: 0.0016, 
        19: 0.0012, 
        20: 0.001, 
        21: 0.0008, 
        22: 0.00063, 
        23: 0.0005, 
        24: 0.0004, 
        25: 0.00032, 
        26: 0.00025, 
        27: 0.0002, 
        28: 0.00016, 
        29: 0.00012, 
        30: 1e-05, 
        31: 8e-06, 
        32: 6.3e-06, 
        33: 5e-06, 
        34: 4e-06, 
        35: 3.2e-06, 
        36: 2.5e-06, 
        37: 2e-06, 
        38: 1.6e-06, 
        39: 1.2e-06, 
    }, 
    "defense_method": "softmax", 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": {0: 0, }, 
    "value_trend_lookback_size": 10, 
    "env_config": {
        "permaban_threshold": 1000, 
        "env_name": "CartPole-v1", 
        "learning_rate": 0.001, 
        "beta": 2e-05, 
        "t_max": 5, 
        "activation": 1, 
        "hidden_size": 64, 
        "variance_scaling_factor": 1, 
    }, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0, 
        "min_number_of_episodes": 30, 
        "thresholds": {}, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": {0: 0, 1: 1, 2: 2, }, }, 
            "sequential_options": {
                "t_max": {0: 3, 1: 5, 2: 10, 3: 20, 4: 30, 5: 50, }, 
                "hidden_size": {0: 16, 1: 32, 2: 64, 3: 128, }, 
                "learning_rate": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
                "beta": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
                "beta": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 21000, }, 
}
args = {
    "processes": 10, 
    "env": "CartPole-v1", 
    "seed": 510160310, 
    "outdir": "results", 
    "t_max": 5, 
    "beta": 2e-05, 
    "profile": False, 
    "steps": 21000, 
    "max_frames": (108000, ), 
    "lr": 0.001, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 1000, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 1, 
}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting run_func()]
[starting train_loop()]
[starting train_loop()]
[starting run_func()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting run_func()]
[starting train_loop()]
[starting train_loop()]
[starting train_loop()]
[starting run_func()]
[starting run_func()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
[starting train_loop()]
[starting run_func()]
[starting train_loop()]
{"step": 0, "filter_choice": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "process_temp_banned_count": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "q_vals": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
{"step": 1, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0], "q_vals": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
{"step": 2, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -1.33, 0.0, 0.0, 0.0, 0.0, -1.33, 0.0, 0.0, 0.0]}
{"step": 3, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4.0, 1.0, 1.0, 1.0, 4.0, 4.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -1.94, 0.0, 0.0, 0.0, 0.0, -1.94, 0.0, 0.0, 0.0]}
{"step": 4, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5.0, 1.0, 1.0, 1.0, 5.0, 5.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -2.598, 0.0, 0.0, 0.0, 0.0, -2.598, 0.0, 0.0, 0.0]}
{"step": 5, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 6.0, 1.0, 1.0, 1.0, 6.0, 6.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -2.165, 0.0, 0.0, 0.0, 0.0, -2.165, 0.0, 0.0, 0.0]}
{"step": 6, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 7.0, 1.0, 1.0, 1.0, 7.0, 7.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -2.402, 0.0, 0.0, 0.0, -0.547, -2.402, 0.0, 0.0, 0.0]}
{"step": 7, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 8.0, 1.0, 1.0, 1.0, 8.0, 8.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -2.102, 0.0, 0.0, 0.0, -0.478, -2.102, 0.0, 0.0, 0.0]}
{"step": 8, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 9.0, 1.0, 1.0, 1.0, 9.0, 9.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.705, 0.0, 0.0, 0.0, -2.262, -3.705, 0.0, 0.0, 0.0]}
{"step": 9, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 10.0, 1.0, 1.0, 1.0, 10.0, 10.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.698, 0.0, 0.0, 0.0, -2.399, -3.335, 0.0, 0.0, 0.0]}
{"step": 10, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 11.0, 1.0, 1.0, 1.0, 11.0, 11.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.362, 0.0, 0.0, 0.0, -2.181, -3.031, 0.0, 0.0, 0.0]}
{"step": 11, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 12.0, 1.0, 1.0, 1.0, 12.0, 12.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.423, 0.0, 0.0, 0.0, -2.341, -3.12, 0.0, 0.0, 0.0]}
{"step": 12, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 13.0, 1.0, 1.0, 1.0, 13.0, 13.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.16, 0.0, 0.0, 0.0, -2.161, -2.88, 0.0, 0.0, 0.0]}
{"step": 13, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 14.0, 1.0, 1.0, 1.0, 14.0, 14.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.256, 0.0, 0.0, 0.0, -2.328, -2.675, 0.0, 0.0, 0.0]}
{"step": 14, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 15.0, 1.0, 1.0, 1.0, 15.0, 15.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.039, 0.0, 0.0, 0.0, -2.811, -3.135, 0.0, 0.0, 0.0]}
{"step": 15, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 16.0, 1.0, 1.0, 1.0, 16.0, 16.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.078, 0.0, 0.0, 0.0, -2.865, -2.939, 0.0, 0.0, 0.0]}
{"step": 16, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 17.0, 1.0, 1.0, 1.0, 17.0, 17.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.196, 0.0, 0.0, 0.0, -2.995, -2.766, 0.0, 0.0, 0.0]}
{"number_of_episodes": 31, "number_of_timesteps": 683, "per_episode_reward": 21.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 17, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 18.0, 1.0, 1.0, 1.0, 18.0, 18.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.018, 0.0, 0.0, 0.0, -2.829, -2.612, 0.0, 0.0, 0.0]}
{"number_of_episodes": 33, "number_of_timesteps": 723, "per_episode_reward": 21.15, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 18, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 19.0, 1.0, 1.0, 1.0, 19.0, 19.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.595, 0.0, 0.0, 0.0, -3.416, -3.211, 0.0, 0.0, 0.0]}
{"number_of_episodes": 35, "number_of_timesteps": 750, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 19, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 20.0, 1.0, 1.0, 1.0, 20.0, 20.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.416, 0.0, 0.0, 0.0, -3.245, -3.051, 0.0, 0.0, 0.0]}
{"number_of_episodes": 35, "number_of_timesteps": 750, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 20, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 21.0, 1.0, 1.0, 1.0, 21.0, 21.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.567, 0.0, 0.0, 0.0, -3.405, -3.22, 0.0, 0.0, 0.0]}
{"step": 21, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 22.0, 1.0, 1.0, 1.0, 22.0, 22.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.581, 0.0, 0.0, 0.0, -3.426, -3.249, 0.0, 0.0, 0.0]}
{"step": 22, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 23.0, 1.0, 1.0, 1.0, 23.0, 23.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.622, 0.0, 0.0, 0.0, -3.474, -3.305, 0.0, 0.0, 0.0]}
{"step": 23, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 24.0, 1.0, 1.0, 1.0, 24.0, 24.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.658, 0.0, 0.0, 0.0, -3.516, -3.354, 0.0, 0.0, 0.0]}
{"number_of_episodes": 45, "number_of_timesteps": 976, "per_episode_reward": 21.1, "episode_reward_trend_value": -0.004999999999999716, "biggest_recent_change": NaN},
{"step": 24, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 25.0, 1.0, 1.0, 1.0, 25.0, 25.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.889, 0.0, 0.0, 0.0, -3.753, -3.597, 0.0, 0.0, 0.0]}
{"number_of_episodes": 46, "number_of_timesteps": 996, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.06999999999999992, "biggest_recent_change": NaN},
{"step": 25, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 26.0, 1.0, 1.0, 1.0, 26.0, 26.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.739, 0.0, 0.0, 0.0, -3.608, -3.459, 0.0, 0.0, 0.0]}
{"number_of_episodes": 49, "number_of_timesteps": 1057, "per_episode_reward": 21.65, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 26, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 27.0, 1.0, 1.0, 1.0, 27.0, 27.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.836, 0.0, 0.0, 0.0, -3.71, -3.566, 0.0, 0.0, 0.0]}
{"number_of_episodes": 52, "number_of_timesteps": 1166, "per_episode_reward": 21.65, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 27, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 28.0, 1.0, 1.0, 1.0, 28.0, 28.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.699, 0.0, 0.0, 0.0, -4.0, -3.861, 0.0, 0.0, 0.0]}
{"number_of_episodes": 52, "number_of_timesteps": 1166, "per_episode_reward": 21.65, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 28, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 29.0, 1.0, 1.0, 1.0, 29.0, 29.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.701, 0.0, 0.0, 0.0, -3.991, -3.728, 0.0, 0.0, 0.0]}
{"number_of_episodes": 55, "number_of_timesteps": 1220, "per_episode_reward": 21.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 29, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 30.0, 1.0, 1.0, 1.0, 30.0, 30.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.749, 0.0, 0.0, 0.0, -3.858, -3.775, 0.0, 0.0, 0.0]}
{"number_of_episodes": 56, "number_of_timesteps": 1248, "per_episode_reward": 21.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 30, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 31.0, 1.0, 1.0, 1.0, 31.0, 31.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.628, 0.0, 0.0, 0.0, -3.734, -3.653, 0.0, 0.0, 0.0]}
{"step": 31, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 32.0, 1.0, 1.0, 1.0, 32.0, 32.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.515, 0.0, 0.0, 0.0, -4.016, -3.938, 0.0, 0.0, 0.0]}
{"number_of_episodes": 63, "number_of_timesteps": 1408, "per_episode_reward": 21.65, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 32, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 33.0, 1.0, 1.0, 1.0, 33.0, 33.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.554, 0.0, 0.0, 0.0, -4.04, -3.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 65, "number_of_timesteps": 1451, "per_episode_reward": 21.75, "episode_reward_trend_value": 0.057499999999999926, "biggest_recent_change": NaN},
{"step": 33, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 34.0, 1.0, 1.0, 1.0, 34.0, 34.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.449, 0.0, 0.0, 0.0, -3.921, -3.848, 0.0, 0.0, 0.0]}
{"step": 34, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 35.0, 1.0, 1.0, 1.0, 35.0, 35.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.351, 0.0, 0.0, 0.0, -3.809, -3.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 69, "number_of_timesteps": 1527, "per_episode_reward": 22.1, "episode_reward_trend_value": 0.05500000000000007, "biggest_recent_change": NaN},
{"step": 35, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 36.0, 1.0, 1.0, 1.0, 36.0, 36.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.258, 0.0, 0.0, 0.0, -3.703, -3.634, 0.0, 0.0, 0.0]}
{"number_of_episodes": 72, "number_of_timesteps": 1564, "per_episode_reward": 21.35, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 36, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 37.0, 1.0, 1.0, 1.0, 37.0, 37.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.285, 0.0, 0.0, 0.0, -3.719, -3.651, 0.0, 0.0, 0.0]}
{"number_of_episodes": 73, "number_of_timesteps": 1585, "per_episode_reward": 21.55, "episode_reward_trend_value": 0.020000000000000108, "biggest_recent_change": NaN},
{"step": 37, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 38.0, 1.0, 1.0, 1.0, 38.0, 38.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.481, 0.0, 0.0, 0.0, -3.904, -3.838, 0.0, 0.0, 0.0]}
{"step": 38, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 39.0, 1.0, 1.0, 1.0, 39.0, 39.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.642, 0.0, 0.0, 0.0, -4.053, -3.989, 0.0, 0.0, 0.0]}
{"number_of_episodes": 75, "number_of_timesteps": 1630, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.11999999999999993, "biggest_recent_change": NaN},
{"step": 39, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 40.0, 1.0, 1.0, 1.0, 40.0, 40.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.664, 0.0, 0.0, 0.0, -4.065, -4.002, 0.0, 0.0, 0.0]}
{"number_of_episodes": 77, "number_of_timesteps": 1689, "per_episode_reward": 21.65, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
{"step": 40, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 41.0, 1.0, 1.0, 1.0, 41.0, 41.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.574, 0.0, 0.0, 0.0, -4.208, -4.147, 0.0, 0.0, 0.0]}
{"step": 41, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 42.0, 1.0, 1.0, 1.0, 42.0, 42.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.514, 0.0, 0.0, 0.0, -4.132, -4.073, 0.0, 0.0, 0.0]}
{"step": 42, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 43.0, 1.0, 1.0, 1.0, 43.0, 43.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.687, 0.0, 0.0, 0.0, -4.291, -4.233, 0.0, 0.0, 0.0]}
{"number_of_episodes": 84, "number_of_timesteps": 1857, "per_episode_reward": 22.1, "episode_reward_trend_value": 0.02250000000000014, "biggest_recent_change": NaN},
{"step": 43, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 44.0, 1.0, 1.0, 1.0, 44.0, 44.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.695, 0.0, 0.0, 0.0, -4.285, -4.228, 0.0, 0.0, 0.0]}
{"number_of_episodes": 86, "number_of_timesteps": 1884, "per_episode_reward": 21.9, "episode_reward_trend_value": 0.05, "biggest_recent_change": NaN},
{"step": 44, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 45.0, 1.0, 1.0, 1.0, 45.0, 45.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.716, 0.0, 0.0, 0.0, -4.19, -4.238, 0.0, 0.0, 0.0]}
{"number_of_episodes": 86, "number_of_timesteps": 1884, "per_episode_reward": 21.9, "episode_reward_trend_value": 0.025, "biggest_recent_change": NaN},
{"step": 45, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 46.0, 1.0, 1.0, 1.0, 46.0, 46.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.853, 0.0, 0.0, 0.0, -4.317, -4.364, 0.0, 0.0, 0.0]}
{"number_of_episodes": 89, "number_of_timesteps": 1944, "per_episode_reward": 21.3, "episode_reward_trend_value": -0.005000000000000071, "biggest_recent_change": NaN},
{"step": 46, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 47.0, 1.0, 1.0, 1.0, 47.0, 47.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.876, 0.0, 0.0, 0.0, -4.33, -4.375, 0.0, 0.0, 0.0]}
{"step": 47, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 48.0, 1.0, 1.0, 1.0, 48.0, 48.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.886, 0.0, 0.0, 0.0, -4.33, -4.375, 0.0, 0.0, 0.0]}
{"step": 48, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 49.0, 1.0, 1.0, 1.0, 49.0, 49.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.892, 0.0, 0.0, 0.0, -4.242, -4.371, 0.0, 0.0, 0.0]}
{"number_of_episodes": 96, "number_of_timesteps": 2164, "per_episode_reward": 21.35, "episode_reward_trend_value": 0.025, "biggest_recent_change": NaN},
{"step": 49, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 50.0, 1.0, 1.0, 1.0, 50.0, 50.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.814, 0.0, 0.0, 0.0, -4.157, -4.284, 0.0, 0.0, 0.0]}
{"number_of_episodes": 100, "number_of_timesteps": 2224, "per_episode_reward": 20.85, "episode_reward_trend_value": 0.0125, "biggest_recent_change": NaN},
{"step": 50, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 51.0, 1.0, 1.0, 1.0, 51.0, 51.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.811, 0.0, 0.0, 0.0, -4.147, -4.272, 0.0, 0.0, 0.0]}
{"number_of_episodes": 103, "number_of_timesteps": 2291, "per_episode_reward": 20.4, "episode_reward_trend_value": -0.04166666666666667, "biggest_recent_change": NaN},
{"step": 51, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 52.0, 1.0, 1.0, 1.0, 52.0, 52.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.826, 0.0, 0.0, 0.0, -4.156, -4.278, 0.0, 0.0, 0.0]}
{"step": 52, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 53.0, 1.0, 1.0, 1.0, 53.0, 53.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.835, 0.0, 0.0, 0.0, -4.158, -4.278, 0.0, 0.0, 0.0]}
{"number_of_episodes": 105, "number_of_timesteps": 2320, "per_episode_reward": 19.9, "episode_reward_trend_value": -0.03125, "biggest_recent_change": NaN},
{"step": 53, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 54.0, 1.0, 1.0, 1.0, 54.0, 54.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.948, 0.0, 0.0, 0.0, -4.266, -4.383, 0.0, 0.0, 0.0]}
{"step": 54, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 55.0, 1.0, 1.0, 1.0, 55.0, 55.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.973, 0.0, 0.0, 0.0, -4.284, -4.4, 0.0, 0.0, 0.0]}
{"number_of_episodes": 109, "number_of_timesteps": 2410, "per_episode_reward": 20.35, "episode_reward_trend_value": -0.06499999999999986, "biggest_recent_change": NaN},
{"step": 55, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 56.0, 1.0, 1.0, 1.0, 56.0, 56.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.902, 0.0, 0.0, 0.0, -4.432, -4.546, 0.0, 0.0, 0.0]}
{"step": 56, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 57.0, 1.0, 1.0, 1.0, 57.0, 57.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.907, 0.0, 0.0, 0.0, -4.428, -4.539, 0.0, 0.0, 0.0]}
{"number_of_episodes": 111, "number_of_timesteps": 2463, "per_episode_reward": 20.45, "episode_reward_trend_value": -0.11999999999999993, "biggest_recent_change": NaN},
{"step": 57, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 58.0, 1.0, 1.0, 1.0, 58.0, 58.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.907, 0.0, 0.0, 0.0, -4.419, -4.461, 0.0, 0.0, 0.0]}
{"number_of_episodes": 114, "number_of_timesteps": 2521, "per_episode_reward": 20.2, "episode_reward_trend_value": -0.013333333333333405, "biggest_recent_change": NaN},
{"step": 58, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 59.0, 1.0, 1.0, 1.0, 59.0, 59.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.931, 0.0, 0.0, 0.0, -4.435, -4.476, 0.0, 0.0, 0.0]}
{"number_of_episodes": 115, "number_of_timesteps": 2557, "per_episode_reward": 20.5, "episode_reward_trend_value": -0.04499999999999993, "biggest_recent_change": NaN},
{"step": 59, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 60.0, 1.0, 1.0, 1.0, 60.0, 60.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.95, 0.0, 0.0, 0.0, -4.361, -4.485, 0.0, 0.0, 0.0]}
{"number_of_episodes": 118, "number_of_timesteps": 2640, "per_episode_reward": 21.1, "episode_reward_trend_value": -0.0125, "biggest_recent_change": NaN},
{"step": 60, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 61.0, 1.0, 1.0, 1.0, 61.0, 61.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.951, 0.0, 0.0, 0.0, -4.356, -4.478, 0.0, 0.0, 0.0]}
{"step": 61, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 62.0, 1.0, 1.0, 1.0, 62.0, 62.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.888, 0.0, 0.0, 0.0, -4.425, -4.545, 0.0, 0.0, 0.0]}
{"number_of_episodes": 121, "number_of_timesteps": 2687, "per_episode_reward": 20.9, "episode_reward_trend_value": -0.0375, "biggest_recent_change": NaN},
{"step": 62, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 63.0, 1.0, 1.0, 1.0, 63.0, 63.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.842, 0.0, 0.0, 0.0, -4.371, -4.473, 0.0, 0.0, 0.0]}
{"step": 63, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 64.0, 1.0, 1.0, 1.0, 64.0, 64.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.838, 0.0, 0.0, 0.0, -4.359, -4.403, 0.0, 0.0, 0.0]}
{"number_of_episodes": 124, "number_of_timesteps": 2776, "per_episode_reward": 20.95, "episode_reward_trend_value": 0.008749999999999947, "biggest_recent_change": NaN},
{"step": 64, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 65.0, 1.0, 1.0, 1.0, 65.0, 65.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.86, 0.0, 0.0, 0.0, -4.372, -4.416, 0.0, 0.0, 0.0]}
{"number_of_episodes": 128, "number_of_timesteps": 2858, "per_episode_reward": 21.3, "episode_reward_trend_value": -0.0125, "biggest_recent_change": NaN},
{"step": 65, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 66.0, 1.0, 1.0, 1.0, 66.0, 66.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.801, 0.0, 0.0, 0.0, -4.306, -4.349, 0.0, 0.0, 0.0]}
{"number_of_episodes": 129, "number_of_timesteps": 2871, "per_episode_reward": 21.3, "episode_reward_trend_value": -0.011666666666666596, "biggest_recent_change": NaN},
{"step": 66, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 67.0, 1.0, 1.0, 1.0, 67.0, 67.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.745, 0.0, 0.0, 0.0, -4.424, -4.467, 0.0, 0.0, 0.0]}
{"eval_score": 30.2, "number_of_episodes": 130}
{"number_of_episodes": 130, "number_of_timesteps": 2880, "per_episode_reward": 21.3, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": NaN},
{"step": 67, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 68.0, 1.0, 1.0, 1.0, 68.0, 68.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.785, 0.0, 0.0, 0.0, -4.455, -4.497, 0.0, 0.0, 0.0]}
{"step": 68, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 69.0, 1.0, 1.0, 1.0, 69.0, 69.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.821, 0.0, 0.0, 0.0, -4.482, -4.523, 0.0, 0.0, 0.0]}
{"number_of_episodes": 136, "number_of_timesteps": 3078, "per_episode_reward": 21.3, "episode_reward_trend_value": -0.0033333333333332624, "biggest_recent_change": NaN},
{"step": 69, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 70.0, 1.0, 1.0, 1.0, 70.0, 70.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.843, 0.0, 0.0, 0.0, -4.418, -4.534, 0.0, 0.0, 0.0]}
{"number_of_episodes": 138, "number_of_timesteps": 3115, "per_episode_reward": 21.35, "episode_reward_trend_value": 0.01875, "biggest_recent_change": NaN},
{"step": 70, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 71.0, 1.0, 1.0, 1.0, 71.0, 71.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.789, 0.0, 0.0, 0.0, -4.355, -4.47, 0.0, 0.0, 0.0]}
{"step": 71, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 72.0, 1.0, 1.0, 1.0, 72.0, 72.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.736, 0.0, 0.0, 0.0, -4.295, -4.408, 0.0, 0.0, 0.0]}
{"step": 72, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 73.0, 1.0, 1.0, 1.0, 73.0, 73.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.685, 0.0, 0.0, 0.0, -4.236, -4.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 144, "number_of_timesteps": 3260, "per_episode_reward": 21.35, "episode_reward_trend_value": 0.004000000000000057, "biggest_recent_change": NaN},
{"step": 73, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 74.0, 1.0, 1.0, 1.0, 74.0, 74.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.821, 0.0, 0.0, 0.0, -4.364, -4.474, 0.0, 0.0, 0.0]}
{"step": 74, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 75.0, 1.0, 1.0, 1.0, 75.0, 75.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.77, 0.0, 0.0, 0.0, -4.306, -4.415, 0.0, 0.0, 0.0]}
{"number_of_episodes": 148, "number_of_timesteps": 3331, "per_episode_reward": 20.95, "episode_reward_trend_value": -0.011249999999999982, "biggest_recent_change": NaN},
{"step": 75, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 76.0, 1.0, 1.0, 1.0, 76.0, 76.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.78, 0.0, 0.0, 0.0, -4.25, -4.417, 0.0, 0.0, 0.0]}
{"number_of_episodes": 148, "number_of_timesteps": 3331, "per_episode_reward": 20.95, "episode_reward_trend_value": 0.006999999999999958, "biggest_recent_change": NaN},
{"step": 76, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 77.0, 1.0, 1.0, 1.0, 77.0, 77.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.803, 0.0, 0.0, 0.0, -4.267, -4.432, 0.0, 0.0, 0.0]}
{"number_of_episodes": 153, "number_of_timesteps": 3440, "per_episode_reward": 20.5, "episode_reward_trend_value": -0.03833333333333329, "biggest_recent_change": NaN},
{"step": 77, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 78.0, 1.0, 1.0, 1.0, 78.0, 78.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.842, 0.0, 0.0, 0.0, -4.299, -4.375, 0.0, 0.0, 0.0]}
{"number_of_episodes": 154, "number_of_timesteps": 3452, "per_episode_reward": 20.4, "episode_reward_trend_value": -0.03125, "biggest_recent_change": NaN},
{"step": 78, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 79.0, 1.0, 1.0, 1.0, 79.0, 79.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.793, 0.0, 0.0, 0.0, -4.366, -4.44, 0.0, 0.0, 0.0]}
{"number_of_episodes": 155, "number_of_timesteps": 3461, "per_episode_reward": 20.25, "episode_reward_trend_value": -0.03499999999999996, "biggest_recent_change": NaN},
{"step": 79, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 80.0, 1.0, 1.0, 1.0, 80.0, 80.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.794, 0.0, 0.0, 0.0, -4.359, -4.432, 0.0, 0.0, 0.0]}
{"number_of_episodes": 157, "number_of_timesteps": 3485, "per_episode_reward": 20.1, "episode_reward_trend_value": -0.14499999999999993, "biggest_recent_change": NaN},
{"step": 80, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 81.0, 1.0, 1.0, 1.0, 81.0, 81.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.747, 0.0, 0.0, 0.0, -4.305, -4.377, 0.0, 0.0, 0.0]}
{"step": 81, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 82.0, 1.0, 1.0, 1.0, 82.0, 82.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.701, 0.0, 0.0, 0.0, -4.372, -4.444, 0.0, 0.0, 0.0]}
{"number_of_episodes": 163, "number_of_timesteps": 3686, "per_episode_reward": 20.4, "episode_reward_trend_value": -0.0383333333333334, "biggest_recent_change": NaN},
{"step": 82, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 83.0, 1.0, 1.0, 1.0, 83.0, 83.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.656, 0.0, 0.0, 0.0, -4.32, -4.39, 0.0, 0.0, 0.0]}
{"number_of_episodes": 163, "number_of_timesteps": 3686, "per_episode_reward": 20.4, "episode_reward_trend_value": -0.0125, "biggest_recent_change": NaN},
{"step": 83, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 84.0, 1.0, 1.0, 1.0, 84.0, 84.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.754, 0.0, 0.0, 0.0, -4.409, -4.479, 0.0, 0.0, 0.0]}
{"number_of_episodes": 166, "number_of_timesteps": 3734, "per_episode_reward": 20.4, "episode_reward_trend_value": -0.03125, "biggest_recent_change": NaN},
{"step": 84, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 85.0, 1.0, 1.0, 1.0, 85.0, 85.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.739, 0.0, 0.0, 0.0, -4.387, -4.426, 0.0, 0.0, 0.0]}
{"number_of_episodes": 168, "number_of_timesteps": 3771, "per_episode_reward": 20.25, "episode_reward_trend_value": -0.007000000000000029, "biggest_recent_change": NaN},
{"step": 85, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 86.0, 1.0, 1.0, 1.0, 86.0, 86.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.696, 0.0, 0.0, 0.0, -4.336, -4.375, 0.0, 0.0, 0.0]}
{"step": 86, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 87.0, 1.0, 1.0, 1.0, 87.0, 87.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.653, 0.0, 0.0, 0.0, -4.286, -4.324, 0.0, 0.0, 0.0]}
{"number_of_episodes": 171, "number_of_timesteps": 3866, "per_episode_reward": 20.35, "episode_reward_trend_value": -0.025, "biggest_recent_change": NaN},
{"step": 87, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 88.0, 1.0, 1.0, 1.0, 88.0, 88.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.676, 0.0, 0.0, 0.0, -4.302, -4.34, 0.0, 0.0, 0.0]}
{"step": 88, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 89.0, 1.0, 1.0, 1.0, 89.0, 89.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.635, 0.0, 0.0, 0.0, -4.253, -4.291, 0.0, 0.0, 0.0]}
{"number_of_episodes": 174, "number_of_timesteps": 3945, "per_episode_reward": 20.5, "episode_reward_trend_value": -0.022999999999999972, "biggest_recent_change": NaN},
{"step": 89, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 90.0, 1.0, 1.0, 1.0, 90.0, 90.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.595, 0.0, 0.0, 0.0, -4.339, -4.376, 0.0, 0.0, 0.0]}
{"number_of_episodes": 175, "number_of_timesteps": 3959, "per_episode_reward": 20.45, "episode_reward_trend_value": -0.023999999999999987, "biggest_recent_change": NaN},
{"step": 90, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 91.0, 1.0, 1.0, 1.0, 91.0, 91.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.614, 0.0, 0.0, 0.0, -4.351, -4.387, 0.0, 0.0, 0.0]}
{"number_of_episodes": 178, "number_of_timesteps": 4007, "per_episode_reward": 20.25, "episode_reward_trend_value": -0.005833333333333357, "biggest_recent_change": NaN},
{"step": 91, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 92.0, 1.0, 1.0, 1.0, 92.0, 92.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.645, 0.0, 0.0, 0.0, -4.373, -4.41, 0.0, 0.0, 0.0]}
{"step": 92, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 93.0, 1.0, 1.0, 1.0, 93.0, 93.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.651, 0.0, 0.0, 0.0, -4.372, -4.407, 0.0, 0.0, 0.0]}
{"number_of_episodes": 181, "number_of_timesteps": 4132, "per_episode_reward": 20.4, "episode_reward_trend_value": -0.02, "biggest_recent_change": NaN},
{"step": 93, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 94.0, 1.0, 1.0, 1.0, 94.0, 94.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.658, 0.0, 0.0, 0.0, -4.325, -4.407, 0.0, 0.0, 0.0]}
{"step": 94, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 95.0, 1.0, 1.0, 1.0, 95.0, 95.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.62, 0.0, 0.0, 0.0, -4.406, -4.486, 0.0, 0.0, 0.0]}
{"step": 95, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 96.0, 1.0, 1.0, 1.0, 96.0, 96.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.653, 0.0, 0.0, 0.0, -4.431, -4.511, 0.0, 0.0, 0.0]}
{"step": 96, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 97.0, 1.0, 1.0, 1.0, 97.0, 97.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.656, 0.0, 0.0, 0.0, -4.385, -4.505, 0.0, 0.0, 0.0]}
{"number_of_episodes": 189, "number_of_timesteps": 4311, "per_episode_reward": 20.75, "episode_reward_trend_value": -0.005714285714285694, "biggest_recent_change": NaN},
{"step": 97, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 98.0, 1.0, 1.0, 1.0, 98.0, 98.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.745, 0.0, 0.0, 0.0, -4.466, -4.585, 0.0, 0.0, 0.0]}
{"number_of_episodes": 190, "number_of_timesteps": 4400, "per_episode_reward": 20.85, "episode_reward_trend_value": -0.01749999999999998, "biggest_recent_change": NaN},
{"step": 98, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 99.0, 1.0, 1.0, 1.0, 99.0, 99.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.707, 0.0, 0.0, 0.0, -4.421, -4.538, 0.0, 0.0, 0.0]}
{"number_of_episodes": 191, "number_of_timesteps": 4418, "per_episode_reward": 20.85, "episode_reward_trend_value": -0.013333333333333286, "biggest_recent_change": NaN},
{"step": 99, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 100.0, 1.0, 1.0, 1.0, 100.0, 100.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.71, 0.0, 0.0, 0.0, -4.417, -4.533, 0.0, 0.0, 0.0]}
{"step": 100, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 101.0, 1.0, 1.0, 1.0, 101.0, 101.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.767, 0.0, 0.0, 0.0, -4.467, -4.582, 0.0, 0.0, 0.0]}
{"number_of_episodes": 197, "number_of_timesteps": 4552, "per_episode_reward": 20.65, "episode_reward_trend_value": 0.0007142857142856736, "biggest_recent_change": NaN},
{"step": 101, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 102.0, 1.0, 1.0, 1.0, 102.0, 102.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.778, 0.0, 0.0, 0.0, -4.471, -4.585, 0.0, 0.0, 0.0]}
{"step": 102, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 103.0, 1.0, 1.0, 1.0, 103.0, 103.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.758, 0.0, 0.0, 0.0, -4.444, -4.557, 0.0, 0.0, 0.0]}
{"number_of_episodes": 198, "number_of_timesteps": 4565, "per_episode_reward": 20.6, "episode_reward_trend_value": -0.013333333333333286, "biggest_recent_change": NaN},
{"step": 103, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 104.0, 1.0, 1.0, 1.0, 104.0, 104.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.777, 0.0, 0.0, 0.0, -4.402, -4.569, 0.0, 0.0, 0.0]}
{"number_of_episodes": 201, "number_of_timesteps": 4631, "per_episode_reward": 20.55, "episode_reward_trend_value": -0.0008333333333333451, "biggest_recent_change": NaN},
{"step": 104, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 105.0, 1.0, 1.0, 1.0, 105.0, 105.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.741, 0.0, 0.0, 0.0, -4.36, -4.525, 0.0, 0.0, 0.0]}
{"number_of_episodes": 203, "number_of_timesteps": 4677, "per_episode_reward": 20.55, "episode_reward_trend_value": -0.007499999999999974, "biggest_recent_change": NaN},
{"step": 105, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 106.0, 1.0, 1.0, 1.0, 106.0, 106.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.796, 0.0, 0.0, 0.0, -4.409, -4.572, 0.0, 0.0, 0.0]}
{"number_of_episodes": 205, "number_of_timesteps": 4766, "per_episode_reward": 20.75, "episode_reward_trend_value": -0.012000000000000028, "biggest_recent_change": NaN},
{"step": 106, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 107.0, 1.0, 1.0, 1.0, 107.0, 107.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.816, 0.0, 0.0, 0.0, -4.423, -4.585, 0.0, 0.0, 0.0]}
{"number_of_episodes": 207, "number_of_timesteps": 4794, "per_episode_reward": 20.7, "episode_reward_trend_value": -0.018999999999999986, "biggest_recent_change": NaN},
{"step": 107, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 108.0, 1.0, 1.0, 1.0, 108.0, 108.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.815, 0.0, 0.0, 0.0, -4.417, -4.543, 0.0, 0.0, 0.0]}
{"number_of_episodes": 210, "number_of_timesteps": 4846, "per_episode_reward": 20.65, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": NaN},
{"step": 108, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 109.0, 1.0, 1.0, 1.0, 109.0, 109.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.78, 0.0, 0.0, 0.0, -4.474, -4.599, 0.0, 0.0, 0.0]}
{"step": 109, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 110.0, 1.0, 1.0, 1.0, 110.0, 110.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.791, 0.0, 0.0, 0.0, -4.478, -4.557, 0.0, 0.0, 0.0]}
{"number_of_episodes": 213, "number_of_timesteps": 4961, "per_episode_reward": 20.8, "episode_reward_trend_value": 0.002499999999999991, "biggest_recent_change": NaN},
{"step": 110, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 111.0, 1.0, 1.0, 1.0, 111.0, 111.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.799, 0.0, 0.0, 0.0, -4.48, -4.558, 0.0, 0.0, 0.0]}
{"step": 111, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 112.0, 1.0, 1.0, 1.0, 112.0, 112.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.765, 0.0, 0.0, 0.0, -4.562, -4.64, 0.0, 0.0, 0.0]}
{"step": 112, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 113.0, 1.0, 1.0, 1.0, 113.0, 113.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.775, 0.0, 0.0, 0.0, -4.565, -4.642, 0.0, 0.0, 0.0]}
{"number_of_episodes": 220, "number_of_timesteps": 5097, "per_episode_reward": 20.75, "episode_reward_trend_value": -0.009285714285714265, "biggest_recent_change": NaN},
{"step": 113, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 114.0, 1.0, 1.0, 1.0, 114.0, 114.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.789, 0.0, 0.0, 0.0, -4.525, -4.649, 0.0, 0.0, 0.0]}
{"step": 114, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 115.0, 1.0, 1.0, 1.0, 115.0, 115.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.8, 0.0, 0.0, 0.0, -4.486, -4.653, 0.0, 0.0, 0.0]}
{"number_of_episodes": 225, "number_of_timesteps": 5193, "per_episode_reward": 20.6, "episode_reward_trend_value": -0.018999999999999986, "biggest_recent_change": NaN},
{"step": 115, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 116.0, 1.0, 1.0, 1.0, 116.0, 116.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.767, 0.0, 0.0, 0.0, -4.447, -4.612, 0.0, 0.0, 0.0]}
{"number_of_episodes": 228, "number_of_timesteps": 5237, "per_episode_reward": 20.45, "episode_reward_trend_value": -0.019999999999999987, "biggest_recent_change": NaN},
{"step": 116, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 117.0, 1.0, 1.0, 1.0, 117.0, 117.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.768, 0.0, 0.0, 0.0, -4.442, -4.573, 0.0, 0.0, 0.0]}
{"number_of_episodes": 229, "number_of_timesteps": 5260, "per_episode_reward": 20.45, "episode_reward_trend_value": -0.05500000000000007, "biggest_recent_change": NaN},
{"step": 117, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 118.0, 1.0, 1.0, 1.0, 118.0, 118.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.736, 0.0, 0.0, 0.0, -4.404, -4.534, 0.0, 0.0, 0.0]}
{"step": 118, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 119.0, 1.0, 1.0, 1.0, 119.0, 119.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.705, 0.0, 0.0, 0.0, -4.367, -4.496, 0.0, 0.0, 0.0]}
{"step": 119, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 120.0, 1.0, 1.0, 1.0, 120.0, 120.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.681, 0.0, 0.0, 0.0, -4.338, -4.459, 0.0, 0.0, 0.0]}
{"number_of_episodes": 238, "number_of_timesteps": 5471, "per_episode_reward": 20.35, "episode_reward_trend_value": -0.013124999999999965, "biggest_recent_change": NaN},
{"step": 120, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 121.0, 1.0, 1.0, 1.0, 121.0, 121.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.707, 0.0, 0.0, 0.0, -4.302, -4.478, 0.0, 0.0, 0.0]}
{"step": 121, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 122.0, 1.0, 1.0, 1.0, 122.0, 122.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.694, 0.0, 0.0, 0.0, -4.267, -4.459, 0.0, 0.0, 0.0]}
{"number_of_episodes": 242, "number_of_timesteps": 5536, "per_episode_reward": 20.2, "episode_reward_trend_value": -0.020714285714285706, "biggest_recent_change": NaN},
{"step": 122, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 123.0, 1.0, 1.0, 1.0, 123.0, 123.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.664, 0.0, 0.0, 0.0, -4.307, -4.499, 0.0, 0.0, 0.0]}
{"step": 123, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 124.0, 1.0, 1.0, 1.0, 124.0, 124.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.635, 0.0, 0.0, 0.0, -4.364, -4.554, 0.0, 0.0, 0.0]}
{"step": 124, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 125.0, 1.0, 1.0, 1.0, 125.0, 125.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.605, 0.0, 0.0, 0.0, -4.417, -4.605, 0.0, 0.0, 0.0]}
{"number_of_episodes": 248, "number_of_timesteps": 5653, "per_episode_reward": 20.45, "episode_reward_trend_value": -0.036666666666666715, "biggest_recent_change": NaN},
{"step": 125, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 126.0, 1.0, 1.0, 1.0, 126.0, 126.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.577, 0.0, 0.0, 0.0, -4.381, -4.568, 0.0, 0.0, 0.0]}
{"number_of_episodes": 251, "number_of_timesteps": 5729, "per_episode_reward": 20.4, "episode_reward_trend_value": -0.0028571428571428975, "biggest_recent_change": NaN},
{"step": 126, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 127.0, 1.0, 1.0, 1.0, 127.0, 127.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.549, 0.0, 0.0, 0.0, -4.347, -4.532, 0.0, 0.0, 0.0]}
{"number_of_episodes": 253, "number_of_timesteps": 5788, "per_episode_reward": 20.45, "episode_reward_trend_value": -0.018333333333333358, "biggest_recent_change": NaN},
{"step": 127, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 128.0, 1.0, 1.0, 1.0, 128.0, 128.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.521, 0.0, 0.0, 0.0, -4.313, -4.497, 0.0, 0.0, 0.0]}
{"number_of_episodes": 254, "number_of_timesteps": 5800, "per_episode_reward": 20.45, "episode_reward_trend_value": -0.017142857142857133, "biggest_recent_change": NaN},
{"step": 128, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 129.0, 1.0, 1.0, 1.0, 129.0, 129.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.526, 0.0, 0.0, 0.0, -4.312, -4.494, 0.0, 0.0, 0.0]}
{"number_of_episodes": 255, "number_of_timesteps": 5814, "per_episode_reward": 20.45, "episode_reward_trend_value": -0.015000000000000036, "biggest_recent_change": NaN},
{"step": 129, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 130.0, 1.0, 1.0, 1.0, 130.0, 130.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.552, 0.0, 0.0, 0.0, -4.332, -4.513, 0.0, 0.0, 0.0]}
{"number_of_episodes": 255, "number_of_timesteps": 5814, "per_episode_reward": 20.45, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 1.1999999999999993},
{"step": 130, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 131.0, 1.0, 1.0, 1.0, 131.0, 131.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.569, 0.0, 0.0, 0.0, -4.343, -4.522, 0.0, 0.0, 0.0]}
{"number_of_episodes": 258, "number_of_timesteps": 5890, "per_episode_reward": 20.5, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 2.0},
{"step": 131, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 132.0, 1.0, 1.0, 1.0, 132.0, 132.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.612, 0.0, 0.0, 0.0, -4.38, -4.559, 0.0, 0.0, 0.0]}
{"eval_score": 23.7, "number_of_episodes": 261}
{"number_of_episodes": 261, "number_of_timesteps": 5938, "per_episode_reward": 20.5, "episode_reward_trend_value": -0.01642857142857141, "biggest_recent_change": NaN},
{"step": 132, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 133.0, 1.0, 1.0, 1.0, 133.0, 133.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.617, 0.0, 0.0, 0.0, -4.379, -4.524, 0.0, 0.0, 0.0]}
{"number_of_episodes": 263, "number_of_timesteps": 6006, "per_episode_reward": 20.6, "episode_reward_trend_value": -0.023749999999999983, "biggest_recent_change": NaN},
{"step": 133, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 134.0, 1.0, 1.0, 1.0, 134.0, 134.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.59, 0.0, 0.0, 0.0, -4.346, -4.491, 0.0, 0.0, 0.0]}
{"step": 134, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 135.0, 1.0, 1.0, 1.0, 135.0, 135.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.649, 0.0, 0.0, 0.0, -4.4, -4.543, 0.0, 0.0, 0.0]}
{"number_of_episodes": 267, "number_of_timesteps": 6061, "per_episode_reward": 20.5, "episode_reward_trend_value": -0.0012500000000000178, "biggest_recent_change": NaN},
{"step": 135, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 136.0, 1.0, 1.0, 1.0, 136.0, 136.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.622, 0.0, 0.0, 0.0, -4.367, -4.509, 0.0, 0.0, 0.0]}
{"number_of_episodes": 268, "number_of_timesteps": 6075, "per_episode_reward": 20.45, "episode_reward_trend_value": -0.01499999999999999, "biggest_recent_change": NaN},
{"step": 136, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 137.0, 1.0, 1.0, 1.0, 137.0, 137.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.595, 0.0, 0.0, 0.0, -4.431, -4.572, 0.0, 0.0, 0.0]}
{"number_of_episodes": 270, "number_of_timesteps": 6152, "per_episode_reward": 20.35, "episode_reward_trend_value": -0.011666666666666634, "biggest_recent_change": 1.3999999999999986},
{"step": 137, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 138.0, 1.0, 1.0, 1.0, 138.0, 138.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.623, 0.0, 0.0, 0.0, -4.399, -4.592, 0.0, 0.0, 0.0]}
{"number_of_episodes": 271, "number_of_timesteps": 6169, "per_episode_reward": 20.35, "episode_reward_trend_value": -0.016111111111111104, "biggest_recent_change": 0.9499999999999993},
{"step": 138, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 139.0, 1.0, 1.0, 1.0, 139.0, 139.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.626, 0.0, 0.0, 0.0, -4.396, -4.589, 0.0, 0.0, 0.0]}
{"step": 139, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 140.0, 1.0, 1.0, 1.0, 140.0, 140.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.636, 0.0, 0.0, 0.0, -4.365, -4.592, 0.0, 0.0, 0.0]}
{"number_of_episodes": 277, "number_of_timesteps": 6331, "per_episode_reward": 20.5, "episode_reward_trend_value": -0.014374999999999982, "biggest_recent_change": NaN},
{"step": 140, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 141.0, 1.0, 1.0, 1.0, 141.0, 141.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.655, 0.0, 0.0, 0.0, -4.379, -4.604, 0.0, 0.0, 0.0]}
{"step": 141, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 142.0, 1.0, 1.0, 1.0, 142.0, 142.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.661, 0.0, 0.0, 0.0, -4.38, -4.603, 0.0, 0.0, 0.0]}
{"number_of_episodes": 278, "number_of_timesteps": 6365, "per_episode_reward": 20.55, "episode_reward_trend_value": -0.013749999999999974, "biggest_recent_change": NaN},
{"step": 142, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 143.0, 1.0, 1.0, 1.0, 143.0, 143.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.668, 0.0, 0.0, 0.0, -4.381, -4.571, 0.0, 0.0, 0.0]}
{"number_of_episodes": 281, "number_of_timesteps": 6411, "per_episode_reward": 20.55, "episode_reward_trend_value": -0.014285714285714285, "biggest_recent_change": NaN},
{"step": 143, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 144.0, 1.0, 1.0, 1.0, 144.0, 144.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.642, 0.0, 0.0, 0.0, -4.351, -4.539, 0.0, 0.0, 0.0]}
{"number_of_episodes": 282, "number_of_timesteps": 6436, "per_episode_reward": 20.55, "episode_reward_trend_value": -0.02, "biggest_recent_change": NaN},
{"step": 144, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 145.0, 1.0, 1.0, 1.0, 145.0, 145.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.617, 0.0, 0.0, 0.0, -4.321, -4.508, 0.0, 0.0, 0.0]}
{"number_of_episodes": 285, "number_of_timesteps": 6532, "per_episode_reward": 20.55, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.75},
{"step": 145, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 146.0, 1.0, 1.0, 1.0, 146.0, 146.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.621, 0.0, 0.0, 0.0, -4.32, -4.506, 0.0, 0.0, 0.0]}
{"number_of_episodes": 286, "number_of_timesteps": 6587, "per_episode_reward": 20.6, "episode_reward_trend_value": -0.014444444444444413, "biggest_recent_change": 1.3999999999999986},
{"step": 146, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 147.0, 1.0, 1.0, 1.0, 147.0, 147.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.645, 0.0, 0.0, 0.0, -4.29, -4.524, 0.0, 0.0, 0.0]}
{"step": 147, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 148.0, 1.0, 1.0, 1.0, 148.0, 148.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.65, 0.0, 0.0, 0.0, -4.261, -4.523, 0.0, 0.0, 0.0]}
{"step": 148, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 149.0, 1.0, 1.0, 1.0, 149.0, 149.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.626, 0.0, 0.0, 0.0, -4.233, -4.493, 0.0, 0.0, 0.0]}
{"step": 149, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 150.0, 1.0, 1.0, 1.0, 150.0, 150.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.602, 0.0, 0.0, 0.0, -4.204, -4.463, 0.0, 0.0, 0.0]}
{"step": 150, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 151.0, 1.0, 1.0, 1.0, 151.0, 151.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.609, 0.0, 0.0, 0.0, -4.208, -4.465, 0.0, 0.0, 0.0]}
{"number_of_episodes": 297, "number_of_timesteps": 6879, "per_episode_reward": 20.65, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.75},
{"step": 151, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 152.0, 1.0, 1.0, 1.0, 152.0, 152.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.621, 0.0, 0.0, 0.0, -4.216, -4.472, 0.0, 0.0, 0.0]}
{"number_of_episodes": 298, "number_of_timesteps": 6907, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 1.1000000000000014},
{"step": 152, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 153.0, 1.0, 1.0, 1.0, 153.0, 153.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.598, 0.0, 0.0, 0.0, -4.189, -4.442, 0.0, 0.0, 0.0]}
{"number_of_episodes": 299, "number_of_timesteps": 6923, "per_episode_reward": 20.7, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 1.7000000000000028},
{"step": 153, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 154.0, 1.0, 1.0, 1.0, 154.0, 154.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.598, 0.0, 0.0, 0.0, -4.186, -4.437, 0.0, 0.0, 0.0]}
{"step": 154, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 155.0, 1.0, 1.0, 1.0, 155.0, 155.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.601, 0.0, 0.0, 0.0, -4.184, -4.434, 0.0, 0.0, 0.0]}
{"number_of_episodes": 306, "number_of_timesteps": 7062, "per_episode_reward": 20.65, "episode_reward_trend_value": -0.01000000000000004, "biggest_recent_change": NaN},
{"step": 155, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 156.0, 1.0, 1.0, 1.0, 156.0, 156.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.618, 0.0, 0.0, 0.0, -4.197, -4.446, 0.0, 0.0, 0.0]}
{"number_of_episodes": 307, "number_of_timesteps": 7072, "per_episode_reward": 20.65, "episode_reward_trend_value": -0.005000000000000031, "biggest_recent_change": 2.0},
{"step": 156, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 157.0, 1.0, 1.0, 1.0, 157.0, 157.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.674, 0.0, 0.0, 0.0, -4.25, -4.497, 0.0, 0.0, 0.0]}
{"number_of_episodes": 309, "number_of_timesteps": 7119, "per_episode_reward": 20.55, "episode_reward_trend_value": -0.012222222222222199, "biggest_recent_change": 1.1999999999999993},
{"step": 157, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 158.0, 1.0, 1.0, 1.0, 158.0, 158.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.675, 0.0, 0.0, 0.0, -4.247, -4.468, 0.0, 0.0, 0.0]}
{"step": 158, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 159.0, 1.0, 1.0, 1.0, 159.0, 159.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.68, 0.0, 0.0, 0.0, -4.249, -4.468, 0.0, 0.0, 0.0]}
{"number_of_episodes": 310, "number_of_timesteps": 7137, "per_episode_reward": 20.55, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.6999999999999993},
{"step": 159, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 160.0, 1.0, 1.0, 1.0, 160.0, 160.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.682, 0.0, 0.0, 0.0, -4.247, -4.465, 0.0, 0.0, 0.0]}
{"number_of_episodes": 313, "number_of_timesteps": 7199, "per_episode_reward": 20.55, "episode_reward_trend_value": -0.0125, "biggest_recent_change": NaN},
{"step": 160, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 161.0, 1.0, 1.0, 1.0, 161.0, 161.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.659, 0.0, 0.0, 0.0, -4.221, -4.437, 0.0, 0.0, 0.0]}
{"step": 161, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 162.0, 1.0, 1.0, 1.0, 162.0, 162.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.675, 0.0, 0.0, 0.0, -4.234, -4.449, 0.0, 0.0, 0.0]}
{"number_of_episodes": 315, "number_of_timesteps": 7248, "per_episode_reward": 20.65, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.8000000000000007},
{"step": 162, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 163.0, 1.0, 1.0, 1.0, 163.0, 163.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.68, 0.0, 0.0, 0.0, -4.208, -4.449, 0.0, 0.0, 0.0]}
{"step": 163, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 164.0, 1.0, 1.0, 1.0, 164.0, 164.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.685, 0.0, 0.0, 0.0, -4.182, -4.449, 0.0, 0.0, 0.0]}
{"step": 164, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 165.0, 1.0, 1.0, 1.0, 165.0, 165.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.685, 0.0, 0.0, 0.0, -4.179, -4.422, 0.0, 0.0, 0.0]}
{"number_of_episodes": 320, "number_of_timesteps": 7417, "per_episode_reward": 20.55, "episode_reward_trend_value": -0.010000000000000009, "biggest_recent_change": NaN},
{"step": 165, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 166.0, 1.0, 1.0, 1.0, 166.0, 166.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.689, 0.0, 0.0, 0.0, -4.18, -4.422, 0.0, 0.0, 0.0]}
{"number_of_episodes": 320, "number_of_timesteps": 7417, "per_episode_reward": 20.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.4499999999999993},
{"step": 166, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 167.0, 1.0, 1.0, 1.0, 167.0, 167.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.689, 0.0, 0.0, 0.0, -4.177, -4.395, 0.0, 0.0, 0.0]}
{"number_of_episodes": 323, "number_of_timesteps": 7547, "per_episode_reward": 20.6, "episode_reward_trend_value": -0.0038888888888888654, "biggest_recent_change": 0.6999999999999993},
{"step": 167, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 168.0, 1.0, 1.0, 1.0, 168.0, 168.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.692, 0.0, 0.0, 0.0, -4.177, -4.394, 0.0, 0.0, 0.0]}
{"step": 168, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 169.0, 1.0, 1.0, 1.0, 169.0, 169.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.692, 0.0, 0.0, 0.0, -4.174, -4.368, 0.0, 0.0, 0.0]}
{"number_of_episodes": 325, "number_of_timesteps": 7588, "per_episode_reward": 20.6, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 2.0},
{"step": 169, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 170.0, 1.0, 1.0, 1.0, 170.0, 170.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.768, 0.0, 0.0, 0.0, -4.247, -4.44, 0.0, 0.0, 0.0]}
{"number_of_episodes": 326, "number_of_timesteps": 7603, "per_episode_reward": 20.55, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.9000000000000021},
{"step": 170, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 171.0, 1.0, 1.0, 1.0, 171.0, 171.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.746, 0.0, 0.0, 0.0, -4.222, -4.414, 0.0, 0.0, 0.0]}
{"step": 171, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 172.0, 1.0, 1.0, 1.0, 172.0, 172.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.756, 0.0, 0.0, 0.0, -4.23, -4.42, 0.0, 0.0, 0.0]}
{"number_of_episodes": 332, "number_of_timesteps": 7802, "per_episode_reward": 20.75, "episode_reward_trend_value": -0.009999999999999985, "biggest_recent_change": 1.7000000000000028},
{"step": 172, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 173.0, 1.0, 1.0, 1.0, 173.0, 173.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.763, 0.0, 0.0, 0.0, -4.234, -4.424, 0.0, 0.0, 0.0]}
{"number_of_episodes": 333, "number_of_timesteps": 7812, "per_episode_reward": 20.75, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.3999999999999986},
{"step": 173, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 174.0, 1.0, 1.0, 1.0, 174.0, 174.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.77, 0.0, 0.0, 0.0, -4.239, -4.398, 0.0, 0.0, 0.0]}
{"number_of_episodes": 334, "number_of_timesteps": 7824, "per_episode_reward": 20.75, "episode_reward_trend_value": -0.013333333333333345, "biggest_recent_change": NaN},
{"step": 174, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 175.0, 1.0, 1.0, 1.0, 175.0, 175.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.749, 0.0, 0.0, 0.0, -4.214, -4.373, 0.0, 0.0, 0.0]}
{"number_of_episodes": 334, "number_of_timesteps": 7824, "per_episode_reward": 20.75, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.9499999999999993},
{"step": 175, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 176.0, 1.0, 1.0, 1.0, 176.0, 176.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.753, 0.0, 0.0, 0.0, -4.216, -4.374, 0.0, 0.0, 0.0]}
{"number_of_episodes": 340, "number_of_timesteps": 7994, "per_episode_reward": 20.7, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 1.2999999999999972},
{"step": 176, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 177.0, 1.0, 1.0, 1.0, 177.0, 177.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.732, 0.0, 0.0, 0.0, -4.247, -4.404, 0.0, 0.0, 0.0]}
{"step": 177, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 178.0, 1.0, 1.0, 1.0, 178.0, 178.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.711, 0.0, 0.0, 0.0, -4.223, -4.379, 0.0, 0.0, 0.0]}
{"number_of_episodes": 343, "number_of_timesteps": 8062, "per_episode_reward": 20.75, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.5500000000000007},
{"step": 178, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 179.0, 1.0, 1.0, 1.0, 179.0, 179.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.72, 0.0, 0.0, 0.0, -4.2, -4.385, 0.0, 0.0, 0.0]}
{"number_of_episodes": 346, "number_of_timesteps": 8096, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.3000000000000007},
{"step": 179, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 180.0, 1.0, 1.0, 1.0, 180.0, 180.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.721, 0.0, 0.0, 0.0, -4.198, -4.36, 0.0, 0.0, 0.0]}
{"step": 180, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 181.0, 1.0, 1.0, 1.0, 181.0, 181.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.701, 0.0, 0.0, 0.0, -4.237, -4.399, 0.0, 0.0, 0.0]}
{"step": 181, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 182.0, 1.0, 1.0, 1.0, 182.0, 182.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.705, 0.0, 0.0, 0.0, -4.239, -4.375, 0.0, 0.0, 0.0]}
{"number_of_episodes": 352, "number_of_timesteps": 8275, "per_episode_reward": 20.7, "episode_reward_trend_value": -0.015555555555555578, "biggest_recent_change": 0.9000000000000021},
{"step": 182, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 183.0, 1.0, 1.0, 1.0, 183.0, 183.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.685, 0.0, 0.0, 0.0, -4.216, -4.351, 0.0, 0.0, 0.0]}
{"number_of_episodes": 353, "number_of_timesteps": 8292, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.3999999999999986},
{"step": 183, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 184.0, 1.0, 1.0, 1.0, 184.0, 184.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.686, 0.0, 0.0, 0.0, -4.213, -4.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 356, "number_of_timesteps": 8356, "per_episode_reward": 20.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 1.1000000000000014},
{"step": 184, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 185.0, 1.0, 1.0, 1.0, 185.0, 185.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.666, 0.0, 0.0, 0.0, -4.19, -4.324, 0.0, 0.0, 0.0]}
{"number_of_episodes": 359, "number_of_timesteps": 8414, "per_episode_reward": 20.7, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 1.2999999999999972},
{"step": 185, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 186.0, 1.0, 1.0, 1.0, 186.0, 186.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.646, 0.0, 0.0, 0.0, -4.217, -4.35, 0.0, 0.0, 0.0]}
{"number_of_episodes": 360, "number_of_timesteps": 8448, "per_episode_reward": 20.75, "episode_reward_trend_value": -0.012777777777777763, "biggest_recent_change": 2.0},
{"step": 186, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 187.0, 1.0, 1.0, 1.0, 187.0, 187.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.706, 0.0, 0.0, 0.0, -4.274, -4.407, 0.0, 0.0, 0.0]}
{"number_of_episodes": 362, "number_of_timesteps": 8490, "per_episode_reward": 20.7, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.5500000000000007},
{"step": 187, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 188.0, 1.0, 1.0, 1.0, 188.0, 188.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.708, 0.0, 0.0, 0.0, -4.252, -4.405, 0.0, 0.0, 0.0]}
{"number_of_episodes": 365, "number_of_timesteps": 8551, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.3000000000000007},
{"step": 188, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 189.0, 1.0, 1.0, 1.0, 189.0, 189.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.711, 0.0, 0.0, 0.0, -4.252, -4.381, 0.0, 0.0, 0.0]}
{"step": 189, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 190.0, 1.0, 1.0, 1.0, 190.0, 190.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.692, 0.0, 0.0, 0.0, -4.273, -4.402, 0.0, 0.0, 0.0]}
{"number_of_episodes": 369, "number_of_timesteps": 8650, "per_episode_reward": 20.7, "episode_reward_trend_value": -0.015555555555555578, "biggest_recent_change": 1.7000000000000028},
{"step": 190, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 191.0, 1.0, 1.0, 1.0, 191.0, 191.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.695, 0.0, 0.0, 0.0, -4.274, -4.402, 0.0, 0.0, 0.0]}
{"number_of_episodes": 370, "number_of_timesteps": 8664, "per_episode_reward": 20.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.9499999999999993},
{"step": 191, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 192.0, 1.0, 1.0, 1.0, 192.0, 192.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.692, 0.0, 0.0, 0.0, -4.267, -4.394, 0.0, 0.0, 0.0]}
{"number_of_episodes": 373, "number_of_timesteps": 8713, "per_episode_reward": 20.75, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.9499999999999993},
{"step": 192, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 193.0, 1.0, 1.0, 1.0, 193.0, 193.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.673, 0.0, 0.0, 0.0, -4.295, -4.421, 0.0, 0.0, 0.0]}
{"step": 193, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 194.0, 1.0, 1.0, 1.0, 194.0, 194.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.674, 0.0, 0.0, 0.0, -4.293, -4.419, 0.0, 0.0, 0.0]}
{"number_of_episodes": 378, "number_of_timesteps": 8825, "per_episode_reward": 20.6, "episode_reward_trend_value": -0.012777777777777763, "biggest_recent_change": 1.1000000000000014},
{"step": 194, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 195.0, 1.0, 1.0, 1.0, 195.0, 195.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.656, 0.0, 0.0, 0.0, -4.271, -4.396, 0.0, 0.0, 0.0]}
{"number_of_episodes": 380, "number_of_timesteps": 8891, "per_episode_reward": 20.65, "episode_reward_trend_value": -0.005000000000000031, "biggest_recent_change": 0.9499999999999993},
{"step": 195, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 196.0, 1.0, 1.0, 1.0, 196.0, 196.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.664, 0.0, 0.0, 0.0, -4.277, -4.401, 0.0, 0.0, 0.0]}
{"step": 196, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 197.0, 1.0, 1.0, 1.0, 197.0, 197.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.646, 0.0, 0.0, 0.0, -4.302, -4.426, 0.0, 0.0, 0.0]}
{"number_of_episodes": 385, "number_of_timesteps": 8973, "per_episode_reward": 20.6, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.9000000000000021},
{"step": 197, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 198.0, 1.0, 1.0, 1.0, 198.0, 198.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.627, 0.0, 0.0, 0.0, -4.28, -4.403, 0.0, 0.0, 0.0]}
{"step": 198, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 199.0, 1.0, 1.0, 1.0, 199.0, 199.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.609, 0.0, 0.0, 0.0, -4.258, -4.381, 0.0, 0.0, 0.0]}
{"number_of_episodes": 389, "number_of_timesteps": 9053, "per_episode_reward": 20.6, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.25},
{"step": 199, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 200.0, 1.0, 1.0, 1.0, 200.0, 200.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.613, 0.0, 0.0, 0.0, -4.259, -4.359, 0.0, 0.0, 0.0]}
{"eval_score": 30.9, "number_of_episodes": 393}
{"number_of_episodes": 393, "number_of_timesteps": 9120, "per_episode_reward": 20.4, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.9000000000000021},
{"step": 200, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 201.0, 1.0, 1.0, 1.0, 201.0, 201.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.595, 0.0, 0.0, 0.0, -4.292, -4.391, 0.0, 0.0, 0.0]}
{"number_of_episodes": 394, "number_of_timesteps": 9136, "per_episode_reward": 20.35, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.40000000000000213},
{"step": 201, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 202.0, 1.0, 1.0, 1.0, 202.0, 202.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.607, 0.0, 0.0, 0.0, -4.3, -4.399, 0.0, 0.0, 0.0]}
{"number_of_episodes": 395, "number_of_timesteps": 9151, "per_episode_reward": 20.35, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.45000000000000284},
{"step": 202, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 203.0, 1.0, 1.0, 1.0, 203.0, 203.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.589, 0.0, 0.0, 0.0, -4.279, -4.377, 0.0, 0.0, 0.0]}
{"number_of_episodes": 398, "number_of_timesteps": 9228, "per_episode_reward": 20.15, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.5500000000000007},
{"step": 203, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 204.0, 1.0, 1.0, 1.0, 204.0, 204.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.589, 0.0, 0.0, 0.0, -4.258, -4.374, 0.0, 0.0, 0.0]}
{"step": 204, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 205.0, 1.0, 1.0, 1.0, 205.0, 205.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.572, 0.0, 0.0, 0.0, -4.237, -4.352, 0.0, 0.0, 0.0]}
{"step": 205, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 206.0, 1.0, 1.0, 1.0, 206.0, 206.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.574, 0.0, 0.0, 0.0, -4.236, -4.351, 0.0, 0.0, 0.0]}
{"number_of_episodes": 403, "number_of_timesteps": 9328, "per_episode_reward": 20.15, "episode_reward_trend_value": -0.012777777777777801, "biggest_recent_change": 0.9499999999999993},
{"step": 206, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 207.0, 1.0, 1.0, 1.0, 207.0, 207.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.582, 0.0, 0.0, 0.0, -4.24, -4.355, 0.0, 0.0, 0.0]}
{"step": 207, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 208.0, 1.0, 1.0, 1.0, 208.0, 208.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.585, 0.0, 0.0, 0.0, -4.24, -4.354, 0.0, 0.0, 0.0]}
{"number_of_episodes": 409, "number_of_timesteps": 9469, "per_episode_reward": 20.15, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.5500000000000007},
{"step": 208, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 209.0, 1.0, 1.0, 1.0, 209.0, 209.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.589, 0.0, 0.0, 0.0, -4.241, -4.355, 0.0, 0.0, 0.0]}
{"number_of_episodes": 410, "number_of_timesteps": 9503, "per_episode_reward": 20.15, "episode_reward_trend_value": -0.013333333333333364, "biggest_recent_change": 1.1000000000000014},
{"step": 209, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 210.0, 1.0, 1.0, 1.0, 210.0, 210.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.572, 0.0, 0.0, 0.0, -4.221, -4.334, 0.0, 0.0, 0.0]}
{"number_of_episodes": 413, "number_of_timesteps": 9554, "per_episode_reward": 20.1, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.25},
{"step": 210, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 211.0, 1.0, 1.0, 1.0, 211.0, 211.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.555, 0.0, 0.0, 0.0, -4.201, -4.313, 0.0, 0.0, 0.0]}
{"number_of_episodes": 416, "number_of_timesteps": 9633, "per_episode_reward": 20.15, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.40000000000000213},
{"step": 211, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 212.0, 1.0, 1.0, 1.0, 212.0, 212.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.565, 0.0, 0.0, 0.0, -4.208, -4.319, 0.0, 0.0, 0.0]}
{"step": 212, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 213.0, 1.0, 1.0, 1.0, 213.0, 213.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.576, 0.0, 0.0, 0.0, -4.216, -4.328, 0.0, 0.0, 0.0]}
{"number_of_episodes": 421, "number_of_timesteps": 9691, "per_episode_reward": 20.1, "episode_reward_trend_value": -0.0038888888888888654, "biggest_recent_change": 0.5},
{"step": 213, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 214.0, 1.0, 1.0, 1.0, 214.0, 214.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.579, 0.0, 0.0, 0.0, -4.216, -4.307, 0.0, 0.0, 0.0]}
{"number_of_episodes": 424, "number_of_timesteps": 9746, "per_episode_reward": 20.05, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.5},
{"step": 214, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 215.0, 1.0, 1.0, 1.0, 215.0, 215.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.583, 0.0, 0.0, 0.0, -4.217, -4.309, 0.0, 0.0, 0.0]}
{"number_of_episodes": 425, "number_of_timesteps": 9783, "per_episode_reward": 20.05, "episode_reward_trend_value": -0.0038888888888888654, "biggest_recent_change": 0.4499999999999993},
{"step": 215, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 216.0, 1.0, 1.0, 1.0, 216.0, 216.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.566, 0.0, 0.0, 0.0, -4.242, -4.333, 0.0, 0.0, 0.0]}
{"number_of_episodes": 429, "number_of_timesteps": 9839, "per_episode_reward": 19.9, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.5500000000000007},
{"step": 216, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 217.0, 1.0, 1.0, 1.0, 217.0, 217.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.575, 0.0, 0.0, 0.0, -4.248, -4.338, 0.0, 0.0, 0.0]}
{"step": 217, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 218.0, 1.0, 1.0, 1.0, 218.0, 218.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.576, 0.0, 0.0, 0.0, -4.245, -4.335, 0.0, 0.0, 0.0]}
{"number_of_episodes": 434, "number_of_timesteps": 9952, "per_episode_reward": 19.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 1.4500000000000028},
{"step": 218, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 219.0, 1.0, 1.0, 1.0, 219.0, 219.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.611, 0.0, 0.0, 0.0, -4.277, -4.367, 0.0, 0.0, 0.0]}
{"number_of_episodes": 436, "number_of_timesteps": 9984, "per_episode_reward": 19.75, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.5},
{"step": 219, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 220.0, 1.0, 1.0, 1.0, 220.0, 220.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.612, 0.0, 0.0, 0.0, -4.276, -4.365, 0.0, 0.0, 0.0]}
{"step": 220, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 221.0, 1.0, 1.0, 1.0, 221.0, 221.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.639, 0.0, 0.0, 0.0, -4.299, -4.388, 0.0, 0.0, 0.0]}
{"number_of_episodes": 439, "number_of_timesteps": 10060, "per_episode_reward": 19.75, "episode_reward_trend_value": -0.00944444444444446, "biggest_recent_change": 0.5500000000000007},
{"step": 221, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 222.0, 1.0, 1.0, 1.0, 222.0, 222.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.655, 0.0, 0.0, 0.0, -4.28, -4.401, 0.0, 0.0, 0.0]}
{"number_of_episodes": 443, "number_of_timesteps": 10142, "per_episode_reward": 19.7, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.4499999999999993},
{"step": 222, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 223.0, 1.0, 1.0, 1.0, 223.0, 223.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.662, 0.0, 0.0, 0.0, -4.283, -4.404, 0.0, 0.0, 0.0]}
{"number_of_episodes": 444, "number_of_timesteps": 10166, "per_episode_reward": 19.7, "episode_reward_trend_value": -0.02642857142857145, "biggest_recent_change": NaN},
{"step": 223, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 224.0, 1.0, 1.0, 1.0, 224.0, 224.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.645, 0.0, 0.0, 0.0, -4.264, -4.385, 0.0, 0.0, 0.0]}
{"number_of_episodes": 447, "number_of_timesteps": 10198, "per_episode_reward": 19.55, "episode_reward_trend_value": -0.009999999999999985, "biggest_recent_change": 0.5500000000000007},
{"step": 224, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 225.0, 1.0, 1.0, 1.0, 225.0, 225.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.649, 0.0, 0.0, 0.0, -4.265, -4.385, 0.0, 0.0, 0.0]}
{"number_of_episodes": 449, "number_of_timesteps": 10247, "per_episode_reward": 19.7, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.5},
{"step": 225, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 226.0, 1.0, 1.0, 1.0, 226.0, 226.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.651, 0.0, 0.0, 0.0, -4.264, -4.365, 0.0, 0.0, 0.0]}
{"step": 226, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 227.0, 1.0, 1.0, 1.0, 227.0, 227.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.634, 0.0, 0.0, 0.0, -4.245, -4.346, 0.0, 0.0, 0.0]}
{"step": 227, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 228.0, 1.0, 1.0, 1.0, 228.0, 228.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.635, 0.0, 0.0, 0.0, -4.243, -4.344, 0.0, 0.0, 0.0]}
{"step": 228, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 229.0, 1.0, 1.0, 1.0, 229.0, 229.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.636, 0.0, 0.0, 0.0, -4.241, -4.341, 0.0, 0.0, 0.0]}
{"number_of_episodes": 458, "number_of_timesteps": 10400, "per_episode_reward": 19.45, "episode_reward_trend_value": -0.021111111111111136, "biggest_recent_change": 1.1000000000000014},
{"step": 229, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 230.0, 1.0, 1.0, 1.0, 230.0, 230.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.62, 0.0, 0.0, 0.0, -4.222, -4.322, 0.0, 0.0, 0.0]}
{"number_of_episodes": 461, "number_of_timesteps": 10462, "per_episode_reward": 19.5, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 0.5},
{"step": 230, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 231.0, 1.0, 1.0, 1.0, 231.0, 231.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.625, 0.0, 0.0, 0.0, -4.225, -4.324, 0.0, 0.0, 0.0]}
{"number_of_episodes": 463, "number_of_timesteps": 10497, "per_episode_reward": 19.55, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.5},
{"step": 231, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 232.0, 1.0, 1.0, 1.0, 232.0, 232.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.629, 0.0, 0.0, 0.0, -4.227, -4.305, 0.0, 0.0, 0.0]}
{"number_of_episodes": 465, "number_of_timesteps": 10534, "per_episode_reward": 19.55, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 0.5},
{"step": 232, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 233.0, 1.0, 1.0, 1.0, 233.0, 233.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.614, 0.0, 0.0, 0.0, -4.263, -4.341, 0.0, 0.0, 0.0]}
{"step": 233, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 234.0, 1.0, 1.0, 1.0, 234.0, 234.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.598, 0.0, 0.0, 0.0, -4.292, -4.37, 0.0, 0.0, 0.0]}
{"step": 234, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 235.0, 1.0, 1.0, 1.0, 235.0, 235.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.583, 0.0, 0.0, 0.0, -4.33, -4.407, 0.0, 0.0, 0.0]}
{"number_of_episodes": 470, "number_of_timesteps": 10600, "per_episode_reward": 19.35, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.75},
{"step": 235, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 236.0, 1.0, 1.0, 1.0, 236.0, 236.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.568, 0.0, 0.0, 0.0, -4.311, -4.389, 0.0, 0.0, 0.0]}
{"number_of_episodes": 475, "number_of_timesteps": 10700, "per_episode_reward": 19.35, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 0.9500000000000028},
{"step": 236, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 237.0, 1.0, 1.0, 1.0, 237.0, 237.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.594, 0.0, 0.0, 0.0, -4.334, -4.411, 0.0, 0.0, 0.0]}
{"number_of_episodes": 476, "number_of_timesteps": 10731, "per_episode_reward": 19.45, "episode_reward_trend_value": -0.026250000000000016, "biggest_recent_change": NaN},
{"step": 237, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 238.0, 1.0, 1.0, 1.0, 238.0, 238.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.579, 0.0, 0.0, 0.0, -4.316, -4.393, 0.0, 0.0, 0.0]}
{"number_of_episodes": 478, "number_of_timesteps": 10770, "per_episode_reward": 19.45, "episode_reward_trend_value": -0.013333333333333326, "biggest_recent_change": 0.5},
{"step": 238, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 239.0, 1.0, 1.0, 1.0, 239.0, 239.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.582, 0.0, 0.0, 0.0, -4.316, -4.393, 0.0, 0.0, 0.0]}
{"number_of_episodes": 479, "number_of_timesteps": 10785, "per_episode_reward": 19.4, "episode_reward_trend_value": -0.012777777777777801, "biggest_recent_change": 0.5},
{"step": 239, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 240.0, 1.0, 1.0, 1.0, 240.0, 240.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.589, 0.0, 0.0, 0.0, -4.32, -4.374, 0.0, 0.0, 0.0]}
{"step": 240, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 241.0, 1.0, 1.0, 1.0, 241.0, 241.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.627, 0.0, 0.0, 0.0, -4.355, -4.409, 0.0, 0.0, 0.0]}
{"step": 241, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 242.0, 1.0, 1.0, 1.0, 242.0, 242.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.631, 0.0, 0.0, 0.0, -4.356, -4.409, 0.0, 0.0, 0.0]}
{"step": 242, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 243.0, 1.0, 1.0, 1.0, 243.0, 243.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.636, 0.0, 0.0, 0.0, -4.358, -4.411, 0.0, 0.0, 0.0]}
{"number_of_episodes": 488, "number_of_timesteps": 11063, "per_episode_reward": 19.4, "episode_reward_trend_value": -0.011666666666666676, "biggest_recent_change": 0.75},
{"step": 243, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 244.0, 1.0, 1.0, 1.0, 244.0, 244.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.621, 0.0, 0.0, 0.0, -4.34, -4.393, 0.0, 0.0, 0.0]}
{"step": 244, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 245.0, 1.0, 1.0, 1.0, 245.0, 245.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.606, 0.0, 0.0, 0.0, -4.322, -4.375, 0.0, 0.0, 0.0]}
{"number_of_episodes": 494, "number_of_timesteps": 11187, "per_episode_reward": 19.3, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 0.6999999999999993},
{"step": 245, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 246.0, 1.0, 1.0, 1.0, 246.0, 246.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.591, 0.0, 0.0, 0.0, -4.305, -4.357, 0.0, 0.0, 0.0]}
{"number_of_episodes": 497, "number_of_timesteps": 11244, "per_episode_reward": 19.35, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 1.4499999999999993},
{"step": 246, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 247.0, 1.0, 1.0, 1.0, 247.0, 247.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.577, 0.0, 0.0, 0.0, -4.287, -4.339, 0.0, 0.0, 0.0]}
{"number_of_episodes": 500, "number_of_timesteps": 11292, "per_episode_reward": 19.35, "episode_reward_trend_value": -0.013333333333333326, "biggest_recent_change": 0.5},
{"step": 247, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 248.0, 1.0, 1.0, 1.0, 248.0, 248.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.583, 0.0, 0.0, 0.0, -4.29, -4.342, 0.0, 0.0, 0.0]}
{"step": 248, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 249.0, 1.0, 1.0, 1.0, 249.0, 249.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.586, 0.0, 0.0, 0.0, -4.291, -4.343, 0.0, 0.0, 0.0]}
{"number_of_episodes": 504, "number_of_timesteps": 11353, "per_episode_reward": 19.4, "episode_reward_trend_value": -0.015000000000000017, "biggest_recent_change": 0.5500000000000007},
{"step": 249, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 250.0, 1.0, 1.0, 1.0, 250.0, 250.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.591, 0.0, 0.0, 0.0, -4.274, -4.344, 0.0, 0.0, 0.0]}
{"number_of_episodes": 507, "number_of_timesteps": 11409, "per_episode_reward": 19.4, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.8500000000000014},
{"step": 250, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 251.0, 1.0, 1.0, 1.0, 251.0, 251.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.621, 0.0, 0.0, 0.0, -4.301, -4.372, 0.0, 0.0, 0.0]}
{"number_of_episodes": 508, "number_of_timesteps": 11429, "per_episode_reward": 19.45, "episode_reward_trend_value": -0.015555555555555578, "biggest_recent_change": 0.4499999999999993},
{"step": 251, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 252.0, 1.0, 1.0, 1.0, 252.0, 252.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.622, 0.0, 0.0, 0.0, -4.299, -4.369, 0.0, 0.0, 0.0]}
{"number_of_episodes": 511, "number_of_timesteps": 11472, "per_episode_reward": 19.25, "episode_reward_trend_value": -0.012222222222222238, "biggest_recent_change": 0.5500000000000007},
{"step": 252, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 253.0, 1.0, 1.0, 1.0, 253.0, 253.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.625, 0.0, 0.0, 0.0, -4.3, -4.37, 0.0, 0.0, 0.0]}
{"number_of_episodes": 513, "number_of_timesteps": 11521, "per_episode_reward": 19.25, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.5},
{"step": 253, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 254.0, 1.0, 1.0, 1.0, 254.0, 254.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.628, 0.0, 0.0, 0.0, -4.3, -4.369, 0.0, 0.0, 0.0]}
{"number_of_episodes": 515, "number_of_timesteps": 11570, "per_episode_reward": 19.3, "episode_reward_trend_value": -0.014999999999999977, "biggest_recent_change": 0.5},
{"step": 254, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 255.0, 1.0, 1.0, 1.0, 255.0, 255.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.614, 0.0, 0.0, 0.0, -4.343, -4.413, 0.0, 0.0, 0.0]}
{"step": 255, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 256.0, 1.0, 1.0, 1.0, 256.0, 256.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.599, 0.0, 0.0, 0.0, -4.371, -4.44, 0.0, 0.0, 0.0]}
{"eval_score": 19.1, "number_of_episodes": 520}
{"number_of_episodes": 520, "number_of_timesteps": 11675, "per_episode_reward": 19.3, "episode_reward_trend_value": -0.011666666666666676, "biggest_recent_change": 0.5500000000000007},
{"step": 256, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 257.0, 1.0, 1.0, 1.0, 257.0, 257.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.601, 0.0, 0.0, 0.0, -4.354, -4.439, 0.0, 0.0, 0.0]}
{"number_of_episodes": 522, "number_of_timesteps": 11708, "per_episode_reward": 19.25, "episode_reward_trend_value": -0.01444444444444445, "biggest_recent_change": 0.5500000000000007},
{"step": 257, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 258.0, 1.0, 1.0, 1.0, 258.0, 258.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.611, 0.0, 0.0, 0.0, -4.361, -4.445, 0.0, 0.0, 0.0]}
{"number_of_episodes": 528, "number_of_timesteps": 11802, "per_episode_reward": 19.15, "episode_reward_trend_value": -0.015555555555555578, "biggest_recent_change": 0.5},
{"step": 258, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 259.0, 1.0, 1.0, 1.0, 259.0, 259.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.624, 0.0, 0.0, 0.0, -4.371, -4.428, 0.0, 0.0, 0.0]}
{"number_of_episodes": 529, "number_of_timesteps": 11816, "per_episode_reward": 19.0, "episode_reward_trend_value": -0.01722222222222223, "biggest_recent_change": 0.6999999999999993},
{"step": 259, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 260.0, 1.0, 1.0, 1.0, 260.0, 260.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.61, 0.0, 0.0, 0.0, -4.355, -4.411, 0.0, 0.0, 0.0]}
{"number_of_episodes": 530, "number_of_timesteps": 11856, "per_episode_reward": 19.1, "episode_reward_trend_value": -0.01833333333333332, "biggest_recent_change": 0.8500000000000014},
{"step": 260, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 261.0, 1.0, 1.0, 1.0, 261.0, 261.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.644, 0.0, 0.0, 0.0, -4.385, -4.442, 0.0, 0.0, 0.0]}
{"number_of_episodes": 532, "number_of_timesteps": 11878, "per_episode_reward": 19.0, "episode_reward_trend_value": -0.013333333333333326, "biggest_recent_change": 0.5},
{"step": 261, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 262.0, 1.0, 1.0, 1.0, 262.0, 262.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.63, 0.0, 0.0, 0.0, -4.408, -4.465, 0.0, 0.0, 0.0]}
{"step": 262, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 263.0, 1.0, 1.0, 1.0, 263.0, 263.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.631, 0.0, 0.0, 0.0, -4.407, -4.448, 0.0, 0.0, 0.0]}
{"number_of_episodes": 537, "number_of_timesteps": 11974, "per_episode_reward": 18.95, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.5},
{"step": 263, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 264.0, 1.0, 1.0, 1.0, 264.0, 264.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.634, 0.0, 0.0, 0.0, -4.407, -4.447, 0.0, 0.0, 0.0]}
{"number_of_episodes": 540, "number_of_timesteps": 12028, "per_episode_reward": 18.85, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.5500000000000007},
{"step": 264, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 265.0, 1.0, 1.0, 1.0, 265.0, 265.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.636, 0.0, 0.0, 0.0, -4.39, -4.446, 0.0, 0.0, 0.0]}
{"number_of_episodes": 543, "number_of_timesteps": 12091, "per_episode_reward": 18.9, "episode_reward_trend_value": -0.01722222222222223, "biggest_recent_change": 0.5},
{"step": 265, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 266.0, 1.0, 1.0, 1.0, 266.0, 266.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.622, 0.0, 0.0, 0.0, -4.417, -4.472, 0.0, 0.0, 0.0]}
{"number_of_episodes": 544, "number_of_timesteps": 12106, "per_episode_reward": 18.85, "episode_reward_trend_value": -0.020555555555555532, "biggest_recent_change": 0.5},
{"step": 266, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 267.0, 1.0, 1.0, 1.0, 267.0, 267.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.627, 0.0, 0.0, 0.0, -4.419, -4.474, 0.0, 0.0, 0.0]}
{"number_of_episodes": 547, "number_of_timesteps": 12154, "per_episode_reward": 18.9, "episode_reward_trend_value": -0.018333333333333358, "biggest_recent_change": 0.8500000000000014},
{"step": 267, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 268.0, 1.0, 1.0, 1.0, 268.0, 268.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.65, 0.0, 0.0, 0.0, -4.439, -4.494, 0.0, 0.0, 0.0]}
{"step": 268, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 269.0, 1.0, 1.0, 1.0, 269.0, 269.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.697, 0.0, 0.0, 0.0, -4.484, -4.539, 0.0, 0.0, 0.0]}
{"step": 269, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 270.0, 1.0, 1.0, 1.0, 270.0, 270.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.714, 0.0, 0.0, 0.0, -4.497, -4.552, 0.0, 0.0, 0.0]}
{"number_of_episodes": 552, "number_of_timesteps": 12230, "per_episode_reward": 18.6, "episode_reward_trend_value": -0.02166666666666666, "biggest_recent_change": 0.7999999999999972},
{"step": 270, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 271.0, 1.0, 1.0, 1.0, 271.0, 271.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.7, 0.0, 0.0, 0.0, -4.48, -4.535, 0.0, 0.0, 0.0]}
{"number_of_episodes": 557, "number_of_timesteps": 12336, "per_episode_reward": 18.6, "episode_reward_trend_value": -0.022777777777777748, "biggest_recent_change": 0.6499999999999986},
{"step": 271, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 272.0, 1.0, 1.0, 1.0, 272.0, 272.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.701, 0.0, 0.0, 0.0, -4.479, -4.533, 0.0, 0.0, 0.0]}
{"number_of_episodes": 558, "number_of_timesteps": 12346, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.5},
{"step": 272, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 273.0, 1.0, 1.0, 1.0, 273.0, 273.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.687, 0.0, 0.0, 0.0, -4.516, -4.57, 0.0, 0.0, 0.0]}
{"number_of_episodes": 561, "number_of_timesteps": 12416, "per_episode_reward": 18.6, "episode_reward_trend_value": -0.021111111111111094, "biggest_recent_change": 0.5},
{"step": 273, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 274.0, 1.0, 1.0, 1.0, 274.0, 274.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.69, 0.0, 0.0, 0.0, -4.515, -4.569, 0.0, 0.0, 0.0]}
{"step": 274, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 275.0, 1.0, 1.0, 1.0, 275.0, 275.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.696, 0.0, 0.0, 0.0, -4.518, -4.572, 0.0, 0.0, 0.0]}
{"number_of_episodes": 566, "number_of_timesteps": 12560, "per_episode_reward": 18.6, "episode_reward_trend_value": -0.02166666666666666, "biggest_recent_change": 0.7999999999999972},
{"step": 275, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 276.0, 1.0, 1.0, 1.0, 276.0, 276.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.682, 0.0, 0.0, 0.0, -4.502, -4.555, 0.0, 0.0, 0.0]}
{"number_of_episodes": 571, "number_of_timesteps": 12642, "per_episode_reward": 18.55, "episode_reward_trend_value": -0.023888888888888873, "biggest_recent_change": 0.5},
{"step": 276, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 277.0, 1.0, 1.0, 1.0, 277.0, 277.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.669, 0.0, 0.0, 0.0, -4.529, -4.582, 0.0, 0.0, 0.0]}
{"number_of_episodes": 571, "number_of_timesteps": 12642, "per_episode_reward": 18.55, "episode_reward_trend_value": -0.02333333333333331, "biggest_recent_change": 0.5},
{"step": 277, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 278.0, 1.0, 1.0, 1.0, 278.0, 278.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.671, 0.0, 0.0, 0.0, -4.528, -4.581, 0.0, 0.0, 0.0]}
{"number_of_episodes": 574, "number_of_timesteps": 12681, "per_episode_reward": 18.55, "episode_reward_trend_value": -0.02166666666666666, "biggest_recent_change": 0.8500000000000014},
{"step": 278, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 279.0, 1.0, 1.0, 1.0, 279.0, 279.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.715, 0.0, 0.0, 0.0, -4.568, -4.621, 0.0, 0.0, 0.0]}
{"step": 279, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 280.0, 1.0, 1.0, 1.0, 280.0, 280.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.715, 0.0, 0.0, 0.0, -4.565, -4.618, 0.0, 0.0, 0.0]}
{"number_of_episodes": 579, "number_of_timesteps": 12752, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.025555555555555564, "biggest_recent_change": 0.5500000000000007},
{"step": 280, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 281.0, 1.0, 1.0, 1.0, 281.0, 281.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.724, 0.0, 0.0, 0.0, -4.549, -4.624, 0.0, 0.0, 0.0]}
{"step": 281, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 282.0, 1.0, 1.0, 1.0, 282.0, 282.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.729, 0.0, 0.0, 0.0, -4.533, -4.625, 0.0, 0.0, 0.0]}
{"step": 282, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 283.0, 1.0, 1.0, 1.0, 283.0, 283.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.767, 0.0, 0.0, 0.0, -4.568, -4.66, 0.0, 0.0, 0.0]}
{"number_of_episodes": 585, "number_of_timesteps": 12859, "per_episode_reward": 18.15, "episode_reward_trend_value": -0.02666666666666669, "biggest_recent_change": 0.7999999999999972},
{"step": 283, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 284.0, 1.0, 1.0, 1.0, 284.0, 284.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.753, 0.0, 0.0, 0.0, -4.552, -4.644, 0.0, 0.0, 0.0]}
{"step": 284, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 285.0, 1.0, 1.0, 1.0, 285.0, 285.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.74, 0.0, 0.0, 0.0, -4.536, -4.627, 0.0, 0.0, 0.0]}
{"number_of_episodes": 590, "number_of_timesteps": 13000, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.0500000000000007},
{"step": 285, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 286.0, 1.0, 1.0, 1.0, 286.0, 286.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.727, 0.0, 0.0, 0.0, -4.52, -4.611, 0.0, 0.0, 0.0]}
{"number_of_episodes": 593, "number_of_timesteps": 13040, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.02777777777777778, "biggest_recent_change": 0.5},
{"step": 286, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 287.0, 1.0, 1.0, 1.0, 287.0, 287.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.714, 0.0, 0.0, 0.0, -4.542, -4.633, 0.0, 0.0, 0.0]}
{"number_of_episodes": 596, "number_of_timesteps": 13101, "per_episode_reward": 18.2, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.8000000000000007},
{"step": 287, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 288.0, 1.0, 1.0, 1.0, 288.0, 288.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.701, 0.0, 0.0, 0.0, -4.526, -4.617, 0.0, 0.0, 0.0]}
{"step": 288, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 289.0, 1.0, 1.0, 1.0, 289.0, 289.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.688, 0.0, 0.0, 0.0, -4.545, -4.635, 0.0, 0.0, 0.0]}
{"number_of_episodes": 601, "number_of_timesteps": 13185, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.027222222222222214, "biggest_recent_change": 0.7999999999999972},
{"step": 289, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 290.0, 1.0, 1.0, 1.0, 290.0, 290.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.676, 0.0, 0.0, 0.0, -4.53, -4.619, 0.0, 0.0, 0.0]}
{"number_of_episodes": 606, "number_of_timesteps": 13277, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.025, "biggest_recent_change": 0.6499999999999986},
{"step": 290, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 291.0, 1.0, 1.0, 1.0, 291.0, 291.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.678, 0.0, 0.0, 0.0, -4.529, -4.618, 0.0, 0.0, 0.0]}
{"number_of_episodes": 606, "number_of_timesteps": 13277, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.02666666666666665, "biggest_recent_change": 0.5},
{"step": 291, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 292.0, 1.0, 1.0, 1.0, 292.0, 292.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.689, 0.0, 0.0, 0.0, -4.537, -4.626, 0.0, 0.0, 0.0]}
{"step": 292, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 293.0, 1.0, 1.0, 1.0, 293.0, 293.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.682, 0.0, 0.0, 0.0, -4.527, -4.616, 0.0, 0.0, 0.0]}
{"number_of_episodes": 612, "number_of_timesteps": 13359, "per_episode_reward": 18.2, "episode_reward_trend_value": -0.02666666666666669, "biggest_recent_change": 0.7999999999999972},
{"step": 293, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 294.0, 1.0, 1.0, 1.0, 294.0, 294.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.669, 0.0, 0.0, 0.0, -4.512, -4.6, 0.0, 0.0, 0.0]}
{"number_of_episodes": 615, "number_of_timesteps": 13409, "per_episode_reward": 18.2, "episode_reward_trend_value": -0.027222222222222214, "biggest_recent_change": 0.5500000000000007},
{"step": 294, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 295.0, 1.0, 1.0, 1.0, 295.0, 295.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.673, 0.0, 0.0, 0.0, -4.496, -4.601, 0.0, 0.0, 0.0]}
{"number_of_episodes": 615, "number_of_timesteps": 13409, "per_episode_reward": 18.2, "episode_reward_trend_value": -0.027222222222222214, "biggest_recent_change": 0.8500000000000014},
{"step": 295, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 296.0, 1.0, 1.0, 1.0, 296.0, 296.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.708, 0.0, 0.0, 0.0, -4.528, -4.633, 0.0, 0.0, 0.0]}
{"step": 296, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 297.0, 1.0, 1.0, 1.0, 297.0, 297.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.704, 0.0, 0.0, 0.0, -4.522, -4.626, 0.0, 0.0, 0.0]}
{"number_of_episodes": 623, "number_of_timesteps": 13550, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.02611111111111113, "biggest_recent_change": 0.6499999999999986},
{"step": 297, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 298.0, 1.0, 1.0, 1.0, 298.0, 298.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.707, 0.0, 0.0, 0.0, -4.522, -4.626, 0.0, 0.0, 0.0]}
{"number_of_episodes": 625, "number_of_timesteps": 13610, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.02777777777777778, "biggest_recent_change": 0.5},
{"step": 298, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 299.0, 1.0, 1.0, 1.0, 299.0, 299.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.709, 0.0, 0.0, 0.0, -4.521, -4.624, 0.0, 0.0, 0.0]}
{"number_of_episodes": 626, "number_of_timesteps": 13621, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.02777777777777778, "biggest_recent_change": 0.8999999999999986},
{"step": 299, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 300.0, 1.0, 1.0, 1.0, 300.0, 300.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.711, 0.0, 0.0, 0.0, -4.521, -4.609, 0.0, 0.0, 0.0]}
{"step": 300, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 301.0, 1.0, 1.0, 1.0, 301.0, 301.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.722, 0.0, 0.0, 0.0, -4.529, -4.616, 0.0, 0.0, 0.0]}
{"step": 301, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 302.0, 1.0, 1.0, 1.0, 302.0, 302.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.729, 0.0, 0.0, 0.0, -4.533, -4.621, 0.0, 0.0, 0.0]}
{"number_of_episodes": 632, "number_of_timesteps": 13737, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.027222222222222214, "biggest_recent_change": 0.5500000000000007},
{"step": 302, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 303.0, 1.0, 1.0, 1.0, 303.0, 303.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.732, 0.0, 0.0, 0.0, -4.518, -4.621, 0.0, 0.0, 0.0]}
{"number_of_episodes": 634, "number_of_timesteps": 13791, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.025555555555555564, "biggest_recent_change": 0.8500000000000014},
{"step": 303, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 304.0, 1.0, 1.0, 1.0, 304.0, 304.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.772, 0.0, 0.0, 0.0, -4.556, -4.658, 0.0, 0.0, 0.0]}
{"number_of_episodes": 636, "number_of_timesteps": 13826, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.02666666666666665, "biggest_recent_change": 0.5},
{"step": 304, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 305.0, 1.0, 1.0, 1.0, 305.0, 305.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.778, 0.0, 0.0, 0.0, -4.559, -4.661, 0.0, 0.0, 0.0]}
{"step": 305, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 306.0, 1.0, 1.0, 1.0, 306.0, 306.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.778, 0.0, 0.0, 0.0, -4.557, -4.658, 0.0, 0.0, 0.0]}
{"step": 306, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 307.0, 1.0, 1.0, 1.0, 307.0, 307.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.784, 0.0, 0.0, 0.0, -4.542, -4.661, 0.0, 0.0, 0.0]}
{"step": 307, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 308.0, 1.0, 1.0, 1.0, 308.0, 308.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.811, 0.0, 0.0, 0.0, -4.567, -4.686, 0.0, 0.0, 0.0]}
{"step": 308, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 309.0, 1.0, 1.0, 1.0, 309.0, 309.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.839, 0.0, 0.0, 0.0, -4.593, -4.711, 0.0, 0.0, 0.0]}
{"number_of_episodes": 644, "number_of_timesteps": 14028, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.027222222222222214, "biggest_recent_change": 0.8500000000000014},
{"step": 309, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 310.0, 1.0, 1.0, 1.0, 310.0, 310.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.86, 0.0, 0.0, 0.0, -4.611, -4.728, 0.0, 0.0, 0.0]}
{"number_of_episodes": 648, "number_of_timesteps": 14123, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.02333333333333331, "biggest_recent_change": 0.5},
{"step": 310, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 311.0, 1.0, 1.0, 1.0, 311.0, 311.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.847, 0.0, 0.0, 0.0, -4.647, -4.765, 0.0, 0.0, 0.0]}
{"step": 311, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 312.0, 1.0, 1.0, 1.0, 312.0, 312.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.835, 0.0, 0.0, 0.0, -4.674, -4.791, 0.0, 0.0, 0.0]}
{"eval_score": 26.9, "number_of_episodes": 652}
{"number_of_episodes": 652, "number_of_timesteps": 14197, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.022777777777777786, "biggest_recent_change": 0.7999999999999972},
{"step": 312, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 313.0, 1.0, 1.0, 1.0, 313.0, 313.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.823, 0.0, 0.0, 0.0, -4.659, -4.775, 0.0, 0.0, 0.0]}
{"number_of_episodes": 655, "number_of_timesteps": 14248, "per_episode_reward": 18.35, "episode_reward_trend_value": -0.023888888888888873, "biggest_recent_change": 0.8000000000000007},
{"step": 313, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 314.0, 1.0, 1.0, 1.0, 314.0, 314.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.811, 0.0, 0.0, 0.0, -4.644, -4.76, 0.0, 0.0, 0.0]}
{"number_of_episodes": 655, "number_of_timesteps": 14248, "per_episode_reward": 18.35, "episode_reward_trend_value": -0.026111111111111085, "biggest_recent_change": 0.8999999999999986},
{"step": 314, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 315.0, 1.0, 1.0, 1.0, 315.0, 315.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.814, 0.0, 0.0, 0.0, -4.645, -4.745, 0.0, 0.0, 0.0]}
{"number_of_episodes": 658, "number_of_timesteps": 14325, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.02666666666666665, "biggest_recent_change": 0.6499999999999986},
{"step": 315, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 316.0, 1.0, 1.0, 1.0, 316.0, 316.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.818, 0.0, 0.0, 0.0, -4.646, -4.746, 0.0, 0.0, 0.0]}
{"step": 316, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 317.0, 1.0, 1.0, 1.0, 317.0, 317.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.806, 0.0, 0.0, 0.0, -4.632, -4.731, 0.0, 0.0, 0.0]}
{"number_of_episodes": 664, "number_of_timesteps": 14452, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 0.7999999999999972},
{"step": 317, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 318.0, 1.0, 1.0, 1.0, 318.0, 318.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.794, 0.0, 0.0, 0.0, -4.617, -4.716, 0.0, 0.0, 0.0]}
{"number_of_episodes": 665, "number_of_timesteps": 14464, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 1.0500000000000007},
{"step": 318, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 319.0, 1.0, 1.0, 1.0, 319.0, 319.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.782, 0.0, 0.0, 0.0, -4.602, -4.701, 0.0, 0.0, 0.0]}
{"step": 319, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 320.0, 1.0, 1.0, 1.0, 320.0, 320.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.77, 0.0, 0.0, 0.0, -4.588, -4.687, 0.0, 0.0, 0.0]}
{"number_of_episodes": 668, "number_of_timesteps": 14513, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.020555555555555532, "biggest_recent_change": 0.6499999999999986},
{"step": 320, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 321.0, 1.0, 1.0, 1.0, 321.0, 321.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.775, 0.0, 0.0, 0.0, -4.59, -4.688, 0.0, 0.0, 0.0]}
{"number_of_episodes": 670, "number_of_timesteps": 14576, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.8999999999999986},
{"step": 321, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 322.0, 1.0, 1.0, 1.0, 322.0, 322.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.778, 0.0, 0.0, 0.0, -4.591, -4.674, 0.0, 0.0, 0.0]}
{"step": 322, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 323.0, 1.0, 1.0, 1.0, 323.0, 323.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.767, 0.0, 0.0, 0.0, -4.577, -4.659, 0.0, 0.0, 0.0]}
{"number_of_episodes": 675, "number_of_timesteps": 14666, "per_episode_reward": 18.45, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.7999999999999972},
{"step": 323, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 324.0, 1.0, 1.0, 1.0, 324.0, 324.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.755, 0.0, 0.0, 0.0, -4.563, -4.645, 0.0, 0.0, 0.0]}
{"step": 324, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 325.0, 1.0, 1.0, 1.0, 325.0, 325.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.757, 0.0, 0.0, 0.0, -4.562, -4.644, 0.0, 0.0, 0.0]}
{"number_of_episodes": 677, "number_of_timesteps": 14717, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.01722222222222223, "biggest_recent_change": 0.5},
{"step": 325, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 326.0, 1.0, 1.0, 1.0, 326.0, 326.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.745, 0.0, 0.0, 0.0, -4.588, -4.67, 0.0, 0.0, 0.0]}
{"number_of_episodes": 682, "number_of_timesteps": 14864, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.023333333333333352, "biggest_recent_change": 0.8999999999999986},
{"step": 326, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 327.0, 1.0, 1.0, 1.0, 327.0, 327.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.747, 0.0, 0.0, 0.0, -4.588, -4.656, 0.0, 0.0, 0.0]}
{"number_of_episodes": 686, "number_of_timesteps": 14938, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 0.5499999999999972},
{"step": 327, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 328.0, 1.0, 1.0, 1.0, 328.0, 328.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.769, 0.0, 0.0, 0.0, -4.607, -4.675, 0.0, 0.0, 0.0]}
{"number_of_episodes": 686, "number_of_timesteps": 14938, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 0.6499999999999986},
{"step": 328, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 329.0, 1.0, 1.0, 1.0, 329.0, 329.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.775, 0.0, 0.0, 0.0, -4.611, -4.678, 0.0, 0.0, 0.0]}
{"number_of_episodes": 690, "number_of_timesteps": 14983, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.5500000000000007},
{"step": 329, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 330.0, 1.0, 1.0, 1.0, 330.0, 330.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.777, 0.0, 0.0, 0.0, -4.597, -4.677, 0.0, 0.0, 0.0]}
{"number_of_episodes": 694, "number_of_timesteps": 15051, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 0.5},
{"step": 330, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 331.0, 1.0, 1.0, 1.0, 331.0, 331.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.785, 0.0, 0.0, 0.0, -4.602, -4.682, 0.0, 0.0, 0.0]}
{"step": 331, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 332.0, 1.0, 1.0, 1.0, 332.0, 332.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.787, 0.0, 0.0, 0.0, -4.602, -4.681, 0.0, 0.0, 0.0]}
{"number_of_episodes": 697, "number_of_timesteps": 15084, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.8000000000000007},
{"step": 332, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 333.0, 1.0, 1.0, 1.0, 333.0, 333.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.776, 0.0, 0.0, 0.0, -4.588, -4.667, 0.0, 0.0, 0.0]}
{"number_of_episodes": 702, "number_of_timesteps": 15159, "per_episode_reward": 18.4, "episode_reward_trend_value": -0.01888888888888892, "biggest_recent_change": 0.8999999999999986},
{"step": 333, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 334.0, 1.0, 1.0, 1.0, 334.0, 334.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.776, 0.0, 0.0, 0.0, -4.586, -4.653, 0.0, 0.0, 0.0]}
{"step": 334, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 335.0, 1.0, 1.0, 1.0, 335.0, 335.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.765, 0.0, 0.0, 0.0, -4.572, -4.639, 0.0, 0.0, 0.0]}
{"number_of_episodes": 705, "number_of_timesteps": 15237, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.00944444444444446, "biggest_recent_change": 0.3500000000000014},
{"step": 335, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 336.0, 1.0, 1.0, 1.0, 336.0, 336.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.797, 0.0, 0.0, 0.0, -4.602, -4.669, 0.0, 0.0, 0.0]}
{"number_of_episodes": 708, "number_of_timesteps": 15272, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.020555555555555532, "biggest_recent_change": 0.5500000000000007},
{"step": 336, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 337.0, 1.0, 1.0, 1.0, 337.0, 337.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.787, 0.0, 0.0, 0.0, -4.589, -4.657, 0.0, 0.0, 0.0]}
{"number_of_episodes": 711, "number_of_timesteps": 15325, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.012777777777777763, "biggest_recent_change": 0.7999999999999972},
{"step": 337, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 338.0, 1.0, 1.0, 1.0, 338.0, 338.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.776, 0.0, 0.0, 0.0, -4.575, -4.643, 0.0, 0.0, 0.0]}
{"number_of_episodes": 713, "number_of_timesteps": 15373, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.01444444444444445, "biggest_recent_change": 0.3999999999999986},
{"step": 338, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 339.0, 1.0, 1.0, 1.0, 339.0, 339.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.765, 0.0, 0.0, 0.0, -4.588, -4.655, 0.0, 0.0, 0.0]}
{"number_of_episodes": 719, "number_of_timesteps": 15465, "per_episode_reward": 18.15, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 0.5},
{"step": 339, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 340.0, 1.0, 1.0, 1.0, 340.0, 340.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.768, 0.0, 0.0, 0.0, -4.588, -4.656, 0.0, 0.0, 0.0]}
{"number_of_episodes": 719, "number_of_timesteps": 15465, "per_episode_reward": 18.15, "episode_reward_trend_value": -0.028333333333333342, "biggest_recent_change": 0.8000000000000007},
{"step": 340, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 341.0, 1.0, 1.0, 1.0, 341.0, 341.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.757, 0.0, 0.0, 0.0, -4.575, -4.642, 0.0, 0.0, 0.0]}
{"step": 341, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 342.0, 1.0, 1.0, 1.0, 342.0, 342.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.757, 0.0, 0.0, 0.0, -4.572, -4.639, 0.0, 0.0, 0.0]}
{"number_of_episodes": 724, "number_of_timesteps": 15550, "per_episode_reward": 18.15, "episode_reward_trend_value": -0.012777777777777801, "biggest_recent_change": 0.3999999999999986},
{"step": 342, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 343.0, 1.0, 1.0, 1.0, 343.0, 343.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.746, 0.0, 0.0, 0.0, -4.595, -4.661, 0.0, 0.0, 0.0]}
{"step": 343, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 344.0, 1.0, 1.0, 1.0, 344.0, 344.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.735, 0.0, 0.0, 0.0, -4.581, -4.648, 0.0, 0.0, 0.0]}
{"number_of_episodes": 729, "number_of_timesteps": 15654, "per_episode_reward": 18.2, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.5},
{"step": 344, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 345.0, 1.0, 1.0, 1.0, 345.0, 345.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.736, 0.0, 0.0, 0.0, -4.58, -4.647, 0.0, 0.0, 0.0]}
{"number_of_episodes": 731, "number_of_timesteps": 15698, "per_episode_reward": 18.2, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.8999999999999986},
{"step": 345, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 346.0, 1.0, 1.0, 1.0, 346.0, 346.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.738, 0.0, 0.0, 0.0, -4.58, -4.633, 0.0, 0.0, 0.0]}
{"number_of_episodes": 733, "number_of_timesteps": 15734, "per_episode_reward": 18.2, "episode_reward_trend_value": -0.015000000000000017, "biggest_recent_change": 0.6499999999999986},
{"step": 346, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 347.0, 1.0, 1.0, 1.0, 347.0, 347.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.742, 0.0, 0.0, 0.0, -4.581, -4.635, 0.0, 0.0, 0.0]}
{"step": 347, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 348.0, 1.0, 1.0, 1.0, 348.0, 348.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.748, 0.0, 0.0, 0.0, -4.585, -4.621, 0.0, 0.0, 0.0]}
{"step": 348, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 349.0, 1.0, 1.0, 1.0, 349.0, 349.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.758, 0.0, 0.0, 0.0, -4.592, -4.608, 0.0, 0.0, 0.0]}
{"number_of_episodes": 741, "number_of_timesteps": 15864, "per_episode_reward": 18.15, "episode_reward_trend_value": -0.025555555555555564, "biggest_recent_change": 1.0500000000000007},
{"step": 349, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 350.0, 1.0, 1.0, 1.0, 350.0, 350.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.747, 0.0, 0.0, 0.0, -4.579, -4.595, 0.0, 0.0, 0.0]}
{"number_of_episodes": 744, "number_of_timesteps": 15903, "per_episode_reward": 18.1, "episode_reward_trend_value": -0.022777777777777748, "biggest_recent_change": 0.4499999999999993},
{"step": 350, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 351.0, 1.0, 1.0, 1.0, 351.0, 351.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.748, 0.0, 0.0, 0.0, -4.577, -4.593, 0.0, 0.0, 0.0]}
{"number_of_episodes": 746, "number_of_timesteps": 15955, "per_episode_reward": 18.15, "episode_reward_trend_value": -0.01444444444444445, "biggest_recent_change": 0.5},
{"step": 351, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 352.0, 1.0, 1.0, 1.0, 352.0, 352.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.749, 0.0, 0.0, 0.0, -4.577, -4.593, 0.0, 0.0, 0.0]}
{"step": 352, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 353.0, 1.0, 1.0, 1.0, 353.0, 353.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.75, 0.0, 0.0, 0.0, -4.575, -4.591, 0.0, 0.0, 0.0]}
{"number_of_episodes": 753, "number_of_timesteps": 16071, "per_episode_reward": 18.05, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 0.5500000000000007},
{"step": 353, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 354.0, 1.0, 1.0, 1.0, 354.0, 354.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.751, 0.0, 0.0, 0.0, -4.562, -4.59, 0.0, 0.0, 0.0]}
{"step": 354, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 355.0, 1.0, 1.0, 1.0, 355.0, 355.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.756, 0.0, 0.0, 0.0, -4.549, -4.592, 0.0, 0.0, 0.0]}
{"number_of_episodes": 758, "number_of_timesteps": 16147, "per_episode_reward": 17.95, "episode_reward_trend_value": -0.011666666666666676, "biggest_recent_change": 0.3999999999999986},
{"step": 355, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 356.0, 1.0, 1.0, 1.0, 356.0, 356.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.745, 0.0, 0.0, 0.0, -4.558, -4.6, 0.0, 0.0, 0.0]}
{"step": 356, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 357.0, 1.0, 1.0, 1.0, 357.0, 357.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.735, 0.0, 0.0, 0.0, -4.578, -4.62, 0.0, 0.0, 0.0]}
{"number_of_episodes": 766, "number_of_timesteps": 16249, "per_episode_reward": 17.7, "episode_reward_trend_value": -0.03222222222222225, "biggest_recent_change": 1.0500000000000007},
{"step": 357, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 358.0, 1.0, 1.0, 1.0, 358.0, 358.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.724, 0.0, 0.0, 0.0, -4.565, -4.607, 0.0, 0.0, 0.0]}
{"number_of_episodes": 767, "number_of_timesteps": 16291, "per_episode_reward": 17.7, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.5500000000000007},
{"step": 358, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 359.0, 1.0, 1.0, 1.0, 359.0, 359.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.714, 0.0, 0.0, 0.0, -4.553, -4.595, 0.0, 0.0, 0.0]}
{"number_of_episodes": 773, "number_of_timesteps": 16366, "per_episode_reward": 17.7, "episode_reward_trend_value": -0.02611111111111113, "biggest_recent_change": 0.4499999999999993},
{"step": 359, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 360.0, 1.0, 1.0, 1.0, 360.0, 360.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.717, 0.0, 0.0, 0.0, -4.553, -4.595, 0.0, 0.0, 0.0]}
{"number_of_episodes": 774, "number_of_timesteps": 16379, "per_episode_reward": 17.65, "episode_reward_trend_value": -0.01777777777777779, "biggest_recent_change": 0.6499999999999986},
{"step": 360, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 361.0, 1.0, 1.0, 1.0, 361.0, 361.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.71, 0.0, 0.0, 0.0, -4.545, -4.586, 0.0, 0.0, 0.0]}
{"number_of_episodes": 777, "number_of_timesteps": 16433, "per_episode_reward": 17.7, "episode_reward_trend_value": -0.03166666666666668, "biggest_recent_change": 1.0500000000000007},
{"step": 361, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 362.0, 1.0, 1.0, 1.0, 362.0, 362.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.7, 0.0, 0.0, 0.0, -4.532, -4.574, 0.0, 0.0, 0.0]}
{"eval_score": 13.5, "number_of_episodes": 781}
{"step": 362, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 363.0, 1.0, 1.0, 1.0, 363.0, 363.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.69, 0.0, 0.0, 0.0, -4.52, -4.561, 0.0, 0.0, 0.0]}
{"number_of_episodes": 783, "number_of_timesteps": 16520, "per_episode_reward": 17.7, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 0.8999999999999986},
{"step": 363, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 364.0, 1.0, 1.0, 1.0, 364.0, 364.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.693, 0.0, 0.0, 0.0, -4.521, -4.548, 0.0, 0.0, 0.0]}
{"number_of_episodes": 786, "number_of_timesteps": 16566, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.02166666666666666, "biggest_recent_change": 1.0500000000000007},
{"step": 364, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 365.0, 1.0, 1.0, 1.0, 365.0, 365.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.726, 0.0, 0.0, 0.0, -4.552, -4.579, 0.0, 0.0, 0.0]}
{"number_of_episodes": 788, "number_of_timesteps": 16594, "per_episode_reward": 17.4, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 0.6499999999999986},
{"step": 365, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 366.0, 1.0, 1.0, 1.0, 366.0, 366.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.727, 0.0, 0.0, 0.0, -4.55, -4.578, 0.0, 0.0, 0.0]}
{"number_of_episodes": 790, "number_of_timesteps": 16614, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.03611111111111111, "biggest_recent_change": 0.8000000000000007},
{"step": 366, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 367.0, 1.0, 1.0, 1.0, 367.0, 367.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.717, 0.0, 0.0, 0.0, -4.538, -4.565, 0.0, 0.0, 0.0]}
{"number_of_episodes": 795, "number_of_timesteps": 16703, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.01722222222222219, "biggest_recent_change": 0.5999999999999979},
{"step": 367, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 368.0, 1.0, 1.0, 1.0, 368.0, 368.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.707, 0.0, 0.0, 0.0, -4.553, -4.581, 0.0, 0.0, 0.0]}
{"step": 368, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 369.0, 1.0, 1.0, 1.0, 369.0, 369.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.697, 0.0, 0.0, 0.0, -4.601, -4.629, 0.0, 0.0, 0.0]}
{"step": 369, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 370.0, 1.0, 1.0, 1.0, 370.0, 370.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.687, 0.0, 0.0, 0.0, -4.589, -4.616, 0.0, 0.0, 0.0]}
{"number_of_episodes": 803, "number_of_timesteps": 16842, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.022777777777777748, "biggest_recent_change": 0.8999999999999986},
{"step": 370, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 371.0, 1.0, 1.0, 1.0, 371.0, 371.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.688, 0.0, 0.0, 0.0, -4.588, -4.604, 0.0, 0.0, 0.0]}
{"number_of_episodes": 805, "number_of_timesteps": 16875, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.012777777777777763, "biggest_recent_change": 0.5999999999999979},
{"step": 371, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 372.0, 1.0, 1.0, 1.0, 372.0, 372.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.678, 0.0, 0.0, 0.0, -4.616, -4.632, 0.0, 0.0, 0.0]}
{"number_of_episodes": 806, "number_of_timesteps": 16889, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.03777777777777776, "biggest_recent_change": 1.0500000000000007},
{"step": 372, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 373.0, 1.0, 1.0, 1.0, 373.0, 373.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.668, 0.0, 0.0, 0.0, -4.604, -4.62, 0.0, 0.0, 0.0]}
{"number_of_episodes": 812, "number_of_timesteps": 16988, "per_episode_reward": 17.35, "episode_reward_trend_value": -0.022777777777777748, "biggest_recent_change": 0.6999999999999993},
{"step": 373, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 374.0, 1.0, 1.0, 1.0, 374.0, 374.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.676, 0.0, 0.0, 0.0, -4.591, -4.625, 0.0, 0.0, 0.0]}
{"step": 374, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 375.0, 1.0, 1.0, 1.0, 375.0, 375.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.678, 0.0, 0.0, 0.0, -4.579, -4.625, 0.0, 0.0, 0.0]}
{"number_of_episodes": 817, "number_of_timesteps": 17060, "per_episode_reward": 17.25, "episode_reward_trend_value": -0.03222222222222221, "biggest_recent_change": 0.8000000000000007},
{"step": 375, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 376.0, 1.0, 1.0, 1.0, 376.0, 376.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.669, 0.0, 0.0, 0.0, -4.567, -4.613, 0.0, 0.0, 0.0]}
{"step": 376, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 377.0, 1.0, 1.0, 1.0, 377.0, 377.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.673, 0.0, 0.0, 0.0, -4.555, -4.615, 0.0, 0.0, 0.0]}
{"number_of_episodes": 824, "number_of_timesteps": 17159, "per_episode_reward": 17.3, "episode_reward_trend_value": -0.020555555555555532, "biggest_recent_change": 0.8999999999999986},
{"step": 377, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 378.0, 1.0, 1.0, 1.0, 378.0, 378.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.679, 0.0, 0.0, 0.0, -4.558, -4.602, 0.0, 0.0, 0.0]}
{"number_of_episodes": 827, "number_of_timesteps": 17197, "per_episode_reward": 17.2, "episode_reward_trend_value": -0.025, "biggest_recent_change": 0.8000000000000007},
{"step": 378, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 379.0, 1.0, 1.0, 1.0, 379.0, 379.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.669, 0.0, 0.0, 0.0, -4.546, -4.59, 0.0, 0.0, 0.0]}
{"step": 379, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 380.0, 1.0, 1.0, 1.0, 380.0, 380.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.673, 0.0, 0.0, 0.0, -4.548, -4.578, 0.0, 0.0, 0.0]}
{"number_of_episodes": 836, "number_of_timesteps": 17296, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.016111111111111104, "biggest_recent_change": 0.5999999999999979},
{"step": 380, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 381.0, 1.0, 1.0, 1.0, 381.0, 381.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.663, 0.0, 0.0, 0.0, -4.565, -4.596, 0.0, 0.0, 0.0]}
{"number_of_episodes": 838, "number_of_timesteps": 17320, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 1.0500000000000007},
{"step": 381, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 382.0, 1.0, 1.0, 1.0, 382.0, 382.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.688, 0.0, 0.0, 0.0, -4.587, -4.617, 0.0, 0.0, 0.0]}
{"number_of_episodes": 842, "number_of_timesteps": 17372, "per_episode_reward": 17.05, "episode_reward_trend_value": -0.021111111111111094, "biggest_recent_change": 1.0999999999999979},
{"step": 382, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 383.0, 1.0, 1.0, 1.0, 383.0, 383.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.694, 0.0, 0.0, 0.0, -4.59, -4.621, 0.0, 0.0, 0.0]}
{"number_of_episodes": 845, "number_of_timesteps": 17410, "per_episode_reward": 17.05, "episode_reward_trend_value": -0.029999999999999992, "biggest_recent_change": 0.6499999999999986},
{"step": 383, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 384.0, 1.0, 1.0, 1.0, 384.0, 384.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.696, 0.0, 0.0, 0.0, -4.591, -4.621, 0.0, 0.0, 0.0]}
{"number_of_episodes": 849, "number_of_timesteps": 17472, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.6999999999999993},
{"step": 384, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 385.0, 1.0, 1.0, 1.0, 385.0, 385.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.703, 0.0, 0.0, 0.0, -4.579, -4.625, 0.0, 0.0, 0.0]}
{"number_of_episodes": 852, "number_of_timesteps": 17508, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.5500000000000007},
{"step": 385, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 386.0, 1.0, 1.0, 1.0, 386.0, 386.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.708, 0.0, 0.0, 0.0, -4.582, -4.628, 0.0, 0.0, 0.0]}
{"number_of_episodes": 857, "number_of_timesteps": 17570, "per_episode_reward": 17.05, "episode_reward_trend_value": -0.02944444444444443, "biggest_recent_change": 1.0500000000000007},
{"step": 386, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 387.0, 1.0, 1.0, 1.0, 387.0, 387.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.698, 0.0, 0.0, 0.0, -4.57, -4.616, 0.0, 0.0, 0.0]}
{"number_of_episodes": 858, "number_of_timesteps": 17584, "per_episode_reward": 17.05, "episode_reward_trend_value": -0.025, "biggest_recent_change": 0.8000000000000007},
{"step": 387, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 388.0, 1.0, 1.0, 1.0, 388.0, 388.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.689, 0.0, 0.0, 0.0, -4.558, -4.604, 0.0, 0.0, 0.0]}
{"number_of_episodes": 862, "number_of_timesteps": 17640, "per_episode_reward": 17.05, "episode_reward_trend_value": -0.01722222222222223, "biggest_recent_change": 0.6499999999999986},
{"step": 388, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 389.0, 1.0, 1.0, 1.0, 389.0, 389.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.679, 0.0, 0.0, 0.0, -4.546, -4.592, 0.0, 0.0, 0.0]}
{"number_of_episodes": 866, "number_of_timesteps": 17692, "per_episode_reward": 16.95, "episode_reward_trend_value": -0.028333333333333342, "biggest_recent_change": 0.6499999999999986},
{"step": 389, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 390.0, 1.0, 1.0, 1.0, 390.0, 390.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.683, 0.0, 0.0, 0.0, -4.548, -4.594, 0.0, 0.0, 0.0]}
{"number_of_episodes": 868, "number_of_timesteps": 17722, "per_episode_reward": 16.95, "episode_reward_trend_value": -0.021111111111111136, "biggest_recent_change": 0.6999999999999993},
{"step": 390, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 391.0, 1.0, 1.0, 1.0, 391.0, 391.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.689, 0.0, 0.0, 0.0, -4.536, -4.597, 0.0, 0.0, 0.0]}
{"number_of_episodes": 873, "number_of_timesteps": 17779, "per_episode_reward": 16.85, "episode_reward_trend_value": -0.028888888888888863, "biggest_recent_change": 1.0500000000000007},
{"step": 391, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 392.0, 1.0, 1.0, 1.0, 392.0, 392.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.679, 0.0, 0.0, 0.0, -4.525, -4.585, 0.0, 0.0, 0.0]}
{"step": 392, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 393.0, 1.0, 1.0, 1.0, 393.0, 393.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.67, 0.0, 0.0, 0.0, -4.513, -4.574, 0.0, 0.0, 0.0]}
{"number_of_episodes": 878, "number_of_timesteps": 17843, "per_episode_reward": 16.85, "episode_reward_trend_value": -0.022777777777777748, "biggest_recent_change": 1.0500000000000007},
{"step": 393, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 394.0, 1.0, 1.0, 1.0, 394.0, 394.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.689, 0.0, 0.0, 0.0, -4.531, -4.591, 0.0, 0.0, 0.0]}
{"number_of_episodes": 884, "number_of_timesteps": 17923, "per_episode_reward": 16.8, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.0999999999999979},
{"step": 394, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 395.0, 1.0, 1.0, 1.0, 395.0, 395.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.691, 0.0, 0.0, 0.0, -4.53, -4.59, 0.0, 0.0, 0.0]}
{"number_of_episodes": 886, "number_of_timesteps": 17948, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.0288888888888889, "biggest_recent_change": 1.0500000000000007},
{"step": 395, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 396.0, 1.0, 1.0, 1.0, 396.0, 396.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.682, 0.0, 0.0, 0.0, -4.519, -4.578, 0.0, 0.0, 0.0]}
{"step": 396, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 397.0, 1.0, 1.0, 1.0, 397.0, 397.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.672, 0.0, 0.0, 0.0, -4.507, -4.567, 0.0, 0.0, 0.0]}
{"step": 397, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 398.0, 1.0, 1.0, 1.0, 398.0, 398.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.674, 0.0, 0.0, 0.0, -4.507, -4.566, 0.0, 0.0, 0.0]}
{"number_of_episodes": 895, "number_of_timesteps": 18059, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 0.5999999999999979},
{"step": 398, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 399.0, 1.0, 1.0, 1.0, 399.0, 399.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.665, 0.0, 0.0, 0.0, -4.534, -4.594, 0.0, 0.0, 0.0]}
{"number_of_episodes": 900, "number_of_timesteps": 18123, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 0.6999999999999993},
{"step": 399, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 400.0, 1.0, 1.0, 1.0, 400.0, 400.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.67, 0.0, 0.0, 0.0, -4.523, -4.596, 0.0, 0.0, 0.0]}
{"number_of_episodes": 901, "number_of_timesteps": 18132, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.028333333333333342, "biggest_recent_change": 0.8000000000000007},
{"step": 400, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 401.0, 1.0, 1.0, 1.0, 401.0, 401.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.661, 0.0, 0.0, 0.0, -4.512, -4.585, 0.0, 0.0, 0.0]}
{"step": 401, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 402.0, 1.0, 1.0, 1.0, 402.0, 402.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.663, 0.0, 0.0, 0.0, -4.5, -4.584, 0.0, 0.0, 0.0]}
{"eval_score": 16.8, "number_of_episodes": 910}
{"step": 402, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 403.0, 1.0, 1.0, 1.0, 403.0, 403.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.653, 0.0, 0.0, 0.0, -4.489, -4.573, 0.0, 0.0, 0.0]}
{"number_of_episodes": 913, "number_of_timesteps": 18293, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 0.5999999999999979},
{"step": 403, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 404.0, 1.0, 1.0, 1.0, 404.0, 404.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.644, 0.0, 0.0, 0.0, -4.507, -4.591, 0.0, 0.0, 0.0]}
{"number_of_episodes": 916, "number_of_timesteps": 18327, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.02388888888888891, "biggest_recent_change": 1.0500000000000007},
{"step": 404, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 405.0, 1.0, 1.0, 1.0, 405.0, 405.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.665, 0.0, 0.0, 0.0, -4.526, -4.609, 0.0, 0.0, 0.0]}
{"step": 405, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 406.0, 1.0, 1.0, 1.0, 406.0, 406.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.696, 0.0, 0.0, 0.0, -4.554, -4.637, 0.0, 0.0, 0.0]}
{"number_of_episodes": 921, "number_of_timesteps": 18415, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.019444444444444445, "biggest_recent_change": 0.6500000000000021},
{"step": 406, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 407.0, 1.0, 1.0, 1.0, 407.0, 407.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.687, 0.0, 0.0, 0.0, -4.543, -4.626, 0.0, 0.0, 0.0]}
{"number_of_episodes": 925, "number_of_timesteps": 18465, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.020555555555555532, "biggest_recent_change": 0.7999999999999972},
{"step": 407, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 408.0, 1.0, 1.0, 1.0, 408.0, 408.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.678, 0.0, 0.0, 0.0, -4.532, -4.615, 0.0, 0.0, 0.0]}
{"number_of_episodes": 928, "number_of_timesteps": 18510, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.02166666666666666, "biggest_recent_change": 1.0999999999999979},
{"step": 408, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 409.0, 1.0, 1.0, 1.0, 409.0, 409.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.682, 0.0, 0.0, 0.0, -4.534, -4.616, 0.0, 0.0, 0.0]}
{"step": 409, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 410.0, 1.0, 1.0, 1.0, 410.0, 410.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.673, 0.0, 0.0, 0.0, -4.523, -4.605, 0.0, 0.0, 0.0]}
{"step": 410, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 411.0, 1.0, 1.0, 1.0, 411.0, 411.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.678, 0.0, 0.0, 0.0, -4.526, -4.608, 0.0, 0.0, 0.0]}
{"number_of_episodes": 933, "number_of_timesteps": 18595, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.023333333333333352, "biggest_recent_change": 0.5999999999999979},
{"step": 411, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 412.0, 1.0, 1.0, 1.0, 412.0, 412.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.669, 0.0, 0.0, 0.0, -4.544, -4.626, 0.0, 0.0, 0.0]}
{"number_of_episodes": 938, "number_of_timesteps": 18688, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.0500000000000007},
{"step": 412, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 413.0, 1.0, 1.0, 1.0, 413.0, 413.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.695, 0.0, 0.0, 0.0, -4.569, -4.65, 0.0, 0.0, 0.0]}
{"step": 413, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 414.0, 1.0, 1.0, 1.0, 414.0, 414.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.686, 0.0, 0.0, 0.0, -4.6, -4.681, 0.0, 0.0, 0.0]}
{"step": 414, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 415.0, 1.0, 1.0, 1.0, 415.0, 415.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.677, 0.0, 0.0, 0.0, -4.616, -4.697, 0.0, 0.0, 0.0]}
{"number_of_episodes": 943, "number_of_timesteps": 18781, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.0999999999999979},
{"step": 415, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 416.0, 1.0, 1.0, 1.0, 416.0, 416.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.672, 0.0, 0.0, 0.0, -4.608, -4.689, 0.0, 0.0, 0.0]}
{"number_of_episodes": 945, "number_of_timesteps": 18814, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.019444444444444445, "biggest_recent_change": 0.6999999999999993},
{"step": 416, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 417.0, 1.0, 1.0, 1.0, 417.0, 417.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.675, 0.0, 0.0, 0.0, -4.597, -4.689, 0.0, 0.0, 0.0]}
{"number_of_episodes": 950, "number_of_timesteps": 18914, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 1.0500000000000007},
{"step": 417, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 418.0, 1.0, 1.0, 1.0, 418.0, 418.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.7, 0.0, 0.0, 0.0, -4.62, -4.713, 0.0, 0.0, 0.0]}
{"number_of_episodes": 951, "number_of_timesteps": 18947, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.03333333333333333, "biggest_recent_change": 0.6499999999999986},
{"step": 418, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 419.0, 1.0, 1.0, 1.0, 419.0, 419.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.705, 0.0, 0.0, 0.0, -4.623, -4.715, 0.0, 0.0, 0.0]}
{"number_of_episodes": 955, "number_of_timesteps": 18989, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 0.5999999999999979},
{"step": 419, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 420.0, 1.0, 1.0, 1.0, 420.0, 420.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.696, 0.0, 0.0, 0.0, -4.642, -4.734, 0.0, 0.0, 0.0]}
{"number_of_episodes": 958, "number_of_timesteps": 19037, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 0.4499999999999993},
{"step": 420, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 421.0, 1.0, 1.0, 1.0, 421.0, 421.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.687, 0.0, 0.0, 0.0, -4.631, -4.722, 0.0, 0.0, 0.0]}
{"number_of_episodes": 960, "number_of_timesteps": 19059, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 0.6999999999999993},
{"step": 421, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 422.0, 1.0, 1.0, 1.0, 422.0, 422.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.692, 0.0, 0.0, 0.0, -4.62, -4.725, 0.0, 0.0, 0.0]}
{"number_of_episodes": 962, "number_of_timesteps": 19091, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 0.6000000000000014},
{"step": 422, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 423.0, 1.0, 1.0, 1.0, 423.0, 423.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.697, 0.0, 0.0, 0.0, -4.623, -4.728, 0.0, 0.0, 0.0]}
{"number_of_episodes": 964, "number_of_timesteps": 19119, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.019444444444444445, "biggest_recent_change": 0.6500000000000021},
{"step": 423, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 424.0, 1.0, 1.0, 1.0, 424.0, 424.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.689, 0.0, 0.0, 0.0, -4.612, -4.716, 0.0, 0.0, 0.0]}
{"step": 424, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 425.0, 1.0, 1.0, 1.0, 425.0, 425.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.68, 0.0, 0.0, 0.0, -4.601, -4.705, 0.0, 0.0, 0.0]}
{"step": 425, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 426.0, 1.0, 1.0, 1.0, 426.0, 426.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.671, 0.0, 0.0, 0.0, -4.59, -4.694, 0.0, 0.0, 0.0]}
{"number_of_episodes": 974, "number_of_timesteps": 19321, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 1.0500000000000007},
{"step": 426, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 427.0, 1.0, 1.0, 1.0, 427.0, 427.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.691, 0.0, 0.0, 0.0, -4.608, -4.712, 0.0, 0.0, 0.0]}
{"number_of_episodes": 975, "number_of_timesteps": 19334, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 1.0999999999999979},
{"step": 427, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 428.0, 1.0, 1.0, 1.0, 428.0, 428.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.693, 0.0, 0.0, 0.0, -4.608, -4.711, 0.0, 0.0, 0.0]}
{"number_of_episodes": 980, "number_of_timesteps": 19408, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 0.6000000000000014},
{"step": 428, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 429.0, 1.0, 1.0, 1.0, 429.0, 429.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.694, 0.0, 0.0, 0.0, -4.607, -4.71, 0.0, 0.0, 0.0]}
{"number_of_episodes": 983, "number_of_timesteps": 19451, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.03222222222222225, "biggest_recent_change": 0.6499999999999986},
{"step": 429, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 430.0, 1.0, 1.0, 1.0, 430.0, 430.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.695, 0.0, 0.0, 0.0, -4.606, -4.709, 0.0, 0.0, 0.0]}
{"step": 430, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 431.0, 1.0, 1.0, 1.0, 431.0, 431.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.701, 0.0, 0.0, 0.0, -4.609, -4.712, 0.0, 0.0, 0.0]}
{"number_of_episodes": 986, "number_of_timesteps": 19500, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.022777777777777786, "biggest_recent_change": 1.0500000000000007},
{"step": 431, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 432.0, 1.0, 1.0, 1.0, 432.0, 432.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.727, 0.0, 0.0, 0.0, -4.633, -4.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 989, "number_of_timesteps": 19543, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 0.9000000000000021},
{"step": 432, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 433.0, 1.0, 1.0, 1.0, 433.0, 433.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.728, 0.0, 0.0, 0.0, -4.632, -4.725, 0.0, 0.0, 0.0]}
{"number_of_episodes": 991, "number_of_timesteps": 19583, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.023888888888888873, "biggest_recent_change": 0.6999999999999993},
{"step": 433, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 434.0, 1.0, 1.0, 1.0, 434.0, 434.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.729, 0.0, 0.0, 0.0, -4.622, -4.723, 0.0, 0.0, 0.0]}
{"number_of_episodes": 996, "number_of_timesteps": 19662, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.020555555555555532, "biggest_recent_change": 0.5999999999999979},
{"step": 434, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 435.0, 1.0, 1.0, 1.0, 435.0, 435.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.72, 0.0, 0.0, 0.0, -4.644, -4.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 998, "number_of_timesteps": 19708, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.032777777777777774, "biggest_recent_change": 0.6499999999999986},
{"step": 435, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 436.0, 1.0, 1.0, 1.0, 436.0, 436.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.722, 0.0, 0.0, 0.0, -4.644, -4.745, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1000, "number_of_timesteps": 19733, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.022777777777777786, "biggest_recent_change": 0.9000000000000021},
{"step": 436, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 437.0, 1.0, 1.0, 1.0, 437.0, 437.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.724, 0.0, 0.0, 0.0, -4.644, -4.734, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1001, "number_of_timesteps": 19747, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.022777777777777786, "biggest_recent_change": 0.6999999999999993},
{"step": 437, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 438.0, 1.0, 1.0, 1.0, 438.0, 438.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.731, 0.0, 0.0, 0.0, -4.633, -4.739, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1005, "number_of_timesteps": 19812, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 1.0999999999999979},
{"step": 438, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 439.0, 1.0, 1.0, 1.0, 439.0, 439.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.732, 0.0, 0.0, 0.0, -4.632, -4.738, 0.0, 0.0, 0.0]}
{"step": 439, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 440.0, 1.0, 1.0, 1.0, 440.0, 440.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.733, 0.0, 0.0, 0.0, -4.621, -4.736, 0.0, 0.0, 0.0]}
{"step": 440, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 441.0, 1.0, 1.0, 1.0, 441.0, 441.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.736, 0.0, 0.0, 0.0, -4.622, -4.725, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1012, "number_of_timesteps": 19954, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.023888888888888873, "biggest_recent_change": 1.0500000000000007},
{"step": 441, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 442.0, 1.0, 1.0, 1.0, 442.0, 442.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.729, 0.0, 0.0, 0.0, -4.613, -4.717, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1016, "number_of_timesteps": 20019, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.02055555555555557, "biggest_recent_change": 0.4499999999999993},
{"step": 442, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 443.0, 1.0, 1.0, 1.0, 443.0, 443.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.721, 0.0, 0.0, 0.0, -4.603, -4.706, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1020, "number_of_timesteps": 20081, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.017777777777777753, "biggest_recent_change": 0.5999999999999979},
{"step": 443, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 444.0, 1.0, 1.0, 1.0, 444.0, 444.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.712, 0.0, 0.0, 0.0, -4.616, -4.719, 0.0, 0.0, 0.0]}
{"step": 444, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 445.0, 1.0, 1.0, 1.0, 445.0, 445.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.704, 0.0, 0.0, 0.0, -4.605, -4.708, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1022, "number_of_timesteps": 20111, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.020555555555555532, "biggest_recent_change": 1.0999999999999979},
{"step": 445, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 446.0, 1.0, 1.0, 1.0, 446.0, 446.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.698, 0.0, 0.0, 0.0, -4.597, -4.7, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1026, "number_of_timesteps": 20172, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.9000000000000021},
{"step": 446, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 447.0, 1.0, 1.0, 1.0, 447.0, 447.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.702, 0.0, 0.0, 0.0, -4.599, -4.689, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1028, "number_of_timesteps": 20221, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.01999999999999997, "biggest_recent_change": 0.4499999999999993},
{"step": 447, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 448.0, 1.0, 1.0, 1.0, 448.0, 448.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.693, 0.0, 0.0, 0.0, -4.589, -4.679, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1030, "number_of_timesteps": 20241, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.020555555555555532, "biggest_recent_change": 0.6500000000000021},
{"step": 448, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 449.0, 1.0, 1.0, 1.0, 449.0, 449.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.685, 0.0, 0.0, 0.0, -4.579, -4.668, 0.0, 0.0, 0.0]}
{"step": 449, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 450.0, 1.0, 1.0, 1.0, 450.0, 450.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.689, 0.0, 0.0, 0.0, -4.58, -4.658, 0.0, 0.0, 0.0]}
{"step": 450, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 451.0, 1.0, 1.0, 1.0, 451.0, 451.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.68, 0.0, 0.0, 0.0, -4.57, -4.648, 0.0, 0.0, 0.0]}
{"eval_score": 16.2, "number_of_episodes": 1040}
{"number_of_episodes": 1040, "number_of_timesteps": 20440, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.012222222222222199, "biggest_recent_change": 0.45000000000000284},
{"step": 451, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 452.0, 1.0, 1.0, 1.0, 452.0, 452.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.695, 0.0, 0.0, 0.0, -4.583, -4.66, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1043, "number_of_timesteps": 20477, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.9000000000000021},
{"step": 452, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 453.0, 1.0, 1.0, 1.0, 453.0, 453.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.7, 0.0, 0.0, 0.0, -4.586, -4.65, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1045, "number_of_timesteps": 20502, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.028333333333333342, "biggest_recent_change": 0.6499999999999986},
{"step": 453, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 454.0, 1.0, 1.0, 1.0, 454.0, 454.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.703, 0.0, 0.0, 0.0, -4.587, -4.651, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1048, "number_of_timesteps": 20546, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.022777777777777786, "biggest_recent_change": 0.7999999999999972},
{"step": 454, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 455.0, 1.0, 1.0, 1.0, 455.0, 455.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.695, 0.0, 0.0, 0.0, -4.577, -4.64, 0.0, 0.0, 0.0]}
{"step": 455, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 456.0, 1.0, 1.0, 1.0, 456.0, 456.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.711, 0.0, 0.0, 0.0, -4.591, -4.654, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1051, "number_of_timesteps": 20586, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.01555555555555554, "biggest_recent_change": 0.34999999999999787},
{"step": 456, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 457.0, 1.0, 1.0, 1.0, 457.0, 457.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.703, 0.0, 0.0, 0.0, -4.581, -4.644, 0.0, 0.0, 0.0]}
{"step": 457, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 458.0, 1.0, 1.0, 1.0, 458.0, 458.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.695, 0.0, 0.0, 0.0, -4.571, -4.634, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1058, "number_of_timesteps": 20719, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.023888888888888873, "biggest_recent_change": 0.9000000000000021},
{"step": 458, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 459.0, 1.0, 1.0, 1.0, 459.0, 459.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.694, 0.0, 0.0, 0.0, -4.568, -4.624, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1059, "number_of_timesteps": 20728, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.022777777777777786, "biggest_recent_change": 0.6000000000000014},
{"step": 459, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 460.0, 1.0, 1.0, 1.0, 460.0, 460.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.695, 0.0, 0.0, 0.0, -4.567, -4.623, 0.0, 0.0, 0.0]}
{"step": 460, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 461.0, 1.0, 1.0, 1.0, 461.0, 461.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.698, 0.0, 0.0, 0.0, -4.568, -4.624, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1066, "number_of_timesteps": 20875, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.021111111111111136, "biggest_recent_change": 0.6999999999999993},
{"step": 461, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 462.0, 1.0, 1.0, 1.0, 462.0, 462.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.699, 0.0, 0.0, 0.0, -4.559, -4.623, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1068, "number_of_timesteps": 20903, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.02388888888888891, "biggest_recent_change": 0.6500000000000021},
{"step": 462, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 463.0, 1.0, 1.0, 1.0, 463.0, 463.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.691, 0.0, 0.0, 0.0, -4.549, -4.613, 0.0, 0.0, 0.0]}
{"step": 463, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 464.0, 1.0, 1.0, 1.0, 464.0, 464.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.683, 0.0, 0.0, 0.0, -4.539, -4.603, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1074, "number_of_timesteps": 21003, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.45000000000000284},
{"step": 464, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 465.0, 1.0, 1.0, 1.0, 465.0, 465.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.696, 0.0, 0.0, 0.0, -4.551, -4.615, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1076, "number_of_timesteps": 21037, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.02333333333333331, "biggest_recent_change": 1.0999999999999979},
{"step": 465, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 466.0, 1.0, 1.0, 1.0, 466.0, 466.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.701, 0.0, 0.0, 0.0, -4.554, -4.618, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1080, "number_of_timesteps": 21106, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.027222222222222214, "biggest_recent_change": 0.7999999999999972},
{"step": 466, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 467.0, 1.0, 1.0, 1.0, 467.0, 467.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.693, 0.0, 0.0, 0.0, -4.544, -4.608, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1080, "number_of_timesteps": 21106, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.6500000000000021},
{"step": 467, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 468.0, 1.0, 1.0, 1.0, 468.0, 468.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.686, 0.0, 0.0, 0.0, -4.534, -4.598, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1083, "number_of_timesteps": 21148, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.01833333333333332, "biggest_recent_change": 0.34999999999999787},
{"step": 468, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 469.0, 1.0, 1.0, 1.0, 469.0, 469.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.678, 0.0, 0.0, 0.0, -4.525, -4.588, 0.0, 0.0, 0.0]}
{"step": 469, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 470.0, 1.0, 1.0, 1.0, 470.0, 470.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.67, 0.0, 0.0, 0.0, -4.515, -4.578, 0.0, 0.0, 0.0]}
{"step": 470, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 471.0, 1.0, 1.0, 1.0, 471.0, 471.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.662, 0.0, 0.0, 0.0, -4.505, -4.569, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1090, "number_of_timesteps": 21281, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.02666666666666669, "biggest_recent_change": 0.6499999999999986},
{"step": 471, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 472.0, 1.0, 1.0, 1.0, 472.0, 472.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.666, 0.0, 0.0, 0.0, -4.507, -4.571, 0.0, 0.0, 0.0]}
{"step": 472, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 473.0, 1.0, 1.0, 1.0, 473.0, 473.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.658, 0.0, 0.0, 0.0, -4.498, -4.561, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1095, "number_of_timesteps": 21377, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.5500000000000007},
{"step": 473, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 474.0, 1.0, 1.0, 1.0, 474.0, 474.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.65, 0.0, 0.0, 0.0, -4.542, -4.605, 0.0, 0.0, 0.0]}
{"step": 474, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 475.0, 1.0, 1.0, 1.0, 475.0, 475.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.643, 0.0, 0.0, 0.0, -4.542, -4.605, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1099, "number_of_timesteps": 21488, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.013333333333333364, "biggest_recent_change": 0.3000000000000007},
{"step": 475, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 476.0, 1.0, 1.0, 1.0, 476.0, 476.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.635, 0.0, 0.0, 0.0, -4.532, -4.595, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1101, "number_of_timesteps": 21509, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.0216666666666667, "biggest_recent_change": 0.6499999999999986},
{"step": 476, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 477.0, 1.0, 1.0, 1.0, 477.0, 477.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.64, 0.0, 0.0, 0.0, -4.535, -4.598, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1103, "number_of_timesteps": 21530, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.02333333333333331, "biggest_recent_change": 0.9000000000000021},
{"step": 477, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 478.0, 1.0, 1.0, 1.0, 478.0, 478.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.643, 0.0, 0.0, 0.0, -4.537, -4.588, 0.0, 0.0, 0.0]}
{"step": 478, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 479.0, 1.0, 1.0, 1.0, 479.0, 479.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.644, 0.0, 0.0, 0.0, -4.536, -4.588, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1111, "number_of_timesteps": 21708, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.013333333333333364, "biggest_recent_change": 0.5500000000000007},
{"step": 479, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 480.0, 1.0, 1.0, 1.0, 480.0, 480.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.637, 0.0, 0.0, 0.0, -4.549, -4.6, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1112, "number_of_timesteps": 21723, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.02222222222222222, "biggest_recent_change": 1.0999999999999979},
{"step": 480, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 481.0, 1.0, 1.0, 1.0, 481.0, 481.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.637, 0.0, 0.0, 0.0, -4.548, -4.599, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1114, "number_of_timesteps": 21744, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.017777777777777753, "biggest_recent_change": 0.9000000000000021},
{"step": 481, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 482.0, 1.0, 1.0, 1.0, 482.0, 482.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.641, 0.0, 0.0, 0.0, -4.549, -4.589, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1118, "number_of_timesteps": 21818, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.45000000000000284},
{"step": 482, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 483.0, 1.0, 1.0, 1.0, 483.0, 483.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.66, 0.0, 0.0, 0.0, -4.567, -4.607, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1122, "number_of_timesteps": 21893, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.4499999999999993},
{"step": 483, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 484.0, 1.0, 1.0, 1.0, 484.0, 484.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.661, 0.0, 0.0, 0.0, -4.557, -4.606, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1123, "number_of_timesteps": 21910, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.024444444444444435, "biggest_recent_change": 0.6000000000000014},
{"step": 484, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 485.0, 1.0, 1.0, 1.0, 485.0, 485.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.657, 0.0, 0.0, 0.0, -4.552, -4.6, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1126, "number_of_timesteps": 21948, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.01388888888888889, "biggest_recent_change": 0.9000000000000021},
{"step": 485, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 486.0, 1.0, 1.0, 1.0, 486.0, 486.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.659, 0.0, 0.0, 0.0, -4.551, -4.591, 0.0, 0.0, 0.0]}
{"step": 486, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 487.0, 1.0, 1.0, 1.0, 487.0, 487.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.662, 0.0, 0.0, 0.0, -4.553, -4.581, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1131, "number_of_timesteps": 22038, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.02666666666666665, "biggest_recent_change": 0.6500000000000021},
{"step": 487, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 488.0, 1.0, 1.0, 1.0, 488.0, 488.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.655, 0.0, 0.0, 0.0, -4.544, -4.572, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1136, "number_of_timesteps": 22116, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.02666666666666665, "biggest_recent_change": 0.6000000000000014},
{"step": 488, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 489.0, 1.0, 1.0, 1.0, 489.0, 489.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.659, 0.0, 0.0, 0.0, -4.546, -4.574, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1138, "number_of_timesteps": 22144, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.5500000000000007},
{"step": 489, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 490.0, 1.0, 1.0, 1.0, 490.0, 490.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.651, 0.0, 0.0, 0.0, -4.558, -4.586, 0.0, 0.0, 0.0]}
{"step": 490, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 491.0, 1.0, 1.0, 1.0, 491.0, 491.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.644, 0.0, 0.0, 0.0, -4.574, -4.602, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1144, "number_of_timesteps": 22230, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.25},
{"step": 491, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 492.0, 1.0, 1.0, 1.0, 492.0, 492.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.659, 0.0, 0.0, 0.0, -4.587, -4.615, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1145, "number_of_timesteps": 22244, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.012222222222222238, "biggest_recent_change": 0.4499999999999993},
{"step": 492, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 493.0, 1.0, 1.0, 1.0, 493.0, 493.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.661, 0.0, 0.0, 0.0, -4.578, -4.616, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1148, "number_of_timesteps": 22286, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.011666666666666676, "biggest_recent_change": 0.4499999999999993},
{"step": 493, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 494.0, 1.0, 1.0, 1.0, 494.0, 494.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.663, 0.0, 0.0, 0.0, -4.578, -4.616, 0.0, 0.0, 0.0]}
{"step": 494, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 495.0, 1.0, 1.0, 1.0, 495.0, 495.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.672, 0.0, 0.0, 0.0, -4.585, -4.623, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1154, "number_of_timesteps": 22387, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.0038888888888888654, "biggest_recent_change": 0.25},
{"step": 495, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 496.0, 1.0, 1.0, 1.0, 496.0, 496.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.69, 0.0, 0.0, 0.0, -4.602, -4.639, 0.0, 0.0, 0.0]}
{"step": 496, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 497.0, 1.0, 1.0, 1.0, 497.0, 497.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.712, 0.0, 0.0, 0.0, -4.622, -4.659, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1160, "number_of_timesteps": 22498, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 497, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 498.0, 1.0, 1.0, 1.0, 498.0, 498.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.705, 0.0, 0.0, 0.0, -4.637, -4.674, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1163, "number_of_timesteps": 22546, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.011666666666666676, "biggest_recent_change": 0.3000000000000007},
{"step": 498, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 499.0, 1.0, 1.0, 1.0, 499.0, 499.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.697, 0.0, 0.0, 0.0, -4.628, -4.665, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1165, "number_of_timesteps": 22587, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.01444444444444445, "biggest_recent_change": 0.9000000000000021},
{"step": 499, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 500.0, 1.0, 1.0, 1.0, 500.0, 500.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.701, 0.0, 0.0, 0.0, -4.629, -4.656, 0.0, 0.0, 0.0]}
{"eval_score": 19.5, "number_of_episodes": 1170}
{"number_of_episodes": 1170, "number_of_timesteps": 22646, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.4499999999999993},
{"step": 500, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 501.0, 1.0, 1.0, 1.0, 501.0, 501.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.702, 0.0, 0.0, 0.0, -4.62, -4.655, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1172, "number_of_timesteps": 22674, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.25},
{"step": 501, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 502.0, 1.0, 1.0, 1.0, 502.0, 502.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.716, 0.0, 0.0, 0.0, -4.632, -4.667, 0.0, 0.0, 0.0]}
{"step": 502, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 503.0, 1.0, 1.0, 1.0, 503.0, 503.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.73, 0.0, 0.0, 0.0, -4.645, -4.68, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1176, "number_of_timesteps": 22720, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.019999999999999987, "biggest_recent_change": 0.6499999999999986},
{"step": 503, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 504.0, 1.0, 1.0, 1.0, 504.0, 504.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.728, 0.0, 0.0, 0.0, -4.641, -4.675, 0.0, 0.0, 0.0]}
{"step": 504, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 505.0, 1.0, 1.0, 1.0, 505.0, 505.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.731, 0.0, 0.0, 0.0, -4.642, -4.677, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1182, "number_of_timesteps": 22828, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.025, "biggest_recent_change": 0.6000000000000014},
{"step": 505, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 506.0, 1.0, 1.0, 1.0, 506.0, 506.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.733, 0.0, 0.0, 0.0, -4.642, -4.676, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1183, "number_of_timesteps": 22840, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 506, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 507.0, 1.0, 1.0, 1.0, 507.0, 507.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.725, 0.0, 0.0, 0.0, -4.658, -4.693, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1185, "number_of_timesteps": 22862, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 507, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 508.0, 1.0, 1.0, 1.0, 508.0, 508.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.74, 0.0, 0.0, 0.0, -4.671, -4.705, 0.0, 0.0, 0.0]}
{"step": 508, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 509.0, 1.0, 1.0, 1.0, 509.0, 509.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.759, 0.0, 0.0, 0.0, -4.688, -4.722, 0.0, 0.0, 0.0]}
{"step": 509, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 510.0, 1.0, 1.0, 1.0, 510.0, 510.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.761, 0.0, 0.0, 0.0, -4.688, -4.723, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1192, "number_of_timesteps": 23019, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.023888888888888873, "biggest_recent_change": 0.7999999999999972},
{"step": 510, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 511.0, 1.0, 1.0, 1.0, 511.0, 511.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.754, 0.0, 0.0, 0.0, -4.679, -4.714, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1195, "number_of_timesteps": 23061, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.011666666666666676, "biggest_recent_change": 0.5},
{"step": 511, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 512.0, 1.0, 1.0, 1.0, 512.0, 512.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.756, 0.0, 0.0, 0.0, -4.68, -4.714, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1198, "number_of_timesteps": 23127, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"step": 512, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 513.0, 1.0, 1.0, 1.0, 513.0, 513.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.761, 0.0, 0.0, 0.0, -4.683, -4.705, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1200, "number_of_timesteps": 23156, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 513, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 514.0, 1.0, 1.0, 1.0, 514.0, 514.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.774, 0.0, 0.0, 0.0, -4.694, -4.717, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1205, "number_of_timesteps": 23223, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.10000000000000142},
{"step": 514, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 515.0, 1.0, 1.0, 1.0, 515.0, 515.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.776, 0.0, 0.0, 0.0, -4.685, -4.717, 0.0, 0.0, 0.0]}
{"step": 515, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 516.0, 1.0, 1.0, 1.0, 516.0, 516.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.782, 0.0, 0.0, 0.0, -4.676, -4.72, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1208, "number_of_timesteps": 23262, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.010555555555555568, "biggest_recent_change": 0.3000000000000007},
{"step": 516, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 517.0, 1.0, 1.0, 1.0, 517.0, 517.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.774, 0.0, 0.0, 0.0, -4.667, -4.711, 0.0, 0.0, 0.0]}
{"step": 517, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 518.0, 1.0, 1.0, 1.0, 518.0, 518.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.777, 0.0, 0.0, 0.0, -4.658, -4.712, 0.0, 0.0, 0.0]}
{"step": 518, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 519.0, 1.0, 1.0, 1.0, 519.0, 519.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.77, 0.0, 0.0, 0.0, -4.649, -4.703, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1217, "number_of_timesteps": 23462, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.011666666666666655, "biggest_recent_change": 0.5},
{"step": 519, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 520.0, 1.0, 1.0, 1.0, 520.0, 520.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.777, 0.0, 0.0, 0.0, -4.655, -4.708, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1219, "number_of_timesteps": 23491, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.016111111111111125, "biggest_recent_change": 0.6000000000000014},
{"step": 520, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 521.0, 1.0, 1.0, 1.0, 521.0, 521.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.77, 0.0, 0.0, 0.0, -4.646, -4.699, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1224, "number_of_timesteps": 23557, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.026111111111111106, "biggest_recent_change": 0.6500000000000021},
{"step": 521, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 522.0, 1.0, 1.0, 1.0, 522.0, 522.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.763, 0.0, 0.0, 0.0, -4.637, -4.69, 0.0, 0.0, 0.0]}
{"step": 522, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 523.0, 1.0, 1.0, 1.0, 523.0, 523.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.755, 0.0, 0.0, 0.0, -4.628, -4.681, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1229, "number_of_timesteps": 23643, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3000000000000007},
{"step": 523, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 524.0, 1.0, 1.0, 1.0, 524.0, 524.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.748, 0.0, 0.0, 0.0, -4.619, -4.672, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1234, "number_of_timesteps": 23713, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.4499999999999993},
{"step": 524, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 525.0, 1.0, 1.0, 1.0, 525.0, 525.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.75, 0.0, 0.0, 0.0, -4.619, -4.672, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1237, "number_of_timesteps": 23749, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.019999999999999987, "biggest_recent_change": 0.6500000000000021},
{"step": 525, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 526.0, 1.0, 1.0, 1.0, 526.0, 526.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.743, 0.0, 0.0, 0.0, -4.61, -4.663, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1240, "number_of_timesteps": 23783, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 526, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 527.0, 1.0, 1.0, 1.0, 527.0, 527.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.756, 0.0, 0.0, 0.0, -4.623, -4.675, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1243, "number_of_timesteps": 23824, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.6000000000000014},
{"step": 527, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 528.0, 1.0, 1.0, 1.0, 528.0, 528.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.749, 0.0, 0.0, 0.0, -4.614, -4.667, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1247, "number_of_timesteps": 23879, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.021111111111111094, "biggest_recent_change": 0.6000000000000014},
{"step": 528, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 529.0, 1.0, 1.0, 1.0, 529.0, 529.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.75, 0.0, 0.0, 0.0, -4.613, -4.666, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1248, "number_of_timesteps": 23890, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.1999999999999993},
{"step": 529, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 530.0, 1.0, 1.0, 1.0, 530.0, 530.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.755, 0.0, 0.0, 0.0, -4.617, -4.669, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1252, "number_of_timesteps": 23949, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.24999999999999822},
{"step": 530, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 531.0, 1.0, 1.0, 1.0, 531.0, 531.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.76, 0.0, 0.0, 0.0, -4.619, -4.672, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1253, "number_of_timesteps": 23970, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 531, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 532.0, 1.0, 1.0, 1.0, 532.0, 532.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.762, 0.0, 0.0, 0.0, -4.62, -4.663, 0.0, 0.0, 0.0]}
{"step": 532, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 533.0, 1.0, 1.0, 1.0, 533.0, 533.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.763, 0.0, 0.0, 0.0, -4.62, -4.662, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1256, "number_of_timesteps": 24019, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.25},
{"step": 533, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 534.0, 1.0, 1.0, 1.0, 534.0, 534.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.756, 0.0, 0.0, 0.0, -4.631, -4.674, 0.0, 0.0, 0.0]}
{"step": 534, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 535.0, 1.0, 1.0, 1.0, 535.0, 535.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.757, 0.0, 0.0, 0.0, -4.63, -4.665, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1263, "number_of_timesteps": 24163, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.25},
{"step": 535, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 536.0, 1.0, 1.0, 1.0, 536.0, 536.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.75, 0.0, 0.0, 0.0, -4.621, -4.656, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1267, "number_of_timesteps": 24216, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 0.6000000000000014},
{"step": 536, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 537.0, 1.0, 1.0, 1.0, 537.0, 537.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.756, 0.0, 0.0, 0.0, -4.626, -4.661, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1268, "number_of_timesteps": 24226, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.016666666666666666, "biggest_recent_change": 0.6000000000000014},
{"step": 537, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 538.0, 1.0, 1.0, 1.0, 538.0, 538.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.749, 0.0, 0.0, 0.0, -4.617, -4.652, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1270, "number_of_timesteps": 24282, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.25},
{"step": 538, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 539.0, 1.0, 1.0, 1.0, 539.0, 539.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.742, 0.0, 0.0, 0.0, -4.639, -4.673, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1272, "number_of_timesteps": 24323, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.25},
{"step": 539, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 540.0, 1.0, 1.0, 1.0, 540.0, 540.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.75, 0.0, 0.0, 0.0, -4.63, -4.679, 0.0, 0.0, 0.0]}
{"step": 540, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 541.0, 1.0, 1.0, 1.0, 541.0, 541.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.743, 0.0, 0.0, 0.0, -4.642, -4.691, 0.0, 0.0, 0.0]}
{"step": 541, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 542.0, 1.0, 1.0, 1.0, 542.0, 542.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.736, 0.0, 0.0, 0.0, -4.665, -4.714, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1277, "number_of_timesteps": 24410, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.007222222222222246, "biggest_recent_change": 0.25},
{"step": 542, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 543.0, 1.0, 1.0, 1.0, 543.0, 543.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.762, 0.0, 0.0, 0.0, -4.69, -4.739, 0.0, 0.0, 0.0]}
{"step": 543, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 544.0, 1.0, 1.0, 1.0, 544.0, 544.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.763, 0.0, 0.0, 0.0, -4.681, -4.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1281, "number_of_timesteps": 24507, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.24999999999999822},
{"step": 544, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 545.0, 1.0, 1.0, 1.0, 545.0, 545.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.76, 0.0, 0.0, 0.0, -4.677, -4.733, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1283, "number_of_timesteps": 24568, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 545, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 546.0, 1.0, 1.0, 1.0, 546.0, 546.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.763, 0.0, 0.0, 0.0, -4.678, -4.724, 0.0, 0.0, 0.0]}
{"step": 546, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 547.0, 1.0, 1.0, 1.0, 547.0, 547.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.764, 0.0, 0.0, 0.0, -4.677, -4.716, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1289, "number_of_timesteps": 24685, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.015000000000000017, "biggest_recent_change": 0.6000000000000014},
{"step": 547, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 548.0, 1.0, 1.0, 1.0, 548.0, 548.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.765, 0.0, 0.0, 0.0, -4.676, -4.715, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1290, "number_of_timesteps": 24700, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.1999999999999993},
{"step": 548, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 549.0, 1.0, 1.0, 1.0, 549.0, 549.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.767, 0.0, 0.0, 0.0, -4.677, -4.716, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1293, "number_of_timesteps": 24746, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.24999999999999822},
{"step": 549, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 550.0, 1.0, 1.0, 1.0, 550.0, 550.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.769, 0.0, 0.0, 0.0, -4.677, -4.716, 0.0, 0.0, 0.0]}
{"step": 550, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 551.0, 1.0, 1.0, 1.0, 551.0, 551.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.774, 0.0, 0.0, 0.0, -4.68, -4.719, 0.0, 0.0, 0.0]}
{"step": 551, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 552.0, 1.0, 1.0, 1.0, 552.0, 552.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.782, 0.0, 0.0, 0.0, -4.686, -4.725, 0.0, 0.0, 0.0]}
{"eval_score": 11.7, "number_of_episodes": 1302}
{"number_of_episodes": 1302, "number_of_timesteps": 24960, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.25},
{"step": 552, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 553.0, 1.0, 1.0, 1.0, 553.0, 553.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.775, 0.0, 0.0, 0.0, -4.678, -4.717, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1305, "number_of_timesteps": 24998, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.25},
{"step": 553, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 554.0, 1.0, 1.0, 1.0, 554.0, 554.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.776, 0.0, 0.0, 0.0, -4.669, -4.716, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1306, "number_of_timesteps": 25020, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.01444444444444445, "biggest_recent_change": 0.6000000000000014},
{"step": 554, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 555.0, 1.0, 1.0, 1.0, 555.0, 555.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.769, 0.0, 0.0, 0.0, -4.661, -4.708, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1308, "number_of_timesteps": 25049, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.01444444444444445, "biggest_recent_change": 0.6500000000000021},
{"step": 555, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 556.0, 1.0, 1.0, 1.0, 556.0, 556.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.763, 0.0, 0.0, 0.0, -4.653, -4.699, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1312, "number_of_timesteps": 25113, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.24999999999999822},
{"step": 556, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 557.0, 1.0, 1.0, 1.0, 557.0, 557.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.765, 0.0, 0.0, 0.0, -4.653, -4.7, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1315, "number_of_timesteps": 25159, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.25},
{"step": 557, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 558.0, 1.0, 1.0, 1.0, 558.0, 558.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.767, 0.0, 0.0, 0.0, -4.645, -4.7, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1316, "number_of_timesteps": 25186, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 558, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 559.0, 1.0, 1.0, 1.0, 559.0, 559.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.76, 0.0, 0.0, 0.0, -4.637, -4.692, 0.0, 0.0, 0.0]}
{"step": 559, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 560.0, 1.0, 1.0, 1.0, 560.0, 560.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.754, 0.0, 0.0, 0.0, -4.628, -4.684, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1324, "number_of_timesteps": 25302, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 560, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 561.0, 1.0, 1.0, 1.0, 561.0, 561.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.747, 0.0, 0.0, 0.0, -4.629, -4.684, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1326, "number_of_timesteps": 25323, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.20000000000000284},
{"step": 561, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 562.0, 1.0, 1.0, 1.0, 562.0, 562.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.74, 0.0, 0.0, 0.0, -4.621, -4.676, 0.0, 0.0, 0.0]}
{"step": 562, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 563.0, 1.0, 1.0, 1.0, 563.0, 563.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.734, 0.0, 0.0, 0.0, -4.642, -4.697, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1330, "number_of_timesteps": 25373, "per_episode_reward": 15.75, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.25},
{"step": 563, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 564.0, 1.0, 1.0, 1.0, 564.0, 564.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.727, 0.0, 0.0, 0.0, -4.634, -4.688, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1333, "number_of_timesteps": 25440, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.25},
{"step": 564, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 565.0, 1.0, 1.0, 1.0, 565.0, 565.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.732, 0.0, 0.0, 0.0, -4.637, -4.68, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1334, "number_of_timesteps": 25455, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 565, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 566.0, 1.0, 1.0, 1.0, 566.0, 566.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.734, 0.0, 0.0, 0.0, -4.629, -4.68, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1338, "number_of_timesteps": 25545, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.24999999999999822},
{"step": 566, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 567.0, 1.0, 1.0, 1.0, 567.0, 567.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.733, 0.0, 0.0, 0.0, -4.627, -4.678, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1343, "number_of_timesteps": 25637, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.20000000000000284},
{"step": 567, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 568.0, 1.0, 1.0, 1.0, 568.0, 568.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.727, 0.0, 0.0, 0.0, -4.618, -4.669, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1344, "number_of_timesteps": 25653, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.008888888888888877, "biggest_recent_change": 0.1999999999999993},
{"step": 568, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 569.0, 1.0, 1.0, 1.0, 569.0, 569.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.728, 0.0, 0.0, 0.0, -4.618, -4.669, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1347, "number_of_timesteps": 25689, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.25},
{"step": 569, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 570.0, 1.0, 1.0, 1.0, 570.0, 570.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.722, 0.0, 0.0, 0.0, -4.61, -4.661, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1351, "number_of_timesteps": 25745, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.24999999999999822},
{"step": 570, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 571.0, 1.0, 1.0, 1.0, 571.0, 571.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.722, 0.0, 0.0, 0.0, -4.61, -4.66, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1352, "number_of_timesteps": 25760, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 571, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 572.0, 1.0, 1.0, 1.0, 572.0, 572.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.726, 0.0, 0.0, 0.0, -4.612, -4.652, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1354, "number_of_timesteps": 25785, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.25},
{"step": 572, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 573.0, 1.0, 1.0, 1.0, 573.0, 573.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.727, 0.0, 0.0, 0.0, -4.604, -4.651, 0.0, 0.0, 0.0]}
{"step": 573, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 574.0, 1.0, 1.0, 1.0, 574.0, 574.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.729, 0.0, 0.0, 0.0, -4.596, -4.651, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1362, "number_of_timesteps": 25945, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.008333333333333354, "biggest_recent_change": 0.20000000000000284},
{"step": 574, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 575.0, 1.0, 1.0, 1.0, 575.0, 575.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.722, 0.0, 0.0, 0.0, -4.588, -4.643, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1363, "number_of_timesteps": 25959, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 575, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 576.0, 1.0, 1.0, 1.0, 576.0, 576.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.716, 0.0, 0.0, 0.0, -4.58, -4.635, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1366, "number_of_timesteps": 25996, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 576, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 577.0, 1.0, 1.0, 1.0, 577.0, 577.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.709, 0.0, 0.0, 0.0, -4.572, -4.627, 0.0, 0.0, 0.0]}
{"step": 577, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 578.0, 1.0, 1.0, 1.0, 578.0, 578.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.703, 0.0, 0.0, 0.0, -4.564, -4.619, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1371, "number_of_timesteps": 26096, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 578, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 579.0, 1.0, 1.0, 1.0, 579.0, 579.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.704, 0.0, 0.0, 0.0, -4.564, -4.619, 0.0, 0.0, 0.0]}
{"step": 579, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 580.0, 1.0, 1.0, 1.0, 580.0, 580.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.707, 0.0, 0.0, 0.0, -4.565, -4.62, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1377, "number_of_timesteps": 26187, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.25},
{"step": 580, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 581.0, 1.0, 1.0, 1.0, 581.0, 581.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.701, 0.0, 0.0, 0.0, -4.557, -4.612, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1378, "number_of_timesteps": 26201, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.008333333333333354, "biggest_recent_change": 0.25},
{"step": 581, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 582.0, 1.0, 1.0, 1.0, 582.0, 582.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.694, 0.0, 0.0, 0.0, -4.578, -4.633, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1379, "number_of_timesteps": 26236, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.1999999999999993},
{"step": 582, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 583.0, 1.0, 1.0, 1.0, 583.0, 583.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.689, 0.0, 0.0, 0.0, -4.571, -4.626, 0.0, 0.0, 0.0]}
{"step": 583, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 584.0, 1.0, 1.0, 1.0, 584.0, 584.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.692, 0.0, 0.0, 0.0, -4.572, -4.627, 0.0, 0.0, 0.0]}
{"step": 584, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 585.0, 1.0, 1.0, 1.0, 585.0, 585.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.685, 0.0, 0.0, 0.0, -4.59, -4.645, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1388, "number_of_timesteps": 26397, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 585, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 586.0, 1.0, 1.0, 1.0, 586.0, 586.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.679, 0.0, 0.0, 0.0, -4.583, -4.637, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1390, "number_of_timesteps": 26448, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 586, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 587.0, 1.0, 1.0, 1.0, 587.0, 587.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.682, 0.0, 0.0, 0.0, -4.584, -4.639, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1393, "number_of_timesteps": 26481, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.004444444444444468, "biggest_recent_change": 0.15000000000000036},
{"step": 587, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 588.0, 1.0, 1.0, 1.0, 588.0, 588.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.703, 0.0, 0.0, 0.0, -4.604, -4.658, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1395, "number_of_timesteps": 26529, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.25},
{"step": 588, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 589.0, 1.0, 1.0, 1.0, 589.0, 589.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.705, 0.0, 0.0, 0.0, -4.605, -4.65, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1397, "number_of_timesteps": 26559, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.005555555555555576, "biggest_recent_change": 0.25},
{"step": 589, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 590.0, 1.0, 1.0, 1.0, 590.0, 590.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.707, 0.0, 0.0, 0.0, -4.597, -4.65, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1401, "number_of_timesteps": 26635, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 590, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 591.0, 1.0, 1.0, 1.0, 591.0, 591.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.708, 0.0, 0.0, 0.0, -4.597, -4.65, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1403, "number_of_timesteps": 26684, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 591, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 592.0, 1.0, 1.0, 1.0, 592.0, 592.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.702, 0.0, 0.0, 0.0, -4.589, -4.642, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1405, "number_of_timesteps": 26717, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.005555555555555576, "biggest_recent_change": 0.15000000000000036},
{"step": 592, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 593.0, 1.0, 1.0, 1.0, 593.0, 593.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.721, 0.0, 0.0, 0.0, -4.607, -4.66, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1408, "number_of_timesteps": 26764, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.1999999999999993},
{"step": 593, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 594.0, 1.0, 1.0, 1.0, 594.0, 594.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.723, 0.0, 0.0, 0.0, -4.607, -4.66, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1411, "number_of_timesteps": 26813, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.1999999999999993},
{"step": 594, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 595.0, 1.0, 1.0, 1.0, 595.0, 595.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.717, 0.0, 0.0, 0.0, -4.6, -4.653, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1414, "number_of_timesteps": 26858, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.25},
{"step": 595, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 596.0, 1.0, 1.0, 1.0, 596.0, 596.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.718, 0.0, 0.0, 0.0, -4.599, -4.645, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1415, "number_of_timesteps": 26872, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 596, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 597.0, 1.0, 1.0, 1.0, 597.0, 597.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.738, 0.0, 0.0, 0.0, -4.617, -4.663, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1418, "number_of_timesteps": 26926, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.25},
{"step": 597, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 598.0, 1.0, 1.0, 1.0, 598.0, 598.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.731, 0.0, 0.0, 0.0, -4.609, -4.656, 0.0, 0.0, 0.0]}
{"step": 598, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 599.0, 1.0, 1.0, 1.0, 599.0, 599.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.748, 0.0, 0.0, 0.0, -4.624, -4.67, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1423, "number_of_timesteps": 27021, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.15000000000000036},
{"step": 599, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 600.0, 1.0, 1.0, 1.0, 600.0, 600.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.742, 0.0, 0.0, 0.0, -4.617, -4.663, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1425, "number_of_timesteps": 27060, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 600, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 601.0, 1.0, 1.0, 1.0, 601.0, 601.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.745, 0.0, 0.0, 0.0, -4.609, -4.664, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1429, "number_of_timesteps": 27144, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
{"step": 601, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 602.0, 1.0, 1.0, 1.0, 602.0, 602.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.756, 0.0, 0.0, 0.0, -4.619, -4.674, 0.0, 0.0, 0.0]}
{"eval_score": 16.8, "number_of_episodes": 1432}
{"number_of_episodes": 1432, "number_of_timesteps": 27183, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.1999999999999993},
{"step": 602, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 603.0, 1.0, 1.0, 1.0, 603.0, 603.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.75, 0.0, 0.0, 0.0, -4.611, -4.666, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1433, "number_of_timesteps": 27197, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.1999999999999993},
{"step": 603, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 604.0, 1.0, 1.0, 1.0, 604.0, 604.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.747, 0.0, 0.0, 0.0, -4.607, -4.662, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1438, "number_of_timesteps": 27260, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.005555555555555576, "biggest_recent_change": 0.25},
{"step": 604, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 605.0, 1.0, 1.0, 1.0, 605.0, 605.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.75, 0.0, 0.0, 0.0, -4.608, -4.655, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1439, "number_of_timesteps": 27270, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.005555555555555576, "biggest_recent_change": 0.15000000000000036},
{"step": 605, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 606.0, 1.0, 1.0, 1.0, 606.0, 606.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.754, 0.0, 0.0, 0.0, -4.611, -4.657, 0.0, 0.0, 0.0]}
{"step": 606, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 607.0, 1.0, 1.0, 1.0, 607.0, 607.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.756, 0.0, 0.0, 0.0, -4.611, -4.658, 0.0, 0.0, 0.0]}
{"step": 607, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 608.0, 1.0, 1.0, 1.0, 608.0, 608.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.759, 0.0, 0.0, 0.0, -4.613, -4.659, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1450, "number_of_timesteps": 27471, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.25},
{"step": 608, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 609.0, 1.0, 1.0, 1.0, 609.0, 609.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.753, 0.0, 0.0, 0.0, -4.606, -4.652, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1450, "number_of_timesteps": 27471, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 609, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 610.0, 1.0, 1.0, 1.0, 610.0, 610.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.757, 0.0, 0.0, 0.0, -4.608, -4.644, 0.0, 0.0, 0.0]}
{"step": 610, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 611.0, 1.0, 1.0, 1.0, 611.0, 611.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.756, 0.0, 0.0, 0.0, -4.606, -4.636, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1459, "number_of_timesteps": 27602, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.25},
{"step": 611, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 612.0, 1.0, 1.0, 1.0, 612.0, 612.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.757, 0.0, 0.0, 0.0, -4.598, -4.637, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1460, "number_of_timesteps": 27612, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.20000000000000107},
{"step": 612, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 613.0, 1.0, 1.0, 1.0, 613.0, 613.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.751, 0.0, 0.0, 0.0, -4.615, -4.653, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1461, "number_of_timesteps": 27627, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 613, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 614.0, 1.0, 1.0, 1.0, 614.0, 614.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.754, 0.0, 0.0, 0.0, -4.616, -4.646, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1463, "number_of_timesteps": 27652, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.14999999999999858},
{"step": 614, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 615.0, 1.0, 1.0, 1.0, 615.0, 615.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.767, 0.0, 0.0, 0.0, -4.628, -4.658, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1467, "number_of_timesteps": 27723, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 615, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 616.0, 1.0, 1.0, 1.0, 616.0, 616.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.768, 0.0, 0.0, 0.0, -4.628, -4.657, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1471, "number_of_timesteps": 27812, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.20000000000000107},
{"step": 616, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 617.0, 1.0, 1.0, 1.0, 617.0, 617.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.762, 0.0, 0.0, 0.0, -4.645, -4.674, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1473, "number_of_timesteps": 27851, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.1999999999999993},
{"step": 617, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 618.0, 1.0, 1.0, 1.0, 618.0, 618.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.763, 0.0, 0.0, 0.0, -4.644, -4.674, 0.0, 0.0, 0.0]}
{"step": 618, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 619.0, 1.0, 1.0, 1.0, 619.0, 619.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.768, 0.0, 0.0, 0.0, -4.648, -4.677, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1478, "number_of_timesteps": 27912, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 619, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 620.0, 1.0, 1.0, 1.0, 620.0, 620.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.769, 0.0, 0.0, 0.0, -4.648, -4.669, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1482, "number_of_timesteps": 27981, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.005555555555555576, "biggest_recent_change": 0.20000000000000107},
{"step": 620, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 621.0, 1.0, 1.0, 1.0, 621.0, 621.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.763, 0.0, 0.0, 0.0, -4.658, -4.679, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1484, "number_of_timesteps": 28014, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.20000000000000107},
{"step": 621, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 622.0, 1.0, 1.0, 1.0, 622.0, 622.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.757, 0.0, 0.0, 0.0, -4.65, -4.672, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1486, "number_of_timesteps": 28042, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.14999999999999858},
{"step": 622, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 623.0, 1.0, 1.0, 1.0, 623.0, 623.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.776, 0.0, 0.0, 0.0, -4.667, -4.689, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1491, "number_of_timesteps": 28118, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.005555555555555576, "biggest_recent_change": 0.1999999999999993},
{"step": 623, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 624.0, 1.0, 1.0, 1.0, 624.0, 624.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.777, 0.0, 0.0, 0.0, -4.667, -4.688, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1492, "number_of_timesteps": 28131, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 624, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 625.0, 1.0, 1.0, 1.0, 625.0, 625.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.778, 0.0, 0.0, 0.0, -4.667, -4.688, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1495, "number_of_timesteps": 28182, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
{"step": 625, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 626.0, 1.0, 1.0, 1.0, 626.0, 626.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.772, 0.0, 0.0, 0.0, -4.66, -4.681, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1500, "number_of_timesteps": 28248, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.20000000000000107},
{"step": 626, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 627.0, 1.0, 1.0, 1.0, 627.0, 627.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.766, 0.0, 0.0, 0.0, -4.652, -4.673, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1501, "number_of_timesteps": 28258, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 627, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 628.0, 1.0, 1.0, 1.0, 628.0, 628.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.769, 0.0, 0.0, 0.0, -4.653, -4.666, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1503, "number_of_timesteps": 28286, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"step": 628, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 629.0, 1.0, 1.0, 1.0, 629.0, 629.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.789, 0.0, 0.0, 0.0, -4.672, -4.685, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1504, "number_of_timesteps": 28299, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.20000000000000107},
{"step": 629, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 630.0, 1.0, 1.0, 1.0, 630.0, 630.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.783, 0.0, 0.0, 0.0, -4.682, -4.695, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1506, "number_of_timesteps": 28331, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"step": 630, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 631.0, 1.0, 1.0, 1.0, 631.0, 631.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.785, 0.0, 0.0, 0.0, -4.683, -4.695, 0.0, 0.0, 0.0]}
{"step": 631, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 632.0, 1.0, 1.0, 1.0, 632.0, 632.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.788, 0.0, 0.0, 0.0, -4.684, -4.697, 0.0, 0.0, 0.0]}
{"step": 632, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 633.0, 1.0, 1.0, 1.0, 633.0, 633.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.782, 0.0, 0.0, 0.0, -4.694, -4.706, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1514, "number_of_timesteps": 28495, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 633, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 634.0, 1.0, 1.0, 1.0, 634.0, 634.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.798, 0.0, 0.0, 0.0, -4.709, -4.721, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1517, "number_of_timesteps": 28577, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.15000000000000036},
{"step": 634, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 635.0, 1.0, 1.0, 1.0, 635.0, 635.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.799, 0.0, 0.0, 0.0, -4.708, -4.721, 0.0, 0.0, 0.0]}
{"step": 635, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 636.0, 1.0, 1.0, 1.0, 636.0, 636.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.801, 0.0, 0.0, 0.0, -4.709, -4.722, 0.0, 0.0, 0.0]}
{"step": 636, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 637.0, 1.0, 1.0, 1.0, 637.0, 637.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.812, 0.0, 0.0, 0.0, -4.718, -4.73, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1523, "number_of_timesteps": 28678, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 637, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 638.0, 1.0, 1.0, 1.0, 638.0, 638.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.812, 0.0, 0.0, 0.0, -4.717, -4.73, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1525, "number_of_timesteps": 28722, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 638, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 639.0, 1.0, 1.0, 1.0, 639.0, 639.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.816, 0.0, 0.0, 0.0, -4.719, -4.722, 0.0, 0.0, 0.0]}
{"step": 639, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 640.0, 1.0, 1.0, 1.0, 640.0, 640.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.815, 0.0, 0.0, 0.0, -4.717, -4.715, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1529, "number_of_timesteps": 28811, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.20000000000000107},
{"step": 640, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 641.0, 1.0, 1.0, 1.0, 641.0, 641.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.809, 0.0, 0.0, 0.0, -4.737, -4.735, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1533, "number_of_timesteps": 28926, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.15000000000000036},
{"step": 641, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 642.0, 1.0, 1.0, 1.0, 642.0, 642.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.803, 0.0, 0.0, 0.0, -4.73, -4.728, 0.0, 0.0, 0.0]}
{"step": 642, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 643.0, 1.0, 1.0, 1.0, 643.0, 643.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.797, 0.0, 0.0, 0.0, -4.723, -4.72, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1538, "number_of_timesteps": 29001, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 643, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 644.0, 1.0, 1.0, 1.0, 644.0, 644.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.813, 0.0, 0.0, 0.0, -4.736, -4.734, 0.0, 0.0, 0.0]}
{"step": 644, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 645.0, 1.0, 1.0, 1.0, 645.0, 645.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.823, 0.0, 0.0, 0.0, -4.745, -4.743, 0.0, 0.0, 0.0]}
{"step": 645, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 646.0, 1.0, 1.0, 1.0, 646.0, 646.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.834, 0.0, 0.0, 0.0, -4.755, -4.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1545, "number_of_timesteps": 29103, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 646, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 647.0, 1.0, 1.0, 1.0, 647.0, 647.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.835, 0.0, 0.0, 0.0, -4.754, -4.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1550, "number_of_timesteps": 29176, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 647, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 648.0, 1.0, 1.0, 1.0, 648.0, 648.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.842, 0.0, 0.0, 0.0, -4.76, -4.758, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1550, "number_of_timesteps": 29176, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"step": 648, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 649.0, 1.0, 1.0, 1.0, 649.0, 649.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.836, 0.0, 0.0, 0.0, -4.753, -4.75, 0.0, 0.0, 0.0]}
{"step": 649, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 650.0, 1.0, 1.0, 1.0, 650.0, 650.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.83, 0.0, 0.0, 0.0, -4.745, -4.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1553, "number_of_timesteps": 29244, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.20000000000000107},
{"step": 650, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 651.0, 1.0, 1.0, 1.0, 651.0, 651.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.824, 0.0, 0.0, 0.0, -4.738, -4.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1553, "number_of_timesteps": 29244, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 651, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 652.0, 1.0, 1.0, 1.0, 652.0, 652.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.82, 0.0, 0.0, 0.0, -4.733, -4.73, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1557, "number_of_timesteps": 29337, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 652, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 653.0, 1.0, 1.0, 1.0, 653.0, 653.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.822, 0.0, 0.0, 0.0, -4.734, -4.723, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1559, "number_of_timesteps": 29372, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 653, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 654.0, 1.0, 1.0, 1.0, 654.0, 654.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.817, 0.0, 0.0, 0.0, -4.726, -4.716, 0.0, 0.0, 0.0]}
{"eval_score": 25.9, "number_of_episodes": 1561}
{"number_of_episodes": 1561, "number_of_timesteps": 29437, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.1999999999999993},
{"step": 654, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 655.0, 1.0, 1.0, 1.0, 655.0, 655.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.811, 0.0, 0.0, 0.0, -4.719, -4.709, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1563, "number_of_timesteps": 29470, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 655, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 656.0, 1.0, 1.0, 1.0, 656.0, 656.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.812, 0.0, 0.0, 0.0, -4.719, -4.709, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1564, "number_of_timesteps": 29490, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.25},
{"step": 656, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 657.0, 1.0, 1.0, 1.0, 657.0, 657.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.813, 0.0, 0.0, 0.0, -4.712, -4.709, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1567, "number_of_timesteps": 29524, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 657, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 658.0, 1.0, 1.0, 1.0, 658.0, 658.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.814, 0.0, 0.0, 0.0, -4.712, -4.708, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1570, "number_of_timesteps": 29587, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 658, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 659.0, 1.0, 1.0, 1.0, 659.0, 659.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.808, 0.0, 0.0, 0.0, -4.722, -4.718, 0.0, 0.0, 0.0]}
{"step": 659, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 660.0, 1.0, 1.0, 1.0, 660.0, 660.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.811, 0.0, 0.0, 0.0, -4.723, -4.719, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1572, "number_of_timesteps": 29625, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 660, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 661.0, 1.0, 1.0, 1.0, 661.0, 661.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.813, 0.0, 0.0, 0.0, -4.724, -4.712, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1575, "number_of_timesteps": 29667, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"step": 661, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 662.0, 1.0, 1.0, 1.0, 662.0, 662.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.815, 0.0, 0.0, 0.0, -4.724, -4.712, 0.0, 0.0, 0.0]}
{"step": 662, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 663.0, 1.0, 1.0, 1.0, 663.0, 663.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.809, 0.0, 0.0, 0.0, -4.74, -4.728, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1580, "number_of_timesteps": 29866, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 663, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 664.0, 1.0, 1.0, 1.0, 664.0, 664.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.804, 0.0, 0.0, 0.0, -4.733, -4.721, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1584, "number_of_timesteps": 29942, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 664, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 665.0, 1.0, 1.0, 1.0, 665.0, 665.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.798, 0.0, 0.0, 0.0, -4.725, -4.714, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1586, "number_of_timesteps": 29972, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.20000000000000107},
{"step": 665, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 666.0, 1.0, 1.0, 1.0, 666.0, 666.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.792, 0.0, 0.0, 0.0, -4.735, -4.724, 0.0, 0.0, 0.0]}
{"step": 666, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 667.0, 1.0, 1.0, 1.0, 667.0, 667.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.787, 0.0, 0.0, 0.0, -4.728, -4.717, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1592, "number_of_timesteps": 30058, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"step": 667, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 668.0, 1.0, 1.0, 1.0, 668.0, 668.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.781, 0.0, 0.0, 0.0, -4.721, -4.71, 0.0, 0.0, 0.0]}
{"step": 668, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 669.0, 1.0, 1.0, 1.0, 669.0, 669.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.775, 0.0, 0.0, 0.0, -4.737, -4.725, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1593, "number_of_timesteps": 30068, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 669, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 670.0, 1.0, 1.0, 1.0, 670.0, 670.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.777, 0.0, 0.0, 0.0, -4.73, -4.725, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1598, "number_of_timesteps": 30157, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.10000000000000142},
{"step": 670, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 671.0, 1.0, 1.0, 1.0, 671.0, 671.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.774, 0.0, 0.0, 0.0, -4.726, -4.722, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1601, "number_of_timesteps": 30259, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 671, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 672.0, 1.0, 1.0, 1.0, 672.0, 672.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.775, 0.0, 0.0, 0.0, -4.725, -4.721, 0.0, 0.0, 0.0]}
{"step": 672, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 673.0, 1.0, 1.0, 1.0, 673.0, 673.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.779, 0.0, 0.0, 0.0, -4.727, -4.723, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1604, "number_of_timesteps": 30300, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 673, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 674.0, 1.0, 1.0, 1.0, 674.0, 674.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.779, 0.0, 0.0, 0.0, -4.726, -4.716, 0.0, 0.0, 0.0]}
{"step": 674, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 675.0, 1.0, 1.0, 1.0, 675.0, 675.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.78, 0.0, 0.0, 0.0, -4.725, -4.709, 0.0, 0.0, 0.0]}
{"step": 675, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 676.0, 1.0, 1.0, 1.0, 676.0, 676.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.781, 0.0, 0.0, 0.0, -4.725, -4.709, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1607, "number_of_timesteps": 30347, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 676, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 677.0, 1.0, 1.0, 1.0, 677.0, 677.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.782, 0.0, 0.0, 0.0, -4.725, -4.709, 0.0, 0.0, 0.0]}
{"step": 677, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 678.0, 1.0, 1.0, 1.0, 678.0, 678.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.784, 0.0, 0.0, 0.0, -4.726, -4.709, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1611, "number_of_timesteps": 30452, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 678, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 679.0, 1.0, 1.0, 1.0, 679.0, 679.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.787, 0.0, 0.0, 0.0, -4.727, -4.711, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1612, "number_of_timesteps": 30511, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 679, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 680.0, 1.0, 1.0, 1.0, 680.0, 680.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.788, 0.0, 0.0, 0.0, -4.72, -4.71, 0.0, 0.0, 0.0]}
{"step": 680, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 681.0, 1.0, 1.0, 1.0, 681.0, 681.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.788, 0.0, 0.0, 0.0, -4.719, -4.709, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1617, "number_of_timesteps": 30668, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 681, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 682.0, 1.0, 1.0, 1.0, 682.0, 682.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.789, 0.0, 0.0, 0.0, -4.718, -4.709, 0.0, 0.0, 0.0]}
{"step": 682, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 683.0, 1.0, 1.0, 1.0, 683.0, 683.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.79, 0.0, 0.0, 0.0, -4.711, -4.709, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1623, "number_of_timesteps": 30755, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 683, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 684.0, 1.0, 1.0, 1.0, 684.0, 684.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.806, 0.0, 0.0, 0.0, -4.726, -4.723, 0.0, 0.0, 0.0]}
{"step": 684, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 685.0, 1.0, 1.0, 1.0, 685.0, 685.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.822, 0.0, 0.0, 0.0, -4.74, -4.737, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1626, "number_of_timesteps": 30848, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.15000000000000036},
{"step": 685, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 686.0, 1.0, 1.0, 1.0, 686.0, 686.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.823, 0.0, 0.0, 0.0, -4.74, -4.737, 0.0, 0.0, 0.0]}
{"step": 686, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 687.0, 1.0, 1.0, 1.0, 687.0, 687.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.818, 0.0, 0.0, 0.0, -4.734, -4.731, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1631, "number_of_timesteps": 30970, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.20000000000000107},
{"step": 687, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 688.0, 1.0, 1.0, 1.0, 688.0, 688.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.813, 0.0, 0.0, 0.0, -4.751, -4.749, 0.0, 0.0, 0.0]}
{"step": 688, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 689.0, 1.0, 1.0, 1.0, 689.0, 689.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.813, 0.0, 0.0, 0.0, -4.751, -4.748, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1634, "number_of_timesteps": 31023, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 689, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 690.0, 1.0, 1.0, 1.0, 690.0, 690.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.808, 0.0, 0.0, 0.0, -4.744, -4.741, 0.0, 0.0, 0.0]}
{"step": 690, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 691.0, 1.0, 1.0, 1.0, 691.0, 691.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.802, 0.0, 0.0, 0.0, -4.737, -4.734, 0.0, 0.0, 0.0]}
{"step": 691, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 692.0, 1.0, 1.0, 1.0, 692.0, 692.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.797, 0.0, 0.0, 0.0, -4.73, -4.727, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1643, "number_of_timesteps": 31227, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 692, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 693.0, 1.0, 1.0, 1.0, 693.0, 693.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.798, 0.0, 0.0, 0.0, -4.73, -4.727, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1646, "number_of_timesteps": 31265, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 693, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 694.0, 1.0, 1.0, 1.0, 694.0, 694.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.793, 0.0, 0.0, 0.0, -4.724, -4.721, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1649, "number_of_timesteps": 31313, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
{"step": 694, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 695.0, 1.0, 1.0, 1.0, 695.0, 695.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.788, 0.0, 0.0, 0.0, -4.717, -4.714, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1650, "number_of_timesteps": 31327, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 695, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 696.0, 1.0, 1.0, 1.0, 696.0, 696.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.79, 0.0, 0.0, 0.0, -4.718, -4.715, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1654, "number_of_timesteps": 31394, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 696, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 697.0, 1.0, 1.0, 1.0, 697.0, 697.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.784, 0.0, 0.0, 0.0, -4.728, -4.726, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1658, "number_of_timesteps": 31454, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 697, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 698.0, 1.0, 1.0, 1.0, 698.0, 698.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.785, 0.0, 0.0, 0.0, -4.728, -4.725, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1658, "number_of_timesteps": 31454, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 698, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 699.0, 1.0, 1.0, 1.0, 699.0, 699.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.788, 0.0, 0.0, 0.0, -4.721, -4.726, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1660, "number_of_timesteps": 31501, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 699, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 700.0, 1.0, 1.0, 1.0, 700.0, 700.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.796, 0.0, 0.0, 0.0, -4.729, -4.734, 0.0, 0.0, 0.0]}
{"step": 700, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 701.0, 1.0, 1.0, 1.0, 701.0, 701.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.81, 0.0, 0.0, 0.0, -4.741, -4.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1667, "number_of_timesteps": 31604, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
{"step": 701, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 702.0, 1.0, 1.0, 1.0, 702.0, 702.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.805, 0.0, 0.0, 0.0, -4.735, -4.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1670, "number_of_timesteps": 31674, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 702, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 703.0, 1.0, 1.0, 1.0, 703.0, 703.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.806, 0.0, 0.0, 0.0, -4.734, -4.739, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1673, "number_of_timesteps": 31712, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.1999999999999993},
{"step": 703, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 704.0, 1.0, 1.0, 1.0, 704.0, 704.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.8, 0.0, 0.0, 0.0, -4.732, -4.737, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1676, "number_of_timesteps": 31756, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.25},
{"step": 704, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 705.0, 1.0, 1.0, 1.0, 705.0, 705.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.795, 0.0, 0.0, 0.0, -4.726, -4.731, 0.0, 0.0, 0.0]}
{"step": 705, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 706.0, 1.0, 1.0, 1.0, 706.0, 706.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.789, 0.0, 0.0, 0.0, -4.736, -4.741, 0.0, 0.0, 0.0]}
{"step": 706, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 707.0, 1.0, 1.0, 1.0, 707.0, 707.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.784, 0.0, 0.0, 0.0, -4.752, -4.758, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1683, "number_of_timesteps": 31864, "per_episode_reward": 15.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 707, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 708.0, 1.0, 1.0, 1.0, 708.0, 708.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.788, 0.0, 0.0, 0.0, -4.755, -4.751, 0.0, 0.0, 0.0]}
{"step": 708, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 709.0, 1.0, 1.0, 1.0, 709.0, 709.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.789, 0.0, 0.0, 0.0, -4.754, -4.744, 0.0, 0.0, 0.0]}
{"eval_score": 14.0, "number_of_episodes": 1690}
{"number_of_episodes": 1690, "number_of_timesteps": 31979, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 709, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 710.0, 1.0, 1.0, 1.0, 710.0, 710.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.79, 0.0, 0.0, 0.0, -4.754, -4.744, 0.0, 0.0, 0.0]}
{"step": 710, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 711.0, 1.0, 1.0, 1.0, 711.0, 711.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.792, 0.0, 0.0, 0.0, -4.755, -4.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1693, "number_of_timesteps": 32012, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.15000000000000036},
{"step": 711, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 712.0, 1.0, 1.0, 1.0, 712.0, 712.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.793, 0.0, 0.0, 0.0, -4.748, -4.737, 0.0, 0.0, 0.0]}
{"step": 712, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 713.0, 1.0, 1.0, 1.0, 713.0, 713.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.796, 0.0, 0.0, 0.0, -4.75, -4.739, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1699, "number_of_timesteps": 32150, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 713, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 714.0, 1.0, 1.0, 1.0, 714.0, 714.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.791, 0.0, 0.0, 0.0, -4.761, -4.75, 0.0, 0.0, 0.0]}
{"step": 714, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 715.0, 1.0, 1.0, 1.0, 715.0, 715.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.785, 0.0, 0.0, 0.0, -4.775, -4.764, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1705, "number_of_timesteps": 32236, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 715, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 716.0, 1.0, 1.0, 1.0, 716.0, 716.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.78, 0.0, 0.0, 0.0, -4.768, -4.757, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1710, "number_of_timesteps": 32304, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.1999999999999993},
{"step": 716, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 717.0, 1.0, 1.0, 1.0, 717.0, 717.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.775, 0.0, 0.0, 0.0, -4.778, -4.767, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1710, "number_of_timesteps": 32304, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.1999999999999993},
{"step": 717, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 718.0, 1.0, 1.0, 1.0, 718.0, 718.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.787, 0.0, 0.0, 0.0, -4.789, -4.778, 0.0, 0.0, 0.0]}
{"step": 718, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 719.0, 1.0, 1.0, 1.0, 719.0, 719.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.804, 0.0, 0.0, 0.0, -4.804, -4.793, 0.0, 0.0, 0.0]}
{"step": 719, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 720.0, 1.0, 1.0, 1.0, 720.0, 720.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.799, 0.0, 0.0, 0.0, -4.814, -4.803, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1717, "number_of_timesteps": 32444, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 720, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 721.0, 1.0, 1.0, 1.0, 721.0, 721.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.802, 0.0, 0.0, 0.0, -4.807, -4.805, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1721, "number_of_timesteps": 32517, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.1999999999999993},
{"step": 721, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 722.0, 1.0, 1.0, 1.0, 722.0, 722.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.797, 0.0, 0.0, 0.0, -4.822, -4.82, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1724, "number_of_timesteps": 32568, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.15000000000000036},
{"step": 722, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 723.0, 1.0, 1.0, 1.0, 723.0, 723.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.799, 0.0, 0.0, 0.0, -4.823, -4.82, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1729, "number_of_timesteps": 32626, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 723, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 724.0, 1.0, 1.0, 1.0, 724.0, 724.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.808, 0.0, 0.0, 0.0, -4.831, -4.829, 0.0, 0.0, 0.0]}
{"step": 724, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 725.0, 1.0, 1.0, 1.0, 725.0, 725.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.817, 0.0, 0.0, 0.0, -4.838, -4.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1734, "number_of_timesteps": 32691, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
{"step": 725, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 726.0, 1.0, 1.0, 1.0, 726.0, 726.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.817, 0.0, 0.0, 0.0, -4.837, -4.835, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1738, "number_of_timesteps": 32741, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 726, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 727.0, 1.0, 1.0, 1.0, 727.0, 727.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.812, 0.0, 0.0, 0.0, -4.851, -4.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1740, "number_of_timesteps": 32773, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 727, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 728.0, 1.0, 1.0, 1.0, 728.0, 728.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.813, 0.0, 0.0, 0.0, -4.851, -4.842, 0.0, 0.0, 0.0]}
{"step": 728, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 729.0, 1.0, 1.0, 1.0, 729.0, 729.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.817, 0.0, 0.0, 0.0, -4.853, -4.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1747, "number_of_timesteps": 32858, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 729, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 730.0, 1.0, 1.0, 1.0, 730.0, 730.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.832, 0.0, 0.0, 0.0, -4.867, -4.85, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1747, "number_of_timesteps": 32858, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 730, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 731.0, 1.0, 1.0, 1.0, 731.0, 731.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.833, 0.0, 0.0, 0.0, -4.86, -4.849, 0.0, 0.0, 0.0]}
{"step": 731, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 732.0, 1.0, 1.0, 1.0, 732.0, 732.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.834, 0.0, 0.0, 0.0, -4.854, -4.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1755, "number_of_timesteps": 33003, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 732, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 733.0, 1.0, 1.0, 1.0, 733.0, 733.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.834, 0.0, 0.0, 0.0, -4.853, -4.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1755, "number_of_timesteps": 33003, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 733, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 734.0, 1.0, 1.0, 1.0, 734.0, 734.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.837, 0.0, 0.0, 0.0, -4.855, -4.849, 0.0, 0.0, 0.0]}
{"step": 734, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 735.0, 1.0, 1.0, 1.0, 735.0, 735.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.841, 0.0, 0.0, 0.0, -4.858, -4.852, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1760, "number_of_timesteps": 33080, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 735, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 736.0, 1.0, 1.0, 1.0, 736.0, 736.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.836, 0.0, 0.0, 0.0, -4.851, -4.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1763, "number_of_timesteps": 33170, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 736, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 737.0, 1.0, 1.0, 1.0, 737.0, 737.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.837, 0.0, 0.0, 0.0, -4.844, -4.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1764, "number_of_timesteps": 33185, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.25},
{"step": 737, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 738.0, 1.0, 1.0, 1.0, 738.0, 738.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.832, 0.0, 0.0, 0.0, -4.838, -4.839, 0.0, 0.0, 0.0]}
{"step": 738, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 739.0, 1.0, 1.0, 1.0, 739.0, 739.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.827, 0.0, 0.0, 0.0, -4.831, -4.832, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1770, "number_of_timesteps": 33274, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 739, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 740.0, 1.0, 1.0, 1.0, 740.0, 740.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.822, 0.0, 0.0, 0.0, -4.839, -4.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1771, "number_of_timesteps": 33314, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
{"step": 740, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 741.0, 1.0, 1.0, 1.0, 741.0, 741.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.823, 0.0, 0.0, 0.0, -4.839, -4.833, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1775, "number_of_timesteps": 33368, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 741, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 742.0, 1.0, 1.0, 1.0, 742.0, 742.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.824, 0.0, 0.0, 0.0, -4.838, -4.832, 0.0, 0.0, 0.0]}
{"step": 742, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 743.0, 1.0, 1.0, 1.0, 743.0, 743.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.818, 0.0, 0.0, 0.0, -4.851, -4.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1778, "number_of_timesteps": 33430, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.25},
{"step": 743, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 744.0, 1.0, 1.0, 1.0, 744.0, 744.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.813, 0.0, 0.0, 0.0, -4.845, -4.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1780, "number_of_timesteps": 33469, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 744, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 745.0, 1.0, 1.0, 1.0, 745.0, 745.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.815, 0.0, 0.0, 0.0, -4.845, -4.839, 0.0, 0.0, 0.0]}
{"step": 745, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 746.0, 1.0, 1.0, 1.0, 746.0, 746.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.813, 0.0, 0.0, 0.0, -4.842, -4.836, 0.0, 0.0, 0.0]}
{"step": 746, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 747.0, 1.0, 1.0, 1.0, 747.0, 747.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.813, 0.0, 0.0, 0.0, -4.841, -4.835, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1787, "number_of_timesteps": 33617, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 747, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 748.0, 1.0, 1.0, 1.0, 748.0, 748.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.815, 0.0, 0.0, 0.0, -4.841, -4.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1790, "number_of_timesteps": 33711, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 748, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 749.0, 1.0, 1.0, 1.0, 749.0, 749.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.817, 0.0, 0.0, 0.0, -4.842, -4.836, 0.0, 0.0, 0.0]}
{"step": 749, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 750.0, 1.0, 1.0, 1.0, 750.0, 750.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.82, 0.0, 0.0, 0.0, -4.843, -4.837, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1794, "number_of_timesteps": 33785, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.15000000000000036},
{"step": 750, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 751.0, 1.0, 1.0, 1.0, 751.0, 751.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.82, 0.0, 0.0, 0.0, -4.836, -4.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1798, "number_of_timesteps": 33846, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 751, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 752.0, 1.0, 1.0, 1.0, 752.0, 752.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.815, 0.0, 0.0, 0.0, -4.853, -4.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1799, "number_of_timesteps": 33870, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.1999999999999993},
{"step": 752, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 753.0, 1.0, 1.0, 1.0, 753.0, 753.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.826, 0.0, 0.0, 0.0, -4.863, -4.863, 0.0, 0.0, 0.0]}
{"step": 753, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 754.0, 1.0, 1.0, 1.0, 754.0, 754.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.836, 0.0, 0.0, 0.0, -4.872, -4.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1803, "number_of_timesteps": 33972, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 754, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 755.0, 1.0, 1.0, 1.0, 755.0, 755.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.838, 0.0, 0.0, 0.0, -4.872, -4.872, 0.0, 0.0, 0.0]}
{"step": 755, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 756.0, 1.0, 1.0, 1.0, 756.0, 756.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.835, 0.0, 0.0, 0.0, -4.868, -4.868, 0.0, 0.0, 0.0]}
{"step": 756, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 757.0, 1.0, 1.0, 1.0, 757.0, 757.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.838, 0.0, 0.0, 0.0, -4.869, -4.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1809, "number_of_timesteps": 34094, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 757, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 758.0, 1.0, 1.0, 1.0, 758.0, 758.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.84, 0.0, 0.0, 0.0, -4.863, -4.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1811, "number_of_timesteps": 34143, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 758, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 759.0, 1.0, 1.0, 1.0, 759.0, 759.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.836, 0.0, 0.0, 0.0, -4.858, -4.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1815, "number_of_timesteps": 34234, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.25},
{"step": 759, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 760.0, 1.0, 1.0, 1.0, 760.0, 760.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.831, 0.0, 0.0, 0.0, -4.851, -4.858, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1816, "number_of_timesteps": 34243, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.15000000000000036},
{"step": 760, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 761.0, 1.0, 1.0, 1.0, 761.0, 761.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.831, 0.0, 0.0, 0.0, -4.851, -4.851, 0.0, 0.0, 0.0]}
{"eval_score": 18.4, "number_of_episodes": 1820}
{"number_of_episodes": 1820, "number_of_timesteps": 34317, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
{"step": 761, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 762.0, 1.0, 1.0, 1.0, 762.0, 762.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.832, 0.0, 0.0, 0.0, -4.844, -4.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1825, "number_of_timesteps": 34402, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 762, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 763.0, 1.0, 1.0, 1.0, 763.0, 763.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.832, 0.0, 0.0, 0.0, -4.843, -4.85, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1827, "number_of_timesteps": 34423, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"step": 763, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 764.0, 1.0, 1.0, 1.0, 764.0, 764.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.836, 0.0, 0.0, 0.0, -4.846, -4.852, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1831, "number_of_timesteps": 34469, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"step": 764, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 765.0, 1.0, 1.0, 1.0, 765.0, 765.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.831, 0.0, 0.0, 0.0, -4.84, -4.846, 0.0, 0.0, 0.0]}
{"step": 765, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 766.0, 1.0, 1.0, 1.0, 766.0, 766.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.826, 0.0, 0.0, 0.0, -4.833, -4.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1837, "number_of_timesteps": 34556, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
{"step": 766, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 767.0, 1.0, 1.0, 1.0, 767.0, 767.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.836, 0.0, 0.0, 0.0, -4.842, -4.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1840, "number_of_timesteps": 34591, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 767, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 768.0, 1.0, 1.0, 1.0, 768.0, 768.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.84, 0.0, 0.0, 0.0, -4.844, -4.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1842, "number_of_timesteps": 34624, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.14999999999999858},
{"step": 768, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 769.0, 1.0, 1.0, 1.0, 769.0, 769.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.842, 0.0, 0.0, 0.0, -4.838, -4.852, 0.0, 0.0, 0.0]}
{"step": 769, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 770.0, 1.0, 1.0, 1.0, 770.0, 770.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.856, 0.0, 0.0, 0.0, -4.851, -4.864, 0.0, 0.0, 0.0]}
{"step": 770, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 771.0, 1.0, 1.0, 1.0, 771.0, 771.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.858, 0.0, 0.0, 0.0, -4.844, -4.865, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1851, "number_of_timesteps": 34771, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 771, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 772.0, 1.0, 1.0, 1.0, 772.0, 772.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.86, 0.0, 0.0, 0.0, -4.845, -4.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1851, "number_of_timesteps": 34771, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 772, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 773.0, 1.0, 1.0, 1.0, 773.0, 773.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.855, 0.0, 0.0, 0.0, -4.859, -4.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1857, "number_of_timesteps": 34846, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
{"step": 773, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 774.0, 1.0, 1.0, 1.0, 774.0, 774.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.856, 0.0, 0.0, 0.0, -4.853, -4.873, 0.0, 0.0, 0.0]}
{"step": 774, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 775.0, 1.0, 1.0, 1.0, 775.0, 775.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.851, 0.0, 0.0, 0.0, -4.86, -4.881, 0.0, 0.0, 0.0]}
{"step": 775, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 776.0, 1.0, 1.0, 1.0, 776.0, 776.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.852, 0.0, 0.0, 0.0, -4.854, -4.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1862, "number_of_timesteps": 34950, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 776, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 777.0, 1.0, 1.0, 1.0, 777.0, 777.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.847, 0.0, 0.0, 0.0, -4.848, -4.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1865, "number_of_timesteps": 35012, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
{"step": 777, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 778.0, 1.0, 1.0, 1.0, 778.0, 778.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.842, 0.0, 0.0, 0.0, -4.842, -4.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1869, "number_of_timesteps": 35082, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 778, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 779.0, 1.0, 1.0, 1.0, 779.0, 779.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.845, 0.0, 0.0, 0.0, -4.843, -4.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1872, "number_of_timesteps": 35136, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 779, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 780.0, 1.0, 1.0, 1.0, 780.0, 780.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.855, 0.0, 0.0, 0.0, -4.852, -4.878, 0.0, 0.0, 0.0]}
{"step": 780, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 781.0, 1.0, 1.0, 1.0, 781.0, 781.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.872, 0.0, 0.0, 0.0, -4.867, -4.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1879, "number_of_timesteps": 35228, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 781, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 782.0, 1.0, 1.0, 1.0, 782.0, 782.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.867, 0.0, 0.0, 0.0, -4.861, -4.887, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1881, "number_of_timesteps": 35259, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
{"step": 782, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 783.0, 1.0, 1.0, 1.0, 783.0, 783.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.871, 0.0, 0.0, 0.0, -4.864, -4.881, 0.0, 0.0, 0.0]}
{"step": 783, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 784.0, 1.0, 1.0, 1.0, 784.0, 784.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.867, 0.0, 0.0, 0.0, -4.858, -4.875, 0.0, 0.0, 0.0]}
{"step": 784, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 785.0, 1.0, 1.0, 1.0, 785.0, 785.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.871, 0.0, 0.0, 0.0, -4.862, -4.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1889, "number_of_timesteps": 35386, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.25},
{"step": 785, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 786.0, 1.0, 1.0, 1.0, 786.0, 786.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.866, 0.0, 0.0, 0.0, -4.856, -4.862, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1893, "number_of_timesteps": 35456, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 786, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 787.0, 1.0, 1.0, 1.0, 787.0, 787.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.861, 0.0, 0.0, 0.0, -4.849, -4.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1895, "number_of_timesteps": 35480, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 787, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 788.0, 1.0, 1.0, 1.0, 788.0, 788.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.864, 0.0, 0.0, 0.0, -4.843, -4.858, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1899, "number_of_timesteps": 35528, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 788, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 789.0, 1.0, 1.0, 1.0, 789.0, 789.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.859, 0.0, 0.0, 0.0, -4.837, -4.851, 0.0, 0.0, 0.0]}
{"step": 789, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 790.0, 1.0, 1.0, 1.0, 790.0, 790.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.854, 0.0, 0.0, 0.0, -4.831, -4.845, 0.0, 0.0, 0.0]}
{"step": 790, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 791.0, 1.0, 1.0, 1.0, 791.0, 791.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.85, 0.0, 0.0, 0.0, -4.825, -4.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1907, "number_of_timesteps": 35645, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 791, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 792.0, 1.0, 1.0, 1.0, 792.0, 792.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.852, 0.0, 0.0, 0.0, -4.826, -4.833, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1909, "number_of_timesteps": 35671, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.25},
{"step": 792, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 793.0, 1.0, 1.0, 1.0, 793.0, 793.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.847, 0.0, 0.0, 0.0, -4.82, -4.827, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1913, "number_of_timesteps": 35733, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 793, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 794.0, 1.0, 1.0, 1.0, 794.0, 794.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.848, 0.0, 0.0, 0.0, -4.814, -4.827, 0.0, 0.0, 0.0]}
{"step": 794, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 795.0, 1.0, 1.0, 1.0, 795.0, 795.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.851, 0.0, 0.0, 0.0, -4.815, -4.821, 0.0, 0.0, 0.0]}
{"step": 795, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 796.0, 1.0, 1.0, 1.0, 796.0, 796.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.846, 0.0, 0.0, 0.0, -4.809, -4.815, 0.0, 0.0, 0.0]}
{"step": 796, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 797.0, 1.0, 1.0, 1.0, 797.0, 797.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.849, 0.0, 0.0, 0.0, -4.803, -4.816, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1924, "number_of_timesteps": 35927, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.14999999999999858},
{"step": 797, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 798.0, 1.0, 1.0, 1.0, 798.0, 798.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.85, 0.0, 0.0, 0.0, -4.803, -4.816, 0.0, 0.0, 0.0]}
{"step": 798, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 799.0, 1.0, 1.0, 1.0, 799.0, 799.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.853, 0.0, 0.0, 0.0, -4.805, -4.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1930, "number_of_timesteps": 36008, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 799, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 800.0, 1.0, 1.0, 1.0, 800.0, 800.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.865, 0.0, 0.0, 0.0, -4.816, -4.829, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1932, "number_of_timesteps": 36037, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 800, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 801.0, 1.0, 1.0, 1.0, 801.0, 801.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.866, 0.0, 0.0, 0.0, -4.81, -4.829, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1936, "number_of_timesteps": 36091, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"step": 801, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 802.0, 1.0, 1.0, 1.0, 802.0, 802.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.867, 0.0, 0.0, 0.0, -4.81, -4.829, 0.0, 0.0, 0.0]}
{"step": 802, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 803.0, 1.0, 1.0, 1.0, 803.0, 803.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.869, 0.0, 0.0, 0.0, -4.81, -4.829, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1941, "number_of_timesteps": 36174, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 803, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 804.0, 1.0, 1.0, 1.0, 804.0, 804.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.871, 0.0, 0.0, 0.0, -4.811, -4.823, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1943, "number_of_timesteps": 36205, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 804, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 805.0, 1.0, 1.0, 1.0, 805.0, 805.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.872, 0.0, 0.0, 0.0, -4.805, -4.823, 0.0, 0.0, 0.0]}
{"step": 805, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 806.0, 1.0, 1.0, 1.0, 806.0, 806.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.877, 0.0, 0.0, 0.0, -4.799, -4.826, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1948, "number_of_timesteps": 36287, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 806, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 807.0, 1.0, 1.0, 1.0, 807.0, 807.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.887, 0.0, 0.0, 0.0, -4.808, -4.835, 0.0, 0.0, 0.0]}
{"eval_score": 17.1, "number_of_episodes": 1951}
{"step": 807, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 808.0, 1.0, 1.0, 1.0, 808.0, 808.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.888, 0.0, 0.0, 0.0, -4.802, -4.835, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1954, "number_of_timesteps": 36367, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 808, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 809.0, 1.0, 1.0, 1.0, 809.0, 809.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.883, 0.0, 0.0, 0.0, -4.813, -4.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1956, "number_of_timesteps": 36421, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.1999999999999993},
{"step": 809, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 810.0, 1.0, 1.0, 1.0, 810.0, 810.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.884, 0.0, 0.0, 0.0, -4.813, -4.846, 0.0, 0.0, 0.0]}
{"step": 810, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 811.0, 1.0, 1.0, 1.0, 811.0, 811.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.88, 0.0, 0.0, 0.0, -4.821, -4.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1960, "number_of_timesteps": 36478, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 811, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 812.0, 1.0, 1.0, 1.0, 812.0, 812.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.882, 0.0, 0.0, 0.0, -4.815, -4.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1963, "number_of_timesteps": 36545, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 812, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 813.0, 1.0, 1.0, 1.0, 813.0, 813.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.894, 0.0, 0.0, 0.0, -4.826, -4.866, 0.0, 0.0, 0.0]}
{"step": 813, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 814.0, 1.0, 1.0, 1.0, 814.0, 814.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.912, 0.0, 0.0, 0.0, -4.843, -4.882, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1969, "number_of_timesteps": 36674, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.25},
{"step": 814, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 815.0, 1.0, 1.0, 1.0, 815.0, 815.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.907, 0.0, 0.0, 0.0, -4.837, -4.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1974, "number_of_timesteps": 36744, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 815, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 816.0, 1.0, 1.0, 1.0, 816.0, 816.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.902, 0.0, 0.0, 0.0, -4.831, -4.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1976, "number_of_timesteps": 36772, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.1999999999999993},
{"step": 816, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 817.0, 1.0, 1.0, 1.0, 817.0, 817.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.897, 0.0, 0.0, 0.0, -4.825, -4.865, 0.0, 0.0, 0.0]}
{"step": 817, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 818.0, 1.0, 1.0, 1.0, 818.0, 818.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.893, 0.0, 0.0, 0.0, -4.819, -4.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1983, "number_of_timesteps": 36865, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 818, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 819.0, 1.0, 1.0, 1.0, 819.0, 819.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.888, 0.0, 0.0, 0.0, -4.83, -4.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1987, "number_of_timesteps": 36924, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 819, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 820.0, 1.0, 1.0, 1.0, 820.0, 820.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.889, 0.0, 0.0, 0.0, -4.831, -4.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1988, "number_of_timesteps": 36939, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 820, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 821.0, 1.0, 1.0, 1.0, 821.0, 821.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.895, 0.0, 0.0, 0.0, -4.825, -4.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1990, "number_of_timesteps": 36967, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 821, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 822.0, 1.0, 1.0, 1.0, 822.0, 822.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.908, 0.0, 0.0, 0.0, -4.837, -4.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1993, "number_of_timesteps": 37016, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 822, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 823.0, 1.0, 1.0, 1.0, 823.0, 823.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.904, 0.0, 0.0, 0.0, -4.832, -4.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 1998, "number_of_timesteps": 37105, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.25},
{"step": 823, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 824.0, 1.0, 1.0, 1.0, 824.0, 824.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.899, 0.0, 0.0, 0.0, -4.826, -4.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2000, "number_of_timesteps": 37129, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 824, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 825.0, 1.0, 1.0, 1.0, 825.0, 825.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.894, 0.0, 0.0, 0.0, -4.837, -4.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2003, "number_of_timesteps": 37161, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.14999999999999858},
{"step": 825, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 826.0, 1.0, 1.0, 1.0, 826.0, 826.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.896, 0.0, 0.0, 0.0, -4.837, -4.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2005, "number_of_timesteps": 37181, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 826, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 827.0, 1.0, 1.0, 1.0, 827.0, 827.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.897, 0.0, 0.0, 0.0, -4.832, -4.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2006, "number_of_timesteps": 37196, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 827, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 828.0, 1.0, 1.0, 1.0, 828.0, 828.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.906, 0.0, 0.0, 0.0, -4.839, -4.888, 0.0, 0.0, 0.0]}
{"step": 828, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 829.0, 1.0, 1.0, 1.0, 829.0, 829.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.91, 0.0, 0.0, 0.0, -4.834, -4.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2013, "number_of_timesteps": 37333, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 829, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 830.0, 1.0, 1.0, 1.0, 830.0, 830.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.906, 0.0, 0.0, 0.0, -4.828, -4.885, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2017, "number_of_timesteps": 37416, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 830, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 831.0, 1.0, 1.0, 1.0, 831.0, 831.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.901, 0.0, 0.0, 0.0, -4.84, -4.898, 0.0, 0.0, 0.0]}
{"step": 831, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 832.0, 1.0, 1.0, 1.0, 832.0, 832.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.896, 0.0, 0.0, 0.0, -4.844, -4.901, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2024, "number_of_timesteps": 37497, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 832, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 833.0, 1.0, 1.0, 1.0, 833.0, 833.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.898, 0.0, 0.0, 0.0, -4.845, -4.902, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2026, "number_of_timesteps": 37518, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 833, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 834.0, 1.0, 1.0, 1.0, 834.0, 834.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.908, 0.0, 0.0, 0.0, -4.853, -4.91, 0.0, 0.0, 0.0]}
{"step": 834, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 835.0, 1.0, 1.0, 1.0, 835.0, 835.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.91, 0.0, 0.0, 0.0, -4.854, -4.911, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2032, "number_of_timesteps": 37620, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 835, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 836.0, 1.0, 1.0, 1.0, 836.0, 836.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.907, 0.0, 0.0, 0.0, -4.848, -4.907, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2037, "number_of_timesteps": 37681, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.1999999999999993},
{"step": 836, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 837.0, 1.0, 1.0, 1.0, 837.0, 837.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.903, 0.0, 0.0, 0.0, -4.842, -4.902, 0.0, 0.0, 0.0]}
{"step": 837, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 838.0, 1.0, 1.0, 1.0, 838.0, 838.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.907, 0.0, 0.0, 0.0, -4.836, -4.904, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2041, "number_of_timesteps": 37737, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 838, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 839.0, 1.0, 1.0, 1.0, 839.0, 839.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.91, 0.0, 0.0, 0.0, -4.838, -4.906, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2043, "number_of_timesteps": 37763, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"step": 839, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 840.0, 1.0, 1.0, 1.0, 840.0, 840.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.915, 0.0, 0.0, 0.0, -4.842, -4.91, 0.0, 0.0, 0.0]}
{"step": 840, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 841.0, 1.0, 1.0, 1.0, 841.0, 841.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.916, 0.0, 0.0, 0.0, -4.843, -4.911, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2049, "number_of_timesteps": 37901, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 841, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 842.0, 1.0, 1.0, 1.0, 842.0, 842.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.917, 0.0, 0.0, 0.0, -4.842, -4.905, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2051, "number_of_timesteps": 37934, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 842, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 843.0, 1.0, 1.0, 1.0, 843.0, 843.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.926, 0.0, 0.0, 0.0, -4.85, -4.913, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2054, "number_of_timesteps": 37983, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 843, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 844.0, 1.0, 1.0, 1.0, 844.0, 844.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.922, 0.0, 0.0, 0.0, -4.845, -4.907, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2059, "number_of_timesteps": 38041, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 844, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 845.0, 1.0, 1.0, 1.0, 845.0, 845.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.923, 0.0, 0.0, 0.0, -4.845, -4.908, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2061, "number_of_timesteps": 38074, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 845, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 846.0, 1.0, 1.0, 1.0, 846.0, 846.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.919, 0.0, 0.0, 0.0, -4.858, -4.92, 0.0, 0.0, 0.0]}
{"step": 846, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 847.0, 1.0, 1.0, 1.0, 847.0, 847.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.915, 0.0, 0.0, 0.0, -4.853, -4.915, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2068, "number_of_timesteps": 38170, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 847, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 848.0, 1.0, 1.0, 1.0, 848.0, 848.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.916, 0.0, 0.0, 0.0, -4.847, -4.916, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2069, "number_of_timesteps": 38187, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 848, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 849.0, 1.0, 1.0, 1.0, 849.0, 849.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.912, 0.0, 0.0, 0.0, -4.842, -4.91, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2074, "number_of_timesteps": 38248, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 849, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 850.0, 1.0, 1.0, 1.0, 850.0, 850.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.907, 0.0, 0.0, 0.0, -4.849, -4.917, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2077, "number_of_timesteps": 38299, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.1999999999999993},
{"step": 850, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 851.0, 1.0, 1.0, 1.0, 851.0, 851.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.916, 0.0, 0.0, 0.0, -4.857, -4.925, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2078, "number_of_timesteps": 38316, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.1999999999999993},
{"step": 851, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 852.0, 1.0, 1.0, 1.0, 852.0, 852.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.912, 0.0, 0.0, 0.0, -4.851, -4.919, 0.0, 0.0, 0.0]}
{"eval_score": 16.1, "number_of_episodes": 2081}
{"number_of_episodes": 2081, "number_of_timesteps": 38352, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 852, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 853.0, 1.0, 1.0, 1.0, 853.0, 853.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.914, 0.0, 0.0, 0.0, -4.853, -4.92, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2085, "number_of_timesteps": 38419, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 853, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 854.0, 1.0, 1.0, 1.0, 854.0, 854.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.917, 0.0, 0.0, 0.0, -4.854, -4.922, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2087, "number_of_timesteps": 38457, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 854, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 855.0, 1.0, 1.0, 1.0, 855.0, 855.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.919, 0.0, 0.0, 0.0, -4.855, -4.916, 0.0, 0.0, 0.0]}
{"step": 855, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 856.0, 1.0, 1.0, 1.0, 856.0, 856.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.917, 0.0, 0.0, 0.0, -4.852, -4.91, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2093, "number_of_timesteps": 38534, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 856, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 857.0, 1.0, 1.0, 1.0, 857.0, 857.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.918, 0.0, 0.0, 0.0, -4.853, -4.911, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2095, "number_of_timesteps": 38563, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 857, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 858.0, 1.0, 1.0, 1.0, 858.0, 858.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.933, 0.0, 0.0, 0.0, -4.867, -4.925, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2096, "number_of_timesteps": 38579, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 858, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 859.0, 1.0, 1.0, 1.0, 859.0, 859.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.929, 0.0, 0.0, 0.0, -4.882, -4.94, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2103, "number_of_timesteps": 38702, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 859, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 860.0, 1.0, 1.0, 1.0, 860.0, 860.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.932, 0.0, 0.0, 0.0, -4.884, -4.942, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2106, "number_of_timesteps": 38748, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 860, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 861.0, 1.0, 1.0, 1.0, 861.0, 861.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.933, 0.0, 0.0, 0.0, -4.884, -4.942, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2107, "number_of_timesteps": 38758, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 861, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 862.0, 1.0, 1.0, 1.0, 862.0, 862.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.938, 0.0, 0.0, 0.0, -4.878, -4.946, 0.0, 0.0, 0.0]}
{"step": 862, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 863.0, 1.0, 1.0, 1.0, 863.0, 863.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.934, 0.0, 0.0, 0.0, -4.873, -4.94, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2114, "number_of_timesteps": 38862, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 863, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 864.0, 1.0, 1.0, 1.0, 864.0, 864.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.937, 0.0, 0.0, 0.0, -4.875, -4.935, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2116, "number_of_timesteps": 38901, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 864, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 865.0, 1.0, 1.0, 1.0, 865.0, 865.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.947, 0.0, 0.0, 0.0, -4.884, -4.944, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2117, "number_of_timesteps": 38909, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 865, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 866.0, 1.0, 1.0, 1.0, 866.0, 866.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.949, 0.0, 0.0, 0.0, -4.884, -4.944, 0.0, 0.0, 0.0]}
{"step": 866, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 867.0, 1.0, 1.0, 1.0, 867.0, 867.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.952, 0.0, 0.0, 0.0, -4.886, -4.938, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2125, "number_of_timesteps": 39036, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 867, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 868.0, 1.0, 1.0, 1.0, 868.0, 868.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.947, 0.0, 0.0, 0.0, -4.901, -4.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2128, "number_of_timesteps": 39079, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 868, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 869.0, 1.0, 1.0, 1.0, 869.0, 869.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.943, 0.0, 0.0, 0.0, -4.895, -4.947, 0.0, 0.0, 0.0]}
{"step": 869, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 870.0, 1.0, 1.0, 1.0, 870.0, 870.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.938, 0.0, 0.0, 0.0, -4.889, -4.941, 0.0, 0.0, 0.0]}
{"step": 870, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 871.0, 1.0, 1.0, 1.0, 871.0, 871.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.934, 0.0, 0.0, 0.0, -4.902, -4.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2138, "number_of_timesteps": 39232, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 871, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 872.0, 1.0, 1.0, 1.0, 872.0, 872.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.935, 0.0, 0.0, 0.0, -4.896, -4.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2140, "number_of_timesteps": 39253, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.25},
{"step": 872, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 873.0, 1.0, 1.0, 1.0, 873.0, 873.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.93, 0.0, 0.0, 0.0, -4.891, -4.948, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2143, "number_of_timesteps": 39297, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 873, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 874.0, 1.0, 1.0, 1.0, 874.0, 874.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.928, 0.0, 0.0, 0.0, -4.887, -4.942, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2146, "number_of_timesteps": 39351, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 874, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 875.0, 1.0, 1.0, 1.0, 875.0, 875.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.923, 0.0, 0.0, 0.0, -4.881, -4.937, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2148, "number_of_timesteps": 39382, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 875, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 876.0, 1.0, 1.0, 1.0, 876.0, 876.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.919, 0.0, 0.0, 0.0, -4.889, -4.944, 0.0, 0.0, 0.0]}
{"step": 876, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 877.0, 1.0, 1.0, 1.0, 877.0, 877.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.914, 0.0, 0.0, 0.0, -4.899, -4.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2156, "number_of_timesteps": 39513, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 877, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 878.0, 1.0, 1.0, 1.0, 878.0, 878.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.93, 0.0, 0.0, 0.0, -4.913, -4.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2158, "number_of_timesteps": 39534, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"step": 878, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 879.0, 1.0, 1.0, 1.0, 879.0, 879.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.932, 0.0, 0.0, 0.0, -4.914, -4.969, 0.0, 0.0, 0.0]}
{"step": 879, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 880.0, 1.0, 1.0, 1.0, 880.0, 880.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.943, 0.0, 0.0, 0.0, -4.925, -4.979, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2162, "number_of_timesteps": 39593, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.15000000000000036},
{"step": 880, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 881.0, 1.0, 1.0, 1.0, 881.0, 881.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.945, 0.0, 0.0, 0.0, -4.925, -4.98, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2165, "number_of_timesteps": 39636, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 881, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 882.0, 1.0, 1.0, 1.0, 882.0, 882.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.947, 0.0, 0.0, 0.0, -4.927, -4.974, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2168, "number_of_timesteps": 39683, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 882, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 883.0, 1.0, 1.0, 1.0, 883.0, 883.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.963, 0.0, 0.0, 0.0, -4.942, -4.989, 0.0, 0.0, 0.0]}
{"step": 883, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 884.0, 1.0, 1.0, 1.0, 884.0, 884.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.962, 0.0, 0.0, 0.0, -4.939, -4.987, 0.0, 0.0, 0.0]}
{"step": 884, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 885.0, 1.0, 1.0, 1.0, 885.0, 885.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.968, 0.0, 0.0, 0.0, -4.944, -4.981, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2176, "number_of_timesteps": 39810, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 885, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 886.0, 1.0, 1.0, 1.0, 886.0, 886.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.964, 0.0, 0.0, 0.0, -4.955, -4.992, 0.0, 0.0, 0.0]}
{"step": 886, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 887.0, 1.0, 1.0, 1.0, 887.0, 887.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.96, 0.0, 0.0, 0.0, -4.964, -5.0, 0.0, 0.0, 0.0]}
{"step": 887, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 888.0, 1.0, 1.0, 1.0, 888.0, 888.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.955, 0.0, 0.0, 0.0, -4.972, -5.009, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2186, "number_of_timesteps": 39991, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 888, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 889.0, 1.0, 1.0, 1.0, 889.0, 889.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.969, 0.0, 0.0, 0.0, -4.985, -5.022, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2188, "number_of_timesteps": 40015, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000036},
{"step": 889, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 890.0, 1.0, 1.0, 1.0, 890.0, 890.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.97, 0.0, 0.0, 0.0, -4.98, -5.021, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2191, "number_of_timesteps": 40054, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 890, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 891.0, 1.0, 1.0, 1.0, 891.0, 891.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.965, 0.0, 0.0, 0.0, -4.987, -5.029, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2194, "number_of_timesteps": 40097, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 891, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 892.0, 1.0, 1.0, 1.0, 892.0, 892.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.961, 0.0, 0.0, 0.0, -4.982, -5.023, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2195, "number_of_timesteps": 40121, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 892, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 893.0, 1.0, 1.0, 1.0, 893.0, 893.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.961, 0.0, 0.0, 0.0, -4.982, -5.017, 0.0, 0.0, 0.0]}
{"step": 893, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 894.0, 1.0, 1.0, 1.0, 894.0, 894.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.957, 0.0, 0.0, 0.0, -4.976, -5.012, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2201, "number_of_timesteps": 40208, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.20000000000000107},
{"step": 894, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 895.0, 1.0, 1.0, 1.0, 895.0, 895.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.958, 0.0, 0.0, 0.0, -4.976, -5.012, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2201, "number_of_timesteps": 40208, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 895, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 896.0, 1.0, 1.0, 1.0, 896.0, 896.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.961, 0.0, 0.0, 0.0, -4.977, -5.013, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2203, "number_of_timesteps": 40230, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 896, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 897.0, 1.0, 1.0, 1.0, 897.0, 897.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.956, 0.0, 0.0, 0.0, -4.984, -5.02, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2207, "number_of_timesteps": 40347, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 897, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 898.0, 1.0, 1.0, 1.0, 898.0, 898.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.952, 0.0, 0.0, 0.0, -4.979, -5.015, 0.0, 0.0, 0.0]}
{"eval_score": 14.9, "number_of_episodes": 2210}
{"number_of_episodes": 2210, "number_of_timesteps": 40428, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 898, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 899.0, 1.0, 1.0, 1.0, 899.0, 899.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.948, 0.0, 0.0, 0.0, -4.974, -5.009, 0.0, 0.0, 0.0]}
{"step": 899, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 900.0, 1.0, 1.0, 1.0, 900.0, 900.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.943, 0.0, 0.0, 0.0, -4.98, -5.015, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2217, "number_of_timesteps": 40540, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 900, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 901.0, 1.0, 1.0, 1.0, 901.0, 901.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.946, 0.0, 0.0, 0.0, -4.981, -5.017, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2219, "number_of_timesteps": 40572, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 901, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 902.0, 1.0, 1.0, 1.0, 902.0, 902.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.942, 0.0, 0.0, 0.0, -4.99, -5.026, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2222, "number_of_timesteps": 40615, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.15000000000000036},
{"step": 902, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 903.0, 1.0, 1.0, 1.0, 903.0, 903.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.938, 0.0, 0.0, 0.0, -4.985, -5.02, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2227, "number_of_timesteps": 40679, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 903, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 904.0, 1.0, 1.0, 1.0, 904.0, 904.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.933, 0.0, 0.0, 0.0, -4.98, -5.015, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2230, "number_of_timesteps": 40715, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 904, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 905.0, 1.0, 1.0, 1.0, 905.0, 905.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.935, 0.0, 0.0, 0.0, -4.98, -5.016, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2231, "number_of_timesteps": 40729, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 905, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 906.0, 1.0, 1.0, 1.0, 906.0, 906.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.936, 0.0, 0.0, 0.0, -4.98, -5.015, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2236, "number_of_timesteps": 40785, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 906, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 907.0, 1.0, 1.0, 1.0, 907.0, 907.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.932, 0.0, 0.0, 0.0, -4.987, -5.022, 0.0, 0.0, 0.0]}
{"step": 907, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 908.0, 1.0, 1.0, 1.0, 908.0, 908.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.928, 0.0, 0.0, 0.0, -4.996, -5.031, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2238, "number_of_timesteps": 40831, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.15000000000000036},
{"step": 908, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 909.0, 1.0, 1.0, 1.0, 909.0, 909.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.923, 0.0, 0.0, 0.0, -4.991, -5.026, 0.0, 0.0, 0.0]}
{"step": 909, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 910.0, 1.0, 1.0, 1.0, 910.0, 910.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.919, 0.0, 0.0, 0.0, -4.999, -5.034, 0.0, 0.0, 0.0]}
{"step": 910, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 911.0, 1.0, 1.0, 1.0, 911.0, 911.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.915, 0.0, 0.0, 0.0, -4.994, -5.029, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2246, "number_of_timesteps": 40997, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 911, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 912.0, 1.0, 1.0, 1.0, 912.0, 912.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.914, 0.0, 0.0, 0.0, -4.991, -5.026, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2248, "number_of_timesteps": 41028, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 912, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 913.0, 1.0, 1.0, 1.0, 913.0, 913.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.915, 0.0, 0.0, 0.0, -4.986, -5.026, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2252, "number_of_timesteps": 41097, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 913, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 914.0, 1.0, 1.0, 1.0, 914.0, 914.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.91, 0.0, 0.0, 0.0, -5.003, -5.043, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2254, "number_of_timesteps": 41124, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.20000000000000107},
{"step": 914, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 915.0, 1.0, 1.0, 1.0, 915.0, 915.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.912, 0.0, 0.0, 0.0, -5.003, -5.043, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2259, "number_of_timesteps": 41195, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 915, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 916.0, 1.0, 1.0, 1.0, 916.0, 916.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.913, 0.0, 0.0, 0.0, -5.004, -5.044, 0.0, 0.0, 0.0]}
{"step": 916, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 917.0, 1.0, 1.0, 1.0, 917.0, 917.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.909, 0.0, 0.0, 0.0, -4.999, -5.039, 0.0, 0.0, 0.0]}
{"step": 917, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 918.0, 1.0, 1.0, 1.0, 918.0, 918.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.91, 0.0, 0.0, 0.0, -4.999, -5.038, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2265, "number_of_timesteps": 41280, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 918, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 919.0, 1.0, 1.0, 1.0, 919.0, 919.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.911, 0.0, 0.0, 0.0, -4.993, -5.038, 0.0, 0.0, 0.0]}
{"step": 919, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 920.0, 1.0, 1.0, 1.0, 920.0, 920.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.912, 0.0, 0.0, 0.0, -4.993, -5.038, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2267, "number_of_timesteps": 41318, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 920, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 921.0, 1.0, 1.0, 1.0, 921.0, 921.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.924, 0.0, 0.0, 0.0, -5.003, -5.048, 0.0, 0.0, 0.0]}
{"step": 921, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 922.0, 1.0, 1.0, 1.0, 922.0, 922.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.927, 0.0, 0.0, 0.0, -4.998, -5.051, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2274, "number_of_timesteps": 41463, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.20000000000000107},
{"step": 922, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 923.0, 1.0, 1.0, 1.0, 923.0, 923.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.928, 0.0, 0.0, 0.0, -4.997, -5.05, 0.0, 0.0, 0.0]}
{"step": 923, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 924.0, 1.0, 1.0, 1.0, 924.0, 924.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.929, 0.0, 0.0, 0.0, -4.997, -5.05, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2279, "number_of_timesteps": 41546, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 924, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 925.0, 1.0, 1.0, 1.0, 925.0, 925.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.925, 0.0, 0.0, 0.0, -4.992, -5.044, 0.0, 0.0, 0.0]}
{"step": 925, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 926.0, 1.0, 1.0, 1.0, 926.0, 926.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.921, 0.0, 0.0, 0.0, -4.986, -5.039, 0.0, 0.0, 0.0]}
{"step": 926, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 927.0, 1.0, 1.0, 1.0, 927.0, 927.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.916, 0.0, 0.0, 0.0, -4.981, -5.034, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2288, "number_of_timesteps": 41697, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 927, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 928.0, 1.0, 1.0, 1.0, 928.0, 928.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.918, 0.0, 0.0, 0.0, -4.981, -5.033, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2290, "number_of_timesteps": 41725, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 928, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 929.0, 1.0, 1.0, 1.0, 929.0, 929.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.918, 0.0, 0.0, 0.0, -4.981, -5.033, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2294, "number_of_timesteps": 41789, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 929, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 930.0, 1.0, 1.0, 1.0, 930.0, 930.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.922, 0.0, 0.0, 0.0, -4.975, -5.035, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2295, "number_of_timesteps": 41808, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
{"step": 930, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 931.0, 1.0, 1.0, 1.0, 931.0, 931.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.933, 0.0, 0.0, 0.0, -4.985, -5.045, 0.0, 0.0, 0.0]}
{"step": 931, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 932.0, 1.0, 1.0, 1.0, 932.0, 932.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.935, 0.0, 0.0, 0.0, -4.98, -5.046, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2299, "number_of_timesteps": 41884, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 932, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 933.0, 1.0, 1.0, 1.0, 933.0, 933.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.931, 0.0, 0.0, 0.0, -4.975, -5.041, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2305, "number_of_timesteps": 41988, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000036},
{"step": 933, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 934.0, 1.0, 1.0, 1.0, 934.0, 934.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.933, 0.0, 0.0, 0.0, -4.975, -5.041, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2306, "number_of_timesteps": 42010, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.10000000000000142},
{"step": 934, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 935.0, 1.0, 1.0, 1.0, 935.0, 935.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.932, 0.0, 0.0, 0.0, -4.974, -5.036, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2307, "number_of_timesteps": 42024, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"step": 935, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 936.0, 1.0, 1.0, 1.0, 936.0, 936.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.928, 0.0, 0.0, 0.0, -4.97, -5.032, 0.0, 0.0, 0.0]}
{"step": 936, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 937.0, 1.0, 1.0, 1.0, 937.0, 937.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.93, 0.0, 0.0, 0.0, -4.971, -5.033, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2313, "number_of_timesteps": 42100, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 937, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 938.0, 1.0, 1.0, 1.0, 938.0, 938.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.945, 0.0, 0.0, 0.0, -4.985, -5.047, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2317, "number_of_timesteps": 42189, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 938, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 939.0, 1.0, 1.0, 1.0, 939.0, 939.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.941, 0.0, 0.0, 0.0, -4.98, -5.042, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2321, "number_of_timesteps": 42250, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 939, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 940.0, 1.0, 1.0, 1.0, 940.0, 940.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.942, 0.0, 0.0, 0.0, -4.974, -5.042, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2324, "number_of_timesteps": 42295, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.20000000000000107},
{"step": 940, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 941.0, 1.0, 1.0, 1.0, 941.0, 941.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.944, 0.0, 0.0, 0.0, -4.975, -5.042, 0.0, 0.0, 0.0]}
{"step": 941, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 942.0, 1.0, 1.0, 1.0, 942.0, 942.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.947, 0.0, 0.0, 0.0, -4.977, -5.044, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2328, "number_of_timesteps": 42348, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 942, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 943.0, 1.0, 1.0, 1.0, 943.0, 943.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.943, 0.0, 0.0, 0.0, -4.974, -5.041, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2334, "number_of_timesteps": 42431, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"step": 943, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 944.0, 1.0, 1.0, 1.0, 944.0, 944.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.944, 0.0, 0.0, 0.0, -4.974, -5.035, 0.0, 0.0, 0.0]}
{"step": 944, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 945.0, 1.0, 1.0, 1.0, 945.0, 945.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.947, 0.0, 0.0, 0.0, -4.976, -5.03, 0.0, 0.0, 0.0]}
{"step": 945, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 946.0, 1.0, 1.0, 1.0, 946.0, 946.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.943, 0.0, 0.0, 0.0, -4.982, -5.036, 0.0, 0.0, 0.0]}
{"step": 946, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 947.0, 1.0, 1.0, 1.0, 947.0, 947.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.944, 0.0, 0.0, 0.0, -4.982, -5.031, 0.0, 0.0, 0.0]}
{"eval_score": 16.4, "number_of_episodes": 2345}
{"number_of_episodes": 2345, "number_of_timesteps": 42599, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 947, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 948.0, 1.0, 1.0, 1.0, 948.0, 948.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.94, 0.0, 0.0, 0.0, -4.977, -5.025, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2346, "number_of_timesteps": 42620, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"step": 948, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 949.0, 1.0, 1.0, 1.0, 949.0, 949.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.942, 0.0, 0.0, 0.0, -4.977, -5.02, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2347, "number_of_timesteps": 42634, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 949, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 950.0, 1.0, 1.0, 1.0, 950.0, 950.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.946, 0.0, 0.0, 0.0, -4.98, -5.023, 0.0, 0.0, 0.0]}
{"step": 950, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 951.0, 1.0, 1.0, 1.0, 951.0, 951.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.943, 0.0, 0.0, 0.0, -4.977, -5.018, 0.0, 0.0, 0.0]}
{"step": 951, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 952.0, 1.0, 1.0, 1.0, 952.0, 952.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.939, 0.0, 0.0, 0.0, -4.972, -5.013, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2357, "number_of_timesteps": 42822, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 952, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 953.0, 1.0, 1.0, 1.0, 953.0, 953.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.935, 0.0, 0.0, 0.0, -4.979, -5.02, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2361, "number_of_timesteps": 42868, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.15000000000000036},
{"step": 953, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 954.0, 1.0, 1.0, 1.0, 954.0, 954.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.933, 0.0, 0.0, 0.0, -4.974, -5.016, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2364, "number_of_timesteps": 42909, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.20000000000000107},
{"step": 954, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 955.0, 1.0, 1.0, 1.0, 955.0, 955.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.934, 0.0, 0.0, 0.0, -4.974, -5.016, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2367, "number_of_timesteps": 42940, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 955, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 956.0, 1.0, 1.0, 1.0, 956.0, 956.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.929, 0.0, 0.0, 0.0, -4.968, -5.011, 0.0, 0.0, 0.0]}
{"step": 956, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 957.0, 1.0, 1.0, 1.0, 957.0, 957.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.932, 0.0, 0.0, 0.0, -4.97, -5.013, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2373, "number_of_timesteps": 43022, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 957, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 958.0, 1.0, 1.0, 1.0, 958.0, 958.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.934, 0.0, 0.0, 0.0, -4.971, -5.013, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2374, "number_of_timesteps": 43038, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.20000000000000107},
{"step": 958, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 959.0, 1.0, 1.0, 1.0, 959.0, 959.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.935, 0.0, 0.0, 0.0, -4.971, -5.013, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2377, "number_of_timesteps": 43076, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 959, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 960.0, 1.0, 1.0, 1.0, 960.0, 960.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.931, 0.0, 0.0, 0.0, -4.967, -5.009, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2379, "number_of_timesteps": 43114, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 960, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 961.0, 1.0, 1.0, 1.0, 961.0, 961.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.927, 0.0, 0.0, 0.0, -4.962, -5.004, 0.0, 0.0, 0.0]}
{"step": 961, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 962.0, 1.0, 1.0, 1.0, 962.0, 962.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.923, 0.0, 0.0, 0.0, -4.957, -4.999, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2385, "number_of_timesteps": 43230, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 962, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 963.0, 1.0, 1.0, 1.0, 963.0, 963.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.919, 0.0, 0.0, 0.0, -4.951, -4.994, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2387, "number_of_timesteps": 43276, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 963, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 964.0, 1.0, 1.0, 1.0, 964.0, 964.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.922, 0.0, 0.0, 0.0, -4.953, -4.995, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2389, "number_of_timesteps": 43309, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 964, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 965.0, 1.0, 1.0, 1.0, 965.0, 965.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.921, 0.0, 0.0, 0.0, -4.948, -4.994, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2396, "number_of_timesteps": 43412, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 965, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 966.0, 1.0, 1.0, 1.0, 966.0, 966.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.917, 0.0, 0.0, 0.0, -4.963, -5.009, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2397, "number_of_timesteps": 43428, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
{"step": 966, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 967.0, 1.0, 1.0, 1.0, 967.0, 967.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.919, 0.0, 0.0, 0.0, -4.964, -5.01, 0.0, 0.0, 0.0]}
{"step": 967, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 968.0, 1.0, 1.0, 1.0, 968.0, 968.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.915, 0.0, 0.0, 0.0, -4.972, -5.018, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2402, "number_of_timesteps": 43490, "per_episode_reward": 15.25, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 968, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 969.0, 1.0, 1.0, 1.0, 969.0, 969.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.911, 0.0, 0.0, 0.0, -4.967, -5.012, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2408, "number_of_timesteps": 43583, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 969, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 970.0, 1.0, 1.0, 1.0, 970.0, 970.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.913, 0.0, 0.0, 0.0, -4.962, -5.013, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2409, "number_of_timesteps": 43594, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 970, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 971.0, 1.0, 1.0, 1.0, 971.0, 971.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.917, 0.0, 0.0, 0.0, -4.964, -5.015, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2413, "number_of_timesteps": 43645, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 971, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 972.0, 1.0, 1.0, 1.0, 972.0, 972.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.913, 0.0, 0.0, 0.0, -4.959, -5.01, 0.0, 0.0, 0.0]}
{"step": 972, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 973.0, 1.0, 1.0, 1.0, 973.0, 973.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.914, 0.0, 0.0, 0.0, -4.959, -5.01, 0.0, 0.0, 0.0]}
{"step": 973, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 974.0, 1.0, 1.0, 1.0, 974.0, 974.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.917, 0.0, 0.0, 0.0, -4.962, -5.013, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2420, "number_of_timesteps": 43743, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 974, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 975.0, 1.0, 1.0, 1.0, 975.0, 975.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.913, 0.0, 0.0, 0.0, -4.957, -5.008, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2423, "number_of_timesteps": 43787, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 975, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 976.0, 1.0, 1.0, 1.0, 976.0, 976.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.919, 0.0, 0.0, 0.0, -4.961, -5.012, 0.0, 0.0, 0.0]}
{"step": 976, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 977.0, 1.0, 1.0, 1.0, 977.0, 977.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.937, 0.0, 0.0, 0.0, -4.978, -5.029, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2433, "number_of_timesteps": 43928, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 977, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 978.0, 1.0, 1.0, 1.0, 978.0, 978.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.947, 0.0, 0.0, 0.0, -4.987, -5.038, 0.0, 0.0, 0.0]}
{"step": 978, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 979.0, 1.0, 1.0, 1.0, 979.0, 979.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.96, 0.0, 0.0, 0.0, -4.999, -5.05, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2437, "number_of_timesteps": 43972, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 979, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 980.0, 1.0, 1.0, 1.0, 980.0, 980.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.956, 0.0, 0.0, 0.0, -4.994, -5.045, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2441, "number_of_timesteps": 44026, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 980, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 981.0, 1.0, 1.0, 1.0, 981.0, 981.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.958, 0.0, 0.0, 0.0, -4.995, -5.046, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2445, "number_of_timesteps": 44080, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 981, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 982.0, 1.0, 1.0, 1.0, 982.0, 982.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.955, 0.0, 0.0, 0.0, -4.991, -5.042, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2448, "number_of_timesteps": 44132, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 982, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 983.0, 1.0, 1.0, 1.0, 983.0, 983.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.957, 0.0, 0.0, 0.0, -4.986, -5.042, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2450, "number_of_timesteps": 44154, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 983, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 984.0, 1.0, 1.0, 1.0, 984.0, 984.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.966, 0.0, 0.0, 0.0, -4.994, -5.05, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2453, "number_of_timesteps": 44199, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 984, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 985.0, 1.0, 1.0, 1.0, 985.0, 985.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.968, 0.0, 0.0, 0.0, -4.995, -5.051, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2455, "number_of_timesteps": 44242, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 985, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 986.0, 1.0, 1.0, 1.0, 986.0, 986.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.964, 0.0, 0.0, 0.0, -4.99, -5.046, 0.0, 0.0, 0.0]}
{"step": 986, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 987.0, 1.0, 1.0, 1.0, 987.0, 987.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.974, 0.0, 0.0, 0.0, -4.999, -5.055, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2461, "number_of_timesteps": 44323, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"step": 987, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 988.0, 1.0, 1.0, 1.0, 988.0, 988.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.975, 0.0, 0.0, 0.0, -5.0, -5.055, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2463, "number_of_timesteps": 44362, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"step": 988, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 989.0, 1.0, 1.0, 1.0, 989.0, 989.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.979, 0.0, 0.0, 0.0, -4.995, -5.057, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2467, "number_of_timesteps": 44430, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 989, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 990.0, 1.0, 1.0, 1.0, 990.0, 990.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.98, 0.0, 0.0, 0.0, -4.995, -5.058, 0.0, 0.0, 0.0]}
{"eval_score": 12.9, "number_of_episodes": 2470}
{"number_of_episodes": 2470, "number_of_timesteps": 44473, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 990, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 991.0, 1.0, 1.0, 1.0, 991.0, 991.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.994, 0.0, 0.0, 0.0, -5.008, -5.071, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2473, "number_of_timesteps": 44528, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"step": 991, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 992.0, 1.0, 1.0, 1.0, 992.0, 992.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.996, 0.0, 0.0, 0.0, -5.009, -5.071, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2478, "number_of_timesteps": 44587, "per_episode_reward": 15.05, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 992, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 993.0, 1.0, 1.0, 1.0, 993.0, 993.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.992, 0.0, 0.0, 0.0, -5.004, -5.066, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2480, "number_of_timesteps": 44610, "per_episode_reward": 15.05, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
{"step": 993, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 994.0, 1.0, 1.0, 1.0, 994.0, 994.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.988, 0.0, 0.0, 0.0, -5.016, -5.079, 0.0, 0.0, 0.0]}
{"step": 994, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 995.0, 1.0, 1.0, 1.0, 995.0, 995.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.984, 0.0, 0.0, 0.0, -5.022, -5.084, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2483, "number_of_timesteps": 44664, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 995, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 996.0, 1.0, 1.0, 1.0, 996.0, 996.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.994, 0.0, 0.0, 0.0, -5.031, -5.093, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2487, "number_of_timesteps": 44725, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.3500000000000014},
{"step": 996, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 997.0, 1.0, 1.0, 1.0, 997.0, 997.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.996, 0.0, 0.0, 0.0, -5.032, -5.088, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2489, "number_of_timesteps": 44759, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 997, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 998.0, 1.0, 1.0, 1.0, 998.0, 998.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.998, 0.0, 0.0, 0.0, -5.027, -5.089, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2493, "number_of_timesteps": 44853, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 998, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 999.0, 1.0, 1.0, 1.0, 999.0, 999.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.994, 0.0, 0.0, 0.0, -5.022, -5.084, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2497, "number_of_timesteps": 44904, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.20000000000000107},
{"step": 999, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1000.0, 1.0, 1.0, 1.0, 1000.0, 1000.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.99, 0.0, 0.0, 0.0, -5.017, -5.079, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2500, "number_of_timesteps": 44939, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.3500000000000014},
{"step": 1000, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1001.0, 1.0, 1.0, 1.0, 1001.0, 1001.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -3.991, 0.0, 0.0, 0.0, -5.017, -5.074, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2503, "number_of_timesteps": 44977, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 1001, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1002.0, 1.0, 1.0, 1.0, 1002.0, 1002.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.007, 0.0, 0.0, 0.0, -5.031, -5.088, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2507, "number_of_timesteps": 45026, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1002, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1003.0, 1.0, 1.0, 1.0, 1003.0, 1003.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.008, 0.0, 0.0, 0.0, -5.026, -5.089, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2509, "number_of_timesteps": 45048, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"step": 1003, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1004.0, 1.0, 1.0, 1.0, 1004.0, 1004.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.004, 0.0, 0.0, 0.0, -5.021, -5.084, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2510, "number_of_timesteps": 45060, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.1999999999999993},
{"step": 1004, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1005.0, 1.0, 1.0, 1.0, 1005.0, 1005.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.004, 0.0, 0.0, 0.0, -5.02, -5.083, 0.0, 0.0, 0.0]}
{"step": 1005, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1006.0, 1.0, 1.0, 1.0, 1006.0, 1006.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.0, 0.0, 0.0, 0.0, -5.015, -5.078, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2520, "number_of_timesteps": 45204, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3500000000000014},
{"step": 1006, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1007.0, 1.0, 1.0, 1.0, 1007.0, 1007.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.002, 0.0, 0.0, 0.0, -5.016, -5.073, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2520, "number_of_timesteps": 45204, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1007, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1008.0, 1.0, 1.0, 1.0, 1008.0, 1008.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.005, 0.0, 0.0, 0.0, -5.018, -5.074, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2520, "number_of_timesteps": 45204, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1008, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1009.0, 1.0, 1.0, 1.0, 1009.0, 1009.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.018, 0.0, 0.0, 0.0, -5.03, -5.086, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2525, "number_of_timesteps": 45286, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 1009, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1010.0, 1.0, 1.0, 1.0, 1010.0, 1010.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.019, 0.0, 0.0, 0.0, -5.025, -5.086, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2527, "number_of_timesteps": 45327, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.20000000000000107},
{"step": 1010, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1011.0, 1.0, 1.0, 1.0, 1011.0, 1011.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.024, 0.0, 0.0, 0.0, -5.029, -5.09, 0.0, 0.0, 0.0]}
{"step": 1011, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1012.0, 1.0, 1.0, 1.0, 1012.0, 1012.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.025, 0.0, 0.0, 0.0, -5.029, -5.09, 0.0, 0.0, 0.0]}
{"step": 1012, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1013.0, 1.0, 1.0, 1.0, 1013.0, 1013.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.026, 0.0, 0.0, 0.0, -5.024, -5.091, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2534, "number_of_timesteps": 45465, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1013, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1014.0, 1.0, 1.0, 1.0, 1014.0, 1014.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.022, 0.0, 0.0, 0.0, -5.034, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2537, "number_of_timesteps": 45524, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1014, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1015.0, 1.0, 1.0, 1.0, 1015.0, 1015.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.022, 0.0, 0.0, 0.0, -5.029, -5.099, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2542, "number_of_timesteps": 45584, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 1015, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1016.0, 1.0, 1.0, 1.0, 1016.0, 1016.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.018, 0.0, 0.0, 0.0, -5.024, -5.094, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2545, "number_of_timesteps": 45632, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.3500000000000014},
{"step": 1016, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1017.0, 1.0, 1.0, 1.0, 1017.0, 1017.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.02, 0.0, 0.0, 0.0, -5.024, -5.089, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2548, "number_of_timesteps": 45675, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1017, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1018.0, 1.0, 1.0, 1.0, 1018.0, 1018.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.021, 0.0, 0.0, 0.0, -5.02, -5.089, 0.0, 0.0, 0.0]}
{"step": 1018, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1019.0, 1.0, 1.0, 1.0, 1019.0, 1019.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.025, 0.0, 0.0, 0.0, -5.015, -5.092, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2554, "number_of_timesteps": 45739, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1019, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1020.0, 1.0, 1.0, 1.0, 1020.0, 1020.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.021, 0.0, 0.0, 0.0, -5.027, -5.105, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2555, "number_of_timesteps": 45749, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 1020, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1021.0, 1.0, 1.0, 1.0, 1021.0, 1021.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.017, 0.0, 0.0, 0.0, -5.022, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2559, "number_of_timesteps": 45820, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1021, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1022.0, 1.0, 1.0, 1.0, 1022.0, 1022.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.015, 0.0, 0.0, 0.0, -5.019, -5.096, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2562, "number_of_timesteps": 45866, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1022, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1023.0, 1.0, 1.0, 1.0, 1023.0, 1023.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.017, 0.0, 0.0, 0.0, -5.014, -5.097, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2565, "number_of_timesteps": 45917, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1023, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1024.0, 1.0, 1.0, 1.0, 1024.0, 1024.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.019, 0.0, 0.0, 0.0, -5.014, -5.098, 0.0, 0.0, 0.0]}
{"step": 1024, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1025.0, 1.0, 1.0, 1.0, 1025.0, 1025.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.022, 0.0, 0.0, 0.0, -5.01, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2571, "number_of_timesteps": 46016, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"step": 1025, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1026.0, 1.0, 1.0, 1.0, 1026.0, 1026.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.023, 0.0, 0.0, 0.0, -5.01, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2575, "number_of_timesteps": 46082, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"step": 1026, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1027.0, 1.0, 1.0, 1.0, 1027.0, 1027.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.019, 0.0, 0.0, 0.0, -5.005, -5.095, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2577, "number_of_timesteps": 46109, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.20000000000000107},
{"step": 1027, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1028.0, 1.0, 1.0, 1.0, 1028.0, 1028.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.015, 0.0, 0.0, 0.0, -5.0, -5.09, 0.0, 0.0, 0.0]}
{"step": 1028, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1029.0, 1.0, 1.0, 1.0, 1029.0, 1029.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.011, 0.0, 0.0, 0.0, -4.995, -5.085, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2584, "number_of_timesteps": 46217, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"step": 1029, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1030.0, 1.0, 1.0, 1.0, 1030.0, 1030.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.019, 0.0, 0.0, 0.0, -5.002, -5.092, 0.0, 0.0, 0.0]}
{"step": 1030, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1031.0, 1.0, 1.0, 1.0, 1031.0, 1031.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.015, 0.0, 0.0, 0.0, -4.997, -5.087, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2587, "number_of_timesteps": 46258, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 1031, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1032.0, 1.0, 1.0, 1.0, 1032.0, 1032.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.011, 0.0, 0.0, 0.0, -4.993, -5.082, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2593, "number_of_timesteps": 46350, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"step": 1032, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1033.0, 1.0, 1.0, 1.0, 1033.0, 1033.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.013, 0.0, 0.0, 0.0, -4.993, -5.082, 0.0, 0.0, 0.0]}
{"step": 1033, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1034.0, 1.0, 1.0, 1.0, 1034.0, 1034.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.009, 0.0, 0.0, 0.0, -4.988, -5.077, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2598, "number_of_timesteps": 46424, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1034, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1035.0, 1.0, 1.0, 1.0, 1035.0, 1035.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.012, 0.0, 0.0, 0.0, -4.99, -5.079, 0.0, 0.0, 0.0]}
{"eval_score": 16.1, "number_of_episodes": 2600}
{"step": 1035, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1036.0, 1.0, 1.0, 1.0, 1036.0, 1036.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.013, 0.0, 0.0, 0.0, -4.99, -5.079, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2603, "number_of_timesteps": 46497, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1036, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1037.0, 1.0, 1.0, 1.0, 1037.0, 1037.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.015, 0.0, 0.0, 0.0, -4.985, -5.08, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2604, "number_of_timesteps": 46511, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1037, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1038.0, 1.0, 1.0, 1.0, 1038.0, 1038.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.014, 0.0, 0.0, 0.0, -4.984, -5.079, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2608, "number_of_timesteps": 46593, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 1038, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1039.0, 1.0, 1.0, 1.0, 1039.0, 1039.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.01, 0.0, 0.0, 0.0, -4.979, -5.074, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2613, "number_of_timesteps": 46665, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 1039, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1040.0, 1.0, 1.0, 1.0, 1040.0, 1040.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.033, 0.0, 0.0, 0.0, -5.001, -5.096, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2615, "number_of_timesteps": 46686, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1040, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1041.0, 1.0, 1.0, 1.0, 1041.0, 1041.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.033, 0.0, 0.0, 0.0, -4.996, -5.095, 0.0, 0.0, 0.0]}
{"step": 1041, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1042.0, 1.0, 1.0, 1.0, 1042.0, 1042.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.035, 0.0, 0.0, 0.0, -4.992, -5.095, 0.0, 0.0, 0.0]}
{"step": 1042, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1043.0, 1.0, 1.0, 1.0, 1043.0, 1043.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.041, 0.0, 0.0, 0.0, -4.987, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2625, "number_of_timesteps": 46822, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.3500000000000014},
{"step": 1043, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1044.0, 1.0, 1.0, 1.0, 1044.0, 1044.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.042, 0.0, 0.0, 0.0, -4.987, -5.095, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2628, "number_of_timesteps": 46860, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1044, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1045.0, 1.0, 1.0, 1.0, 1045.0, 1045.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.038, 0.0, 0.0, 0.0, -5.006, -5.115, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2631, "number_of_timesteps": 46897, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1045, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1046.0, 1.0, 1.0, 1.0, 1046.0, 1046.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.037, 0.0, 0.0, 0.0, -5.005, -5.113, 0.0, 0.0, 0.0]}
{"step": 1046, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1047.0, 1.0, 1.0, 1.0, 1047.0, 1047.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.039, 0.0, 0.0, 0.0, -5.006, -5.114, 0.0, 0.0, 0.0]}
{"step": 1047, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1048.0, 1.0, 1.0, 1.0, 1048.0, 1048.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.041, 0.0, 0.0, 0.0, -5.007, -5.109, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2635, "number_of_timesteps": 46954, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"step": 1048, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1049.0, 1.0, 1.0, 1.0, 1049.0, 1049.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.037, 0.0, 0.0, 0.0, -5.002, -5.104, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2642, "number_of_timesteps": 47100, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.3500000000000014},
{"step": 1049, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1050.0, 1.0, 1.0, 1.0, 1050.0, 1050.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.039, 0.0, 0.0, 0.0, -5.003, -5.1, 0.0, 0.0, 0.0]}
{"step": 1050, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1051.0, 1.0, 1.0, 1.0, 1051.0, 1051.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.04, 0.0, 0.0, 0.0, -5.003, -5.095, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2647, "number_of_timesteps": 47175, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"step": 1051, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1052.0, 1.0, 1.0, 1.0, 1052.0, 1052.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.037, 0.0, 0.0, 0.0, -4.999, -5.09, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2650, "number_of_timesteps": 47214, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.20000000000000107},
{"step": 1052, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1053.0, 1.0, 1.0, 1.0, 1053.0, 1053.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.038, 0.0, 0.0, 0.0, -4.999, -5.09, 0.0, 0.0, 0.0]}
{"step": 1053, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1054.0, 1.0, 1.0, 1.0, 1054.0, 1054.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.043, 0.0, 0.0, 0.0, -5.003, -5.094, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2654, "number_of_timesteps": 47277, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.1999999999999993},
{"step": 1054, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1055.0, 1.0, 1.0, 1.0, 1055.0, 1055.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.039, 0.0, 0.0, 0.0, -4.998, -5.089, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2658, "number_of_timesteps": 47338, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.1999999999999993},
{"step": 1055, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1056.0, 1.0, 1.0, 1.0, 1056.0, 1056.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.043, 0.0, 0.0, 0.0, -5.001, -5.092, 0.0, 0.0, 0.0]}
{"step": 1056, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1057.0, 1.0, 1.0, 1.0, 1057.0, 1057.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.039, 0.0, 0.0, 0.0, -4.996, -5.087, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2663, "number_of_timesteps": 47405, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.1999999999999993},
{"step": 1057, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1058.0, 1.0, 1.0, 1.0, 1058.0, 1058.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.04, 0.0, 0.0, 0.0, -4.996, -5.087, 0.0, 0.0, 0.0]}
{"step": 1058, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1059.0, 1.0, 1.0, 1.0, 1059.0, 1059.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.042, 0.0, 0.0, 0.0, -4.998, -5.088, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2668, "number_of_timesteps": 47511, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 1059, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1060.0, 1.0, 1.0, 1.0, 1060.0, 1060.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.038, 0.0, 0.0, 0.0, -4.993, -5.084, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2672, "number_of_timesteps": 47566, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1060, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1061.0, 1.0, 1.0, 1.0, 1061.0, 1061.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.035, 0.0, 0.0, 0.0, -4.988, -5.079, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2673, "number_of_timesteps": 47583, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1061, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1062.0, 1.0, 1.0, 1.0, 1062.0, 1062.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.047, 0.0, 0.0, 0.0, -4.999, -5.09, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2674, "number_of_timesteps": 47595, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1062, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1063.0, 1.0, 1.0, 1.0, 1063.0, 1063.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.043, 0.0, 0.0, 0.0, -4.995, -5.085, 0.0, 0.0, 0.0]}
{"step": 1063, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1064.0, 1.0, 1.0, 1.0, 1064.0, 1064.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.039, 0.0, 0.0, 0.0, -4.99, -5.08, 0.0, 0.0, 0.0]}
{"step": 1064, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1065.0, 1.0, 1.0, 1.0, 1065.0, 1065.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.035, 0.0, 0.0, 0.0, -4.985, -5.076, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2681, "number_of_timesteps": 47751, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 1065, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1066.0, 1.0, 1.0, 1.0, 1066.0, 1066.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.035, 0.0, 0.0, 0.0, -4.981, -5.074, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2686, "number_of_timesteps": 47839, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1066, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1067.0, 1.0, 1.0, 1.0, 1067.0, 1067.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.044, 0.0, 0.0, 0.0, -4.989, -5.083, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2688, "number_of_timesteps": 47876, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.20000000000000107},
{"step": 1067, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1068.0, 1.0, 1.0, 1.0, 1068.0, 1068.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.046, 0.0, 0.0, 0.0, -4.99, -5.084, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2690, "number_of_timesteps": 47897, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 1068, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1069.0, 1.0, 1.0, 1.0, 1069.0, 1069.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.048, 0.0, 0.0, 0.0, -4.991, -5.084, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2692, "number_of_timesteps": 47934, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.3500000000000014},
{"step": 1069, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1070.0, 1.0, 1.0, 1.0, 1070.0, 1070.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.051, 0.0, 0.0, 0.0, -4.993, -5.079, 0.0, 0.0, 0.0]}
{"step": 1070, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1071.0, 1.0, 1.0, 1.0, 1071.0, 1071.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.053, 0.0, 0.0, 0.0, -4.995, -5.075, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2699, "number_of_timesteps": 48070, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 1071, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1072.0, 1.0, 1.0, 1.0, 1072.0, 1072.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.05, 0.0, 0.0, 0.0, -4.99, -5.07, 0.0, 0.0, 0.0]}
{"step": 1072, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1073.0, 1.0, 1.0, 1.0, 1073.0, 1073.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.046, 0.0, 0.0, 0.0, -4.985, -5.065, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2703, "number_of_timesteps": 48132, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"step": 1073, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1074.0, 1.0, 1.0, 1.0, 1074.0, 1074.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.047, 0.0, 0.0, 0.0, -4.986, -5.066, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2707, "number_of_timesteps": 48199, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.20000000000000107},
{"step": 1074, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1075.0, 1.0, 1.0, 1.0, 1075.0, 1075.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.043, 0.0, 0.0, 0.0, -4.981, -5.061, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2709, "number_of_timesteps": 48227, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1075, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1076.0, 1.0, 1.0, 1.0, 1076.0, 1076.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.046, 0.0, 0.0, 0.0, -4.977, -5.062, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2711, "number_of_timesteps": 48262, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 1076, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1077.0, 1.0, 1.0, 1.0, 1077.0, 1077.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.042, 0.0, 0.0, 0.0, -4.986, -5.072, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2714, "number_of_timesteps": 48311, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 1077, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1078.0, 1.0, 1.0, 1.0, 1078.0, 1078.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.045, 0.0, 0.0, 0.0, -4.988, -5.073, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2716, "number_of_timesteps": 48340, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"step": 1078, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1079.0, 1.0, 1.0, 1.0, 1079.0, 1079.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.041, 0.0, 0.0, 0.0, -4.983, -5.069, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2718, "number_of_timesteps": 48368, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 1079, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1080.0, 1.0, 1.0, 1.0, 1080.0, 1080.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.037, 0.0, 0.0, 0.0, -4.978, -5.064, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2720, "number_of_timesteps": 48412, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.20000000000000107},
{"step": 1080, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1081.0, 1.0, 1.0, 1.0, 1081.0, 1081.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.035, 0.0, 0.0, 0.0, -4.975, -5.061, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2724, "number_of_timesteps": 48492, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1081, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1082.0, 1.0, 1.0, 1.0, 1082.0, 1082.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.045, 0.0, 0.0, 0.0, -4.984, -5.069, 0.0, 0.0, 0.0]}
{"step": 1082, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1083.0, 1.0, 1.0, 1.0, 1083.0, 1083.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.06, 0.0, 0.0, 0.0, -4.998, -5.084, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2728, "number_of_timesteps": 48564, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 1083, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1084.0, 1.0, 1.0, 1.0, 1084.0, 1084.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.061, 0.0, 0.0, 0.0, -4.998, -5.084, 0.0, 0.0, 0.0]}
{"step": 1084, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1085.0, 1.0, 1.0, 1.0, 1085.0, 1085.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.068, 0.0, 0.0, 0.0, -5.005, -5.09, 0.0, 0.0, 0.0]}
{"eval_score": 21.0, "number_of_episodes": 2732}
{"number_of_episodes": 2732, "number_of_timesteps": 48667, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 1085, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1086.0, 1.0, 1.0, 1.0, 1086.0, 1086.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.069, 0.0, 0.0, 0.0, -5.005, -5.09, 0.0, 0.0, 0.0]}
{"step": 1086, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1087.0, 1.0, 1.0, 1.0, 1087.0, 1087.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.07, 0.0, 0.0, 0.0, -5.005, -5.09, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2737, "number_of_timesteps": 48756, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.3500000000000014},
{"step": 1087, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1088.0, 1.0, 1.0, 1.0, 1088.0, 1088.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.072, 0.0, 0.0, 0.0, -5.006, -5.086, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2739, "number_of_timesteps": 48785, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.20000000000000107},
{"step": 1088, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1089.0, 1.0, 1.0, 1.0, 1089.0, 1089.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.068, 0.0, 0.0, 0.0, -5.001, -5.081, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2743, "number_of_timesteps": 48842, "per_episode_reward": 14.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"step": 1089, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1090.0, 1.0, 1.0, 1.0, 1090.0, 1090.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.069, 0.0, 0.0, 0.0, -4.997, -5.081, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2743, "number_of_timesteps": 48842, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1090, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1091.0, 1.0, 1.0, 1.0, 1091.0, 1091.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.065, 0.0, 0.0, 0.0, -5.008, -5.092, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2746, "number_of_timesteps": 48896, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 1091, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1092.0, 1.0, 1.0, 1.0, 1092.0, 1092.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.07, 0.0, 0.0, 0.0, -5.011, -5.095, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2748, "number_of_timesteps": 48947, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1092, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1093.0, 1.0, 1.0, 1.0, 1093.0, 1093.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.079, 0.0, 0.0, 0.0, -5.019, -5.104, 0.0, 0.0, 0.0]}
{"step": 1093, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1094.0, 1.0, 1.0, 1.0, 1094.0, 1094.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.093, 0.0, 0.0, 0.0, -5.032, -5.117, 0.0, 0.0, 0.0]}
{"step": 1094, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1095.0, 1.0, 1.0, 1.0, 1095.0, 1095.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.095, 0.0, 0.0, 0.0, -5.034, -5.118, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2756, "number_of_timesteps": 49117, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1095, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1096.0, 1.0, 1.0, 1.0, 1096.0, 1096.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.097, 0.0, 0.0, 0.0, -5.035, -5.119, 0.0, 0.0, 0.0]}
{"step": 1096, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1097.0, 1.0, 1.0, 1.0, 1097.0, 1097.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.099, 0.0, 0.0, 0.0, -5.036, -5.121, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2761, "number_of_timesteps": 49199, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.20000000000000107},
{"step": 1097, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1098.0, 1.0, 1.0, 1.0, 1098.0, 1098.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.096, 0.0, 0.0, 0.0, -5.032, -5.116, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2762, "number_of_timesteps": 49223, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1098, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1099.0, 1.0, 1.0, 1.0, 1099.0, 1099.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.096, 0.0, 0.0, 0.0, -5.027, -5.116, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2764, "number_of_timesteps": 49264, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1099, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1100.0, 1.0, 1.0, 1.0, 1100.0, 1100.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.093, 0.0, 0.0, 0.0, -5.023, -5.111, 0.0, 0.0, 0.0]}
{"step": 1100, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1101.0, 1.0, 1.0, 1.0, 1101.0, 1101.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.089, 0.0, 0.0, 0.0, -5.018, -5.106, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2769, "number_of_timesteps": 49379, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 1101, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1102.0, 1.0, 1.0, 1.0, 1102.0, 1102.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.087, 0.0, 0.0, 0.0, -5.016, -5.104, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2772, "number_of_timesteps": 49443, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 1102, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1103.0, 1.0, 1.0, 1.0, 1103.0, 1103.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.084, 0.0, 0.0, 0.0, -5.011, -5.099, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2775, "number_of_timesteps": 49497, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1103, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1104.0, 1.0, 1.0, 1.0, 1104.0, 1104.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.08, 0.0, 0.0, 0.0, -5.007, -5.095, 0.0, 0.0, 0.0]}
{"step": 1104, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1105.0, 1.0, 1.0, 1.0, 1105.0, 1105.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.076, 0.0, 0.0, 0.0, -5.002, -5.09, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2778, "number_of_timesteps": 49544, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1105, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1106.0, 1.0, 1.0, 1.0, 1106.0, 1106.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.079, 0.0, 0.0, 0.0, -5.004, -5.092, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2781, "number_of_timesteps": 49605, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.3500000000000014},
{"step": 1106, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1107.0, 1.0, 1.0, 1.0, 1107.0, 1107.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.081, 0.0, 0.0, 0.0, -5.005, -5.088, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2782, "number_of_timesteps": 49621, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1107, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1108.0, 1.0, 1.0, 1.0, 1108.0, 1108.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.1, 0.0, 0.0, 0.0, -5.023, -5.105, 0.0, 0.0, 0.0]}
{"step": 1108, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1109.0, 1.0, 1.0, 1.0, 1109.0, 1109.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.102, 0.0, 0.0, 0.0, -5.025, -5.101, 0.0, 0.0, 0.0]}
{"step": 1109, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1110.0, 1.0, 1.0, 1.0, 1110.0, 1110.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.111, 0.0, 0.0, 0.0, -5.033, -5.109, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2788, "number_of_timesteps": 49712, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1110, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1111.0, 1.0, 1.0, 1.0, 1111.0, 1111.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.112, 0.0, 0.0, 0.0, -5.033, -5.109, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2790, "number_of_timesteps": 49774, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1111, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1112.0, 1.0, 1.0, 1.0, 1112.0, 1112.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.108, 0.0, 0.0, 0.0, -5.029, -5.104, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2791, "number_of_timesteps": 49792, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1112, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1113.0, 1.0, 1.0, 1.0, 1113.0, 1113.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.111, 0.0, 0.0, 0.0, -5.024, -5.105, 0.0, 0.0, 0.0]}
{"step": 1113, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1114.0, 1.0, 1.0, 1.0, 1114.0, 1114.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.113, 0.0, 0.0, 0.0, -5.026, -5.107, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2794, "number_of_timesteps": 49905, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 1114, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1115.0, 1.0, 1.0, 1.0, 1115.0, 1115.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.114, 0.0, 0.0, 0.0, -5.026, -5.107, 0.0, 0.0, 0.0]}
{"step": 1115, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1116.0, 1.0, 1.0, 1.0, 1116.0, 1116.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.116, 0.0, 0.0, 0.0, -5.027, -5.108, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2800, "number_of_timesteps": 50087, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1116, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1117.0, 1.0, 1.0, 1.0, 1117.0, 1117.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.118, 0.0, 0.0, 0.0, -5.028, -5.103, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2803, "number_of_timesteps": 50125, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 1117, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1118.0, 1.0, 1.0, 1.0, 1118.0, 1118.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.114, 0.0, 0.0, 0.0, -5.023, -5.099, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2806, "number_of_timesteps": 50201, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1118, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1119.0, 1.0, 1.0, 1.0, 1119.0, 1119.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.115, 0.0, 0.0, 0.0, -5.019, -5.099, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2808, "number_of_timesteps": 50235, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 1119, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1120.0, 1.0, 1.0, 1.0, 1120.0, 1120.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.117, 0.0, 0.0, 0.0, -5.02, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2809, "number_of_timesteps": 50252, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 1120, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1121.0, 1.0, 1.0, 1.0, 1121.0, 1121.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.114, 0.0, 0.0, 0.0, -5.016, -5.096, 0.0, 0.0, 0.0]}
{"step": 1121, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1122.0, 1.0, 1.0, 1.0, 1122.0, 1122.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.115, 0.0, 0.0, 0.0, -5.017, -5.097, 0.0, 0.0, 0.0]}
{"step": 1122, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1123.0, 1.0, 1.0, 1.0, 1123.0, 1123.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.117, 0.0, 0.0, 0.0, -5.017, -5.097, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2819, "number_of_timesteps": 50433, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1123, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1124.0, 1.0, 1.0, 1.0, 1124.0, 1124.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.118, 0.0, 0.0, 0.0, -5.018, -5.097, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2820, "number_of_timesteps": 50444, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1124, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1125.0, 1.0, 1.0, 1.0, 1125.0, 1125.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.131, 0.0, 0.0, 0.0, -5.03, -5.109, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2822, "number_of_timesteps": 50471, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1125, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1126.0, 1.0, 1.0, 1.0, 1126.0, 1126.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.127, 0.0, 0.0, 0.0, -5.025, -5.105, 0.0, 0.0, 0.0]}
{"step": 1126, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1127.0, 1.0, 1.0, 1.0, 1127.0, 1127.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.123, 0.0, 0.0, 0.0, -5.021, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2826, "number_of_timesteps": 50555, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1127, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1128.0, 1.0, 1.0, 1.0, 1128.0, 1128.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.124, 0.0, 0.0, 0.0, -5.021, -5.096, 0.0, 0.0, 0.0]}
{"step": 1128, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1129.0, 1.0, 1.0, 1.0, 1129.0, 1129.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.136, 0.0, 0.0, 0.0, -5.031, -5.106, 0.0, 0.0, 0.0]}
{"step": 1129, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1130.0, 1.0, 1.0, 1.0, 1130.0, 1130.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.138, 0.0, 0.0, 0.0, -5.033, -5.102, 0.0, 0.0, 0.0]}
{"step": 1130, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1131.0, 1.0, 1.0, 1.0, 1131.0, 1131.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.139, 0.0, 0.0, 0.0, -5.034, -5.097, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2836, "number_of_timesteps": 50761, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1131, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1132.0, 1.0, 1.0, 1.0, 1132.0, 1132.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.156, 0.0, 0.0, 0.0, -5.05, -5.113, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2838, "number_of_timesteps": 50793, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1132, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1133.0, 1.0, 1.0, 1.0, 1133.0, 1133.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.152, 0.0, 0.0, 0.0, -5.045, -5.109, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2842, "number_of_timesteps": 50862, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 1133, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1134.0, 1.0, 1.0, 1.0, 1134.0, 1134.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.156, 0.0, 0.0, 0.0, -5.048, -5.111, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2843, "number_of_timesteps": 50878, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1134, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1135.0, 1.0, 1.0, 1.0, 1135.0, 1135.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.157, 0.0, 0.0, 0.0, -5.048, -5.112, 0.0, 0.0, 0.0]}
{"step": 1135, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1136.0, 1.0, 1.0, 1.0, 1136.0, 1136.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.153, 0.0, 0.0, 0.0, -5.044, -5.107, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2850, "number_of_timesteps": 50995, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1136, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1137.0, 1.0, 1.0, 1.0, 1137.0, 1137.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.156, 0.0, 0.0, 0.0, -5.045, -5.103, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2852, "number_of_timesteps": 51051, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.1999999999999993},
{"step": 1137, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1138.0, 1.0, 1.0, 1.0, 1138.0, 1138.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.153, 0.0, 0.0, 0.0, -5.042, -5.099, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2855, "number_of_timesteps": 51092, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1138, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1139.0, 1.0, 1.0, 1.0, 1139.0, 1139.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.15, 0.0, 0.0, 0.0, -5.038, -5.095, 0.0, 0.0, 0.0]}
{"step": 1139, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1140.0, 1.0, 1.0, 1.0, 1140.0, 1140.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.149, 0.0, 0.0, 0.0, -5.036, -5.094, 0.0, 0.0, 0.0]}
{"eval_score": 18.8, "number_of_episodes": 2863}
{"number_of_episodes": 2863, "number_of_timesteps": 51215, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1140, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1141.0, 1.0, 1.0, 1.0, 1141.0, 1141.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.151, 0.0, 0.0, 0.0, -5.037, -5.094, 0.0, 0.0, 0.0]}
{"step": 1141, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1142.0, 1.0, 1.0, 1.0, 1142.0, 1142.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.153, 0.0, 0.0, 0.0, -5.039, -5.096, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2865, "number_of_timesteps": 51242, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1142, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1143.0, 1.0, 1.0, 1.0, 1143.0, 1143.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.15, 0.0, 0.0, 0.0, -5.035, -5.092, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2867, "number_of_timesteps": 51267, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1143, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1144.0, 1.0, 1.0, 1.0, 1144.0, 1144.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.154, 0.0, 0.0, 0.0, -5.039, -5.096, 0.0, 0.0, 0.0]}
{"step": 1144, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1145.0, 1.0, 1.0, 1.0, 1145.0, 1145.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.151, 0.0, 0.0, 0.0, -5.034, -5.091, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2869, "number_of_timesteps": 51312, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1145, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1146.0, 1.0, 1.0, 1.0, 1146.0, 1146.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.147, 0.0, 0.0, 0.0, -5.03, -5.087, 0.0, 0.0, 0.0]}
{"step": 1146, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1147.0, 1.0, 1.0, 1.0, 1147.0, 1147.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.144, 0.0, 0.0, 0.0, -5.025, -5.082, 0.0, 0.0, 0.0]}
{"step": 1147, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1148.0, 1.0, 1.0, 1.0, 1148.0, 1148.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.14, 0.0, 0.0, 0.0, -5.021, -5.078, 0.0, 0.0, 0.0]}
{"step": 1148, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1149.0, 1.0, 1.0, 1.0, 1149.0, 1149.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.141, 0.0, 0.0, 0.0, -5.021, -5.078, 0.0, 0.0, 0.0]}
{"step": 1149, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1150.0, 1.0, 1.0, 1.0, 1150.0, 1150.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.137, 0.0, 0.0, 0.0, -5.017, -5.074, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2880, "number_of_timesteps": 51580, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1150, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1151.0, 1.0, 1.0, 1.0, 1151.0, 1151.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.134, 0.0, 0.0, 0.0, -5.013, -5.069, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2882, "number_of_timesteps": 51624, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 1151, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1152.0, 1.0, 1.0, 1.0, 1152.0, 1152.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.13, 0.0, 0.0, 0.0, -5.022, -5.079, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2886, "number_of_timesteps": 51682, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1152, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1153.0, 1.0, 1.0, 1.0, 1153.0, 1153.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.132, 0.0, 0.0, 0.0, -5.018, -5.08, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2887, "number_of_timesteps": 51705, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1153, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1154.0, 1.0, 1.0, 1.0, 1154.0, 1154.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.129, 0.0, 0.0, 0.0, -5.014, -5.076, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2890, "number_of_timesteps": 51758, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1154, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1155.0, 1.0, 1.0, 1.0, 1155.0, 1155.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.125, 0.0, 0.0, 0.0, -5.009, -5.072, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2891, "number_of_timesteps": 51773, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1155, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1156.0, 1.0, 1.0, 1.0, 1156.0, 1156.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.127, 0.0, 0.0, 0.0, -5.01, -5.072, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2895, "number_of_timesteps": 51913, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1156, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1157.0, 1.0, 1.0, 1.0, 1157.0, 1157.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.123, 0.0, 0.0, 0.0, -5.019, -5.081, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2896, "number_of_timesteps": 51927, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1157, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1158.0, 1.0, 1.0, 1.0, 1158.0, 1158.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.126, 0.0, 0.0, 0.0, -5.021, -5.077, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2898, "number_of_timesteps": 51971, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1158, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1159.0, 1.0, 1.0, 1.0, 1159.0, 1159.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.137, 0.0, 0.0, 0.0, -5.031, -5.087, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2901, "number_of_timesteps": 52025, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1159, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1160.0, 1.0, 1.0, 1.0, 1160.0, 1160.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.138, 0.0, 0.0, 0.0, -5.027, -5.087, 0.0, 0.0, 0.0]}
{"step": 1160, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1161.0, 1.0, 1.0, 1.0, 1161.0, 1161.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.143, 0.0, 0.0, 0.0, -5.031, -5.092, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2907, "number_of_timesteps": 52148, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1161, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1162.0, 1.0, 1.0, 1.0, 1162.0, 1162.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.144, 0.0, 0.0, 0.0, -5.032, -5.087, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2909, "number_of_timesteps": 52170, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1162, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1163.0, 1.0, 1.0, 1.0, 1163.0, 1163.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.147, 0.0, 0.0, 0.0, -5.034, -5.09, 0.0, 0.0, 0.0]}
{"step": 1163, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1164.0, 1.0, 1.0, 1.0, 1164.0, 1164.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.148, 0.0, 0.0, 0.0, -5.035, -5.085, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2914, "number_of_timesteps": 52244, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1164, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1165.0, 1.0, 1.0, 1.0, 1165.0, 1165.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.145, 0.0, 0.0, 0.0, -5.03, -5.081, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2918, "number_of_timesteps": 52312, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 1165, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1166.0, 1.0, 1.0, 1.0, 1166.0, 1166.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.141, 0.0, 0.0, 0.0, -5.036, -5.086, 0.0, 0.0, 0.0]}
{"step": 1166, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1167.0, 1.0, 1.0, 1.0, 1167.0, 1167.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.138, 0.0, 0.0, 0.0, -5.045, -5.096, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2921, "number_of_timesteps": 52370, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1167, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1168.0, 1.0, 1.0, 1.0, 1168.0, 1168.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.14, 0.0, 0.0, 0.0, -5.047, -5.097, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2922, "number_of_timesteps": 52384, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1168, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1169.0, 1.0, 1.0, 1.0, 1169.0, 1169.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.141, 0.0, 0.0, 0.0, -5.042, -5.098, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2924, "number_of_timesteps": 52409, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1169, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1170.0, 1.0, 1.0, 1.0, 1170.0, 1170.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.144, 0.0, 0.0, 0.0, -5.045, -5.094, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2928, "number_of_timesteps": 52502, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1170, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1171.0, 1.0, 1.0, 1.0, 1171.0, 1171.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.141, 0.0, 0.0, 0.0, -5.04, -5.089, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2930, "number_of_timesteps": 52572, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1171, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1172.0, 1.0, 1.0, 1.0, 1172.0, 1172.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.142, 0.0, 0.0, 0.0, -5.041, -5.089, 0.0, 0.0, 0.0]}
{"step": 1172, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1173.0, 1.0, 1.0, 1.0, 1173.0, 1173.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.138, 0.0, 0.0, 0.0, -5.036, -5.085, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2932, "number_of_timesteps": 52610, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1173, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1174.0, 1.0, 1.0, 1.0, 1174.0, 1174.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.14, 0.0, 0.0, 0.0, -5.038, -5.087, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2935, "number_of_timesteps": 52657, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1174, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1175.0, 1.0, 1.0, 1.0, 1175.0, 1175.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.149, 0.0, 0.0, 0.0, -5.046, -5.094, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2938, "number_of_timesteps": 52724, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.15000000000000036},
{"step": 1175, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1176.0, 1.0, 1.0, 1.0, 1176.0, 1176.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.146, 0.0, 0.0, 0.0, -5.057, -5.105, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2939, "number_of_timesteps": 52776, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1176, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1177.0, 1.0, 1.0, 1.0, 1177.0, 1177.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.149, 0.0, 0.0, 0.0, -5.06, -5.101, 0.0, 0.0, 0.0]}
{"step": 1177, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1178.0, 1.0, 1.0, 1.0, 1178.0, 1178.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.146, 0.0, 0.0, 0.0, -5.067, -5.108, 0.0, 0.0, 0.0]}
{"step": 1178, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1179.0, 1.0, 1.0, 1.0, 1179.0, 1179.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.146, 0.0, 0.0, 0.0, -5.066, -5.104, 0.0, 0.0, 0.0]}
{"step": 1179, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1180.0, 1.0, 1.0, 1.0, 1180.0, 1180.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.147, 0.0, 0.0, 0.0, -5.066, -5.099, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2949, "number_of_timesteps": 52980, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1180, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1181.0, 1.0, 1.0, 1.0, 1181.0, 1181.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.152, 0.0, 0.0, 0.0, -5.071, -5.104, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2952, "number_of_timesteps": 53030, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1181, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1182.0, 1.0, 1.0, 1.0, 1182.0, 1182.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.149, 0.0, 0.0, 0.0, -5.067, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2954, "number_of_timesteps": 53068, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1182, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1183.0, 1.0, 1.0, 1.0, 1183.0, 1183.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.145, 0.0, 0.0, 0.0, -5.062, -5.095, 0.0, 0.0, 0.0]}
{"step": 1183, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1184.0, 1.0, 1.0, 1.0, 1184.0, 1184.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.142, 0.0, 0.0, 0.0, -5.058, -5.091, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2961, "number_of_timesteps": 53183, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1184, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1185.0, 1.0, 1.0, 1.0, 1185.0, 1185.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.151, 0.0, 0.0, 0.0, -5.066, -5.099, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2963, "number_of_timesteps": 53207, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1185, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1186.0, 1.0, 1.0, 1.0, 1186.0, 1186.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.147, 0.0, 0.0, 0.0, -5.072, -5.105, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2965, "number_of_timesteps": 53233, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1186, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1187.0, 1.0, 1.0, 1.0, 1187.0, 1187.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.147, 0.0, 0.0, 0.0, -5.071, -5.104, 0.0, 0.0, 0.0]}
{"step": 1187, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1188.0, 1.0, 1.0, 1.0, 1188.0, 1188.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.148, 0.0, 0.0, 0.0, -5.071, -5.104, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2971, "number_of_timesteps": 53348, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1188, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1189.0, 1.0, 1.0, 1.0, 1189.0, 1189.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.144, 0.0, 0.0, 0.0, -5.067, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2974, "number_of_timesteps": 53391, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1189, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1190.0, 1.0, 1.0, 1.0, 1190.0, 1190.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.141, 0.0, 0.0, 0.0, -5.062, -5.095, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2975, "number_of_timesteps": 53411, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1190, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1191.0, 1.0, 1.0, 1.0, 1191.0, 1191.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.149, 0.0, 0.0, 0.0, -5.07, -5.103, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2977, "number_of_timesteps": 53451, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1191, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1192.0, 1.0, 1.0, 1.0, 1192.0, 1192.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.149, 0.0, 0.0, 0.0, -5.07, -5.102, 0.0, 0.0, 0.0]}
{"step": 1192, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1193.0, 1.0, 1.0, 1.0, 1193.0, 1193.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.146, 0.0, 0.0, 0.0, -5.065, -5.098, 0.0, 0.0, 0.0]}
{"step": 1193, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1194.0, 1.0, 1.0, 1.0, 1194.0, 1194.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.143, 0.0, 0.0, 0.0, -5.061, -5.094, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2984, "number_of_timesteps": 53576, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1194, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1195.0, 1.0, 1.0, 1.0, 1195.0, 1195.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.144, 0.0, 0.0, 0.0, -5.062, -5.094, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2986, "number_of_timesteps": 53623, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1195, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1196.0, 1.0, 1.0, 1.0, 1196.0, 1196.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.144, 0.0, 0.0, 0.0, -5.061, -5.09, 0.0, 0.0, 0.0]}
{"step": 1196, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1197.0, 1.0, 1.0, 1.0, 1197.0, 1197.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.145, 0.0, 0.0, 0.0, -5.061, -5.086, 0.0, 0.0, 0.0]}
{"eval_score": 18.5, "number_of_episodes": 2991}
{"number_of_episodes": 2991, "number_of_timesteps": 53722, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1197, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1198.0, 1.0, 1.0, 1.0, 1198.0, 1198.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.145, 0.0, 0.0, 0.0, -5.061, -5.086, 0.0, 0.0, 0.0]}
{"step": 1198, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1199.0, 1.0, 1.0, 1.0, 1199.0, 1199.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.147, 0.0, 0.0, 0.0, -5.062, -5.081, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2994, "number_of_timesteps": 53810, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1199, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1200.0, 1.0, 1.0, 1.0, 1200.0, 1200.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.144, 0.0, 0.0, 0.0, -5.069, -5.088, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2997, "number_of_timesteps": 53870, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1200, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1201.0, 1.0, 1.0, 1.0, 1201.0, 1201.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.143, 0.0, 0.0, 0.0, -5.067, -5.087, 0.0, 0.0, 0.0]}
{"number_of_episodes": 2999, "number_of_timesteps": 53916, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1201, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1202.0, 1.0, 1.0, 1.0, 1202.0, 1202.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.145, 0.0, 0.0, 0.0, -5.063, -5.088, 0.0, 0.0, 0.0]}
{"step": 1202, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1203.0, 1.0, 1.0, 1.0, 1203.0, 1203.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.141, 0.0, 0.0, 0.0, -5.059, -5.084, 0.0, 0.0, 0.0]}
{"step": 1203, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1204.0, 1.0, 1.0, 1.0, 1204.0, 1204.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.142, 0.0, 0.0, 0.0, -5.055, -5.084, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3007, "number_of_timesteps": 54063, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1204, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1205.0, 1.0, 1.0, 1.0, 1205.0, 1205.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.144, 0.0, 0.0, 0.0, -5.056, -5.085, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3009, "number_of_timesteps": 54098, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1205, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1206.0, 1.0, 1.0, 1.0, 1206.0, 1206.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.146, 0.0, 0.0, 0.0, -5.057, -5.086, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3010, "number_of_timesteps": 54112, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1206, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1207.0, 1.0, 1.0, 1.0, 1207.0, 1207.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.147, 0.0, 0.0, 0.0, -5.057, -5.086, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3012, "number_of_timesteps": 54153, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1207, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1208.0, 1.0, 1.0, 1.0, 1208.0, 1208.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.143, 0.0, 0.0, 0.0, -5.068, -5.097, 0.0, 0.0, 0.0]}
{"step": 1208, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1209.0, 1.0, 1.0, 1.0, 1209.0, 1209.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.144, 0.0, 0.0, 0.0, -5.068, -5.097, 0.0, 0.0, 0.0]}
{"step": 1209, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1210.0, 1.0, 1.0, 1.0, 1210.0, 1210.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.141, 0.0, 0.0, 0.0, -5.073, -5.102, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3021, "number_of_timesteps": 54350, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1210, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1211.0, 1.0, 1.0, 1.0, 1211.0, 1211.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.141, 0.0, 0.0, 0.0, -5.069, -5.101, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3024, "number_of_timesteps": 54406, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1211, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1212.0, 1.0, 1.0, 1.0, 1212.0, 1212.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.142, 0.0, 0.0, 0.0, -5.069, -5.101, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3026, "number_of_timesteps": 54433, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1212, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1213.0, 1.0, 1.0, 1.0, 1213.0, 1213.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.138, 0.0, 0.0, 0.0, -5.065, -5.097, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3028, "number_of_timesteps": 54472, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1213, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1214.0, 1.0, 1.0, 1.0, 1214.0, 1214.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.135, 0.0, 0.0, 0.0, -5.06, -5.093, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3030, "number_of_timesteps": 54508, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1214, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1215.0, 1.0, 1.0, 1.0, 1215.0, 1215.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.145, 0.0, 0.0, 0.0, -5.07, -5.102, 0.0, 0.0, 0.0]}
{"step": 1215, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1216.0, 1.0, 1.0, 1.0, 1216.0, 1216.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.157, 0.0, 0.0, 0.0, -5.081, -5.113, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3036, "number_of_timesteps": 54618, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1216, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1217.0, 1.0, 1.0, 1.0, 1217.0, 1217.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.158, 0.0, 0.0, 0.0, -5.081, -5.113, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3038, "number_of_timesteps": 54660, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1217, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1218.0, 1.0, 1.0, 1.0, 1218.0, 1218.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.159, 0.0, 0.0, 0.0, -5.082, -5.109, 0.0, 0.0, 0.0]}
{"step": 1218, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1219.0, 1.0, 1.0, 1.0, 1219.0, 1219.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.16, 0.0, 0.0, 0.0, -5.082, -5.109, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3042, "number_of_timesteps": 54722, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1219, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1220.0, 1.0, 1.0, 1.0, 1220.0, 1220.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.16, 0.0, 0.0, 0.0, -5.082, -5.109, 0.0, 0.0, 0.0]}
{"step": 1220, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1221.0, 1.0, 1.0, 1.0, 1221.0, 1221.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.162, 0.0, 0.0, 0.0, -5.082, -5.11, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3046, "number_of_timesteps": 54790, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1221, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1222.0, 1.0, 1.0, 1.0, 1222.0, 1222.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.159, 0.0, 0.0, 0.0, -5.078, -5.105, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3049, "number_of_timesteps": 54847, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1222, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1223.0, 1.0, 1.0, 1.0, 1223.0, 1223.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.16, 0.0, 0.0, 0.0, -5.078, -5.105, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3052, "number_of_timesteps": 54919, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1223, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1224.0, 1.0, 1.0, 1.0, 1224.0, 1224.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.16, 0.0, 0.0, 0.0, -5.074, -5.105, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3055, "number_of_timesteps": 55005, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1224, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1225.0, 1.0, 1.0, 1.0, 1225.0, 1225.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.168, 0.0, 0.0, 0.0, -5.081, -5.112, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3057, "number_of_timesteps": 55031, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1225, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1226.0, 1.0, 1.0, 1.0, 1226.0, 1226.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.165, 0.0, 0.0, 0.0, -5.077, -5.108, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3059, "number_of_timesteps": 55062, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1226, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1227.0, 1.0, 1.0, 1.0, 1227.0, 1227.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.161, 0.0, 0.0, 0.0, -5.073, -5.104, 0.0, 0.0, 0.0]}
{"step": 1227, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1228.0, 1.0, 1.0, 1.0, 1228.0, 1228.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.158, 0.0, 0.0, 0.0, -5.069, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3062, "number_of_timesteps": 55127, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1228, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1229.0, 1.0, 1.0, 1.0, 1229.0, 1229.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.159, 0.0, 0.0, 0.0, -5.07, -5.101, 0.0, 0.0, 0.0]}
{"step": 1229, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1230.0, 1.0, 1.0, 1.0, 1230.0, 1230.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.156, 0.0, 0.0, 0.0, -5.066, -5.096, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3065, "number_of_timesteps": 55186, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1230, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1231.0, 1.0, 1.0, 1.0, 1231.0, 1231.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.157, 0.0, 0.0, 0.0, -5.066, -5.097, 0.0, 0.0, 0.0]}
{"step": 1231, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1232.0, 1.0, 1.0, 1.0, 1232.0, 1232.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.159, 0.0, 0.0, 0.0, -5.067, -5.098, 0.0, 0.0, 0.0]}
{"step": 1232, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1233.0, 1.0, 1.0, 1.0, 1233.0, 1233.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.161, 0.0, 0.0, 0.0, -5.068, -5.099, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3075, "number_of_timesteps": 55420, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1233, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1234.0, 1.0, 1.0, 1.0, 1234.0, 1234.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.157, 0.0, 0.0, 0.0, -5.064, -5.095, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3077, "number_of_timesteps": 55450, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 1234, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1235.0, 1.0, 1.0, 1.0, 1235.0, 1235.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.157, 0.0, 0.0, 0.0, -5.064, -5.094, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3077, "number_of_timesteps": 55450, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1235, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1236.0, 1.0, 1.0, 1.0, 1236.0, 1236.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.157, 0.0, 0.0, 0.0, -5.063, -5.09, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3081, "number_of_timesteps": 55504, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1236, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1237.0, 1.0, 1.0, 1.0, 1237.0, 1237.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.155, 0.0, 0.0, 0.0, -5.059, -5.086, 0.0, 0.0, 0.0]}
{"step": 1237, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1238.0, 1.0, 1.0, 1.0, 1238.0, 1238.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.157, 0.0, 0.0, 0.0, -5.06, -5.082, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3088, "number_of_timesteps": 55636, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1238, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1239.0, 1.0, 1.0, 1.0, 1239.0, 1239.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.158, 0.0, 0.0, 0.0, -5.061, -5.083, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3089, "number_of_timesteps": 55647, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1239, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1240.0, 1.0, 1.0, 1.0, 1240.0, 1240.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.16, 0.0, 0.0, 0.0, -5.062, -5.085, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3093, "number_of_timesteps": 55696, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1240, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1241.0, 1.0, 1.0, 1.0, 1241.0, 1241.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.157, 0.0, 0.0, 0.0, -5.058, -5.081, 0.0, 0.0, 0.0]}
{"step": 1241, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1242.0, 1.0, 1.0, 1.0, 1242.0, 1242.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.157, 0.0, 0.0, 0.0, -5.058, -5.08, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3096, "number_of_timesteps": 55746, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
{"step": 1242, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1243.0, 1.0, 1.0, 1.0, 1243.0, 1243.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.159, 0.0, 0.0, 0.0, -5.058, -5.081, 0.0, 0.0, 0.0]}
{"step": 1243, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1244.0, 1.0, 1.0, 1.0, 1244.0, 1244.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.158, 0.0, 0.0, 0.0, -5.057, -5.079, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3101, "number_of_timesteps": 55853, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1244, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1245.0, 1.0, 1.0, 1.0, 1245.0, 1245.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.161, 0.0, 0.0, 0.0, -5.059, -5.082, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3101, "number_of_timesteps": 55853, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1245, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1246.0, 1.0, 1.0, 1.0, 1246.0, 1246.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.163, 0.0, 0.0, 0.0, -5.061, -5.083, 0.0, 0.0, 0.0]}
{"step": 1246, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1247.0, 1.0, 1.0, 1.0, 1247.0, 1247.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.16, 0.0, 0.0, 0.0, -5.057, -5.079, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3107, "number_of_timesteps": 55998, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1247, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1248.0, 1.0, 1.0, 1.0, 1248.0, 1248.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.157, 0.0, 0.0, 0.0, -5.053, -5.075, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3108, "number_of_timesteps": 56014, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1248, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1249.0, 1.0, 1.0, 1.0, 1249.0, 1249.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.154, 0.0, 0.0, 0.0, -5.062, -5.084, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3110, "number_of_timesteps": 56091, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1249, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1250.0, 1.0, 1.0, 1.0, 1250.0, 1250.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.15, 0.0, 0.0, 0.0, -5.058, -5.08, 0.0, 0.0, 0.0]}
{"step": 1250, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1251.0, 1.0, 1.0, 1.0, 1251.0, 1251.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.147, 0.0, 0.0, 0.0, -5.066, -5.088, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3115, "number_of_timesteps": 56185, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1251, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1252.0, 1.0, 1.0, 1.0, 1252.0, 1252.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.148, 0.0, 0.0, 0.0, -5.066, -5.084, 0.0, 0.0, 0.0]}
{"step": 1252, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1253.0, 1.0, 1.0, 1.0, 1253.0, 1253.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.149, 0.0, 0.0, 0.0, -5.066, -5.08, 0.0, 0.0, 0.0]}
{"eval_score": 21.5, "number_of_episodes": 3120}
{"number_of_episodes": 3120, "number_of_timesteps": 56280, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1253, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1254.0, 1.0, 1.0, 1.0, 1254.0, 1254.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.151, 0.0, 0.0, 0.0, -5.067, -5.081, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3120, "number_of_timesteps": 56280, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1254, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1255.0, 1.0, 1.0, 1.0, 1255.0, 1255.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.148, 0.0, 0.0, 0.0, -5.063, -5.077, 0.0, 0.0, 0.0]}
{"step": 1255, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1256.0, 1.0, 1.0, 1.0, 1256.0, 1256.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.146, 0.0, 0.0, 0.0, -5.061, -5.074, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3128, "number_of_timesteps": 56430, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"step": 1256, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1257.0, 1.0, 1.0, 1.0, 1257.0, 1257.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.143, 0.0, 0.0, 0.0, -5.065, -5.079, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3129, "number_of_timesteps": 56451, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 1257, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1258.0, 1.0, 1.0, 1.0, 1258.0, 1258.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.145, 0.0, 0.0, 0.0, -5.067, -5.075, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3129, "number_of_timesteps": 56451, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1258, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1259.0, 1.0, 1.0, 1.0, 1259.0, 1259.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.152, 0.0, 0.0, 0.0, -5.073, -5.082, 0.0, 0.0, 0.0]}
{"step": 1259, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1260.0, 1.0, 1.0, 1.0, 1260.0, 1260.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.154, 0.0, 0.0, 0.0, -5.074, -5.078, 0.0, 0.0, 0.0]}
{"step": 1260, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1261.0, 1.0, 1.0, 1.0, 1261.0, 1261.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.15, 0.0, 0.0, 0.0, -5.086, -5.09, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3135, "number_of_timesteps": 56570, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"step": 1261, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1262.0, 1.0, 1.0, 1.0, 1262.0, 1262.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.155, 0.0, 0.0, 0.0, -5.09, -5.093, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3137, "number_of_timesteps": 56606, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1262, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1263.0, 1.0, 1.0, 1.0, 1263.0, 1263.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.159, 0.0, 0.0, 0.0, -5.093, -5.097, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3139, "number_of_timesteps": 56659, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 1263, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1264.0, 1.0, 1.0, 1.0, 1264.0, 1264.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.156, 0.0, 0.0, 0.0, -5.089, -5.094, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3143, "number_of_timesteps": 56774, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1264, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1265.0, 1.0, 1.0, 1.0, 1265.0, 1265.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.164, 0.0, 0.0, 0.0, -5.096, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3145, "number_of_timesteps": 56800, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1265, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1266.0, 1.0, 1.0, 1.0, 1266.0, 1266.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.161, 0.0, 0.0, 0.0, -5.092, -5.096, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3147, "number_of_timesteps": 56849, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"step": 1266, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1267.0, 1.0, 1.0, 1.0, 1267.0, 1267.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.161, 0.0, 0.0, 0.0, -5.092, -5.096, 0.0, 0.0, 0.0]}
{"step": 1267, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1268.0, 1.0, 1.0, 1.0, 1268.0, 1268.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.158, 0.0, 0.0, 0.0, -5.088, -5.092, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3154, "number_of_timesteps": 56977, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 1268, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1269.0, 1.0, 1.0, 1.0, 1269.0, 1269.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.159, 0.0, 0.0, 0.0, -5.089, -5.088, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3155, "number_of_timesteps": 57001, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1269, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1270.0, 1.0, 1.0, 1.0, 1270.0, 1270.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.156, 0.0, 0.0, 0.0, -5.084, -5.084, 0.0, 0.0, 0.0]}
{"step": 1270, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1271.0, 1.0, 1.0, 1.0, 1271.0, 1271.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.153, 0.0, 0.0, 0.0, -5.08, -5.08, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3160, "number_of_timesteps": 57089, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1271, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1272.0, 1.0, 1.0, 1.0, 1272.0, 1272.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.15, 0.0, 0.0, 0.0, -5.091, -5.091, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3163, "number_of_timesteps": 57142, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 1272, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1273.0, 1.0, 1.0, 1.0, 1273.0, 1273.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.151, 0.0, 0.0, 0.0, -5.092, -5.091, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3164, "number_of_timesteps": 57177, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"step": 1273, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1274.0, 1.0, 1.0, 1.0, 1274.0, 1274.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.152, 0.0, 0.0, 0.0, -5.092, -5.092, 0.0, 0.0, 0.0]}
{"step": 1274, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1275.0, 1.0, 1.0, 1.0, 1275.0, 1275.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.155, 0.0, 0.0, 0.0, -5.095, -5.094, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3170, "number_of_timesteps": 57273, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1275, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1276.0, 1.0, 1.0, 1.0, 1276.0, 1276.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.158, 0.0, 0.0, 0.0, -5.096, -5.096, 0.0, 0.0, 0.0]}
{"step": 1276, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1277.0, 1.0, 1.0, 1.0, 1277.0, 1277.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.159, 0.0, 0.0, 0.0, -5.097, -5.097, 0.0, 0.0, 0.0]}
{"step": 1277, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1278.0, 1.0, 1.0, 1.0, 1278.0, 1278.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.161, 0.0, 0.0, 0.0, -5.098, -5.098, 0.0, 0.0, 0.0]}
{"step": 1278, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1279.0, 1.0, 1.0, 1.0, 1279.0, 1279.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.162, 0.0, 0.0, 0.0, -5.099, -5.098, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3179, "number_of_timesteps": 57455, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
{"step": 1279, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1280.0, 1.0, 1.0, 1.0, 1280.0, 1280.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.165, 0.0, 0.0, 0.0, -5.101, -5.1, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3182, "number_of_timesteps": 57502, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1280, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1281.0, 1.0, 1.0, 1.0, 1281.0, 1281.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.161, 0.0, 0.0, 0.0, -5.106, -5.106, 0.0, 0.0, 0.0]}
{"step": 1281, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1282.0, 1.0, 1.0, 1.0, 1282.0, 1282.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.158, 0.0, 0.0, 0.0, -5.114, -5.113, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3188, "number_of_timesteps": 57598, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 1282, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1283.0, 1.0, 1.0, 1.0, 1283.0, 1283.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.159, 0.0, 0.0, 0.0, -5.114, -5.109, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3189, "number_of_timesteps": 57615, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"step": 1283, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1284.0, 1.0, 1.0, 1.0, 1284.0, 1284.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.16, 0.0, 0.0, 0.0, -5.114, -5.109, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3191, "number_of_timesteps": 57647, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 1284, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1285.0, 1.0, 1.0, 1.0, 1285.0, 1285.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.162, 0.0, 0.0, 0.0, -5.11, -5.11, 0.0, 0.0, 0.0]}
{"step": 1285, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1286.0, 1.0, 1.0, 1.0, 1286.0, 1286.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.163, 0.0, 0.0, 0.0, -5.111, -5.11, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3196, "number_of_timesteps": 57762, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.25},
{"step": 1286, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1287.0, 1.0, 1.0, 1.0, 1287.0, 1287.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.16, 0.0, 0.0, 0.0, -5.107, -5.106, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3198, "number_of_timesteps": 57801, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.1999999999999993},
{"step": 1287, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1288.0, 1.0, 1.0, 1.0, 1288.0, 1288.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.162, 0.0, 0.0, 0.0, -5.108, -5.108, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3202, "number_of_timesteps": 57881, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1288, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1289.0, 1.0, 1.0, 1.0, 1289.0, 1289.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.159, 0.0, 0.0, 0.0, -5.115, -5.114, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3203, "number_of_timesteps": 57898, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"step": 1289, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1290.0, 1.0, 1.0, 1.0, 1290.0, 1290.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.16, 0.0, 0.0, 0.0, -5.115, -5.11, 0.0, 0.0, 0.0]}
{"step": 1290, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1291.0, 1.0, 1.0, 1.0, 1291.0, 1291.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.161, 0.0, 0.0, 0.0, -5.116, -5.106, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3208, "number_of_timesteps": 57985, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1291, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1292.0, 1.0, 1.0, 1.0, 1292.0, 1292.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.169, 0.0, 0.0, 0.0, -5.122, -5.113, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3212, "number_of_timesteps": 58045, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 1292, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1293.0, 1.0, 1.0, 1.0, 1293.0, 1293.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.165, 0.0, 0.0, 0.0, -5.132, -5.123, 0.0, 0.0, 0.0]}
{"step": 1293, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1294.0, 1.0, 1.0, 1.0, 1294.0, 1294.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.162, 0.0, 0.0, 0.0, -5.132, -5.123, 0.0, 0.0, 0.0]}
{"step": 1294, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1295.0, 1.0, 1.0, 1.0, 1295.0, 1295.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.159, 0.0, 0.0, 0.0, -5.142, -5.133, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3219, "number_of_timesteps": 58175, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1295, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1296.0, 1.0, 1.0, 1.0, 1296.0, 1296.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.156, 0.0, 0.0, 0.0, -5.138, -5.129, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3222, "number_of_timesteps": 58228, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 1296, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1297.0, 1.0, 1.0, 1.0, 1297.0, 1297.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.16, 0.0, 0.0, 0.0, -5.134, -5.133, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3225, "number_of_timesteps": 58268, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 1297, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1298.0, 1.0, 1.0, 1.0, 1298.0, 1298.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.157, 0.0, 0.0, 0.0, -5.14, -5.139, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3227, "number_of_timesteps": 58294, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 1298, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1299.0, 1.0, 1.0, 1.0, 1299.0, 1299.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.166, 0.0, 0.0, 0.0, -5.147, -5.146, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3230, "number_of_timesteps": 58346, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 1299, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1300.0, 1.0, 1.0, 1.0, 1300.0, 1300.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.167, 0.0, 0.0, 0.0, -5.148, -5.147, 0.0, 0.0, 0.0]}
{"step": 1300, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1301.0, 1.0, 1.0, 1.0, 1301.0, 1301.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.164, 0.0, 0.0, 0.0, -5.154, -5.153, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3236, "number_of_timesteps": 58441, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1301, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1302.0, 1.0, 1.0, 1.0, 1302.0, 1302.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.16, 0.0, 0.0, 0.0, -5.15, -5.149, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3238, "number_of_timesteps": 58472, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"step": 1302, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1303.0, 1.0, 1.0, 1.0, 1303.0, 1303.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.163, 0.0, 0.0, 0.0, -5.152, -5.145, 0.0, 0.0, 0.0]}
{"step": 1303, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1304.0, 1.0, 1.0, 1.0, 1304.0, 1304.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.165, 0.0, 0.0, 0.0, -5.154, -5.141, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3245, "number_of_timesteps": 58570, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1304, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1305.0, 1.0, 1.0, 1.0, 1305.0, 1305.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.167, 0.0, 0.0, 0.0, -5.154, -5.142, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3247, "number_of_timesteps": 58597, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1305, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1306.0, 1.0, 1.0, 1.0, 1306.0, 1306.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.175, 0.0, 0.0, 0.0, -5.162, -5.15, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3248, "number_of_timesteps": 58610, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"step": 1306, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1307.0, 1.0, 1.0, 1.0, 1307.0, 1307.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.178, 0.0, 0.0, 0.0, -5.164, -5.146, 0.0, 0.0, 0.0]}
{"eval_score": 17.2, "number_of_episodes": 3253}
{"number_of_episodes": 3253, "number_of_timesteps": 58693, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.25},
{"step": 1307, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1308.0, 1.0, 1.0, 1.0, 1308.0, 1308.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.175, 0.0, 0.0, 0.0, -5.161, -5.142, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3256, "number_of_timesteps": 58756, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 1308, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1309.0, 1.0, 1.0, 1.0, 1309.0, 1309.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.172, 0.0, 0.0, 0.0, -5.17, -5.151, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3257, "number_of_timesteps": 58772, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 1309, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1310.0, 1.0, 1.0, 1.0, 1310.0, 1310.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.171, 0.0, 0.0, 0.0, -5.168, -5.15, 0.0, 0.0, 0.0]}
{"step": 1310, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1311.0, 1.0, 1.0, 1.0, 1311.0, 1311.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.178, 0.0, 0.0, 0.0, -5.175, -5.156, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3263, "number_of_timesteps": 58860, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 1311, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1312.0, 1.0, 1.0, 1.0, 1312.0, 1312.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.179, 0.0, 0.0, 0.0, -5.171, -5.156, 0.0, 0.0, 0.0]}
{"step": 1312, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1313.0, 1.0, 1.0, 1.0, 1313.0, 1313.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.179, 0.0, 0.0, 0.0, -5.17, -5.156, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3268, "number_of_timesteps": 58941, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1313, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1314.0, 1.0, 1.0, 1.0, 1314.0, 1314.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.176, 0.0, 0.0, 0.0, -5.166, -5.152, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3270, "number_of_timesteps": 58998, "per_episode_reward": 15.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 1314, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1315.0, 1.0, 1.0, 1.0, 1315.0, 1315.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.176, 0.0, 0.0, 0.0, -5.166, -5.151, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3275, "number_of_timesteps": 59072, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"step": 1315, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1316.0, 1.0, 1.0, 1.0, 1316.0, 1316.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.177, 0.0, 0.0, 0.0, -5.165, -5.151, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3276, "number_of_timesteps": 59086, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 1316, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1317.0, 1.0, 1.0, 1.0, 1317.0, 1317.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.178, 0.0, 0.0, 0.0, -5.166, -5.151, 0.0, 0.0, 0.0]}
{"step": 1317, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1318.0, 1.0, 1.0, 1.0, 1318.0, 1318.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.175, 0.0, 0.0, 0.0, -5.162, -5.147, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3281, "number_of_timesteps": 59170, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"step": 1318, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1319.0, 1.0, 1.0, 1.0, 1319.0, 1319.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.171, 0.0, 0.0, 0.0, -5.158, -5.143, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3284, "number_of_timesteps": 59239, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 1319, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1320.0, 1.0, 1.0, 1.0, 1320.0, 1320.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.173, 0.0, 0.0, 0.0, -5.154, -5.144, 0.0, 0.0, 0.0]}
{"step": 1320, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1321.0, 1.0, 1.0, 1.0, 1321.0, 1321.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.174, 0.0, 0.0, 0.0, -5.15, -5.145, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3291, "number_of_timesteps": 59363, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1321, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1322.0, 1.0, 1.0, 1.0, 1322.0, 1322.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.171, 0.0, 0.0, 0.0, -5.146, -5.141, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3291, "number_of_timesteps": 59363, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1322, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1323.0, 1.0, 1.0, 1.0, 1323.0, 1323.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.168, 0.0, 0.0, 0.0, -5.158, -5.153, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3294, "number_of_timesteps": 59415, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.20000000000000107},
{"step": 1323, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1324.0, 1.0, 1.0, 1.0, 1324.0, 1324.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.172, 0.0, 0.0, 0.0, -5.162, -5.156, 0.0, 0.0, 0.0]}
{"step": 1324, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1325.0, 1.0, 1.0, 1.0, 1325.0, 1325.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.174, 0.0, 0.0, 0.0, -5.163, -5.158, 0.0, 0.0, 0.0]}
{"step": 1325, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1326.0, 1.0, 1.0, 1.0, 1326.0, 1326.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.175, 0.0, 0.0, 0.0, -5.163, -5.158, 0.0, 0.0, 0.0]}
{"step": 1326, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1327.0, 1.0, 1.0, 1.0, 1327.0, 1327.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.177, 0.0, 0.0, 0.0, -5.164, -5.159, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3304, "number_of_timesteps": 59602, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 1327, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1328.0, 1.0, 1.0, 1.0, 1328.0, 1328.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.177, 0.0, 0.0, 0.0, -5.164, -5.159, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3306, "number_of_timesteps": 59645, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.15000000000000036},
{"step": 1328, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1329.0, 1.0, 1.0, 1.0, 1329.0, 1329.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.177, 0.0, 0.0, 0.0, -5.163, -5.155, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3307, "number_of_timesteps": 59659, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.20000000000000107},
{"step": 1329, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1330.0, 1.0, 1.0, 1.0, 1330.0, 1330.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.184, 0.0, 0.0, 0.0, -5.169, -5.161, 0.0, 0.0, 0.0]}
{"step": 1330, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1331.0, 1.0, 1.0, 1.0, 1331.0, 1331.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.185, 0.0, 0.0, 0.0, -5.169, -5.161, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3313, "number_of_timesteps": 59783, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.20000000000000107},
{"step": 1331, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1332.0, 1.0, 1.0, 1.0, 1332.0, 1332.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.186, 0.0, 0.0, 0.0, -5.169, -5.161, 0.0, 0.0, 0.0]}
{"step": 1332, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1333.0, 1.0, 1.0, 1.0, 1333.0, 1333.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.188, 0.0, 0.0, 0.0, -5.171, -5.163, 0.0, 0.0, 0.0]}
{"step": 1333, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1334.0, 1.0, 1.0, 1.0, 1334.0, 1334.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.189, 0.0, 0.0, 0.0, -5.171, -5.163, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3316, "number_of_timesteps": 59849, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1334, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1335.0, 1.0, 1.0, 1.0, 1335.0, 1335.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.185, 0.0, 0.0, 0.0, -5.167, -5.159, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3317, "number_of_timesteps": 59871, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.25},
{"step": 1335, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1336.0, 1.0, 1.0, 1.0, 1336.0, 1336.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.182, 0.0, 0.0, 0.0, -5.163, -5.155, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3319, "number_of_timesteps": 59908, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1336, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1337.0, 1.0, 1.0, 1.0, 1337.0, 1337.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.179, 0.0, 0.0, 0.0, -5.159, -5.151, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3320, "number_of_timesteps": 59947, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 1337, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1338.0, 1.0, 1.0, 1.0, 1338.0, 1338.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.18, 0.0, 0.0, 0.0, -5.159, -5.151, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3322, "number_of_timesteps": 59989, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 1338, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1339.0, 1.0, 1.0, 1.0, 1339.0, 1339.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.181, 0.0, 0.0, 0.0, -5.159, -5.147, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3322, "number_of_timesteps": 59989, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.1999999999999993},
{"step": 1339, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1340.0, 1.0, 1.0, 1.0, 1340.0, 1340.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.182, 0.0, 0.0, 0.0, -5.155, -5.148, 0.0, 0.0, 0.0]}
{"step": 1340, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1341.0, 1.0, 1.0, 1.0, 1341.0, 1341.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.186, 0.0, 0.0, 0.0, -5.158, -5.151, 0.0, 0.0, 0.0]}
{"step": 1341, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1342.0, 1.0, 1.0, 1.0, 1342.0, 1342.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.188, 0.0, 0.0, 0.0, -5.154, -5.152, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3326, "number_of_timesteps": 60134, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1342, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1343.0, 1.0, 1.0, 1.0, 1343.0, 1343.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.191, 0.0, 0.0, 0.0, -5.157, -5.154, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3328, "number_of_timesteps": 60181, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.20000000000000107},
{"step": 1343, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1344.0, 1.0, 1.0, 1.0, 1344.0, 1344.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.192, 0.0, 0.0, 0.0, -5.157, -5.155, 0.0, 0.0, 0.0]}
{"step": 1344, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1345.0, 1.0, 1.0, 1.0, 1345.0, 1345.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.189, 0.0, 0.0, 0.0, -5.154, -5.151, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3331, "number_of_timesteps": 60298, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.10000000000000142},
{"step": 1345, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1346.0, 1.0, 1.0, 1.0, 1346.0, 1346.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.186, 0.0, 0.0, 0.0, -5.15, -5.147, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3332, "number_of_timesteps": 60314, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 1346, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1347.0, 1.0, 1.0, 1.0, 1347.0, 1347.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.189, 0.0, 0.0, 0.0, -5.146, -5.149, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3334, "number_of_timesteps": 60349, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"step": 1347, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1348.0, 1.0, 1.0, 1.0, 1348.0, 1348.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.191, 0.0, 0.0, 0.0, -5.148, -5.151, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3335, "number_of_timesteps": 60384, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.20000000000000107},
{"step": 1348, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1349.0, 1.0, 1.0, 1.0, 1349.0, 1349.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.188, 0.0, 0.0, 0.0, -5.144, -5.147, 0.0, 0.0, 0.0]}
{"step": 1349, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1350.0, 1.0, 1.0, 1.0, 1350.0, 1350.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.189, 0.0, 0.0, 0.0, -5.144, -5.147, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3338, "number_of_timesteps": 60432, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.20000000000000107},
{"step": 1350, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1351.0, 1.0, 1.0, 1.0, 1351.0, 1351.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.191, 0.0, 0.0, 0.0, -5.146, -5.149, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3340, "number_of_timesteps": 60627, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.15000000000000036},
{"step": 1351, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1352.0, 1.0, 1.0, 1.0, 1352.0, 1352.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.193, 0.0, 0.0, 0.0, -5.146, -5.15, 0.0, 0.0, 0.0]}
{"step": 1352, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1353.0, 1.0, 1.0, 1.0, 1353.0, 1353.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.194, 0.0, 0.0, 0.0, -5.148, -5.151, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3345, "number_of_timesteps": 60774, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 1353, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1354.0, 1.0, 1.0, 1.0, 1354.0, 1354.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.196, 0.0, 0.0, 0.0, -5.149, -5.147, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3347, "number_of_timesteps": 60809, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.20000000000000107},
{"step": 1354, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1355.0, 1.0, 1.0, 1.0, 1355.0, 1355.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.208, 0.0, 0.0, 0.0, -5.16, -5.158, 0.0, 0.0, 0.0]}
{"step": 1355, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1356.0, 1.0, 1.0, 1.0, 1356.0, 1356.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.21, 0.0, 0.0, 0.0, -5.161, -5.154, 0.0, 0.0, 0.0]}
{"step": 1356, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1357.0, 1.0, 1.0, 1.0, 1357.0, 1357.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.222, 0.0, 0.0, 0.0, -5.173, -5.165, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3352, "number_of_timesteps": 60903, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1357, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1358.0, 1.0, 1.0, 1.0, 1358.0, 1358.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.219, 0.0, 0.0, 0.0, -5.169, -5.162, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3352, "number_of_timesteps": 60903, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 1358, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1359.0, 1.0, 1.0, 1.0, 1359.0, 1359.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.216, 0.0, 0.0, 0.0, -5.176, -5.168, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3355, "number_of_timesteps": 60952, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 1359, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1360.0, 1.0, 1.0, 1.0, 1360.0, 1360.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.213, 0.0, 0.0, 0.0, -5.172, -5.165, 0.0, 0.0, 0.0]}
{"step": 1360, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1361.0, 1.0, 1.0, 1.0, 1361.0, 1361.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.21, 0.0, 0.0, 0.0, -5.168, -5.161, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3357, "number_of_timesteps": 61047, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.25},
{"step": 1361, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1362.0, 1.0, 1.0, 1.0, 1362.0, 1362.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.207, 0.0, 0.0, 0.0, -5.164, -5.157, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3358, "number_of_timesteps": 61095, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.15000000000000036},
{"step": 1362, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1363.0, 1.0, 1.0, 1.0, 1363.0, 1363.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.209, 0.0, 0.0, 0.0, -5.166, -5.153, 0.0, 0.0, 0.0]}
{"step": 1363, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1364.0, 1.0, 1.0, 1.0, 1364.0, 1364.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.212, 0.0, 0.0, 0.0, -5.168, -5.15, 0.0, 0.0, 0.0]}
{"step": 1364, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1365.0, 1.0, 1.0, 1.0, 1365.0, 1365.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.209, 0.0, 0.0, 0.0, -5.164, -5.146, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3364, "number_of_timesteps": 61277, "per_episode_reward": 15.35, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 1365, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1366.0, 1.0, 1.0, 1.0, 1366.0, 1366.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.212, 0.0, 0.0, 0.0, -5.167, -5.148, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3365, "number_of_timesteps": 61328, "per_episode_reward": 15.35, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1366, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1367.0, 1.0, 1.0, 1.0, 1367.0, 1367.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.212, 0.0, 0.0, 0.0, -5.163, -5.147, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3369, "number_of_timesteps": 61423, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1367, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1368.0, 1.0, 1.0, 1.0, 1368.0, 1368.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.214, 0.0, 0.0, 0.0, -5.165, -5.144, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3370, "number_of_timesteps": 61441, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1368, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1369.0, 1.0, 1.0, 1.0, 1369.0, 1369.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.211, 0.0, 0.0, 0.0, -5.173, -5.152, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3370, "number_of_timesteps": 61441, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1369, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1370.0, 1.0, 1.0, 1.0, 1370.0, 1370.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.208, 0.0, 0.0, 0.0, -5.169, -5.148, 0.0, 0.0, 0.0]}
{"step": 1370, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1371.0, 1.0, 1.0, 1.0, 1371.0, 1371.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.21, 0.0, 0.0, 0.0, -5.165, -5.149, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3375, "number_of_timesteps": 61527, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1371, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1372.0, 1.0, 1.0, 1.0, 1372.0, 1372.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.211, 0.0, 0.0, 0.0, -5.166, -5.15, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3377, "number_of_timesteps": 61611, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1372, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1373.0, 1.0, 1.0, 1.0, 1373.0, 1373.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.217, 0.0, 0.0, 0.0, -5.171, -5.155, 0.0, 0.0, 0.0]}
{"step": 1373, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1374.0, 1.0, 1.0, 1.0, 1374.0, 1374.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.227, 0.0, 0.0, 0.0, -5.181, -5.164, 0.0, 0.0, 0.0]}
{"step": 1374, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1375.0, 1.0, 1.0, 1.0, 1375.0, 1375.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.228, 0.0, 0.0, 0.0, -5.181, -5.164, 0.0, 0.0, 0.0]}
{"eval_score": 25.6, "number_of_episodes": 3382}
{"number_of_episodes": 3382, "number_of_timesteps": 61717, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.20000000000000107},
{"step": 1375, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1376.0, 1.0, 1.0, 1.0, 1376.0, 1376.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.229, 0.0, 0.0, 0.0, -5.181, -5.165, 0.0, 0.0, 0.0]}
{"step": 1376, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1377.0, 1.0, 1.0, 1.0, 1377.0, 1377.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.239, 0.0, 0.0, 0.0, -5.19, -5.174, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3385, "number_of_timesteps": 61828, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 1377, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1378.0, 1.0, 1.0, 1.0, 1378.0, 1378.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.24, 0.0, 0.0, 0.0, -5.191, -5.17, 0.0, 0.0, 0.0]}
{"step": 1378, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1379.0, 1.0, 1.0, 1.0, 1379.0, 1379.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.245, 0.0, 0.0, 0.0, -5.194, -5.174, 0.0, 0.0, 0.0]}
{"step": 1379, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1380.0, 1.0, 1.0, 1.0, 1380.0, 1380.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.243, 0.0, 0.0, 0.0, -5.192, -5.172, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3390, "number_of_timesteps": 62014, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 1380, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1381.0, 1.0, 1.0, 1.0, 1381.0, 1381.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.24, 0.0, 0.0, 0.0, -5.188, -5.168, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3391, "number_of_timesteps": 62042, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 1381, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1382.0, 1.0, 1.0, 1.0, 1382.0, 1382.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.252, 0.0, 0.0, 0.0, -5.2, -5.179, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3391, "number_of_timesteps": 62042, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 1382, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1383.0, 1.0, 1.0, 1.0, 1383.0, 1383.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.249, 0.0, 0.0, 0.0, -5.196, -5.176, 0.0, 0.0, 0.0]}
{"step": 1383, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1384.0, 1.0, 1.0, 1.0, 1384.0, 1384.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.256, 0.0, 0.0, 0.0, -5.202, -5.182, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3394, "number_of_timesteps": 62155, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.20000000000000107},
{"step": 1384, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1385.0, 1.0, 1.0, 1.0, 1385.0, 1385.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.256, 0.0, 0.0, 0.0, -5.202, -5.181, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3396, "number_of_timesteps": 62223, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 1385, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1386.0, 1.0, 1.0, 1.0, 1386.0, 1386.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.253, 0.0, 0.0, 0.0, -5.198, -5.178, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3398, "number_of_timesteps": 62297, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.3000000000000007},
{"step": 1386, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1387.0, 1.0, 1.0, 1.0, 1387.0, 1387.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.254, 0.0, 0.0, 0.0, -5.198, -5.178, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3402, "number_of_timesteps": 62389, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1387, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1388.0, 1.0, 1.0, 1.0, 1388.0, 1388.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.254, 0.0, 0.0, 0.0, -5.198, -5.174, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3402, "number_of_timesteps": 62389, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1388, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1389.0, 1.0, 1.0, 1.0, 1389.0, 1389.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.255, 0.0, 0.0, 0.0, -5.198, -5.174, 0.0, 0.0, 0.0]}
{"step": 1389, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1390.0, 1.0, 1.0, 1.0, 1390.0, 1390.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.256, 0.0, 0.0, 0.0, -5.198, -5.174, 0.0, 0.0, 0.0]}
{"step": 1390, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1391.0, 1.0, 1.0, 1.0, 1391.0, 1391.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.257, 0.0, 0.0, 0.0, -5.198, -5.174, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3408, "number_of_timesteps": 62515, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.25},
{"step": 1391, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1392.0, 1.0, 1.0, 1.0, 1392.0, 1392.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.254, 0.0, 0.0, 0.0, -5.194, -5.171, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3408, "number_of_timesteps": 62515, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.3000000000000007},
{"step": 1392, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1393.0, 1.0, 1.0, 1.0, 1393.0, 1393.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.256, 0.0, 0.0, 0.0, -5.196, -5.172, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3409, "number_of_timesteps": 62543, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 1393, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1394.0, 1.0, 1.0, 1.0, 1394.0, 1394.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.253, 0.0, 0.0, 0.0, -5.192, -5.169, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3410, "number_of_timesteps": 62563, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 1394, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1395.0, 1.0, 1.0, 1.0, 1395.0, 1395.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.25, 0.0, 0.0, 0.0, -5.197, -5.173, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3412, "number_of_timesteps": 62606, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.20000000000000107},
{"step": 1395, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1396.0, 1.0, 1.0, 1.0, 1396.0, 1396.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.25, 0.0, 0.0, 0.0, -5.197, -5.173, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3413, "number_of_timesteps": 62629, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1396, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1397.0, 1.0, 1.0, 1.0, 1397.0, 1397.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.25, 0.0, 0.0, 0.0, -5.196, -5.172, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3413, "number_of_timesteps": 62629, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1397, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1398.0, 1.0, 1.0, 1.0, 1398.0, 1398.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.257, 0.0, 0.0, 0.0, -5.202, -5.179, 0.0, 0.0, 0.0]}
{"step": 1398, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1399.0, 1.0, 1.0, 1.0, 1399.0, 1399.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.255, 0.0, 0.0, 0.0, -5.199, -5.175, 0.0, 0.0, 0.0]}
{"step": 1399, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1400.0, 1.0, 1.0, 1.0, 1400.0, 1400.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.256, 0.0, 0.0, 0.0, -5.2, -5.176, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3419, "number_of_timesteps": 62903, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
{"step": 1400, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1401.0, 1.0, 1.0, 1.0, 1401.0, 1401.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.257, 0.0, 0.0, 0.0, -5.2, -5.172, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3420, "number_of_timesteps": 62973, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1401, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1402.0, 1.0, 1.0, 1.0, 1402.0, 1402.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.254, 0.0, 0.0, 0.0, -5.197, -5.169, 0.0, 0.0, 0.0]}
{"step": 1402, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1403.0, 1.0, 1.0, 1.0, 1403.0, 1403.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.209, -5.181, 0.0, 0.0, 0.0]}
{"step": 1403, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1404.0, 1.0, 1.0, 1.0, 1404.0, 1404.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.264, 0.0, 0.0, 0.0, -5.205, -5.177, 0.0, 0.0, 0.0]}
{"step": 1404, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1405.0, 1.0, 1.0, 1.0, 1405.0, 1405.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.264, 0.0, 0.0, 0.0, -5.204, -5.174, 0.0, 0.0, 0.0]}
{"step": 1405, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1406.0, 1.0, 1.0, 1.0, 1406.0, 1406.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.201, -5.17, 0.0, 0.0, 0.0]}
{"step": 1406, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1407.0, 1.0, 1.0, 1.0, 1407.0, 1407.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.2, -5.166, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3431, "number_of_timesteps": 63283, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1407, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1408.0, 1.0, 1.0, 1.0, 1408.0, 1408.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.262, 0.0, 0.0, 0.0, -5.2, -5.163, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3432, "number_of_timesteps": 63304, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.20000000000000107},
{"step": 1408, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1409.0, 1.0, 1.0, 1.0, 1409.0, 1409.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.209, -5.171, 0.0, 0.0, 0.0]}
{"step": 1409, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1410.0, 1.0, 1.0, 1.0, 1410.0, 1410.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.208, -5.167, 0.0, 0.0, 0.0]}
{"step": 1410, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1411.0, 1.0, 1.0, 1.0, 1411.0, 1411.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.209, -5.164, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3435, "number_of_timesteps": 63395, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 1411, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1412.0, 1.0, 1.0, 1.0, 1412.0, 1412.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.209, -5.164, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3436, "number_of_timesteps": 63426, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.3000000000000007},
{"step": 1412, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1413.0, 1.0, 1.0, 1.0, 1413.0, 1413.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.209, -5.164, 0.0, 0.0, 0.0]}
{"step": 1413, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1414.0, 1.0, 1.0, 1.0, 1414.0, 1414.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.209, -5.16, 0.0, 0.0, 0.0]}
{"step": 1414, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1415.0, 1.0, 1.0, 1.0, 1415.0, 1415.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.211, -5.161, 0.0, 0.0, 0.0]}
{"step": 1415, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1416.0, 1.0, 1.0, 1.0, 1416.0, 1416.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.21, -5.161, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3444, "number_of_timesteps": 63709, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1416, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1417.0, 1.0, 1.0, 1.0, 1417.0, 1417.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.214, -5.158, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3445, "number_of_timesteps": 63722, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1417, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1418.0, 1.0, 1.0, 1.0, 1418.0, 1418.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.288, 0.0, 0.0, 0.0, -5.22, -5.164, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3446, "number_of_timesteps": 63746, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.3000000000000007},
{"step": 1418, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1419.0, 1.0, 1.0, 1.0, 1419.0, 1419.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.288, 0.0, 0.0, 0.0, -5.22, -5.164, 0.0, 0.0, 0.0]}
{"step": 1419, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1420.0, 1.0, 1.0, 1.0, 1420.0, 1420.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.297, 0.0, 0.0, 0.0, -5.227, -5.171, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3448, "number_of_timesteps": 63778, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 1420, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1421.0, 1.0, 1.0, 1.0, 1421.0, 1421.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.223, -5.168, 0.0, 0.0, 0.0]}
{"step": 1421, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1422.0, 1.0, 1.0, 1.0, 1422.0, 1422.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.22, -5.164, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3452, "number_of_timesteps": 63908, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 1422, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1423.0, 1.0, 1.0, 1.0, 1423.0, 1423.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.219, -5.163, 0.0, 0.0, 0.0]}
{"step": 1423, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1424.0, 1.0, 1.0, 1.0, 1424.0, 1424.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.296, 0.0, 0.0, 0.0, -5.224, -5.169, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3452, "number_of_timesteps": 63908, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.25},
{"step": 1424, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1425.0, 1.0, 1.0, 1.0, 1425.0, 1425.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.293, 0.0, 0.0, 0.0, -5.221, -5.165, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3454, "number_of_timesteps": 63969, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.20000000000000107},
{"step": 1425, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1426.0, 1.0, 1.0, 1.0, 1426.0, 1426.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.22, -5.165, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3455, "number_of_timesteps": 64085, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1426, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1427.0, 1.0, 1.0, 1.0, 1427.0, 1427.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.225, -5.17, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3457, "number_of_timesteps": 64145, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.20000000000000107},
{"step": 1427, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1428.0, 1.0, 1.0, 1.0, 1428.0, 1428.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.228, -5.172, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3459, "number_of_timesteps": 64256, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.3000000000000007},
{"step": 1428, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1429.0, 1.0, 1.0, 1.0, 1429.0, 1429.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.295, 0.0, 0.0, 0.0, -5.228, -5.173, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3462, "number_of_timesteps": 64353, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 1429, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1430.0, 1.0, 1.0, 1.0, 1430.0, 1430.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.292, 0.0, 0.0, 0.0, -5.224, -5.169, 0.0, 0.0, 0.0]}
{"step": 1430, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1431.0, 1.0, 1.0, 1.0, 1431.0, 1431.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.289, 0.0, 0.0, 0.0, -5.228, -5.173, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3465, "number_of_timesteps": 64410, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 1431, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1432.0, 1.0, 1.0, 1.0, 1432.0, 1432.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.229, -5.169, 0.0, 0.0, 0.0]}
{"step": 1432, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1433.0, 1.0, 1.0, 1.0, 1433.0, 1433.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.292, 0.0, 0.0, 0.0, -5.23, -5.17, 0.0, 0.0, 0.0]}
{"step": 1433, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1434.0, 1.0, 1.0, 1.0, 1434.0, 1434.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.293, 0.0, 0.0, 0.0, -5.231, -5.171, 0.0, 0.0, 0.0]}
{"step": 1434, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1435.0, 1.0, 1.0, 1.0, 1435.0, 1435.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.231, -5.167, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3469, "number_of_timesteps": 64516, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.25},
{"step": 1435, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1436.0, 1.0, 1.0, 1.0, 1436.0, 1436.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.227, -5.163, 0.0, 0.0, 0.0]}
{"step": 1436, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1437.0, 1.0, 1.0, 1.0, 1437.0, 1437.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.288, 0.0, 0.0, 0.0, -5.223, -5.16, 0.0, 0.0, 0.0]}
{"step": 1437, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1438.0, 1.0, 1.0, 1.0, 1438.0, 1438.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.285, 0.0, 0.0, 0.0, -5.22, -5.156, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3474, "number_of_timesteps": 64738, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 1438, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1439.0, 1.0, 1.0, 1.0, 1439.0, 1439.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.216, -5.153, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3475, "number_of_timesteps": 64750, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 1439, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1440.0, 1.0, 1.0, 1.0, 1440.0, 1440.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.221, -5.158, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3475, "number_of_timesteps": 64750, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.3000000000000007},
{"step": 1440, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1441.0, 1.0, 1.0, 1.0, 1441.0, 1441.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.222, -5.159, 0.0, 0.0, 0.0]}
{"step": 1441, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1442.0, 1.0, 1.0, 1.0, 1442.0, 1442.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.283, 0.0, 0.0, 0.0, -5.223, -5.16, 0.0, 0.0, 0.0]}
{"step": 1442, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1443.0, 1.0, 1.0, 1.0, 1443.0, 1443.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.228, -5.165, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3479, "number_of_timesteps": 64860, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
{"step": 1443, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1444.0, 1.0, 1.0, 1.0, 1444.0, 1444.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.229, -5.165, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3481, "number_of_timesteps": 64915, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.25},
{"step": 1444, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1445.0, 1.0, 1.0, 1.0, 1445.0, 1445.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.225, -5.162, 0.0, 0.0, 0.0]}
{"step": 1445, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1446.0, 1.0, 1.0, 1.0, 1446.0, 1446.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.221, -5.158, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3485, "number_of_timesteps": 65067, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.3000000000000007},
{"step": 1446, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1447.0, 1.0, 1.0, 1.0, 1447.0, 1447.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.222, -5.159, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3485, "number_of_timesteps": 65067, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 1447, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1448.0, 1.0, 1.0, 1.0, 1448.0, 1448.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.218, -5.155, 0.0, 0.0, 0.0]}
{"step": 1448, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1449.0, 1.0, 1.0, 1.0, 1449.0, 1449.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.218, -5.155, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3487, "number_of_timesteps": 65145, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 1449, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1450.0, 1.0, 1.0, 1.0, 1450.0, 1450.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.223, -5.161, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3487, "number_of_timesteps": 65145, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 1450, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1451.0, 1.0, 1.0, 1.0, 1451.0, 1451.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.225, -5.157, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3488, "number_of_timesteps": 65170, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.25},
{"step": 1451, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1452.0, 1.0, 1.0, 1.0, 1452.0, 1452.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.221, -5.153, 0.0, 0.0, 0.0]}
{"step": 1452, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1453.0, 1.0, 1.0, 1.0, 1453.0, 1453.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.217, -5.15, 0.0, 0.0, 0.0]}
{"step": 1453, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1454.0, 1.0, 1.0, 1.0, 1454.0, 1454.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.283, 0.0, 0.0, 0.0, -5.225, -5.157, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3493, "number_of_timesteps": 65420, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 1454, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1455.0, 1.0, 1.0, 1.0, 1455.0, 1455.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.285, 0.0, 0.0, 0.0, -5.226, -5.159, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3495, "number_of_timesteps": 65478, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 1455, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1456.0, 1.0, 1.0, 1.0, 1456.0, 1456.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.287, 0.0, 0.0, 0.0, -5.227, -5.159, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3496, "number_of_timesteps": 65551, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.006666666666666663, "biggest_recent_change": 0.25},
{"step": 1456, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1457.0, 1.0, 1.0, 1.0, 1457.0, 1457.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.287, 0.0, 0.0, 0.0, -5.223, -5.159, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3497, "number_of_timesteps": 65572, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 1457, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1458.0, 1.0, 1.0, 1.0, 1458.0, 1458.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.284, 0.0, 0.0, 0.0, -5.22, -5.155, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3499, "number_of_timesteps": 65618, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1458, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1459.0, 1.0, 1.0, 1.0, 1459.0, 1459.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.223, -5.159, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3501, "number_of_timesteps": 65716, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.3000000000000007},
{"step": 1459, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1460.0, 1.0, 1.0, 1.0, 1460.0, 1460.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.224, -5.159, 0.0, 0.0, 0.0]}
{"step": 1460, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1461.0, 1.0, 1.0, 1.0, 1461.0, 1461.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.22, -5.156, 0.0, 0.0, 0.0]}
{"step": 1461, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1462.0, 1.0, 1.0, 1.0, 1462.0, 1462.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.216, -5.152, 0.0, 0.0, 0.0]}
{"step": 1462, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1463.0, 1.0, 1.0, 1.0, 1463.0, 1463.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.213, -5.153, 0.0, 0.0, 0.0]}
{"step": 1463, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1464.0, 1.0, 1.0, 1.0, 1464.0, 1464.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.212, -5.152, 0.0, 0.0, 0.0]}
{"step": 1464, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1465.0, 1.0, 1.0, 1.0, 1465.0, 1465.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.212, -5.152, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3509, "number_of_timesteps": 65956, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1465, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1466.0, 1.0, 1.0, 1.0, 1466.0, 1466.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.216, -5.156, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3509, "number_of_timesteps": 65956, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 1466, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1467.0, 1.0, 1.0, 1.0, 1467.0, 1467.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.212, -5.16, 0.0, 0.0, 0.0]}
{"eval_score": 33.3, "number_of_episodes": 3510}
{"step": 1467, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1468.0, 1.0, 1.0, 1.0, 1468.0, 1468.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.219, -5.167, 0.0, 0.0, 0.0]}
{"step": 1468, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1469.0, 1.0, 1.0, 1.0, 1469.0, 1469.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.227, -5.175, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3515, "number_of_timesteps": 66187, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1469, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1470.0, 1.0, 1.0, 1.0, 1470.0, 1470.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.233, -5.18, 0.0, 0.0, 0.0]}
{"step": 1470, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1471.0, 1.0, 1.0, 1.0, 1471.0, 1471.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.285, 0.0, 0.0, 0.0, -5.238, -5.186, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3516, "number_of_timesteps": 66222, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 1471, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1472.0, 1.0, 1.0, 1.0, 1472.0, 1472.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.29, 0.0, 0.0, 0.0, -5.242, -5.19, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3518, "number_of_timesteps": 66281, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 1472, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1473.0, 1.0, 1.0, 1.0, 1473.0, 1473.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.29, 0.0, 0.0, 0.0, -5.241, -5.186, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3518, "number_of_timesteps": 66281, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1473, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1474.0, 1.0, 1.0, 1.0, 1474.0, 1474.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.287, 0.0, 0.0, 0.0, -5.238, -5.183, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3520, "number_of_timesteps": 66381, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 1474, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1475.0, 1.0, 1.0, 1.0, 1475.0, 1475.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.284, 0.0, 0.0, 0.0, -5.234, -5.179, 0.0, 0.0, 0.0]}
{"step": 1475, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1476.0, 1.0, 1.0, 1.0, 1476.0, 1476.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.231, -5.176, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3523, "number_of_timesteps": 66497, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 1476, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1477.0, 1.0, 1.0, 1.0, 1477.0, 1477.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.235, -5.18, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3525, "number_of_timesteps": 66555, "per_episode_reward": 15.6, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.3000000000000007},
{"step": 1477, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1478.0, 1.0, 1.0, 1.0, 1478.0, 1478.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.235, -5.18, 0.0, 0.0, 0.0]}
{"step": 1478, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1479.0, 1.0, 1.0, 1.0, 1479.0, 1479.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.231, -5.176, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3528, "number_of_timesteps": 66669, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 1479, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1480.0, 1.0, 1.0, 1.0, 1480.0, 1480.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.228, -5.177, 0.0, 0.0, 0.0]}
{"step": 1480, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1481.0, 1.0, 1.0, 1.0, 1481.0, 1481.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.228, -5.178, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3530, "number_of_timesteps": 66710, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 1481, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1482.0, 1.0, 1.0, 1.0, 1482.0, 1482.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.225, -5.174, 0.0, 0.0, 0.0]}
{"step": 1482, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1483.0, 1.0, 1.0, 1.0, 1483.0, 1483.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.221, -5.171, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3532, "number_of_timesteps": 66750, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.006111111111111099, "biggest_recent_change": 0.15000000000000036},
{"step": 1483, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1484.0, 1.0, 1.0, 1.0, 1484.0, 1484.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.221, -5.171, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3533, "number_of_timesteps": 66798, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 1484, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1485.0, 1.0, 1.0, 1.0, 1485.0, 1485.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.226, -5.176, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3536, "number_of_timesteps": 66889, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 1485, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1486.0, 1.0, 1.0, 1.0, 1486.0, 1486.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.225, -5.175, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3537, "number_of_timesteps": 66943, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.006111111111111099, "biggest_recent_change": 0.20000000000000107},
{"step": 1486, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1487.0, 1.0, 1.0, 1.0, 1487.0, 1487.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.226, -5.176, 0.0, 0.0, 0.0]}
{"step": 1487, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1488.0, 1.0, 1.0, 1.0, 1488.0, 1488.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.227, -5.177, 0.0, 0.0, 0.0]}
{"step": 1488, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1489.0, 1.0, 1.0, 1.0, 1489.0, 1489.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.235, -5.185, 0.0, 0.0, 0.0]}
{"step": 1489, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1490.0, 1.0, 1.0, 1.0, 1490.0, 1490.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.235, -5.185, 0.0, 0.0, 0.0]}
{"step": 1490, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1491.0, 1.0, 1.0, 1.0, 1491.0, 1491.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.235, -5.184, 0.0, 0.0, 0.0]}
{"step": 1491, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1492.0, 1.0, 1.0, 1.0, 1492.0, 1492.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.234, -5.183, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3542, "number_of_timesteps": 67188, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.25},
{"step": 1492, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1493.0, 1.0, 1.0, 1.0, 1493.0, 1493.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.23, -5.183, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3543, "number_of_timesteps": 67203, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 1493, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1494.0, 1.0, 1.0, 1.0, 1494.0, 1494.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.296, 0.0, 0.0, 0.0, -5.234, -5.187, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3543, "number_of_timesteps": 67203, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.006111111111111099, "biggest_recent_change": 0.25},
{"step": 1494, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1495.0, 1.0, 1.0, 1.0, 1495.0, 1495.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.293, 0.0, 0.0, 0.0, -5.231, -5.184, 0.0, 0.0, 0.0]}
{"step": 1495, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1496.0, 1.0, 1.0, 1.0, 1496.0, 1496.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.29, 0.0, 0.0, 0.0, -5.227, -5.18, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3545, "number_of_timesteps": 67282, "per_episode_reward": 15.75, "episode_reward_trend_value": 0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 1496, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1497.0, 1.0, 1.0, 1.0, 1497.0, 1497.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.288, 0.0, 0.0, 0.0, -5.235, -5.188, 0.0, 0.0, 0.0]}
{"step": 1497, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1498.0, 1.0, 1.0, 1.0, 1498.0, 1498.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.293, 0.0, 0.0, 0.0, -5.24, -5.193, 0.0, 0.0, 0.0]}
{"step": 1498, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1499.0, 1.0, 1.0, 1.0, 1499.0, 1499.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.299, 0.0, 0.0, 0.0, -5.245, -5.198, 0.0, 0.0, 0.0]}
{"step": 1499, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1500.0, 1.0, 1.0, 1.0, 1500.0, 1500.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.252, -5.205, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3553, "number_of_timesteps": 67713, "per_episode_reward": 15.75, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 1500, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1501.0, 1.0, 1.0, 1.0, 1501.0, 1501.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.309, 0.0, 0.0, 0.0, -5.248, -5.207, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3556, "number_of_timesteps": 67787, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1501, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1502.0, 1.0, 1.0, 1.0, 1502.0, 1502.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.31, 0.0, 0.0, 0.0, -5.25, -5.203, 0.0, 0.0, 0.0]}
{"step": 1502, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1503.0, 1.0, 1.0, 1.0, 1503.0, 1503.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.31, 0.0, 0.0, 0.0, -5.249, -5.2, 0.0, 0.0, 0.0]}
{"step": 1503, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1504.0, 1.0, 1.0, 1.0, 1504.0, 1504.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.31, 0.0, 0.0, 0.0, -5.248, -5.196, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3557, "number_of_timesteps": 67816, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.15000000000000036},
{"step": 1504, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1505.0, 1.0, 1.0, 1.0, 1505.0, 1505.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.251, -5.2, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3559, "number_of_timesteps": 67884, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1505, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1506.0, 1.0, 1.0, 1.0, 1506.0, 1506.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.311, 0.0, 0.0, 0.0, -5.255, -5.203, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3559, "number_of_timesteps": 67884, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 1506, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1507.0, 1.0, 1.0, 1.0, 1507.0, 1507.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.308, 0.0, 0.0, 0.0, -5.251, -5.2, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3560, "number_of_timesteps": 67914, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 1507, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1508.0, 1.0, 1.0, 1.0, 1508.0, 1508.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.306, 0.0, 0.0, 0.0, -5.248, -5.196, 0.0, 0.0, 0.0]}
{"step": 1508, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1509.0, 1.0, 1.0, 1.0, 1509.0, 1509.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.308, 0.0, 0.0, 0.0, -5.249, -5.193, 0.0, 0.0, 0.0]}
{"step": 1509, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1510.0, 1.0, 1.0, 1.0, 1510.0, 1510.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.309, 0.0, 0.0, 0.0, -5.25, -5.189, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3563, "number_of_timesteps": 68043, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.15000000000000036},
{"step": 1510, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1511.0, 1.0, 1.0, 1.0, 1511.0, 1511.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.309, 0.0, 0.0, 0.0, -5.249, -5.189, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3565, "number_of_timesteps": 68127, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.20000000000000107},
{"step": 1511, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1512.0, 1.0, 1.0, 1.0, 1512.0, 1512.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.311, 0.0, 0.0, 0.0, -5.251, -5.19, 0.0, 0.0, 0.0]}
{"step": 1512, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1513.0, 1.0, 1.0, 1.0, 1513.0, 1513.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.309, 0.0, 0.0, 0.0, -5.248, -5.187, 0.0, 0.0, 0.0]}
{"step": 1513, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1514.0, 1.0, 1.0, 1.0, 1514.0, 1514.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.313, 0.0, 0.0, 0.0, -5.251, -5.19, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3568, "number_of_timesteps": 68253, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.25},
{"step": 1514, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1515.0, 1.0, 1.0, 1.0, 1515.0, 1515.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.247, -5.19, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3569, "number_of_timesteps": 68280, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1515, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1516.0, 1.0, 1.0, 1.0, 1516.0, 1516.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.309, 0.0, 0.0, 0.0, -5.253, -5.195, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3570, "number_of_timesteps": 68296, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.25},
{"step": 1516, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1517.0, 1.0, 1.0, 1.0, 1517.0, 1517.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.249, -5.191, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3572, "number_of_timesteps": 68376, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 1517, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1518.0, 1.0, 1.0, 1.0, 1518.0, 1518.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.246, -5.188, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3572, "number_of_timesteps": 68376, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1518, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1519.0, 1.0, 1.0, 1.0, 1519.0, 1519.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.255, -5.198, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3572, "number_of_timesteps": 68376, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1519, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1520.0, 1.0, 1.0, 1.0, 1520.0, 1520.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.315, 0.0, 0.0, 0.0, -5.256, -5.194, 0.0, 0.0, 0.0]}
{"step": 1520, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1521.0, 1.0, 1.0, 1.0, 1521.0, 1521.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.313, 0.0, 0.0, 0.0, -5.253, -5.191, 0.0, 0.0, 0.0]}
{"step": 1521, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1522.0, 1.0, 1.0, 1.0, 1522.0, 1522.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.31, 0.0, 0.0, 0.0, -5.256, -5.194, 0.0, 0.0, 0.0]}
{"step": 1522, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1523.0, 1.0, 1.0, 1.0, 1523.0, 1523.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.253, -5.191, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3579, "number_of_timesteps": 68738, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.00777777777777777, "biggest_recent_change": 0.20000000000000107},
{"step": 1523, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1524.0, 1.0, 1.0, 1.0, 1524.0, 1524.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.249, -5.187, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3582, "number_of_timesteps": 68823, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 1524, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1525.0, 1.0, 1.0, 1.0, 1525.0, 1525.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.249, -5.187, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3582, "number_of_timesteps": 68823, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
{"step": 1525, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1526.0, 1.0, 1.0, 1.0, 1526.0, 1526.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.309, 0.0, 0.0, 0.0, -5.253, -5.191, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3583, "number_of_timesteps": 68865, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.00777777777777777, "biggest_recent_change": 0.25},
{"step": 1526, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1527.0, 1.0, 1.0, 1.0, 1527.0, 1527.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.311, 0.0, 0.0, 0.0, -5.249, -5.193, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3584, "number_of_timesteps": 68942, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 1527, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1528.0, 1.0, 1.0, 1.0, 1528.0, 1528.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.25, -5.189, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3585, "number_of_timesteps": 68963, "per_episode_reward": 15.85, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 1528, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1529.0, 1.0, 1.0, 1.0, 1529.0, 1529.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.309, 0.0, 0.0, 0.0, -5.255, -5.194, 0.0, 0.0, 0.0]}
{"step": 1529, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1530.0, 1.0, 1.0, 1.0, 1530.0, 1530.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.259, -5.199, 0.0, 0.0, 0.0]}
{"step": 1530, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1531.0, 1.0, 1.0, 1.0, 1531.0, 1531.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.311, 0.0, 0.0, 0.0, -5.263, -5.203, 0.0, 0.0, 0.0]}
{"step": 1531, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1532.0, 1.0, 1.0, 1.0, 1532.0, 1532.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.316, 0.0, 0.0, 0.0, -5.267, -5.206, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3590, "number_of_timesteps": 69128, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1532, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1533.0, 1.0, 1.0, 1.0, 1533.0, 1533.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.313, 0.0, 0.0, 0.0, -5.264, -5.203, 0.0, 0.0, 0.0]}
{"step": 1533, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1534.0, 1.0, 1.0, 1.0, 1534.0, 1534.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.31, 0.0, 0.0, 0.0, -5.268, -5.207, 0.0, 0.0, 0.0]}
{"step": 1534, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1535.0, 1.0, 1.0, 1.0, 1535.0, 1535.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.264, -5.208, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3593, "number_of_timesteps": 69222, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.007777777777777789, "biggest_recent_change": 0.25},
{"step": 1535, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1536.0, 1.0, 1.0, 1.0, 1536.0, 1536.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.261, -5.208, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3596, "number_of_timesteps": 69342, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1536, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1537.0, 1.0, 1.0, 1.0, 1537.0, 1537.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.26, -5.204, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3598, "number_of_timesteps": 69441, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1537, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1538.0, 1.0, 1.0, 1.0, 1538.0, 1538.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.315, 0.0, 0.0, 0.0, -5.263, -5.207, 0.0, 0.0, 0.0]}
{"step": 1538, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1539.0, 1.0, 1.0, 1.0, 1539.0, 1539.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.26, -5.204, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3599, "number_of_timesteps": 69512, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.007222222222222225, "biggest_recent_change": 0.20000000000000107},
{"step": 1539, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1540.0, 1.0, 1.0, 1.0, 1540.0, 1540.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.309, 0.0, 0.0, 0.0, -5.256, -5.2, 0.0, 0.0, 0.0]}
{"step": 1540, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1541.0, 1.0, 1.0, 1.0, 1541.0, 1541.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.313, 0.0, 0.0, 0.0, -5.253, -5.204, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3601, "number_of_timesteps": 69576, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"step": 1541, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1542.0, 1.0, 1.0, 1.0, 1542.0, 1542.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.253, -5.204, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3603, "number_of_timesteps": 69632, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 1542, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1543.0, 1.0, 1.0, 1.0, 1543.0, 1543.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.317, 0.0, 0.0, 0.0, -5.249, -5.206, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3607, "number_of_timesteps": 69775, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1543, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1544.0, 1.0, 1.0, 1.0, 1544.0, 1544.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.246, -5.202, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3607, "number_of_timesteps": 69775, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1544, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1545.0, 1.0, 1.0, 1.0, 1545.0, 1545.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.315, 0.0, 0.0, 0.0, -5.246, -5.202, 0.0, 0.0, 0.0]}
{"step": 1545, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1546.0, 1.0, 1.0, 1.0, 1546.0, 1546.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.313, 0.0, 0.0, 0.0, -5.244, -5.201, 0.0, 0.0, 0.0]}
{"step": 1546, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1547.0, 1.0, 1.0, 1.0, 1547.0, 1547.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.315, 0.0, 0.0, 0.0, -5.245, -5.202, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3612, "number_of_timesteps": 69925, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 1547, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1548.0, 1.0, 1.0, 1.0, 1548.0, 1548.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.242, -5.198, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3612, "number_of_timesteps": 69925, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.10000000000000142},
{"step": 1548, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1549.0, 1.0, 1.0, 1.0, 1549.0, 1549.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.311, 0.0, 0.0, 0.0, -5.24, -5.197, 0.0, 0.0, 0.0]}
{"step": 1549, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1550.0, 1.0, 1.0, 1.0, 1550.0, 1550.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.308, 0.0, 0.0, 0.0, -5.237, -5.193, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3616, "number_of_timesteps": 70029, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1550, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1551.0, 1.0, 1.0, 1.0, 1551.0, 1551.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.306, 0.0, 0.0, 0.0, -5.241, -5.198, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3617, "number_of_timesteps": 70057, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 1551, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1552.0, 1.0, 1.0, 1.0, 1552.0, 1552.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.238, -5.195, 0.0, 0.0, 0.0]}
{"step": 1552, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1553.0, 1.0, 1.0, 1.0, 1553.0, 1553.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.235, -5.191, 0.0, 0.0, 0.0]}
{"step": 1553, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1554.0, 1.0, 1.0, 1.0, 1554.0, 1554.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.234, -5.191, 0.0, 0.0, 0.0]}
{"step": 1554, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1555.0, 1.0, 1.0, 1.0, 1555.0, 1555.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.297, 0.0, 0.0, 0.0, -5.239, -5.196, 0.0, 0.0, 0.0]}
{"step": 1555, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1556.0, 1.0, 1.0, 1.0, 1556.0, 1556.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.295, 0.0, 0.0, 0.0, -5.236, -5.193, 0.0, 0.0, 0.0]}
{"step": 1556, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1557.0, 1.0, 1.0, 1.0, 1557.0, 1557.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.292, 0.0, 0.0, 0.0, -5.24, -5.196, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3626, "number_of_timesteps": 70412, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 1557, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1558.0, 1.0, 1.0, 1.0, 1558.0, 1558.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.289, 0.0, 0.0, 0.0, -5.25, -5.207, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3627, "number_of_timesteps": 70455, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1558, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1559.0, 1.0, 1.0, 1.0, 1559.0, 1559.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.289, 0.0, 0.0, 0.0, -5.25, -5.203, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3627, "number_of_timesteps": 70455, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1559, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1560.0, 1.0, 1.0, 1.0, 1560.0, 1560.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.254, -5.207, 0.0, 0.0, 0.0]}
{"step": 1560, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1561.0, 1.0, 1.0, 1.0, 1561.0, 1561.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.259, -5.212, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3630, "number_of_timesteps": 70546, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1561, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1562.0, 1.0, 1.0, 1.0, 1562.0, 1562.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.258, -5.212, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3632, "number_of_timesteps": 70618, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1562, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1563.0, 1.0, 1.0, 1.0, 1563.0, 1563.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.297, 0.0, 0.0, 0.0, -5.255, -5.208, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3633, "number_of_timesteps": 70641, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1563, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1564.0, 1.0, 1.0, 1.0, 1564.0, 1564.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.251, -5.205, 0.0, 0.0, 0.0]}
{"step": 1564, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1565.0, 1.0, 1.0, 1.0, 1565.0, 1565.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.255, -5.209, 0.0, 0.0, 0.0]}
{"step": 1565, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1566.0, 1.0, 1.0, 1.0, 1566.0, 1566.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.289, 0.0, 0.0, 0.0, -5.252, -5.206, 0.0, 0.0, 0.0]}
{"step": 1566, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1567.0, 1.0, 1.0, 1.0, 1567.0, 1567.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.286, 0.0, 0.0, 0.0, -5.249, -5.202, 0.0, 0.0, 0.0]}
{"eval_score": 28.8, "number_of_episodes": 3640}
{"step": 1567, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1568.0, 1.0, 1.0, 1.0, 1568.0, 1568.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.283, 0.0, 0.0, 0.0, -5.245, -5.199, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3642, "number_of_timesteps": 70931, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 1568, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1569.0, 1.0, 1.0, 1.0, 1569.0, 1569.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.284, 0.0, 0.0, 0.0, -5.242, -5.2, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3643, "number_of_timesteps": 70951, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1569, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1570.0, 1.0, 1.0, 1.0, 1570.0, 1570.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.239, -5.196, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3644, "number_of_timesteps": 70973, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1570, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1571.0, 1.0, 1.0, 1.0, 1571.0, 1571.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.238, -5.196, 0.0, 0.0, 0.0]}
{"step": 1571, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1572.0, 1.0, 1.0, 1.0, 1572.0, 1572.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.283, 0.0, 0.0, 0.0, -5.238, -5.192, 0.0, 0.0, 0.0]}
{"step": 1572, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1573.0, 1.0, 1.0, 1.0, 1573.0, 1573.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.283, 0.0, 0.0, 0.0, -5.238, -5.192, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3648, "number_of_timesteps": 71089, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1573, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1574.0, 1.0, 1.0, 1.0, 1574.0, 1574.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.235, -5.188, 0.0, 0.0, 0.0]}
{"step": 1574, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1575.0, 1.0, 1.0, 1.0, 1575.0, 1575.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.231, -5.185, 0.0, 0.0, 0.0]}
{"step": 1575, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1576.0, 1.0, 1.0, 1.0, 1576.0, 1576.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.228, -5.186, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3653, "number_of_timesteps": 71288, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"step": 1576, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1577.0, 1.0, 1.0, 1.0, 1577.0, 1577.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.229, -5.186, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3655, "number_of_timesteps": 71377, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 1577, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1578.0, 1.0, 1.0, 1.0, 1578.0, 1578.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.226, -5.186, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3655, "number_of_timesteps": 71377, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1578, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1579.0, 1.0, 1.0, 1.0, 1579.0, 1579.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.285, 0.0, 0.0, 0.0, -5.23, -5.191, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3655, "number_of_timesteps": 71377, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1579, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1580.0, 1.0, 1.0, 1.0, 1580.0, 1580.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.286, 0.0, 0.0, 0.0, -5.23, -5.191, 0.0, 0.0, 0.0]}
{"step": 1580, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1581.0, 1.0, 1.0, 1.0, 1581.0, 1581.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.289, 0.0, 0.0, 0.0, -5.233, -5.194, 0.0, 0.0, 0.0]}
{"step": 1581, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1582.0, 1.0, 1.0, 1.0, 1582.0, 1582.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.237, -5.197, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3664, "number_of_timesteps": 71595, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1582, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1583.0, 1.0, 1.0, 1.0, 1583.0, 1583.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.295, 0.0, 0.0, 0.0, -5.237, -5.194, 0.0, 0.0, 0.0]}
{"step": 1583, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1584.0, 1.0, 1.0, 1.0, 1584.0, 1584.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.296, 0.0, 0.0, 0.0, -5.238, -5.191, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3666, "number_of_timesteps": 71696, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"step": 1584, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1585.0, 1.0, 1.0, 1.0, 1585.0, 1585.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.297, 0.0, 0.0, 0.0, -5.235, -5.191, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3668, "number_of_timesteps": 71738, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1585, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1586.0, 1.0, 1.0, 1.0, 1586.0, 1586.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.295, 0.0, 0.0, 0.0, -5.232, -5.188, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3668, "number_of_timesteps": 71738, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 1586, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1587.0, 1.0, 1.0, 1.0, 1587.0, 1587.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.292, 0.0, 0.0, 0.0, -5.239, -5.196, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3669, "number_of_timesteps": 71764, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1587, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1588.0, 1.0, 1.0, 1.0, 1588.0, 1588.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.289, 0.0, 0.0, 0.0, -5.236, -5.193, 0.0, 0.0, 0.0]}
{"step": 1588, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1589.0, 1.0, 1.0, 1.0, 1589.0, 1589.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.286, 0.0, 0.0, 0.0, -5.233, -5.189, 0.0, 0.0, 0.0]}
{"step": 1589, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1590.0, 1.0, 1.0, 1.0, 1590.0, 1590.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.287, 0.0, 0.0, 0.0, -5.23, -5.19, 0.0, 0.0, 0.0]}
{"step": 1590, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1591.0, 1.0, 1.0, 1.0, 1591.0, 1591.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.285, 0.0, 0.0, 0.0, -5.226, -5.186, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3675, "number_of_timesteps": 71942, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1591, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1592.0, 1.0, 1.0, 1.0, 1592.0, 1592.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.29, 0.0, 0.0, 0.0, -5.231, -5.191, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3676, "number_of_timesteps": 71957, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 1592, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1593.0, 1.0, 1.0, 1.0, 1593.0, 1593.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.29, 0.0, 0.0, 0.0, -5.23, -5.187, 0.0, 0.0, 0.0]}
{"step": 1593, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1594.0, 1.0, 1.0, 1.0, 1594.0, 1594.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.293, 0.0, 0.0, 0.0, -5.233, -5.19, 0.0, 0.0, 0.0]}
{"step": 1594, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1595.0, 1.0, 1.0, 1.0, 1595.0, 1595.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.298, 0.0, 0.0, 0.0, -5.237, -5.194, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3681, "number_of_timesteps": 72139, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1595, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1596.0, 1.0, 1.0, 1.0, 1596.0, 1596.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.295, 0.0, 0.0, 0.0, -5.234, -5.191, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3681, "number_of_timesteps": 72139, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 1596, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1597.0, 1.0, 1.0, 1.0, 1597.0, 1597.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.292, 0.0, 0.0, 0.0, -5.238, -5.196, 0.0, 0.0, 0.0]}
{"step": 1597, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1598.0, 1.0, 1.0, 1.0, 1598.0, 1598.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.29, 0.0, 0.0, 0.0, -5.244, -5.201, 0.0, 0.0, 0.0]}
{"step": 1598, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1599.0, 1.0, 1.0, 1.0, 1599.0, 1599.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.287, 0.0, 0.0, 0.0, -5.25, -5.207, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3684, "number_of_timesteps": 72300, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"step": 1599, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1600.0, 1.0, 1.0, 1.0, 1600.0, 1600.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.287, 0.0, 0.0, 0.0, -5.247, -5.207, 0.0, 0.0, 0.0]}
{"step": 1600, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1601.0, 1.0, 1.0, 1.0, 1601.0, 1601.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.284, 0.0, 0.0, 0.0, -5.258, -5.218, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3686, "number_of_timesteps": 72369, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 1601, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1602.0, 1.0, 1.0, 1.0, 1602.0, 1602.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.285, 0.0, 0.0, 0.0, -5.257, -5.214, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3687, "number_of_timesteps": 72381, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1602, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1603.0, 1.0, 1.0, 1.0, 1603.0, 1603.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.286, 0.0, 0.0, 0.0, -5.257, -5.215, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3689, "number_of_timesteps": 72435, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1603, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1604.0, 1.0, 1.0, 1.0, 1604.0, 1604.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.283, 0.0, 0.0, 0.0, -5.254, -5.211, 0.0, 0.0, 0.0]}
{"step": 1604, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1605.0, 1.0, 1.0, 1.0, 1605.0, 1605.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.283, 0.0, 0.0, 0.0, -5.251, -5.211, 0.0, 0.0, 0.0]}
{"step": 1605, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1606.0, 1.0, 1.0, 1.0, 1606.0, 1606.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.283, 0.0, 0.0, 0.0, -5.25, -5.208, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3694, "number_of_timesteps": 72711, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1606, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1607.0, 1.0, 1.0, 1.0, 1607.0, 1607.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.284, 0.0, 0.0, 0.0, -5.251, -5.208, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3696, "number_of_timesteps": 72790, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1607, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1608.0, 1.0, 1.0, 1.0, 1608.0, 1608.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.289, 0.0, 0.0, 0.0, -5.256, -5.213, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3698, "number_of_timesteps": 72842, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
{"step": 1608, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1609.0, 1.0, 1.0, 1.0, 1609.0, 1609.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.287, 0.0, 0.0, 0.0, -5.252, -5.21, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3699, "number_of_timesteps": 72861, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 1609, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1610.0, 1.0, 1.0, 1.0, 1610.0, 1610.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.287, 0.0, 0.0, 0.0, -5.249, -5.209, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3699, "number_of_timesteps": 72861, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 1610, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1611.0, 1.0, 1.0, 1.0, 1611.0, 1611.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.285, 0.0, 0.0, 0.0, -5.254, -5.215, 0.0, 0.0, 0.0]}
{"step": 1611, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1612.0, 1.0, 1.0, 1.0, 1612.0, 1612.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.261, -5.221, 0.0, 0.0, 0.0]}
{"step": 1612, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1613.0, 1.0, 1.0, 1.0, 1613.0, 1613.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.283, 0.0, 0.0, 0.0, -5.257, -5.221, 0.0, 0.0, 0.0]}
{"step": 1613, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1614.0, 1.0, 1.0, 1.0, 1614.0, 1614.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.262, -5.226, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3705, "number_of_timesteps": 73064, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1614, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1615.0, 1.0, 1.0, 1.0, 1615.0, 1615.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.261, -5.222, 0.0, 0.0, 0.0]}
{"step": 1615, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1616.0, 1.0, 1.0, 1.0, 1616.0, 1616.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.261, -5.219, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3709, "number_of_timesteps": 73178, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1616, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1617.0, 1.0, 1.0, 1.0, 1617.0, 1617.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.284, 0.0, 0.0, 0.0, -5.258, -5.222, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3710, "number_of_timesteps": 73194, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 1617, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1618.0, 1.0, 1.0, 1.0, 1618.0, 1618.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.255, -5.218, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3712, "number_of_timesteps": 73260, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1618, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1619.0, 1.0, 1.0, 1.0, 1619.0, 1619.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.251, -5.215, 0.0, 0.0, 0.0]}
{"step": 1619, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1620.0, 1.0, 1.0, 1.0, 1620.0, 1620.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.248, -5.212, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3715, "number_of_timesteps": 73355, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1620, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1621.0, 1.0, 1.0, 1.0, 1621.0, 1621.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.248, -5.211, 0.0, 0.0, 0.0]}
{"step": 1621, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1622.0, 1.0, 1.0, 1.0, 1622.0, 1622.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.247, -5.211, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3719, "number_of_timesteps": 73456, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1622, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1623.0, 1.0, 1.0, 1.0, 1623.0, 1623.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.247, -5.211, 0.0, 0.0, 0.0]}
{"step": 1623, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1624.0, 1.0, 1.0, 1.0, 1624.0, 1624.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.248, -5.212, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3721, "number_of_timesteps": 73496, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 1624, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1625.0, 1.0, 1.0, 1.0, 1625.0, 1625.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.256, -5.22, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3721, "number_of_timesteps": 73496, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1625, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1626.0, 1.0, 1.0, 1.0, 1626.0, 1626.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.257, -5.221, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3722, "number_of_timesteps": 73515, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1626, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1627.0, 1.0, 1.0, 1.0, 1627.0, 1627.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.254, -5.221, 0.0, 0.0, 0.0]}
{"step": 1627, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1628.0, 1.0, 1.0, 1.0, 1628.0, 1628.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.251, -5.221, 0.0, 0.0, 0.0]}
{"step": 1628, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1629.0, 1.0, 1.0, 1.0, 1629.0, 1629.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.251, -5.222, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3725, "number_of_timesteps": 73577, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 1629, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1630.0, 1.0, 1.0, 1.0, 1630.0, 1630.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.248, -5.218, 0.0, 0.0, 0.0]}
{"step": 1630, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1631.0, 1.0, 1.0, 1.0, 1631.0, 1631.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.251, -5.222, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3726, "number_of_timesteps": 73632, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 1631, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1632.0, 1.0, 1.0, 1.0, 1632.0, 1632.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.25, -5.221, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3727, "number_of_timesteps": 73709, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1632, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1633.0, 1.0, 1.0, 1.0, 1633.0, 1633.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.25, -5.218, 0.0, 0.0, 0.0]}
{"step": 1633, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1634.0, 1.0, 1.0, 1.0, 1634.0, 1634.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.26, -5.228, 0.0, 0.0, 0.0]}
{"step": 1634, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1635.0, 1.0, 1.0, 1.0, 1635.0, 1635.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.261, -5.229, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3729, "number_of_timesteps": 73807, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1635, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1636.0, 1.0, 1.0, 1.0, 1636.0, 1636.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.26, -5.228, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3732, "number_of_timesteps": 74021, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1636, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1637.0, 1.0, 1.0, 1.0, 1637.0, 1637.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.257, -5.228, 0.0, 0.0, 0.0]}
{"step": 1637, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1638.0, 1.0, 1.0, 1.0, 1638.0, 1638.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.254, -5.227, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3733, "number_of_timesteps": 74032, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1638, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1639.0, 1.0, 1.0, 1.0, 1639.0, 1639.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.257, -5.231, 0.0, 0.0, 0.0]}
{"step": 1639, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1640.0, 1.0, 1.0, 1.0, 1640.0, 1640.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.257, -5.23, 0.0, 0.0, 0.0]}
{"step": 1640, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1641.0, 1.0, 1.0, 1.0, 1641.0, 1641.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.262, -5.235, 0.0, 0.0, 0.0]}
{"step": 1641, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1642.0, 1.0, 1.0, 1.0, 1642.0, 1642.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.258, -5.236, 0.0, 0.0, 0.0]}
{"step": 1642, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1643.0, 1.0, 1.0, 1.0, 1643.0, 1643.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.265, -5.243, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3739, "number_of_timesteps": 74352, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1643, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1644.0, 1.0, 1.0, 1.0, 1644.0, 1644.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.269, -5.246, 0.0, 0.0, 0.0]}
{"step": 1644, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1645.0, 1.0, 1.0, 1.0, 1645.0, 1645.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.266, -5.246, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3741, "number_of_timesteps": 74504, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1645, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1646.0, 1.0, 1.0, 1.0, 1646.0, 1646.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.265, -5.246, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3742, "number_of_timesteps": 74553, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
{"step": 1646, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1647.0, 1.0, 1.0, 1.0, 1647.0, 1647.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.262, -5.242, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3742, "number_of_timesteps": 74553, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 1647, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1648.0, 1.0, 1.0, 1.0, 1648.0, 1648.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.261, -5.242, 0.0, 0.0, 0.0]}
{"step": 1648, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1649.0, 1.0, 1.0, 1.0, 1649.0, 1649.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.261, -5.242, 0.0, 0.0, 0.0]}
{"step": 1649, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1650.0, 1.0, 1.0, 1.0, 1650.0, 1650.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.261, -5.241, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3748, "number_of_timesteps": 74817, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 1650, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1651.0, 1.0, 1.0, 1.0, 1651.0, 1651.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.261, -5.242, 0.0, 0.0, 0.0]}
{"step": 1651, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1652.0, 1.0, 1.0, 1.0, 1652.0, 1652.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.264, -5.245, 0.0, 0.0, 0.0]}
{"step": 1652, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1653.0, 1.0, 1.0, 1.0, 1653.0, 1653.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.266, -5.246, 0.0, 0.0, 0.0]}
{"step": 1653, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1654.0, 1.0, 1.0, 1.0, 1654.0, 1654.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.265, -5.246, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3750, "number_of_timesteps": 74868, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1654, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1655.0, 1.0, 1.0, 1.0, 1655.0, 1655.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.265, -5.243, 0.0, 0.0, 0.0]}
{"step": 1655, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1656.0, 1.0, 1.0, 1.0, 1656.0, 1656.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.262, -5.24, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3751, "number_of_timesteps": 74918, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 1656, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1657.0, 1.0, 1.0, 1.0, 1657.0, 1657.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.265, -5.243, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3753, "number_of_timesteps": 75013, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1657, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1658.0, 1.0, 1.0, 1.0, 1658.0, 1658.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.262, -5.243, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3754, "number_of_timesteps": 75062, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
{"step": 1658, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1659.0, 1.0, 1.0, 1.0, 1659.0, 1659.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.259, -5.24, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3755, "number_of_timesteps": 75141, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
{"step": 1659, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1660.0, 1.0, 1.0, 1.0, 1660.0, 1660.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.258, -5.239, 0.0, 0.0, 0.0]}
{"step": 1660, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1661.0, 1.0, 1.0, 1.0, 1661.0, 1661.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.258, -5.236, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3757, "number_of_timesteps": 75277, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 1661, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1662.0, 1.0, 1.0, 1.0, 1662.0, 1662.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.255, -5.233, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3761, "number_of_timesteps": 75372, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1662, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1663.0, 1.0, 1.0, 1.0, 1663.0, 1663.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.261, -5.239, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3762, "number_of_timesteps": 75443, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 1663, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1664.0, 1.0, 1.0, 1.0, 1664.0, 1664.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.262, -5.24, 0.0, 0.0, 0.0]}
{"step": 1664, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1665.0, 1.0, 1.0, 1.0, 1665.0, 1665.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.259, -5.237, 0.0, 0.0, 0.0]}
{"step": 1665, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1666.0, 1.0, 1.0, 1.0, 1666.0, 1666.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.256, -5.234, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3765, "number_of_timesteps": 75560, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1666, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1667.0, 1.0, 1.0, 1.0, 1667.0, 1667.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.253, -5.231, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3766, "number_of_timesteps": 75576, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 1667, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1668.0, 1.0, 1.0, 1.0, 1668.0, 1668.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.25, -5.228, 0.0, 0.0, 0.0]}
{"step": 1668, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1669.0, 1.0, 1.0, 1.0, 1669.0, 1669.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.249, -5.227, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3769, "number_of_timesteps": 75675, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 1669, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1670.0, 1.0, 1.0, 1.0, 1670.0, 1670.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.249, -5.227, 0.0, 0.0, 0.0]}
{"eval_score": 36.7, "number_of_episodes": 3771}
{"number_of_episodes": 3771, "number_of_timesteps": 75715, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 1670, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1671.0, 1.0, 1.0, 1.0, 1671.0, 1671.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.246, -5.224, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3771, "number_of_timesteps": 75715, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 1671, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1672.0, 1.0, 1.0, 1.0, 1672.0, 1672.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.243, -5.224, 0.0, 0.0, 0.0]}
{"step": 1672, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1673.0, 1.0, 1.0, 1.0, 1673.0, 1673.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.244, -5.224, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3775, "number_of_timesteps": 75815, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 1673, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1674.0, 1.0, 1.0, 1.0, 1674.0, 1674.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.248, -5.229, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3776, "number_of_timesteps": 75845, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.20000000000000107},
{"step": 1674, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1675.0, 1.0, 1.0, 1.0, 1675.0, 1675.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.247, -5.228, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3776, "number_of_timesteps": 75845, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.20000000000000107},
{"step": 1675, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1676.0, 1.0, 1.0, 1.0, 1676.0, 1676.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.244, -5.225, 0.0, 0.0, 0.0]}
{"step": 1676, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1677.0, 1.0, 1.0, 1.0, 1677.0, 1677.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.264, 0.0, 0.0, 0.0, -5.241, -5.222, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3780, "number_of_timesteps": 76030, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.1999999999999993},
{"step": 1677, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1678.0, 1.0, 1.0, 1.0, 1678.0, 1678.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.242, -5.223, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3780, "number_of_timesteps": 76030, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.006111111111111099, "biggest_recent_change": 0.24999999999999822},
{"step": 1678, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1679.0, 1.0, 1.0, 1.0, 1679.0, 1679.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.242, -5.223, 0.0, 0.0, 0.0]}
{"step": 1679, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1680.0, 1.0, 1.0, 1.0, 1680.0, 1680.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.263, 0.0, 0.0, 0.0, -5.247, -5.228, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3785, "number_of_timesteps": 76180, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1680, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1681.0, 1.0, 1.0, 1.0, 1681.0, 1681.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.26, 0.0, 0.0, 0.0, -5.253, -5.234, 0.0, 0.0, 0.0]}
{"step": 1681, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1682.0, 1.0, 1.0, 1.0, 1682.0, 1682.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.26, 0.0, 0.0, 0.0, -5.253, -5.234, 0.0, 0.0, 0.0]}
{"step": 1682, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1683.0, 1.0, 1.0, 1.0, 1683.0, 1683.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.258, 0.0, 0.0, 0.0, -5.256, -5.237, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3788, "number_of_timesteps": 76273, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0027777777777777584, "biggest_recent_change": 0.14999999999999858},
{"step": 1683, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1684.0, 1.0, 1.0, 1.0, 1684.0, 1684.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.259, 0.0, 0.0, 0.0, -5.253, -5.238, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3789, "number_of_timesteps": 76291, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0027777777777777584, "biggest_recent_change": 0.24999999999999822},
{"step": 1684, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1685.0, 1.0, 1.0, 1.0, 1685.0, 1685.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.263, 0.0, 0.0, 0.0, -5.256, -5.241, 0.0, 0.0, 0.0]}
{"step": 1685, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1686.0, 1.0, 1.0, 1.0, 1686.0, 1686.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.264, -5.249, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3790, "number_of_timesteps": 76321, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.24999999999999822},
{"step": 1686, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1687.0, 1.0, 1.0, 1.0, 1687.0, 1687.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.261, -5.246, 0.0, 0.0, 0.0]}
{"step": 1687, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1688.0, 1.0, 1.0, 1.0, 1688.0, 1688.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.258, -5.245, 0.0, 0.0, 0.0]}
{"step": 1688, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1689.0, 1.0, 1.0, 1.0, 1689.0, 1689.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.255, -5.245, 0.0, 0.0, 0.0]}
{"step": 1689, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1690.0, 1.0, 1.0, 1.0, 1690.0, 1690.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.252, -5.244, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3795, "number_of_timesteps": 76594, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0027777777777777584, "biggest_recent_change": 0.24999999999999822},
{"step": 1690, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1691.0, 1.0, 1.0, 1.0, 1691.0, 1691.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.252, -5.241, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3796, "number_of_timesteps": 76648, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.24999999999999822},
{"step": 1691, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1692.0, 1.0, 1.0, 1.0, 1692.0, 1692.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.251, -5.24, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3798, "number_of_timesteps": 76738, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.1999999999999993},
{"step": 1692, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1693.0, 1.0, 1.0, 1.0, 1693.0, 1693.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.248, -5.237, 0.0, 0.0, 0.0]}
{"step": 1693, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1694.0, 1.0, 1.0, 1.0, 1694.0, 1694.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.248, -5.237, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3801, "number_of_timesteps": 76827, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 1694, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1695.0, 1.0, 1.0, 1.0, 1695.0, 1695.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.247, -5.236, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3802, "number_of_timesteps": 76916, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.24999999999999822},
{"step": 1695, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1696.0, 1.0, 1.0, 1.0, 1696.0, 1696.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.244, -5.233, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3805, "number_of_timesteps": 76998, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1696, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1697.0, 1.0, 1.0, 1.0, 1697.0, 1697.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.263, 0.0, 0.0, 0.0, -5.249, -5.238, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3807, "number_of_timesteps": 77025, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.14999999999999858},
{"step": 1697, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1698.0, 1.0, 1.0, 1.0, 1698.0, 1698.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.263, 0.0, 0.0, 0.0, -5.246, -5.237, 0.0, 0.0, 0.0]}
{"step": 1698, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1699.0, 1.0, 1.0, 1.0, 1699.0, 1699.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.26, 0.0, 0.0, 0.0, -5.252, -5.244, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3812, "number_of_timesteps": 77144, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1699, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1700.0, 1.0, 1.0, 1.0, 1700.0, 1700.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.26, 0.0, 0.0, 0.0, -5.252, -5.243, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3813, "number_of_timesteps": 77163, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1700, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1701.0, 1.0, 1.0, 1.0, 1701.0, 1701.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.26, 0.0, 0.0, 0.0, -5.251, -5.24, 0.0, 0.0, 0.0]}
{"step": 1701, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1702.0, 1.0, 1.0, 1.0, 1702.0, 1702.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.251, -5.237, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3817, "number_of_timesteps": 77248, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 1702, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1703.0, 1.0, 1.0, 1.0, 1703.0, 1703.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.262, 0.0, 0.0, 0.0, -5.252, -5.238, 0.0, 0.0, 0.0]}
{"step": 1703, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1704.0, 1.0, 1.0, 1.0, 1704.0, 1704.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.263, 0.0, 0.0, 0.0, -5.253, -5.239, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3820, "number_of_timesteps": 77324, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1704, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1705.0, 1.0, 1.0, 1.0, 1705.0, 1705.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.257, -5.244, 0.0, 0.0, 0.0]}
{"step": 1705, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1706.0, 1.0, 1.0, 1.0, 1706.0, 1706.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.258, -5.244, 0.0, 0.0, 0.0]}
{"step": 1706, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1707.0, 1.0, 1.0, 1.0, 1707.0, 1707.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.259, -5.241, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3825, "number_of_timesteps": 77536, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1707, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1708.0, 1.0, 1.0, 1.0, 1708.0, 1708.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.256, -5.238, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3827, "number_of_timesteps": 77577, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.24999999999999822},
{"step": 1708, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1709.0, 1.0, 1.0, 1.0, 1709.0, 1709.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.256, -5.238, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3828, "number_of_timesteps": 77611, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1709, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1710.0, 1.0, 1.0, 1.0, 1710.0, 1710.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.262, -5.243, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3832, "number_of_timesteps": 77732, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1710, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1711.0, 1.0, 1.0, 1.0, 1711.0, 1711.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.269, -5.251, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3834, "number_of_timesteps": 77780, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.20000000000000107},
{"step": 1711, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1712.0, 1.0, 1.0, 1.0, 1712.0, 1712.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.266, -5.248, 0.0, 0.0, 0.0]}
{"step": 1712, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1713.0, 1.0, 1.0, 1.0, 1713.0, 1713.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.27, -5.252, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3837, "number_of_timesteps": 77842, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.20000000000000107},
{"step": 1713, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1714.0, 1.0, 1.0, 1.0, 1714.0, 1714.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.27, -5.251, 0.0, 0.0, 0.0]}
{"step": 1714, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1715.0, 1.0, 1.0, 1.0, 1715.0, 1715.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.266, -5.248, 0.0, 0.0, 0.0]}
{"step": 1715, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1716.0, 1.0, 1.0, 1.0, 1716.0, 1716.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.266, -5.248, 0.0, 0.0, 0.0]}
{"step": 1716, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1717.0, 1.0, 1.0, 1.0, 1717.0, 1717.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.266, -5.247, 0.0, 0.0, 0.0]}
{"step": 1717, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1718.0, 1.0, 1.0, 1.0, 1718.0, 1718.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.265, -5.247, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3847, "number_of_timesteps": 78059, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1718, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1719.0, 1.0, 1.0, 1.0, 1719.0, 1719.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.264, -5.244, 0.0, 0.0, 0.0]}
{"step": 1719, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1720.0, 1.0, 1.0, 1.0, 1720.0, 1720.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.264, -5.241, 0.0, 0.0, 0.0]}
{"step": 1720, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1721.0, 1.0, 1.0, 1.0, 1721.0, 1721.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.264, -5.238, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3852, "number_of_timesteps": 78192, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1721, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1722.0, 1.0, 1.0, 1.0, 1722.0, 1722.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.266, -5.241, 0.0, 0.0, 0.0]}
{"step": 1722, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1723.0, 1.0, 1.0, 1.0, 1723.0, 1723.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.264, -5.238, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3856, "number_of_timesteps": 78288, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1723, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1724.0, 1.0, 1.0, 1.0, 1724.0, 1724.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.269, -5.242, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3857, "number_of_timesteps": 78327, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1724, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1725.0, 1.0, 1.0, 1.0, 1725.0, 1725.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.266, -5.239, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3859, "number_of_timesteps": 78373, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1725, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1726.0, 1.0, 1.0, 1.0, 1726.0, 1726.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.265, -5.236, 0.0, 0.0, 0.0]}
{"step": 1726, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1727.0, 1.0, 1.0, 1.0, 1727.0, 1727.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.267, -5.233, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3862, "number_of_timesteps": 78468, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.20000000000000107},
{"step": 1727, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1728.0, 1.0, 1.0, 1.0, 1728.0, 1728.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.263, -5.23, 0.0, 0.0, 0.0]}
{"step": 1728, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1729.0, 1.0, 1.0, 1.0, 1729.0, 1729.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.263, -5.227, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3866, "number_of_timesteps": 78566, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1729, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1730.0, 1.0, 1.0, 1.0, 1730.0, 1730.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.263, -5.227, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3868, "number_of_timesteps": 78598, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1730, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1731.0, 1.0, 1.0, 1.0, 1731.0, 1731.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.262, -5.227, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3869, "number_of_timesteps": 78638, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.20000000000000107},
{"step": 1731, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1732.0, 1.0, 1.0, 1.0, 1732.0, 1732.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.262, -5.226, 0.0, 0.0, 0.0]}
{"step": 1732, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1733.0, 1.0, 1.0, 1.0, 1733.0, 1733.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.262, -5.226, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3873, "number_of_timesteps": 78718, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1733, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1734.0, 1.0, 1.0, 1.0, 1734.0, 1734.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.264, 0.0, 0.0, 0.0, -5.267, -5.231, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3876, "number_of_timesteps": 78847, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1734, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1735.0, 1.0, 1.0, 1.0, 1735.0, 1735.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.264, -5.228, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3878, "number_of_timesteps": 78873, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1735, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1736.0, 1.0, 1.0, 1.0, 1736.0, 1736.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.259, 0.0, 0.0, 0.0, -5.261, -5.225, 0.0, 0.0, 0.0]}
{"step": 1736, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1737.0, 1.0, 1.0, 1.0, 1737.0, 1737.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.256, 0.0, 0.0, 0.0, -5.258, -5.222, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3879, "number_of_timesteps": 78906, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1737, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1738.0, 1.0, 1.0, 1.0, 1738.0, 1738.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.262, -5.226, 0.0, 0.0, 0.0]}
{"step": 1738, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1739.0, 1.0, 1.0, 1.0, 1739.0, 1739.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.265, -5.229, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3883, "number_of_timesteps": 78986, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1739, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1740.0, 1.0, 1.0, 1.0, 1740.0, 1740.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.268, -5.232, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3884, "number_of_timesteps": 79009, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1740, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1741.0, 1.0, 1.0, 1.0, 1741.0, 1741.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.265, -5.23, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3887, "number_of_timesteps": 79075, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1741, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1742.0, 1.0, 1.0, 1.0, 1742.0, 1742.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.265, -5.227, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3890, "number_of_timesteps": 79181, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.20000000000000107},
{"step": 1742, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1743.0, 1.0, 1.0, 1.0, 1743.0, 1743.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.264, 0.0, 0.0, 0.0, -5.262, -5.224, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3890, "number_of_timesteps": 79181, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1743, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1744.0, 1.0, 1.0, 1.0, 1744.0, 1744.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.267, -5.229, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3890, "number_of_timesteps": 79181, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1744, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1745.0, 1.0, 1.0, 1.0, 1745.0, 1745.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.266, -5.227, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3894, "number_of_timesteps": 79270, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.14999999999999858},
{"step": 1745, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1746.0, 1.0, 1.0, 1.0, 1746.0, 1746.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.263, -5.227, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3896, "number_of_timesteps": 79311, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1746, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1747.0, 1.0, 1.0, 1.0, 1747.0, 1747.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.262, -5.227, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3898, "number_of_timesteps": 79361, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1747, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1748.0, 1.0, 1.0, 1.0, 1748.0, 1748.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.262, -5.224, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3899, "number_of_timesteps": 79374, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1748, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1749.0, 1.0, 1.0, 1.0, 1749.0, 1749.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.259, -5.221, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3899, "number_of_timesteps": 79374, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.20000000000000107},
{"step": 1749, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1750.0, 1.0, 1.0, 1.0, 1750.0, 1750.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.26, -5.222, 0.0, 0.0, 0.0]}
{"eval_score": 22.3, "number_of_episodes": 3902}
{"number_of_episodes": 3902, "number_of_timesteps": 79433, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.20000000000000107},
{"step": 1750, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1751.0, 1.0, 1.0, 1.0, 1751.0, 1751.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.264, 0.0, 0.0, 0.0, -5.257, -5.219, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3907, "number_of_timesteps": 79590, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1751, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1752.0, 1.0, 1.0, 1.0, 1752.0, 1752.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.257, -5.219, 0.0, 0.0, 0.0]}
{"step": 1752, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1753.0, 1.0, 1.0, 1.0, 1753.0, 1753.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.257, -5.218, 0.0, 0.0, 0.0]}
{"step": 1753, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1754.0, 1.0, 1.0, 1.0, 1754.0, 1754.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.257, -5.218, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3911, "number_of_timesteps": 79667, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1754, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1755.0, 1.0, 1.0, 1.0, 1755.0, 1755.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.257, -5.218, 0.0, 0.0, 0.0]}
{"step": 1755, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1756.0, 1.0, 1.0, 1.0, 1756.0, 1756.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.257, -5.218, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3915, "number_of_timesteps": 79740, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1756, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1757.0, 1.0, 1.0, 1.0, 1757.0, 1757.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.263, -5.225, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3916, "number_of_timesteps": 79769, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1757, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1758.0, 1.0, 1.0, 1.0, 1758.0, 1758.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.268, -5.229, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3920, "number_of_timesteps": 79970, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1758, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1759.0, 1.0, 1.0, 1.0, 1759.0, 1759.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.269, -5.226, 0.0, 0.0, 0.0]}
{"step": 1759, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1760.0, 1.0, 1.0, 1.0, 1760.0, 1760.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.269, -5.223, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3923, "number_of_timesteps": 80034, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 1760, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1761.0, 1.0, 1.0, 1.0, 1761.0, 1761.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.27, -5.224, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3926, "number_of_timesteps": 80081, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1761, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1762.0, 1.0, 1.0, 1.0, 1762.0, 1762.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.271, -5.224, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3928, "number_of_timesteps": 80123, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.14999999999999858},
{"step": 1762, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1763.0, 1.0, 1.0, 1.0, 1763.0, 1763.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.268, -5.224, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3928, "number_of_timesteps": 80123, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1763, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1764.0, 1.0, 1.0, 1.0, 1764.0, 1764.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.272, -5.228, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3930, "number_of_timesteps": 80162, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.24999999999999822},
{"step": 1764, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1765.0, 1.0, 1.0, 1.0, 1765.0, 1765.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.272, -5.225, 0.0, 0.0, 0.0]}
{"step": 1765, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1766.0, 1.0, 1.0, 1.0, 1766.0, 1766.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.283, 0.0, 0.0, 0.0, -5.273, -5.222, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3936, "number_of_timesteps": 80326, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 1766, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1767.0, 1.0, 1.0, 1.0, 1767.0, 1767.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.27, -5.219, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3939, "number_of_timesteps": 80392, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 1767, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1768.0, 1.0, 1.0, 1.0, 1768.0, 1768.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.269, -5.219, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3941, "number_of_timesteps": 80418, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.24999999999999822},
{"step": 1768, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1769.0, 1.0, 1.0, 1.0, 1769.0, 1769.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.266, -5.216, 0.0, 0.0, 0.0]}
{"step": 1769, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1770.0, 1.0, 1.0, 1.0, 1770.0, 1770.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.263, -5.213, 0.0, 0.0, 0.0]}
{"step": 1770, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1771.0, 1.0, 1.0, 1.0, 1771.0, 1771.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.26, -5.21, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3950, "number_of_timesteps": 80582, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.14999999999999858},
{"step": 1771, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1772.0, 1.0, 1.0, 1.0, 1772.0, 1772.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.257, -5.211, 0.0, 0.0, 0.0]}
{"step": 1772, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1773.0, 1.0, 1.0, 1.0, 1773.0, 1773.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.254, -5.211, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3956, "number_of_timesteps": 80683, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 1773, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1774.0, 1.0, 1.0, 1.0, 1774.0, 1774.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.254, -5.21, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3958, "number_of_timesteps": 80719, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 1774, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1775.0, 1.0, 1.0, 1.0, 1775.0, 1775.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.254, -5.21, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3958, "number_of_timesteps": 80719, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.24999999999999822},
{"step": 1775, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1776.0, 1.0, 1.0, 1.0, 1776.0, 1776.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.258, -5.214, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3962, "number_of_timesteps": 80779, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 1776, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1777.0, 1.0, 1.0, 1.0, 1777.0, 1777.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.255, -5.211, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3967, "number_of_timesteps": 80887, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 1777, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1778.0, 1.0, 1.0, 1.0, 1778.0, 1778.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.259, -5.215, 0.0, 0.0, 0.0]}
{"step": 1778, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1779.0, 1.0, 1.0, 1.0, 1779.0, 1779.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.262, -5.219, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3971, "number_of_timesteps": 80945, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 1779, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1780.0, 1.0, 1.0, 1.0, 1780.0, 1780.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.259, -5.216, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3976, "number_of_timesteps": 81010, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 1780, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1781.0, 1.0, 1.0, 1.0, 1781.0, 1781.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.26, -5.216, 0.0, 0.0, 0.0]}
{"step": 1781, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1782.0, 1.0, 1.0, 1.0, 1782.0, 1782.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.259, -5.216, 0.0, 0.0, 0.0]}
{"step": 1782, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1783.0, 1.0, 1.0, 1.0, 1783.0, 1783.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.257, -5.214, 0.0, 0.0, 0.0]}
{"step": 1783, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1784.0, 1.0, 1.0, 1.0, 1784.0, 1784.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.257, -5.214, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3987, "number_of_timesteps": 81193, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1784, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1785.0, 1.0, 1.0, 1.0, 1785.0, 1785.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.254, -5.211, 0.0, 0.0, 0.0]}
{"step": 1785, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1786.0, 1.0, 1.0, 1.0, 1786.0, 1786.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.251, -5.208, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3991, "number_of_timesteps": 81248, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1786, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1787.0, 1.0, 1.0, 1.0, 1787.0, 1787.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.256, -5.213, 0.0, 0.0, 0.0]}
{"step": 1787, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1788.0, 1.0, 1.0, 1.0, 1788.0, 1788.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.26, -5.217, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3995, "number_of_timesteps": 81311, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 1788, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1789.0, 1.0, 1.0, 1.0, 1789.0, 1789.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.26, -5.217, 0.0, 0.0, 0.0]}
{"number_of_episodes": 3997, "number_of_timesteps": 81339, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.14999999999999858},
{"step": 1789, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1790.0, 1.0, 1.0, 1.0, 1790.0, 1790.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.257, -5.218, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4001, "number_of_timesteps": 81422, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"step": 1790, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1791.0, 1.0, 1.0, 1.0, 1791.0, 1791.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.258, -5.219, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4004, "number_of_timesteps": 81488, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 1791, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1792.0, 1.0, 1.0, 1.0, 1792.0, 1792.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.265, -5.225, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4006, "number_of_timesteps": 81517, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 1792, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1793.0, 1.0, 1.0, 1.0, 1793.0, 1793.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.262, -5.222, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4008, "number_of_timesteps": 81542, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.24999999999999822},
{"step": 1793, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1794.0, 1.0, 1.0, 1.0, 1794.0, 1794.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.259, -5.22, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4011, "number_of_timesteps": 81608, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"step": 1794, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1795.0, 1.0, 1.0, 1.0, 1795.0, 1795.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.259, -5.219, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4012, "number_of_timesteps": 81617, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1795, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1796.0, 1.0, 1.0, 1.0, 1796.0, 1796.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.258, -5.218, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4017, "number_of_timesteps": 81715, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.005000000000000012, "biggest_recent_change": 0.20000000000000107},
{"step": 1796, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1797.0, 1.0, 1.0, 1.0, 1797.0, 1797.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.255, -5.216, 0.0, 0.0, 0.0]}
{"step": 1797, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1798.0, 1.0, 1.0, 1.0, 1798.0, 1798.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.255, -5.215, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4021, "number_of_timesteps": 81781, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.005000000000000012, "biggest_recent_change": 0.24999999999999822},
{"step": 1798, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1799.0, 1.0, 1.0, 1.0, 1799.0, 1799.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.255, -5.212, 0.0, 0.0, 0.0]}
{"step": 1799, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1800.0, 1.0, 1.0, 1.0, 1800.0, 1800.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.255, -5.209, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4027, "number_of_timesteps": 81894, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.005555555555555536, "biggest_recent_change": 0.24999999999999822},
{"step": 1800, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1801.0, 1.0, 1.0, 1.0, 1801.0, 1801.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.254, -5.209, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4029, "number_of_timesteps": 81927, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.005555555555555536, "biggest_recent_change": 0.20000000000000107},
{"step": 1801, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1802.0, 1.0, 1.0, 1.0, 1802.0, 1802.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.251, -5.206, 0.0, 0.0, 0.0]}
{"eval_score": 16.9, "number_of_episodes": 4031}
{"number_of_episodes": 4031, "number_of_timesteps": 81953, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"step": 1802, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1803.0, 1.0, 1.0, 1.0, 1803.0, 1803.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.251, -5.203, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4035, "number_of_timesteps": 82022, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.005000000000000012, "biggest_recent_change": 0.14999999999999858},
{"step": 1803, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1804.0, 1.0, 1.0, 1.0, 1804.0, 1804.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.248, -5.203, 0.0, 0.0, 0.0]}
{"step": 1804, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1805.0, 1.0, 1.0, 1.0, 1805.0, 1805.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.245, -5.204, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4041, "number_of_timesteps": 82123, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1805, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1806.0, 1.0, 1.0, 1.0, 1806.0, 1806.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.246, -5.201, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4044, "number_of_timesteps": 82160, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 1806, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1807.0, 1.0, 1.0, 1.0, 1807.0, 1807.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.243, -5.198, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4047, "number_of_timesteps": 82195, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1807, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1808.0, 1.0, 1.0, 1.0, 1808.0, 1808.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.245, -5.2, 0.0, 0.0, 0.0]}
{"step": 1808, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1809.0, 1.0, 1.0, 1.0, 1809.0, 1809.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.244, -5.199, 0.0, 0.0, 0.0]}
{"step": 1809, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1810.0, 1.0, 1.0, 1.0, 1810.0, 1810.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.244, -5.2, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4057, "number_of_timesteps": 82340, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1810, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1811.0, 1.0, 1.0, 1.0, 1811.0, 1811.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.245, -5.2, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4060, "number_of_timesteps": 82373, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.24999999999999822},
{"step": 1811, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1812.0, 1.0, 1.0, 1.0, 1812.0, 1812.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.245, -5.2, 0.0, 0.0, 0.0]}
{"step": 1812, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1813.0, 1.0, 1.0, 1.0, 1813.0, 1813.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.245, -5.201, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4066, "number_of_timesteps": 82460, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1813, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1814.0, 1.0, 1.0, 1.0, 1814.0, 1814.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.249, -5.205, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4068, "number_of_timesteps": 82489, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000213},
{"step": 1814, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1815.0, 1.0, 1.0, 1.0, 1815.0, 1815.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.247, -5.204, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4072, "number_of_timesteps": 82552, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1815, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1816.0, 1.0, 1.0, 1.0, 1816.0, 1816.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.246, -5.204, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4075, "number_of_timesteps": 82590, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1816, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1817.0, 1.0, 1.0, 1.0, 1817.0, 1817.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.247, -5.204, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4076, "number_of_timesteps": 82607, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.1999999999999993},
{"step": 1817, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1818.0, 1.0, 1.0, 1.0, 1818.0, 1818.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.244, -5.201, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4081, "number_of_timesteps": 82677, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
{"step": 1818, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1819.0, 1.0, 1.0, 1.0, 1819.0, 1819.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.245, -5.202, 0.0, 0.0, 0.0]}
{"step": 1819, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1820.0, 1.0, 1.0, 1.0, 1820.0, 1820.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.244, -5.202, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4086, "number_of_timesteps": 82760, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1820, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1821.0, 1.0, 1.0, 1.0, 1821.0, 1821.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.242, -5.199, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4088, "number_of_timesteps": 82786, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1821, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1822.0, 1.0, 1.0, 1.0, 1822.0, 1822.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.244, -5.196, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4094, "number_of_timesteps": 82868, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1822, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1823.0, 1.0, 1.0, 1.0, 1823.0, 1823.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.244, -5.196, 0.0, 0.0, 0.0]}
{"step": 1823, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1824.0, 1.0, 1.0, 1.0, 1824.0, 1824.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.243, -5.196, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4098, "number_of_timesteps": 82924, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1824, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1825.0, 1.0, 1.0, 1.0, 1825.0, 1825.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.243, -5.196, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4102, "number_of_timesteps": 82983, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1825, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1826.0, 1.0, 1.0, 1.0, 1826.0, 1826.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.244, -5.193, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4106, "number_of_timesteps": 83044, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1826, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1827.0, 1.0, 1.0, 1.0, 1827.0, 1827.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.283, 0.0, 0.0, 0.0, -5.25, -5.199, 0.0, 0.0, 0.0]}
{"step": 1827, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1828.0, 1.0, 1.0, 1.0, 1828.0, 1828.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.284, 0.0, 0.0, 0.0, -5.25, -5.196, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4110, "number_of_timesteps": 83097, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
{"step": 1828, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1829.0, 1.0, 1.0, 1.0, 1829.0, 1829.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.285, 0.0, 0.0, 0.0, -5.25, -5.197, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4111, "number_of_timesteps": 83111, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1829, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1830.0, 1.0, 1.0, 1.0, 1830.0, 1830.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.256, -5.203, 0.0, 0.0, 0.0]}
{"step": 1830, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1831.0, 1.0, 1.0, 1.0, 1831.0, 1831.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.263, -5.21, 0.0, 0.0, 0.0]}
{"step": 1831, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1832.0, 1.0, 1.0, 1.0, 1832.0, 1832.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.265, -5.211, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4121, "number_of_timesteps": 83302, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1832, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1833.0, 1.0, 1.0, 1.0, 1833.0, 1833.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.271, -5.218, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4122, "number_of_timesteps": 83313, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1833, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1834.0, 1.0, 1.0, 1.0, 1834.0, 1834.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.272, -5.219, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4128, "number_of_timesteps": 83388, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 1834, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1835.0, 1.0, 1.0, 1.0, 1835.0, 1835.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.269, -5.216, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4131, "number_of_timesteps": 83442, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 1835, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1836.0, 1.0, 1.0, 1.0, 1836.0, 1836.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.27, -5.216, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4132, "number_of_timesteps": 83452, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1836, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1837.0, 1.0, 1.0, 1.0, 1837.0, 1837.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.277, -5.224, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4137, "number_of_timesteps": 83510, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1837, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1838.0, 1.0, 1.0, 1.0, 1838.0, 1838.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.28, -5.227, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4140, "number_of_timesteps": 83556, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1838, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1839.0, 1.0, 1.0, 1.0, 1839.0, 1839.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.28, -5.224, 0.0, 0.0, 0.0]}
{"step": 1839, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1840.0, 1.0, 1.0, 1.0, 1840.0, 1840.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.28, -5.221, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4146, "number_of_timesteps": 83649, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 1840, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1841.0, 1.0, 1.0, 1.0, 1841.0, 1841.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.279, -5.221, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4148, "number_of_timesteps": 83675, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.15000000000000213},
{"step": 1841, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1842.0, 1.0, 1.0, 1.0, 1842.0, 1842.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.276, -5.222, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4151, "number_of_timesteps": 83726, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1842, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1843.0, 1.0, 1.0, 1.0, 1843.0, 1843.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.277, -5.222, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4153, "number_of_timesteps": 83756, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1843, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1844.0, 1.0, 1.0, 1.0, 1844.0, 1844.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.282, -5.227, 0.0, 0.0, 0.0]}
{"step": 1844, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1845.0, 1.0, 1.0, 1.0, 1845.0, 1845.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.286, -5.231, 0.0, 0.0, 0.0]}
{"step": 1845, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1846.0, 1.0, 1.0, 1.0, 1846.0, 1846.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.29, -5.235, 0.0, 0.0, 0.0]}
{"step": 1846, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1847.0, 1.0, 1.0, 1.0, 1847.0, 1847.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.293, -5.238, 0.0, 0.0, 0.0]}
{"eval_score": 20.9, "number_of_episodes": 4162}
{"number_of_episodes": 4162, "number_of_timesteps": 83925, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1847, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1848.0, 1.0, 1.0, 1.0, 1848.0, 1848.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.292, -5.238, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4165, "number_of_timesteps": 83990, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 1848, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1849.0, 1.0, 1.0, 1.0, 1849.0, 1849.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.289, -5.235, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4167, "number_of_timesteps": 84025, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1849, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1850.0, 1.0, 1.0, 1.0, 1850.0, 1850.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.293, -5.238, 0.0, 0.0, 0.0]}
{"step": 1850, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1851.0, 1.0, 1.0, 1.0, 1851.0, 1851.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.296, -5.242, 0.0, 0.0, 0.0]}
{"step": 1851, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1852.0, 1.0, 1.0, 1.0, 1852.0, 1852.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.296, -5.242, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4174, "number_of_timesteps": 84139, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 1852, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1853.0, 1.0, 1.0, 1.0, 1853.0, 1853.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.296, -5.242, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4179, "number_of_timesteps": 84236, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 1853, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1854.0, 1.0, 1.0, 1.0, 1854.0, 1854.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.293, -5.239, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4181, "number_of_timesteps": 84263, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1854, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1855.0, 1.0, 1.0, 1.0, 1855.0, 1855.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.297, -5.242, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4183, "number_of_timesteps": 84288, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000213},
{"step": 1855, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1856.0, 1.0, 1.0, 1.0, 1856.0, 1856.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.294, -5.24, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4187, "number_of_timesteps": 84344, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1856, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1857.0, 1.0, 1.0, 1.0, 1857.0, 1857.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.298, -5.244, 0.0, 0.0, 0.0]}
{"step": 1857, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1858.0, 1.0, 1.0, 1.0, 1858.0, 1858.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.295, -5.244, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4192, "number_of_timesteps": 84429, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 1858, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1859.0, 1.0, 1.0, 1.0, 1859.0, 1859.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.292, -5.241, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4194, "number_of_timesteps": 84458, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1859, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1860.0, 1.0, 1.0, 1.0, 1860.0, 1860.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.294, -5.238, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4197, "number_of_timesteps": 84507, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1860, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1861.0, 1.0, 1.0, 1.0, 1861.0, 1861.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.298, -5.242, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4201, "number_of_timesteps": 84557, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
{"step": 1861, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1862.0, 1.0, 1.0, 1.0, 1862.0, 1862.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.295, -5.242, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4203, "number_of_timesteps": 84605, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1862, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1863.0, 1.0, 1.0, 1.0, 1863.0, 1863.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.295, -5.242, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4206, "number_of_timesteps": 84654, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1863, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1864.0, 1.0, 1.0, 1.0, 1864.0, 1864.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.292, -5.239, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4209, "number_of_timesteps": 84690, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1864, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1865.0, 1.0, 1.0, 1.0, 1865.0, 1865.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.289, -5.236, 0.0, 0.0, 0.0]}
{"step": 1865, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1866.0, 1.0, 1.0, 1.0, 1866.0, 1866.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.289, -5.237, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4213, "number_of_timesteps": 84759, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 1866, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1867.0, 1.0, 1.0, 1.0, 1867.0, 1867.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.286, -5.234, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4214, "number_of_timesteps": 84773, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1867, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1868.0, 1.0, 1.0, 1.0, 1868.0, 1868.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.286, -5.233, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4218, "number_of_timesteps": 84864, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 1868, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1869.0, 1.0, 1.0, 1.0, 1869.0, 1869.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.286, -5.233, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4220, "number_of_timesteps": 84887, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1869, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1870.0, 1.0, 1.0, 1.0, 1870.0, 1870.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.29, -5.238, 0.0, 0.0, 0.0]}
{"step": 1870, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1871.0, 1.0, 1.0, 1.0, 1871.0, 1871.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.264, 0.0, 0.0, 0.0, -5.298, -5.245, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4225, "number_of_timesteps": 84982, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1871, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1872.0, 1.0, 1.0, 1.0, 1872.0, 1872.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.298, -5.246, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4228, "number_of_timesteps": 85035, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.24999999999999822},
{"step": 1872, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1873.0, 1.0, 1.0, 1.0, 1873.0, 1873.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.263, 0.0, 0.0, 0.0, -5.296, -5.243, 0.0, 0.0, 0.0]}
{"step": 1873, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1874.0, 1.0, 1.0, 1.0, 1874.0, 1874.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.293, -5.24, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4233, "number_of_timesteps": 85143, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1874, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1875.0, 1.0, 1.0, 1.0, 1875.0, 1875.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.259, 0.0, 0.0, 0.0, -5.29, -5.238, 0.0, 0.0, 0.0]}
{"step": 1875, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1876.0, 1.0, 1.0, 1.0, 1876.0, 1876.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.256, 0.0, 0.0, 0.0, -5.287, -5.235, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4238, "number_of_timesteps": 85231, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
{"step": 1876, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1877.0, 1.0, 1.0, 1.0, 1877.0, 1877.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.254, 0.0, 0.0, 0.0, -5.284, -5.232, 0.0, 0.0, 0.0]}
{"step": 1877, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1878.0, 1.0, 1.0, 1.0, 1878.0, 1878.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.252, 0.0, 0.0, 0.0, -5.281, -5.229, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4245, "number_of_timesteps": 85340, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1878, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1879.0, 1.0, 1.0, 1.0, 1879.0, 1879.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.25, 0.0, 0.0, 0.0, -5.285, -5.233, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4247, "number_of_timesteps": 85362, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 1879, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1880.0, 1.0, 1.0, 1.0, 1880.0, 1880.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.251, 0.0, 0.0, 0.0, -5.286, -5.233, 0.0, 0.0, 0.0]}
{"step": 1880, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1881.0, 1.0, 1.0, 1.0, 1881.0, 1881.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.251, 0.0, 0.0, 0.0, -5.285, -5.233, 0.0, 0.0, 0.0]}
{"step": 1881, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1882.0, 1.0, 1.0, 1.0, 1882.0, 1882.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.25, 0.0, 0.0, 0.0, -5.283, -5.231, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4257, "number_of_timesteps": 85516, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1882, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1883.0, 1.0, 1.0, 1.0, 1883.0, 1883.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.248, 0.0, 0.0, 0.0, -5.28, -5.228, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4259, "number_of_timesteps": 85539, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1883, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1884.0, 1.0, 1.0, 1.0, 1884.0, 1884.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.248, 0.0, 0.0, 0.0, -5.281, -5.229, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4262, "number_of_timesteps": 85581, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1884, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1885.0, 1.0, 1.0, 1.0, 1885.0, 1885.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.248, 0.0, 0.0, 0.0, -5.28, -5.226, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4265, "number_of_timesteps": 85631, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1885, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1886.0, 1.0, 1.0, 1.0, 1886.0, 1886.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.246, 0.0, 0.0, 0.0, -5.285, -5.231, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4268, "number_of_timesteps": 85677, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.1999999999999993},
{"step": 1886, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1887.0, 1.0, 1.0, 1.0, 1887.0, 1887.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.247, 0.0, 0.0, 0.0, -5.285, -5.231, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4270, "number_of_timesteps": 85707, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1887, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1888.0, 1.0, 1.0, 1.0, 1888.0, 1888.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.245, 0.0, 0.0, 0.0, -5.283, -5.228, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4273, "number_of_timesteps": 85752, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1888, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1889.0, 1.0, 1.0, 1.0, 1889.0, 1889.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.246, 0.0, 0.0, 0.0, -5.283, -5.229, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4276, "number_of_timesteps": 85794, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1889, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1890.0, 1.0, 1.0, 1.0, 1890.0, 1890.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.246, 0.0, 0.0, 0.0, -5.283, -5.229, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4279, "number_of_timesteps": 85847, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1890, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1891.0, 1.0, 1.0, 1.0, 1891.0, 1891.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.252, 0.0, 0.0, 0.0, -5.288, -5.234, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4282, "number_of_timesteps": 85896, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1891, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1892.0, 1.0, 1.0, 1.0, 1892.0, 1892.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.25, 0.0, 0.0, 0.0, -5.291, -5.237, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4287, "number_of_timesteps": 85961, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1892, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1893.0, 1.0, 1.0, 1.0, 1893.0, 1893.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.25, 0.0, 0.0, 0.0, -5.291, -5.237, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4287, "number_of_timesteps": 85961, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.1999999999999993},
{"step": 1893, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1894.0, 1.0, 1.0, 1.0, 1894.0, 1894.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.247, 0.0, 0.0, 0.0, -5.288, -5.234, 0.0, 0.0, 0.0]}
{"eval_score": 15.9, "number_of_episodes": 4291}
{"number_of_episodes": 4291, "number_of_timesteps": 86020, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1894, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1895.0, 1.0, 1.0, 1.0, 1895.0, 1895.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.248, 0.0, 0.0, 0.0, -5.288, -5.234, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4295, "number_of_timesteps": 86079, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1895, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1896.0, 1.0, 1.0, 1.0, 1896.0, 1896.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.246, 0.0, 0.0, 0.0, -5.286, -5.231, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4295, "number_of_timesteps": 86079, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1896, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1897.0, 1.0, 1.0, 1.0, 1897.0, 1897.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.251, 0.0, 0.0, 0.0, -5.29, -5.236, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4299, "number_of_timesteps": 86138, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1897, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1898.0, 1.0, 1.0, 1.0, 1898.0, 1898.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.249, 0.0, 0.0, 0.0, -5.297, -5.243, 0.0, 0.0, 0.0]}
{"step": 1898, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1899.0, 1.0, 1.0, 1.0, 1899.0, 1899.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.246, 0.0, 0.0, 0.0, -5.295, -5.241, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4305, "number_of_timesteps": 86248, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.1999999999999993},
{"step": 1899, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1900.0, 1.0, 1.0, 1.0, 1900.0, 1900.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.244, 0.0, 0.0, 0.0, -5.292, -5.238, 0.0, 0.0, 0.0]}
{"step": 1900, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1901.0, 1.0, 1.0, 1.0, 1901.0, 1901.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.242, 0.0, 0.0, 0.0, -5.289, -5.235, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4312, "number_of_timesteps": 86334, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1901, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1902.0, 1.0, 1.0, 1.0, 1902.0, 1902.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.243, 0.0, 0.0, 0.0, -5.289, -5.235, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4315, "number_of_timesteps": 86383, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1902, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1903.0, 1.0, 1.0, 1.0, 1903.0, 1903.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.249, 0.0, 0.0, 0.0, -5.295, -5.241, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4319, "number_of_timesteps": 86425, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1903, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1904.0, 1.0, 1.0, 1.0, 1904.0, 1904.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.247, 0.0, 0.0, 0.0, -5.292, -5.238, 0.0, 0.0, 0.0]}
{"step": 1904, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1905.0, 1.0, 1.0, 1.0, 1905.0, 1905.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.244, 0.0, 0.0, 0.0, -5.289, -5.236, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4326, "number_of_timesteps": 86519, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"step": 1905, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1906.0, 1.0, 1.0, 1.0, 1906.0, 1906.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.246, 0.0, 0.0, 0.0, -5.291, -5.237, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4328, "number_of_timesteps": 86543, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1906, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1907.0, 1.0, 1.0, 1.0, 1907.0, 1907.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.247, 0.0, 0.0, 0.0, -5.291, -5.238, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4332, "number_of_timesteps": 86587, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1907, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1908.0, 1.0, 1.0, 1.0, 1908.0, 1908.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.245, 0.0, 0.0, 0.0, -5.297, -5.243, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4336, "number_of_timesteps": 86644, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1908, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1909.0, 1.0, 1.0, 1.0, 1909.0, 1909.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.246, 0.0, 0.0, 0.0, -5.297, -5.24, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4338, "number_of_timesteps": 86668, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
{"step": 1909, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1910.0, 1.0, 1.0, 1.0, 1910.0, 1910.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.244, 0.0, 0.0, 0.0, -5.294, -5.238, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4343, "number_of_timesteps": 86728, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"step": 1910, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1911.0, 1.0, 1.0, 1.0, 1911.0, 1911.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.242, 0.0, 0.0, 0.0, -5.292, -5.235, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4346, "number_of_timesteps": 86764, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"step": 1911, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1912.0, 1.0, 1.0, 1.0, 1912.0, 1912.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.24, 0.0, 0.0, 0.0, -5.289, -5.232, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4349, "number_of_timesteps": 86800, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1912, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1913.0, 1.0, 1.0, 1.0, 1913.0, 1913.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.238, 0.0, 0.0, 0.0, -5.289, -5.233, 0.0, 0.0, 0.0]}
{"step": 1913, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1914.0, 1.0, 1.0, 1.0, 1914.0, 1914.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.235, 0.0, 0.0, 0.0, -5.294, -5.237, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4355, "number_of_timesteps": 86878, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 1914, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1915.0, 1.0, 1.0, 1.0, 1915.0, 1915.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.248, 0.0, 0.0, 0.0, -5.306, -5.249, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4360, "number_of_timesteps": 86941, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 1915, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1916.0, 1.0, 1.0, 1.0, 1916.0, 1916.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.249, 0.0, 0.0, 0.0, -5.306, -5.249, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4361, "number_of_timesteps": 86953, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1916, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1917.0, 1.0, 1.0, 1.0, 1917.0, 1917.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.249, 0.0, 0.0, 0.0, -5.306, -5.25, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4364, "number_of_timesteps": 86996, "per_episode_reward": 16.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
{"step": 1917, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1918.0, 1.0, 1.0, 1.0, 1918.0, 1918.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.25, 0.0, 0.0, 0.0, -5.303, -5.25, 0.0, 0.0, 0.0]}
{"step": 1918, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1919.0, 1.0, 1.0, 1.0, 1919.0, 1919.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.248, 0.0, 0.0, 0.0, -5.301, -5.248, 0.0, 0.0, 0.0]}
{"step": 1919, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1920.0, 1.0, 1.0, 1.0, 1920.0, 1920.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.248, 0.0, 0.0, 0.0, -5.298, -5.247, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4374, "number_of_timesteps": 87135, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.15000000000000213},
{"step": 1920, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1921.0, 1.0, 1.0, 1.0, 1921.0, 1921.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.248, 0.0, 0.0, 0.0, -5.295, -5.246, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4379, "number_of_timesteps": 87203, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1921, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1922.0, 1.0, 1.0, 1.0, 1922.0, 1922.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.253, 0.0, 0.0, 0.0, -5.299, -5.25, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4381, "number_of_timesteps": 87226, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 1922, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1923.0, 1.0, 1.0, 1.0, 1923.0, 1923.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.253, 0.0, 0.0, 0.0, -5.299, -5.25, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4383, "number_of_timesteps": 87252, "per_episode_reward": 16.15, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"step": 1923, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1924.0, 1.0, 1.0, 1.0, 1924.0, 1924.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.251, 0.0, 0.0, 0.0, -5.296, -5.247, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4386, "number_of_timesteps": 87297, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.15000000000000213},
{"step": 1924, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1925.0, 1.0, 1.0, 1.0, 1925.0, 1925.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.252, 0.0, 0.0, 0.0, -5.294, -5.248, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4392, "number_of_timesteps": 87389, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.003333333333333302, "biggest_recent_change": 0.1999999999999993},
{"step": 1925, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1926.0, 1.0, 1.0, 1.0, 1926.0, 1926.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.249, 0.0, 0.0, 0.0, -5.291, -5.245, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4393, "number_of_timesteps": 87402, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"step": 1926, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1927.0, 1.0, 1.0, 1.0, 1927.0, 1927.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.247, 0.0, 0.0, 0.0, -5.294, -5.248, 0.0, 0.0, 0.0]}
{"step": 1927, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1928.0, 1.0, 1.0, 1.0, 1928.0, 1928.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.245, 0.0, 0.0, 0.0, -5.293, -5.247, 0.0, 0.0, 0.0]}
{"step": 1928, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1929.0, 1.0, 1.0, 1.0, 1929.0, 1929.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.243, 0.0, 0.0, 0.0, -5.299, -5.253, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4404, "number_of_timesteps": 87542, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 1929, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1930.0, 1.0, 1.0, 1.0, 1930.0, 1930.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.243, 0.0, 0.0, 0.0, -5.298, -5.25, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4408, "number_of_timesteps": 87587, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000213},
{"step": 1930, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1931.0, 1.0, 1.0, 1.0, 1931.0, 1931.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.244, 0.0, 0.0, 0.0, -5.295, -5.251, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4411, "number_of_timesteps": 87621, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"step": 1931, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1932.0, 1.0, 1.0, 1.0, 1932.0, 1932.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.242, 0.0, 0.0, 0.0, -5.301, -5.257, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4415, "number_of_timesteps": 87677, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"step": 1932, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1933.0, 1.0, 1.0, 1.0, 1933.0, 1933.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.24, 0.0, 0.0, 0.0, -5.298, -5.254, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4418, "number_of_timesteps": 87715, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"step": 1933, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1934.0, 1.0, 1.0, 1.0, 1934.0, 1934.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.24, 0.0, 0.0, 0.0, -5.298, -5.254, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4419, "number_of_timesteps": 87727, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"step": 1934, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1935.0, 1.0, 1.0, 1.0, 1935.0, 1935.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.241, 0.0, 0.0, 0.0, -5.298, -5.254, 0.0, 0.0, 0.0]}
{"eval_score": 10.7, "number_of_episodes": 4423}
{"step": 1935, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1936.0, 1.0, 1.0, 1.0, 1936.0, 1936.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.238, 0.0, 0.0, 0.0, -5.295, -5.251, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4428, "number_of_timesteps": 87864, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"step": 1936, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1937.0, 1.0, 1.0, 1.0, 1937.0, 1937.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.242, 0.0, 0.0, 0.0, -5.299, -5.254, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4430, "number_of_timesteps": 87887, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"step": 1937, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1938.0, 1.0, 1.0, 1.0, 1938.0, 1938.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.243, 0.0, 0.0, 0.0, -5.299, -5.254, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4434, "number_of_timesteps": 87935, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 1938, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1939.0, 1.0, 1.0, 1.0, 1939.0, 1939.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.243, 0.0, 0.0, 0.0, -5.298, -5.252, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4438, "number_of_timesteps": 87982, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"step": 1939, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1940.0, 1.0, 1.0, 1.0, 1940.0, 1940.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.244, 0.0, 0.0, 0.0, -5.298, -5.252, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4440, "number_of_timesteps": 88008, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"step": 1940, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1941.0, 1.0, 1.0, 1.0, 1941.0, 1941.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.241, 0.0, 0.0, 0.0, -5.302, -5.255, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4444, "number_of_timesteps": 88058, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.10000000000000142},
{"step": 1941, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1942.0, 1.0, 1.0, 1.0, 1942.0, 1942.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.239, 0.0, 0.0, 0.0, -5.299, -5.253, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4448, "number_of_timesteps": 88115, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"step": 1942, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1943.0, 1.0, 1.0, 1.0, 1943.0, 1943.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.237, 0.0, 0.0, 0.0, -5.297, -5.25, 0.0, 0.0, 0.0]}
{"step": 1943, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1944.0, 1.0, 1.0, 1.0, 1944.0, 1944.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.235, 0.0, 0.0, 0.0, -5.294, -5.247, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4454, "number_of_timesteps": 88188, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"step": 1944, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1945.0, 1.0, 1.0, 1.0, 1945.0, 1945.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.236, 0.0, 0.0, 0.0, -5.294, -5.248, 0.0, 0.0, 0.0]}
{"step": 1945, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1946.0, 1.0, 1.0, 1.0, 1946.0, 1946.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.237, 0.0, 0.0, 0.0, -5.295, -5.248, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4463, "number_of_timesteps": 88298, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"step": 1946, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1947.0, 1.0, 1.0, 1.0, 1947.0, 1947.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.241, 0.0, 0.0, 0.0, -5.299, -5.252, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4466, "number_of_timesteps": 88328, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"step": 1947, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1948.0, 1.0, 1.0, 1.0, 1948.0, 1948.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.242, 0.0, 0.0, 0.0, -5.299, -5.252, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4470, "number_of_timesteps": 88374, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"step": 1948, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1949.0, 1.0, 1.0, 1.0, 1949.0, 1949.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.24, 0.0, 0.0, 0.0, -5.302, -5.256, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4476, "number_of_timesteps": 88443, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"step": 1949, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1950.0, 1.0, 1.0, 1.0, 1950.0, 1950.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.238, 0.0, 0.0, 0.0, -5.299, -5.253, 0.0, 0.0, 0.0]}
{"step": 1950, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1951.0, 1.0, 1.0, 1.0, 1951.0, 1951.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.235, 0.0, 0.0, 0.0, -5.303, -5.257, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4483, "number_of_timesteps": 88512, "per_episode_reward": 16.1, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"step": 1951, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1952.0, 1.0, 1.0, 1.0, 1952.0, 1952.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.237, 0.0, 0.0, 0.0, -5.301, -5.258, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4487, "number_of_timesteps": 88558, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"step": 1952, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1953.0, 1.0, 1.0, 1.0, 1953.0, 1953.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.244, 0.0, 0.0, 0.0, -5.308, -5.265, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4489, "number_of_timesteps": 88579, "per_episode_reward": 16.05, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"step": 1953, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1954.0, 1.0, 1.0, 1.0, 1954.0, 1954.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.246, 0.0, 0.0, 0.0, -5.309, -5.266, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4495, "number_of_timesteps": 88645, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 1954, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1955.0, 1.0, 1.0, 1.0, 1955.0, 1955.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.247, 0.0, 0.0, 0.0, -5.309, -5.263, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4497, "number_of_timesteps": 88671, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"step": 1955, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1956.0, 1.0, 1.0, 1.0, 1956.0, 1956.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.245, 0.0, 0.0, 0.0, -5.315, -5.269, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4502, "number_of_timesteps": 88719, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"step": 1956, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1957.0, 1.0, 1.0, 1.0, 1957.0, 1957.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.245, 0.0, 0.0, 0.0, -5.316, -5.269, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4507, "number_of_timesteps": 88777, "per_episode_reward": 16.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"step": 1957, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1958.0, 1.0, 1.0, 1.0, 1958.0, 1958.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.246, 0.0, 0.0, 0.0, -5.316, -5.27, 0.0, 0.0, 0.0]}
{"step": 1958, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1959.0, 1.0, 1.0, 1.0, 1959.0, 1959.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.245, 0.0, 0.0, 0.0, -5.314, -5.267, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4513, "number_of_timesteps": 88841, "per_episode_reward": 15.95, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 1959, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1960.0, 1.0, 1.0, 1.0, 1960.0, 1960.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.242, 0.0, 0.0, 0.0, -5.319, -5.273, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4519, "number_of_timesteps": 88908, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 1960, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1961.0, 1.0, 1.0, 1.0, 1961.0, 1961.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.24, 0.0, 0.0, 0.0, -5.316, -5.27, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4521, "number_of_timesteps": 88926, "per_episode_reward": 15.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"step": 1961, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1962.0, 1.0, 1.0, 1.0, 1962.0, 1962.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.246, 0.0, 0.0, 0.0, -5.321, -5.275, 0.0, 0.0, 0.0]}
{"step": 1962, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1963.0, 1.0, 1.0, 1.0, 1963.0, 1963.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.244, 0.0, 0.0, 0.0, -5.319, -5.273, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4529, "number_of_timesteps": 89024, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"step": 1963, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1964.0, 1.0, 1.0, 1.0, 1964.0, 1964.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.242, 0.0, 0.0, 0.0, -5.322, -5.276, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4531, "number_of_timesteps": 89045, "per_episode_reward": 15.8, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 1964, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1965.0, 1.0, 1.0, 1.0, 1965.0, 1965.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.243, 0.0, 0.0, 0.0, -5.322, -5.276, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4536, "number_of_timesteps": 89099, "per_episode_reward": 15.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 1965, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1966.0, 1.0, 1.0, 1.0, 1966.0, 1966.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.241, 0.0, 0.0, 0.0, -5.319, -5.274, 0.0, 0.0, 0.0]}
{"step": 1966, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1967.0, 1.0, 1.0, 1.0, 1967.0, 1967.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.239, 0.0, 0.0, 0.0, -5.317, -5.271, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4542, "number_of_timesteps": 89163, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.15000000000000036},
{"step": 1967, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1968.0, 1.0, 1.0, 1.0, 1968.0, 1968.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.236, 0.0, 0.0, 0.0, -5.321, -5.276, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4547, "number_of_timesteps": 89219, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.45000000000000107},
{"step": 1968, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1969.0, 1.0, 1.0, 1.0, 1969.0, 1969.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.234, 0.0, 0.0, 0.0, -5.319, -5.273, 0.0, 0.0, 0.0]}
{"eval_score": 11.1, "number_of_episodes": 4550}
{"number_of_episodes": 4550, "number_of_timesteps": 89251, "per_episode_reward": 15.65, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.1999999999999993},
{"step": 1969, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1970.0, 1.0, 1.0, 1.0, 1970.0, 1970.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.235, 0.0, 0.0, 0.0, -5.319, -5.273, 0.0, 0.0, 0.0]}
{"step": 1970, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1971.0, 1.0, 1.0, 1.0, 1971.0, 1971.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.237, 0.0, 0.0, 0.0, -5.32, -5.274, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4556, "number_of_timesteps": 89326, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.5000000000000018},
{"step": 1971, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1972.0, 1.0, 1.0, 1.0, 1972.0, 1972.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.239, 0.0, 0.0, 0.0, -5.318, -5.276, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4561, "number_of_timesteps": 89383, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.3000000000000007},
{"step": 1972, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1973.0, 1.0, 1.0, 1.0, 1973.0, 1973.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.244, 0.0, 0.0, 0.0, -5.323, -5.281, 0.0, 0.0, 0.0]}
{"step": 1973, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1974.0, 1.0, 1.0, 1.0, 1974.0, 1974.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.251, 0.0, 0.0, 0.0, -5.328, -5.286, 0.0, 0.0, 0.0]}
{"step": 1974, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1975.0, 1.0, 1.0, 1.0, 1975.0, 1975.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.253, 0.0, 0.0, 0.0, -5.331, -5.289, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4571, "number_of_timesteps": 89503, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.40000000000000036},
{"step": 1975, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1976.0, 1.0, 1.0, 1.0, 1976.0, 1976.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.253, 0.0, 0.0, 0.0, -5.329, -5.287, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4576, "number_of_timesteps": 89558, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.40000000000000036},
{"step": 1976, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1977.0, 1.0, 1.0, 1.0, 1977.0, 1977.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.254, 0.0, 0.0, 0.0, -5.33, -5.285, 0.0, 0.0, 0.0]}
{"step": 1977, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1978.0, 1.0, 1.0, 1.0, 1978.0, 1978.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.255, 0.0, 0.0, 0.0, -5.33, -5.282, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4583, "number_of_timesteps": 89633, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.45000000000000107},
{"step": 1978, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1979.0, 1.0, 1.0, 1.0, 1979.0, 1979.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.252, 0.0, 0.0, 0.0, -5.328, -5.279, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4587, "number_of_timesteps": 89680, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.5000000000000018},
{"step": 1979, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1980.0, 1.0, 1.0, 1.0, 1980.0, 1980.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.253, 0.0, 0.0, 0.0, -5.325, -5.28, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4590, "number_of_timesteps": 89712, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.40000000000000036},
{"step": 1980, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1981.0, 1.0, 1.0, 1.0, 1981.0, 1981.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.255, 0.0, 0.0, 0.0, -5.326, -5.277, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4592, "number_of_timesteps": 89738, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.40000000000000036},
{"step": 1981, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1982.0, 1.0, 1.0, 1.0, 1982.0, 1982.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.255, 0.0, 0.0, 0.0, -5.326, -5.277, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4598, "number_of_timesteps": 89807, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.1999999999999993},
{"step": 1982, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1983.0, 1.0, 1.0, 1.0, 1983.0, 1983.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.253, 0.0, 0.0, 0.0, -5.323, -5.275, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4602, "number_of_timesteps": 89862, "per_episode_reward": 15.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.45000000000000107},
{"step": 1983, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1984.0, 1.0, 1.0, 1.0, 1984.0, 1984.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.254, 0.0, 0.0, 0.0, -5.324, -5.275, 0.0, 0.0, 0.0]}
{"step": 1984, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1985.0, 1.0, 1.0, 1.0, 1985.0, 1985.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.255, 0.0, 0.0, 0.0, -5.324, -5.275, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4610, "number_of_timesteps": 89942, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.5000000000000018},
{"step": 1985, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1986.0, 1.0, 1.0, 1.0, 1986.0, 1986.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.255, 0.0, 0.0, 0.0, -5.321, -5.274, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4614, "number_of_timesteps": 89985, "per_episode_reward": 15.55, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.40000000000000036},
{"step": 1986, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1987.0, 1.0, 1.0, 1.0, 1987.0, 1987.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.256, 0.0, 0.0, 0.0, -5.322, -5.275, 0.0, 0.0, 0.0]}
{"step": 1987, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1988.0, 1.0, 1.0, 1.0, 1988.0, 1988.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.258, 0.0, 0.0, 0.0, -5.324, -5.277, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4621, "number_of_timesteps": 90063, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.15000000000000036},
{"step": 1988, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1989.0, 1.0, 1.0, 1.0, 1989.0, 1989.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.256, 0.0, 0.0, 0.0, -5.328, -5.282, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4623, "number_of_timesteps": 90086, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.6000000000000014},
{"step": 1989, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1990.0, 1.0, 1.0, 1.0, 1990.0, 1990.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.254, 0.0, 0.0, 0.0, -5.326, -5.279, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4626, "number_of_timesteps": 90122, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3000000000000007},
{"step": 1990, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1991.0, 1.0, 1.0, 1.0, 1991.0, 1991.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.259, 0.0, 0.0, 0.0, -5.331, -5.284, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4631, "number_of_timesteps": 90185, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.45000000000000107},
{"step": 1991, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1992.0, 1.0, 1.0, 1.0, 1992.0, 1992.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.257, 0.0, 0.0, 0.0, -5.328, -5.281, 0.0, 0.0, 0.0]}
{"step": 1992, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1993.0, 1.0, 1.0, 1.0, 1993.0, 1993.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.263, 0.0, 0.0, 0.0, -5.333, -5.287, 0.0, 0.0, 0.0]}
{"step": 1993, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1994.0, 1.0, 1.0, 1.0, 1994.0, 1994.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.331, -5.284, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4642, "number_of_timesteps": 90322, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.45000000000000107},
{"step": 1994, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1995.0, 1.0, 1.0, 1.0, 1995.0, 1995.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.259, 0.0, 0.0, 0.0, -5.328, -5.282, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4643, "number_of_timesteps": 90335, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.40000000000000036},
{"step": 1995, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1996.0, 1.0, 1.0, 1.0, 1996.0, 1996.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.259, 0.0, 0.0, 0.0, -5.328, -5.282, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4648, "number_of_timesteps": 90394, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.40000000000000036},
{"step": 1996, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1997.0, 1.0, 1.0, 1.0, 1997.0, 1997.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.26, 0.0, 0.0, 0.0, -5.328, -5.279, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4652, "number_of_timesteps": 90448, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.5000000000000018},
{"step": 1997, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1998.0, 1.0, 1.0, 1.0, 1998.0, 1998.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.326, -5.279, 0.0, 0.0, 0.0]}
{"step": 1998, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 1999.0, 1.0, 1.0, 1.0, 1999.0, 1999.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.263, 0.0, 0.0, 0.0, -5.323, -5.281, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4659, "number_of_timesteps": 90534, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.40000000000000036},
{"step": 1999, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2000.0, 1.0, 1.0, 1.0, 2000.0, 2000.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.264, 0.0, 0.0, 0.0, -5.323, -5.281, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4662, "number_of_timesteps": 90570, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3000000000000007},
{"step": 2000, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2001.0, 1.0, 1.0, 1.0, 2001.0, 2001.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.327, -5.285, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4667, "number_of_timesteps": 90623, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.1999999999999993},
{"step": 2001, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2002.0, 1.0, 1.0, 1.0, 2002.0, 2002.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.328, -5.286, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4670, "number_of_timesteps": 90657, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.45000000000000107},
{"step": 2002, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2003.0, 1.0, 1.0, 1.0, 2003.0, 2003.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.329, -5.287, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4675, "number_of_timesteps": 90711, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.40000000000000036},
{"step": 2003, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2004.0, 1.0, 1.0, 1.0, 2004.0, 2004.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.329, -5.287, 0.0, 0.0, 0.0]}
{"step": 2004, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2005.0, 1.0, 1.0, 1.0, 2005.0, 2005.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.328, -5.286, 0.0, 0.0, 0.0]}
{"eval_score": 11.9, "number_of_episodes": 4684}
{"number_of_episodes": 4684, "number_of_timesteps": 90801, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.15000000000000036},
{"step": 2005, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2006.0, 1.0, 1.0, 1.0, 2006.0, 2006.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.334, -5.292, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4686, "number_of_timesteps": 90823, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.45000000000000107},
{"step": 2006, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2007.0, 1.0, 1.0, 1.0, 2007.0, 2007.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.334, -5.292, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4692, "number_of_timesteps": 90891, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3000000000000007},
{"step": 2007, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2008.0, 1.0, 1.0, 1.0, 2008.0, 2008.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.34, -5.298, 0.0, 0.0, 0.0]}
{"step": 2008, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2009.0, 1.0, 1.0, 1.0, 2009.0, 2009.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.34, -5.298, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4698, "number_of_timesteps": 90953, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.5000000000000018},
{"step": 2009, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2010.0, 1.0, 1.0, 1.0, 2010.0, 2010.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.337, -5.297, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4702, "number_of_timesteps": 91004, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.3000000000000007},
{"step": 2010, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2011.0, 1.0, 1.0, 1.0, 2011.0, 2011.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.342, -5.302, 0.0, 0.0, 0.0]}
{"step": 2011, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2012.0, 1.0, 1.0, 1.0, 2012.0, 2012.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.284, 0.0, 0.0, 0.0, -5.34, -5.303, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4709, "number_of_timesteps": 91091, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.15000000000000036},
{"step": 2012, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2013.0, 1.0, 1.0, 1.0, 2013.0, 2013.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.345, -5.309, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4713, "number_of_timesteps": 91139, "per_episode_reward": 15.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.20000000000000107},
{"step": 2013, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2014.0, 1.0, 1.0, 1.0, 2014.0, 2014.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.343, -5.306, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4717, "number_of_timesteps": 91185, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.40000000000000036},
{"step": 2014, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2015.0, 1.0, 1.0, 1.0, 2015.0, 2015.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.343, -5.303, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4722, "number_of_timesteps": 91234, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.5000000000000018},
{"step": 2015, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2016.0, 1.0, 1.0, 1.0, 2016.0, 2016.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.34, -5.303, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4723, "number_of_timesteps": 91246, "per_episode_reward": 15.45, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.45000000000000107},
{"step": 2016, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2017.0, 1.0, 1.0, 1.0, 2017.0, 2017.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.338, -5.301, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4729, "number_of_timesteps": 91315, "per_episode_reward": 15.4, "episode_reward_trend_value": -0.008888888888888877, "biggest_recent_change": 0.20000000000000107},
{"step": 2017, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2018.0, 1.0, 1.0, 1.0, 2018.0, 2018.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.335, -5.298, 0.0, 0.0, 0.0]}
{"step": 2018, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2019.0, 1.0, 1.0, 1.0, 2019.0, 2019.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.332, -5.296, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4737, "number_of_timesteps": 91402, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.40000000000000036},
{"step": 2019, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2020.0, 1.0, 1.0, 1.0, 2020.0, 2020.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.33, -5.293, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4741, "number_of_timesteps": 91445, "per_episode_reward": 15.35, "episode_reward_trend_value": -0.008333333333333354, "biggest_recent_change": 0.3000000000000007},
{"step": 2020, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2021.0, 1.0, 1.0, 1.0, 2021.0, 2021.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.334, -5.297, 0.0, 0.0, 0.0]}
{"step": 2021, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2022.0, 1.0, 1.0, 1.0, 2022.0, 2022.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.286, 0.0, 0.0, 0.0, -5.342, -5.305, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4749, "number_of_timesteps": 91536, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.009999999999999985, "biggest_recent_change": 0.45000000000000107},
{"step": 2022, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2023.0, 1.0, 1.0, 1.0, 2023.0, 2023.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.284, 0.0, 0.0, 0.0, -5.34, -5.302, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4751, "number_of_timesteps": 91560, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.009999999999999985, "biggest_recent_change": 0.20000000000000107},
{"step": 2023, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2024.0, 1.0, 1.0, 1.0, 2024.0, 2024.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.337, -5.3, 0.0, 0.0, 0.0]}
{"step": 2024, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2025.0, 1.0, 1.0, 1.0, 2025.0, 2025.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.334, -5.297, 0.0, 0.0, 0.0]}
{"step": 2025, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2026.0, 1.0, 1.0, 1.0, 2026.0, 2026.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.332, -5.294, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4762, "number_of_timesteps": 91697, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.00944444444444442, "biggest_recent_change": 0.40000000000000036},
{"step": 2026, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2027.0, 1.0, 1.0, 1.0, 2027.0, 2027.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.332, -5.294, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4766, "number_of_timesteps": 91743, "per_episode_reward": 15.3, "episode_reward_trend_value": -0.009999999999999985, "biggest_recent_change": 0.45000000000000107},
{"step": 2027, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2028.0, 1.0, 1.0, 1.0, 2028.0, 2028.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.329, -5.292, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4770, "number_of_timesteps": 91791, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.6000000000000014},
{"step": 2028, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2029.0, 1.0, 1.0, 1.0, 2029.0, 2029.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.327, -5.289, 0.0, 0.0, 0.0]}
{"step": 2029, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2030.0, 1.0, 1.0, 1.0, 2030.0, 2030.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.327, -5.29, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4777, "number_of_timesteps": 91876, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.3000000000000007},
{"step": 2030, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2031.0, 1.0, 1.0, 1.0, 2031.0, 2031.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.328, -5.291, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4780, "number_of_timesteps": 91912, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.40000000000000036},
{"step": 2031, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2032.0, 1.0, 1.0, 1.0, 2032.0, 2032.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.328, -5.291, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4784, "number_of_timesteps": 91953, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.20000000000000107},
{"step": 2032, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2033.0, 1.0, 1.0, 1.0, 2033.0, 2033.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.326, -5.288, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4788, "number_of_timesteps": 91996, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.3000000000000007},
{"step": 2033, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2034.0, 1.0, 1.0, 1.0, 2034.0, 2034.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.33, -5.293, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4792, "number_of_timesteps": 92046, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.40000000000000036},
{"step": 2034, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2035.0, 1.0, 1.0, 1.0, 2035.0, 2035.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.331, -5.29, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4796, "number_of_timesteps": 92088, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.3000000000000007},
{"step": 2035, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2036.0, 1.0, 1.0, 1.0, 2036.0, 2036.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.337, -5.296, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4800, "number_of_timesteps": 92131, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.5000000000000018},
{"step": 2036, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2037.0, 1.0, 1.0, 1.0, 2037.0, 2037.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.334, -5.298, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4804, "number_of_timesteps": 92174, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.45000000000000107},
{"step": 2037, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2038.0, 1.0, 1.0, 1.0, 2038.0, 2038.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.332, -5.295, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4809, "number_of_timesteps": 92226, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.3000000000000007},
{"step": 2038, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2039.0, 1.0, 1.0, 1.0, 2039.0, 2039.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.331, -5.295, 0.0, 0.0, 0.0]}
{"eval_score": 11.1, "number_of_episodes": 4812}
{"number_of_episodes": 4812, "number_of_timesteps": 92257, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.40000000000000036},
{"step": 2039, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2040.0, 1.0, 1.0, 1.0, 2040.0, 2040.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.331, -5.293, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4815, "number_of_timesteps": 92288, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.3000000000000007},
{"step": 2040, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2041.0, 1.0, 1.0, 1.0, 2041.0, 2041.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.338, -5.299, 0.0, 0.0, 0.0]}
{"step": 2041, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2042.0, 1.0, 1.0, 1.0, 2042.0, 2042.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.336, -5.297, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4824, "number_of_timesteps": 92397, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2042, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2043.0, 1.0, 1.0, 1.0, 2043.0, 2043.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.336, -5.298, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4825, "number_of_timesteps": 92408, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3000000000000007},
{"step": 2043, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2044.0, 1.0, 1.0, 1.0, 2044.0, 2044.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.342, -5.303, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4830, "number_of_timesteps": 92462, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.6000000000000014},
{"step": 2044, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2045.0, 1.0, 1.0, 1.0, 2045.0, 2045.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.339, -5.3, 0.0, 0.0, 0.0]}
{"step": 2045, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2046.0, 1.0, 1.0, 1.0, 2046.0, 2046.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.343, -5.304, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4835, "number_of_timesteps": 92525, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.40000000000000036},
{"step": 2046, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2047.0, 1.0, 1.0, 1.0, 2047.0, 2047.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.343, -5.302, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4840, "number_of_timesteps": 92590, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.20000000000000107},
{"step": 2047, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2048.0, 1.0, 1.0, 1.0, 2048.0, 2048.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.341, -5.299, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4845, "number_of_timesteps": 92650, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 2048, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2049.0, 1.0, 1.0, 1.0, 2049.0, 2049.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.342, -5.3, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4846, "number_of_timesteps": 92659, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.00944444444444446, "biggest_recent_change": 0.3000000000000007},
{"step": 2049, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2050.0, 1.0, 1.0, 1.0, 2050.0, 2050.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.343, -5.301, 0.0, 0.0, 0.0]}
{"step": 2050, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2051.0, 1.0, 1.0, 1.0, 2051.0, 2051.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.343, -5.301, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4855, "number_of_timesteps": 92760, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.1999999999999993},
{"step": 2051, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2052.0, 1.0, 1.0, 1.0, 2052.0, 2052.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.344, -5.302, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4858, "number_of_timesteps": 92790, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.45000000000000107},
{"step": 2052, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2053.0, 1.0, 1.0, 1.0, 2053.0, 2053.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.342, -5.3, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4864, "number_of_timesteps": 92860, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2053, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2054.0, 1.0, 1.0, 1.0, 2054.0, 2054.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.342, -5.297, 0.0, 0.0, 0.0]}
{"step": 2054, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2055.0, 1.0, 1.0, 1.0, 2055.0, 2055.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.342, -5.295, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4869, "number_of_timesteps": 92911, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 0.20000000000000107},
{"step": 2055, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2056.0, 1.0, 1.0, 1.0, 2056.0, 2056.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.339, -5.292, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4876, "number_of_timesteps": 92992, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.45000000000000107},
{"step": 2056, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2057.0, 1.0, 1.0, 1.0, 2057.0, 2057.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.337, -5.29, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4878, "number_of_timesteps": 93014, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.1999999999999993},
{"step": 2057, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2058.0, 1.0, 1.0, 1.0, 2058.0, 2058.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.338, -5.291, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4884, "number_of_timesteps": 93076, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.5000000000000018},
{"step": 2058, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2059.0, 1.0, 1.0, 1.0, 2059.0, 2059.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.335, -5.292, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4888, "number_of_timesteps": 93120, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3000000000000007},
{"step": 2059, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2060.0, 1.0, 1.0, 1.0, 2060.0, 2060.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.341, -5.297, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4891, "number_of_timesteps": 93148, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.3000000000000007},
{"step": 2060, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2061.0, 1.0, 1.0, 1.0, 2061.0, 2061.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.339, -5.295, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4897, "number_of_timesteps": 93211, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.6000000000000014},
{"step": 2061, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2062.0, 1.0, 1.0, 1.0, 2062.0, 2062.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.336, -5.292, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4899, "number_of_timesteps": 93232, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 2062, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2063.0, 1.0, 1.0, 1.0, 2063.0, 2063.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.336, -5.293, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4905, "number_of_timesteps": 93294, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.5000000000000018},
{"step": 2063, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2064.0, 1.0, 1.0, 1.0, 2064.0, 2064.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.334, -5.293, 0.0, 0.0, 0.0]}
{"step": 2064, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2065.0, 1.0, 1.0, 1.0, 2065.0, 2065.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.331, -5.296, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4912, "number_of_timesteps": 93373, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.3000000000000007},
{"step": 2065, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2066.0, 1.0, 1.0, 1.0, 2066.0, 2066.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.337, -5.301, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4918, "number_of_timesteps": 93435, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 2066, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2067.0, 1.0, 1.0, 1.0, 2067.0, 2067.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.337, -5.302, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4920, "number_of_timesteps": 93454, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.45000000000000107},
{"step": 2067, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2068.0, 1.0, 1.0, 1.0, 2068.0, 2068.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.336, -5.301, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4927, "number_of_timesteps": 93525, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.14999999999999858},
{"step": 2068, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2069.0, 1.0, 1.0, 1.0, 2069.0, 2069.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.333, -5.298, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4928, "number_of_timesteps": 93536, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2069, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2070.0, 1.0, 1.0, 1.0, 2070.0, 2070.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.332, -5.296, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4933, "number_of_timesteps": 93586, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 2070, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2071.0, 1.0, 1.0, 1.0, 2071.0, 2071.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.33, -5.296, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4936, "number_of_timesteps": 93620, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.20000000000000107},
{"step": 2071, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2072.0, 1.0, 1.0, 1.0, 2072.0, 2072.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.327, -5.294, 0.0, 0.0, 0.0]}
{"step": 2072, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2073.0, 1.0, 1.0, 1.0, 2073.0, 2073.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.325, -5.291, 0.0, 0.0, 0.0]}
{"eval_score": 11.5, "number_of_episodes": 4942}
{"number_of_episodes": 4942, "number_of_timesteps": 93701, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.15000000000000036},
{"step": 2073, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2074.0, 1.0, 1.0, 1.0, 2074.0, 2074.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.325, -5.288, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4946, "number_of_timesteps": 93764, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.45000000000000107},
{"step": 2074, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2075.0, 1.0, 1.0, 1.0, 2075.0, 2075.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.326, -5.289, 0.0, 0.0, 0.0]}
{"step": 2075, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2076.0, 1.0, 1.0, 1.0, 2076.0, 2076.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.324, -5.288, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4954, "number_of_timesteps": 93853, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.6000000000000014},
{"step": 2076, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2077.0, 1.0, 1.0, 1.0, 2077.0, 2077.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.322, -5.285, 0.0, 0.0, 0.0]}
{"step": 2077, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2078.0, 1.0, 1.0, 1.0, 2078.0, 2078.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.319, -5.283, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4962, "number_of_timesteps": 93948, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.25},
{"step": 2078, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2079.0, 1.0, 1.0, 1.0, 2079.0, 2079.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.317, -5.283, 0.0, 0.0, 0.0]}
{"step": 2079, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2080.0, 1.0, 1.0, 1.0, 2080.0, 2080.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.314, -5.281, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4968, "number_of_timesteps": 94020, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.14999999999999858},
{"step": 2080, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2081.0, 1.0, 1.0, 1.0, 2081.0, 2081.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.312, -5.278, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4973, "number_of_timesteps": 94080, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 2081, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2082.0, 1.0, 1.0, 1.0, 2082.0, 2082.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.312, -5.276, 0.0, 0.0, 0.0]}
{"step": 2082, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2083.0, 1.0, 1.0, 1.0, 2083.0, 2083.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.309, -5.273, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4979, "number_of_timesteps": 94137, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.3000000000000007},
{"step": 2083, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2084.0, 1.0, 1.0, 1.0, 2084.0, 2084.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.309, -5.273, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4984, "number_of_timesteps": 94199, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.3000000000000007},
{"step": 2084, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2085.0, 1.0, 1.0, 1.0, 2085.0, 2085.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.264, 0.0, 0.0, 0.0, -5.315, -5.279, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4986, "number_of_timesteps": 94222, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 2085, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2086.0, 1.0, 1.0, 1.0, 2086.0, 2086.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.264, 0.0, 0.0, 0.0, -5.314, -5.278, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4990, "number_of_timesteps": 94264, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.25},
{"step": 2086, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2087.0, 1.0, 1.0, 1.0, 2087.0, 2087.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.312, -5.279, 0.0, 0.0, 0.0]}
{"number_of_episodes": 4995, "number_of_timesteps": 94340, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2087, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2088.0, 1.0, 1.0, 1.0, 2088.0, 2088.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.315, -5.283, 0.0, 0.0, 0.0]}
{"step": 2088, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2089.0, 1.0, 1.0, 1.0, 2089.0, 2089.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.32, -5.288, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5002, "number_of_timesteps": 94415, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 2089, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2090.0, 1.0, 1.0, 1.0, 2090.0, 2090.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.319, -5.285, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5007, "number_of_timesteps": 94470, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 2090, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2091.0, 1.0, 1.0, 1.0, 2091.0, 2091.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.324, -5.291, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5009, "number_of_timesteps": 94493, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.25},
{"step": 2091, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2092.0, 1.0, 1.0, 1.0, 2092.0, 2092.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.321, -5.291, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5015, "number_of_timesteps": 94555, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.6000000000000014},
{"step": 2092, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2093.0, 1.0, 1.0, 1.0, 2093.0, 2093.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.319, -5.289, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5018, "number_of_timesteps": 94592, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.010000000000000024, "biggest_recent_change": 0.3000000000000007},
{"step": 2093, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2094.0, 1.0, 1.0, 1.0, 2094.0, 2094.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.319, -5.289, 0.0, 0.0, 0.0]}
{"step": 2094, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2095.0, 1.0, 1.0, 1.0, 2095.0, 2095.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.318, -5.288, 0.0, 0.0, 0.0]}
{"step": 2095, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2096.0, 1.0, 1.0, 1.0, 2096.0, 2096.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.319, -5.289, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5028, "number_of_timesteps": 94715, "per_episode_reward": 15.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.25},
{"step": 2096, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2097.0, 1.0, 1.0, 1.0, 2097.0, 2097.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.316, -5.289, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5031, "number_of_timesteps": 94750, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.011666666666666655, "biggest_recent_change": 0.6000000000000014},
{"step": 2097, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2098.0, 1.0, 1.0, 1.0, 2098.0, 2098.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.314, -5.286, 0.0, 0.0, 0.0]}
{"step": 2098, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2099.0, 1.0, 1.0, 1.0, 2099.0, 2099.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.311, -5.284, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5038, "number_of_timesteps": 94831, "per_episode_reward": 15.15, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 2099, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2100.0, 1.0, 1.0, 1.0, 2100.0, 2100.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.316, -5.288, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5043, "number_of_timesteps": 94885, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.3000000000000007},
{"step": 2100, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2101.0, 1.0, 1.0, 1.0, 2101.0, 2101.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.319, -5.291, 0.0, 0.0, 0.0]}
{"step": 2101, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2102.0, 1.0, 1.0, 1.0, 2102.0, 2102.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.324, -5.297, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5050, "number_of_timesteps": 94958, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.01111111111111113, "biggest_recent_change": 0.6000000000000014},
{"step": 2102, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2103.0, 1.0, 1.0, 1.0, 2103.0, 2103.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.322, -5.294, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5054, "number_of_timesteps": 95002, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.14999999999999858},
{"step": 2103, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2104.0, 1.0, 1.0, 1.0, 2104.0, 2104.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.319, -5.292, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5059, "number_of_timesteps": 95055, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2104, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2105.0, 1.0, 1.0, 1.0, 2105.0, 2105.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.32, -5.292, 0.0, 0.0, 0.0]}
{"step": 2105, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2106.0, 1.0, 1.0, 1.0, 2106.0, 2106.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.317, -5.29, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5067, "number_of_timesteps": 95138, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.01111111111111113, "biggest_recent_change": 0.6000000000000014},
{"step": 2106, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2107.0, 1.0, 1.0, 1.0, 2107.0, 2107.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.315, -5.287, 0.0, 0.0, 0.0]}
{"eval_score": 11.6, "number_of_episodes": 5070}
{"number_of_episodes": 5070, "number_of_timesteps": 95171, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 2107, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2108.0, 1.0, 1.0, 1.0, 2108.0, 2108.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.315, -5.285, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5076, "number_of_timesteps": 95243, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.14999999999999858},
{"step": 2108, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2109.0, 1.0, 1.0, 1.0, 2109.0, 2109.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.313, -5.282, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5078, "number_of_timesteps": 95264, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.01111111111111113, "biggest_recent_change": 0.45000000000000107},
{"step": 2109, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2110.0, 1.0, 1.0, 1.0, 2110.0, 2110.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.314, -5.283, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5081, "number_of_timesteps": 95298, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3000000000000007},
{"step": 2110, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2111.0, 1.0, 1.0, 1.0, 2111.0, 2111.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.311, -5.281, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5085, "number_of_timesteps": 95349, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2111, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2112.0, 1.0, 1.0, 1.0, 2112.0, 2112.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.311, -5.278, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5089, "number_of_timesteps": 95402, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.20000000000000107},
{"step": 2112, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2113.0, 1.0, 1.0, 1.0, 2113.0, 2113.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.309, -5.276, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5093, "number_of_timesteps": 95445, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 2113, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2114.0, 1.0, 1.0, 1.0, 2114.0, 2114.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.306, -5.276, 0.0, 0.0, 0.0]}
{"step": 2114, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2115.0, 1.0, 1.0, 1.0, 2115.0, 2115.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.304, -5.273, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5100, "number_of_timesteps": 95522, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 2115, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2116.0, 1.0, 1.0, 1.0, 2116.0, 2116.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.264, 0.0, 0.0, 0.0, -5.301, -5.271, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5106, "number_of_timesteps": 95587, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.1999999999999993},
{"step": 2116, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2117.0, 1.0, 1.0, 1.0, 2117.0, 2117.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.299, -5.268, 0.0, 0.0, 0.0]}
{"step": 2117, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2118.0, 1.0, 1.0, 1.0, 2118.0, 2118.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.259, 0.0, 0.0, 0.0, -5.296, -5.266, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5112, "number_of_timesteps": 95646, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.3000000000000007},
{"step": 2118, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2119.0, 1.0, 1.0, 1.0, 2119.0, 2119.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.257, 0.0, 0.0, 0.0, -5.3, -5.27, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5116, "number_of_timesteps": 95688, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 2119, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2120.0, 1.0, 1.0, 1.0, 2120.0, 2120.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.259, 0.0, 0.0, 0.0, -5.301, -5.271, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5121, "number_of_timesteps": 95749, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2120, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2121.0, 1.0, 1.0, 1.0, 2121.0, 2121.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.26, 0.0, 0.0, 0.0, -5.301, -5.268, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5125, "number_of_timesteps": 95791, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.013333333333333345, "biggest_recent_change": 0.45000000000000107},
{"step": 2121, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2122.0, 1.0, 1.0, 1.0, 2122.0, 2122.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.302, -5.269, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5129, "number_of_timesteps": 95829, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.012222222222222218, "biggest_recent_change": 0.3000000000000007},
{"step": 2122, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2123.0, 1.0, 1.0, 1.0, 2123.0, 2123.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.262, 0.0, 0.0, 0.0, -5.303, -5.27, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5132, "number_of_timesteps": 95867, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 2123, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2124.0, 1.0, 1.0, 1.0, 2124.0, 2124.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.301, -5.268, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5138, "number_of_timesteps": 95930, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"step": 2124, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2125.0, 1.0, 1.0, 1.0, 2125.0, 2125.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.259, 0.0, 0.0, 0.0, -5.299, -5.266, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5141, "number_of_timesteps": 95959, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"step": 2125, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2126.0, 1.0, 1.0, 1.0, 2126.0, 2126.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.3, -5.263, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5146, "number_of_timesteps": 96010, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 2126, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2127.0, 1.0, 1.0, 1.0, 2127.0, 2127.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.298, -5.264, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5148, "number_of_timesteps": 96034, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.009999999999999985, "biggest_recent_change": 0.1999999999999993},
{"step": 2127, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2128.0, 1.0, 1.0, 1.0, 2128.0, 2128.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.259, 0.0, 0.0, 0.0, -5.295, -5.261, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5152, "number_of_timesteps": 96074, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2128, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2129.0, 1.0, 1.0, 1.0, 2129.0, 2129.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.257, 0.0, 0.0, 0.0, -5.293, -5.259, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5157, "number_of_timesteps": 96136, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 2129, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2130.0, 1.0, 1.0, 1.0, 2130.0, 2130.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.258, 0.0, 0.0, 0.0, -5.293, -5.259, 0.0, 0.0, 0.0]}
{"step": 2130, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2131.0, 1.0, 1.0, 1.0, 2131.0, 2131.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.259, 0.0, 0.0, 0.0, -5.294, -5.26, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5165, "number_of_timesteps": 96217, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.3000000000000007},
{"step": 2131, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2132.0, 1.0, 1.0, 1.0, 2132.0, 2132.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.261, 0.0, 0.0, 0.0, -5.294, -5.261, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5170, "number_of_timesteps": 96269, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.34999999999999964},
{"step": 2132, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2133.0, 1.0, 1.0, 1.0, 2133.0, 2133.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.3, -5.266, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5173, "number_of_timesteps": 96298, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 2133, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2134.0, 1.0, 1.0, 1.0, 2134.0, 2134.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.297, -5.266, 0.0, 0.0, 0.0]}
{"step": 2134, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2135.0, 1.0, 1.0, 1.0, 2135.0, 2135.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.295, -5.266, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5182, "number_of_timesteps": 96398, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.3000000000000007},
{"step": 2135, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2136.0, 1.0, 1.0, 1.0, 2136.0, 2136.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.292, -5.264, 0.0, 0.0, 0.0]}
{"step": 2136, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2137.0, 1.0, 1.0, 1.0, 2137.0, 2137.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.293, -5.264, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5189, "number_of_timesteps": 96465, "per_episode_reward": 14.75, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.34999999999999964},
{"step": 2137, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2138.0, 1.0, 1.0, 1.0, 2138.0, 2138.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.297, -5.269, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5196, "number_of_timesteps": 96542, "per_episode_reward": 14.75, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"step": 2138, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2139.0, 1.0, 1.0, 1.0, 2139.0, 2139.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.298, -5.269, 0.0, 0.0, 0.0]}
{"step": 2139, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2140.0, 1.0, 1.0, 1.0, 2140.0, 2140.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.297, -5.269, 0.0, 0.0, 0.0]}
{"eval_score": 10.4, "number_of_episodes": 5203}
{"number_of_episodes": 5203, "number_of_timesteps": 96611, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3000000000000007},
{"step": 2140, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2141.0, 1.0, 1.0, 1.0, 2141.0, 2141.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.271, 0.0, 0.0, 0.0, -5.301, -5.273, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5206, "number_of_timesteps": 96648, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 2141, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2142.0, 1.0, 1.0, 1.0, 2142.0, 2142.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.269, 0.0, 0.0, 0.0, -5.299, -5.27, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5211, "number_of_timesteps": 96699, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.1999999999999993},
{"step": 2142, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2143.0, 1.0, 1.0, 1.0, 2143.0, 2143.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.296, -5.268, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5214, "number_of_timesteps": 96730, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2143, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2144.0, 1.0, 1.0, 1.0, 2144.0, 2144.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.265, 0.0, 0.0, 0.0, -5.299, -5.271, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5220, "number_of_timesteps": 96790, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.00944444444444446, "biggest_recent_change": 0.3000000000000007},
{"step": 2144, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2145.0, 1.0, 1.0, 1.0, 2145.0, 2145.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.266, 0.0, 0.0, 0.0, -5.3, -5.271, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5223, "number_of_timesteps": 96820, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2145, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2146.0, 1.0, 1.0, 1.0, 2146.0, 2146.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.267, 0.0, 0.0, 0.0, -5.297, -5.272, 0.0, 0.0, 0.0]}
{"step": 2146, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2147.0, 1.0, 1.0, 1.0, 2147.0, 2147.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.268, 0.0, 0.0, 0.0, -5.295, -5.272, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5233, "number_of_timesteps": 96923, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.34999999999999964},
{"step": 2147, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2148.0, 1.0, 1.0, 1.0, 2148.0, 2148.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.299, -5.277, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5236, "number_of_timesteps": 96951, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.1999999999999993},
{"step": 2148, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2149.0, 1.0, 1.0, 1.0, 2149.0, 2149.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.296, -5.274, 0.0, 0.0, 0.0]}
{"step": 2149, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2150.0, 1.0, 1.0, 1.0, 2150.0, 2150.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.295, -5.273, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5245, "number_of_timesteps": 97049, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.34999999999999964},
{"step": 2150, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2151.0, 1.0, 1.0, 1.0, 2151.0, 2151.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.3, -5.278, 0.0, 0.0, 0.0]}
{"step": 2151, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2152.0, 1.0, 1.0, 1.0, 2152.0, 2152.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.305, -5.282, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5255, "number_of_timesteps": 97150, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.015000000000000017, "biggest_recent_change": 0.45000000000000107},
{"step": 2152, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2153.0, 1.0, 1.0, 1.0, 2153.0, 2153.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.306, -5.284, 0.0, 0.0, 0.0]}
{"step": 2153, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2154.0, 1.0, 1.0, 1.0, 2154.0, 2154.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.304, -5.282, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5261, "number_of_timesteps": 97209, "per_episode_reward": 14.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 2154, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2155.0, 1.0, 1.0, 1.0, 2155.0, 2155.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.302, -5.279, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5267, "number_of_timesteps": 97273, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.1999999999999993},
{"step": 2155, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2156.0, 1.0, 1.0, 1.0, 2156.0, 2156.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.303, -5.28, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5269, "number_of_timesteps": 97293, "per_episode_reward": 14.65, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.34999999999999964},
{"step": 2156, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2157.0, 1.0, 1.0, 1.0, 2157.0, 2157.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.285, 0.0, 0.0, 0.0, -5.307, -5.285, 0.0, 0.0, 0.0]}
{"step": 2157, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2158.0, 1.0, 1.0, 1.0, 2158.0, 2158.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.286, 0.0, 0.0, 0.0, -5.307, -5.285, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5278, "number_of_timesteps": 97392, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2158, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2159.0, 1.0, 1.0, 1.0, 2159.0, 2159.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.284, 0.0, 0.0, 0.0, -5.314, -5.291, 0.0, 0.0, 0.0]}
{"step": 2159, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2160.0, 1.0, 1.0, 1.0, 2160.0, 2160.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.312, -5.289, 0.0, 0.0, 0.0]}
{"step": 2160, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2161.0, 1.0, 1.0, 1.0, 2161.0, 2161.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.317, -5.294, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5291, "number_of_timesteps": 97525, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2161, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2162.0, 1.0, 1.0, 1.0, 2162.0, 2162.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.314, -5.292, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5295, "number_of_timesteps": 97564, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.20000000000000107},
{"step": 2162, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2163.0, 1.0, 1.0, 1.0, 2163.0, 2163.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.315, -5.292, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5300, "number_of_timesteps": 97616, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.3000000000000007},
{"step": 2163, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2164.0, 1.0, 1.0, 1.0, 2164.0, 2164.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.315, -5.293, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5303, "number_of_timesteps": 97645, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 2164, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2165.0, 1.0, 1.0, 1.0, 2165.0, 2165.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.316, -5.29, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5308, "number_of_timesteps": 97697, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2165, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2166.0, 1.0, 1.0, 1.0, 2166.0, 2166.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.321, -5.295, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5311, "number_of_timesteps": 97731, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.20000000000000107},
{"step": 2166, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2167.0, 1.0, 1.0, 1.0, 2167.0, 2167.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.321, -5.295, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5315, "number_of_timesteps": 97771, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 2167, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2168.0, 1.0, 1.0, 1.0, 2168.0, 2168.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.318, -5.296, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5320, "number_of_timesteps": 97820, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2168, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2169.0, 1.0, 1.0, 1.0, 2169.0, 2169.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.316, -5.294, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5323, "number_of_timesteps": 97867, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 2169, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2170.0, 1.0, 1.0, 1.0, 2170.0, 2170.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.315, -5.291, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5329, "number_of_timesteps": 97927, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 2170, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2171.0, 1.0, 1.0, 1.0, 2171.0, 2171.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.313, -5.292, 0.0, 0.0, 0.0]}
{"eval_score": 10.8, "number_of_episodes": 5331}
{"number_of_episodes": 5331, "number_of_timesteps": 97947, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 2171, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2172.0, 1.0, 1.0, 1.0, 2172.0, 2172.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.31, -5.29, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5335, "number_of_timesteps": 97991, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2172, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2173.0, 1.0, 1.0, 1.0, 2173.0, 2173.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.308, -5.287, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5340, "number_of_timesteps": 98046, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 2173, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2174.0, 1.0, 1.0, 1.0, 2174.0, 2174.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.275, 0.0, 0.0, 0.0, -5.305, -5.286, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5345, "number_of_timesteps": 98093, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2174, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2175.0, 1.0, 1.0, 1.0, 2175.0, 2175.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.273, 0.0, 0.0, 0.0, -5.303, -5.284, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5348, "number_of_timesteps": 98121, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 2175, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2176.0, 1.0, 1.0, 1.0, 2176.0, 2176.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.274, 0.0, 0.0, 0.0, -5.303, -5.281, 0.0, 0.0, 0.0]}
{"step": 2176, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2177.0, 1.0, 1.0, 1.0, 2177.0, 2177.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.272, 0.0, 0.0, 0.0, -5.301, -5.279, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5356, "number_of_timesteps": 98206, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.1999999999999993},
{"step": 2177, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2178.0, 1.0, 1.0, 1.0, 2178.0, 2178.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.27, 0.0, 0.0, 0.0, -5.299, -5.276, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5362, "number_of_timesteps": 98266, "per_episode_reward": 14.6, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.34999999999999964},
{"step": 2178, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2179.0, 1.0, 1.0, 1.0, 2179.0, 2179.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.304, -5.282, 0.0, 0.0, 0.0]}
{"step": 2179, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2180.0, 1.0, 1.0, 1.0, 2180.0, 2180.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.284, 0.0, 0.0, 0.0, -5.311, -5.289, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5370, "number_of_timesteps": 98351, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.20000000000000107},
{"step": 2180, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2181.0, 1.0, 1.0, 1.0, 2181.0, 2181.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.282, 0.0, 0.0, 0.0, -5.31, -5.288, 0.0, 0.0, 0.0]}
{"step": 2181, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2182.0, 1.0, 1.0, 1.0, 2182.0, 2182.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.314, -5.292, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5378, "number_of_timesteps": 98434, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.1999999999999993},
{"step": 2182, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2183.0, 1.0, 1.0, 1.0, 2183.0, 2183.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.312, -5.29, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5382, "number_of_timesteps": 98479, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.20000000000000107},
{"step": 2183, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2184.0, 1.0, 1.0, 1.0, 2184.0, 2184.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.276, 0.0, 0.0, 0.0, -5.317, -5.295, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5385, "number_of_timesteps": 98514, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.34999999999999964},
{"step": 2184, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2185.0, 1.0, 1.0, 1.0, 2185.0, 2185.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.322, -5.3, 0.0, 0.0, 0.0]}
{"step": 2185, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2186.0, 1.0, 1.0, 1.0, 2186.0, 2186.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.327, -5.305, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5395, "number_of_timesteps": 98621, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.20000000000000107},
{"step": 2186, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2187.0, 1.0, 1.0, 1.0, 2187.0, 2187.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.325, -5.303, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5396, "number_of_timesteps": 98629, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.1999999999999993},
{"step": 2187, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2188.0, 1.0, 1.0, 1.0, 2188.0, 2188.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.322, -5.304, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5401, "number_of_timesteps": 98678, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.29999999999999893},
{"step": 2188, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2189.0, 1.0, 1.0, 1.0, 2189.0, 2189.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.323, -5.304, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5405, "number_of_timesteps": 98729, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.15000000000000036},
{"step": 2189, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2190.0, 1.0, 1.0, 1.0, 2190.0, 2190.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.322, -5.302, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5411, "number_of_timesteps": 98790, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.1999999999999993},
{"step": 2190, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2191.0, 1.0, 1.0, 1.0, 2191.0, 2191.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.281, 0.0, 0.0, 0.0, -5.32, -5.303, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5413, "number_of_timesteps": 98807, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.20000000000000107},
{"step": 2191, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2192.0, 1.0, 1.0, 1.0, 2192.0, 2192.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.325, -5.307, 0.0, 0.0, 0.0]}
{"step": 2192, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2193.0, 1.0, 1.0, 1.0, 2193.0, 2193.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.277, 0.0, 0.0, 0.0, -5.322, -5.305, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5422, "number_of_timesteps": 98909, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 2193, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2194.0, 1.0, 1.0, 1.0, 2194.0, 2194.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.279, 0.0, 0.0, 0.0, -5.323, -5.303, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5424, "number_of_timesteps": 98930, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.1999999999999993},
{"step": 2194, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2195.0, 1.0, 1.0, 1.0, 2195.0, 2195.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.28, 0.0, 0.0, 0.0, -5.324, -5.303, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5431, "number_of_timesteps": 99002, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2195, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2196.0, 1.0, 1.0, 1.0, 2196.0, 2196.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.278, 0.0, 0.0, 0.0, -5.321, -5.301, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5433, "number_of_timesteps": 99023, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.34999999999999964},
{"step": 2196, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2197.0, 1.0, 1.0, 1.0, 2197.0, 2197.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.288, 0.0, 0.0, 0.0, -5.332, -5.311, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5436, "number_of_timesteps": 99054, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2197, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2198.0, 1.0, 1.0, 1.0, 2198.0, 2198.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.286, 0.0, 0.0, 0.0, -5.335, -5.315, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5442, "number_of_timesteps": 99124, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 2198, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2199.0, 1.0, 1.0, 1.0, 2199.0, 2199.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.288, 0.0, 0.0, 0.0, -5.337, -5.312, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5445, "number_of_timesteps": 99155, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.34999999999999964},
{"step": 2199, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2200.0, 1.0, 1.0, 1.0, 2200.0, 2200.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.299, 0.0, 0.0, 0.0, -5.347, -5.323, 0.0, 0.0, 0.0]}
{"step": 2200, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2201.0, 1.0, 1.0, 1.0, 2201.0, 2201.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.349, -5.324, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5452, "number_of_timesteps": 99230, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.20000000000000107},
{"step": 2201, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2202.0, 1.0, 1.0, 1.0, 2202.0, 2202.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.349, -5.325, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5458, "number_of_timesteps": 99302, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.1999999999999993},
{"step": 2202, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2203.0, 1.0, 1.0, 1.0, 2203.0, 2203.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.349, -5.325, 0.0, 0.0, 0.0]}
{"eval_score": 9.9, "number_of_episodes": 5462}
{"number_of_episodes": 5462, "number_of_timesteps": 99339, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"step": 2203, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2204.0, 1.0, 1.0, 1.0, 2204.0, 2204.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.308, 0.0, 0.0, 0.0, -5.353, -5.329, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5468, "number_of_timesteps": 99394, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2204, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2205.0, 1.0, 1.0, 1.0, 2205.0, 2205.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.306, 0.0, 0.0, 0.0, -5.359, -5.334, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5469, "number_of_timesteps": 99403, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.15000000000000036},
{"step": 2205, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2206.0, 1.0, 1.0, 1.0, 2206.0, 2206.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.356, -5.332, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5475, "number_of_timesteps": 99470, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.1999999999999993},
{"step": 2206, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2207.0, 1.0, 1.0, 1.0, 2207.0, 2207.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.305, 0.0, 0.0, 0.0, -5.357, -5.333, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5479, "number_of_timesteps": 99513, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2207, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2208.0, 1.0, 1.0, 1.0, 2208.0, 2208.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.306, 0.0, 0.0, 0.0, -5.354, -5.333, 0.0, 0.0, 0.0]}
{"step": 2208, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2209.0, 1.0, 1.0, 1.0, 2209.0, 2209.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.308, 0.0, 0.0, 0.0, -5.356, -5.334, 0.0, 0.0, 0.0]}
{"step": 2209, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2210.0, 1.0, 1.0, 1.0, 2210.0, 2210.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.353, -5.333, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5489, "number_of_timesteps": 99620, "per_episode_reward": 14.5, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.20000000000000107},
{"step": 2210, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2211.0, 1.0, 1.0, 1.0, 2211.0, 2211.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.305, 0.0, 0.0, 0.0, -5.351, -5.331, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5494, "number_of_timesteps": 99679, "per_episode_reward": 14.45, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
{"step": 2211, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2212.0, 1.0, 1.0, 1.0, 2212.0, 2212.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.306, 0.0, 0.0, 0.0, -5.351, -5.329, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5498, "number_of_timesteps": 99724, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.20000000000000107},
{"step": 2212, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2213.0, 1.0, 1.0, 1.0, 2213.0, 2213.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.349, -5.326, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5501, "number_of_timesteps": 99753, "per_episode_reward": 14.4, "episode_reward_trend_value": -0.008888888888888877, "biggest_recent_change": 0.29999999999999893},
{"step": 2213, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2214.0, 1.0, 1.0, 1.0, 2214.0, 2214.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.349, -5.326, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5504, "number_of_timesteps": 99788, "per_episode_reward": 14.35, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.20000000000000107},
{"step": 2214, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2215.0, 1.0, 1.0, 1.0, 2215.0, 2215.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.305, 0.0, 0.0, 0.0, -5.349, -5.327, 0.0, 0.0, 0.0]}
{"step": 2215, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2216.0, 1.0, 1.0, 1.0, 2216.0, 2216.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.306, 0.0, 0.0, 0.0, -5.349, -5.327, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5514, "number_of_timesteps": 99898, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.15000000000000036},
{"step": 2216, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2217.0, 1.0, 1.0, 1.0, 2217.0, 2217.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.306, 0.0, 0.0, 0.0, -5.349, -5.325, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5518, "number_of_timesteps": 99935, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.008888888888888877, "biggest_recent_change": 0.1999999999999993},
{"step": 2217, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2218.0, 1.0, 1.0, 1.0, 2218.0, 2218.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.35, -5.325, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5521, "number_of_timesteps": 99968, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 2218, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2219.0, 1.0, 1.0, 1.0, 2219.0, 2219.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.305, 0.0, 0.0, 0.0, -5.351, -5.326, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5525, "number_of_timesteps": 100014, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.009999999999999985, "biggest_recent_change": 0.20000000000000107},
{"step": 2219, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2220.0, 1.0, 1.0, 1.0, 2220.0, 2220.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.306, 0.0, 0.0, 0.0, -5.351, -5.326, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5530, "number_of_timesteps": 100069, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.009999999999999985, "biggest_recent_change": 0.29999999999999893},
{"step": 2220, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2221.0, 1.0, 1.0, 1.0, 2221.0, 2221.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.351, -5.326, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5534, "number_of_timesteps": 100111, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"step": 2221, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2222.0, 1.0, 1.0, 1.0, 2222.0, 2222.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.308, 0.0, 0.0, 0.0, -5.352, -5.324, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5538, "number_of_timesteps": 100151, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.008888888888888877, "biggest_recent_change": 0.20000000000000107},
{"step": 2222, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2223.0, 1.0, 1.0, 1.0, 2223.0, 2223.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.308, 0.0, 0.0, 0.0, -5.352, -5.324, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5542, "number_of_timesteps": 100194, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.009999999999999985, "biggest_recent_change": 0.29999999999999893},
{"step": 2223, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2224.0, 1.0, 1.0, 1.0, 2224.0, 2224.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.309, 0.0, 0.0, 0.0, -5.352, -5.325, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5546, "number_of_timesteps": 100239, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"step": 2224, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2225.0, 1.0, 1.0, 1.0, 2225.0, 2225.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.357, -5.329, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5550, "number_of_timesteps": 100282, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.1999999999999993},
{"step": 2225, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2226.0, 1.0, 1.0, 1.0, 2226.0, 2226.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.355, -5.327, 0.0, 0.0, 0.0]}
{"step": 2226, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2227.0, 1.0, 1.0, 1.0, 2227.0, 2227.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.31, 0.0, 0.0, 0.0, -5.352, -5.325, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5558, "number_of_timesteps": 100365, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.10000000000000142},
{"step": 2227, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2228.0, 1.0, 1.0, 1.0, 2228.0, 2228.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.353, -5.325, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5561, "number_of_timesteps": 100401, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 2228, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2229.0, 1.0, 1.0, 1.0, 2229.0, 2229.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.317, 0.0, 0.0, 0.0, -5.358, -5.33, 0.0, 0.0, 0.0]}
{"step": 2229, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2230.0, 1.0, 1.0, 1.0, 2230.0, 2230.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.318, 0.0, 0.0, 0.0, -5.358, -5.331, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5569, "number_of_timesteps": 100488, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.14999999999999858},
{"step": 2230, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2231.0, 1.0, 1.0, 1.0, 2231.0, 2231.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.318, 0.0, 0.0, 0.0, -5.358, -5.328, 0.0, 0.0, 0.0]}
{"step": 2231, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2232.0, 1.0, 1.0, 1.0, 2232.0, 2232.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.319, 0.0, 0.0, 0.0, -5.358, -5.326, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5578, "number_of_timesteps": 100586, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.008888888888888877, "biggest_recent_change": 0.1999999999999993},
{"step": 2232, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2233.0, 1.0, 1.0, 1.0, 2233.0, 2233.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.317, 0.0, 0.0, 0.0, -5.356, -5.323, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5581, "number_of_timesteps": 100614, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2233, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2234.0, 1.0, 1.0, 1.0, 2234.0, 2234.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.316, 0.0, 0.0, 0.0, -5.354, -5.321, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5586, "number_of_timesteps": 100666, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 2234, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2235.0, 1.0, 1.0, 1.0, 2235.0, 2235.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.317, 0.0, 0.0, 0.0, -5.354, -5.322, 0.0, 0.0, 0.0]}
{"eval_score": 11.4, "number_of_episodes": 5590}
{"step": 2235, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2236.0, 1.0, 1.0, 1.0, 2236.0, 2236.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.325, 0.0, 0.0, 0.0, -5.362, -5.33, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5592, "number_of_timesteps": 100737, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.008888888888888877, "biggest_recent_change": 0.1999999999999993},
{"step": 2236, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2237.0, 1.0, 1.0, 1.0, 2237.0, 2237.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.323, 0.0, 0.0, 0.0, -5.36, -5.328, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5599, "number_of_timesteps": 100811, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 2237, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2238.0, 1.0, 1.0, 1.0, 2238.0, 2238.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.321, 0.0, 0.0, 0.0, -5.365, -5.333, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5601, "number_of_timesteps": 100836, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2238, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2239.0, 1.0, 1.0, 1.0, 2239.0, 2239.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.323, 0.0, 0.0, 0.0, -5.366, -5.334, 0.0, 0.0, 0.0]}
{"step": 2239, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2240.0, 1.0, 1.0, 1.0, 2240.0, 2240.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.321, 0.0, 0.0, 0.0, -5.37, -5.338, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5610, "number_of_timesteps": 100929, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2240, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2241.0, 1.0, 1.0, 1.0, 2241.0, 2241.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.319, 0.0, 0.0, 0.0, -5.368, -5.336, 0.0, 0.0, 0.0]}
{"step": 2241, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2242.0, 1.0, 1.0, 1.0, 2242.0, 2242.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.317, 0.0, 0.0, 0.0, -5.365, -5.333, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5618, "number_of_timesteps": 101015, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.14999999999999858},
{"step": 2242, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2243.0, 1.0, 1.0, 1.0, 2243.0, 2243.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.318, 0.0, 0.0, 0.0, -5.366, -5.331, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5622, "number_of_timesteps": 101057, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 2243, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2244.0, 1.0, 1.0, 1.0, 2244.0, 2244.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.316, 0.0, 0.0, 0.0, -5.369, -5.334, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5627, "number_of_timesteps": 101109, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2244, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2245.0, 1.0, 1.0, 1.0, 2245.0, 2245.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.367, -5.332, 0.0, 0.0, 0.0]}
{"step": 2245, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2246.0, 1.0, 1.0, 1.0, 2246.0, 2246.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.365, -5.329, 0.0, 0.0, 0.0]}
{"step": 2246, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2247.0, 1.0, 1.0, 1.0, 2247.0, 2247.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.31, 0.0, 0.0, 0.0, -5.362, -5.327, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5639, "number_of_timesteps": 101238, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.15000000000000036},
{"step": 2247, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2248.0, 1.0, 1.0, 1.0, 2248.0, 2248.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.311, 0.0, 0.0, 0.0, -5.363, -5.328, 0.0, 0.0, 0.0]}
{"step": 2248, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2249.0, 1.0, 1.0, 1.0, 2249.0, 2249.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.363, -5.328, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5645, "number_of_timesteps": 101300, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.1999999999999993},
{"step": 2249, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2250.0, 1.0, 1.0, 1.0, 2250.0, 2250.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.31, 0.0, 0.0, 0.0, -5.36, -5.325, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5650, "number_of_timesteps": 101357, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2250, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2251.0, 1.0, 1.0, 1.0, 2251.0, 2251.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.308, 0.0, 0.0, 0.0, -5.358, -5.323, 0.0, 0.0, 0.0]}
{"step": 2251, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2252.0, 1.0, 1.0, 1.0, 2252.0, 2252.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.306, 0.0, 0.0, 0.0, -5.356, -5.321, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5655, "number_of_timesteps": 101411, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.1999999999999993},
{"step": 2252, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2253.0, 1.0, 1.0, 1.0, 2253.0, 2253.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.362, -5.327, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5660, "number_of_timesteps": 101474, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.1999999999999993},
{"step": 2253, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2254.0, 1.0, 1.0, 1.0, 2254.0, 2254.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.362, -5.327, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5664, "number_of_timesteps": 101516, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2254, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2255.0, 1.0, 1.0, 1.0, 2255.0, 2255.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.305, 0.0, 0.0, 0.0, -5.362, -5.327, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5668, "number_of_timesteps": 101565, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.1999999999999993},
{"step": 2255, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2256.0, 1.0, 1.0, 1.0, 2256.0, 2256.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.366, -5.331, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5674, "number_of_timesteps": 101627, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.3000000000000007},
{"step": 2256, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2257.0, 1.0, 1.0, 1.0, 2257.0, 2257.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.364, -5.329, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5676, "number_of_timesteps": 101646, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2257, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2258.0, 1.0, 1.0, 1.0, 2258.0, 2258.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.365, -5.33, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5682, "number_of_timesteps": 101707, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.1999999999999993},
{"step": 2258, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2259.0, 1.0, 1.0, 1.0, 2259.0, 2259.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.305, 0.0, 0.0, 0.0, -5.362, -5.331, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5684, "number_of_timesteps": 101730, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 2259, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2260.0, 1.0, 1.0, 1.0, 2260.0, 2260.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.365, -5.334, 0.0, 0.0, 0.0]}
{"step": 2260, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2261.0, 1.0, 1.0, 1.0, 2261.0, 2261.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.363, -5.334, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5693, "number_of_timesteps": 101824, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.14999999999999858},
{"step": 2261, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2262.0, 1.0, 1.0, 1.0, 2262.0, 2262.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.362, -5.332, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5697, "number_of_timesteps": 101865, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.10000000000000142},
{"step": 2262, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2263.0, 1.0, 1.0, 1.0, 2263.0, 2263.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.361, -5.33, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5701, "number_of_timesteps": 101909, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 2263, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2264.0, 1.0, 1.0, 1.0, 2264.0, 2264.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.366, -5.335, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5705, "number_of_timesteps": 101953, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 2264, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2265.0, 1.0, 1.0, 1.0, 2265.0, 2265.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.366, -5.336, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5710, "number_of_timesteps": 102005, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.14999999999999858},
{"step": 2265, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2266.0, 1.0, 1.0, 1.0, 2266.0, 2266.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.365, -5.333, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5714, "number_of_timesteps": 102044, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2266, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2267.0, 1.0, 1.0, 1.0, 2267.0, 2267.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.363, -5.333, 0.0, 0.0, 0.0]}
{"step": 2267, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2268.0, 1.0, 1.0, 1.0, 2268.0, 2268.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.36, -5.334, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 5721}
{"number_of_episodes": 5721, "number_of_timesteps": 102119, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 2268, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2269.0, 1.0, 1.0, 1.0, 2269.0, 2269.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.365, -5.339, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5727, "number_of_timesteps": 102185, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.10000000000000142},
{"step": 2269, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2270.0, 1.0, 1.0, 1.0, 2270.0, 2270.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.365, -5.339, 0.0, 0.0, 0.0]}
{"step": 2270, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2271.0, 1.0, 1.0, 1.0, 2271.0, 2271.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.299, 0.0, 0.0, 0.0, -5.37, -5.344, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5736, "number_of_timesteps": 102273, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 2271, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2272.0, 1.0, 1.0, 1.0, 2272.0, 2272.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.371, -5.345, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5738, "number_of_timesteps": 102291, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"step": 2272, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2273.0, 1.0, 1.0, 1.0, 2273.0, 2273.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.299, 0.0, 0.0, 0.0, -5.369, -5.342, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5744, "number_of_timesteps": 102353, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 2273, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2274.0, 1.0, 1.0, 1.0, 2274.0, 2274.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.297, 0.0, 0.0, 0.0, -5.374, -5.347, 0.0, 0.0, 0.0]}
{"step": 2274, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2275.0, 1.0, 1.0, 1.0, 2275.0, 2275.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.295, 0.0, 0.0, 0.0, -5.379, -5.352, 0.0, 0.0, 0.0]}
{"step": 2275, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2276.0, 1.0, 1.0, 1.0, 2276.0, 2276.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.293, 0.0, 0.0, 0.0, -5.383, -5.356, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5757, "number_of_timesteps": 102495, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2276, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2277.0, 1.0, 1.0, 1.0, 2277.0, 2277.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.38, -5.354, 0.0, 0.0, 0.0]}
{"step": 2277, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2278.0, 1.0, 1.0, 1.0, 2278.0, 2278.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.289, 0.0, 0.0, 0.0, -5.378, -5.352, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5766, "number_of_timesteps": 102582, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.012222222222222218, "biggest_recent_change": 0.3000000000000007},
{"step": 2278, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2279.0, 1.0, 1.0, 1.0, 2279.0, 2279.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.287, 0.0, 0.0, 0.0, -5.376, -5.349, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5767, "number_of_timesteps": 102593, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 2279, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2280.0, 1.0, 1.0, 1.0, 2280.0, 2280.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.289, 0.0, 0.0, 0.0, -5.377, -5.351, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5771, "number_of_timesteps": 102636, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.20000000000000107},
{"step": 2280, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2281.0, 1.0, 1.0, 1.0, 2281.0, 2281.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.287, 0.0, 0.0, 0.0, -5.375, -5.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5776, "number_of_timesteps": 102697, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2281, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2282.0, 1.0, 1.0, 1.0, 2282.0, 2282.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.289, 0.0, 0.0, 0.0, -5.372, -5.349, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5777, "number_of_timesteps": 102711, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.14999999999999858},
{"step": 2282, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2283.0, 1.0, 1.0, 1.0, 2283.0, 2283.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.288, 0.0, 0.0, 0.0, -5.371, -5.347, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5784, "number_of_timesteps": 102784, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.20000000000000107},
{"step": 2283, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2284.0, 1.0, 1.0, 1.0, 2284.0, 2284.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.376, -5.352, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5787, "number_of_timesteps": 102817, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.10000000000000142},
{"step": 2284, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2285.0, 1.0, 1.0, 1.0, 2285.0, 2285.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.295, 0.0, 0.0, 0.0, -5.377, -5.353, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5790, "number_of_timesteps": 102846, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.012222222222222218, "biggest_recent_change": 0.3000000000000007},
{"step": 2285, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2286.0, 1.0, 1.0, 1.0, 2286.0, 2286.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.293, 0.0, 0.0, 0.0, -5.375, -5.351, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5796, "number_of_timesteps": 102909, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2286, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2287.0, 1.0, 1.0, 1.0, 2287.0, 2287.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.372, -5.351, 0.0, 0.0, 0.0]}
{"step": 2287, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2288.0, 1.0, 1.0, 1.0, 2288.0, 2288.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.295, 0.0, 0.0, 0.0, -5.37, -5.352, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5803, "number_of_timesteps": 102981, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2288, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2289.0, 1.0, 1.0, 1.0, 2289.0, 2289.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.375, -5.357, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5807, "number_of_timesteps": 103026, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2289, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2290.0, 1.0, 1.0, 1.0, 2290.0, 2290.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.376, -5.358, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5813, "number_of_timesteps": 103084, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2290, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2291.0, 1.0, 1.0, 1.0, 2291.0, 2291.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.374, -5.356, 0.0, 0.0, 0.0]}
{"step": 2291, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2292.0, 1.0, 1.0, 1.0, 2292.0, 2292.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.374, -5.356, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5820, "number_of_timesteps": 103154, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.3000000000000007},
{"step": 2292, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2293.0, 1.0, 1.0, 1.0, 2293.0, 2293.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.372, -5.354, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5824, "number_of_timesteps": 103198, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.20000000000000107},
{"step": 2293, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2294.0, 1.0, 1.0, 1.0, 2294.0, 2294.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.298, 0.0, 0.0, 0.0, -5.37, -5.352, 0.0, 0.0, 0.0]}
{"step": 2294, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2295.0, 1.0, 1.0, 1.0, 2295.0, 2295.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.296, 0.0, 0.0, 0.0, -5.367, -5.349, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5833, "number_of_timesteps": 103291, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3000000000000007},
{"step": 2295, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2296.0, 1.0, 1.0, 1.0, 2296.0, 2296.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.365, -5.347, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5837, "number_of_timesteps": 103332, "per_episode_reward": 14.05, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2296, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2297.0, 1.0, 1.0, 1.0, 2297.0, 2297.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.37, -5.352, 0.0, 0.0, 0.0]}
{"step": 2297, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2298.0, 1.0, 1.0, 1.0, 2298.0, 2298.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.374, -5.356, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5846, "number_of_timesteps": 103425, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.25},
{"step": 2298, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2299.0, 1.0, 1.0, 1.0, 2299.0, 2299.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.372, -5.354, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5849, "number_of_timesteps": 103455, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2299, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2300.0, 1.0, 1.0, 1.0, 2300.0, 2300.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.37, -5.354, 0.0, 0.0, 0.0]}
{"eval_score": 9.8, "number_of_episodes": 5853}
{"number_of_episodes": 5853, "number_of_timesteps": 103496, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.10000000000000142},
{"step": 2300, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2301.0, 1.0, 1.0, 1.0, 2301.0, 2301.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.37, -5.355, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5858, "number_of_timesteps": 103553, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 2301, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2302.0, 1.0, 1.0, 1.0, 2302.0, 2302.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.376, -5.361, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5861, "number_of_timesteps": 103584, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2302, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2303.0, 1.0, 1.0, 1.0, 2303.0, 2303.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.375, -5.36, 0.0, 0.0, 0.0]}
{"step": 2303, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2304.0, 1.0, 1.0, 1.0, 2304.0, 2304.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.376, -5.361, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5870, "number_of_timesteps": 103679, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2304, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2305.0, 1.0, 1.0, 1.0, 2305.0, 2305.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.374, -5.361, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5876, "number_of_timesteps": 103741, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 2305, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2306.0, 1.0, 1.0, 1.0, 2306.0, 2306.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.379, -5.366, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5879, "number_of_timesteps": 103769, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"step": 2306, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2307.0, 1.0, 1.0, 1.0, 2307.0, 2307.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.379, -5.364, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5881, "number_of_timesteps": 103790, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2307, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2308.0, 1.0, 1.0, 1.0, 2308.0, 2308.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.377, -5.362, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5887, "number_of_timesteps": 103859, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"step": 2308, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2309.0, 1.0, 1.0, 1.0, 2309.0, 2309.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.377, -5.362, 0.0, 0.0, 0.0]}
{"step": 2309, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2310.0, 1.0, 1.0, 1.0, 2310.0, 2310.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.375, -5.359, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5894, "number_of_timesteps": 103941, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2310, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2311.0, 1.0, 1.0, 1.0, 2311.0, 2311.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.299, 0.0, 0.0, 0.0, -5.372, -5.357, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5899, "number_of_timesteps": 103997, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.14999999999999858},
{"step": 2311, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2312.0, 1.0, 1.0, 1.0, 2312.0, 2312.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.373, -5.355, 0.0, 0.0, 0.0]}
{"step": 2312, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2313.0, 1.0, 1.0, 1.0, 2313.0, 2313.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.298, 0.0, 0.0, 0.0, -5.37, -5.352, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5908, "number_of_timesteps": 104086, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2313, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2314.0, 1.0, 1.0, 1.0, 2314.0, 2314.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.299, 0.0, 0.0, 0.0, -5.368, -5.353, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5911, "number_of_timesteps": 104117, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2314, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2315.0, 1.0, 1.0, 1.0, 2315.0, 2315.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.369, -5.354, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5915, "number_of_timesteps": 104156, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2315, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2316.0, 1.0, 1.0, 1.0, 2316.0, 2316.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.369, -5.351, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5920, "number_of_timesteps": 104211, "per_episode_reward": 13.95, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.20000000000000107},
{"step": 2316, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2317.0, 1.0, 1.0, 1.0, 2317.0, 2317.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.299, 0.0, 0.0, 0.0, -5.367, -5.349, 0.0, 0.0, 0.0]}
{"step": 2317, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2318.0, 1.0, 1.0, 1.0, 2318.0, 2318.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.297, 0.0, 0.0, 0.0, -5.365, -5.347, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5926, "number_of_timesteps": 104276, "per_episode_reward": 13.95, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"step": 2318, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2319.0, 1.0, 1.0, 1.0, 2319.0, 2319.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.297, 0.0, 0.0, 0.0, -5.362, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5931, "number_of_timesteps": 104333, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2319, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2320.0, 1.0, 1.0, 1.0, 2320.0, 2320.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.298, 0.0, 0.0, 0.0, -5.363, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5934, "number_of_timesteps": 104371, "per_episode_reward": 14.0, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3000000000000007},
{"step": 2320, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2321.0, 1.0, 1.0, 1.0, 2321.0, 2321.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.296, 0.0, 0.0, 0.0, -5.36, -5.344, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5940, "number_of_timesteps": 104438, "per_episode_reward": 13.95, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.20000000000000107},
{"step": 2321, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2322.0, 1.0, 1.0, 1.0, 2322.0, 2322.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.364, -5.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5942, "number_of_timesteps": 104459, "per_episode_reward": 13.95, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 2322, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2323.0, 1.0, 1.0, 1.0, 2323.0, 2323.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.362, -5.348, 0.0, 0.0, 0.0]}
{"step": 2323, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2324.0, 1.0, 1.0, 1.0, 2324.0, 2324.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.359, -5.347, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5952, "number_of_timesteps": 104566, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2324, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2325.0, 1.0, 1.0, 1.0, 2325.0, 2325.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.298, 0.0, 0.0, 0.0, -5.357, -5.345, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5953, "number_of_timesteps": 104576, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.008888888888888877, "biggest_recent_change": 0.3000000000000007},
{"step": 2325, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2326.0, 1.0, 1.0, 1.0, 2326.0, 2326.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.296, 0.0, 0.0, 0.0, -5.355, -5.342, 0.0, 0.0, 0.0]}
{"step": 2326, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2327.0, 1.0, 1.0, 1.0, 2327.0, 2327.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.352, -5.34, 0.0, 0.0, 0.0]}
{"step": 2327, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2328.0, 1.0, 1.0, 1.0, 2328.0, 2328.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.293, 0.0, 0.0, 0.0, -5.35, -5.338, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5967, "number_of_timesteps": 104728, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3000000000000007},
{"step": 2328, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2329.0, 1.0, 1.0, 1.0, 2329.0, 2329.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.291, 0.0, 0.0, 0.0, -5.348, -5.336, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5971, "number_of_timesteps": 104773, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2329, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2330.0, 1.0, 1.0, 1.0, 2330.0, 2330.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.296, 0.0, 0.0, 0.0, -5.353, -5.34, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5974, "number_of_timesteps": 104802, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.09999999999999964},
{"step": 2330, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2331.0, 1.0, 1.0, 1.0, 2331.0, 2331.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.359, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5979, "number_of_timesteps": 104864, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2331, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2332.0, 1.0, 1.0, 1.0, 2332.0, 2332.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.358, -5.346, 0.0, 0.0, 0.0]}
{"eval_score": 11.0, "number_of_episodes": 5984}
{"number_of_episodes": 5984, "number_of_timesteps": 104916, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2332, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2333.0, 1.0, 1.0, 1.0, 2333.0, 2333.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.295, 0.0, 0.0, 0.0, -5.356, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5985, "number_of_timesteps": 104926, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.3000000000000007},
{"step": 2333, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2334.0, 1.0, 1.0, 1.0, 2334.0, 2334.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.294, 0.0, 0.0, 0.0, -5.354, -5.344, 0.0, 0.0, 0.0]}
{"step": 2334, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2335.0, 1.0, 1.0, 1.0, 2335.0, 2335.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.295, 0.0, 0.0, 0.0, -5.351, -5.345, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5995, "number_of_timesteps": 105034, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.25},
{"step": 2335, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2336.0, 1.0, 1.0, 1.0, 2336.0, 2336.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.296, 0.0, 0.0, 0.0, -5.352, -5.345, 0.0, 0.0, 0.0]}
{"number_of_episodes": 5999, "number_of_timesteps": 105073, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2336, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2337.0, 1.0, 1.0, 1.0, 2337.0, 2337.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.297, 0.0, 0.0, 0.0, -5.352, -5.343, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6004, "number_of_timesteps": 105133, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2337, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2338.0, 1.0, 1.0, 1.0, 2338.0, 2338.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.295, 0.0, 0.0, 0.0, -5.35, -5.341, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6007, "number_of_timesteps": 105168, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2338, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2339.0, 1.0, 1.0, 1.0, 2339.0, 2339.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.355, -5.345, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6012, "number_of_timesteps": 105220, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.25},
{"step": 2339, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2340.0, 1.0, 1.0, 1.0, 2340.0, 2340.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.355, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6015, "number_of_timesteps": 105251, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2340, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2341.0, 1.0, 1.0, 1.0, 2341.0, 2341.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.356, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6019, "number_of_timesteps": 105303, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2341, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2342.0, 1.0, 1.0, 1.0, 2342.0, 2342.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.36, -5.351, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6023, "number_of_timesteps": 105347, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2342, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2343.0, 1.0, 1.0, 1.0, 2343.0, 2343.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.308, 0.0, 0.0, 0.0, -5.362, -5.349, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6028, "number_of_timesteps": 105398, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.20000000000000107},
{"step": 2343, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2344.0, 1.0, 1.0, 1.0, 2344.0, 2344.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.359, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6032, "number_of_timesteps": 105439, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"step": 2344, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2345.0, 1.0, 1.0, 1.0, 2345.0, 2345.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.305, 0.0, 0.0, 0.0, -5.365, -5.352, 0.0, 0.0, 0.0]}
{"step": 2345, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2346.0, 1.0, 1.0, 1.0, 2346.0, 2346.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.362, -5.349, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6041, "number_of_timesteps": 105535, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 2346, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2347.0, 1.0, 1.0, 1.0, 2347.0, 2347.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.36, -5.35, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6043, "number_of_timesteps": 105555, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2347, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2348.0, 1.0, 1.0, 1.0, 2348.0, 2348.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.36, -5.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6049, "number_of_timesteps": 105615, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2348, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2349.0, 1.0, 1.0, 1.0, 2349.0, 2349.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.357, -5.345, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6051, "number_of_timesteps": 105638, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2349, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2350.0, 1.0, 1.0, 1.0, 2350.0, 2350.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.355, -5.343, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6056, "number_of_timesteps": 105689, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2350, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2351.0, 1.0, 1.0, 1.0, 2351.0, 2351.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.356, -5.344, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6061, "number_of_timesteps": 105742, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2351, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2352.0, 1.0, 1.0, 1.0, 2352.0, 2352.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.299, 0.0, 0.0, 0.0, -5.36, -5.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6064, "number_of_timesteps": 105770, "per_episode_reward": 13.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2352, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2353.0, 1.0, 1.0, 1.0, 2353.0, 2353.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.297, 0.0, 0.0, 0.0, -5.358, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6071, "number_of_timesteps": 105842, "per_episode_reward": 13.85, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"step": 2353, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2354.0, 1.0, 1.0, 1.0, 2354.0, 2354.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.298, 0.0, 0.0, 0.0, -5.359, -5.344, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6072, "number_of_timesteps": 105852, "per_episode_reward": 13.85, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.20000000000000107},
{"step": 2354, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2355.0, 1.0, 1.0, 1.0, 2355.0, 2355.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.305, 0.0, 0.0, 0.0, -5.365, -5.35, 0.0, 0.0, 0.0]}
{"step": 2355, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2356.0, 1.0, 1.0, 1.0, 2356.0, 2356.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.363, -5.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6082, "number_of_timesteps": 105964, "per_episode_reward": 13.8, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2356, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2357.0, 1.0, 1.0, 1.0, 2357.0, 2357.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.304, 0.0, 0.0, 0.0, -5.363, -5.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6085, "number_of_timesteps": 105992, "per_episode_reward": 13.8, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.25},
{"step": 2357, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2358.0, 1.0, 1.0, 1.0, 2358.0, 2358.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.305, 0.0, 0.0, 0.0, -5.363, -5.349, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6090, "number_of_timesteps": 106045, "per_episode_reward": 13.8, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2358, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2359.0, 1.0, 1.0, 1.0, 2359.0, 2359.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.303, 0.0, 0.0, 0.0, -5.361, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6094, "number_of_timesteps": 106088, "per_episode_reward": 13.8, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2359, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2360.0, 1.0, 1.0, 1.0, 2360.0, 2360.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.302, 0.0, 0.0, 0.0, -5.359, -5.345, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6100, "number_of_timesteps": 106145, "per_episode_reward": 13.8, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2360, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2361.0, 1.0, 1.0, 1.0, 2361.0, 2361.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.3, 0.0, 0.0, 0.0, -5.357, -5.343, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6104, "number_of_timesteps": 106181, "per_episode_reward": 13.8, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.09999999999999964},
{"step": 2361, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2362.0, 1.0, 1.0, 1.0, 2362.0, 2362.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.301, 0.0, 0.0, 0.0, -5.357, -5.34, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 6110}
{"number_of_episodes": 6110, "number_of_timesteps": 106238, "per_episode_reward": 13.8, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2362, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2363.0, 1.0, 1.0, 1.0, 2363.0, 2363.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.363, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6114, "number_of_timesteps": 106277, "per_episode_reward": 13.8, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2363, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2364.0, 1.0, 1.0, 1.0, 2364.0, 2364.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.305, 0.0, 0.0, 0.0, -5.36, -5.344, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6117, "number_of_timesteps": 106305, "per_episode_reward": 13.8, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2364, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2365.0, 1.0, 1.0, 1.0, 2365.0, 2365.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.307, 0.0, 0.0, 0.0, -5.362, -5.345, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6124, "number_of_timesteps": 106376, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.20000000000000107},
{"step": 2365, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2366.0, 1.0, 1.0, 1.0, 2366.0, 2366.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.305, 0.0, 0.0, 0.0, -5.359, -5.343, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6126, "number_of_timesteps": 106394, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2366, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2367.0, 1.0, 1.0, 1.0, 2367.0, 2367.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.306, 0.0, 0.0, 0.0, -5.36, -5.343, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6132, "number_of_timesteps": 106451, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2367, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2368.0, 1.0, 1.0, 1.0, 2368.0, 2368.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.365, -5.348, 0.0, 0.0, 0.0]}
{"step": 2368, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2369.0, 1.0, 1.0, 1.0, 2369.0, 2369.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.31, 0.0, 0.0, 0.0, -5.363, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6141, "number_of_timesteps": 106546, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.1999999999999993},
{"step": 2369, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2370.0, 1.0, 1.0, 1.0, 2370.0, 2370.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.311, 0.0, 0.0, 0.0, -5.363, -5.347, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6142, "number_of_timesteps": 106554, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2370, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2371.0, 1.0, 1.0, 1.0, 2371.0, 2371.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.315, 0.0, 0.0, 0.0, -5.367, -5.35, 0.0, 0.0, 0.0]}
{"step": 2371, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2372.0, 1.0, 1.0, 1.0, 2372.0, 2372.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.316, 0.0, 0.0, 0.0, -5.367, -5.35, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6151, "number_of_timesteps": 106649, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.20000000000000107},
{"step": 2372, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2373.0, 1.0, 1.0, 1.0, 2373.0, 2373.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.365, -5.348, 0.0, 0.0, 0.0]}
{"step": 2373, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2374.0, 1.0, 1.0, 1.0, 2374.0, 2374.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.363, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6160, "number_of_timesteps": 106741, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2374, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2375.0, 1.0, 1.0, 1.0, 2375.0, 2375.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.313, 0.0, 0.0, 0.0, -5.363, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6165, "number_of_timesteps": 106794, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2375, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2376.0, 1.0, 1.0, 1.0, 2376.0, 2376.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.363, -5.344, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6169, "number_of_timesteps": 106833, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2376, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2377.0, 1.0, 1.0, 1.0, 2377.0, 2377.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.368, -5.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6172, "number_of_timesteps": 106865, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2377, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2378.0, 1.0, 1.0, 1.0, 2378.0, 2378.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.313, 0.0, 0.0, 0.0, -5.369, -5.349, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6178, "number_of_timesteps": 106931, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2378, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2379.0, 1.0, 1.0, 1.0, 2379.0, 2379.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.366, -5.35, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6179, "number_of_timesteps": 106940, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2379, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2380.0, 1.0, 1.0, 1.0, 2380.0, 2380.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.313, 0.0, 0.0, 0.0, -5.365, -5.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6188, "number_of_timesteps": 107035, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.20000000000000107},
{"step": 2380, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2381.0, 1.0, 1.0, 1.0, 2381.0, 2381.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.311, 0.0, 0.0, 0.0, -5.363, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6188, "number_of_timesteps": 107035, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2381, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2382.0, 1.0, 1.0, 1.0, 2382.0, 2382.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.311, 0.0, 0.0, 0.0, -5.36, -5.346, 0.0, 0.0, 0.0]}
{"step": 2382, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2383.0, 1.0, 1.0, 1.0, 2383.0, 2383.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.358, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6198, "number_of_timesteps": 107139, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"step": 2383, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2384.0, 1.0, 1.0, 1.0, 2384.0, 2384.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.316, 0.0, 0.0, 0.0, -5.362, -5.35, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6203, "number_of_timesteps": 107188, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.20000000000000107},
{"step": 2384, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2385.0, 1.0, 1.0, 1.0, 2385.0, 2385.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.359, -5.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6207, "number_of_timesteps": 107231, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2385, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2386.0, 1.0, 1.0, 1.0, 2386.0, 2386.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.315, 0.0, 0.0, 0.0, -5.36, -5.345, 0.0, 0.0, 0.0]}
{"step": 2386, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2387.0, 1.0, 1.0, 1.0, 2387.0, 2387.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.358, -5.343, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6215, "number_of_timesteps": 107312, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 2387, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2388.0, 1.0, 1.0, 1.0, 2388.0, 2388.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.319, 0.0, 0.0, 0.0, -5.363, -5.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6221, "number_of_timesteps": 107374, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2388, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2389.0, 1.0, 1.0, 1.0, 2389.0, 2389.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.32, 0.0, 0.0, 0.0, -5.361, -5.349, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6224, "number_of_timesteps": 107402, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.20000000000000107},
{"step": 2389, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2390.0, 1.0, 1.0, 1.0, 2390.0, 2390.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.318, 0.0, 0.0, 0.0, -5.358, -5.347, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6228, "number_of_timesteps": 107440, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2390, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2391.0, 1.0, 1.0, 1.0, 2391.0, 2391.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.317, 0.0, 0.0, 0.0, -5.364, -5.353, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6233, "number_of_timesteps": 107494, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2391, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2392.0, 1.0, 1.0, 1.0, 2392.0, 2392.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.317, 0.0, 0.0, 0.0, -5.362, -5.353, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6235, "number_of_timesteps": 107518, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2392, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2393.0, 1.0, 1.0, 1.0, 2393.0, 2393.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.315, 0.0, 0.0, 0.0, -5.36, -5.35, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6239, "number_of_timesteps": 107563, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2393, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2394.0, 1.0, 1.0, 1.0, 2394.0, 2394.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.358, -5.348, 0.0, 0.0, 0.0]}
{"eval_score": 11.3, "number_of_episodes": 6244}
{"step": 2394, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2395.0, 1.0, 1.0, 1.0, 2395.0, 2395.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.355, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6248, "number_of_timesteps": 107665, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 2395, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2396.0, 1.0, 1.0, 1.0, 2396.0, 2396.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.312, 0.0, 0.0, 0.0, -5.355, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6251, "number_of_timesteps": 107695, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 2396, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2397.0, 1.0, 1.0, 1.0, 2397.0, 2397.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.313, 0.0, 0.0, 0.0, -5.353, -5.346, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6257, "number_of_timesteps": 107764, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2397, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2398.0, 1.0, 1.0, 1.0, 2398.0, 2398.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.354, -5.347, 0.0, 0.0, 0.0]}
{"step": 2398, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2399.0, 1.0, 1.0, 1.0, 2399.0, 2399.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.315, 0.0, 0.0, 0.0, -5.352, -5.347, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6265, "number_of_timesteps": 107842, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2399, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2400.0, 1.0, 1.0, 1.0, 2400.0, 2400.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.319, 0.0, 0.0, 0.0, -5.356, -5.351, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6269, "number_of_timesteps": 107883, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2400, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2401.0, 1.0, 1.0, 1.0, 2401.0, 2401.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.317, 0.0, 0.0, 0.0, -5.354, -5.349, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6272, "number_of_timesteps": 107914, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 2401, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2402.0, 1.0, 1.0, 1.0, 2402.0, 2402.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.318, 0.0, 0.0, 0.0, -5.351, -5.35, 0.0, 0.0, 0.0]}
{"step": 2402, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2403.0, 1.0, 1.0, 1.0, 2403.0, 2403.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.317, 0.0, 0.0, 0.0, -5.349, -5.348, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6280, "number_of_timesteps": 108001, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2403, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2404.0, 1.0, 1.0, 1.0, 2404.0, 2404.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.315, 0.0, 0.0, 0.0, -5.347, -5.345, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6284, "number_of_timesteps": 108053, "per_episode_reward": 13.7, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2404, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2405.0, 1.0, 1.0, 1.0, 2405.0, 2405.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.313, 0.0, 0.0, 0.0, -5.351, -5.349, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6289, "number_of_timesteps": 108106, "per_episode_reward": 13.65, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.1999999999999993},
{"step": 2405, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2406.0, 1.0, 1.0, 1.0, 2406.0, 2406.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.352, -5.35, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6293, "number_of_timesteps": 108146, "per_episode_reward": 13.65, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 2406, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2407.0, 1.0, 1.0, 1.0, 2407.0, 2407.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.315, 0.0, 0.0, 0.0, -5.352, -5.351, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6297, "number_of_timesteps": 108189, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2407, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2408.0, 1.0, 1.0, 1.0, 2408.0, 2408.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.313, 0.0, 0.0, 0.0, -5.357, -5.356, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6302, "number_of_timesteps": 108241, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2408, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2409.0, 1.0, 1.0, 1.0, 2409.0, 2409.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.319, 0.0, 0.0, 0.0, -5.362, -5.361, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6305, "number_of_timesteps": 108273, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 2409, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2410.0, 1.0, 1.0, 1.0, 2410.0, 2410.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.32, 0.0, 0.0, 0.0, -5.363, -5.361, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6309, "number_of_timesteps": 108316, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2410, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2411.0, 1.0, 1.0, 1.0, 2411.0, 2411.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.319, 0.0, 0.0, 0.0, -5.362, -5.359, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6314, "number_of_timesteps": 108370, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 2411, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2412.0, 1.0, 1.0, 1.0, 2412.0, 2412.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.32, 0.0, 0.0, 0.0, -5.362, -5.359, 0.0, 0.0, 0.0]}
{"step": 2412, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2413.0, 1.0, 1.0, 1.0, 2413.0, 2413.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.321, 0.0, 0.0, 0.0, -5.362, -5.36, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6322, "number_of_timesteps": 108450, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2413, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2414.0, 1.0, 1.0, 1.0, 2414.0, 2414.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.319, 0.0, 0.0, 0.0, -5.36, -5.358, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6326, "number_of_timesteps": 108492, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.20000000000000107},
{"step": 2414, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2415.0, 1.0, 1.0, 1.0, 2415.0, 2415.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.32, 0.0, 0.0, 0.0, -5.361, -5.358, 0.0, 0.0, 0.0]}
{"step": 2415, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2416.0, 1.0, 1.0, 1.0, 2416.0, 2416.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.32, 0.0, 0.0, 0.0, -5.361, -5.358, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6334, "number_of_timesteps": 108577, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2416, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2417.0, 1.0, 1.0, 1.0, 2417.0, 2417.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.321, 0.0, 0.0, 0.0, -5.361, -5.356, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6338, "number_of_timesteps": 108622, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 2417, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2418.0, 1.0, 1.0, 1.0, 2418.0, 2418.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.322, 0.0, 0.0, 0.0, -5.361, -5.356, 0.0, 0.0, 0.0]}
{"step": 2418, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2419.0, 1.0, 1.0, 1.0, 2419.0, 2419.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.323, 0.0, 0.0, 0.0, -5.362, -5.354, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6347, "number_of_timesteps": 108717, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2419, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2420.0, 1.0, 1.0, 1.0, 2420.0, 2420.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.321, 0.0, 0.0, 0.0, -5.36, -5.352, 0.0, 0.0, 0.0]}
{"step": 2420, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2421.0, 1.0, 1.0, 1.0, 2421.0, 2421.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.319, 0.0, 0.0, 0.0, -5.357, -5.35, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6353, "number_of_timesteps": 108786, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2421, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2422.0, 1.0, 1.0, 1.0, 2422.0, 2422.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.32, 0.0, 0.0, 0.0, -5.358, -5.35, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6358, "number_of_timesteps": 108843, "per_episode_reward": 13.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2422, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2423.0, 1.0, 1.0, 1.0, 2423.0, 2423.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.325, 0.0, 0.0, 0.0, -5.363, -5.355, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6362, "number_of_timesteps": 108883, "per_episode_reward": 13.55, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.20000000000000107},
{"step": 2423, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2424.0, 1.0, 1.0, 1.0, 2424.0, 2424.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.323, 0.0, 0.0, 0.0, -5.366, -5.359, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6365, "number_of_timesteps": 108912, "per_episode_reward": 13.55, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"step": 2424, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2425.0, 1.0, 1.0, 1.0, 2425.0, 2425.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.322, 0.0, 0.0, 0.0, -5.364, -5.357, 0.0, 0.0, 0.0]}
{"eval_score": 11.8, "number_of_episodes": 6371}
{"number_of_episodes": 6371, "number_of_timesteps": 108976, "per_episode_reward": 13.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2425, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2426.0, 1.0, 1.0, 1.0, 2426.0, 2426.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.32, 0.0, 0.0, 0.0, -5.362, -5.355, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6374, "number_of_timesteps": 109006, "per_episode_reward": 13.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 2426, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2427.0, 1.0, 1.0, 1.0, 2427.0, 2427.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.321, 0.0, 0.0, 0.0, -5.36, -5.355, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6378, "number_of_timesteps": 109047, "per_episode_reward": 13.5, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2427, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2428.0, 1.0, 1.0, 1.0, 2428.0, 2428.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.322, 0.0, 0.0, 0.0, -5.36, -5.356, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6384, "number_of_timesteps": 109112, "per_episode_reward": 13.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"step": 2428, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2429.0, 1.0, 1.0, 1.0, 2429.0, 2429.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.323, 0.0, 0.0, 0.0, -5.361, -5.356, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6385, "number_of_timesteps": 109120, "per_episode_reward": 13.45, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.20000000000000107},
{"step": 2429, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2430.0, 1.0, 1.0, 1.0, 2430.0, 2430.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.321, 0.0, 0.0, 0.0, -5.366, -5.361, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6393, "number_of_timesteps": 109204, "per_episode_reward": 13.45, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.20000000000000107},
{"step": 2430, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2431.0, 1.0, 1.0, 1.0, 2431.0, 2431.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.319, 0.0, 0.0, 0.0, -5.364, -5.359, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6394, "number_of_timesteps": 109216, "per_episode_reward": 13.45, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2431, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2432.0, 1.0, 1.0, 1.0, 2432.0, 2432.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.317, 0.0, 0.0, 0.0, -5.362, -5.357, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6400, "number_of_timesteps": 109276, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2432, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2433.0, 1.0, 1.0, 1.0, 2433.0, 2433.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.316, 0.0, 0.0, 0.0, -5.36, -5.355, 0.0, 0.0, 0.0]}
{"step": 2433, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2434.0, 1.0, 1.0, 1.0, 2434.0, 2434.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.314, 0.0, 0.0, 0.0, -5.357, -5.353, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6410, "number_of_timesteps": 109382, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2434, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2435.0, 1.0, 1.0, 1.0, 2435.0, 2435.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.315, 0.0, 0.0, 0.0, -5.358, -5.353, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6411, "number_of_timesteps": 109392, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"step": 2435, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2436.0, 1.0, 1.0, 1.0, 2436.0, 2436.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.324, 0.0, 0.0, 0.0, -5.367, -5.362, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6417, "number_of_timesteps": 109452, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2436, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2437.0, 1.0, 1.0, 1.0, 2437.0, 2437.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.325, 0.0, 0.0, 0.0, -5.367, -5.36, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6421, "number_of_timesteps": 109494, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2437, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2438.0, 1.0, 1.0, 1.0, 2438.0, 2438.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.323, 0.0, 0.0, 0.0, -5.365, -5.358, 0.0, 0.0, 0.0]}
{"step": 2438, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2439.0, 1.0, 1.0, 1.0, 2439.0, 2439.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.322, 0.0, 0.0, 0.0, -5.363, -5.356, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6430, "number_of_timesteps": 109585, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2439, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2440.0, 1.0, 1.0, 1.0, 2440.0, 2440.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.32, 0.0, 0.0, 0.0, -5.367, -5.36, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6433, "number_of_timesteps": 109614, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2440, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2441.0, 1.0, 1.0, 1.0, 2441.0, 2441.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.322, 0.0, 0.0, 0.0, -5.369, -5.358, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6438, "number_of_timesteps": 109668, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2441, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2442.0, 1.0, 1.0, 1.0, 2442.0, 2442.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.32, 0.0, 0.0, 0.0, -5.366, -5.356, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6441, "number_of_timesteps": 109701, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2442, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2443.0, 1.0, 1.0, 1.0, 2443.0, 2443.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.318, 0.0, 0.0, 0.0, -5.364, -5.354, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6446, "number_of_timesteps": 109749, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2443, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2444.0, 1.0, 1.0, 1.0, 2444.0, 2444.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.316, 0.0, 0.0, 0.0, -5.369, -5.358, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6451, "number_of_timesteps": 109799, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.20000000000000107},
{"step": 2444, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2445.0, 1.0, 1.0, 1.0, 2445.0, 2445.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.317, 0.0, 0.0, 0.0, -5.369, -5.358, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6455, "number_of_timesteps": 109839, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 2445, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2446.0, 1.0, 1.0, 1.0, 2446.0, 2446.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.318, 0.0, 0.0, 0.0, -5.367, -5.359, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6460, "number_of_timesteps": 109890, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 2446, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2447.0, 1.0, 1.0, 1.0, 2447.0, 2447.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.324, 0.0, 0.0, 0.0, -5.372, -5.364, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6463, "number_of_timesteps": 109921, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2447, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2448.0, 1.0, 1.0, 1.0, 2448.0, 2448.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.322, 0.0, 0.0, 0.0, -5.37, -5.362, 0.0, 0.0, 0.0]}
{"step": 2448, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2449.0, 1.0, 1.0, 1.0, 2449.0, 2449.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.32, 0.0, 0.0, 0.0, -5.367, -5.36, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6473, "number_of_timesteps": 110021, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2449, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2450.0, 1.0, 1.0, 1.0, 2450.0, 2450.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.318, 0.0, 0.0, 0.0, -5.365, -5.357, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6477, "number_of_timesteps": 110060, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2450, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2451.0, 1.0, 1.0, 1.0, 2451.0, 2451.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.32, 0.0, 0.0, 0.0, -5.366, -5.355, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6481, "number_of_timesteps": 110102, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"step": 2451, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2452.0, 1.0, 1.0, 1.0, 2452.0, 2452.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.321, 0.0, 0.0, 0.0, -5.367, -5.356, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6487, "number_of_timesteps": 110163, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2452, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2453.0, 1.0, 1.0, 1.0, 2453.0, 2453.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.322, 0.0, 0.0, 0.0, -5.368, -5.357, 0.0, 0.0, 0.0]}
{"step": 2453, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2454.0, 1.0, 1.0, 1.0, 2454.0, 2454.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.323, 0.0, 0.0, 0.0, -5.368, -5.358, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6495, "number_of_timesteps": 110239, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2454, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2455.0, 1.0, 1.0, 1.0, 2455.0, 2455.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.321, 0.0, 0.0, 0.0, -5.366, -5.355, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 6500}
{"number_of_episodes": 6500, "number_of_timesteps": 110290, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 2455, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2456.0, 1.0, 1.0, 1.0, 2456.0, 2456.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.327, 0.0, 0.0, 0.0, -5.372, -5.361, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6505, "number_of_timesteps": 110335, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2456, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2457.0, 1.0, 1.0, 1.0, 2457.0, 2457.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.328, 0.0, 0.0, 0.0, -5.372, -5.361, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6510, "number_of_timesteps": 110381, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"step": 2457, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2458.0, 1.0, 1.0, 1.0, 2458.0, 2458.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.329, 0.0, 0.0, 0.0, -5.373, -5.362, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6513, "number_of_timesteps": 110406, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2458, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2459.0, 1.0, 1.0, 1.0, 2459.0, 2459.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.328, 0.0, 0.0, 0.0, -5.371, -5.36, 0.0, 0.0, 0.0]}
{"step": 2459, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2460.0, 1.0, 1.0, 1.0, 2460.0, 2460.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.329, 0.0, 0.0, 0.0, -5.372, -5.361, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6523, "number_of_timesteps": 110505, "per_episode_reward": 13.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2460, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2461.0, 1.0, 1.0, 1.0, 2461.0, 2461.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.33, 0.0, 0.0, 0.0, -5.372, -5.362, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6526, "number_of_timesteps": 110532, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.1999999999999993},
{"step": 2461, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2462.0, 1.0, 1.0, 1.0, 2462.0, 2462.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.332, 0.0, 0.0, 0.0, -5.37, -5.363, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6532, "number_of_timesteps": 110596, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.1999999999999993},
{"step": 2462, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2463.0, 1.0, 1.0, 1.0, 2463.0, 2463.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.337, 0.0, 0.0, 0.0, -5.375, -5.368, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6535, "number_of_timesteps": 110627, "per_episode_reward": 13.35, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2463, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2464.0, 1.0, 1.0, 1.0, 2464.0, 2464.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.338, 0.0, 0.0, 0.0, -5.375, -5.365, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6541, "number_of_timesteps": 110683, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.09999999999999964},
{"step": 2464, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2465.0, 1.0, 1.0, 1.0, 2465.0, 2465.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.338, 0.0, 0.0, 0.0, -5.376, -5.366, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6544, "number_of_timesteps": 110715, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.09999999999999964},
{"step": 2465, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2466.0, 1.0, 1.0, 1.0, 2466.0, 2466.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.337, 0.0, 0.0, 0.0, -5.373, -5.364, 0.0, 0.0, 0.0]}
{"step": 2466, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2467.0, 1.0, 1.0, 1.0, 2467.0, 2467.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.338, 0.0, 0.0, 0.0, -5.374, -5.364, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6551, "number_of_timesteps": 110786, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 2467, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2468.0, 1.0, 1.0, 1.0, 2468.0, 2468.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.343, 0.0, 0.0, 0.0, -5.379, -5.369, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6557, "number_of_timesteps": 110850, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 2468, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2469.0, 1.0, 1.0, 1.0, 2469.0, 2469.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.344, 0.0, 0.0, 0.0, -5.377, -5.369, 0.0, 0.0, 0.0]}
{"step": 2469, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2470.0, 1.0, 1.0, 1.0, 2470.0, 2470.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.343, 0.0, 0.0, 0.0, -5.374, -5.369, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6565, "number_of_timesteps": 110927, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.09999999999999964},
{"step": 2470, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2471.0, 1.0, 1.0, 1.0, 2471.0, 2471.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.345, 0.0, 0.0, 0.0, -5.375, -5.37, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6570, "number_of_timesteps": 110981, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2471, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2472.0, 1.0, 1.0, 1.0, 2472.0, 2472.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.344, 0.0, 0.0, 0.0, -5.375, -5.367, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6572, "number_of_timesteps": 111001, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2472, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2473.0, 1.0, 1.0, 1.0, 2473.0, 2473.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.345, 0.0, 0.0, 0.0, -5.374, -5.367, 0.0, 0.0, 0.0]}
{"step": 2473, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2474.0, 1.0, 1.0, 1.0, 2474.0, 2474.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.346, 0.0, 0.0, 0.0, -5.375, -5.368, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6582, "number_of_timesteps": 111107, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"step": 2474, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2475.0, 1.0, 1.0, 1.0, 2475.0, 2475.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.346, 0.0, 0.0, 0.0, -5.375, -5.368, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6585, "number_of_timesteps": 111136, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2475, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2476.0, 1.0, 1.0, 1.0, 2476.0, 2476.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.347, 0.0, 0.0, 0.0, -5.376, -5.369, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6590, "number_of_timesteps": 111186, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 2476, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2477.0, 1.0, 1.0, 1.0, 2477.0, 2477.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.35, 0.0, 0.0, 0.0, -5.374, -5.37, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6593, "number_of_timesteps": 111221, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2477, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2478.0, 1.0, 1.0, 1.0, 2478.0, 2478.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.348, 0.0, 0.0, 0.0, -5.378, -5.375, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6599, "number_of_timesteps": 111284, "per_episode_reward": 13.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 2478, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2479.0, 1.0, 1.0, 1.0, 2479.0, 2479.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.353, 0.0, 0.0, 0.0, -5.382, -5.379, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6602, "number_of_timesteps": 111314, "per_episode_reward": 13.25, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"step": 2479, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2480.0, 1.0, 1.0, 1.0, 2480.0, 2480.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.354, 0.0, 0.0, 0.0, -5.383, -5.377, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6607, "number_of_timesteps": 111363, "per_episode_reward": 13.25, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.15000000000000036},
{"step": 2480, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2481.0, 1.0, 1.0, 1.0, 2481.0, 2481.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.355, 0.0, 0.0, 0.0, -5.383, -5.378, 0.0, 0.0, 0.0]}
{"step": 2481, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2482.0, 1.0, 1.0, 1.0, 2482.0, 2482.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.354, 0.0, 0.0, 0.0, -5.383, -5.377, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6615, "number_of_timesteps": 111444, "per_episode_reward": 13.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2482, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2483.0, 1.0, 1.0, 1.0, 2483.0, 2483.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.355, 0.0, 0.0, 0.0, -5.38, -5.377, 0.0, 0.0, 0.0]}
{"step": 2483, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2484.0, 1.0, 1.0, 1.0, 2484.0, 2484.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.356, 0.0, 0.0, 0.0, -5.378, -5.378, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6625, "number_of_timesteps": 111546, "per_episode_reward": 13.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2484, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2485.0, 1.0, 1.0, 1.0, 2485.0, 2485.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.354, 0.0, 0.0, 0.0, -5.376, -5.376, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6629, "number_of_timesteps": 111585, "per_episode_reward": 13.15, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.15000000000000036},
{"step": 2485, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2486.0, 1.0, 1.0, 1.0, 2486.0, 2486.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.353, 0.0, 0.0, 0.0, -5.381, -5.38, 0.0, 0.0, 0.0]}
{"eval_score": 10.1, "number_of_episodes": 6633}
{"number_of_episodes": 6633, "number_of_timesteps": 111623, "per_episode_reward": 13.15, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.15000000000000036},
{"step": 2486, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2487.0, 1.0, 1.0, 1.0, 2487.0, 2487.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.351, 0.0, 0.0, 0.0, -5.379, -5.378, 0.0, 0.0, 0.0]}
{"step": 2487, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2488.0, 1.0, 1.0, 1.0, 2488.0, 2488.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.349, 0.0, 0.0, 0.0, -5.383, -5.383, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6642, "number_of_timesteps": 111718, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2488, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2489.0, 1.0, 1.0, 1.0, 2489.0, 2489.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.355, 0.0, 0.0, 0.0, -5.389, -5.388, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6647, "number_of_timesteps": 111770, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3000000000000007},
{"step": 2489, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2490.0, 1.0, 1.0, 1.0, 2490.0, 2490.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.353, 0.0, 0.0, 0.0, -5.386, -5.386, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6651, "number_of_timesteps": 111810, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 2490, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2491.0, 1.0, 1.0, 1.0, 2491.0, 2491.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.354, 0.0, 0.0, 0.0, -5.384, -5.386, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6654, "number_of_timesteps": 111841, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2491, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2492.0, 1.0, 1.0, 1.0, 2492.0, 2492.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.352, 0.0, 0.0, 0.0, -5.382, -5.384, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6659, "number_of_timesteps": 111896, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 2492, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2493.0, 1.0, 1.0, 1.0, 2493.0, 2493.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.353, 0.0, 0.0, 0.0, -5.383, -5.382, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6664, "number_of_timesteps": 111947, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2493, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2494.0, 1.0, 1.0, 1.0, 2494.0, 2494.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.356, 0.0, 0.0, 0.0, -5.385, -5.385, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6667, "number_of_timesteps": 111975, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2494, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2495.0, 1.0, 1.0, 1.0, 2495.0, 2495.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.358, 0.0, 0.0, 0.0, -5.386, -5.386, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6672, "number_of_timesteps": 112024, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2495, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2496.0, 1.0, 1.0, 1.0, 2496.0, 2496.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.356, 0.0, 0.0, 0.0, -5.384, -5.383, 0.0, 0.0, 0.0]}
{"step": 2496, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2497.0, 1.0, 1.0, 1.0, 2497.0, 2497.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.354, 0.0, 0.0, 0.0, -5.382, -5.381, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6680, "number_of_timesteps": 112101, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2497, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2498.0, 1.0, 1.0, 1.0, 2498.0, 2498.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.359, 0.0, 0.0, 0.0, -5.387, -5.386, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6686, "number_of_timesteps": 112162, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2498, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2499.0, 1.0, 1.0, 1.0, 2499.0, 2499.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.361, 0.0, 0.0, 0.0, -5.388, -5.384, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6690, "number_of_timesteps": 112198, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 2499, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2500.0, 1.0, 1.0, 1.0, 2500.0, 2500.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.359, 0.0, 0.0, 0.0, -5.385, -5.382, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6693, "number_of_timesteps": 112228, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 2500, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2501.0, 1.0, 1.0, 1.0, 2501.0, 2501.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.357, 0.0, 0.0, 0.0, -5.39, -5.386, 0.0, 0.0, 0.0]}
{"step": 2501, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2502.0, 1.0, 1.0, 1.0, 2502.0, 2502.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.355, 0.0, 0.0, 0.0, -5.388, -5.384, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6702, "number_of_timesteps": 112319, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 2502, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2503.0, 1.0, 1.0, 1.0, 2503.0, 2503.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.356, 0.0, 0.0, 0.0, -5.386, -5.385, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6708, "number_of_timesteps": 112379, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2503, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2504.0, 1.0, 1.0, 1.0, 2504.0, 2504.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.357, 0.0, 0.0, 0.0, -5.386, -5.385, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6711, "number_of_timesteps": 112409, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 2504, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2505.0, 1.0, 1.0, 1.0, 2505.0, 2505.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.359, 0.0, 0.0, 0.0, -5.387, -5.386, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6718, "number_of_timesteps": 112475, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 2505, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2506.0, 1.0, 1.0, 1.0, 2506.0, 2506.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.357, 0.0, 0.0, 0.0, -5.392, -5.391, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6720, "number_of_timesteps": 112494, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 2506, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2507.0, 1.0, 1.0, 1.0, 2507.0, 2507.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.356, 0.0, 0.0, 0.0, -5.39, -5.389, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6727, "number_of_timesteps": 112562, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 2507, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2508.0, 1.0, 1.0, 1.0, 2508.0, 2508.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.362, 0.0, 0.0, 0.0, -5.395, -5.394, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6730, "number_of_timesteps": 112590, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2508, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2509.0, 1.0, 1.0, 1.0, 2509.0, 2509.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.362, 0.0, 0.0, 0.0, -5.393, -5.394, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6735, "number_of_timesteps": 112637, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2509, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2510.0, 1.0, 1.0, 1.0, 2510.0, 2510.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.363, 0.0, 0.0, 0.0, -5.394, -5.395, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6738, "number_of_timesteps": 112668, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2510, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2511.0, 1.0, 1.0, 1.0, 2511.0, 2511.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.364, 0.0, 0.0, 0.0, -5.395, -5.393, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6744, "number_of_timesteps": 112732, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 2511, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2512.0, 1.0, 1.0, 1.0, 2512.0, 2512.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.363, 0.0, 0.0, 0.0, -5.399, -5.397, 0.0, 0.0, 0.0]}
{"step": 2512, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2513.0, 1.0, 1.0, 1.0, 2513.0, 2513.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.361, 0.0, 0.0, 0.0, -5.404, -5.402, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6752, "number_of_timesteps": 112815, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 2513, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2514.0, 1.0, 1.0, 1.0, 2514.0, 2514.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.366, 0.0, 0.0, 0.0, -5.409, -5.407, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6755, "number_of_timesteps": 112848, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2514, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2515.0, 1.0, 1.0, 1.0, 2515.0, 2515.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.368, 0.0, 0.0, 0.0, -5.407, -5.409, 0.0, 0.0, 0.0]}
{"eval_score": 10.0, "number_of_episodes": 6761}
{"number_of_episodes": 6761, "number_of_timesteps": 112909, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2515, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2516.0, 1.0, 1.0, 1.0, 2516.0, 2516.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.366, 0.0, 0.0, 0.0, -5.405, -5.407, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6765, "number_of_timesteps": 112947, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
{"step": 2516, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2517.0, 1.0, 1.0, 1.0, 2517.0, 2517.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.365, 0.0, 0.0, 0.0, -5.41, -5.412, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6770, "number_of_timesteps": 112993, "per_episode_reward": 13.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3000000000000007},
{"step": 2517, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2518.0, 1.0, 1.0, 1.0, 2518.0, 2518.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.363, 0.0, 0.0, 0.0, -5.408, -5.409, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6775, "number_of_timesteps": 113041, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.20000000000000107},
{"step": 2518, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2519.0, 1.0, 1.0, 1.0, 2519.0, 2519.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.364, 0.0, 0.0, 0.0, -5.408, -5.41, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6778, "number_of_timesteps": 113071, "per_episode_reward": 13.05, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 2519, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2520.0, 1.0, 1.0, 1.0, 2520.0, 2520.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.362, 0.0, 0.0, 0.0, -5.406, -5.408, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6785, "number_of_timesteps": 113141, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2520, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2521.0, 1.0, 1.0, 1.0, 2521.0, 2521.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.363, 0.0, 0.0, 0.0, -5.404, -5.409, 0.0, 0.0, 0.0]}
{"step": 2521, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2522.0, 1.0, 1.0, 1.0, 2522.0, 2522.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.363, 0.0, 0.0, 0.0, -5.402, -5.408, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6795, "number_of_timesteps": 113232, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 2522, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2523.0, 1.0, 1.0, 1.0, 2523.0, 2523.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.361, 0.0, 0.0, 0.0, -5.407, -5.413, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6798, "number_of_timesteps": 113261, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3000000000000007},
{"step": 2523, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2524.0, 1.0, 1.0, 1.0, 2524.0, 2524.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.359, 0.0, 0.0, 0.0, -5.405, -5.41, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6804, "number_of_timesteps": 113316, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.25},
{"step": 2524, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2525.0, 1.0, 1.0, 1.0, 2525.0, 2525.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.36, 0.0, 0.0, 0.0, -5.405, -5.411, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6807, "number_of_timesteps": 113343, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2525, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2526.0, 1.0, 1.0, 1.0, 2526.0, 2526.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.358, 0.0, 0.0, 0.0, -5.409, -5.414, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6813, "number_of_timesteps": 113403, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.25},
{"step": 2526, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2527.0, 1.0, 1.0, 1.0, 2527.0, 2527.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.357, 0.0, 0.0, 0.0, -5.407, -5.412, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6816, "number_of_timesteps": 113432, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3000000000000007},
{"step": 2527, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2528.0, 1.0, 1.0, 1.0, 2528.0, 2528.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.355, 0.0, 0.0, 0.0, -5.404, -5.41, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6822, "number_of_timesteps": 113491, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2528, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2529.0, 1.0, 1.0, 1.0, 2529.0, 2529.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.356, 0.0, 0.0, 0.0, -5.405, -5.411, 0.0, 0.0, 0.0]}
{"step": 2529, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2530.0, 1.0, 1.0, 1.0, 2530.0, 2530.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.355, 0.0, 0.0, 0.0, -5.404, -5.41, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6831, "number_of_timesteps": 113576, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2530, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2531.0, 1.0, 1.0, 1.0, 2531.0, 2531.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.356, 0.0, 0.0, 0.0, -5.405, -5.41, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6834, "number_of_timesteps": 113605, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2531, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2532.0, 1.0, 1.0, 1.0, 2532.0, 2532.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.355, 0.0, 0.0, 0.0, -5.409, -5.414, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6840, "number_of_timesteps": 113664, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3000000000000007},
{"step": 2532, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2533.0, 1.0, 1.0, 1.0, 2533.0, 2533.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.353, 0.0, 0.0, 0.0, -5.407, -5.412, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6843, "number_of_timesteps": 113694, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2533, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2534.0, 1.0, 1.0, 1.0, 2534.0, 2534.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.354, 0.0, 0.0, 0.0, -5.407, -5.413, 0.0, 0.0, 0.0]}
{"step": 2534, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2535.0, 1.0, 1.0, 1.0, 2535.0, 2535.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.352, 0.0, 0.0, 0.0, -5.405, -5.411, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6852, "number_of_timesteps": 113780, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2535, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2536.0, 1.0, 1.0, 1.0, 2536.0, 2536.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.351, 0.0, 0.0, 0.0, -5.403, -5.409, 0.0, 0.0, 0.0]}
{"step": 2536, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2537.0, 1.0, 1.0, 1.0, 2537.0, 2537.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.349, 0.0, 0.0, 0.0, -5.401, -5.406, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6862, "number_of_timesteps": 113883, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.25},
{"step": 2537, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2538.0, 1.0, 1.0, 1.0, 2538.0, 2538.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.347, 0.0, 0.0, 0.0, -5.399, -5.404, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6864, "number_of_timesteps": 113901, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2538, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2539.0, 1.0, 1.0, 1.0, 2539.0, 2539.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.345, 0.0, 0.0, 0.0, -5.397, -5.402, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6871, "number_of_timesteps": 113973, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
{"step": 2539, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2540.0, 1.0, 1.0, 1.0, 2540.0, 2540.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.346, 0.0, 0.0, 0.0, -5.395, -5.403, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6874, "number_of_timesteps": 114004, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.25},
{"step": 2540, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2541.0, 1.0, 1.0, 1.0, 2541.0, 2541.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.347, 0.0, 0.0, 0.0, -5.395, -5.403, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6879, "number_of_timesteps": 114053, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2541, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2542.0, 1.0, 1.0, 1.0, 2542.0, 2542.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.348, 0.0, 0.0, 0.0, -5.395, -5.401, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6883, "number_of_timesteps": 114094, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2542, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2543.0, 1.0, 1.0, 1.0, 2543.0, 2543.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.346, 0.0, 0.0, 0.0, -5.393, -5.399, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6888, "number_of_timesteps": 114143, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2543, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2544.0, 1.0, 1.0, 1.0, 2544.0, 2544.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.347, 0.0, 0.0, 0.0, -5.394, -5.4, 0.0, 0.0, 0.0]}
{"eval_score": 9.9, "number_of_episodes": 6893}
{"number_of_episodes": 6893, "number_of_timesteps": 114194, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.25},
{"step": 2544, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2545.0, 1.0, 1.0, 1.0, 2545.0, 2545.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.345, 0.0, 0.0, 0.0, -5.391, -5.398, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6898, "number_of_timesteps": 114239, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.3000000000000007},
{"step": 2545, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2546.0, 1.0, 1.0, 1.0, 2546.0, 2546.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.344, 0.0, 0.0, 0.0, -5.389, -5.396, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6902, "number_of_timesteps": 114278, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2546, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2547.0, 1.0, 1.0, 1.0, 2547.0, 2547.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.345, 0.0, 0.0, 0.0, -5.39, -5.393, 0.0, 0.0, 0.0]}
{"step": 2547, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2548.0, 1.0, 1.0, 1.0, 2548.0, 2548.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.344, 0.0, 0.0, 0.0, -5.388, -5.391, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6911, "number_of_timesteps": 114368, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 2548, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2549.0, 1.0, 1.0, 1.0, 2549.0, 2549.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.342, 0.0, 0.0, 0.0, -5.389, -5.392, 0.0, 0.0, 0.0]}
{"step": 2549, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2550.0, 1.0, 1.0, 1.0, 2550.0, 2550.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.34, 0.0, 0.0, 0.0, -5.394, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6920, "number_of_timesteps": 114456, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2550, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2551.0, 1.0, 1.0, 1.0, 2551.0, 2551.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.341, 0.0, 0.0, 0.0, -5.395, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6925, "number_of_timesteps": 114505, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 2551, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2552.0, 1.0, 1.0, 1.0, 2552.0, 2552.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.347, 0.0, 0.0, 0.0, -5.4, -5.403, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6930, "number_of_timesteps": 114554, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2552, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2553.0, 1.0, 1.0, 1.0, 2553.0, 2553.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.348, 0.0, 0.0, 0.0, -5.4, -5.403, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6935, "number_of_timesteps": 114603, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2553, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2554.0, 1.0, 1.0, 1.0, 2554.0, 2554.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.349, 0.0, 0.0, 0.0, -5.401, -5.401, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6938, "number_of_timesteps": 114630, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 2554, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2555.0, 1.0, 1.0, 1.0, 2555.0, 2555.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.35, 0.0, 0.0, 0.0, -5.402, -5.402, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6944, "number_of_timesteps": 114689, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 2555, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2556.0, 1.0, 1.0, 1.0, 2556.0, 2556.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.356, 0.0, 0.0, 0.0, -5.407, -5.407, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6947, "number_of_timesteps": 114719, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 2556, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2557.0, 1.0, 1.0, 1.0, 2557.0, 2557.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.354, 0.0, 0.0, 0.0, -5.41, -5.41, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6953, "number_of_timesteps": 114780, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2557, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2558.0, 1.0, 1.0, 1.0, 2558.0, 2558.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.355, 0.0, 0.0, 0.0, -5.41, -5.41, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6956, "number_of_timesteps": 114810, "per_episode_reward": 13.0, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 2558, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2559.0, 1.0, 1.0, 1.0, 2559.0, 2559.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.355, 0.0, 0.0, 0.0, -5.41, -5.408, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6961, "number_of_timesteps": 114860, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2559, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2560.0, 1.0, 1.0, 1.0, 2560.0, 2560.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.354, 0.0, 0.0, 0.0, -5.408, -5.406, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6964, "number_of_timesteps": 114890, "per_episode_reward": 12.95, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.20000000000000107},
{"step": 2560, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2561.0, 1.0, 1.0, 1.0, 2561.0, 2561.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.357, 0.0, 0.0, 0.0, -5.411, -5.409, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6971, "number_of_timesteps": 114960, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2561, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2562.0, 1.0, 1.0, 1.0, 2562.0, 2562.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.358, 0.0, 0.0, 0.0, -5.409, -5.41, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6974, "number_of_timesteps": 114988, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.3000000000000007},
{"step": 2562, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2563.0, 1.0, 1.0, 1.0, 2563.0, 2563.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.356, 0.0, 0.0, 0.0, -5.407, -5.408, 0.0, 0.0, 0.0]}
{"step": 2563, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2564.0, 1.0, 1.0, 1.0, 2564.0, 2564.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.357, 0.0, 0.0, 0.0, -5.405, -5.408, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6982, "number_of_timesteps": 115066, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2564, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2565.0, 1.0, 1.0, 1.0, 2565.0, 2565.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.356, 0.0, 0.0, 0.0, -5.408, -5.411, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6988, "number_of_timesteps": 115129, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2565, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2566.0, 1.0, 1.0, 1.0, 2566.0, 2566.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.361, 0.0, 0.0, 0.0, -5.413, -5.416, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6992, "number_of_timesteps": 115168, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2566, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2567.0, 1.0, 1.0, 1.0, 2567.0, 2567.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.362, 0.0, 0.0, 0.0, -5.41, -5.417, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6997, "number_of_timesteps": 115216, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2567, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2568.0, 1.0, 1.0, 1.0, 2568.0, 2568.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.363, 0.0, 0.0, 0.0, -5.411, -5.417, 0.0, 0.0, 0.0]}
{"number_of_episodes": 6999, "number_of_timesteps": 115236, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2568, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2569.0, 1.0, 1.0, 1.0, 2569.0, 2569.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.364, 0.0, 0.0, 0.0, -5.412, -5.418, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7007, "number_of_timesteps": 115318, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 2569, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2570.0, 1.0, 1.0, 1.0, 2570.0, 2570.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.362, 0.0, 0.0, 0.0, -5.41, -5.416, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7009, "number_of_timesteps": 115336, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2570, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2571.0, 1.0, 1.0, 1.0, 2571.0, 2571.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.368, 0.0, 0.0, 0.0, -5.415, -5.421, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7016, "number_of_timesteps": 115401, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2571, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2572.0, 1.0, 1.0, 1.0, 2572.0, 2572.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.369, 0.0, 0.0, 0.0, -5.415, -5.419, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7018, "number_of_timesteps": 115422, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2572, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2573.0, 1.0, 1.0, 1.0, 2573.0, 2573.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.37, 0.0, 0.0, 0.0, -5.416, -5.419, 0.0, 0.0, 0.0]}
{"eval_score": 10.1, "number_of_episodes": 7025}
{"step": 2573, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2574.0, 1.0, 1.0, 1.0, 2574.0, 2574.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.371, 0.0, 0.0, 0.0, -5.416, -5.417, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7027, "number_of_timesteps": 115513, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.25},
{"step": 2574, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2575.0, 1.0, 1.0, 1.0, 2575.0, 2575.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.372, 0.0, 0.0, 0.0, -5.417, -5.418, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7033, "number_of_timesteps": 115569, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2575, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2576.0, 1.0, 1.0, 1.0, 2576.0, 2576.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.373, 0.0, 0.0, 0.0, -5.415, -5.419, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7037, "number_of_timesteps": 115610, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2576, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2577.0, 1.0, 1.0, 1.0, 2577.0, 2577.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.378, 0.0, 0.0, 0.0, -5.42, -5.423, 0.0, 0.0, 0.0]}
{"step": 2577, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2578.0, 1.0, 1.0, 1.0, 2578.0, 2578.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.379, 0.0, 0.0, 0.0, -5.418, -5.424, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7046, "number_of_timesteps": 115700, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 2578, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2579.0, 1.0, 1.0, 1.0, 2579.0, 2579.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.418, -5.424, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7050, "number_of_timesteps": 115739, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2579, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2580.0, 1.0, 1.0, 1.0, 2580.0, 2580.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.378, 0.0, 0.0, 0.0, -5.416, -5.422, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7055, "number_of_timesteps": 115790, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2580, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2581.0, 1.0, 1.0, 1.0, 2581.0, 2581.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.377, 0.0, 0.0, 0.0, -5.421, -5.427, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7060, "number_of_timesteps": 115839, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2581, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2582.0, 1.0, 1.0, 1.0, 2582.0, 2582.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.377, 0.0, 0.0, 0.0, -5.421, -5.427, 0.0, 0.0, 0.0]}
{"step": 2582, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2583.0, 1.0, 1.0, 1.0, 2583.0, 2583.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.378, 0.0, 0.0, 0.0, -5.421, -5.428, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7068, "number_of_timesteps": 115915, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.25},
{"step": 2583, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2584.0, 1.0, 1.0, 1.0, 2584.0, 2584.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.379, 0.0, 0.0, 0.0, -5.422, -5.428, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7075, "number_of_timesteps": 115983, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2584, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2585.0, 1.0, 1.0, 1.0, 2585.0, 2585.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.419, -5.428, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7077, "number_of_timesteps": 116002, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2585, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2586.0, 1.0, 1.0, 1.0, 2586.0, 2586.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.381, 0.0, 0.0, 0.0, -5.42, -5.429, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7082, "number_of_timesteps": 116051, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2586, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2587.0, 1.0, 1.0, 1.0, 2587.0, 2587.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.379, 0.0, 0.0, 0.0, -5.418, -5.427, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7087, "number_of_timesteps": 116105, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2587, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2588.0, 1.0, 1.0, 1.0, 2588.0, 2588.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.418, -5.427, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7091, "number_of_timesteps": 116142, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 2588, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2589.0, 1.0, 1.0, 1.0, 2589.0, 2589.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.378, 0.0, 0.0, 0.0, -5.416, -5.425, 0.0, 0.0, 0.0]}
{"step": 2589, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2590.0, 1.0, 1.0, 1.0, 2590.0, 2590.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.376, 0.0, 0.0, 0.0, -5.414, -5.423, 0.0, 0.0, 0.0]}
{"step": 2590, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2591.0, 1.0, 1.0, 1.0, 2591.0, 2591.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.375, 0.0, 0.0, 0.0, -5.412, -5.421, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7102, "number_of_timesteps": 116261, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2591, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2592.0, 1.0, 1.0, 1.0, 2592.0, 2592.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.373, 0.0, 0.0, 0.0, -5.41, -5.419, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7110, "number_of_timesteps": 116337, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2592, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2593.0, 1.0, 1.0, 1.0, 2593.0, 2593.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.374, 0.0, 0.0, 0.0, -5.41, -5.419, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7112, "number_of_timesteps": 116355, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3000000000000007},
{"step": 2593, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2594.0, 1.0, 1.0, 1.0, 2594.0, 2594.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.372, 0.0, 0.0, 0.0, -5.408, -5.417, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7118, "number_of_timesteps": 116410, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 2594, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2595.0, 1.0, 1.0, 1.0, 2595.0, 2595.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.373, 0.0, 0.0, 0.0, -5.408, -5.415, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7122, "number_of_timesteps": 116453, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2595, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2596.0, 1.0, 1.0, 1.0, 2596.0, 2596.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.374, 0.0, 0.0, 0.0, -5.406, -5.416, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7128, "number_of_timesteps": 116507, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2596, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2597.0, 1.0, 1.0, 1.0, 2597.0, 2597.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.383, 0.0, 0.0, 0.0, -5.415, -5.424, 0.0, 0.0, 0.0]}
{"step": 2597, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2598.0, 1.0, 1.0, 1.0, 2598.0, 2598.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.389, 0.0, 0.0, 0.0, -5.421, -5.43, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7137, "number_of_timesteps": 116590, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2598, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2599.0, 1.0, 1.0, 1.0, 2599.0, 2599.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.39, 0.0, 0.0, 0.0, -5.421, -5.431, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7140, "number_of_timesteps": 116617, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3000000000000007},
{"step": 2599, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2600.0, 1.0, 1.0, 1.0, 2600.0, 2600.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.388, 0.0, 0.0, 0.0, -5.419, -5.429, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7147, "number_of_timesteps": 116690, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2600, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2601.0, 1.0, 1.0, 1.0, 2601.0, 2601.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.387, 0.0, 0.0, 0.0, -5.424, -5.433, 0.0, 0.0, 0.0]}
{"eval_score": 10.5, "number_of_episodes": 7150}
{"number_of_episodes": 7150, "number_of_timesteps": 116720, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 2601, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2602.0, 1.0, 1.0, 1.0, 2602.0, 2602.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.385, 0.0, 0.0, 0.0, -5.421, -5.431, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7155, "number_of_timesteps": 116765, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2602, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2603.0, 1.0, 1.0, 1.0, 2603.0, 2603.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.383, 0.0, 0.0, 0.0, -5.419, -5.429, 0.0, 0.0, 0.0]}
{"step": 2603, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2604.0, 1.0, 1.0, 1.0, 2604.0, 2604.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.382, 0.0, 0.0, 0.0, -5.417, -5.427, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7163, "number_of_timesteps": 116858, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2604, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2605.0, 1.0, 1.0, 1.0, 2605.0, 2605.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.415, -5.425, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7168, "number_of_timesteps": 116910, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2605, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2606.0, 1.0, 1.0, 1.0, 2606.0, 2606.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.378, 0.0, 0.0, 0.0, -5.413, -5.423, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7172, "number_of_timesteps": 116948, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2606, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2607.0, 1.0, 1.0, 1.0, 2607.0, 2607.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.377, 0.0, 0.0, 0.0, -5.411, -5.421, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7178, "number_of_timesteps": 117004, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2607, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2608.0, 1.0, 1.0, 1.0, 2608.0, 2608.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.378, 0.0, 0.0, 0.0, -5.412, -5.419, 0.0, 0.0, 0.0]}
{"step": 2608, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2609.0, 1.0, 1.0, 1.0, 2609.0, 2609.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.379, 0.0, 0.0, 0.0, -5.413, -5.417, 0.0, 0.0, 0.0]}
{"step": 2609, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2610.0, 1.0, 1.0, 1.0, 2610.0, 2610.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.378, 0.0, 0.0, 0.0, -5.411, -5.414, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7191, "number_of_timesteps": 117123, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2610, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2611.0, 1.0, 1.0, 1.0, 2611.0, 2611.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.376, 0.0, 0.0, 0.0, -5.409, -5.412, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7196, "number_of_timesteps": 117172, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2611, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2612.0, 1.0, 1.0, 1.0, 2612.0, 2612.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.377, 0.0, 0.0, 0.0, -5.409, -5.413, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7201, "number_of_timesteps": 117224, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2612, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2613.0, 1.0, 1.0, 1.0, 2613.0, 2613.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.375, 0.0, 0.0, 0.0, -5.407, -5.411, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7206, "number_of_timesteps": 117273, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2613, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2614.0, 1.0, 1.0, 1.0, 2614.0, 2614.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.375, 0.0, 0.0, 0.0, -5.407, -5.409, 0.0, 0.0, 0.0]}
{"step": 2614, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2615.0, 1.0, 1.0, 1.0, 2615.0, 2615.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.376, 0.0, 0.0, 0.0, -5.407, -5.407, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7215, "number_of_timesteps": 117362, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 2615, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2616.0, 1.0, 1.0, 1.0, 2616.0, 2616.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.377, 0.0, 0.0, 0.0, -5.408, -5.407, 0.0, 0.0, 0.0]}
{"step": 2616, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2617.0, 1.0, 1.0, 1.0, 2617.0, 2617.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.377, 0.0, 0.0, 0.0, -5.407, -5.407, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7223, "number_of_timesteps": 117439, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2617, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2618.0, 1.0, 1.0, 1.0, 2618.0, 2618.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.375, 0.0, 0.0, 0.0, -5.405, -5.405, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7228, "number_of_timesteps": 117490, "per_episode_reward": 12.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2618, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2619.0, 1.0, 1.0, 1.0, 2619.0, 2619.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.373, 0.0, 0.0, 0.0, -5.409, -5.409, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7233, "number_of_timesteps": 117538, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 2619, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2620.0, 1.0, 1.0, 1.0, 2620.0, 2620.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.372, 0.0, 0.0, 0.0, -5.407, -5.407, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7237, "number_of_timesteps": 117573, "per_episode_reward": 12.85, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 2620, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2621.0, 1.0, 1.0, 1.0, 2621.0, 2621.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.372, 0.0, 0.0, 0.0, -5.408, -5.405, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7242, "number_of_timesteps": 117623, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2621, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2622.0, 1.0, 1.0, 1.0, 2622.0, 2622.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.373, 0.0, 0.0, 0.0, -5.406, -5.406, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7247, "number_of_timesteps": 117673, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2622, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2623.0, 1.0, 1.0, 1.0, 2623.0, 2623.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.374, 0.0, 0.0, 0.0, -5.406, -5.403, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7249, "number_of_timesteps": 117693, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2623, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2624.0, 1.0, 1.0, 1.0, 2624.0, 2624.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.373, 0.0, 0.0, 0.0, -5.404, -5.401, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7257, "number_of_timesteps": 117773, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"step": 2624, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2625.0, 1.0, 1.0, 1.0, 2625.0, 2625.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.371, 0.0, 0.0, 0.0, -5.402, -5.399, 0.0, 0.0, 0.0]}
{"step": 2625, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2626.0, 1.0, 1.0, 1.0, 2626.0, 2626.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.369, 0.0, 0.0, 0.0, -5.4, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7265, "number_of_timesteps": 117850, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2626, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2627.0, 1.0, 1.0, 1.0, 2627.0, 2627.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.371, 0.0, 0.0, 0.0, -5.401, -5.395, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7268, "number_of_timesteps": 117884, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2627, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2628.0, 1.0, 1.0, 1.0, 2628.0, 2628.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.369, 0.0, 0.0, 0.0, -5.399, -5.393, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7273, "number_of_timesteps": 117931, "per_episode_reward": 12.8, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 2628, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2629.0, 1.0, 1.0, 1.0, 2629.0, 2629.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.37, 0.0, 0.0, 0.0, -5.4, -5.394, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7278, "number_of_timesteps": 117982, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 2629, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2630.0, 1.0, 1.0, 1.0, 2630.0, 2630.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.368, 0.0, 0.0, 0.0, -5.397, -5.392, 0.0, 0.0, 0.0]}
{"eval_score": 10.7, "number_of_episodes": 7283}
{"number_of_episodes": 7283, "number_of_timesteps": 118026, "per_episode_reward": 12.75, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"step": 2630, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2631.0, 1.0, 1.0, 1.0, 2631.0, 2631.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.369, 0.0, 0.0, 0.0, -5.395, -5.393, 0.0, 0.0, 0.0]}
{"step": 2631, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2632.0, 1.0, 1.0, 1.0, 2632.0, 2632.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.369, 0.0, 0.0, 0.0, -5.393, -5.392, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7292, "number_of_timesteps": 118108, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 2632, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2633.0, 1.0, 1.0, 1.0, 2633.0, 2633.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.37, 0.0, 0.0, 0.0, -5.394, -5.392, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7296, "number_of_timesteps": 118147, "per_episode_reward": 12.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2633, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2634.0, 1.0, 1.0, 1.0, 2634.0, 2634.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.375, 0.0, 0.0, 0.0, -5.399, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7302, "number_of_timesteps": 118207, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 2634, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2635.0, 1.0, 1.0, 1.0, 2635.0, 2635.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.375, 0.0, 0.0, 0.0, -5.399, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7306, "number_of_timesteps": 118243, "per_episode_reward": 12.65, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 2635, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2636.0, 1.0, 1.0, 1.0, 2636.0, 2636.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.374, 0.0, 0.0, 0.0, -5.397, -5.395, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7312, "number_of_timesteps": 118300, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 2636, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2637.0, 1.0, 1.0, 1.0, 2637.0, 2637.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.375, 0.0, 0.0, 0.0, -5.397, -5.393, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7316, "number_of_timesteps": 118337, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 2637, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2638.0, 1.0, 1.0, 1.0, 2638.0, 2638.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.374, 0.0, 0.0, 0.0, -5.396, -5.392, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7321, "number_of_timesteps": 118381, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2638, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2639.0, 1.0, 1.0, 1.0, 2639.0, 2639.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.375, 0.0, 0.0, 0.0, -5.394, -5.392, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7325, "number_of_timesteps": 118423, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2639, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2640.0, 1.0, 1.0, 1.0, 2640.0, 2640.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.376, 0.0, 0.0, 0.0, -5.395, -5.393, 0.0, 0.0, 0.0]}
{"step": 2640, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2641.0, 1.0, 1.0, 1.0, 2641.0, 2641.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.377, 0.0, 0.0, 0.0, -5.396, -5.394, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7334, "number_of_timesteps": 118512, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2641, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2642.0, 1.0, 1.0, 1.0, 2642.0, 2642.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.375, 0.0, 0.0, 0.0, -5.394, -5.392, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7338, "number_of_timesteps": 118550, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2642, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2643.0, 1.0, 1.0, 1.0, 2643.0, 2643.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.375, 0.0, 0.0, 0.0, -5.393, -5.391, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7344, "number_of_timesteps": 118609, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 2643, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2644.0, 1.0, 1.0, 1.0, 2644.0, 2644.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.373, 0.0, 0.0, 0.0, -5.391, -5.389, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7347, "number_of_timesteps": 118639, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2644, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2645.0, 1.0, 1.0, 1.0, 2645.0, 2645.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.378, 0.0, 0.0, 0.0, -5.395, -5.393, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7352, "number_of_timesteps": 118687, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.40000000000000036},
{"step": 2645, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2646.0, 1.0, 1.0, 1.0, 2646.0, 2646.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.376, 0.0, 0.0, 0.0, -5.399, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7357, "number_of_timesteps": 118737, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2646, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2647.0, 1.0, 1.0, 1.0, 2647.0, 2647.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.381, 0.0, 0.0, 0.0, -5.403, -5.401, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7359, "number_of_timesteps": 118756, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2647, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2648.0, 1.0, 1.0, 1.0, 2648.0, 2648.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.382, 0.0, 0.0, 0.0, -5.404, -5.399, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7365, "number_of_timesteps": 118818, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2648, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2649.0, 1.0, 1.0, 1.0, 2649.0, 2649.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.402, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7369, "number_of_timesteps": 118858, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2649, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2650.0, 1.0, 1.0, 1.0, 2650.0, 2650.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.4, -5.396, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7373, "number_of_timesteps": 118896, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2650, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2651.0, 1.0, 1.0, 1.0, 2651.0, 2651.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.381, 0.0, 0.0, 0.0, -5.401, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7377, "number_of_timesteps": 118938, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2651, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2652.0, 1.0, 1.0, 1.0, 2652.0, 2652.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.381, 0.0, 0.0, 0.0, -5.4, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7382, "number_of_timesteps": 118989, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 2652, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2653.0, 1.0, 1.0, 1.0, 2653.0, 2653.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.379, 0.0, 0.0, 0.0, -5.398, -5.395, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7386, "number_of_timesteps": 119030, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 2653, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2654.0, 1.0, 1.0, 1.0, 2654.0, 2654.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.399, -5.393, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7389, "number_of_timesteps": 119060, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 2654, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2655.0, 1.0, 1.0, 1.0, 2655.0, 2655.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.397, -5.392, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7396, "number_of_timesteps": 119131, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2655, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2656.0, 1.0, 1.0, 1.0, 2656.0, 2656.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.379, 0.0, 0.0, 0.0, -5.396, -5.391, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7399, "number_of_timesteps": 119157, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2656, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2657.0, 1.0, 1.0, 1.0, 2657.0, 2657.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.397, -5.392, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7405, "number_of_timesteps": 119211, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 2657, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2658.0, 1.0, 1.0, 1.0, 2658.0, 2658.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.382, 0.0, 0.0, 0.0, -5.398, -5.39, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7408, "number_of_timesteps": 119243, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.40000000000000036},
{"step": 2658, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2659.0, 1.0, 1.0, 1.0, 2659.0, 2659.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.4, -5.392, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 7415}
{"number_of_episodes": 7415, "number_of_timesteps": 119311, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 2659, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2660.0, 1.0, 1.0, 1.0, 2660.0, 2660.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.381, 0.0, 0.0, 0.0, -5.398, -5.393, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7417, "number_of_timesteps": 119329, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2660, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2661.0, 1.0, 1.0, 1.0, 2661.0, 2661.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.397, -5.392, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7424, "number_of_timesteps": 119396, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2661, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2662.0, 1.0, 1.0, 1.0, 2662.0, 2662.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.379, 0.0, 0.0, 0.0, -5.395, -5.39, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7426, "number_of_timesteps": 119416, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2662, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2663.0, 1.0, 1.0, 1.0, 2663.0, 2663.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.379, 0.0, 0.0, 0.0, -5.395, -5.388, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7434, "number_of_timesteps": 119493, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 2663, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2664.0, 1.0, 1.0, 1.0, 2664.0, 2664.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.378, 0.0, 0.0, 0.0, -5.393, -5.386, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7436, "number_of_timesteps": 119511, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 2664, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2665.0, 1.0, 1.0, 1.0, 2665.0, 2665.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.376, 0.0, 0.0, 0.0, -5.391, -5.384, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7442, "number_of_timesteps": 119570, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 2665, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2666.0, 1.0, 1.0, 1.0, 2666.0, 2666.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.377, 0.0, 0.0, 0.0, -5.392, -5.385, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7446, "number_of_timesteps": 119612, "per_episode_reward": 12.35, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 2666, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2667.0, 1.0, 1.0, 1.0, 2667.0, 2667.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.378, 0.0, 0.0, 0.0, -5.39, -5.385, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7451, "number_of_timesteps": 119659, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.15000000000000036},
{"step": 2667, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2668.0, 1.0, 1.0, 1.0, 2668.0, 2668.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.376, 0.0, 0.0, 0.0, -5.388, -5.383, 0.0, 0.0, 0.0]}
{"step": 2668, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2669.0, 1.0, 1.0, 1.0, 2669.0, 2669.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.375, 0.0, 0.0, 0.0, -5.386, -5.381, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7460, "number_of_timesteps": 119748, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.25},
{"step": 2669, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2670.0, 1.0, 1.0, 1.0, 2670.0, 2670.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.376, 0.0, 0.0, 0.0, -5.384, -5.382, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7463, "number_of_timesteps": 119776, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.20000000000000107},
{"step": 2670, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2671.0, 1.0, 1.0, 1.0, 2671.0, 2671.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.38, 0.0, 0.0, 0.0, -5.388, -5.386, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7468, "number_of_timesteps": 119825, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2671, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2672.0, 1.0, 1.0, 1.0, 2672.0, 2672.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.381, 0.0, 0.0, 0.0, -5.389, -5.387, 0.0, 0.0, 0.0]}
{"step": 2672, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2673.0, 1.0, 1.0, 1.0, 2673.0, 2673.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.382, 0.0, 0.0, 0.0, -5.389, -5.387, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7477, "number_of_timesteps": 119920, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.25},
{"step": 2673, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2674.0, 1.0, 1.0, 1.0, 2674.0, 2674.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.383, 0.0, 0.0, 0.0, -5.389, -5.385, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7480, "number_of_timesteps": 119951, "per_episode_reward": 12.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2674, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2675.0, 1.0, 1.0, 1.0, 2675.0, 2675.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.383, 0.0, 0.0, 0.0, -5.389, -5.384, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7485, "number_of_timesteps": 119999, "per_episode_reward": 12.25, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.5500000000000007},
{"step": 2675, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2676.0, 1.0, 1.0, 1.0, 2676.0, 2676.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.381, 0.0, 0.0, 0.0, -5.387, -5.382, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7490, "number_of_timesteps": 120051, "per_episode_reward": 12.25, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.20000000000000107},
{"step": 2676, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2677.0, 1.0, 1.0, 1.0, 2677.0, 2677.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.386, 0.0, 0.0, 0.0, -5.392, -5.387, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7494, "number_of_timesteps": 120088, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.20000000000000107},
{"step": 2677, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2678.0, 1.0, 1.0, 1.0, 2678.0, 2678.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.387, 0.0, 0.0, 0.0, -5.392, -5.388, 0.0, 0.0, 0.0]}
{"step": 2678, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2679.0, 1.0, 1.0, 1.0, 2679.0, 2679.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.392, 0.0, 0.0, 0.0, -5.397, -5.392, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7504, "number_of_timesteps": 120186, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.25},
{"step": 2679, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2680.0, 1.0, 1.0, 1.0, 2680.0, 2680.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.393, 0.0, 0.0, 0.0, -5.395, -5.393, 0.0, 0.0, 0.0]}
{"step": 2680, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2681.0, 1.0, 1.0, 1.0, 2681.0, 2681.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.393, 0.0, 0.0, 0.0, -5.393, -5.393, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7514, "number_of_timesteps": 120281, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.25},
{"step": 2681, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2682.0, 1.0, 1.0, 1.0, 2682.0, 2682.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.394, 0.0, 0.0, 0.0, -5.393, -5.393, 0.0, 0.0, 0.0]}
{"step": 2682, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2683.0, 1.0, 1.0, 1.0, 2683.0, 2683.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.394, 0.0, 0.0, 0.0, -5.392, -5.392, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7523, "number_of_timesteps": 120360, "per_episode_reward": 12.15, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.20000000000000107},
{"step": 2683, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2684.0, 1.0, 1.0, 1.0, 2684.0, 2684.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.395, 0.0, 0.0, 0.0, -5.393, -5.393, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7526, "number_of_timesteps": 120390, "per_episode_reward": 12.15, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.25},
{"step": 2684, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2685.0, 1.0, 1.0, 1.0, 2685.0, 2685.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.393, 0.0, 0.0, 0.0, -5.391, -5.391, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7532, "number_of_timesteps": 120448, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.20000000000000107},
{"step": 2685, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2686.0, 1.0, 1.0, 1.0, 2686.0, 2686.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.391, 0.0, 0.0, 0.0, -5.389, -5.389, 0.0, 0.0, 0.0]}
{"step": 2686, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2687.0, 1.0, 1.0, 1.0, 2687.0, 2687.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.39, 0.0, 0.0, 0.0, -5.387, -5.387, 0.0, 0.0, 0.0]}
{"eval_score": 10.2, "number_of_episodes": 7541}
{"number_of_episodes": 7541, "number_of_timesteps": 120529, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.5500000000000007},
{"step": 2687, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2688.0, 1.0, 1.0, 1.0, 2688.0, 2688.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.388, 0.0, 0.0, 0.0, -5.385, -5.385, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7545, "number_of_timesteps": 120568, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.20000000000000107},
{"step": 2688, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2689.0, 1.0, 1.0, 1.0, 2689.0, 2689.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.389, 0.0, 0.0, 0.0, -5.386, -5.386, 0.0, 0.0, 0.0]}
{"step": 2689, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2690.0, 1.0, 1.0, 1.0, 2690.0, 2690.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.388, 0.0, 0.0, 0.0, -5.384, -5.384, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7554, "number_of_timesteps": 120658, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.40000000000000036},
{"step": 2690, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2691.0, 1.0, 1.0, 1.0, 2691.0, 2691.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.386, 0.0, 0.0, 0.0, -5.389, -5.389, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7559, "number_of_timesteps": 120706, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.25},
{"step": 2691, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2692.0, 1.0, 1.0, 1.0, 2692.0, 2692.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.387, 0.0, 0.0, 0.0, -5.387, -5.39, 0.0, 0.0, 0.0]}
{"step": 2692, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2693.0, 1.0, 1.0, 1.0, 2693.0, 2693.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.385, 0.0, 0.0, 0.0, -5.393, -5.395, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7568, "number_of_timesteps": 120791, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2693, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2694.0, 1.0, 1.0, 1.0, 2694.0, 2694.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.386, 0.0, 0.0, 0.0, -5.393, -5.395, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7572, "number_of_timesteps": 120828, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 2694, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2695.0, 1.0, 1.0, 1.0, 2695.0, 2695.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.387, 0.0, 0.0, 0.0, -5.391, -5.396, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7576, "number_of_timesteps": 120871, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.20000000000000107},
{"step": 2695, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2696.0, 1.0, 1.0, 1.0, 2696.0, 2696.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.39, 0.0, 0.0, 0.0, -5.393, -5.399, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7582, "number_of_timesteps": 120932, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.40000000000000036},
{"step": 2696, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2697.0, 1.0, 1.0, 1.0, 2697.0, 2697.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.389, 0.0, 0.0, 0.0, -5.393, -5.398, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7586, "number_of_timesteps": 120969, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2697, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2698.0, 1.0, 1.0, 1.0, 2698.0, 2698.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.388, 0.0, 0.0, 0.0, -5.391, -5.396, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7591, "number_of_timesteps": 121015, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2698, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2699.0, 1.0, 1.0, 1.0, 2699.0, 2699.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.389, 0.0, 0.0, 0.0, -5.392, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7595, "number_of_timesteps": 121055, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.20000000000000107},
{"step": 2699, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2700.0, 1.0, 1.0, 1.0, 2700.0, 2700.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.395, 0.0, 0.0, 0.0, -5.397, -5.402, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7599, "number_of_timesteps": 121098, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.00944444444444444, "biggest_recent_change": 0.20000000000000107},
{"step": 2700, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2701.0, 1.0, 1.0, 1.0, 2701.0, 2701.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.393, 0.0, 0.0, 0.0, -5.395, -5.4, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7605, "number_of_timesteps": 121159, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2701, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2702.0, 1.0, 1.0, 1.0, 2702.0, 2702.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.393, 0.0, 0.0, 0.0, -5.395, -5.4, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7609, "number_of_timesteps": 121198, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.20000000000000107},
{"step": 2702, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2703.0, 1.0, 1.0, 1.0, 2703.0, 2703.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.396, 0.0, 0.0, 0.0, -5.397, -5.402, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7614, "number_of_timesteps": 121244, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2703, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2704.0, 1.0, 1.0, 1.0, 2704.0, 2704.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.394, 0.0, 0.0, 0.0, -5.395, -5.4, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7617, "number_of_timesteps": 121272, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.40000000000000036},
{"step": 2704, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2705.0, 1.0, 1.0, 1.0, 2705.0, 2705.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.393, 0.0, 0.0, 0.0, -5.396, -5.401, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7623, "number_of_timesteps": 121331, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2705, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2706.0, 1.0, 1.0, 1.0, 2706.0, 2706.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.394, 0.0, 0.0, 0.0, -5.396, -5.401, 0.0, 0.0, 0.0]}
{"step": 2706, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2707.0, 1.0, 1.0, 1.0, 2707.0, 2707.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.393, 0.0, 0.0, 0.0, -5.396, -5.401, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7632, "number_of_timesteps": 121418, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 2707, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2708.0, 1.0, 1.0, 1.0, 2708.0, 2708.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.392, 0.0, 0.0, 0.0, -5.394, -5.399, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7636, "number_of_timesteps": 121457, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.5500000000000007},
{"step": 2708, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2709.0, 1.0, 1.0, 1.0, 2709.0, 2709.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.39, 0.0, 0.0, 0.0, -5.392, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7642, "number_of_timesteps": 121517, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2709, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2710.0, 1.0, 1.0, 1.0, 2710.0, 2710.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.391, 0.0, 0.0, 0.0, -5.392, -5.397, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7646, "number_of_timesteps": 121554, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.25},
{"step": 2710, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2711.0, 1.0, 1.0, 1.0, 2711.0, 2711.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.392, 0.0, 0.0, 0.0, -5.393, -5.395, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7652, "number_of_timesteps": 121608, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2711, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2712.0, 1.0, 1.0, 1.0, 2712.0, 2712.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.393, 0.0, 0.0, 0.0, -5.393, -5.396, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7656, "number_of_timesteps": 121646, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 2712, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2713.0, 1.0, 1.0, 1.0, 2713.0, 2713.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.398, -5.401, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7661, "number_of_timesteps": 121693, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 2713, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2714.0, 1.0, 1.0, 1.0, 2714.0, 2714.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.397, -5.4, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7665, "number_of_timesteps": 121731, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.010000000000000004, "biggest_recent_change": 0.40000000000000036},
{"step": 2714, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2715.0, 1.0, 1.0, 1.0, 2715.0, 2715.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.396, 0.0, 0.0, 0.0, -5.4, -5.402, 0.0, 0.0, 0.0]}
{"eval_score": 9.2, "number_of_episodes": 7670}
{"number_of_episodes": 7670, "number_of_timesteps": 121781, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.25},
{"step": 2715, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2716.0, 1.0, 1.0, 1.0, 2716.0, 2716.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.401, -5.4, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7674, "number_of_timesteps": 121820, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2716, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2717.0, 1.0, 1.0, 1.0, 2717.0, 2717.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.401, -5.401, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7679, "number_of_timesteps": 121868, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2717, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2718.0, 1.0, 1.0, 1.0, 2718.0, 2718.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.399, 0.0, 0.0, 0.0, -5.399, -5.402, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7683, "number_of_timesteps": 121908, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2718, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2719.0, 1.0, 1.0, 1.0, 2719.0, 2719.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.398, -5.401, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7689, "number_of_timesteps": 121963, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2719, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2720.0, 1.0, 1.0, 1.0, 2720.0, 2720.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.396, -5.399, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7692, "number_of_timesteps": 121991, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.25},
{"step": 2720, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2721.0, 1.0, 1.0, 1.0, 2721.0, 2721.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.396, 0.0, 0.0, 0.0, -5.395, -5.398, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7699, "number_of_timesteps": 122060, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.25},
{"step": 2721, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2722.0, 1.0, 1.0, 1.0, 2722.0, 2722.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.395, 0.0, 0.0, 0.0, -5.393, -5.396, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7701, "number_of_timesteps": 122077, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2722, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2723.0, 1.0, 1.0, 1.0, 2723.0, 2723.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.393, 0.0, 0.0, 0.0, -5.398, -5.401, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7708, "number_of_timesteps": 122147, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.40000000000000036},
{"step": 2723, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2724.0, 1.0, 1.0, 1.0, 2724.0, 2724.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.394, 0.0, 0.0, 0.0, -5.399, -5.402, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7711, "number_of_timesteps": 122178, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.25},
{"step": 2724, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2725.0, 1.0, 1.0, 1.0, 2725.0, 2725.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.394, 0.0, 0.0, 0.0, -5.399, -5.4, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7716, "number_of_timesteps": 122226, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 2725, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2726.0, 1.0, 1.0, 1.0, 2726.0, 2726.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.399, 0.0, 0.0, 0.0, -5.404, -5.404, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7721, "number_of_timesteps": 122279, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2726, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2727.0, 1.0, 1.0, 1.0, 2727.0, 2727.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.401, 0.0, 0.0, 0.0, -5.404, -5.405, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7726, "number_of_timesteps": 122328, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.40000000000000036},
{"step": 2727, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2728.0, 1.0, 1.0, 1.0, 2728.0, 2728.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.4, 0.0, 0.0, 0.0, -5.404, -5.404, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7731, "number_of_timesteps": 122376, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2728, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2729.0, 1.0, 1.0, 1.0, 2729.0, 2729.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.399, 0.0, 0.0, 0.0, -5.408, -5.409, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7735, "number_of_timesteps": 122415, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 2729, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2730.0, 1.0, 1.0, 1.0, 2730.0, 2730.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.406, -5.407, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7741, "number_of_timesteps": 122475, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.15000000000000036},
{"step": 2730, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2731.0, 1.0, 1.0, 1.0, 2731.0, 2731.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.407, -5.407, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7745, "number_of_timesteps": 122511, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2731, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2732.0, 1.0, 1.0, 1.0, 2732.0, 2732.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.396, 0.0, 0.0, 0.0, -5.411, -5.412, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7749, "number_of_timesteps": 122550, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 2732, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2733.0, 1.0, 1.0, 1.0, 2733.0, 2733.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.4, 0.0, 0.0, 0.0, -5.415, -5.415, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7755, "number_of_timesteps": 122610, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2733, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2734.0, 1.0, 1.0, 1.0, 2734.0, 2734.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.4, 0.0, 0.0, 0.0, -5.414, -5.415, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7758, "number_of_timesteps": 122639, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2734, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2735.0, 1.0, 1.0, 1.0, 2735.0, 2735.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.4, 0.0, 0.0, 0.0, -5.412, -5.415, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7765, "number_of_timesteps": 122710, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.5500000000000007},
{"step": 2735, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2736.0, 1.0, 1.0, 1.0, 2736.0, 2736.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.399, 0.0, 0.0, 0.0, -5.41, -5.413, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7767, "number_of_timesteps": 122729, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2736, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2737.0, 1.0, 1.0, 1.0, 2737.0, 2737.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.4, 0.0, 0.0, 0.0, -5.411, -5.414, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7774, "number_of_timesteps": 122794, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 2737, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2738.0, 1.0, 1.0, 1.0, 2738.0, 2738.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.404, 0.0, 0.0, 0.0, -5.415, -5.418, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7777, "number_of_timesteps": 122825, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.40000000000000036},
{"step": 2738, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2739.0, 1.0, 1.0, 1.0, 2739.0, 2739.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.405, 0.0, 0.0, 0.0, -5.415, -5.418, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7782, "number_of_timesteps": 122870, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2739, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2740.0, 1.0, 1.0, 1.0, 2740.0, 2740.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.403, 0.0, 0.0, 0.0, -5.419, -5.422, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7786, "number_of_timesteps": 122912, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.5500000000000007},
{"step": 2740, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2741.0, 1.0, 1.0, 1.0, 2741.0, 2741.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.402, 0.0, 0.0, 0.0, -5.417, -5.42, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7790, "number_of_timesteps": 122949, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2741, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2742.0, 1.0, 1.0, 1.0, 2742.0, 2742.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.402, 0.0, 0.0, 0.0, -5.417, -5.42, 0.0, 0.0, 0.0]}
{"step": 2742, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2743.0, 1.0, 1.0, 1.0, 2743.0, 2743.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.403, 0.0, 0.0, 0.0, -5.418, -5.421, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7798, "number_of_timesteps": 123034, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.40000000000000036},
{"step": 2743, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2744.0, 1.0, 1.0, 1.0, 2744.0, 2744.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.401, 0.0, 0.0, 0.0, -5.422, -5.425, 0.0, 0.0, 0.0]}
{"eval_score": 10.0, "number_of_episodes": 7803}
{"number_of_episodes": 7803, "number_of_timesteps": 123087, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.10000000000000142},
{"step": 2744, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2745.0, 1.0, 1.0, 1.0, 2745.0, 2745.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.402, 0.0, 0.0, 0.0, -5.422, -5.425, 0.0, 0.0, 0.0]}
{"step": 2745, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2746.0, 1.0, 1.0, 1.0, 2746.0, 2746.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.401, 0.0, 0.0, 0.0, -5.421, -5.424, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7812, "number_of_timesteps": 123175, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 2746, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2747.0, 1.0, 1.0, 1.0, 2747.0, 2747.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.399, 0.0, 0.0, 0.0, -5.419, -5.422, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7817, "number_of_timesteps": 123227, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.40000000000000036},
{"step": 2747, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2748.0, 1.0, 1.0, 1.0, 2748.0, 2748.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.423, -5.426, 0.0, 0.0, 0.0]}
{"step": 2748, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2749.0, 1.0, 1.0, 1.0, 2749.0, 2749.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.396, 0.0, 0.0, 0.0, -5.421, -5.424, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7827, "number_of_timesteps": 123328, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.5500000000000007},
{"step": 2749, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2750.0, 1.0, 1.0, 1.0, 2750.0, 2750.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.395, 0.0, 0.0, 0.0, -5.419, -5.422, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7831, "number_of_timesteps": 123363, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 2750, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2751.0, 1.0, 1.0, 1.0, 2751.0, 2751.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.396, 0.0, 0.0, 0.0, -5.42, -5.423, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7834, "number_of_timesteps": 123392, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.20000000000000107},
{"step": 2751, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2752.0, 1.0, 1.0, 1.0, 2752.0, 2752.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.421, -5.421, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7840, "number_of_timesteps": 123455, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2752, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2753.0, 1.0, 1.0, 1.0, 2753.0, 2753.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.421, -5.422, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7843, "number_of_timesteps": 123486, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.20000000000000107},
{"step": 2753, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2754.0, 1.0, 1.0, 1.0, 2754.0, 2754.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.42, -5.42, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7850, "number_of_timesteps": 123556, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2754, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2755.0, 1.0, 1.0, 1.0, 2755.0, 2755.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.42, -5.421, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7851, "number_of_timesteps": 123564, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2755, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2756.0, 1.0, 1.0, 1.0, 2756.0, 2756.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.418, -5.42, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7859, "number_of_timesteps": 123641, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 2756, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2757.0, 1.0, 1.0, 1.0, 2757.0, 2757.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.399, 0.0, 0.0, 0.0, -5.419, -5.421, 0.0, 0.0, 0.0]}
{"step": 2757, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2758.0, 1.0, 1.0, 1.0, 2758.0, 2758.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.418, -5.42, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7868, "number_of_timesteps": 123727, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 2758, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2759.0, 1.0, 1.0, 1.0, 2759.0, 2759.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.416, -5.418, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7870, "number_of_timesteps": 123747, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.20000000000000107},
{"step": 2759, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2760.0, 1.0, 1.0, 1.0, 2760.0, 2760.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.395, 0.0, 0.0, 0.0, -5.414, -5.416, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7876, "number_of_timesteps": 123804, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.5500000000000007},
{"step": 2760, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2761.0, 1.0, 1.0, 1.0, 2761.0, 2761.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.394, 0.0, 0.0, 0.0, -5.412, -5.414, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7880, "number_of_timesteps": 123846, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2761, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2762.0, 1.0, 1.0, 1.0, 2762.0, 2762.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.392, 0.0, 0.0, 0.0, -5.417, -5.419, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7886, "number_of_timesteps": 123900, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2762, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2763.0, 1.0, 1.0, 1.0, 2763.0, 2763.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.392, 0.0, 0.0, 0.0, -5.416, -5.419, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7890, "number_of_timesteps": 123937, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2763, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2764.0, 1.0, 1.0, 1.0, 2764.0, 2764.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.393, 0.0, 0.0, 0.0, -5.417, -5.417, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7895, "number_of_timesteps": 123984, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2764, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2765.0, 1.0, 1.0, 1.0, 2765.0, 2765.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.399, 0.0, 0.0, 0.0, -5.422, -5.422, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7900, "number_of_timesteps": 124030, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.5500000000000007},
{"step": 2765, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2766.0, 1.0, 1.0, 1.0, 2766.0, 2766.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.42, -5.42, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7902, "number_of_timesteps": 124049, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2766, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2767.0, 1.0, 1.0, 1.0, 2767.0, 2767.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.421, -5.42, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7909, "number_of_timesteps": 124122, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 2767, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2768.0, 1.0, 1.0, 1.0, 2768.0, 2768.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.4, 0.0, 0.0, 0.0, -5.419, -5.422, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7911, "number_of_timesteps": 124143, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2768, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2769.0, 1.0, 1.0, 1.0, 2769.0, 2769.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.405, 0.0, 0.0, 0.0, -5.424, -5.427, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7919, "number_of_timesteps": 124219, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2769, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2770.0, 1.0, 1.0, 1.0, 2770.0, 2770.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.406, 0.0, 0.0, 0.0, -5.425, -5.427, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7921, "number_of_timesteps": 124238, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.5500000000000007},
{"step": 2770, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2771.0, 1.0, 1.0, 1.0, 2771.0, 2771.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.405, 0.0, 0.0, 0.0, -5.423, -5.425, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7927, "number_of_timesteps": 124293, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 2771, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2772.0, 1.0, 1.0, 1.0, 2772.0, 2772.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.406, 0.0, 0.0, 0.0, -5.423, -5.426, 0.0, 0.0, 0.0]}
{"eval_score": 9.3, "number_of_episodes": 7930}
{"number_of_episodes": 7930, "number_of_timesteps": 124328, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2772, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2773.0, 1.0, 1.0, 1.0, 2773.0, 2773.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.41, 0.0, 0.0, 0.0, -5.428, -5.43, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7937, "number_of_timesteps": 124398, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2773, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2774.0, 1.0, 1.0, 1.0, 2774.0, 2774.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.411, 0.0, 0.0, 0.0, -5.428, -5.431, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7940, "number_of_timesteps": 124425, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2774, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2775.0, 1.0, 1.0, 1.0, 2775.0, 2775.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.41, 0.0, 0.0, 0.0, -5.431, -5.434, 0.0, 0.0, 0.0]}
{"step": 2775, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2776.0, 1.0, 1.0, 1.0, 2776.0, 2776.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.408, 0.0, 0.0, 0.0, -5.436, -5.438, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7950, "number_of_timesteps": 124517, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2776, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2777.0, 1.0, 1.0, 1.0, 2777.0, 2777.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.438, -5.441, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7954, "number_of_timesteps": 124555, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 2777, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2778.0, 1.0, 1.0, 1.0, 2778.0, 2778.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.406, 0.0, 0.0, 0.0, -5.436, -5.44, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7959, "number_of_timesteps": 124607, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2778, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2779.0, 1.0, 1.0, 1.0, 2779.0, 2779.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.437, -5.438, 0.0, 0.0, 0.0]}
{"step": 2779, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2780.0, 1.0, 1.0, 1.0, 2780.0, 2780.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.437, -5.436, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7967, "number_of_timesteps": 124690, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2780, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2781.0, 1.0, 1.0, 1.0, 2781.0, 2781.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.408, 0.0, 0.0, 0.0, -5.438, -5.436, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7972, "number_of_timesteps": 124743, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2781, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2782.0, 1.0, 1.0, 1.0, 2782.0, 2782.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.409, 0.0, 0.0, 0.0, -5.436, -5.437, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7977, "number_of_timesteps": 124793, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.20000000000000107},
{"step": 2782, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2783.0, 1.0, 1.0, 1.0, 2783.0, 2783.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.434, -5.435, 0.0, 0.0, 0.0]}
{"step": 2783, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2784.0, 1.0, 1.0, 1.0, 2784.0, 2784.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.406, 0.0, 0.0, 0.0, -5.432, -5.433, 0.0, 0.0, 0.0]}
{"step": 2784, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2785.0, 1.0, 1.0, 1.0, 2785.0, 2785.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.404, 0.0, 0.0, 0.0, -5.43, -5.431, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7990, "number_of_timesteps": 124921, "per_episode_reward": 12.05, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 2785, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2786.0, 1.0, 1.0, 1.0, 2786.0, 2786.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.404, 0.0, 0.0, 0.0, -5.429, -5.43, 0.0, 0.0, 0.0]}
{"number_of_episodes": 7996, "number_of_timesteps": 124981, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2786, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2787.0, 1.0, 1.0, 1.0, 2787.0, 2787.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.408, 0.0, 0.0, 0.0, -5.433, -5.435, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8000, "number_of_timesteps": 125016, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2787, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2788.0, 1.0, 1.0, 1.0, 2788.0, 2788.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.437, -5.439, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8005, "number_of_timesteps": 125063, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2788, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2789.0, 1.0, 1.0, 1.0, 2789.0, 2789.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.406, 0.0, 0.0, 0.0, -5.436, -5.437, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8009, "number_of_timesteps": 125102, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2789, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2790.0, 1.0, 1.0, 1.0, 2790.0, 2790.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.434, -5.438, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8012, "number_of_timesteps": 125134, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 2790, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2791.0, 1.0, 1.0, 1.0, 2791.0, 2791.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.406, 0.0, 0.0, 0.0, -5.432, -5.436, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8018, "number_of_timesteps": 125195, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2791, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2792.0, 1.0, 1.0, 1.0, 2792.0, 2792.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.433, -5.437, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8022, "number_of_timesteps": 125237, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2792, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2793.0, 1.0, 1.0, 1.0, 2793.0, 2793.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.405, 0.0, 0.0, 0.0, -5.437, -5.441, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8025, "number_of_timesteps": 125267, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 2793, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2794.0, 1.0, 1.0, 1.0, 2794.0, 2794.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.404, 0.0, 0.0, 0.0, -5.436, -5.44, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8032, "number_of_timesteps": 125340, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 2794, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2795.0, 1.0, 1.0, 1.0, 2795.0, 2795.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.402, 0.0, 0.0, 0.0, -5.434, -5.438, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8034, "number_of_timesteps": 125359, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2795, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2796.0, 1.0, 1.0, 1.0, 2796.0, 2796.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.401, 0.0, 0.0, 0.0, -5.433, -5.437, 0.0, 0.0, 0.0]}
{"step": 2796, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2797.0, 1.0, 1.0, 1.0, 2797.0, 2797.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.399, 0.0, 0.0, 0.0, -5.431, -5.436, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8044, "number_of_timesteps": 125454, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2797, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2798.0, 1.0, 1.0, 1.0, 2798.0, 2798.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.431, -5.435, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8050, "number_of_timesteps": 125511, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2798, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2799.0, 1.0, 1.0, 1.0, 2799.0, 2799.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.402, 0.0, 0.0, 0.0, -5.435, -5.439, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8054, "number_of_timesteps": 125551, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2799, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2800.0, 1.0, 1.0, 1.0, 2800.0, 2800.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.403, 0.0, 0.0, 0.0, -5.436, -5.438, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8058, "number_of_timesteps": 125588, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2800, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2801.0, 1.0, 1.0, 1.0, 2801.0, 2801.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.401, 0.0, 0.0, 0.0, -5.434, -5.436, 0.0, 0.0, 0.0]}
{"eval_score": 9.8, "number_of_episodes": 8063}
{"number_of_episodes": 8063, "number_of_timesteps": 125637, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.20000000000000107},
{"step": 2801, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2802.0, 1.0, 1.0, 1.0, 2802.0, 2802.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.4, 0.0, 0.0, 0.0, -5.432, -5.434, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8068, "number_of_timesteps": 125686, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2802, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2803.0, 1.0, 1.0, 1.0, 2803.0, 2803.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.43, -5.432, 0.0, 0.0, 0.0]}
{"step": 2803, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2804.0, 1.0, 1.0, 1.0, 2804.0, 2804.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.428, -5.43, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8078, "number_of_timesteps": 125785, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 2804, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2805.0, 1.0, 1.0, 1.0, 2805.0, 2805.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.429, -5.43, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8081, "number_of_timesteps": 125813, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2805, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2806.0, 1.0, 1.0, 1.0, 2806.0, 2806.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.429, -5.431, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8085, "number_of_timesteps": 125850, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2806, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2807.0, 1.0, 1.0, 1.0, 2807.0, 2807.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.428, -5.429, 0.0, 0.0, 0.0]}
{"step": 2807, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2808.0, 1.0, 1.0, 1.0, 2808.0, 2808.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.395, 0.0, 0.0, 0.0, -5.432, -5.434, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8093, "number_of_timesteps": 125934, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2808, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2809.0, 1.0, 1.0, 1.0, 2809.0, 2809.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.4, 0.0, 0.0, 0.0, -5.436, -5.438, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8098, "number_of_timesteps": 125983, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2809, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2810.0, 1.0, 1.0, 1.0, 2810.0, 2810.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.442, -5.444, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8103, "number_of_timesteps": 126033, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2810, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2811.0, 1.0, 1.0, 1.0, 2811.0, 2811.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.397, 0.0, 0.0, 0.0, -5.44, -5.442, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8107, "number_of_timesteps": 126071, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2811, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2812.0, 1.0, 1.0, 1.0, 2812.0, 2812.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.438, -5.442, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8111, "number_of_timesteps": 126111, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2812, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2813.0, 1.0, 1.0, 1.0, 2813.0, 2813.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.398, 0.0, 0.0, 0.0, -5.438, -5.44, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8117, "number_of_timesteps": 126172, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2813, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2814.0, 1.0, 1.0, 1.0, 2814.0, 2814.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.405, 0.0, 0.0, 0.0, -5.444, -5.447, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8119, "number_of_timesteps": 126190, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2814, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2815.0, 1.0, 1.0, 1.0, 2815.0, 2815.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.404, 0.0, 0.0, 0.0, -5.443, -5.445, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8127, "number_of_timesteps": 126271, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2815, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2816.0, 1.0, 1.0, 1.0, 2816.0, 2816.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.402, 0.0, 0.0, 0.0, -5.441, -5.443, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8127, "number_of_timesteps": 126271, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 2816, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2817.0, 1.0, 1.0, 1.0, 2817.0, 2817.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.402, 0.0, 0.0, 0.0, -5.441, -5.441, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8136, "number_of_timesteps": 126361, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2817, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2818.0, 1.0, 1.0, 1.0, 2818.0, 2818.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.445, -5.446, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8137, "number_of_timesteps": 126373, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2818, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2819.0, 1.0, 1.0, 1.0, 2819.0, 2819.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.406, 0.0, 0.0, 0.0, -5.443, -5.444, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8144, "number_of_timesteps": 126439, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2819, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2820.0, 1.0, 1.0, 1.0, 2820.0, 2820.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.444, -5.444, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8147, "number_of_timesteps": 126471, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 2820, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2821.0, 1.0, 1.0, 1.0, 2821.0, 2821.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.444, -5.445, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8153, "number_of_timesteps": 126527, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2821, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2822.0, 1.0, 1.0, 1.0, 2822.0, 2822.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.406, 0.0, 0.0, 0.0, -5.449, -5.449, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8157, "number_of_timesteps": 126566, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 2822, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2823.0, 1.0, 1.0, 1.0, 2823.0, 2823.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.408, 0.0, 0.0, 0.0, -5.45, -5.451, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8162, "number_of_timesteps": 126615, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2823, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2824.0, 1.0, 1.0, 1.0, 2824.0, 2824.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.449, -5.449, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8165, "number_of_timesteps": 126644, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2824, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2825.0, 1.0, 1.0, 1.0, 2825.0, 2825.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.409, 0.0, 0.0, 0.0, -5.45, -5.451, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8170, "number_of_timesteps": 126699, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 2825, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2826.0, 1.0, 1.0, 1.0, 2826.0, 2826.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.407, 0.0, 0.0, 0.0, -5.448, -5.449, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8174, "number_of_timesteps": 126740, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2826, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2827.0, 1.0, 1.0, 1.0, 2827.0, 2827.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.405, 0.0, 0.0, 0.0, -5.452, -5.453, 0.0, 0.0, 0.0]}
{"step": 2827, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2828.0, 1.0, 1.0, 1.0, 2828.0, 2828.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.404, 0.0, 0.0, 0.0, -5.457, -5.457, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8183, "number_of_timesteps": 126826, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2828, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2829.0, 1.0, 1.0, 1.0, 2829.0, 2829.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.405, 0.0, 0.0, 0.0, -5.457, -5.458, 0.0, 0.0, 0.0]}
{"step": 2829, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2830.0, 1.0, 1.0, 1.0, 2830.0, 2830.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.404, 0.0, 0.0, 0.0, -5.456, -5.457, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 8192}
{"number_of_episodes": 8192, "number_of_timesteps": 126915, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2830, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2831.0, 1.0, 1.0, 1.0, 2831.0, 2831.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.409, 0.0, 0.0, 0.0, -5.461, -5.461, 0.0, 0.0, 0.0]}
{"step": 2831, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2832.0, 1.0, 1.0, 1.0, 2832.0, 2832.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.414, 0.0, 0.0, 0.0, -5.465, -5.466, 0.0, 0.0, 0.0]}
{"step": 2832, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2833.0, 1.0, 1.0, 1.0, 2833.0, 2833.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.413, 0.0, 0.0, 0.0, -5.464, -5.464, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8206, "number_of_timesteps": 127060, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2833, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2834.0, 1.0, 1.0, 1.0, 2834.0, 2834.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.411, 0.0, 0.0, 0.0, -5.462, -5.462, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8210, "number_of_timesteps": 127099, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2834, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2835.0, 1.0, 1.0, 1.0, 2835.0, 2835.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.412, 0.0, 0.0, 0.0, -5.462, -5.463, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8216, "number_of_timesteps": 127156, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2835, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2836.0, 1.0, 1.0, 1.0, 2836.0, 2836.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.416, 0.0, 0.0, 0.0, -5.466, -5.467, 0.0, 0.0, 0.0]}
{"step": 2836, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2837.0, 1.0, 1.0, 1.0, 2837.0, 2837.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.421, 0.0, 0.0, 0.0, -5.471, -5.471, 0.0, 0.0, 0.0]}
{"step": 2837, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2838.0, 1.0, 1.0, 1.0, 2838.0, 2838.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.426, 0.0, 0.0, 0.0, -5.475, -5.476, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8228, "number_of_timesteps": 127273, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2838, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2839.0, 1.0, 1.0, 1.0, 2839.0, 2839.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.431, 0.0, 0.0, 0.0, -5.48, -5.48, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8234, "number_of_timesteps": 127333, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2839, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2840.0, 1.0, 1.0, 1.0, 2840.0, 2840.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.429, 0.0, 0.0, 0.0, -5.478, -5.478, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8238, "number_of_timesteps": 127372, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 2840, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2841.0, 1.0, 1.0, 1.0, 2841.0, 2841.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.43, 0.0, 0.0, 0.0, -5.478, -5.479, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8243, "number_of_timesteps": 127418, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2841, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2842.0, 1.0, 1.0, 1.0, 2842.0, 2842.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.431, 0.0, 0.0, 0.0, -5.479, -5.48, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8248, "number_of_timesteps": 127468, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2842, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2843.0, 1.0, 1.0, 1.0, 2843.0, 2843.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.431, 0.0, 0.0, 0.0, -5.478, -5.479, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8253, "number_of_timesteps": 127516, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2843, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2844.0, 1.0, 1.0, 1.0, 2844.0, 2844.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.432, 0.0, 0.0, 0.0, -5.479, -5.479, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8258, "number_of_timesteps": 127561, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2844, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2845.0, 1.0, 1.0, 1.0, 2845.0, 2845.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.437, 0.0, 0.0, 0.0, -5.483, -5.484, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8263, "number_of_timesteps": 127606, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2845, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2846.0, 1.0, 1.0, 1.0, 2846.0, 2846.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.435, 0.0, 0.0, 0.0, -5.481, -5.482, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8268, "number_of_timesteps": 127648, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 2846, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2847.0, 1.0, 1.0, 1.0, 2847.0, 2847.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.434, 0.0, 0.0, 0.0, -5.48, -5.48, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8272, "number_of_timesteps": 127686, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2847, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2848.0, 1.0, 1.0, 1.0, 2848.0, 2848.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.432, 0.0, 0.0, 0.0, -5.485, -5.485, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8277, "number_of_timesteps": 127732, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2848, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2849.0, 1.0, 1.0, 1.0, 2849.0, 2849.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.432, 0.0, 0.0, 0.0, -5.484, -5.484, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8282, "number_of_timesteps": 127779, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2849, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2850.0, 1.0, 1.0, 1.0, 2850.0, 2850.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.434, 0.0, 0.0, 0.0, -5.486, -5.486, 0.0, 0.0, 0.0]}
{"step": 2850, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2851.0, 1.0, 1.0, 1.0, 2851.0, 2851.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.439, 0.0, 0.0, 0.0, -5.491, -5.491, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8292, "number_of_timesteps": 127874, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2851, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2852.0, 1.0, 1.0, 1.0, 2852.0, 2852.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.439, 0.0, 0.0, 0.0, -5.49, -5.489, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8297, "number_of_timesteps": 127921, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 2852, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2853.0, 1.0, 1.0, 1.0, 2853.0, 2853.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.439, 0.0, 0.0, 0.0, -5.49, -5.49, 0.0, 0.0, 0.0]}
{"step": 2853, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2854.0, 1.0, 1.0, 1.0, 2854.0, 2854.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.439, 0.0, 0.0, 0.0, -5.489, -5.489, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8306, "number_of_timesteps": 128010, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2854, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2855.0, 1.0, 1.0, 1.0, 2855.0, 2855.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.44, 0.0, 0.0, 0.0, -5.487, -5.489, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8311, "number_of_timesteps": 128059, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2855, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2856.0, 1.0, 1.0, 1.0, 2856.0, 2856.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.441, 0.0, 0.0, 0.0, -5.489, -5.491, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8316, "number_of_timesteps": 128107, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2856, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2857.0, 1.0, 1.0, 1.0, 2857.0, 2857.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.44, 0.0, 0.0, 0.0, -5.491, -5.493, 0.0, 0.0, 0.0]}
{"eval_score": 9.5, "number_of_episodes": 8320}
{"step": 2857, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2858.0, 1.0, 1.0, 1.0, 2858.0, 2858.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.438, 0.0, 0.0, 0.0, -5.495, -5.498, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8326, "number_of_timesteps": 128204, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2858, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2859.0, 1.0, 1.0, 1.0, 2859.0, 2859.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.437, 0.0, 0.0, 0.0, -5.494, -5.496, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8330, "number_of_timesteps": 128242, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 2859, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2860.0, 1.0, 1.0, 1.0, 2860.0, 2860.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.435, 0.0, 0.0, 0.0, -5.499, -5.501, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8335, "number_of_timesteps": 128289, "per_episode_reward": 11.95, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 2860, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2861.0, 1.0, 1.0, 1.0, 2861.0, 2861.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.436, 0.0, 0.0, 0.0, -5.497, -5.502, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8339, "number_of_timesteps": 128329, "per_episode_reward": 11.95, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 2861, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2862.0, 1.0, 1.0, 1.0, 2862.0, 2862.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.436, 0.0, 0.0, 0.0, -5.497, -5.5, 0.0, 0.0, 0.0]}
{"step": 2862, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2863.0, 1.0, 1.0, 1.0, 2863.0, 2863.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.437, 0.0, 0.0, 0.0, -5.497, -5.498, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8349, "number_of_timesteps": 128429, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2863, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2864.0, 1.0, 1.0, 1.0, 2864.0, 2864.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.435, 0.0, 0.0, 0.0, -5.495, -5.496, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8354, "number_of_timesteps": 128475, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2864, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2865.0, 1.0, 1.0, 1.0, 2865.0, 2865.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.434, 0.0, 0.0, 0.0, -5.5, -5.501, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8358, "number_of_timesteps": 128512, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2865, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2866.0, 1.0, 1.0, 1.0, 2866.0, 2866.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.433, 0.0, 0.0, 0.0, -5.498, -5.5, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8362, "number_of_timesteps": 128551, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2866, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2867.0, 1.0, 1.0, 1.0, 2867.0, 2867.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.434, 0.0, 0.0, 0.0, -5.498, -5.5, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8367, "number_of_timesteps": 128600, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2867, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2868.0, 1.0, 1.0, 1.0, 2868.0, 2868.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.439, 0.0, 0.0, 0.0, -5.502, -5.504, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8372, "number_of_timesteps": 128646, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2868, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2869.0, 1.0, 1.0, 1.0, 2869.0, 2869.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.439, 0.0, 0.0, 0.0, -5.503, -5.505, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8376, "number_of_timesteps": 128683, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2869, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2870.0, 1.0, 1.0, 1.0, 2870.0, 2870.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.441, 0.0, 0.0, 0.0, -5.504, -5.506, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8381, "number_of_timesteps": 128733, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2870, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2871.0, 1.0, 1.0, 1.0, 2871.0, 2871.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.439, 0.0, 0.0, 0.0, -5.502, -5.504, 0.0, 0.0, 0.0]}
{"step": 2871, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2872.0, 1.0, 1.0, 1.0, 2872.0, 2872.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.438, 0.0, 0.0, 0.0, -5.501, -5.503, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8390, "number_of_timesteps": 128819, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2872, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2873.0, 1.0, 1.0, 1.0, 2873.0, 2873.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.44, 0.0, 0.0, 0.0, -5.501, -5.504, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8394, "number_of_timesteps": 128858, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2873, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2874.0, 1.0, 1.0, 1.0, 2874.0, 2874.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.438, 0.0, 0.0, 0.0, -5.5, -5.502, 0.0, 0.0, 0.0]}
{"step": 2874, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2875.0, 1.0, 1.0, 1.0, 2875.0, 2875.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.436, 0.0, 0.0, 0.0, -5.498, -5.5, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8401, "number_of_timesteps": 128925, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2875, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2876.0, 1.0, 1.0, 1.0, 2876.0, 2876.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.437, 0.0, 0.0, 0.0, -5.498, -5.5, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8410, "number_of_timesteps": 129017, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2876, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2877.0, 1.0, 1.0, 1.0, 2877.0, 2877.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.441, 0.0, 0.0, 0.0, -5.502, -5.504, 0.0, 0.0, 0.0]}
{"step": 2877, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2878.0, 1.0, 1.0, 1.0, 2878.0, 2878.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.443, 0.0, 0.0, 0.0, -5.503, -5.505, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8419, "number_of_timesteps": 129103, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2878, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2879.0, 1.0, 1.0, 1.0, 2879.0, 2879.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.443, 0.0, 0.0, 0.0, -5.503, -5.503, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8420, "number_of_timesteps": 129116, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2879, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2880.0, 1.0, 1.0, 1.0, 2880.0, 2880.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.444, 0.0, 0.0, 0.0, -5.503, -5.503, 0.0, 0.0, 0.0]}
{"step": 2880, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2881.0, 1.0, 1.0, 1.0, 2881.0, 2881.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.445, 0.0, 0.0, 0.0, -5.504, -5.501, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8430, "number_of_timesteps": 129213, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2881, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2882.0, 1.0, 1.0, 1.0, 2882.0, 2882.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.444, 0.0, 0.0, 0.0, -5.503, -5.5, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8438, "number_of_timesteps": 129288, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2882, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2883.0, 1.0, 1.0, 1.0, 2883.0, 2883.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.445, 0.0, 0.0, 0.0, -5.504, -5.498, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8439, "number_of_timesteps": 129297, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2883, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2884.0, 1.0, 1.0, 1.0, 2884.0, 2884.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.444, 0.0, 0.0, 0.0, -5.506, -5.501, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8447, "number_of_timesteps": 129378, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2884, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2885.0, 1.0, 1.0, 1.0, 2885.0, 2885.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.445, 0.0, 0.0, 0.0, -5.507, -5.501, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8449, "number_of_timesteps": 129398, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2885, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2886.0, 1.0, 1.0, 1.0, 2886.0, 2886.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.443, 0.0, 0.0, 0.0, -5.505, -5.499, 0.0, 0.0, 0.0]}
{"eval_score": 9.1, "number_of_episodes": 8457}
{"number_of_episodes": 8457, "number_of_timesteps": 129473, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2886, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2887.0, 1.0, 1.0, 1.0, 2887.0, 2887.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.444, 0.0, 0.0, 0.0, -5.505, -5.5, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8458, "number_of_timesteps": 129483, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2887, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2888.0, 1.0, 1.0, 1.0, 2888.0, 2888.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.443, 0.0, 0.0, 0.0, -5.503, -5.498, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8466, "number_of_timesteps": 129559, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2888, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2889.0, 1.0, 1.0, 1.0, 2889.0, 2889.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.444, 0.0, 0.0, 0.0, -5.504, -5.496, 0.0, 0.0, 0.0]}
{"step": 2889, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2890.0, 1.0, 1.0, 1.0, 2890.0, 2890.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.444, 0.0, 0.0, 0.0, -5.504, -5.494, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8475, "number_of_timesteps": 129644, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2890, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2891.0, 1.0, 1.0, 1.0, 2891.0, 2891.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.445, 0.0, 0.0, 0.0, -5.505, -5.495, 0.0, 0.0, 0.0]}
{"step": 2891, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2892.0, 1.0, 1.0, 1.0, 2892.0, 2892.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.444, 0.0, 0.0, 0.0, -5.504, -5.494, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8485, "number_of_timesteps": 129734, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2892, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2893.0, 1.0, 1.0, 1.0, 2893.0, 2893.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.445, 0.0, 0.0, 0.0, -5.502, -5.495, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8488, "number_of_timesteps": 129761, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 2893, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2894.0, 1.0, 1.0, 1.0, 2894.0, 2894.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.447, 0.0, 0.0, 0.0, -5.503, -5.496, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8493, "number_of_timesteps": 129807, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2894, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2895.0, 1.0, 1.0, 1.0, 2895.0, 2895.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.448, 0.0, 0.0, 0.0, -5.503, -5.494, 0.0, 0.0, 0.0]}
{"step": 2895, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2896.0, 1.0, 1.0, 1.0, 2896.0, 2896.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.447, 0.0, 0.0, 0.0, -5.502, -5.492, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8502, "number_of_timesteps": 129892, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2896, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2897.0, 1.0, 1.0, 1.0, 2897.0, 2897.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.445, 0.0, 0.0, 0.0, -5.5, -5.49, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8507, "number_of_timesteps": 129943, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2897, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2898.0, 1.0, 1.0, 1.0, 2898.0, 2898.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.444, 0.0, 0.0, 0.0, -5.498, -5.488, 0.0, 0.0, 0.0]}
{"step": 2898, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2899.0, 1.0, 1.0, 1.0, 2899.0, 2899.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.442, 0.0, 0.0, 0.0, -5.496, -5.486, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8517, "number_of_timesteps": 130040, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2899, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2900.0, 1.0, 1.0, 1.0, 2900.0, 2900.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.441, 0.0, 0.0, 0.0, -5.499, -5.489, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8522, "number_of_timesteps": 130090, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2900, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2901.0, 1.0, 1.0, 1.0, 2901.0, 2901.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.441, 0.0, 0.0, 0.0, -5.5, -5.49, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8526, "number_of_timesteps": 130129, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2901, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2902.0, 1.0, 1.0, 1.0, 2902.0, 2902.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.446, 0.0, 0.0, 0.0, -5.504, -5.494, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8531, "number_of_timesteps": 130179, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 2902, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2903.0, 1.0, 1.0, 1.0, 2903.0, 2903.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.447, 0.0, 0.0, 0.0, -5.504, -5.492, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8536, "number_of_timesteps": 130225, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2903, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2904.0, 1.0, 1.0, 1.0, 2904.0, 2904.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.446, 0.0, 0.0, 0.0, -5.503, -5.491, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8541, "number_of_timesteps": 130269, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2904, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2905.0, 1.0, 1.0, 1.0, 2905.0, 2905.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.444, 0.0, 0.0, 0.0, -5.507, -5.495, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8546, "number_of_timesteps": 130315, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2905, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2906.0, 1.0, 1.0, 1.0, 2906.0, 2906.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.449, 0.0, 0.0, 0.0, -5.512, -5.499, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8550, "number_of_timesteps": 130353, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2906, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2907.0, 1.0, 1.0, 1.0, 2907.0, 2907.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.45, 0.0, 0.0, 0.0, -5.512, -5.5, 0.0, 0.0, 0.0]}
{"step": 2907, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2908.0, 1.0, 1.0, 1.0, 2908.0, 2908.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.452, 0.0, 0.0, 0.0, -5.514, -5.501, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8559, "number_of_timesteps": 130440, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2908, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2909.0, 1.0, 1.0, 1.0, 2909.0, 2909.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.45, 0.0, 0.0, 0.0, -5.512, -5.499, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8566, "number_of_timesteps": 130507, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 2909, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2910.0, 1.0, 1.0, 1.0, 2910.0, 2910.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.451, 0.0, 0.0, 0.0, -5.512, -5.497, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8569, "number_of_timesteps": 130536, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2910, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2911.0, 1.0, 1.0, 1.0, 2911.0, 2911.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.449, 0.0, 0.0, 0.0, -5.514, -5.5, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8576, "number_of_timesteps": 130601, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2911, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2912.0, 1.0, 1.0, 1.0, 2912.0, 2912.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.45, 0.0, 0.0, 0.0, -5.512, -5.5, 0.0, 0.0, 0.0]}
{"step": 2912, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2913.0, 1.0, 1.0, 1.0, 2913.0, 2913.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.449, 0.0, 0.0, 0.0, -5.51, -5.499, 0.0, 0.0, 0.0]}
{"eval_score": 9.2, "number_of_episodes": 8586}
{"number_of_episodes": 8586, "number_of_timesteps": 130695, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2913, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2914.0, 1.0, 1.0, 1.0, 2914.0, 2914.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.448, 0.0, 0.0, 0.0, -5.508, -5.497, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8588, "number_of_timesteps": 130714, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2914, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2915.0, 1.0, 1.0, 1.0, 2915.0, 2915.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.446, 0.0, 0.0, 0.0, -5.506, -5.495, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8593, "number_of_timesteps": 130760, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2915, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2916.0, 1.0, 1.0, 1.0, 2916.0, 2916.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.451, 0.0, 0.0, 0.0, -5.511, -5.5, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8598, "number_of_timesteps": 130814, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2916, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2917.0, 1.0, 1.0, 1.0, 2917.0, 2917.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.45, 0.0, 0.0, 0.0, -5.516, -5.505, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8603, "number_of_timesteps": 130858, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 2917, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2918.0, 1.0, 1.0, 1.0, 2918.0, 2918.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.451, 0.0, 0.0, 0.0, -5.517, -5.505, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8608, "number_of_timesteps": 130903, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2918, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2919.0, 1.0, 1.0, 1.0, 2919.0, 2919.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.449, 0.0, 0.0, 0.0, -5.515, -5.504, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8612, "number_of_timesteps": 130940, "per_episode_reward": 11.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 2919, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2920.0, 1.0, 1.0, 1.0, 2920.0, 2920.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.448, 0.0, 0.0, 0.0, -5.515, -5.504, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8618, "number_of_timesteps": 130997, "per_episode_reward": 11.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 2920, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2921.0, 1.0, 1.0, 1.0, 2921.0, 2921.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.449, 0.0, 0.0, 0.0, -5.516, -5.502, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8621, "number_of_timesteps": 131027, "per_episode_reward": 11.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2921, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2922.0, 1.0, 1.0, 1.0, 2922.0, 2922.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.454, 0.0, 0.0, 0.0, -5.521, -5.507, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8628, "number_of_timesteps": 131094, "per_episode_reward": 11.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2922, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2923.0, 1.0, 1.0, 1.0, 2923.0, 2923.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.453, 0.0, 0.0, 0.0, -5.525, -5.512, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8631, "number_of_timesteps": 131123, "per_episode_reward": 11.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2923, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2924.0, 1.0, 1.0, 1.0, 2924.0, 2924.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.459, 0.0, 0.0, 0.0, -5.531, -5.517, 0.0, 0.0, 0.0]}
{"step": 2924, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2925.0, 1.0, 1.0, 1.0, 2925.0, 2925.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.464, 0.0, 0.0, 0.0, -5.536, -5.522, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8640, "number_of_timesteps": 131206, "per_episode_reward": 11.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2925, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2926.0, 1.0, 1.0, 1.0, 2926.0, 2926.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.465, 0.0, 0.0, 0.0, -5.537, -5.523, 0.0, 0.0, 0.0]}
{"step": 2926, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2927.0, 1.0, 1.0, 1.0, 2927.0, 2927.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.465, 0.0, 0.0, 0.0, -5.537, -5.523, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8650, "number_of_timesteps": 131306, "per_episode_reward": 11.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2927, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2928.0, 1.0, 1.0, 1.0, 2928.0, 2928.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.467, 0.0, 0.0, 0.0, -5.537, -5.524, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8654, "number_of_timesteps": 131342, "per_episode_reward": 11.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 2928, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2929.0, 1.0, 1.0, 1.0, 2929.0, 2929.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.467, 0.0, 0.0, 0.0, -5.537, -5.524, 0.0, 0.0, 0.0]}
{"step": 2929, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2930.0, 1.0, 1.0, 1.0, 2930.0, 2930.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.468, 0.0, 0.0, 0.0, -5.538, -5.524, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8664, "number_of_timesteps": 131440, "per_episode_reward": 11.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 2930, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2931.0, 1.0, 1.0, 1.0, 2931.0, 2931.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.469, 0.0, 0.0, 0.0, -5.539, -5.522, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8669, "number_of_timesteps": 131489, "per_episode_reward": 11.75, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 2931, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2932.0, 1.0, 1.0, 1.0, 2932.0, 2932.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.47, 0.0, 0.0, 0.0, -5.539, -5.523, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8674, "number_of_timesteps": 131535, "per_episode_reward": 11.75, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 2932, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2933.0, 1.0, 1.0, 1.0, 2933.0, 2933.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.471, 0.0, 0.0, 0.0, -5.54, -5.521, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8679, "number_of_timesteps": 131582, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2933, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2934.0, 1.0, 1.0, 1.0, 2934.0, 2934.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.472, 0.0, 0.0, 0.0, -5.541, -5.522, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8682, "number_of_timesteps": 131610, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 2934, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2935.0, 1.0, 1.0, 1.0, 2935.0, 2935.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.472, 0.0, 0.0, 0.0, -5.541, -5.522, 0.0, 0.0, 0.0]}
{"step": 2935, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2936.0, 1.0, 1.0, 1.0, 2936.0, 2936.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.473, 0.0, 0.0, 0.0, -5.541, -5.522, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8692, "number_of_timesteps": 131710, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2936, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2937.0, 1.0, 1.0, 1.0, 2937.0, 2937.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.474, 0.0, 0.0, 0.0, -5.541, -5.522, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8697, "number_of_timesteps": 131756, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 2937, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2938.0, 1.0, 1.0, 1.0, 2938.0, 2938.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.472, 0.0, 0.0, 0.0, -5.539, -5.52, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8702, "number_of_timesteps": 131807, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2938, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2939.0, 1.0, 1.0, 1.0, 2939.0, 2939.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.473, 0.0, 0.0, 0.0, -5.54, -5.521, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8707, "number_of_timesteps": 131855, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 2939, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2940.0, 1.0, 1.0, 1.0, 2940.0, 2940.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.472, 0.0, 0.0, 0.0, -5.538, -5.519, 0.0, 0.0, 0.0]}
{"eval_score": 9.1, "number_of_episodes": 8711}
{"step": 2940, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2941.0, 1.0, 1.0, 1.0, 2941.0, 2941.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.473, 0.0, 0.0, 0.0, -5.539, -5.52, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8717, "number_of_timesteps": 131951, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 2941, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2942.0, 1.0, 1.0, 1.0, 2942.0, 2942.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.474, 0.0, 0.0, 0.0, -5.54, -5.521, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8721, "number_of_timesteps": 131989, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2942, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2943.0, 1.0, 1.0, 1.0, 2943.0, 2943.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.479, 0.0, 0.0, 0.0, -5.544, -5.526, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8727, "number_of_timesteps": 132048, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2943, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2944.0, 1.0, 1.0, 1.0, 2944.0, 2944.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.478, 0.0, 0.0, 0.0, -5.549, -5.531, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8731, "number_of_timesteps": 132085, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 2944, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2945.0, 1.0, 1.0, 1.0, 2945.0, 2945.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.477, 0.0, 0.0, 0.0, -5.548, -5.53, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8737, "number_of_timesteps": 132141, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2945, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2946.0, 1.0, 1.0, 1.0, 2946.0, 2946.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.475, 0.0, 0.0, 0.0, -5.546, -5.528, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8741, "number_of_timesteps": 132178, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2946, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2947.0, 1.0, 1.0, 1.0, 2947.0, 2947.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.474, 0.0, 0.0, 0.0, -5.548, -5.529, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8747, "number_of_timesteps": 132234, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2947, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2948.0, 1.0, 1.0, 1.0, 2948.0, 2948.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.472, 0.0, 0.0, 0.0, -5.546, -5.528, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8751, "number_of_timesteps": 132271, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 2948, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2949.0, 1.0, 1.0, 1.0, 2949.0, 2949.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.472, 0.0, 0.0, 0.0, -5.546, -5.527, 0.0, 0.0, 0.0]}
{"step": 2949, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2950.0, 1.0, 1.0, 1.0, 2950.0, 2950.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.474, 0.0, 0.0, 0.0, -5.547, -5.528, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8760, "number_of_timesteps": 132360, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2950, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2951.0, 1.0, 1.0, 1.0, 2951.0, 2951.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.475, 0.0, 0.0, 0.0, -5.548, -5.529, 0.0, 0.0, 0.0]}
{"step": 2951, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2952.0, 1.0, 1.0, 1.0, 2952.0, 2952.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.475, 0.0, 0.0, 0.0, -5.547, -5.529, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8770, "number_of_timesteps": 132458, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2952, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2953.0, 1.0, 1.0, 1.0, 2953.0, 2953.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.476, 0.0, 0.0, 0.0, -5.548, -5.53, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8776, "number_of_timesteps": 132512, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 2953, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2954.0, 1.0, 1.0, 1.0, 2954.0, 2954.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.477, 0.0, 0.0, 0.0, -5.549, -5.53, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8780, "number_of_timesteps": 132547, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2954, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2955.0, 1.0, 1.0, 1.0, 2955.0, 2955.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.479, 0.0, 0.0, 0.0, -5.551, -5.532, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8786, "number_of_timesteps": 132606, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2955, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2956.0, 1.0, 1.0, 1.0, 2956.0, 2956.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.478, 0.0, 0.0, 0.0, -5.555, -5.537, 0.0, 0.0, 0.0]}
{"step": 2956, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2957.0, 1.0, 1.0, 1.0, 2957.0, 2957.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.48, 0.0, 0.0, 0.0, -5.558, -5.539, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8795, "number_of_timesteps": 132691, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2957, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2958.0, 1.0, 1.0, 1.0, 2958.0, 2958.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.48, 0.0, 0.0, 0.0, -5.556, -5.538, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8799, "number_of_timesteps": 132730, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2958, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2959.0, 1.0, 1.0, 1.0, 2959.0, 2959.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.478, 0.0, 0.0, 0.0, -5.558, -5.54, 0.0, 0.0, 0.0]}
{"step": 2959, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2960.0, 1.0, 1.0, 1.0, 2960.0, 2960.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.477, 0.0, 0.0, 0.0, -5.562, -5.545, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8809, "number_of_timesteps": 132825, "per_episode_reward": 11.65, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"step": 2960, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2961.0, 1.0, 1.0, 1.0, 2961.0, 2961.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.478, 0.0, 0.0, 0.0, -5.563, -5.543, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8814, "number_of_timesteps": 132869, "per_episode_reward": 11.65, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 2961, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2962.0, 1.0, 1.0, 1.0, 2962.0, 2962.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.476, 0.0, 0.0, 0.0, -5.561, -5.541, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8818, "number_of_timesteps": 132909, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2962, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2963.0, 1.0, 1.0, 1.0, 2963.0, 2963.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.475, 0.0, 0.0, 0.0, -5.562, -5.541, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8824, "number_of_timesteps": 132967, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2963, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2964.0, 1.0, 1.0, 1.0, 2964.0, 2964.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.473, 0.0, 0.0, 0.0, -5.56, -5.54, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8828, "number_of_timesteps": 133003, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 2964, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2965.0, 1.0, 1.0, 1.0, 2965.0, 2965.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.474, 0.0, 0.0, 0.0, -5.561, -5.538, 0.0, 0.0, 0.0]}
{"step": 2965, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2966.0, 1.0, 1.0, 1.0, 2966.0, 2966.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.473, 0.0, 0.0, 0.0, -5.559, -5.536, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8838, "number_of_timesteps": 133095, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 2966, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2967.0, 1.0, 1.0, 1.0, 2967.0, 2967.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.474, 0.0, 0.0, 0.0, -5.559, -5.534, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 8843}
{"number_of_episodes": 8843, "number_of_timesteps": 133142, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2967, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2968.0, 1.0, 1.0, 1.0, 2968.0, 2968.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.479, 0.0, 0.0, 0.0, -5.564, -5.538, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8848, "number_of_timesteps": 133189, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2968, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2969.0, 1.0, 1.0, 1.0, 2969.0, 2969.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.479, 0.0, 0.0, 0.0, -5.564, -5.538, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8853, "number_of_timesteps": 133237, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2969, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2970.0, 1.0, 1.0, 1.0, 2970.0, 2970.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.477, 0.0, 0.0, 0.0, -5.569, -5.544, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8858, "number_of_timesteps": 133283, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2970, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2971.0, 1.0, 1.0, 1.0, 2971.0, 2971.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.48, 0.0, 0.0, 0.0, -5.571, -5.546, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8863, "number_of_timesteps": 133330, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 2971, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2972.0, 1.0, 1.0, 1.0, 2972.0, 2972.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.48, 0.0, 0.0, 0.0, -5.571, -5.544, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8867, "number_of_timesteps": 133366, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2972, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2973.0, 1.0, 1.0, 1.0, 2973.0, 2973.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.482, 0.0, 0.0, 0.0, -5.572, -5.545, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8871, "number_of_timesteps": 133406, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2973, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2974.0, 1.0, 1.0, 1.0, 2974.0, 2974.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.48, 0.0, 0.0, 0.0, -5.57, -5.543, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8876, "number_of_timesteps": 133456, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 2974, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2975.0, 1.0, 1.0, 1.0, 2975.0, 2975.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.481, 0.0, 0.0, 0.0, -5.568, -5.544, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8881, "number_of_timesteps": 133504, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.20000000000000107},
{"step": 2975, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2976.0, 1.0, 1.0, 1.0, 2976.0, 2976.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.48, 0.0, 0.0, 0.0, -5.566, -5.542, 0.0, 0.0, 0.0]}
{"step": 2976, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2977.0, 1.0, 1.0, 1.0, 2977.0, 2977.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.478, 0.0, 0.0, 0.0, -5.564, -5.54, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8891, "number_of_timesteps": 133599, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2977, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2978.0, 1.0, 1.0, 1.0, 2978.0, 2978.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.483, 0.0, 0.0, 0.0, -5.569, -5.545, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8894, "number_of_timesteps": 133626, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.3000000000000007},
{"step": 2978, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2979.0, 1.0, 1.0, 1.0, 2979.0, 2979.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.482, 0.0, 0.0, 0.0, -5.567, -5.543, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8901, "number_of_timesteps": 133694, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2979, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2980.0, 1.0, 1.0, 1.0, 2980.0, 2980.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.481, 0.0, 0.0, 0.0, -5.566, -5.542, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8904, "number_of_timesteps": 133721, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 2980, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2981.0, 1.0, 1.0, 1.0, 2981.0, 2981.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.481, 0.0, 0.0, 0.0, -5.566, -5.542, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8911, "number_of_timesteps": 133785, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"step": 2981, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2982.0, 1.0, 1.0, 1.0, 2982.0, 2982.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.483, 0.0, 0.0, 0.0, -5.567, -5.54, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8914, "number_of_timesteps": 133812, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 2982, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2983.0, 1.0, 1.0, 1.0, 2983.0, 2983.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.483, 0.0, 0.0, 0.0, -5.567, -5.541, 0.0, 0.0, 0.0]}
{"step": 2983, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2984.0, 1.0, 1.0, 1.0, 2984.0, 2984.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.489, 0.0, 0.0, 0.0, -5.572, -5.546, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8924, "number_of_timesteps": 133903, "per_episode_reward": 11.55, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.20000000000000107},
{"step": 2984, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2985.0, 1.0, 1.0, 1.0, 2985.0, 2985.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.487, 0.0, 0.0, 0.0, -5.57, -5.544, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8931, "number_of_timesteps": 133969, "per_episode_reward": 11.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.09999999999999964},
{"step": 2985, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2986.0, 1.0, 1.0, 1.0, 2986.0, 2986.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.488, 0.0, 0.0, 0.0, -5.571, -5.542, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8933, "number_of_timesteps": 133987, "per_episode_reward": 11.45, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.3000000000000007},
{"step": 2986, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2987.0, 1.0, 1.0, 1.0, 2987.0, 2987.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.487, 0.0, 0.0, 0.0, -5.569, -5.54, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8941, "number_of_timesteps": 134059, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2987, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2988.0, 1.0, 1.0, 1.0, 2988.0, 2988.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.485, 0.0, 0.0, 0.0, -5.568, -5.538, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8942, "number_of_timesteps": 134068, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 2988, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2989.0, 1.0, 1.0, 1.0, 2989.0, 2989.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.484, 0.0, 0.0, 0.0, -5.573, -5.544, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8949, "number_of_timesteps": 134134, "per_episode_reward": 11.35, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.25},
{"step": 2989, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2990.0, 1.0, 1.0, 1.0, 2990.0, 2990.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.485, 0.0, 0.0, 0.0, -5.574, -5.544, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8952, "number_of_timesteps": 134165, "per_episode_reward": 11.35, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.3000000000000007},
{"step": 2990, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2991.0, 1.0, 1.0, 1.0, 2991.0, 2991.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.484, 0.0, 0.0, 0.0, -5.572, -5.543, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8959, "number_of_timesteps": 134229, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 2991, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2992.0, 1.0, 1.0, 1.0, 2992.0, 2992.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.482, 0.0, 0.0, 0.0, -5.57, -5.541, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8962, "number_of_timesteps": 134257, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.1999999999999993},
{"step": 2992, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2993.0, 1.0, 1.0, 1.0, 2993.0, 2993.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.483, 0.0, 0.0, 0.0, -5.571, -5.539, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8969, "number_of_timesteps": 134322, "per_episode_reward": 11.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.25},
{"step": 2993, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2994.0, 1.0, 1.0, 1.0, 2994.0, 2994.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.485, 0.0, 0.0, 0.0, -5.572, -5.54, 0.0, 0.0, 0.0]}
{"eval_score": 9.8, "number_of_episodes": 8972}
{"number_of_episodes": 8972, "number_of_timesteps": 134352, "per_episode_reward": 11.25, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"step": 2994, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2995.0, 1.0, 1.0, 1.0, 2995.0, 2995.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.486, 0.0, 0.0, 0.0, -5.573, -5.538, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8977, "number_of_timesteps": 134396, "per_episode_reward": 11.25, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 2995, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2996.0, 1.0, 1.0, 1.0, 2996.0, 2996.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.484, 0.0, 0.0, 0.0, -5.572, -5.538, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8982, "number_of_timesteps": 134446, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.40000000000000036},
{"step": 2996, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2997.0, 1.0, 1.0, 1.0, 2997.0, 2997.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.49, 0.0, 0.0, 0.0, -5.578, -5.543, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8987, "number_of_timesteps": 134490, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 2997, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2998.0, 1.0, 1.0, 1.0, 2998.0, 2998.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.491, 0.0, 0.0, 0.0, -5.576, -5.544, 0.0, 0.0, 0.0]}
{"step": 2998, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 2999.0, 1.0, 1.0, 1.0, 2999.0, 2999.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.491, 0.0, 0.0, 0.0, -5.574, -5.543, 0.0, 0.0, 0.0]}
{"number_of_episodes": 8997, "number_of_timesteps": 134583, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.25},
{"step": 2999, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3000.0, 1.0, 1.0, 1.0, 3000.0, 3000.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.492, 0.0, 0.0, 0.0, -5.575, -5.544, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9002, "number_of_timesteps": 134630, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3000000000000007},
{"step": 3000, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3001.0, 1.0, 1.0, 1.0, 3001.0, 3001.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.491, 0.0, 0.0, 0.0, -5.573, -5.542, 0.0, 0.0, 0.0]}
{"step": 3001, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3002.0, 1.0, 1.0, 1.0, 3002.0, 3002.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.489, 0.0, 0.0, 0.0, -5.571, -5.54, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9012, "number_of_timesteps": 134724, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.20000000000000107},
{"step": 3002, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3003.0, 1.0, 1.0, 1.0, 3003.0, 3003.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.488, 0.0, 0.0, 0.0, -5.569, -5.539, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9017, "number_of_timesteps": 134772, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3500000000000014},
{"step": 3003, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3004.0, 1.0, 1.0, 1.0, 3004.0, 3004.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.486, 0.0, 0.0, 0.0, -5.568, -5.537, 0.0, 0.0, 0.0]}
{"step": 3004, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3005.0, 1.0, 1.0, 1.0, 3005.0, 3005.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.485, 0.0, 0.0, 0.0, -5.566, -5.535, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9026, "number_of_timesteps": 134860, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 3005, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3006.0, 1.0, 1.0, 1.0, 3006.0, 3006.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.486, 0.0, 0.0, 0.0, -5.566, -5.536, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9031, "number_of_timesteps": 134909, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.20000000000000107},
{"step": 3006, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3007.0, 1.0, 1.0, 1.0, 3007.0, 3007.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.484, 0.0, 0.0, 0.0, -5.565, -5.534, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9036, "number_of_timesteps": 134955, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3500000000000014},
{"step": 3007, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3008.0, 1.0, 1.0, 1.0, 3008.0, 3008.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.483, 0.0, 0.0, 0.0, -5.563, -5.532, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9040, "number_of_timesteps": 134994, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.5},
{"step": 3008, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3009.0, 1.0, 1.0, 1.0, 3009.0, 3009.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.485, 0.0, 0.0, 0.0, -5.564, -5.533, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9044, "number_of_timesteps": 135035, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.1999999999999993},
{"step": 3009, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3010.0, 1.0, 1.0, 1.0, 3010.0, 3010.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.483, 0.0, 0.0, 0.0, -5.569, -5.538, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9050, "number_of_timesteps": 135093, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.40000000000000036},
{"step": 3010, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3011.0, 1.0, 1.0, 1.0, 3011.0, 3011.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.488, 0.0, 0.0, 0.0, -5.574, -5.543, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9053, "number_of_timesteps": 135121, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3500000000000014},
{"step": 3011, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3012.0, 1.0, 1.0, 1.0, 3012.0, 3012.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.487, 0.0, 0.0, 0.0, -5.572, -5.541, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9060, "number_of_timesteps": 135187, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3012, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3013.0, 1.0, 1.0, 1.0, 3013.0, 3013.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.485, 0.0, 0.0, 0.0, -5.572, -5.542, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9063, "number_of_timesteps": 135215, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 3013, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3014.0, 1.0, 1.0, 1.0, 3014.0, 3014.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.485, 0.0, 0.0, 0.0, -5.57, -5.541, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9070, "number_of_timesteps": 135283, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.40000000000000036},
{"step": 3014, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3015.0, 1.0, 1.0, 1.0, 3015.0, 3015.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.49, 0.0, 0.0, 0.0, -5.575, -5.546, 0.0, 0.0, 0.0]}
{"step": 3015, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3016.0, 1.0, 1.0, 1.0, 3016.0, 3016.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.493, 0.0, 0.0, 0.0, -5.577, -5.548, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9080, "number_of_timesteps": 135381, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.45000000000000107},
{"step": 3016, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3017.0, 1.0, 1.0, 1.0, 3017.0, 3017.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.494, 0.0, 0.0, 0.0, -5.578, -5.549, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9081, "number_of_timesteps": 135389, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3017, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3018.0, 1.0, 1.0, 1.0, 3018.0, 3018.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.492, 0.0, 0.0, 0.0, -5.583, -5.553, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9086, "number_of_timesteps": 135437, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 3018, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3019.0, 1.0, 1.0, 1.0, 3019.0, 3019.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.494, 0.0, 0.0, 0.0, -5.581, -5.554, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9090, "number_of_timesteps": 135484, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"step": 3019, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3020.0, 1.0, 1.0, 1.0, 3020.0, 3020.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.495, 0.0, 0.0, 0.0, -5.581, -5.552, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9096, "number_of_timesteps": 135541, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.20000000000000107},
{"step": 3020, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3021.0, 1.0, 1.0, 1.0, 3021.0, 3021.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.493, 0.0, 0.0, 0.0, -5.58, -5.55, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 9100}
{"number_of_episodes": 9100, "number_of_timesteps": 135576, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.5},
{"step": 3021, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3022.0, 1.0, 1.0, 1.0, 3022.0, 3022.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.494, 0.0, 0.0, 0.0, -5.58, -5.551, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9105, "number_of_timesteps": 135620, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3500000000000014},
{"step": 3022, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3023.0, 1.0, 1.0, 1.0, 3023.0, 3023.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.493, 0.0, 0.0, 0.0, -5.578, -5.549, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9109, "number_of_timesteps": 135661, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 3023, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3024.0, 1.0, 1.0, 1.0, 3024.0, 3024.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.494, 0.0, 0.0, 0.0, -5.579, -5.55, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9115, "number_of_timesteps": 135721, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.40000000000000036},
{"step": 3024, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3025.0, 1.0, 1.0, 1.0, 3025.0, 3025.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.499, 0.0, 0.0, 0.0, -5.584, -5.555, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9118, "number_of_timesteps": 135748, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3025, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3026.0, 1.0, 1.0, 1.0, 3026.0, 3026.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.497, 0.0, 0.0, 0.0, -5.582, -5.553, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9125, "number_of_timesteps": 135816, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.40000000000000036},
{"step": 3026, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3027.0, 1.0, 1.0, 1.0, 3027.0, 3027.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.502, 0.0, 0.0, 0.0, -5.587, -5.558, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9128, "number_of_timesteps": 135844, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.5},
{"step": 3027, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3028.0, 1.0, 1.0, 1.0, 3028.0, 3028.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.503, 0.0, 0.0, 0.0, -5.587, -5.558, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9134, "number_of_timesteps": 135898, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3028, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3029.0, 1.0, 1.0, 1.0, 3029.0, 3029.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.502, 0.0, 0.0, 0.0, -5.592, -5.563, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9138, "number_of_timesteps": 135938, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3000000000000007},
{"step": 3029, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3030.0, 1.0, 1.0, 1.0, 3030.0, 3030.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.5, 0.0, 0.0, 0.0, -5.59, -5.561, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9143, "number_of_timesteps": 135987, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.45000000000000107},
{"step": 3030, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3031.0, 1.0, 1.0, 1.0, 3031.0, 3031.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.501, 0.0, 0.0, 0.0, -5.591, -5.562, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9148, "number_of_timesteps": 136037, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.1999999999999993},
{"step": 3031, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3032.0, 1.0, 1.0, 1.0, 3032.0, 3032.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.503, 0.0, 0.0, 0.0, -5.592, -5.56, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9153, "number_of_timesteps": 136086, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3500000000000014},
{"step": 3032, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3033.0, 1.0, 1.0, 1.0, 3033.0, 3033.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.501, 0.0, 0.0, 0.0, -5.59, -5.558, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9158, "number_of_timesteps": 136132, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 3033, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3034.0, 1.0, 1.0, 1.0, 3034.0, 3034.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.502, 0.0, 0.0, 0.0, -5.59, -5.559, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9163, "number_of_timesteps": 136182, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3034, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3035.0, 1.0, 1.0, 1.0, 3035.0, 3035.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.501, 0.0, 0.0, 0.0, -5.595, -5.563, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9168, "number_of_timesteps": 136230, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.45000000000000107},
{"step": 3035, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3036.0, 1.0, 1.0, 1.0, 3036.0, 3036.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.502, 0.0, 0.0, 0.0, -5.596, -5.564, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9172, "number_of_timesteps": 136269, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.5},
{"step": 3036, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3037.0, 1.0, 1.0, 1.0, 3037.0, 3037.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.501, 0.0, 0.0, 0.0, -5.595, -5.563, 0.0, 0.0, 0.0]}
{"step": 3037, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3038.0, 1.0, 1.0, 1.0, 3038.0, 3038.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.502, 0.0, 0.0, 0.0, -5.595, -5.564, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9182, "number_of_timesteps": 136363, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3500000000000014},
{"step": 3038, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3039.0, 1.0, 1.0, 1.0, 3039.0, 3039.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.501, 0.0, 0.0, 0.0, -5.594, -5.562, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9186, "number_of_timesteps": 136401, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.45000000000000107},
{"step": 3039, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3040.0, 1.0, 1.0, 1.0, 3040.0, 3040.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.502, 0.0, 0.0, 0.0, -5.594, -5.563, 0.0, 0.0, 0.0]}
{"step": 3040, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3041.0, 1.0, 1.0, 1.0, 3041.0, 3041.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.5, 0.0, 0.0, 0.0, -5.592, -5.561, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9196, "number_of_timesteps": 136497, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 3041, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3042.0, 1.0, 1.0, 1.0, 3042.0, 3042.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.5, 0.0, 0.0, 0.0, -5.591, -5.56, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9199, "number_of_timesteps": 136525, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 3042, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3043.0, 1.0, 1.0, 1.0, 3043.0, 3043.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.498, 0.0, 0.0, 0.0, -5.596, -5.564, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9206, "number_of_timesteps": 136598, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.45000000000000107},
{"step": 3043, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3044.0, 1.0, 1.0, 1.0, 3044.0, 3044.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.499, 0.0, 0.0, 0.0, -5.596, -5.565, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9208, "number_of_timesteps": 136616, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.40000000000000036},
{"step": 3044, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3045.0, 1.0, 1.0, 1.0, 3045.0, 3045.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.499, 0.0, 0.0, 0.0, -5.594, -5.564, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9216, "number_of_timesteps": 136694, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.5},
{"step": 3045, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3046.0, 1.0, 1.0, 1.0, 3046.0, 3046.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.5, 0.0, 0.0, 0.0, -5.595, -5.565, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9218, "number_of_timesteps": 136713, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3046, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3047.0, 1.0, 1.0, 1.0, 3047.0, 3047.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.499, 0.0, 0.0, 0.0, -5.593, -5.563, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9224, "number_of_timesteps": 136772, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3000000000000007},
{"step": 3047, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3048.0, 1.0, 1.0, 1.0, 3048.0, 3048.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.497, 0.0, 0.0, 0.0, -5.591, -5.561, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9228, "number_of_timesteps": 136813, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 3048, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3049.0, 1.0, 1.0, 1.0, 3049.0, 3049.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.498, 0.0, 0.0, 0.0, -5.592, -5.56, 0.0, 0.0, 0.0]}
{"eval_score": 9.4, "number_of_episodes": 9233}
{"step": 3049, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3050.0, 1.0, 1.0, 1.0, 3050.0, 3050.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.497, 0.0, 0.0, 0.0, -5.59, -5.558, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9238, "number_of_timesteps": 136907, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3500000000000014},
{"step": 3050, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3051.0, 1.0, 1.0, 1.0, 3051.0, 3051.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.495, 0.0, 0.0, 0.0, -5.588, -5.556, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9243, "number_of_timesteps": 136953, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.45000000000000107},
{"step": 3051, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3052.0, 1.0, 1.0, 1.0, 3052.0, 3052.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.496, 0.0, 0.0, 0.0, -5.589, -5.557, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9248, "number_of_timesteps": 136999, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 3052, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3053.0, 1.0, 1.0, 1.0, 3053.0, 3053.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.497, 0.0, 0.0, 0.0, -5.589, -5.555, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9252, "number_of_timesteps": 137036, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3000000000000007},
{"step": 3053, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3054.0, 1.0, 1.0, 1.0, 3054.0, 3054.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.496, 0.0, 0.0, 0.0, -5.588, -5.553, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9258, "number_of_timesteps": 137093, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 3054, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3055.0, 1.0, 1.0, 1.0, 3055.0, 3055.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.497, 0.0, 0.0, 0.0, -5.588, -5.554, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9262, "number_of_timesteps": 137131, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.40000000000000036},
{"step": 3055, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3056.0, 1.0, 1.0, 1.0, 3056.0, 3056.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.499, 0.0, 0.0, 0.0, -5.59, -5.556, 0.0, 0.0, 0.0]}
{"step": 3056, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3057.0, 1.0, 1.0, 1.0, 3057.0, 3057.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.504, 0.0, 0.0, 0.0, -5.595, -5.56, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9270, "number_of_timesteps": 137206, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 3057, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3058.0, 1.0, 1.0, 1.0, 3058.0, 3058.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.503, 0.0, 0.0, 0.0, -5.599, -5.564, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9277, "number_of_timesteps": 137273, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.5},
{"step": 3058, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3059.0, 1.0, 1.0, 1.0, 3059.0, 3059.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.503, 0.0, 0.0, 0.0, -5.6, -5.565, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9280, "number_of_timesteps": 137301, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.25},
{"step": 3059, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3060.0, 1.0, 1.0, 1.0, 3060.0, 3060.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.504, 0.0, 0.0, 0.0, -5.599, -5.565, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9286, "number_of_timesteps": 137357, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.40000000000000036},
{"step": 3060, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3061.0, 1.0, 1.0, 1.0, 3061.0, 3061.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.505, 0.0, 0.0, 0.0, -5.598, -5.565, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9290, "number_of_timesteps": 137397, "per_episode_reward": 11.2, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 3061, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3062.0, 1.0, 1.0, 1.0, 3062.0, 3062.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.503, 0.0, 0.0, 0.0, -5.602, -5.57, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9296, "number_of_timesteps": 137451, "per_episode_reward": 11.15, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"step": 3062, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3063.0, 1.0, 1.0, 1.0, 3063.0, 3063.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.504, 0.0, 0.0, 0.0, -5.602, -5.57, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9299, "number_of_timesteps": 137477, "per_episode_reward": 11.15, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.45000000000000107},
{"step": 3063, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3064.0, 1.0, 1.0, 1.0, 3064.0, 3064.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.505, 0.0, 0.0, 0.0, -5.603, -5.571, 0.0, 0.0, 0.0]}
{"step": 3064, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3065.0, 1.0, 1.0, 1.0, 3065.0, 3065.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.505, 0.0, 0.0, 0.0, -5.603, -5.571, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9309, "number_of_timesteps": 137577, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3500000000000014},
{"step": 3065, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3066.0, 1.0, 1.0, 1.0, 3066.0, 3066.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.504, 0.0, 0.0, 0.0, -5.601, -5.569, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9313, "number_of_timesteps": 137613, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3000000000000007},
{"step": 3066, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3067.0, 1.0, 1.0, 1.0, 3067.0, 3067.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.502, 0.0, 0.0, 0.0, -5.599, -5.567, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9317, "number_of_timesteps": 137653, "per_episode_reward": 11.15, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.5},
{"step": 3067, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3068.0, 1.0, 1.0, 1.0, 3068.0, 3068.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.503, 0.0, 0.0, 0.0, -5.6, -5.568, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9321, "number_of_timesteps": 137694, "per_episode_reward": 11.15, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"step": 3068, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3069.0, 1.0, 1.0, 1.0, 3069.0, 3069.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.504, 0.0, 0.0, 0.0, -5.6, -5.566, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9327, "number_of_timesteps": 137759, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3069, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3070.0, 1.0, 1.0, 1.0, 3070.0, 3070.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.505, 0.0, 0.0, 0.0, -5.601, -5.566, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9330, "number_of_timesteps": 137785, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3000000000000007},
{"step": 3070, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3071.0, 1.0, 1.0, 1.0, 3071.0, 3071.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.503, 0.0, 0.0, 0.0, -5.599, -5.565, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9336, "number_of_timesteps": 137840, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.40000000000000036},
{"step": 3071, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3072.0, 1.0, 1.0, 1.0, 3072.0, 3072.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.509, 0.0, 0.0, 0.0, -5.604, -5.569, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9340, "number_of_timesteps": 137880, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.5},
{"step": 3072, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3073.0, 1.0, 1.0, 1.0, 3073.0, 3073.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.508, 0.0, 0.0, 0.0, -5.603, -5.568, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9344, "number_of_timesteps": 137915, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 3073, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3074.0, 1.0, 1.0, 1.0, 3074.0, 3074.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.509, 0.0, 0.0, 0.0, -5.601, -5.569, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9350, "number_of_timesteps": 137974, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 3074, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3075.0, 1.0, 1.0, 1.0, 3075.0, 3075.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.508, 0.0, 0.0, 0.0, -5.605, -5.573, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9354, "number_of_timesteps": 138009, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.45000000000000107},
{"step": 3075, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3076.0, 1.0, 1.0, 1.0, 3076.0, 3076.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.509, 0.0, 0.0, 0.0, -5.606, -5.574, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9359, "number_of_timesteps": 138058, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 3076, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3077.0, 1.0, 1.0, 1.0, 3077.0, 3077.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.507, 0.0, 0.0, 0.0, -5.604, -5.572, 0.0, 0.0, 0.0]}
{"eval_score": 9.5, "number_of_episodes": 9364}
{"number_of_episodes": 9364, "number_of_timesteps": 138108, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.5},
{"step": 3077, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3078.0, 1.0, 1.0, 1.0, 3078.0, 3078.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.508, 0.0, 0.0, 0.0, -5.605, -5.573, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9369, "number_of_timesteps": 138157, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.3500000000000014},
{"step": 3078, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3079.0, 1.0, 1.0, 1.0, 3079.0, 3079.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.507, 0.0, 0.0, 0.0, -5.603, -5.571, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9373, "number_of_timesteps": 138196, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3079, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3080.0, 1.0, 1.0, 1.0, 3080.0, 3080.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.507, 0.0, 0.0, 0.0, -5.603, -5.571, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9379, "number_of_timesteps": 138254, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.45000000000000107},
{"step": 3080, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3081.0, 1.0, 1.0, 1.0, 3081.0, 3081.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.508, 0.0, 0.0, 0.0, -5.603, -5.571, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9382, "number_of_timesteps": 138283, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3081, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3082.0, 1.0, 1.0, 1.0, 3082.0, 3082.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.506, 0.0, 0.0, 0.0, -5.605, -5.573, 0.0, 0.0, 0.0]}
{"step": 3082, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3083.0, 1.0, 1.0, 1.0, 3083.0, 3083.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.505, 0.0, 0.0, 0.0, -5.61, -5.578, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9391, "number_of_timesteps": 138370, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3083, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3084.0, 1.0, 1.0, 1.0, 3084.0, 3084.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.504, 0.0, 0.0, 0.0, -5.609, -5.576, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9398, "number_of_timesteps": 138438, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.40000000000000036},
{"step": 3084, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3085.0, 1.0, 1.0, 1.0, 3085.0, 3085.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.509, 0.0, 0.0, 0.0, -5.613, -5.581, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9401, "number_of_timesteps": 138465, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3085, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3086.0, 1.0, 1.0, 1.0, 3086.0, 3086.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.508, 0.0, 0.0, 0.0, -5.612, -5.579, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9406, "number_of_timesteps": 138512, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000036},
{"step": 3086, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3087.0, 1.0, 1.0, 1.0, 3087.0, 3087.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.508, 0.0, 0.0, 0.0, -5.61, -5.579, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9411, "number_of_timesteps": 138566, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 3087, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3088.0, 1.0, 1.0, 1.0, 3088.0, 3088.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.508, 0.0, 0.0, 0.0, -5.609, -5.577, 0.0, 0.0, 0.0]}
{"step": 3088, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3089.0, 1.0, 1.0, 1.0, 3089.0, 3089.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.509, 0.0, 0.0, 0.0, -5.61, -5.575, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9419, "number_of_timesteps": 138638, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3089, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3090.0, 1.0, 1.0, 1.0, 3090.0, 3090.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.51, 0.0, 0.0, 0.0, -5.61, -5.576, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9425, "number_of_timesteps": 138698, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.40000000000000036},
{"step": 3090, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3091.0, 1.0, 1.0, 1.0, 3091.0, 3091.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.511, 0.0, 0.0, 0.0, -5.609, -5.577, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9428, "number_of_timesteps": 138728, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3091, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3092.0, 1.0, 1.0, 1.0, 3092.0, 3092.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.512, 0.0, 0.0, 0.0, -5.609, -5.577, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9432, "number_of_timesteps": 138769, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3092, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3093.0, 1.0, 1.0, 1.0, 3093.0, 3093.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.51, 0.0, 0.0, 0.0, -5.607, -5.576, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9438, "number_of_timesteps": 138831, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3093, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3094.0, 1.0, 1.0, 1.0, 3094.0, 3094.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.509, 0.0, 0.0, 0.0, -5.612, -5.58, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9440, "number_of_timesteps": 138849, "per_episode_reward": 11.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.40000000000000036},
{"step": 3094, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3095.0, 1.0, 1.0, 1.0, 3095.0, 3095.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.508, 0.0, 0.0, 0.0, -5.61, -5.579, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9448, "number_of_timesteps": 138927, "per_episode_reward": 11.05, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"step": 3095, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3096.0, 1.0, 1.0, 1.0, 3096.0, 3096.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.509, 0.0, 0.0, 0.0, -5.611, -5.58, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9449, "number_of_timesteps": 138937, "per_episode_reward": 11.05, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 3096, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3097.0, 1.0, 1.0, 1.0, 3097.0, 3097.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.507, 0.0, 0.0, 0.0, -5.609, -5.578, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9458, "number_of_timesteps": 139024, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3097, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3098.0, 1.0, 1.0, 1.0, 3098.0, 3098.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.508, 0.0, 0.0, 0.0, -5.61, -5.578, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9459, "number_of_timesteps": 139032, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3098, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3099.0, 1.0, 1.0, 1.0, 3099.0, 3099.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.507, 0.0, 0.0, 0.0, -5.61, -5.579, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9466, "number_of_timesteps": 139099, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.40000000000000036},
{"step": 3099, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3100.0, 1.0, 1.0, 1.0, 3100.0, 3100.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.511, 0.0, 0.0, 0.0, -5.614, -5.583, 0.0, 0.0, 0.0]}
{"step": 3100, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3101.0, 1.0, 1.0, 1.0, 3101.0, 3101.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.514, 0.0, 0.0, 0.0, -5.617, -5.585, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9476, "number_of_timesteps": 139201, "per_episode_reward": 11.05, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"step": 3101, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3102.0, 1.0, 1.0, 1.0, 3102.0, 3102.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.514, 0.0, 0.0, 0.0, -5.617, -5.583, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9477, "number_of_timesteps": 139210, "per_episode_reward": 11.05, "episode_reward_trend_value": -0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"step": 3102, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3103.0, 1.0, 1.0, 1.0, 3103.0, 3103.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.519, 0.0, 0.0, 0.0, -5.621, -5.587, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9482, "number_of_timesteps": 139261, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3103, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3104.0, 1.0, 1.0, 1.0, 3104.0, 3104.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.519, 0.0, 0.0, 0.0, -5.621, -5.588, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9487, "number_of_timesteps": 139318, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3104, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3105.0, 1.0, 1.0, 1.0, 3105.0, 3105.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.52, 0.0, 0.0, 0.0, -5.619, -5.588, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9489, "number_of_timesteps": 139336, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3105, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3106.0, 1.0, 1.0, 1.0, 3106.0, 3106.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.519, 0.0, 0.0, 0.0, -5.624, -5.593, 0.0, 0.0, 0.0]}
{"eval_score": 9.8, "number_of_episodes": 9496}
{"number_of_episodes": 9496, "number_of_timesteps": 139407, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3106, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3107.0, 1.0, 1.0, 1.0, 3107.0, 3107.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.517, 0.0, 0.0, 0.0, -5.623, -5.591, 0.0, 0.0, 0.0]}
{"step": 3107, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3108.0, 1.0, 1.0, 1.0, 3108.0, 3108.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.516, 0.0, 0.0, 0.0, -5.621, -5.59, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9505, "number_of_timesteps": 139497, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"step": 3108, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3109.0, 1.0, 1.0, 1.0, 3109.0, 3109.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.517, 0.0, 0.0, 0.0, -5.621, -5.588, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9507, "number_of_timesteps": 139516, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3109, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3110.0, 1.0, 1.0, 1.0, 3110.0, 3110.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.518, 0.0, 0.0, 0.0, -5.622, -5.588, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9514, "number_of_timesteps": 139582, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3110, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3111.0, 1.0, 1.0, 1.0, 3111.0, 3111.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.522, 0.0, 0.0, 0.0, -5.626, -5.593, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9517, "number_of_timesteps": 139612, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 3111, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3112.0, 1.0, 1.0, 1.0, 3112.0, 3112.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.521, 0.0, 0.0, 0.0, -5.624, -5.591, 0.0, 0.0, 0.0]}
{"step": 3112, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3113.0, 1.0, 1.0, 1.0, 3113.0, 3113.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.525, 0.0, 0.0, 0.0, -5.628, -5.595, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9527, "number_of_timesteps": 139710, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 3113, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3114.0, 1.0, 1.0, 1.0, 3114.0, 3114.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.526, 0.0, 0.0, 0.0, -5.629, -5.596, 0.0, 0.0, 0.0]}
{"step": 3114, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3115.0, 1.0, 1.0, 1.0, 3115.0, 3115.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.527, 0.0, 0.0, 0.0, -5.629, -5.596, 0.0, 0.0, 0.0]}
{"step": 3115, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3116.0, 1.0, 1.0, 1.0, 3116.0, 3116.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.528, 0.0, 0.0, 0.0, -5.63, -5.596, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9541, "number_of_timesteps": 139847, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3116, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3117.0, 1.0, 1.0, 1.0, 3117.0, 3117.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.529, 0.0, 0.0, 0.0, -5.63, -5.597, 0.0, 0.0, 0.0]}
{"step": 3117, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3118.0, 1.0, 1.0, 1.0, 3118.0, 3118.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.53, 0.0, 0.0, 0.0, -5.631, -5.598, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9550, "number_of_timesteps": 139933, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3118, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3119.0, 1.0, 1.0, 1.0, 3119.0, 3119.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.528, 0.0, 0.0, 0.0, -5.635, -5.601, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9553, "number_of_timesteps": 139962, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 3119, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3120.0, 1.0, 1.0, 1.0, 3120.0, 3120.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.528, 0.0, 0.0, 0.0, -5.634, -5.601, 0.0, 0.0, 0.0]}
{"step": 3120, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3121.0, 1.0, 1.0, 1.0, 3121.0, 3121.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.529, 0.0, 0.0, 0.0, -5.634, -5.601, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9562, "number_of_timesteps": 140049, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 3121, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3122.0, 1.0, 1.0, 1.0, 3122.0, 3122.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.529, 0.0, 0.0, 0.0, -5.635, -5.599, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9569, "number_of_timesteps": 140117, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3122, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3123.0, 1.0, 1.0, 1.0, 3123.0, 3123.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.528, 0.0, 0.0, 0.0, -5.638, -5.603, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9572, "number_of_timesteps": 140150, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3123, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3124.0, 1.0, 1.0, 1.0, 3124.0, 3124.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.532, 0.0, 0.0, 0.0, -5.642, -5.607, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9579, "number_of_timesteps": 140216, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"step": 3124, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3125.0, 1.0, 1.0, 1.0, 3125.0, 3125.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.531, 0.0, 0.0, 0.0, -5.64, -5.605, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9580, "number_of_timesteps": 140224, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3125, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3126.0, 1.0, 1.0, 1.0, 3126.0, 3126.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.531, 0.0, 0.0, 0.0, -5.641, -5.605, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9588, "number_of_timesteps": 140302, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3126, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3127.0, 1.0, 1.0, 1.0, 3127.0, 3127.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.537, 0.0, 0.0, 0.0, -5.646, -5.61, 0.0, 0.0, 0.0]}
{"step": 3127, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3128.0, 1.0, 1.0, 1.0, 3128.0, 3128.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.541, 0.0, 0.0, 0.0, -5.65, -5.615, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9597, "number_of_timesteps": 140391, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3128, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3129.0, 1.0, 1.0, 1.0, 3129.0, 3129.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.54, 0.0, 0.0, 0.0, -5.654, -5.619, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9599, "number_of_timesteps": 140411, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3129, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3130.0, 1.0, 1.0, 1.0, 3130.0, 3130.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.544, 0.0, 0.0, 0.0, -5.658, -5.623, 0.0, 0.0, 0.0]}
{"step": 3130, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3131.0, 1.0, 1.0, 1.0, 3131.0, 3131.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.543, 0.0, 0.0, 0.0, -5.663, -5.627, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9609, "number_of_timesteps": 140513, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3131, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3132.0, 1.0, 1.0, 1.0, 3132.0, 3132.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.544, 0.0, 0.0, 0.0, -5.663, -5.628, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9613, "number_of_timesteps": 140550, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3132, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3133.0, 1.0, 1.0, 1.0, 3133.0, 3133.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.545, 0.0, 0.0, 0.0, -5.664, -5.629, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9619, "number_of_timesteps": 140607, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 3133, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3134.0, 1.0, 1.0, 1.0, 3134.0, 3134.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.546, 0.0, 0.0, 0.0, -5.664, -5.627, 0.0, 0.0, 0.0]}
{"eval_score": 9.4, "number_of_episodes": 9622}
{"number_of_episodes": 9622, "number_of_timesteps": 140634, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3134, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3135.0, 1.0, 1.0, 1.0, 3135.0, 3135.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.547, 0.0, 0.0, 0.0, -5.663, -5.627, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9629, "number_of_timesteps": 140700, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 3135, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3136.0, 1.0, 1.0, 1.0, 3136.0, 3136.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.548, 0.0, 0.0, 0.0, -5.663, -5.626, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9632, "number_of_timesteps": 140726, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3136, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3137.0, 1.0, 1.0, 1.0, 3137.0, 3137.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.547, 0.0, 0.0, 0.0, -5.662, -5.624, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9637, "number_of_timesteps": 140773, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3137, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3138.0, 1.0, 1.0, 1.0, 3138.0, 3138.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.545, 0.0, 0.0, 0.0, -5.66, -5.622, 0.0, 0.0, 0.0]}
{"step": 3138, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3139.0, 1.0, 1.0, 1.0, 3139.0, 3139.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.544, 0.0, 0.0, 0.0, -5.658, -5.621, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9646, "number_of_timesteps": 140864, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 3139, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3140.0, 1.0, 1.0, 1.0, 3140.0, 3140.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.544, 0.0, 0.0, 0.0, -5.658, -5.619, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9650, "number_of_timesteps": 140902, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3140, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3141.0, 1.0, 1.0, 1.0, 3141.0, 3141.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.542, 0.0, 0.0, 0.0, -5.656, -5.617, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9656, "number_of_timesteps": 140959, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3141, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3142.0, 1.0, 1.0, 1.0, 3142.0, 3142.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.541, 0.0, 0.0, 0.0, -5.66, -5.621, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9660, "number_of_timesteps": 140996, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 3142, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3143.0, 1.0, 1.0, 1.0, 3143.0, 3143.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.539, 0.0, 0.0, 0.0, -5.659, -5.62, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9666, "number_of_timesteps": 141052, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3143, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3144.0, 1.0, 1.0, 1.0, 3144.0, 3144.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.54, 0.0, 0.0, 0.0, -5.659, -5.62, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9670, "number_of_timesteps": 141090, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 3144, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3145.0, 1.0, 1.0, 1.0, 3145.0, 3145.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.541, 0.0, 0.0, 0.0, -5.66, -5.618, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9676, "number_of_timesteps": 141147, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3145, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3146.0, 1.0, 1.0, 1.0, 3146.0, 3146.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.54, 0.0, 0.0, 0.0, -5.658, -5.617, 0.0, 0.0, 0.0]}
{"step": 3146, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3147.0, 1.0, 1.0, 1.0, 3147.0, 3147.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.538, 0.0, 0.0, 0.0, -5.656, -5.615, 0.0, 0.0, 0.0]}
{"step": 3147, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3148.0, 1.0, 1.0, 1.0, 3148.0, 3148.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.537, 0.0, 0.0, 0.0, -5.654, -5.613, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9690, "number_of_timesteps": 141285, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 3148, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3149.0, 1.0, 1.0, 1.0, 3149.0, 3149.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.538, 0.0, 0.0, 0.0, -5.655, -5.613, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9692, "number_of_timesteps": 141304, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3149, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3150.0, 1.0, 1.0, 1.0, 3150.0, 3150.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.539, 0.0, 0.0, 0.0, -5.653, -5.614, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9700, "number_of_timesteps": 141380, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3150, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3151.0, 1.0, 1.0, 1.0, 3151.0, 3151.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.537, 0.0, 0.0, 0.0, -5.654, -5.615, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9702, "number_of_timesteps": 141399, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3151, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3152.0, 1.0, 1.0, 1.0, 3152.0, 3152.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.538, 0.0, 0.0, 0.0, -5.652, -5.615, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9709, "number_of_timesteps": 141465, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3152, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3153.0, 1.0, 1.0, 1.0, 3153.0, 3153.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.539, 0.0, 0.0, 0.0, -5.652, -5.616, 0.0, 0.0, 0.0]}
{"step": 3153, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3154.0, 1.0, 1.0, 1.0, 3154.0, 3154.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.539, 0.0, 0.0, 0.0, -5.651, -5.615, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9718, "number_of_timesteps": 141549, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3154, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3155.0, 1.0, 1.0, 1.0, 3155.0, 3155.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.543, 0.0, 0.0, 0.0, -5.656, -5.619, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9722, "number_of_timesteps": 141588, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3155, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3156.0, 1.0, 1.0, 1.0, 3156.0, 3156.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.544, 0.0, 0.0, 0.0, -5.654, -5.62, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9728, "number_of_timesteps": 141641, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3156, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3157.0, 1.0, 1.0, 1.0, 3157.0, 3157.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.543, 0.0, 0.0, 0.0, -5.652, -5.618, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9732, "number_of_timesteps": 141680, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3157, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3158.0, 1.0, 1.0, 1.0, 3158.0, 3158.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.541, 0.0, 0.0, 0.0, -5.656, -5.622, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9737, "number_of_timesteps": 141725, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3158, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3159.0, 1.0, 1.0, 1.0, 3159.0, 3159.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.54, 0.0, 0.0, 0.0, -5.654, -5.621, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9742, "number_of_timesteps": 141773, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 3159, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3160.0, 1.0, 1.0, 1.0, 3160.0, 3160.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.54, 0.0, 0.0, 0.0, -5.654, -5.62, 0.0, 0.0, 0.0]}
{"step": 3160, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3161.0, 1.0, 1.0, 1.0, 3161.0, 3161.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.541, 0.0, 0.0, 0.0, -5.655, -5.621, 0.0, 0.0, 0.0]}
{"eval_score": 9.1, "number_of_episodes": 9750}
{"number_of_episodes": 9750, "number_of_timesteps": 141846, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3161, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3162.0, 1.0, 1.0, 1.0, 3162.0, 3162.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.542, 0.0, 0.0, 0.0, -5.653, -5.622, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9757, "number_of_timesteps": 141916, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3162, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3163.0, 1.0, 1.0, 1.0, 3163.0, 3163.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.543, 0.0, 0.0, 0.0, -5.654, -5.622, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9760, "number_of_timesteps": 141945, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"step": 3163, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3164.0, 1.0, 1.0, 1.0, 3164.0, 3164.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.544, 0.0, 0.0, 0.0, -5.655, -5.623, 0.0, 0.0, 0.0]}
{"step": 3164, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3165.0, 1.0, 1.0, 1.0, 3165.0, 3165.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.543, 0.0, 0.0, 0.0, -5.653, -5.621, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9770, "number_of_timesteps": 142044, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3165, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3166.0, 1.0, 1.0, 1.0, 3166.0, 3166.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.544, 0.0, 0.0, 0.0, -5.654, -5.622, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9774, "number_of_timesteps": 142082, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3166, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3167.0, 1.0, 1.0, 1.0, 3167.0, 3167.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.545, 0.0, 0.0, 0.0, -5.654, -5.62, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9780, "number_of_timesteps": 142137, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"step": 3167, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3168.0, 1.0, 1.0, 1.0, 3168.0, 3168.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.545, 0.0, 0.0, 0.0, -5.655, -5.621, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9784, "number_of_timesteps": 142175, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 3168, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3169.0, 1.0, 1.0, 1.0, 3169.0, 3169.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.544, 0.0, 0.0, 0.0, -5.653, -5.619, 0.0, 0.0, 0.0]}
{"step": 3169, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3170.0, 1.0, 1.0, 1.0, 3170.0, 3170.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.543, 0.0, 0.0, 0.0, -5.651, -5.617, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9793, "number_of_timesteps": 142261, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3170, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3171.0, 1.0, 1.0, 1.0, 3171.0, 3171.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.547, 0.0, 0.0, 0.0, -5.655, -5.622, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9798, "number_of_timesteps": 142310, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3171, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3172.0, 1.0, 1.0, 1.0, 3172.0, 3172.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.547, 0.0, 0.0, 0.0, -5.655, -5.62, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9803, "number_of_timesteps": 142359, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3172, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3173.0, 1.0, 1.0, 1.0, 3173.0, 3173.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.551, 0.0, 0.0, 0.0, -5.659, -5.624, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9807, "number_of_timesteps": 142399, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3173, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3174.0, 1.0, 1.0, 1.0, 3174.0, 3174.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.553, 0.0, 0.0, 0.0, -5.66, -5.625, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9812, "number_of_timesteps": 142447, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3174, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3175.0, 1.0, 1.0, 1.0, 3175.0, 3175.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.554, 0.0, 0.0, 0.0, -5.658, -5.626, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9817, "number_of_timesteps": 142499, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3175, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3176.0, 1.0, 1.0, 1.0, 3176.0, 3176.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.555, 0.0, 0.0, 0.0, -5.659, -5.626, 0.0, 0.0, 0.0]}
{"step": 3176, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3177.0, 1.0, 1.0, 1.0, 3177.0, 3177.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.555, 0.0, 0.0, 0.0, -5.657, -5.627, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9826, "number_of_timesteps": 142585, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 3177, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3178.0, 1.0, 1.0, 1.0, 3178.0, 3178.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.556, 0.0, 0.0, 0.0, -5.658, -5.627, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9831, "number_of_timesteps": 142631, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3178, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3179.0, 1.0, 1.0, 1.0, 3179.0, 3179.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.557, 0.0, 0.0, 0.0, -5.658, -5.628, 0.0, 0.0, 0.0]}
{"step": 3179, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3180.0, 1.0, 1.0, 1.0, 3180.0, 3180.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.558, 0.0, 0.0, 0.0, -5.659, -5.629, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9841, "number_of_timesteps": 142724, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3180, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3181.0, 1.0, 1.0, 1.0, 3181.0, 3181.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.559, 0.0, 0.0, 0.0, -5.659, -5.629, 0.0, 0.0, 0.0]}
{"step": 3181, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3182.0, 1.0, 1.0, 1.0, 3182.0, 3182.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.56, 0.0, 0.0, 0.0, -5.659, -5.629, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9850, "number_of_timesteps": 142808, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3182, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3183.0, 1.0, 1.0, 1.0, 3183.0, 3183.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.558, 0.0, 0.0, 0.0, -5.663, -5.633, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9855, "number_of_timesteps": 142857, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3183, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3184.0, 1.0, 1.0, 1.0, 3184.0, 3184.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.559, 0.0, 0.0, 0.0, -5.664, -5.634, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9859, "number_of_timesteps": 142893, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"step": 3184, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3185.0, 1.0, 1.0, 1.0, 3185.0, 3185.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.563, 0.0, 0.0, 0.0, -5.668, -5.638, 0.0, 0.0, 0.0]}
{"step": 3185, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3186.0, 1.0, 1.0, 1.0, 3186.0, 3186.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.563, 0.0, 0.0, 0.0, -5.667, -5.637, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9869, "number_of_timesteps": 142986, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3186, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3187.0, 1.0, 1.0, 1.0, 3187.0, 3187.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.564, 0.0, 0.0, 0.0, -5.668, -5.638, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9875, "number_of_timesteps": 143041, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3187, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3188.0, 1.0, 1.0, 1.0, 3188.0, 3188.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.562, 0.0, 0.0, 0.0, -5.666, -5.636, 0.0, 0.0, 0.0]}
{"step": 3188, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3189.0, 1.0, 1.0, 1.0, 3189.0, 3189.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.561, 0.0, 0.0, 0.0, -5.664, -5.634, 0.0, 0.0, 0.0]}
{"eval_score": 9.1, "number_of_episodes": 9884}
{"number_of_episodes": 9884, "number_of_timesteps": 143124, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 3189, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3190.0, 1.0, 1.0, 1.0, 3190.0, 3190.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.56, 0.0, 0.0, 0.0, -5.662, -5.632, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9888, "number_of_timesteps": 143163, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3190, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3191.0, 1.0, 1.0, 1.0, 3191.0, 3191.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.558, 0.0, 0.0, 0.0, -5.666, -5.636, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9892, "number_of_timesteps": 143203, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3191, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3192.0, 1.0, 1.0, 1.0, 3192.0, 3192.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.56, 0.0, 0.0, 0.0, -5.665, -5.638, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9897, "number_of_timesteps": 143258, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3192, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3193.0, 1.0, 1.0, 1.0, 3193.0, 3193.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.561, 0.0, 0.0, 0.0, -5.665, -5.638, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9901, "number_of_timesteps": 143299, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 3193, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3194.0, 1.0, 1.0, 1.0, 3194.0, 3194.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.565, 0.0, 0.0, 0.0, -5.669, -5.642, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9907, "number_of_timesteps": 143355, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3194, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3195.0, 1.0, 1.0, 1.0, 3195.0, 3195.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.564, 0.0, 0.0, 0.0, -5.673, -5.646, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9911, "number_of_timesteps": 143391, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3195, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3196.0, 1.0, 1.0, 1.0, 3196.0, 3196.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.562, 0.0, 0.0, 0.0, -5.672, -5.645, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9916, "number_of_timesteps": 143438, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3196, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3197.0, 1.0, 1.0, 1.0, 3197.0, 3197.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.563, 0.0, 0.0, 0.0, -5.672, -5.645, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9920, "number_of_timesteps": 143474, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 3197, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3198.0, 1.0, 1.0, 1.0, 3198.0, 3198.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.563, 0.0, 0.0, 0.0, -5.672, -5.643, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9926, "number_of_timesteps": 143533, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3198, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3199.0, 1.0, 1.0, 1.0, 3199.0, 3199.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.564, 0.0, 0.0, 0.0, -5.673, -5.644, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9930, "number_of_timesteps": 143569, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3199, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3200.0, 1.0, 1.0, 1.0, 3200.0, 3200.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.564, 0.0, 0.0, 0.0, -5.671, -5.643, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9935, "number_of_timesteps": 143613, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3200, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3201.0, 1.0, 1.0, 1.0, 3201.0, 3201.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.564, 0.0, 0.0, 0.0, -5.672, -5.641, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9940, "number_of_timesteps": 143662, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.1999999999999993},
{"step": 3201, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3202.0, 1.0, 1.0, 1.0, 3202.0, 3202.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.563, 0.0, 0.0, 0.0, -5.67, -5.639, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9945, "number_of_timesteps": 143707, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3202, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3203.0, 1.0, 1.0, 1.0, 3203.0, 3203.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.564, 0.0, 0.0, 0.0, -5.671, -5.638, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9949, "number_of_timesteps": 143743, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3203, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3204.0, 1.0, 1.0, 1.0, 3204.0, 3204.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.568, 0.0, 0.0, 0.0, -5.675, -5.642, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9955, "number_of_timesteps": 143799, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3204, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3205.0, 1.0, 1.0, 1.0, 3205.0, 3205.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.568, 0.0, 0.0, 0.0, -5.673, -5.642, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9958, "number_of_timesteps": 143827, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3205, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3206.0, 1.0, 1.0, 1.0, 3206.0, 3206.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.567, 0.0, 0.0, 0.0, -5.671, -5.64, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9965, "number_of_timesteps": 143892, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3206, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3207.0, 1.0, 1.0, 1.0, 3207.0, 3207.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.567, 0.0, 0.0, 0.0, -5.671, -5.64, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9968, "number_of_timesteps": 143920, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3207, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3208.0, 1.0, 1.0, 1.0, 3208.0, 3208.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.566, 0.0, 0.0, 0.0, -5.673, -5.642, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9975, "number_of_timesteps": 143983, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3208, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3209.0, 1.0, 1.0, 1.0, 3209.0, 3209.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.568, 0.0, 0.0, 0.0, -5.675, -5.644, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9978, "number_of_timesteps": 144013, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3209, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3210.0, 1.0, 1.0, 1.0, 3210.0, 3210.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.569, 0.0, 0.0, 0.0, -5.673, -5.644, 0.0, 0.0, 0.0]}
{"step": 3210, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3211.0, 1.0, 1.0, 1.0, 3211.0, 3211.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.568, 0.0, 0.0, 0.0, -5.671, -5.643, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9988, "number_of_timesteps": 144110, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3211, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3212.0, 1.0, 1.0, 1.0, 3212.0, 3212.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.567, 0.0, 0.0, 0.0, -5.677, -5.649, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9993, "number_of_timesteps": 144156, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3212, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3213.0, 1.0, 1.0, 1.0, 3213.0, 3213.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.568, 0.0, 0.0, 0.0, -5.678, -5.65, 0.0, 0.0, 0.0]}
{"number_of_episodes": 9997, "number_of_timesteps": 144194, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3213, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3214.0, 1.0, 1.0, 1.0, 3214.0, 3214.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.573, 0.0, 0.0, 0.0, -5.683, -5.654, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10003, "number_of_timesteps": 144252, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3214, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3215.0, 1.0, 1.0, 1.0, 3215.0, 3215.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.572, 0.0, 0.0, 0.0, -5.681, -5.653, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10007, "number_of_timesteps": 144291, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3215, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3216.0, 1.0, 1.0, 1.0, 3216.0, 3216.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.576, 0.0, 0.0, 0.0, -5.685, -5.657, 0.0, 0.0, 0.0]}
{"eval_score": 9.5, "number_of_episodes": 10012}
{"number_of_episodes": 10012, "number_of_timesteps": 144336, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3216, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3217.0, 1.0, 1.0, 1.0, 3217.0, 3217.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.577, 0.0, 0.0, 0.0, -5.686, -5.655, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10017, "number_of_timesteps": 144380, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3217, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3218.0, 1.0, 1.0, 1.0, 3218.0, 3218.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.578, 0.0, 0.0, 0.0, -5.687, -5.656, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10021, "number_of_timesteps": 144416, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3218, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3219.0, 1.0, 1.0, 1.0, 3219.0, 3219.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.58, 0.0, 0.0, 0.0, -5.687, -5.657, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10027, "number_of_timesteps": 144473, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3219, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3220.0, 1.0, 1.0, 1.0, 3220.0, 3220.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.578, 0.0, 0.0, 0.0, -5.686, -5.655, 0.0, 0.0, 0.0]}
{"step": 3220, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3221.0, 1.0, 1.0, 1.0, 3221.0, 3221.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.579, 0.0, 0.0, 0.0, -5.686, -5.656, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10037, "number_of_timesteps": 144565, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3221, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3222.0, 1.0, 1.0, 1.0, 3222.0, 3222.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.58, 0.0, 0.0, 0.0, -5.685, -5.657, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10039, "number_of_timesteps": 144584, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3222, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3223.0, 1.0, 1.0, 1.0, 3223.0, 3223.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.579, 0.0, 0.0, 0.0, -5.69, -5.662, 0.0, 0.0, 0.0]}
{"step": 3223, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3224.0, 1.0, 1.0, 1.0, 3224.0, 3224.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.58, 0.0, 0.0, 0.0, -5.688, -5.662, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10048, "number_of_timesteps": 144674, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3224, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3225.0, 1.0, 1.0, 1.0, 3225.0, 3225.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.581, 0.0, 0.0, 0.0, -5.688, -5.663, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10055, "number_of_timesteps": 144743, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3225, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3226.0, 1.0, 1.0, 1.0, 3226.0, 3226.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.585, 0.0, 0.0, 0.0, -5.693, -5.667, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10058, "number_of_timesteps": 144771, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3226, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3227.0, 1.0, 1.0, 1.0, 3227.0, 3227.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.586, 0.0, 0.0, 0.0, -5.692, -5.667, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10065, "number_of_timesteps": 144838, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3227, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3228.0, 1.0, 1.0, 1.0, 3228.0, 3228.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.584, 0.0, 0.0, 0.0, -5.691, -5.665, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10067, "number_of_timesteps": 144858, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3228, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3229.0, 1.0, 1.0, 1.0, 3229.0, 3229.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.584, 0.0, 0.0, 0.0, -5.689, -5.665, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10075, "number_of_timesteps": 144935, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3229, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3230.0, 1.0, 1.0, 1.0, 3230.0, 3230.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.583, 0.0, 0.0, 0.0, -5.687, -5.663, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10077, "number_of_timesteps": 144954, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3230, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3231.0, 1.0, 1.0, 1.0, 3231.0, 3231.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.582, 0.0, 0.0, 0.0, -5.691, -5.667, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10085, "number_of_timesteps": 145027, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3231, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3232.0, 1.0, 1.0, 1.0, 3232.0, 3232.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.586, 0.0, 0.0, 0.0, -5.695, -5.672, 0.0, 0.0, 0.0]}
{"step": 3232, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3233.0, 1.0, 1.0, 1.0, 3233.0, 3233.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.59, 0.0, 0.0, 0.0, -5.7, -5.676, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10095, "number_of_timesteps": 145124, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3233, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3234.0, 1.0, 1.0, 1.0, 3234.0, 3234.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.591, 0.0, 0.0, 0.0, -5.698, -5.676, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10097, "number_of_timesteps": 145142, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.1999999999999993},
{"step": 3234, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3235.0, 1.0, 1.0, 1.0, 3235.0, 3235.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.59, 0.0, 0.0, 0.0, -5.696, -5.674, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10105, "number_of_timesteps": 145215, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3235, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3236.0, 1.0, 1.0, 1.0, 3236.0, 3236.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.591, 0.0, 0.0, 0.0, -5.697, -5.675, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10107, "number_of_timesteps": 145232, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3236, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3237.0, 1.0, 1.0, 1.0, 3237.0, 3237.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.592, 0.0, 0.0, 0.0, -5.697, -5.676, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10113, "number_of_timesteps": 145288, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3237, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3238.0, 1.0, 1.0, 1.0, 3238.0, 3238.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.59, 0.0, 0.0, 0.0, -5.695, -5.674, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10117, "number_of_timesteps": 145330, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3238, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3239.0, 1.0, 1.0, 1.0, 3239.0, 3239.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.589, 0.0, 0.0, 0.0, -5.7, -5.678, 0.0, 0.0, 0.0]}
{"step": 3239, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3240.0, 1.0, 1.0, 1.0, 3240.0, 3240.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.588, 0.0, 0.0, 0.0, -5.702, -5.68, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10127, "number_of_timesteps": 145428, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3240, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3241.0, 1.0, 1.0, 1.0, 3241.0, 3241.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.586, 0.0, 0.0, 0.0, -5.7, -5.679, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10132, "number_of_timesteps": 145473, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3241, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3242.0, 1.0, 1.0, 1.0, 3242.0, 3242.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.585, 0.0, 0.0, 0.0, -5.698, -5.677, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10136, "number_of_timesteps": 145508, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3242, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3243.0, 1.0, 1.0, 1.0, 3243.0, 3243.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.583, 0.0, 0.0, 0.0, -5.703, -5.681, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 10141}
{"number_of_episodes": 10141, "number_of_timesteps": 145556, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 3243, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3244.0, 1.0, 1.0, 1.0, 3244.0, 3244.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.584, 0.0, 0.0, 0.0, -5.703, -5.681, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10146, "number_of_timesteps": 145605, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3244, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3245.0, 1.0, 1.0, 1.0, 3245.0, 3245.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.585, 0.0, 0.0, 0.0, -5.704, -5.682, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10151, "number_of_timesteps": 145653, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3245, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3246.0, 1.0, 1.0, 1.0, 3246.0, 3246.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.586, 0.0, 0.0, 0.0, -5.704, -5.682, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10155, "number_of_timesteps": 145690, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3246, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3247.0, 1.0, 1.0, 1.0, 3247.0, 3247.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.584, 0.0, 0.0, 0.0, -5.702, -5.681, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10161, "number_of_timesteps": 145749, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3247, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3248.0, 1.0, 1.0, 1.0, 3248.0, 3248.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.589, 0.0, 0.0, 0.0, -5.706, -5.685, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10164, "number_of_timesteps": 145776, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3248, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3249.0, 1.0, 1.0, 1.0, 3249.0, 3249.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.588, 0.0, 0.0, 0.0, -5.711, -5.689, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10170, "number_of_timesteps": 145833, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3249, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3250.0, 1.0, 1.0, 1.0, 3250.0, 3250.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.588, 0.0, 0.0, 0.0, -5.711, -5.69, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10174, "number_of_timesteps": 145872, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3250, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3251.0, 1.0, 1.0, 1.0, 3251.0, 3251.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.588, 0.0, 0.0, 0.0, -5.71, -5.689, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10180, "number_of_timesteps": 145927, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3251, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3252.0, 1.0, 1.0, 1.0, 3252.0, 3252.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.589, 0.0, 0.0, 0.0, -5.711, -5.689, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10184, "number_of_timesteps": 145965, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3252, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3253.0, 1.0, 1.0, 1.0, 3253.0, 3253.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.594, 0.0, 0.0, 0.0, -5.715, -5.694, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10189, "number_of_timesteps": 146012, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3253, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3254.0, 1.0, 1.0, 1.0, 3254.0, 3254.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.592, 0.0, 0.0, 0.0, -5.713, -5.692, 0.0, 0.0, 0.0]}
{"step": 3254, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3255.0, 1.0, 1.0, 1.0, 3255.0, 3255.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.591, 0.0, 0.0, 0.0, -5.712, -5.69, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10198, "number_of_timesteps": 146098, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3255, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3256.0, 1.0, 1.0, 1.0, 3256.0, 3256.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.591, 0.0, 0.0, 0.0, -5.712, -5.69, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10203, "number_of_timesteps": 146145, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3256, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3257.0, 1.0, 1.0, 1.0, 3257.0, 3257.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.59, 0.0, 0.0, 0.0, -5.71, -5.689, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10207, "number_of_timesteps": 146185, "per_episode_reward": 11.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3257, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3258.0, 1.0, 1.0, 1.0, 3258.0, 3258.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.589, 0.0, 0.0, 0.0, -5.708, -5.687, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10212, "number_of_timesteps": 146235, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3258, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3259.0, 1.0, 1.0, 1.0, 3259.0, 3259.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.588, 0.0, 0.0, 0.0, -5.708, -5.686, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10217, "number_of_timesteps": 146283, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3259, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3260.0, 1.0, 1.0, 1.0, 3260.0, 3260.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.587, 0.0, 0.0, 0.0, -5.712, -5.691, 0.0, 0.0, 0.0]}
{"step": 3260, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3261.0, 1.0, 1.0, 1.0, 3261.0, 3261.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.585, 0.0, 0.0, 0.0, -5.714, -5.692, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10226, "number_of_timesteps": 146368, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3261, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3262.0, 1.0, 1.0, 1.0, 3262.0, 3262.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.585, 0.0, 0.0, 0.0, -5.713, -5.691, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10231, "number_of_timesteps": 146417, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3262, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3263.0, 1.0, 1.0, 1.0, 3263.0, 3263.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.586, 0.0, 0.0, 0.0, -5.713, -5.69, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10236, "number_of_timesteps": 146466, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3263, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3264.0, 1.0, 1.0, 1.0, 3264.0, 3264.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.587, 0.0, 0.0, 0.0, -5.714, -5.69, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10241, "number_of_timesteps": 146511, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3264, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3265.0, 1.0, 1.0, 1.0, 3265.0, 3265.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.588, 0.0, 0.0, 0.0, -5.712, -5.691, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10246, "number_of_timesteps": 146557, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3265, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3266.0, 1.0, 1.0, 1.0, 3266.0, 3266.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.589, 0.0, 0.0, 0.0, -5.713, -5.691, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10251, "number_of_timesteps": 146601, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3266, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3267.0, 1.0, 1.0, 1.0, 3267.0, 3267.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.589, 0.0, 0.0, 0.0, -5.713, -5.69, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10256, "number_of_timesteps": 146649, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3267, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3268.0, 1.0, 1.0, 1.0, 3268.0, 3268.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.588, 0.0, 0.0, 0.0, -5.712, -5.688, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10261, "number_of_timesteps": 146694, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3268, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3269.0, 1.0, 1.0, 1.0, 3269.0, 3269.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.593, 0.0, 0.0, 0.0, -5.717, -5.693, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10266, "number_of_timesteps": 146742, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3269, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3270.0, 1.0, 1.0, 1.0, 3270.0, 3270.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.592, 0.0, 0.0, 0.0, -5.721, -5.697, 0.0, 0.0, 0.0]}
{"eval_score": 9.4, "number_of_episodes": 10271}
{"number_of_episodes": 10271, "number_of_timesteps": 146790, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3270, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3271.0, 1.0, 1.0, 1.0, 3271.0, 3271.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.593, 0.0, 0.0, 0.0, -5.721, -5.698, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10276, "number_of_timesteps": 146837, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3271, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3272.0, 1.0, 1.0, 1.0, 3272.0, 3272.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.594, 0.0, 0.0, 0.0, -5.722, -5.698, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10280, "number_of_timesteps": 146873, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3272, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3273.0, 1.0, 1.0, 1.0, 3273.0, 3273.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.592, 0.0, 0.0, 0.0, -5.722, -5.698, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10286, "number_of_timesteps": 146930, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3273, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3274.0, 1.0, 1.0, 1.0, 3274.0, 3274.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.594, 0.0, 0.0, 0.0, -5.72, -5.699, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10289, "number_of_timesteps": 146957, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3274, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3275.0, 1.0, 1.0, 1.0, 3275.0, 3275.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.595, 0.0, 0.0, 0.0, -5.721, -5.697, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10295, "number_of_timesteps": 147015, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3275, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3276.0, 1.0, 1.0, 1.0, 3276.0, 3276.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.596, 0.0, 0.0, 0.0, -5.722, -5.698, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10298, "number_of_timesteps": 147044, "per_episode_reward": 10.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 3276, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3277.0, 1.0, 1.0, 1.0, 3277.0, 3277.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.596, 0.0, 0.0, 0.0, -5.721, -5.698, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10305, "number_of_timesteps": 147114, "per_episode_reward": 10.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 3277, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3278.0, 1.0, 1.0, 1.0, 3278.0, 3278.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.595, 0.0, 0.0, 0.0, -5.721, -5.696, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10308, "number_of_timesteps": 147141, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3278, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3279.0, 1.0, 1.0, 1.0, 3279.0, 3279.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.594, 0.0, 0.0, 0.0, -5.725, -5.7, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10314, "number_of_timesteps": 147198, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3279, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3280.0, 1.0, 1.0, 1.0, 3280.0, 3280.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.593, 0.0, 0.0, 0.0, -5.724, -5.699, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10318, "number_of_timesteps": 147239, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 3280, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3281.0, 1.0, 1.0, 1.0, 3281.0, 3281.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.591, 0.0, 0.0, 0.0, -5.722, -5.697, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10324, "number_of_timesteps": 147296, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3281, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3282.0, 1.0, 1.0, 1.0, 3282.0, 3282.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.592, 0.0, 0.0, 0.0, -5.723, -5.698, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10327, "number_of_timesteps": 147323, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3282, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3283.0, 1.0, 1.0, 1.0, 3283.0, 3283.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.591, 0.0, 0.0, 0.0, -5.721, -5.696, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10334, "number_of_timesteps": 147390, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3283, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3284.0, 1.0, 1.0, 1.0, 3284.0, 3284.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.592, 0.0, 0.0, 0.0, -5.719, -5.697, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10337, "number_of_timesteps": 147418, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 3284, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3285.0, 1.0, 1.0, 1.0, 3285.0, 3285.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.591, 0.0, 0.0, 0.0, -5.717, -5.695, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10343, "number_of_timesteps": 147475, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3285, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3286.0, 1.0, 1.0, 1.0, 3286.0, 3286.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.592, 0.0, 0.0, 0.0, -5.718, -5.696, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10347, "number_of_timesteps": 147514, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3286, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3287.0, 1.0, 1.0, 1.0, 3287.0, 3287.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.597, 0.0, 0.0, 0.0, -5.723, -5.701, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10352, "number_of_timesteps": 147560, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3287, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3288.0, 1.0, 1.0, 1.0, 3288.0, 3288.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.596, 0.0, 0.0, 0.0, -5.721, -5.699, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10356, "number_of_timesteps": 147599, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3288, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3289.0, 1.0, 1.0, 1.0, 3289.0, 3289.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.597, 0.0, 0.0, 0.0, -5.722, -5.697, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10360, "number_of_timesteps": 147637, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3289, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3290.0, 1.0, 1.0, 1.0, 3290.0, 3290.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.598, 0.0, 0.0, 0.0, -5.721, -5.698, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10365, "number_of_timesteps": 147686, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3290, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3291.0, 1.0, 1.0, 1.0, 3291.0, 3291.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.597, 0.0, 0.0, 0.0, -5.719, -5.696, 0.0, 0.0, 0.0]}
{"step": 3291, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3292.0, 1.0, 1.0, 1.0, 3292.0, 3292.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.598, 0.0, 0.0, 0.0, -5.717, -5.697, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10373, "number_of_timesteps": 147767, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3292, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3293.0, 1.0, 1.0, 1.0, 3293.0, 3293.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.599, 0.0, 0.0, 0.0, -5.718, -5.695, 0.0, 0.0, 0.0]}
{"step": 3293, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3294.0, 1.0, 1.0, 1.0, 3294.0, 3294.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.599, 0.0, 0.0, 0.0, -5.718, -5.694, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10383, "number_of_timesteps": 147868, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3294, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3295.0, 1.0, 1.0, 1.0, 3295.0, 3295.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.597, 0.0, 0.0, 0.0, -5.716, -5.692, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10389, "number_of_timesteps": 147922, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3295, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3296.0, 1.0, 1.0, 1.0, 3296.0, 3296.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.598, 0.0, 0.0, 0.0, -5.714, -5.693, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10393, "number_of_timesteps": 147959, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3296, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3297.0, 1.0, 1.0, 1.0, 3297.0, 3297.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.598, 0.0, 0.0, 0.0, -5.714, -5.692, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10397, "number_of_timesteps": 147995, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3297, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3298.0, 1.0, 1.0, 1.0, 3298.0, 3298.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.597, 0.0, 0.0, 0.0, -5.715, -5.694, 0.0, 0.0, 0.0]}
{"eval_score": 9.1, "number_of_episodes": 10403}
{"number_of_episodes": 10403, "number_of_timesteps": 148054, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3298, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3299.0, 1.0, 1.0, 1.0, 3299.0, 3299.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.598, 0.0, 0.0, 0.0, -5.714, -5.694, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10406, "number_of_timesteps": 148083, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3299, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3300.0, 1.0, 1.0, 1.0, 3300.0, 3300.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.599, 0.0, 0.0, 0.0, -5.714, -5.695, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10413, "number_of_timesteps": 148147, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3300, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3301.0, 1.0, 1.0, 1.0, 3301.0, 3301.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.6, 0.0, 0.0, 0.0, -5.713, -5.696, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10415, "number_of_timesteps": 148165, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3301, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3302.0, 1.0, 1.0, 1.0, 3302.0, 3302.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.598, 0.0, 0.0, 0.0, -5.711, -5.694, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10420, "number_of_timesteps": 148214, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3302, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3303.0, 1.0, 1.0, 1.0, 3303.0, 3303.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.599, 0.0, 0.0, 0.0, -5.711, -5.694, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10424, "number_of_timesteps": 148259, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3303, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3304.0, 1.0, 1.0, 1.0, 3304.0, 3304.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.598, 0.0, 0.0, 0.0, -5.715, -5.698, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10428, "number_of_timesteps": 148298, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3304, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3305.0, 1.0, 1.0, 1.0, 3305.0, 3305.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.6, 0.0, 0.0, 0.0, -5.717, -5.7, 0.0, 0.0, 0.0]}
{"step": 3305, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3306.0, 1.0, 1.0, 1.0, 3306.0, 3306.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.604, 0.0, 0.0, 0.0, -5.721, -5.704, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10438, "number_of_timesteps": 148399, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3306, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3307.0, 1.0, 1.0, 1.0, 3307.0, 3307.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.603, 0.0, 0.0, 0.0, -5.72, -5.702, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10443, "number_of_timesteps": 148446, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3307, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3308.0, 1.0, 1.0, 1.0, 3308.0, 3308.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.607, 0.0, 0.0, 0.0, -5.724, -5.706, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10447, "number_of_timesteps": 148486, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3308, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3309.0, 1.0, 1.0, 1.0, 3309.0, 3309.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.608, 0.0, 0.0, 0.0, -5.724, -5.707, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10453, "number_of_timesteps": 148546, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3309, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3310.0, 1.0, 1.0, 1.0, 3310.0, 3310.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.609, 0.0, 0.0, 0.0, -5.722, -5.707, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10457, "number_of_timesteps": 148584, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3310, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3311.0, 1.0, 1.0, 1.0, 3311.0, 3311.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.61, 0.0, 0.0, 0.0, -5.723, -5.708, 0.0, 0.0, 0.0]}
{"step": 3311, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3312.0, 1.0, 1.0, 1.0, 3312.0, 3312.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.614, 0.0, 0.0, 0.0, -5.726, -5.711, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10464, "number_of_timesteps": 148649, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3312, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3313.0, 1.0, 1.0, 1.0, 3313.0, 3313.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.613, 0.0, 0.0, 0.0, -5.726, -5.711, 0.0, 0.0, 0.0]}
{"step": 3313, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3314.0, 1.0, 1.0, 1.0, 3314.0, 3314.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.614, 0.0, 0.0, 0.0, -5.726, -5.711, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10474, "number_of_timesteps": 148751, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3314, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3315.0, 1.0, 1.0, 1.0, 3315.0, 3315.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.618, 0.0, 0.0, 0.0, -5.73, -5.715, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10481, "number_of_timesteps": 148817, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3315, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3316.0, 1.0, 1.0, 1.0, 3316.0, 3316.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.618, 0.0, 0.0, 0.0, -5.729, -5.714, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10484, "number_of_timesteps": 148845, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3316, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3317.0, 1.0, 1.0, 1.0, 3317.0, 3317.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.619, 0.0, 0.0, 0.0, -5.73, -5.712, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10490, "number_of_timesteps": 148904, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3317, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3318.0, 1.0, 1.0, 1.0, 3318.0, 3318.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.617, 0.0, 0.0, 0.0, -5.728, -5.711, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10494, "number_of_timesteps": 148946, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3318, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3319.0, 1.0, 1.0, 1.0, 3319.0, 3319.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.618, 0.0, 0.0, 0.0, -5.729, -5.709, 0.0, 0.0, 0.0]}
{"step": 3319, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3320.0, 1.0, 1.0, 1.0, 3320.0, 3320.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.619, 0.0, 0.0, 0.0, -5.729, -5.707, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10503, "number_of_timesteps": 149031, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3320, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3321.0, 1.0, 1.0, 1.0, 3321.0, 3321.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.623, 0.0, 0.0, 0.0, -5.733, -5.711, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10509, "number_of_timesteps": 149090, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3321, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3322.0, 1.0, 1.0, 1.0, 3322.0, 3322.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.622, 0.0, 0.0, 0.0, -5.735, -5.713, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10512, "number_of_timesteps": 149120, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3322, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3323.0, 1.0, 1.0, 1.0, 3323.0, 3323.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.623, 0.0, 0.0, 0.0, -5.736, -5.713, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10519, "number_of_timesteps": 149188, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3323, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3324.0, 1.0, 1.0, 1.0, 3324.0, 3324.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.624, 0.0, 0.0, 0.0, -5.736, -5.712, 0.0, 0.0, 0.0]}
{"step": 3324, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3325.0, 1.0, 1.0, 1.0, 3325.0, 3325.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.624, 0.0, 0.0, 0.0, -5.736, -5.71, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10529, "number_of_timesteps": 149282, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 3325, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3326.0, 1.0, 1.0, 1.0, 3326.0, 3326.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.622, 0.0, 0.0, 0.0, -5.734, -5.708, 0.0, 0.0, 0.0]}
{"eval_score": 10.1, "number_of_episodes": 10532}
{"number_of_episodes": 10532, "number_of_timesteps": 149309, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3326, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3327.0, 1.0, 1.0, 1.0, 3327.0, 3327.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.623, 0.0, 0.0, 0.0, -5.735, -5.709, 0.0, 0.0, 0.0]}
{"step": 3327, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3328.0, 1.0, 1.0, 1.0, 3328.0, 3328.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.622, 0.0, 0.0, 0.0, -5.733, -5.707, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10542, "number_of_timesteps": 149405, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3328, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3329.0, 1.0, 1.0, 1.0, 3329.0, 3329.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.62, 0.0, 0.0, 0.0, -5.737, -5.711, 0.0, 0.0, 0.0]}
{"step": 3329, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3330.0, 1.0, 1.0, 1.0, 3330.0, 3330.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.619, 0.0, 0.0, 0.0, -5.736, -5.71, 0.0, 0.0, 0.0]}
{"step": 3330, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3331.0, 1.0, 1.0, 1.0, 3331.0, 3331.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.618, 0.0, 0.0, 0.0, -5.74, -5.714, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10555, "number_of_timesteps": 149528, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3331, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3332.0, 1.0, 1.0, 1.0, 3332.0, 3332.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.616, 0.0, 0.0, 0.0, -5.738, -5.712, 0.0, 0.0, 0.0]}
{"step": 3332, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3333.0, 1.0, 1.0, 1.0, 3333.0, 3333.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.615, 0.0, 0.0, 0.0, -5.736, -5.71, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10565, "number_of_timesteps": 149628, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3333, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3334.0, 1.0, 1.0, 1.0, 3334.0, 3334.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.616, 0.0, 0.0, 0.0, -5.737, -5.711, 0.0, 0.0, 0.0]}
{"step": 3334, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3335.0, 1.0, 1.0, 1.0, 3335.0, 3335.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.615, 0.0, 0.0, 0.0, -5.736, -5.71, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10575, "number_of_timesteps": 149725, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3335, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3336.0, 1.0, 1.0, 1.0, 3336.0, 3336.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.615, 0.0, 0.0, 0.0, -5.735, -5.708, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10579, "number_of_timesteps": 149763, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3336, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3337.0, 1.0, 1.0, 1.0, 3337.0, 3337.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.614, 0.0, 0.0, 0.0, -5.734, -5.708, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10585, "number_of_timesteps": 149820, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3337, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3338.0, 1.0, 1.0, 1.0, 3338.0, 3338.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.613, 0.0, 0.0, 0.0, -5.732, -5.706, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10589, "number_of_timesteps": 149857, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3338, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3339.0, 1.0, 1.0, 1.0, 3339.0, 3339.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.613, 0.0, 0.0, 0.0, -5.732, -5.706, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10595, "number_of_timesteps": 149915, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3339, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3340.0, 1.0, 1.0, 1.0, 3340.0, 3340.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.614, 0.0, 0.0, 0.0, -5.73, -5.706, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10599, "number_of_timesteps": 149954, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3340, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3341.0, 1.0, 1.0, 1.0, 3341.0, 3341.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.613, 0.0, 0.0, 0.0, -5.735, -5.71, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10605, "number_of_timesteps": 150009, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 3341, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3342.0, 1.0, 1.0, 1.0, 3342.0, 3342.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.614, 0.0, 0.0, 0.0, -5.735, -5.709, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10608, "number_of_timesteps": 150035, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3342, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3343.0, 1.0, 1.0, 1.0, 3343.0, 3343.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.615, 0.0, 0.0, 0.0, -5.736, -5.709, 0.0, 0.0, 0.0]}
{"step": 3343, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3344.0, 1.0, 1.0, 1.0, 3344.0, 3344.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.615, 0.0, 0.0, 0.0, -5.736, -5.707, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10618, "number_of_timesteps": 150133, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3344, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3345.0, 1.0, 1.0, 1.0, 3345.0, 3345.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.615, 0.0, 0.0, 0.0, -5.736, -5.706, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10622, "number_of_timesteps": 150172, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3345, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3346.0, 1.0, 1.0, 1.0, 3346.0, 3346.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.614, 0.0, 0.0, 0.0, -5.734, -5.704, 0.0, 0.0, 0.0]}
{"step": 3346, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3347.0, 1.0, 1.0, 1.0, 3347.0, 3347.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.615, 0.0, 0.0, 0.0, -5.735, -5.705, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10630, "number_of_timesteps": 150256, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3347, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3348.0, 1.0, 1.0, 1.0, 3348.0, 3348.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.615, 0.0, 0.0, 0.0, -5.735, -5.703, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10634, "number_of_timesteps": 150300, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3348, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3349.0, 1.0, 1.0, 1.0, 3349.0, 3349.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.62, 0.0, 0.0, 0.0, -5.739, -5.707, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10640, "number_of_timesteps": 150361, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3349, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3350.0, 1.0, 1.0, 1.0, 3350.0, 3350.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.618, 0.0, 0.0, 0.0, -5.737, -5.705, 0.0, 0.0, 0.0]}
{"step": 3350, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3351.0, 1.0, 1.0, 1.0, 3351.0, 3351.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.622, 0.0, 0.0, 0.0, -5.741, -5.709, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10648, "number_of_timesteps": 150439, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3351, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3352.0, 1.0, 1.0, 1.0, 3352.0, 3352.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.623, 0.0, 0.0, 0.0, -5.741, -5.709, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10652, "number_of_timesteps": 150483, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3352, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3353.0, 1.0, 1.0, 1.0, 3353.0, 3353.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.624, 0.0, 0.0, 0.0, -5.742, -5.71, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10657, "number_of_timesteps": 150532, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3353, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3354.0, 1.0, 1.0, 1.0, 3354.0, 3354.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.623, 0.0, 0.0, 0.0, -5.74, -5.708, 0.0, 0.0, 0.0]}
{"eval_score": 9.2, "number_of_episodes": 10661}
{"number_of_episodes": 10661, "number_of_timesteps": 150571, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3354, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3355.0, 1.0, 1.0, 1.0, 3355.0, 3355.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.621, 0.0, 0.0, 0.0, -5.744, -5.712, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10667, "number_of_timesteps": 150629, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3355, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3356.0, 1.0, 1.0, 1.0, 3356.0, 3356.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.622, 0.0, 0.0, 0.0, -5.745, -5.713, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10670, "number_of_timesteps": 150656, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3356, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3357.0, 1.0, 1.0, 1.0, 3357.0, 3357.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.621, 0.0, 0.0, 0.0, -5.743, -5.711, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10675, "number_of_timesteps": 150705, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3357, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3358.0, 1.0, 1.0, 1.0, 3358.0, 3358.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.621, 0.0, 0.0, 0.0, -5.741, -5.711, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10680, "number_of_timesteps": 150757, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3358, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3359.0, 1.0, 1.0, 1.0, 3359.0, 3359.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.62, 0.0, 0.0, 0.0, -5.745, -5.715, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10685, "number_of_timesteps": 150804, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3359, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3360.0, 1.0, 1.0, 1.0, 3360.0, 3360.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.621, 0.0, 0.0, 0.0, -5.745, -5.716, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10690, "number_of_timesteps": 150848, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3360, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3361.0, 1.0, 1.0, 1.0, 3361.0, 3361.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.622, 0.0, 0.0, 0.0, -5.746, -5.716, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10695, "number_of_timesteps": 150894, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3361, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3362.0, 1.0, 1.0, 1.0, 3362.0, 3362.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.624, 0.0, 0.0, 0.0, -5.748, -5.718, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10700, "number_of_timesteps": 150943, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3362, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3363.0, 1.0, 1.0, 1.0, 3363.0, 3363.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.625, 0.0, 0.0, 0.0, -5.748, -5.719, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10704, "number_of_timesteps": 150978, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3363, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3364.0, 1.0, 1.0, 1.0, 3364.0, 3364.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.626, 0.0, 0.0, 0.0, -5.747, -5.719, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10709, "number_of_timesteps": 151026, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3364, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3365.0, 1.0, 1.0, 1.0, 3365.0, 3365.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.626, 0.0, 0.0, 0.0, -5.747, -5.717, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10714, "number_of_timesteps": 151074, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3365, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3366.0, 1.0, 1.0, 1.0, 3366.0, 3366.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.627, 0.0, 0.0, 0.0, -5.748, -5.718, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10719, "number_of_timesteps": 151122, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3366, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3367.0, 1.0, 1.0, 1.0, 3367.0, 3367.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.628, 0.0, 0.0, 0.0, -5.748, -5.716, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10723, "number_of_timesteps": 151158, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3367, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3368.0, 1.0, 1.0, 1.0, 3368.0, 3368.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.629, 0.0, 0.0, 0.0, -5.749, -5.717, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10729, "number_of_timesteps": 151215, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3368, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3369.0, 1.0, 1.0, 1.0, 3369.0, 3369.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.633, 0.0, 0.0, 0.0, -5.752, -5.721, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10733, "number_of_timesteps": 151253, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3369, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3370.0, 1.0, 1.0, 1.0, 3370.0, 3370.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.633, 0.0, 0.0, 0.0, -5.752, -5.72, 0.0, 0.0, 0.0]}
{"step": 3370, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3371.0, 1.0, 1.0, 1.0, 3371.0, 3371.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.637, 0.0, 0.0, 0.0, -5.756, -5.724, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10743, "number_of_timesteps": 151347, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3371, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3372.0, 1.0, 1.0, 1.0, 3372.0, 3372.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.638, 0.0, 0.0, 0.0, -5.757, -5.725, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10748, "number_of_timesteps": 151396, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3372, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3373.0, 1.0, 1.0, 1.0, 3373.0, 3373.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.639, 0.0, 0.0, 0.0, -5.755, -5.725, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10753, "number_of_timesteps": 151441, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 3373, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3374.0, 1.0, 1.0, 1.0, 3374.0, 3374.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.64, 0.0, 0.0, 0.0, -5.755, -5.726, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10757, "number_of_timesteps": 151479, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3374, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3375.0, 1.0, 1.0, 1.0, 3375.0, 3375.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.644, 0.0, 0.0, 0.0, -5.759, -5.73, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10760, "number_of_timesteps": 151508, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3375, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3376.0, 1.0, 1.0, 1.0, 3376.0, 3376.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.763, -5.734, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10766, "number_of_timesteps": 151569, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3376, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3377.0, 1.0, 1.0, 1.0, 3377.0, 3377.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.763, -5.732, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10770, "number_of_timesteps": 151608, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3377, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3378.0, 1.0, 1.0, 1.0, 3378.0, 3378.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.761, -5.731, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10776, "number_of_timesteps": 151663, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3378, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3379.0, 1.0, 1.0, 1.0, 3379.0, 3379.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.646, 0.0, 0.0, 0.0, -5.765, -5.735, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10779, "number_of_timesteps": 151692, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3379, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3380.0, 1.0, 1.0, 1.0, 3380.0, 3380.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.647, 0.0, 0.0, 0.0, -5.766, -5.735, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10785, "number_of_timesteps": 151749, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3380, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3381.0, 1.0, 1.0, 1.0, 3381.0, 3381.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.646, 0.0, 0.0, 0.0, -5.77, -5.739, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10789, "number_of_timesteps": 151790, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 3381, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3382.0, 1.0, 1.0, 1.0, 3382.0, 3382.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.644, 0.0, 0.0, 0.0, -5.768, -5.738, 0.0, 0.0, 0.0]}
{"eval_score": 9.5, "number_of_episodes": 10794}
{"number_of_episodes": 10794, "number_of_timesteps": 151836, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3382, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3383.0, 1.0, 1.0, 1.0, 3383.0, 3383.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.766, -5.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10798, "number_of_timesteps": 151876, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3383, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3384.0, 1.0, 1.0, 1.0, 3384.0, 3384.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.766, -5.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10804, "number_of_timesteps": 151935, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.1999999999999993},
{"step": 3384, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3385.0, 1.0, 1.0, 1.0, 3385.0, 3385.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.644, 0.0, 0.0, 0.0, -5.765, -5.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10808, "number_of_timesteps": 151973, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3385, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3386.0, 1.0, 1.0, 1.0, 3386.0, 3386.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.644, 0.0, 0.0, 0.0, -5.764, -5.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10814, "number_of_timesteps": 152029, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3386, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3387.0, 1.0, 1.0, 1.0, 3387.0, 3387.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.766, -5.737, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10818, "number_of_timesteps": 152068, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3387, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3388.0, 1.0, 1.0, 1.0, 3388.0, 3388.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.644, 0.0, 0.0, 0.0, -5.766, -5.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10824, "number_of_timesteps": 152124, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3388, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3389.0, 1.0, 1.0, 1.0, 3389.0, 3389.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.767, -5.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10827, "number_of_timesteps": 152152, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3389, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3390.0, 1.0, 1.0, 1.0, 3390.0, 3390.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.646, 0.0, 0.0, 0.0, -5.768, -5.738, 0.0, 0.0, 0.0]}
{"step": 3390, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3391.0, 1.0, 1.0, 1.0, 3391.0, 3391.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.65, 0.0, 0.0, 0.0, -5.772, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10836, "number_of_timesteps": 152239, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3391, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3392.0, 1.0, 1.0, 1.0, 3392.0, 3392.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.65, 0.0, 0.0, 0.0, -5.772, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10844, "number_of_timesteps": 152318, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3392, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3393.0, 1.0, 1.0, 1.0, 3393.0, 3393.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.65, 0.0, 0.0, 0.0, -5.771, -5.74, 0.0, 0.0, 0.0]}
{"step": 3393, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3394.0, 1.0, 1.0, 1.0, 3394.0, 3394.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.651, 0.0, 0.0, 0.0, -5.772, -5.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10853, "number_of_timesteps": 152407, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3394, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3395.0, 1.0, 1.0, 1.0, 3395.0, 3395.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.652, 0.0, 0.0, 0.0, -5.773, -5.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10855, "number_of_timesteps": 152428, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3395, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3396.0, 1.0, 1.0, 1.0, 3396.0, 3396.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.651, 0.0, 0.0, 0.0, -5.776, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10860, "number_of_timesteps": 152476, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3396, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3397.0, 1.0, 1.0, 1.0, 3397.0, 3397.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.652, 0.0, 0.0, 0.0, -5.777, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10865, "number_of_timesteps": 152527, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3397, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3398.0, 1.0, 1.0, 1.0, 3398.0, 3398.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.65, 0.0, 0.0, 0.0, -5.775, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10869, "number_of_timesteps": 152565, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3398, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3399.0, 1.0, 1.0, 1.0, 3399.0, 3399.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.65, 0.0, 0.0, 0.0, -5.775, -5.74, 0.0, 0.0, 0.0]}
{"step": 3399, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3400.0, 1.0, 1.0, 1.0, 3400.0, 3400.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.651, 0.0, 0.0, 0.0, -5.775, -5.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10879, "number_of_timesteps": 152660, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3400, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3401.0, 1.0, 1.0, 1.0, 3401.0, 3401.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.65, 0.0, 0.0, 0.0, -5.774, -5.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10885, "number_of_timesteps": 152713, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3401, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3402.0, 1.0, 1.0, 1.0, 3402.0, 3402.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.649, 0.0, 0.0, 0.0, -5.778, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10889, "number_of_timesteps": 152753, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3402, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3403.0, 1.0, 1.0, 1.0, 3403.0, 3403.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.65, 0.0, 0.0, 0.0, -5.779, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10894, "number_of_timesteps": 152799, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3403, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3404.0, 1.0, 1.0, 1.0, 3404.0, 3404.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.651, 0.0, 0.0, 0.0, -5.779, -5.739, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10898, "number_of_timesteps": 152839, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3404, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3405.0, 1.0, 1.0, 1.0, 3405.0, 3405.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.649, 0.0, 0.0, 0.0, -5.778, -5.738, 0.0, 0.0, 0.0]}
{"step": 3405, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3406.0, 1.0, 1.0, 1.0, 3406.0, 3406.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.648, 0.0, 0.0, 0.0, -5.776, -5.736, 0.0, 0.0, 0.0]}
{"step": 3406, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3407.0, 1.0, 1.0, 1.0, 3407.0, 3407.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.647, 0.0, 0.0, 0.0, -5.774, -5.734, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10911, "number_of_timesteps": 152972, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3407, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3408.0, 1.0, 1.0, 1.0, 3408.0, 3408.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.773, -5.732, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10917, "number_of_timesteps": 153032, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3408, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3409.0, 1.0, 1.0, 1.0, 3409.0, 3409.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.644, 0.0, 0.0, 0.0, -5.774, -5.734, 0.0, 0.0, 0.0]}
{"eval_score": 9.0, "number_of_episodes": 10921}
{"number_of_episodes": 10921, "number_of_timesteps": 153071, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3409, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3410.0, 1.0, 1.0, 1.0, 3410.0, 3410.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.775, -5.735, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10927, "number_of_timesteps": 153128, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3410, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3411.0, 1.0, 1.0, 1.0, 3411.0, 3411.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.773, -5.733, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10931, "number_of_timesteps": 153165, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3411, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3412.0, 1.0, 1.0, 1.0, 3412.0, 3412.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.777, -5.737, 0.0, 0.0, 0.0]}
{"step": 3412, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3413.0, 1.0, 1.0, 1.0, 3413.0, 3413.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.776, -5.735, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10941, "number_of_timesteps": 153257, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3413, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3414.0, 1.0, 1.0, 1.0, 3414.0, 3414.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.64, 0.0, 0.0, 0.0, -5.774, -5.734, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10946, "number_of_timesteps": 153303, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3414, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3415.0, 1.0, 1.0, 1.0, 3415.0, 3415.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.639, 0.0, 0.0, 0.0, -5.773, -5.733, 0.0, 0.0, 0.0]}
{"step": 3415, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3416.0, 1.0, 1.0, 1.0, 3416.0, 3416.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.64, 0.0, 0.0, 0.0, -5.774, -5.733, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10955, "number_of_timesteps": 153389, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3416, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3417.0, 1.0, 1.0, 1.0, 3417.0, 3417.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.64, 0.0, 0.0, 0.0, -5.773, -5.733, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10960, "number_of_timesteps": 153439, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3417, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3418.0, 1.0, 1.0, 1.0, 3418.0, 3418.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.638, 0.0, 0.0, 0.0, -5.78, -5.739, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10965, "number_of_timesteps": 153484, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3418, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3419.0, 1.0, 1.0, 1.0, 3419.0, 3419.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.784, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10968, "number_of_timesteps": 153512, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3419, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3420.0, 1.0, 1.0, 1.0, 3420.0, 3420.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.783, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10974, "number_of_timesteps": 153573, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3420, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3421.0, 1.0, 1.0, 1.0, 3421.0, 3421.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.783, -5.742, 0.0, 0.0, 0.0]}
{"step": 3421, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3422.0, 1.0, 1.0, 1.0, 3422.0, 3422.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.783, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10983, "number_of_timesteps": 153659, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3422, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3423.0, 1.0, 1.0, 1.0, 3423.0, 3423.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.644, 0.0, 0.0, 0.0, -5.781, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10988, "number_of_timesteps": 153708, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3423, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3424.0, 1.0, 1.0, 1.0, 3424.0, 3424.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.782, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10993, "number_of_timesteps": 153755, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3424, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3425.0, 1.0, 1.0, 1.0, 3425.0, 3425.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.782, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 10998, "number_of_timesteps": 153803, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3425, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3426.0, 1.0, 1.0, 1.0, 3426.0, 3426.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.781, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11003, "number_of_timesteps": 153848, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3426, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3427.0, 1.0, 1.0, 1.0, 3427.0, 3427.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.781, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11007, "number_of_timesteps": 153884, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3427, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3428.0, 1.0, 1.0, 1.0, 3428.0, 3428.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.644, 0.0, 0.0, 0.0, -5.779, -5.741, 0.0, 0.0, 0.0]}
{"step": 3428, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3429.0, 1.0, 1.0, 1.0, 3429.0, 3429.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.777, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11016, "number_of_timesteps": 153969, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3429, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3430.0, 1.0, 1.0, 1.0, 3430.0, 3430.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.644, 0.0, 0.0, 0.0, -5.779, -5.743, 0.0, 0.0, 0.0]}
{"step": 3430, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3431.0, 1.0, 1.0, 1.0, 3431.0, 3431.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.783, -5.747, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11026, "number_of_timesteps": 154068, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3431, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3432.0, 1.0, 1.0, 1.0, 3432.0, 3432.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.783, -5.747, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11032, "number_of_timesteps": 154121, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3432, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3433.0, 1.0, 1.0, 1.0, 3433.0, 3433.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.784, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11035, "number_of_timesteps": 154149, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3433, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3434.0, 1.0, 1.0, 1.0, 3434.0, 3434.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.782, -5.744, 0.0, 0.0, 0.0]}
{"step": 3434, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3435.0, 1.0, 1.0, 1.0, 3435.0, 3435.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.639, 0.0, 0.0, 0.0, -5.78, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11044, "number_of_timesteps": 154236, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3435, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3436.0, 1.0, 1.0, 1.0, 3436.0, 3436.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.639, 0.0, 0.0, 0.0, -5.779, -5.742, 0.0, 0.0, 0.0]}
{"eval_score": 9.2, "number_of_episodes": 11052}
{"step": 3436, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3437.0, 1.0, 1.0, 1.0, 3437.0, 3437.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.64, 0.0, 0.0, 0.0, -5.777, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11053, "number_of_timesteps": 154321, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3437, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3438.0, 1.0, 1.0, 1.0, 3438.0, 3438.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.778, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11060, "number_of_timesteps": 154388, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3438, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3439.0, 1.0, 1.0, 1.0, 3439.0, 3439.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.778, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11063, "number_of_timesteps": 154420, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3439, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3440.0, 1.0, 1.0, 1.0, 3440.0, 3440.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.777, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11070, "number_of_timesteps": 154485, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3440, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3441.0, 1.0, 1.0, 1.0, 3441.0, 3441.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.64, 0.0, 0.0, 0.0, -5.775, -5.741, 0.0, 0.0, 0.0]}
{"step": 3441, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3442.0, 1.0, 1.0, 1.0, 3442.0, 3442.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.776, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11077, "number_of_timesteps": 154549, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3442, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3443.0, 1.0, 1.0, 1.0, 3443.0, 3443.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.777, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11082, "number_of_timesteps": 154603, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3443, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3444.0, 1.0, 1.0, 1.0, 3444.0, 3444.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.775, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11087, "number_of_timesteps": 154651, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3444, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3445.0, 1.0, 1.0, 1.0, 3445.0, 3445.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.773, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11090, "number_of_timesteps": 154679, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3445, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3446.0, 1.0, 1.0, 1.0, 3446.0, 3446.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.64, 0.0, 0.0, 0.0, -5.772, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11095, "number_of_timesteps": 154728, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3446, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3447.0, 1.0, 1.0, 1.0, 3447.0, 3447.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.639, 0.0, 0.0, 0.0, -5.77, -5.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11100, "number_of_timesteps": 154778, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3447, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3448.0, 1.0, 1.0, 1.0, 3448.0, 3448.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.64, 0.0, 0.0, 0.0, -5.771, -5.739, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11104, "number_of_timesteps": 154813, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3448, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3449.0, 1.0, 1.0, 1.0, 3449.0, 3449.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.638, 0.0, 0.0, 0.0, -5.769, -5.737, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11110, "number_of_timesteps": 154873, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3449, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3450.0, 1.0, 1.0, 1.0, 3450.0, 3450.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.639, 0.0, 0.0, 0.0, -5.77, -5.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11114, "number_of_timesteps": 154912, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3450, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3451.0, 1.0, 1.0, 1.0, 3451.0, 3451.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.768, -5.739, 0.0, 0.0, 0.0]}
{"step": 3451, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3452.0, 1.0, 1.0, 1.0, 3452.0, 3452.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.769, -5.739, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11124, "number_of_timesteps": 155009, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3452, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3453.0, 1.0, 1.0, 1.0, 3453.0, 3453.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.77, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11128, "number_of_timesteps": 155047, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3453, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3454.0, 1.0, 1.0, 1.0, 3454.0, 3454.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.644, 0.0, 0.0, 0.0, -5.771, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11133, "number_of_timesteps": 155094, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3454, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3455.0, 1.0, 1.0, 1.0, 3455.0, 3455.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.769, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11137, "number_of_timesteps": 155134, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3455, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3456.0, 1.0, 1.0, 1.0, 3456.0, 3456.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.774, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11143, "number_of_timesteps": 155193, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3456, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3457.0, 1.0, 1.0, 1.0, 3457.0, 3457.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.773, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11146, "number_of_timesteps": 155223, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3457, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3458.0, 1.0, 1.0, 1.0, 3458.0, 3458.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.64, 0.0, 0.0, 0.0, -5.771, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11153, "number_of_timesteps": 155289, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3458, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3459.0, 1.0, 1.0, 1.0, 3459.0, 3459.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.772, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11156, "number_of_timesteps": 155316, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3459, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3460.0, 1.0, 1.0, 1.0, 3460.0, 3460.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.773, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11162, "number_of_timesteps": 155371, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3460, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3461.0, 1.0, 1.0, 1.0, 3461.0, 3461.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.772, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11166, "number_of_timesteps": 155410, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3461, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3462.0, 1.0, 1.0, 1.0, 3462.0, 3462.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.772, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11172, "number_of_timesteps": 155467, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3462, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3463.0, 1.0, 1.0, 1.0, 3463.0, 3463.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.771, -5.739, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11175, "number_of_timesteps": 155494, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3463, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3464.0, 1.0, 1.0, 1.0, 3464.0, 3464.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.639, 0.0, 0.0, 0.0, -5.771, -5.739, 0.0, 0.0, 0.0]}
{"eval_score": 9.2, "number_of_episodes": 11182}
{"number_of_episodes": 11182, "number_of_timesteps": 155557, "per_episode_reward": 10.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3464, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3465.0, 1.0, 1.0, 1.0, 3465.0, 3465.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.638, 0.0, 0.0, 0.0, -5.769, -5.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11185, "number_of_timesteps": 155585, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3465, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3466.0, 1.0, 1.0, 1.0, 3466.0, 3466.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.638, 0.0, 0.0, 0.0, -5.768, -5.737, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11192, "number_of_timesteps": 155651, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3466, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3467.0, 1.0, 1.0, 1.0, 3467.0, 3467.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.638, 0.0, 0.0, 0.0, -5.767, -5.737, 0.0, 0.0, 0.0]}
{"step": 3467, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3468.0, 1.0, 1.0, 1.0, 3468.0, 3468.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.639, 0.0, 0.0, 0.0, -5.768, -5.738, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11201, "number_of_timesteps": 155732, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3468, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3469.0, 1.0, 1.0, 1.0, 3469.0, 3469.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.638, 0.0, 0.0, 0.0, -5.766, -5.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11205, "number_of_timesteps": 155771, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3469, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3470.0, 1.0, 1.0, 1.0, 3470.0, 3470.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.639, 0.0, 0.0, 0.0, -5.767, -5.737, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11211, "number_of_timesteps": 155829, "per_episode_reward": 10.85, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 3470, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3471.0, 1.0, 1.0, 1.0, 3471.0, 3471.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.639, 0.0, 0.0, 0.0, -5.765, -5.737, 0.0, 0.0, 0.0]}
{"step": 3471, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3472.0, 1.0, 1.0, 1.0, 3472.0, 3472.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.639, 0.0, 0.0, 0.0, -5.763, -5.737, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11220, "number_of_timesteps": 155916, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3472, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3473.0, 1.0, 1.0, 1.0, 3473.0, 3473.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.64, 0.0, 0.0, 0.0, -5.764, -5.735, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11225, "number_of_timesteps": 155963, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3473, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3474.0, 1.0, 1.0, 1.0, 3474.0, 3474.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.765, -5.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11229, "number_of_timesteps": 156002, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3474, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3475.0, 1.0, 1.0, 1.0, 3475.0, 3475.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.64, 0.0, 0.0, 0.0, -5.763, -5.735, 0.0, 0.0, 0.0]}
{"step": 3475, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3476.0, 1.0, 1.0, 1.0, 3476.0, 3476.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.764, -5.735, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11239, "number_of_timesteps": 156097, "per_episode_reward": 10.85, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
{"step": 3476, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3477.0, 1.0, 1.0, 1.0, 3477.0, 3477.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.764, -5.733, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11244, "number_of_timesteps": 156146, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3477, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3478.0, 1.0, 1.0, 1.0, 3478.0, 3478.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.765, -5.734, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11248, "number_of_timesteps": 156183, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3478, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3479.0, 1.0, 1.0, 1.0, 3479.0, 3479.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.763, -5.732, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11253, "number_of_timesteps": 156234, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3479, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3480.0, 1.0, 1.0, 1.0, 3480.0, 3480.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.646, 0.0, 0.0, 0.0, -5.767, -5.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11257, "number_of_timesteps": 156271, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3480, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3481.0, 1.0, 1.0, 1.0, 3481.0, 3481.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.766, -5.735, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11263, "number_of_timesteps": 156328, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3481, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3482.0, 1.0, 1.0, 1.0, 3482.0, 3482.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.766, -5.735, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11267, "number_of_timesteps": 156366, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3482, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3483.0, 1.0, 1.0, 1.0, 3483.0, 3483.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.644, 0.0, 0.0, 0.0, -5.764, -5.733, 0.0, 0.0, 0.0]}
{"step": 3483, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3484.0, 1.0, 1.0, 1.0, 3484.0, 3484.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.643, 0.0, 0.0, 0.0, -5.763, -5.732, 0.0, 0.0, 0.0]}
{"step": 3484, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3485.0, 1.0, 1.0, 1.0, 3485.0, 3485.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.641, 0.0, 0.0, 0.0, -5.761, -5.73, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11282, "number_of_timesteps": 156509, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3485, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3486.0, 1.0, 1.0, 1.0, 3486.0, 3486.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.642, 0.0, 0.0, 0.0, -5.762, -5.731, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11285, "number_of_timesteps": 156537, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3486, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3487.0, 1.0, 1.0, 1.0, 3487.0, 3487.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.646, 0.0, 0.0, 0.0, -5.765, -5.735, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11290, "number_of_timesteps": 156587, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3487, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3488.0, 1.0, 1.0, 1.0, 3488.0, 3488.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.648, 0.0, 0.0, 0.0, -5.767, -5.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11294, "number_of_timesteps": 156629, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3488, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3489.0, 1.0, 1.0, 1.0, 3489.0, 3489.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.648, 0.0, 0.0, 0.0, -5.767, -5.736, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11299, "number_of_timesteps": 156679, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3489, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3490.0, 1.0, 1.0, 1.0, 3490.0, 3490.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.649, 0.0, 0.0, 0.0, -5.767, -5.736, 0.0, 0.0, 0.0]}
{"step": 3490, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3491.0, 1.0, 1.0, 1.0, 3491.0, 3491.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.648, 0.0, 0.0, 0.0, -5.766, -5.735, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11309, "number_of_timesteps": 156778, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3491, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3492.0, 1.0, 1.0, 1.0, 3492.0, 3492.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.649, 0.0, 0.0, 0.0, -5.764, -5.736, 0.0, 0.0, 0.0]}
{"eval_score": 9.1, "number_of_episodes": 11313}
{"number_of_episodes": 11313, "number_of_timesteps": 156816, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3492, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3493.0, 1.0, 1.0, 1.0, 3493.0, 3493.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.648, 0.0, 0.0, 0.0, -5.763, -5.734, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11319, "number_of_timesteps": 156871, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3493, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3494.0, 1.0, 1.0, 1.0, 3494.0, 3494.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.646, 0.0, 0.0, 0.0, -5.767, -5.738, 0.0, 0.0, 0.0]}
{"step": 3494, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3495.0, 1.0, 1.0, 1.0, 3495.0, 3495.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.645, 0.0, 0.0, 0.0, -5.768, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11329, "number_of_timesteps": 156967, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3495, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3496.0, 1.0, 1.0, 1.0, 3496.0, 3496.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.646, 0.0, 0.0, 0.0, -5.769, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11333, "number_of_timesteps": 157003, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3496, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3497.0, 1.0, 1.0, 1.0, 3497.0, 3497.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.65, 0.0, 0.0, 0.0, -5.773, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11339, "number_of_timesteps": 157060, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3497, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3498.0, 1.0, 1.0, 1.0, 3498.0, 3498.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.651, 0.0, 0.0, 0.0, -5.773, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11341, "number_of_timesteps": 157078, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3498, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3499.0, 1.0, 1.0, 1.0, 3499.0, 3499.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.65, 0.0, 0.0, 0.0, -5.772, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11347, "number_of_timesteps": 157137, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3499, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3500.0, 1.0, 1.0, 1.0, 3500.0, 3500.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.651, 0.0, 0.0, 0.0, -5.77, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11351, "number_of_timesteps": 157176, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3500, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3501.0, 1.0, 1.0, 1.0, 3501.0, 3501.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.651, 0.0, 0.0, 0.0, -5.769, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11357, "number_of_timesteps": 157233, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3501, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3502.0, 1.0, 1.0, 1.0, 3502.0, 3502.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.65, 0.0, 0.0, 0.0, -5.769, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11360, "number_of_timesteps": 157259, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3502, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3503.0, 1.0, 1.0, 1.0, 3503.0, 3503.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.649, 0.0, 0.0, 0.0, -5.767, -5.739, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11365, "number_of_timesteps": 157309, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3503, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3504.0, 1.0, 1.0, 1.0, 3504.0, 3504.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.65, 0.0, 0.0, 0.0, -5.768, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11370, "number_of_timesteps": 157360, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3504, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3505.0, 1.0, 1.0, 1.0, 3505.0, 3505.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.651, 0.0, 0.0, 0.0, -5.768, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11375, "number_of_timesteps": 157407, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3505, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3506.0, 1.0, 1.0, 1.0, 3506.0, 3506.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.651, 0.0, 0.0, 0.0, -5.768, -5.74, 0.0, 0.0, 0.0]}
{"step": 3506, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3507.0, 1.0, 1.0, 1.0, 3507.0, 3507.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.652, 0.0, 0.0, 0.0, -5.769, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11385, "number_of_timesteps": 157501, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3507, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3508.0, 1.0, 1.0, 1.0, 3508.0, 3508.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.653, 0.0, 0.0, 0.0, -5.767, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11389, "number_of_timesteps": 157538, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3508, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3509.0, 1.0, 1.0, 1.0, 3509.0, 3509.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.653, 0.0, 0.0, 0.0, -5.767, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11395, "number_of_timesteps": 157595, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3509, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3510.0, 1.0, 1.0, 1.0, 3510.0, 3510.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.654, 0.0, 0.0, 0.0, -5.768, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11399, "number_of_timesteps": 157632, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3510, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3511.0, 1.0, 1.0, 1.0, 3511.0, 3511.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.655, 0.0, 0.0, 0.0, -5.768, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11405, "number_of_timesteps": 157689, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3511, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3512.0, 1.0, 1.0, 1.0, 3512.0, 3512.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.659, 0.0, 0.0, 0.0, -5.772, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11407, "number_of_timesteps": 157708, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3512, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3513.0, 1.0, 1.0, 1.0, 3513.0, 3513.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.66, 0.0, 0.0, 0.0, -5.773, -5.745, 0.0, 0.0, 0.0]}
{"step": 3513, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3514.0, 1.0, 1.0, 1.0, 3514.0, 3514.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.664, 0.0, 0.0, 0.0, -5.777, -5.749, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11417, "number_of_timesteps": 157807, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3514, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3515.0, 1.0, 1.0, 1.0, 3515.0, 3515.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.664, 0.0, 0.0, 0.0, -5.776, -5.748, 0.0, 0.0, 0.0]}
{"step": 3515, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3516.0, 1.0, 1.0, 1.0, 3516.0, 3516.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.665, 0.0, 0.0, 0.0, -5.777, -5.748, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11427, "number_of_timesteps": 157899, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3516, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3517.0, 1.0, 1.0, 1.0, 3517.0, 3517.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.663, 0.0, 0.0, 0.0, -5.775, -5.747, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11432, "number_of_timesteps": 157945, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3517, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3518.0, 1.0, 1.0, 1.0, 3518.0, 3518.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.668, 0.0, 0.0, 0.0, -5.779, -5.751, 0.0, 0.0, 0.0]}
{"step": 3518, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3519.0, 1.0, 1.0, 1.0, 3519.0, 3519.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.672, 0.0, 0.0, 0.0, -5.783, -5.755, 0.0, 0.0, 0.0]}
{"eval_score": 9.2, "number_of_episodes": 11441}
{"number_of_episodes": 11441, "number_of_timesteps": 158031, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3519, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3520.0, 1.0, 1.0, 1.0, 3520.0, 3520.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.671, 0.0, 0.0, 0.0, -5.782, -5.753, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11447, "number_of_timesteps": 158088, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3520, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3521.0, 1.0, 1.0, 1.0, 3521.0, 3521.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.67, 0.0, 0.0, 0.0, -5.783, -5.755, 0.0, 0.0, 0.0]}
{"step": 3521, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3522.0, 1.0, 1.0, 1.0, 3522.0, 3522.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.668, 0.0, 0.0, 0.0, -5.782, -5.754, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11457, "number_of_timesteps": 158186, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3522, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3523.0, 1.0, 1.0, 1.0, 3523.0, 3523.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.667, 0.0, 0.0, 0.0, -5.78, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11460, "number_of_timesteps": 158214, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3523, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3524.0, 1.0, 1.0, 1.0, 3524.0, 3524.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.668, 0.0, 0.0, 0.0, -5.78, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11467, "number_of_timesteps": 158279, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3524, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3525.0, 1.0, 1.0, 1.0, 3525.0, 3525.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.666, 0.0, 0.0, 0.0, -5.781, -5.753, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11470, "number_of_timesteps": 158308, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3525, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3526.0, 1.0, 1.0, 1.0, 3526.0, 3526.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.667, 0.0, 0.0, 0.0, -5.781, -5.753, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11477, "number_of_timesteps": 158374, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3526, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3527.0, 1.0, 1.0, 1.0, 3527.0, 3527.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.668, 0.0, 0.0, 0.0, -5.779, -5.754, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11479, "number_of_timesteps": 158394, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3527, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3528.0, 1.0, 1.0, 1.0, 3528.0, 3528.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.667, 0.0, 0.0, 0.0, -5.779, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11487, "number_of_timesteps": 158472, "per_episode_reward": 10.8, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3528, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3529.0, 1.0, 1.0, 1.0, 3529.0, 3529.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.668, 0.0, 0.0, 0.0, -5.777, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11489, "number_of_timesteps": 158491, "per_episode_reward": 10.75, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 3529, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3530.0, 1.0, 1.0, 1.0, 3530.0, 3530.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.667, 0.0, 0.0, 0.0, -5.775, -5.751, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11496, "number_of_timesteps": 158555, "per_episode_reward": 10.75, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"step": 3530, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3531.0, 1.0, 1.0, 1.0, 3531.0, 3531.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.665, 0.0, 0.0, 0.0, -5.774, -5.749, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11499, "number_of_timesteps": 158585, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3531, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3532.0, 1.0, 1.0, 1.0, 3532.0, 3532.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.67, 0.0, 0.0, 0.0, -5.778, -5.753, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11503, "number_of_timesteps": 158623, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3532, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3533.0, 1.0, 1.0, 1.0, 3533.0, 3533.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.671, 0.0, 0.0, 0.0, -5.778, -5.754, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11508, "number_of_timesteps": 158677, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3533, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3534.0, 1.0, 1.0, 1.0, 3534.0, 3534.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.669, 0.0, 0.0, 0.0, -5.777, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11512, "number_of_timesteps": 158716, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3534, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3535.0, 1.0, 1.0, 1.0, 3535.0, 3535.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.67, 0.0, 0.0, 0.0, -5.777, -5.753, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11517, "number_of_timesteps": 158764, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3535, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3536.0, 1.0, 1.0, 1.0, 3536.0, 3536.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.671, 0.0, 0.0, 0.0, -5.778, -5.751, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11522, "number_of_timesteps": 158811, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3536, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3537.0, 1.0, 1.0, 1.0, 3537.0, 3537.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.67, 0.0, 0.0, 0.0, -5.781, -5.755, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11526, "number_of_timesteps": 158847, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 3537, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3538.0, 1.0, 1.0, 1.0, 3538.0, 3538.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.674, 0.0, 0.0, 0.0, -5.786, -5.759, 0.0, 0.0, 0.0]}
{"step": 3538, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3539.0, 1.0, 1.0, 1.0, 3539.0, 3539.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.678, 0.0, 0.0, 0.0, -5.789, -5.762, 0.0, 0.0, 0.0]}
{"step": 3539, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3540.0, 1.0, 1.0, 1.0, 3540.0, 3540.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.677, 0.0, 0.0, 0.0, -5.787, -5.76, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11541, "number_of_timesteps": 158988, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3540, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3541.0, 1.0, 1.0, 1.0, 3541.0, 3541.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.677, 0.0, 0.0, 0.0, -5.787, -5.759, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11544, "number_of_timesteps": 159020, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3541, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3542.0, 1.0, 1.0, 1.0, 3542.0, 3542.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.678, 0.0, 0.0, 0.0, -5.786, -5.759, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11550, "number_of_timesteps": 159072, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 3542, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3543.0, 1.0, 1.0, 1.0, 3543.0, 3543.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.789, -5.763, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11554, "number_of_timesteps": 159112, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"step": 3543, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3544.0, 1.0, 1.0, 1.0, 3544.0, 3544.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.789, -5.763, 0.0, 0.0, 0.0]}
{"step": 3544, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3545.0, 1.0, 1.0, 1.0, 3545.0, 3545.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.79, -5.763, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11564, "number_of_timesteps": 159206, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3545, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3546.0, 1.0, 1.0, 1.0, 3546.0, 3546.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.79, -5.764, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11569, "number_of_timesteps": 159253, "per_episode_reward": 10.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3546, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3547.0, 1.0, 1.0, 1.0, 3547.0, 3547.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.789, -5.764, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 11573}
{"number_of_episodes": 11573, "number_of_timesteps": 159293, "per_episode_reward": 10.65, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 3547, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3548.0, 1.0, 1.0, 1.0, 3548.0, 3548.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.787, -5.763, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11579, "number_of_timesteps": 159350, "per_episode_reward": 10.65, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"step": 3548, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3549.0, 1.0, 1.0, 1.0, 3549.0, 3549.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.79, -5.766, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11581, "number_of_timesteps": 159369, "per_episode_reward": 10.65, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 3549, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3550.0, 1.0, 1.0, 1.0, 3550.0, 3550.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.789, -5.765, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11588, "number_of_timesteps": 159441, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 3550, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3551.0, 1.0, 1.0, 1.0, 3551.0, 3551.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.787, -5.763, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11591, "number_of_timesteps": 159471, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3551, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3552.0, 1.0, 1.0, 1.0, 3552.0, 3552.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.786, -5.762, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11598, "number_of_timesteps": 159536, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 3552, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3553.0, 1.0, 1.0, 1.0, 3553.0, 3553.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.784, -5.76, 0.0, 0.0, 0.0]}
{"step": 3553, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3554.0, 1.0, 1.0, 1.0, 3554.0, 3554.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.783, -5.759, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11608, "number_of_timesteps": 159629, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3554, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3555.0, 1.0, 1.0, 1.0, 3555.0, 3555.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.783, -5.759, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11611, "number_of_timesteps": 159657, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 3555, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3556.0, 1.0, 1.0, 1.0, 3556.0, 3556.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.68, 0.0, 0.0, 0.0, -5.782, -5.757, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11617, "number_of_timesteps": 159712, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 3556, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3557.0, 1.0, 1.0, 1.0, 3557.0, 3557.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.679, 0.0, 0.0, 0.0, -5.78, -5.756, 0.0, 0.0, 0.0]}
{"step": 3557, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3558.0, 1.0, 1.0, 1.0, 3558.0, 3558.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.678, 0.0, 0.0, 0.0, -5.778, -5.754, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11627, "number_of_timesteps": 159806, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 3558, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3559.0, 1.0, 1.0, 1.0, 3559.0, 3559.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.677, 0.0, 0.0, 0.0, -5.777, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11631, "number_of_timesteps": 159844, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3559, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3560.0, 1.0, 1.0, 1.0, 3560.0, 3560.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.676, 0.0, 0.0, 0.0, -5.776, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11637, "number_of_timesteps": 159899, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 3560, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3561.0, 1.0, 1.0, 1.0, 3561.0, 3561.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.676, 0.0, 0.0, 0.0, -5.775, -5.75, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11639, "number_of_timesteps": 159919, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3561, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3562.0, 1.0, 1.0, 1.0, 3562.0, 3562.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.677, 0.0, 0.0, 0.0, -5.776, -5.751, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11646, "number_of_timesteps": 159989, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3562, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3563.0, 1.0, 1.0, 1.0, 3563.0, 3563.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.78, -5.754, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11649, "number_of_timesteps": 160017, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3563, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3564.0, 1.0, 1.0, 1.0, 3564.0, 3564.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.78, -5.755, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11656, "number_of_timesteps": 160081, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 3564, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3565.0, 1.0, 1.0, 1.0, 3565.0, 3565.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.68, 0.0, 0.0, 0.0, -5.779, -5.753, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11659, "number_of_timesteps": 160110, "per_episode_reward": 10.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 3565, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3566.0, 1.0, 1.0, 1.0, 3566.0, 3566.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.779, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11666, "number_of_timesteps": 160177, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 3566, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3567.0, 1.0, 1.0, 1.0, 3567.0, 3567.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.783, -5.755, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11668, "number_of_timesteps": 160196, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 3567, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3568.0, 1.0, 1.0, 1.0, 3568.0, 3568.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.781, -5.754, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11674, "number_of_timesteps": 160253, "per_episode_reward": 10.45, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
{"step": 3568, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3569.0, 1.0, 1.0, 1.0, 3569.0, 3569.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.78, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11678, "number_of_timesteps": 160296, "per_episode_reward": 10.5, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 3569, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3570.0, 1.0, 1.0, 1.0, 3570.0, 3570.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.778, -5.75, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11684, "number_of_timesteps": 160350, "per_episode_reward": 10.45, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 3570, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3571.0, 1.0, 1.0, 1.0, 3571.0, 3571.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.776, -5.751, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11688, "number_of_timesteps": 160388, "per_episode_reward": 10.4, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 3571, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3572.0, 1.0, 1.0, 1.0, 3572.0, 3572.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.777, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11694, "number_of_timesteps": 160446, "per_episode_reward": 10.35, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.25},
{"step": 3572, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3573.0, 1.0, 1.0, 1.0, 3573.0, 3573.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.777, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11696, "number_of_timesteps": 160464, "per_episode_reward": 10.35, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
{"step": 3573, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3574.0, 1.0, 1.0, 1.0, 3574.0, 3574.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.777, -5.752, 0.0, 0.0, 0.0]}
{"eval_score": 9.8, "number_of_episodes": 11704}
{"number_of_episodes": 11704, "number_of_timesteps": 160542, "per_episode_reward": 10.4, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"step": 3574, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3575.0, 1.0, 1.0, 1.0, 3575.0, 3575.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.775, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11706, "number_of_timesteps": 160561, "per_episode_reward": 10.4, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.1999999999999993},
{"step": 3575, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3576.0, 1.0, 1.0, 1.0, 3576.0, 3576.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.776, -5.75, 0.0, 0.0, 0.0]}
{"step": 3576, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3577.0, 1.0, 1.0, 1.0, 3577.0, 3577.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.777, -5.749, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11715, "number_of_timesteps": 160649, "per_episode_reward": 10.35, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.25},
{"step": 3577, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3578.0, 1.0, 1.0, 1.0, 3578.0, 3578.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.777, -5.749, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11720, "number_of_timesteps": 160698, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 3578, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3579.0, 1.0, 1.0, 1.0, 3579.0, 3579.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.775, -5.748, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11725, "number_of_timesteps": 160750, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"step": 3579, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3580.0, 1.0, 1.0, 1.0, 3580.0, 3580.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.776, -5.748, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11729, "number_of_timesteps": 160787, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 3580, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3581.0, 1.0, 1.0, 1.0, 3581.0, 3581.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.774, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11735, "number_of_timesteps": 160846, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 3581, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3582.0, 1.0, 1.0, 1.0, 3582.0, 3582.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.775, -5.747, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11737, "number_of_timesteps": 160864, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 3582, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3583.0, 1.0, 1.0, 1.0, 3583.0, 3583.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.689, 0.0, 0.0, 0.0, -5.778, -5.75, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11745, "number_of_timesteps": 160939, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.3999999999999986},
{"step": 3583, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3584.0, 1.0, 1.0, 1.0, 3584.0, 3584.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.779, -5.751, 0.0, 0.0, 0.0]}
{"step": 3584, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3585.0, 1.0, 1.0, 1.0, 3585.0, 3585.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.778, -5.751, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11755, "number_of_timesteps": 161035, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.15000000000000036},
{"step": 3585, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3586.0, 1.0, 1.0, 1.0, 3586.0, 3586.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.78, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11757, "number_of_timesteps": 161055, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 3586, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3587.0, 1.0, 1.0, 1.0, 3587.0, 3587.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.779, -5.751, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11764, "number_of_timesteps": 161121, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3587, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3588.0, 1.0, 1.0, 1.0, 3588.0, 3588.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.779, -5.751, 0.0, 0.0, 0.0]}
{"step": 3588, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3589.0, 1.0, 1.0, 1.0, 3589.0, 3589.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.779, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11773, "number_of_timesteps": 161208, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.1999999999999993},
{"step": 3589, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3590.0, 1.0, 1.0, 1.0, 3590.0, 3590.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.78, -5.75, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11776, "number_of_timesteps": 161237, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3590, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3591.0, 1.0, 1.0, 1.0, 3591.0, 3591.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.78, -5.751, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11782, "number_of_timesteps": 161292, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 3591, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3592.0, 1.0, 1.0, 1.0, 3592.0, 3592.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.779, -5.749, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11785, "number_of_timesteps": 161323, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3592, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3593.0, 1.0, 1.0, 1.0, 3593.0, 3593.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.779, -5.748, 0.0, 0.0, 0.0]}
{"step": 3593, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3594.0, 1.0, 1.0, 1.0, 3594.0, 3594.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.778, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11795, "number_of_timesteps": 161421, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3594, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3595.0, 1.0, 1.0, 1.0, 3595.0, 3595.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.778, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11801, "number_of_timesteps": 161478, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 3595, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3596.0, 1.0, 1.0, 1.0, 3596.0, 3596.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.777, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11804, "number_of_timesteps": 161506, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 3596, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3597.0, 1.0, 1.0, 1.0, 3597.0, 3597.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.775, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11808, "number_of_timesteps": 161544, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.15000000000000036},
{"step": 3597, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3598.0, 1.0, 1.0, 1.0, 3598.0, 3598.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.779, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11814, "number_of_timesteps": 161608, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3598, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3599.0, 1.0, 1.0, 1.0, 3599.0, 3599.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.777, -5.745, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11817, "number_of_timesteps": 161638, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 3599, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3600.0, 1.0, 1.0, 1.0, 3600.0, 3600.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.775, -5.745, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11822, "number_of_timesteps": 161686, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 3600, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3601.0, 1.0, 1.0, 1.0, 3601.0, 3601.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.774, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11827, "number_of_timesteps": 161734, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3601, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3602.0, 1.0, 1.0, 1.0, 3602.0, 3602.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.774, -5.742, 0.0, 0.0, 0.0]}
{"eval_score": 9.9, "number_of_episodes": 11832}
{"number_of_episodes": 11832, "number_of_timesteps": 161779, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.3999999999999986},
{"step": 3602, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3603.0, 1.0, 1.0, 1.0, 3603.0, 3603.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.778, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11837, "number_of_timesteps": 161825, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 3603, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3604.0, 1.0, 1.0, 1.0, 3604.0, 3604.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.778, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11842, "number_of_timesteps": 161874, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.3999999999999986},
{"step": 3604, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3605.0, 1.0, 1.0, 1.0, 3605.0, 3605.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.782, -5.75, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11847, "number_of_timesteps": 161923, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3605, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3606.0, 1.0, 1.0, 1.0, 3606.0, 3606.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.783, -5.748, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11852, "number_of_timesteps": 161969, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"step": 3606, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3607.0, 1.0, 1.0, 1.0, 3607.0, 3607.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.783, -5.749, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11856, "number_of_timesteps": 162008, "per_episode_reward": 10.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 3607, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3608.0, 1.0, 1.0, 1.0, 3608.0, 3608.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.784, -5.749, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11862, "number_of_timesteps": 162067, "per_episode_reward": 10.25, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.15000000000000036},
{"step": 3608, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3609.0, 1.0, 1.0, 1.0, 3609.0, 3609.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.782, -5.748, 0.0, 0.0, 0.0]}
{"step": 3609, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3610.0, 1.0, 1.0, 1.0, 3610.0, 3610.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.781, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11872, "number_of_timesteps": 162158, "per_episode_reward": 10.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3610, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3611.0, 1.0, 1.0, 1.0, 3611.0, 3611.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.781, -5.747, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11874, "number_of_timesteps": 162177, "per_episode_reward": 10.2, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.25},
{"step": 3611, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3612.0, 1.0, 1.0, 1.0, 3612.0, 3612.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.781, -5.747, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11882, "number_of_timesteps": 162257, "per_episode_reward": 10.15, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.1999999999999993},
{"step": 3612, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3613.0, 1.0, 1.0, 1.0, 3613.0, 3613.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.782, -5.746, 0.0, 0.0, 0.0]}
{"step": 3613, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3614.0, 1.0, 1.0, 1.0, 3614.0, 3614.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.783, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11890, "number_of_timesteps": 162331, "per_episode_reward": 10.15, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.3999999999999986},
{"step": 3614, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3615.0, 1.0, 1.0, 1.0, 3615.0, 3615.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.786, -5.748, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11894, "number_of_timesteps": 162373, "per_episode_reward": 10.2, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.15000000000000036},
{"step": 3615, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3616.0, 1.0, 1.0, 1.0, 3616.0, 3616.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.785, -5.748, 0.0, 0.0, 0.0]}
{"step": 3616, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3617.0, 1.0, 1.0, 1.0, 3617.0, 3617.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.783, -5.748, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11904, "number_of_timesteps": 162468, "per_episode_reward": 10.15, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
{"step": 3617, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3618.0, 1.0, 1.0, 1.0, 3618.0, 3618.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.784, -5.748, 0.0, 0.0, 0.0]}
{"step": 3618, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3619.0, 1.0, 1.0, 1.0, 3619.0, 3619.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.783, -5.748, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11914, "number_of_timesteps": 162561, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3999999999999986},
{"step": 3619, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3620.0, 1.0, 1.0, 1.0, 3620.0, 3620.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.784, -5.748, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11919, "number_of_timesteps": 162608, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3999999999999986},
{"step": 3620, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3621.0, 1.0, 1.0, 1.0, 3621.0, 3621.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.787, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11923, "number_of_timesteps": 162647, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.20000000000000107},
{"step": 3621, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3622.0, 1.0, 1.0, 1.0, 3622.0, 3622.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.786, -5.75, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11928, "number_of_timesteps": 162694, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3999999999999986},
{"step": 3622, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3623.0, 1.0, 1.0, 1.0, 3623.0, 3623.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.786, -5.75, 0.0, 0.0, 0.0]}
{"step": 3623, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3624.0, 1.0, 1.0, 1.0, 3624.0, 3624.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.784, -5.749, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11938, "number_of_timesteps": 162788, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.1999999999999993},
{"step": 3624, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3625.0, 1.0, 1.0, 1.0, 3625.0, 3625.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.784, -5.749, 0.0, 0.0, 0.0]}
{"step": 3625, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3626.0, 1.0, 1.0, 1.0, 3626.0, 3626.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.784, -5.748, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11946, "number_of_timesteps": 162861, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.3999999999999986},
{"step": 3626, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3627.0, 1.0, 1.0, 1.0, 3627.0, 3627.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.787, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11952, "number_of_timesteps": 162922, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3627, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3628.0, 1.0, 1.0, 1.0, 3628.0, 3628.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.787, -5.752, 0.0, 0.0, 0.0]}
{"step": 3628, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3629.0, 1.0, 1.0, 1.0, 3629.0, 3629.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.787, -5.752, 0.0, 0.0, 0.0]}
{"eval_score": 9.4, "number_of_episodes": 11961}
{"number_of_episodes": 11961, "number_of_timesteps": 163005, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3999999999999986},
{"step": 3629, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3630.0, 1.0, 1.0, 1.0, 3630.0, 3630.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.788, -5.753, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11966, "number_of_timesteps": 163056, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3999999999999986},
{"step": 3630, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3631.0, 1.0, 1.0, 1.0, 3631.0, 3631.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.791, -5.756, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11971, "number_of_timesteps": 163104, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.15000000000000036},
{"step": 3631, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3632.0, 1.0, 1.0, 1.0, 3632.0, 3632.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.79, -5.756, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11974, "number_of_timesteps": 163133, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.1999999999999993},
{"step": 3632, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3633.0, 1.0, 1.0, 1.0, 3633.0, 3633.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.79, -5.755, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11980, "number_of_timesteps": 163192, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.20000000000000107},
{"step": 3633, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3634.0, 1.0, 1.0, 1.0, 3634.0, 3634.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.789, -5.753, 0.0, 0.0, 0.0]}
{"step": 3634, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3635.0, 1.0, 1.0, 1.0, 3635.0, 3635.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.787, -5.752, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11990, "number_of_timesteps": 163291, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3635, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3636.0, 1.0, 1.0, 1.0, 3636.0, 3636.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.787, -5.75, 0.0, 0.0, 0.0]}
{"number_of_episodes": 11992, "number_of_timesteps": 163310, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.20000000000000107},
{"step": 3636, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3637.0, 1.0, 1.0, 1.0, 3637.0, 3637.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.786, -5.749, 0.0, 0.0, 0.0]}
{"step": 3637, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3638.0, 1.0, 1.0, 1.0, 3638.0, 3638.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.784, -5.747, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12002, "number_of_timesteps": 163405, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 3638, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3639.0, 1.0, 1.0, 1.0, 3639.0, 3639.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.783, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12006, "number_of_timesteps": 163442, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.15000000000000036},
{"step": 3639, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3640.0, 1.0, 1.0, 1.0, 3640.0, 3640.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.782, -5.746, 0.0, 0.0, 0.0]}
{"step": 3640, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3641.0, 1.0, 1.0, 1.0, 3641.0, 3641.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.782, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12016, "number_of_timesteps": 163545, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3999999999999986},
{"step": 3641, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3642.0, 1.0, 1.0, 1.0, 3642.0, 3642.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.781, -5.745, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12020, "number_of_timesteps": 163583, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3999999999999986},
{"step": 3642, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3643.0, 1.0, 1.0, 1.0, 3643.0, 3643.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.781, -5.745, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12025, "number_of_timesteps": 163630, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.15000000000000036},
{"step": 3643, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3644.0, 1.0, 1.0, 1.0, 3644.0, 3644.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.78, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12030, "number_of_timesteps": 163677, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.20000000000000107},
{"step": 3644, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3645.0, 1.0, 1.0, 1.0, 3645.0, 3645.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.778, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12035, "number_of_timesteps": 163725, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3999999999999986},
{"step": 3645, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3646.0, 1.0, 1.0, 1.0, 3646.0, 3646.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.782, -5.746, 0.0, 0.0, 0.0]}
{"step": 3646, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3647.0, 1.0, 1.0, 1.0, 3647.0, 3647.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.78, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12044, "number_of_timesteps": 163812, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3647, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3648.0, 1.0, 1.0, 1.0, 3648.0, 3648.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.781, -5.743, 0.0, 0.0, 0.0]}
{"step": 3648, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3649.0, 1.0, 1.0, 1.0, 3649.0, 3649.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.78, -5.741, 0.0, 0.0, 0.0]}
{"step": 3649, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3650.0, 1.0, 1.0, 1.0, 3650.0, 3650.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.781, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12058, "number_of_timesteps": 163948, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.3999999999999986},
{"step": 3650, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3651.0, 1.0, 1.0, 1.0, 3651.0, 3651.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.784, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12062, "number_of_timesteps": 163984, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 3651, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3652.0, 1.0, 1.0, 1.0, 3652.0, 3652.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.782, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12068, "number_of_timesteps": 164041, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"step": 3652, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3653.0, 1.0, 1.0, 1.0, 3653.0, 3653.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.783, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12072, "number_of_timesteps": 164075, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
{"step": 3653, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3654.0, 1.0, 1.0, 1.0, 3654.0, 3654.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.783, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12078, "number_of_timesteps": 164130, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.20000000000000107},
{"step": 3654, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3655.0, 1.0, 1.0, 1.0, 3655.0, 3655.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.782, -5.742, 0.0, 0.0, 0.0]}
{"step": 3655, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3656.0, 1.0, 1.0, 1.0, 3656.0, 3656.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.782, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12087, "number_of_timesteps": 164224, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 3656, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3657.0, 1.0, 1.0, 1.0, 3657.0, 3657.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.78, -5.741, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 12090}
{"number_of_episodes": 12090, "number_of_timesteps": 164255, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.15000000000000036},
{"step": 3657, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3658.0, 1.0, 1.0, 1.0, 3658.0, 3658.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.779, -5.742, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12097, "number_of_timesteps": 164317, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 3658, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3659.0, 1.0, 1.0, 1.0, 3659.0, 3659.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.782, -5.745, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12099, "number_of_timesteps": 164336, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 3659, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3660.0, 1.0, 1.0, 1.0, 3660.0, 3660.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.781, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12107, "number_of_timesteps": 164414, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 3660, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3661.0, 1.0, 1.0, 1.0, 3661.0, 3661.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.782, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12108, "number_of_timesteps": 164423, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 3661, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3662.0, 1.0, 1.0, 1.0, 3662.0, 3662.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.78, -5.742, 0.0, 0.0, 0.0]}
{"step": 3662, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3663.0, 1.0, 1.0, 1.0, 3663.0, 3663.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.781, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12118, "number_of_timesteps": 164523, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3999999999999986},
{"step": 3663, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3664.0, 1.0, 1.0, 1.0, 3664.0, 3664.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.781, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12122, "number_of_timesteps": 164559, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 3664, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3665.0, 1.0, 1.0, 1.0, 3665.0, 3665.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.781, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12127, "number_of_timesteps": 164615, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.10000000000000142},
{"step": 3665, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3666.0, 1.0, 1.0, 1.0, 3666.0, 3666.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.78, -5.741, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12131, "number_of_timesteps": 164652, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 3666, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3667.0, 1.0, 1.0, 1.0, 3667.0, 3667.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.78, -5.74, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12137, "number_of_timesteps": 164712, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 3667, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3668.0, 1.0, 1.0, 1.0, 3668.0, 3668.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.784, -5.743, 0.0, 0.0, 0.0]}
{"step": 3668, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3669.0, 1.0, 1.0, 1.0, 3669.0, 3669.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.784, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12146, "number_of_timesteps": 164797, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3669, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3670.0, 1.0, 1.0, 1.0, 3670.0, 3670.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.784, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12149, "number_of_timesteps": 164829, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 3670, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3671.0, 1.0, 1.0, 1.0, 3671.0, 3671.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.783, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12156, "number_of_timesteps": 164894, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 3671, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3672.0, 1.0, 1.0, 1.0, 3672.0, 3672.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.786, -5.747, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12159, "number_of_timesteps": 164922, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3672, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3673.0, 1.0, 1.0, 1.0, 3673.0, 3673.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.68, 0.0, 0.0, 0.0, -5.785, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12166, "number_of_timesteps": 164989, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"step": 3673, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3674.0, 1.0, 1.0, 1.0, 3674.0, 3674.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.679, 0.0, 0.0, 0.0, -5.784, -5.744, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12169, "number_of_timesteps": 165017, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.007777777777777789, "biggest_recent_change": 0.3999999999999986},
{"step": 3674, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3675.0, 1.0, 1.0, 1.0, 3675.0, 3675.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.679, 0.0, 0.0, 0.0, -5.783, -5.743, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12175, "number_of_timesteps": 165073, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3675, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3676.0, 1.0, 1.0, 1.0, 3676.0, 3676.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.678, 0.0, 0.0, 0.0, -5.787, -5.747, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12178, "number_of_timesteps": 165104, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000036},
{"step": 3676, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3677.0, 1.0, 1.0, 1.0, 3677.0, 3677.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.676, 0.0, 0.0, 0.0, -5.785, -5.746, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12184, "number_of_timesteps": 165162, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 3677, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3678.0, 1.0, 1.0, 1.0, 3678.0, 3678.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.678, 0.0, 0.0, 0.0, -5.786, -5.747, 0.0, 0.0, 0.0]}
{"step": 3678, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3679.0, 1.0, 1.0, 1.0, 3679.0, 3679.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.79, -5.751, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12192, "number_of_timesteps": 165241, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3679, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3680.0, 1.0, 1.0, 1.0, 3680.0, 3680.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.794, -5.754, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12196, "number_of_timesteps": 165284, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"step": 3680, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3681.0, 1.0, 1.0, 1.0, 3681.0, 3681.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.68, 0.0, 0.0, 0.0, -5.793, -5.753, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12202, "number_of_timesteps": 165341, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3681, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3682.0, 1.0, 1.0, 1.0, 3682.0, 3682.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.791, -5.754, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12205, "number_of_timesteps": 165369, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.3999999999999986},
{"step": 3682, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3683.0, 1.0, 1.0, 1.0, 3683.0, 3683.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.681, 0.0, 0.0, 0.0, -5.791, -5.754, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12211, "number_of_timesteps": 165427, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3683, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3684.0, 1.0, 1.0, 1.0, 3684.0, 3684.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.68, 0.0, 0.0, 0.0, -5.79, -5.753, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12214, "number_of_timesteps": 165456, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 3684, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3685.0, 1.0, 1.0, 1.0, 3685.0, 3685.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.794, -5.757, 0.0, 0.0, 0.0]}
{"eval_score": 9.1, "number_of_episodes": 12220}
{"number_of_episodes": 12220, "number_of_timesteps": 165516, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3685, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3686.0, 1.0, 1.0, 1.0, 3686.0, 3686.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.797, -5.76, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12223, "number_of_timesteps": 165547, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"step": 3686, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3687.0, 1.0, 1.0, 1.0, 3687.0, 3687.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.798, -5.76, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12229, "number_of_timesteps": 165605, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.20000000000000107},
{"step": 3687, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3688.0, 1.0, 1.0, 1.0, 3688.0, 3688.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.799, -5.762, 0.0, 0.0, 0.0]}
{"step": 3688, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3689.0, 1.0, 1.0, 1.0, 3689.0, 3689.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.803, -5.766, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12238, "number_of_timesteps": 165693, "per_episode_reward": 10.05, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.15000000000000036},
{"step": 3689, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3690.0, 1.0, 1.0, 1.0, 3690.0, 3690.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.801, -5.764, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12243, "number_of_timesteps": 165740, "per_episode_reward": 10.05, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"step": 3690, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3691.0, 1.0, 1.0, 1.0, 3691.0, 3691.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.803, -5.766, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12248, "number_of_timesteps": 165787, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.20000000000000107},
{"step": 3691, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3692.0, 1.0, 1.0, 1.0, 3692.0, 3692.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.802, -5.765, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12252, "number_of_timesteps": 165825, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 3692, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3693.0, 1.0, 1.0, 1.0, 3693.0, 3693.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.802, -5.765, 0.0, 0.0, 0.0]}
{"step": 3693, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3694.0, 1.0, 1.0, 1.0, 3694.0, 3694.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.801, -5.764, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12261, "number_of_timesteps": 165910, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3694, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3695.0, 1.0, 1.0, 1.0, 3695.0, 3695.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.799, -5.764, 0.0, 0.0, 0.0]}
{"step": 3695, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3696.0, 1.0, 1.0, 1.0, 3696.0, 3696.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.798, -5.763, 0.0, 0.0, 0.0]}
{"step": 3696, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3697.0, 1.0, 1.0, 1.0, 3697.0, 3697.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.796, -5.764, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12275, "number_of_timesteps": 166052, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 3697, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3698.0, 1.0, 1.0, 1.0, 3698.0, 3698.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.797, -5.762, 0.0, 0.0, 0.0]}
{"step": 3698, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3699.0, 1.0, 1.0, 1.0, 3699.0, 3699.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.796, -5.761, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12285, "number_of_timesteps": 166148, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 3699, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3700.0, 1.0, 1.0, 1.0, 3700.0, 3700.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.799, -5.764, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12289, "number_of_timesteps": 166184, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3700, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3701.0, 1.0, 1.0, 1.0, 3701.0, 3701.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.798, -5.764, 0.0, 0.0, 0.0]}
{"step": 3701, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3702.0, 1.0, 1.0, 1.0, 3702.0, 3702.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.796, -5.764, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12299, "number_of_timesteps": 166285, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 3702, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3703.0, 1.0, 1.0, 1.0, 3703.0, 3703.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.799, -5.767, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12303, "number_of_timesteps": 166324, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3703, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3704.0, 1.0, 1.0, 1.0, 3704.0, 3704.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.797, -5.766, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12309, "number_of_timesteps": 166383, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3704, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3705.0, 1.0, 1.0, 1.0, 3705.0, 3705.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.801, -5.77, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12311, "number_of_timesteps": 166402, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 3705, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3706.0, 1.0, 1.0, 1.0, 3706.0, 3706.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.802, -5.769, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12317, "number_of_timesteps": 166463, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3706, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3707.0, 1.0, 1.0, 1.0, 3707.0, 3707.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.802, -5.769, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12321, "number_of_timesteps": 166504, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
{"step": 3707, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3708.0, 1.0, 1.0, 1.0, 3708.0, 3708.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.801, -5.768, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12327, "number_of_timesteps": 166559, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.20000000000000107},
{"step": 3708, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3709.0, 1.0, 1.0, 1.0, 3709.0, 3709.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.805, -5.772, 0.0, 0.0, 0.0]}
{"step": 3709, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3710.0, 1.0, 1.0, 1.0, 3710.0, 3710.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.804, -5.771, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12336, "number_of_timesteps": 166649, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.20000000000000107},
{"step": 3710, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3711.0, 1.0, 1.0, 1.0, 3711.0, 3711.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.802, -5.769, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12340, "number_of_timesteps": 166691, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3711, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3712.0, 1.0, 1.0, 1.0, 3712.0, 3712.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.699, 0.0, 0.0, 0.0, -5.806, -5.773, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12344, "number_of_timesteps": 166724, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3712, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3713.0, 1.0, 1.0, 1.0, 3713.0, 3713.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.805, -5.774, 0.0, 0.0, 0.0]}
{"eval_score": 9.5, "number_of_episodes": 12350}
{"number_of_episodes": 12350, "number_of_timesteps": 166783, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 3713, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3714.0, 1.0, 1.0, 1.0, 3714.0, 3714.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.805, -5.773, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12353, "number_of_timesteps": 166813, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3714, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3715.0, 1.0, 1.0, 1.0, 3715.0, 3715.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.806, -5.773, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12360, "number_of_timesteps": 166879, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3715, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3716.0, 1.0, 1.0, 1.0, 3716.0, 3716.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.703, 0.0, 0.0, 0.0, -5.804, -5.773, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12362, "number_of_timesteps": 166899, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3716, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3717.0, 1.0, 1.0, 1.0, 3717.0, 3717.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.704, 0.0, 0.0, 0.0, -5.804, -5.774, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12368, "number_of_timesteps": 166956, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.20000000000000107},
{"step": 3717, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3718.0, 1.0, 1.0, 1.0, 3718.0, 3718.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.803, -5.772, 0.0, 0.0, 0.0]}
{"step": 3718, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3719.0, 1.0, 1.0, 1.0, 3719.0, 3719.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.801, -5.771, 0.0, 0.0, 0.0]}
{"step": 3719, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3720.0, 1.0, 1.0, 1.0, 3720.0, 3720.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.8, -5.769, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12381, "number_of_timesteps": 167093, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 3720, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3721.0, 1.0, 1.0, 1.0, 3721.0, 3721.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.699, 0.0, 0.0, 0.0, -5.798, -5.768, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12385, "number_of_timesteps": 167128, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3721, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3722.0, 1.0, 1.0, 1.0, 3722.0, 3722.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.8, -5.769, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12390, "number_of_timesteps": 167179, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3722, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3723.0, 1.0, 1.0, 1.0, 3723.0, 3723.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.8, -5.769, 0.0, 0.0, 0.0]}
{"step": 3723, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3724.0, 1.0, 1.0, 1.0, 3724.0, 3724.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.8, -5.77, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12400, "number_of_timesteps": 167277, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3724, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3725.0, 1.0, 1.0, 1.0, 3725.0, 3725.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.802, -5.772, 0.0, 0.0, 0.0]}
{"step": 3725, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3726.0, 1.0, 1.0, 1.0, 3726.0, 3726.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.699, 0.0, 0.0, 0.0, -5.805, -5.775, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12410, "number_of_timesteps": 167374, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
{"step": 3726, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3727.0, 1.0, 1.0, 1.0, 3727.0, 3727.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.804, -5.773, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12413, "number_of_timesteps": 167401, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3727, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3728.0, 1.0, 1.0, 1.0, 3728.0, 3728.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.807, -5.777, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12420, "number_of_timesteps": 167467, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3728, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3729.0, 1.0, 1.0, 1.0, 3729.0, 3729.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.808, -5.775, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12423, "number_of_timesteps": 167496, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 3729, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3730.0, 1.0, 1.0, 1.0, 3730.0, 3730.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.806, -5.774, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12430, "number_of_timesteps": 167561, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3730, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3731.0, 1.0, 1.0, 1.0, 3731.0, 3731.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.805, -5.774, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12433, "number_of_timesteps": 167590, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 3731, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3732.0, 1.0, 1.0, 1.0, 3732.0, 3732.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.805, -5.775, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12439, "number_of_timesteps": 167646, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3732, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3733.0, 1.0, 1.0, 1.0, 3733.0, 3733.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.807, -5.776, 0.0, 0.0, 0.0]}
{"step": 3733, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3734.0, 1.0, 1.0, 1.0, 3734.0, 3734.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.81, -5.78, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12449, "number_of_timesteps": 167741, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3734, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3735.0, 1.0, 1.0, 1.0, 3735.0, 3735.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.811, -5.78, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12452, "number_of_timesteps": 167769, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3735, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3736.0, 1.0, 1.0, 1.0, 3736.0, 3736.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.809, -5.78, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12458, "number_of_timesteps": 167825, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3736, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3737.0, 1.0, 1.0, 1.0, 3737.0, 3737.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.813, -5.784, 0.0, 0.0, 0.0]}
{"step": 3737, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3738.0, 1.0, 1.0, 1.0, 3738.0, 3738.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.813, -5.783, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12468, "number_of_timesteps": 167921, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3738, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3739.0, 1.0, 1.0, 1.0, 3739.0, 3739.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.704, 0.0, 0.0, 0.0, -5.817, -5.787, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12472, "number_of_timesteps": 167957, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3739, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3740.0, 1.0, 1.0, 1.0, 3740.0, 3740.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.703, 0.0, 0.0, 0.0, -5.815, -5.786, 0.0, 0.0, 0.0]}
{"step": 3740, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3741.0, 1.0, 1.0, 1.0, 3741.0, 3741.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.814, -5.784, 0.0, 0.0, 0.0]}
{"eval_score": 8.9, "number_of_episodes": 12482}
{"number_of_episodes": 12482, "number_of_timesteps": 168046, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3741, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3742.0, 1.0, 1.0, 1.0, 3742.0, 3742.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.818, -5.788, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12488, "number_of_timesteps": 168100, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.20000000000000107},
{"step": 3742, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3743.0, 1.0, 1.0, 1.0, 3743.0, 3743.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.699, 0.0, 0.0, 0.0, -5.816, -5.787, 0.0, 0.0, 0.0]}
{"step": 3743, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3744.0, 1.0, 1.0, 1.0, 3744.0, 3744.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.819, -5.79, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12498, "number_of_timesteps": 168196, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3744, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3745.0, 1.0, 1.0, 1.0, 3745.0, 3745.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.818, -5.788, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12500, "number_of_timesteps": 168214, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3745, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3746.0, 1.0, 1.0, 1.0, 3746.0, 3746.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.818, -5.789, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12507, "number_of_timesteps": 168283, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
{"step": 3746, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3747.0, 1.0, 1.0, 1.0, 3747.0, 3747.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.817, -5.787, 0.0, 0.0, 0.0]}
{"step": 3747, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3748.0, 1.0, 1.0, 1.0, 3748.0, 3748.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.815, -5.786, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12515, "number_of_timesteps": 168356, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3748, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3749.0, 1.0, 1.0, 1.0, 3749.0, 3749.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.814, -5.786, 0.0, 0.0, 0.0]}
{"step": 3749, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3750.0, 1.0, 1.0, 1.0, 3750.0, 3750.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.812, -5.785, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12525, "number_of_timesteps": 168459, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3750, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3751.0, 1.0, 1.0, 1.0, 3751.0, 3751.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.811, -5.784, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12528, "number_of_timesteps": 168489, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 3751, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3752.0, 1.0, 1.0, 1.0, 3752.0, 3752.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.809, -5.782, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12534, "number_of_timesteps": 168549, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3752, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3753.0, 1.0, 1.0, 1.0, 3753.0, 3753.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.813, -5.786, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12538, "number_of_timesteps": 168589, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3753, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3754.0, 1.0, 1.0, 1.0, 3754.0, 3754.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.815, -5.788, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12542, "number_of_timesteps": 168623, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3754, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3755.0, 1.0, 1.0, 1.0, 3755.0, 3755.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.815, -5.788, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12548, "number_of_timesteps": 168685, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3755, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3756.0, 1.0, 1.0, 1.0, 3756.0, 3756.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.815, -5.789, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12552, "number_of_timesteps": 168724, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3756, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3757.0, 1.0, 1.0, 1.0, 3757.0, 3757.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.814, -5.787, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12555, "number_of_timesteps": 168749, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3757, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3758.0, 1.0, 1.0, 1.0, 3758.0, 3758.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.812, -5.787, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12561, "number_of_timesteps": 168810, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3758, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3759.0, 1.0, 1.0, 1.0, 3759.0, 3759.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.812, -5.786, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12565, "number_of_timesteps": 168849, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3759, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3760.0, 1.0, 1.0, 1.0, 3760.0, 3760.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.813, -5.786, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12571, "number_of_timesteps": 168904, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3760, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3761.0, 1.0, 1.0, 1.0, 3761.0, 3761.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.813, -5.787, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12575, "number_of_timesteps": 168939, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3761, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3762.0, 1.0, 1.0, 1.0, 3762.0, 3762.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.812, -5.787, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12581, "number_of_timesteps": 168994, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3762, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3763.0, 1.0, 1.0, 1.0, 3763.0, 3763.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.815, -5.791, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12585, "number_of_timesteps": 169033, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3763, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3764.0, 1.0, 1.0, 1.0, 3764.0, 3764.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.814, -5.789, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12591, "number_of_timesteps": 169088, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 3764, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3765.0, 1.0, 1.0, 1.0, 3765.0, 3765.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.817, -5.793, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12595, "number_of_timesteps": 169126, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3765, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3766.0, 1.0, 1.0, 1.0, 3766.0, 3766.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.817, -5.792, 0.0, 0.0, 0.0]}
{"step": 3766, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3767.0, 1.0, 1.0, 1.0, 3767.0, 3767.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.817, -5.793, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12605, "number_of_timesteps": 169223, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3767, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3768.0, 1.0, 1.0, 1.0, 3768.0, 3768.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.821, -5.796, 0.0, 0.0, 0.0]}
{"step": 3768, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3769.0, 1.0, 1.0, 1.0, 3769.0, 3769.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.822, -5.798, 0.0, 0.0, 0.0]}
{"eval_score": 10.1, "number_of_episodes": 12615}
{"number_of_episodes": 12615, "number_of_timesteps": 169315, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3769, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3770.0, 1.0, 1.0, 1.0, 3770.0, 3770.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.826, -5.801, 0.0, 0.0, 0.0]}
{"step": 3770, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3771.0, 1.0, 1.0, 1.0, 3771.0, 3771.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.831, -5.806, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12624, "number_of_timesteps": 169396, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.20000000000000107},
{"step": 3771, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3772.0, 1.0, 1.0, 1.0, 3772.0, 3772.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.829, -5.804, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12628, "number_of_timesteps": 169435, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3772, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3773.0, 1.0, 1.0, 1.0, 3773.0, 3773.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.829, -5.805, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12632, "number_of_timesteps": 169472, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 3773, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3774.0, 1.0, 1.0, 1.0, 3774.0, 3774.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.828, -5.803, 0.0, 0.0, 0.0]}
{"step": 3774, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3775.0, 1.0, 1.0, 1.0, 3775.0, 3775.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.828, -5.804, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12640, "number_of_timesteps": 169549, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3775, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3776.0, 1.0, 1.0, 1.0, 3776.0, 3776.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.828, -5.804, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12646, "number_of_timesteps": 169608, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3776, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3777.0, 1.0, 1.0, 1.0, 3777.0, 3777.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.83, -5.806, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12649, "number_of_timesteps": 169641, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3777, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3778.0, 1.0, 1.0, 1.0, 3778.0, 3778.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.829, -5.805, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12656, "number_of_timesteps": 169710, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 3778, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3779.0, 1.0, 1.0, 1.0, 3779.0, 3779.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.827, -5.804, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12659, "number_of_timesteps": 169738, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3779, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3780.0, 1.0, 1.0, 1.0, 3780.0, 3780.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.829, -5.806, 0.0, 0.0, 0.0]}
{"step": 3780, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3781.0, 1.0, 1.0, 1.0, 3781.0, 3781.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.832, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12668, "number_of_timesteps": 169822, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3781, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3782.0, 1.0, 1.0, 1.0, 3782.0, 3782.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.832, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12675, "number_of_timesteps": 169889, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3782, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3783.0, 1.0, 1.0, 1.0, 3783.0, 3783.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.831, -5.81, 0.0, 0.0, 0.0]}
{"step": 3783, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3784.0, 1.0, 1.0, 1.0, 3784.0, 3784.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.829, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12685, "number_of_timesteps": 169986, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3784, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3785.0, 1.0, 1.0, 1.0, 3785.0, 3785.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.833, -5.813, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12688, "number_of_timesteps": 170015, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3785, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3786.0, 1.0, 1.0, 1.0, 3786.0, 3786.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.831, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12695, "number_of_timesteps": 170076, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"step": 3786, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3787.0, 1.0, 1.0, 1.0, 3787.0, 3787.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.832, -5.812, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12698, "number_of_timesteps": 170104, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3787, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3788.0, 1.0, 1.0, 1.0, 3788.0, 3788.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.833, -5.812, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12702, "number_of_timesteps": 170140, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3788, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3789.0, 1.0, 1.0, 1.0, 3789.0, 3789.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.831, -5.811, 0.0, 0.0, 0.0]}
{"step": 3789, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3790.0, 1.0, 1.0, 1.0, 3790.0, 3790.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.83, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12712, "number_of_timesteps": 170243, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3790, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3791.0, 1.0, 1.0, 1.0, 3791.0, 3791.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.83, -5.81, 0.0, 0.0, 0.0]}
{"step": 3791, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3792.0, 1.0, 1.0, 1.0, 3792.0, 3792.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.829, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12721, "number_of_timesteps": 170324, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3792, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3793.0, 1.0, 1.0, 1.0, 3793.0, 3793.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.833, -5.812, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12726, "number_of_timesteps": 170374, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3793, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3794.0, 1.0, 1.0, 1.0, 3794.0, 3794.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.833, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12730, "number_of_timesteps": 170410, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"step": 3794, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3795.0, 1.0, 1.0, 1.0, 3795.0, 3795.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.831, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12736, "number_of_timesteps": 170467, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3795, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3796.0, 1.0, 1.0, 1.0, 3796.0, 3796.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.832, -5.81, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12739, "number_of_timesteps": 170495, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"step": 3796, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3797.0, 1.0, 1.0, 1.0, 3797.0, 3797.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.832, -5.81, 0.0, 0.0, 0.0]}
{"eval_score": 9.3, "number_of_episodes": 12744}
{"step": 3797, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3798.0, 1.0, 1.0, 1.0, 3798.0, 3798.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.833, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12748, "number_of_timesteps": 170583, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3798, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3799.0, 1.0, 1.0, 1.0, 3799.0, 3799.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.832, -5.81, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12754, "number_of_timesteps": 170640, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3799, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3800.0, 1.0, 1.0, 1.0, 3800.0, 3800.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.833, -5.811, 0.0, 0.0, 0.0]}
{"step": 3800, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3801.0, 1.0, 1.0, 1.0, 3801.0, 3801.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.832, -5.81, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12763, "number_of_timesteps": 170727, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3801, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3802.0, 1.0, 1.0, 1.0, 3802.0, 3802.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.833, -5.811, 0.0, 0.0, 0.0]}
{"step": 3802, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3803.0, 1.0, 1.0, 1.0, 3803.0, 3803.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.833, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12772, "number_of_timesteps": 170816, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"step": 3803, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3804.0, 1.0, 1.0, 1.0, 3804.0, 3804.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.834, -5.812, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12775, "number_of_timesteps": 170848, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"step": 3804, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3805.0, 1.0, 1.0, 1.0, 3805.0, 3805.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.832, -5.81, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12781, "number_of_timesteps": 170902, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3805, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3806.0, 1.0, 1.0, 1.0, 3806.0, 3806.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.831, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12785, "number_of_timesteps": 170942, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3806, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3807.0, 1.0, 1.0, 1.0, 3807.0, 3807.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.829, -5.808, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12790, "number_of_timesteps": 170988, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3807, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3808.0, 1.0, 1.0, 1.0, 3808.0, 3808.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.833, -5.811, 0.0, 0.0, 0.0]}
{"step": 3808, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3809.0, 1.0, 1.0, 1.0, 3809.0, 3809.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.833, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12800, "number_of_timesteps": 171079, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3809, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3810.0, 1.0, 1.0, 1.0, 3810.0, 3810.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.831, -5.81, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12804, "number_of_timesteps": 171116, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3810, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3811.0, 1.0, 1.0, 1.0, 3811.0, 3811.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.83, -5.808, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12809, "number_of_timesteps": 171164, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3811, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3812.0, 1.0, 1.0, 1.0, 3812.0, 3812.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.83, -5.807, 0.0, 0.0, 0.0]}
{"step": 3812, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3813.0, 1.0, 1.0, 1.0, 3813.0, 3813.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.83, -5.805, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12819, "number_of_timesteps": 171262, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3813, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3814.0, 1.0, 1.0, 1.0, 3814.0, 3814.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.689, 0.0, 0.0, 0.0, -5.83, -5.806, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12822, "number_of_timesteps": 171290, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3814, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3815.0, 1.0, 1.0, 1.0, 3815.0, 3815.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.832, -5.808, 0.0, 0.0, 0.0]}
{"step": 3815, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3816.0, 1.0, 1.0, 1.0, 3816.0, 3816.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.835, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12830, "number_of_timesteps": 171368, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3816, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3817.0, 1.0, 1.0, 1.0, 3817.0, 3817.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.836, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12838, "number_of_timesteps": 171444, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3817, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3818.0, 1.0, 1.0, 1.0, 3818.0, 3818.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.834, -5.81, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12839, "number_of_timesteps": 171452, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3818, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3819.0, 1.0, 1.0, 1.0, 3819.0, 3819.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.833, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12847, "number_of_timesteps": 171527, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3819, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3820.0, 1.0, 1.0, 1.0, 3820.0, 3820.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.833, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12849, "number_of_timesteps": 171546, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3820, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3821.0, 1.0, 1.0, 1.0, 3821.0, 3821.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.833, -5.808, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12856, "number_of_timesteps": 171613, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3821, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3822.0, 1.0, 1.0, 1.0, 3822.0, 3822.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.831, -5.807, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12859, "number_of_timesteps": 171644, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3822, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3823.0, 1.0, 1.0, 1.0, 3823.0, 3823.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.682, 0.0, 0.0, 0.0, -5.83, -5.805, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12864, "number_of_timesteps": 171690, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3823, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3824.0, 1.0, 1.0, 1.0, 3824.0, 3824.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.828, -5.806, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12869, "number_of_timesteps": 171742, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3824, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3825.0, 1.0, 1.0, 1.0, 3825.0, 3825.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.828, -5.804, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 12874}
{"number_of_episodes": 12874, "number_of_timesteps": 171791, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3825, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3826.0, 1.0, 1.0, 1.0, 3826.0, 3826.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.827, -5.805, 0.0, 0.0, 0.0]}
{"step": 3826, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3827.0, 1.0, 1.0, 1.0, 3827.0, 3827.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.827, -5.803, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12882, "number_of_timesteps": 171866, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3827, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3828.0, 1.0, 1.0, 1.0, 3828.0, 3828.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.831, -5.807, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12887, "number_of_timesteps": 171918, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3828, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3829.0, 1.0, 1.0, 1.0, 3829.0, 3829.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.831, -5.807, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12892, "number_of_timesteps": 171965, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3829, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3830.0, 1.0, 1.0, 1.0, 3830.0, 3830.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.835, -5.81, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12895, "number_of_timesteps": 171992, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3830, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3831.0, 1.0, 1.0, 1.0, 3831.0, 3831.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.835, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12901, "number_of_timesteps": 172049, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3831, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3832.0, 1.0, 1.0, 1.0, 3832.0, 3832.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.835, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12905, "number_of_timesteps": 172087, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3832, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3833.0, 1.0, 1.0, 1.0, 3833.0, 3833.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.836, -5.812, 0.0, 0.0, 0.0]}
{"step": 3833, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3834.0, 1.0, 1.0, 1.0, 3834.0, 3834.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.837, -5.813, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12913, "number_of_timesteps": 172161, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3834, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3835.0, 1.0, 1.0, 1.0, 3835.0, 3835.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.835, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12920, "number_of_timesteps": 172229, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3835, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3836.0, 1.0, 1.0, 1.0, 3836.0, 3836.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.836, -5.812, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12922, "number_of_timesteps": 172247, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3836, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3837.0, 1.0, 1.0, 1.0, 3837.0, 3837.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.834, -5.81, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12930, "number_of_timesteps": 172324, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3837, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3838.0, 1.0, 1.0, 1.0, 3838.0, 3838.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.833, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12932, "number_of_timesteps": 172341, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3838, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3839.0, 1.0, 1.0, 1.0, 3839.0, 3839.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.832, -5.809, 0.0, 0.0, 0.0]}
{"step": 3839, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3840.0, 1.0, 1.0, 1.0, 3840.0, 3840.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.833, -5.808, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12941, "number_of_timesteps": 172431, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3840, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3841.0, 1.0, 1.0, 1.0, 3841.0, 3841.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.831, -5.806, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12948, "number_of_timesteps": 172500, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3841, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3842.0, 1.0, 1.0, 1.0, 3842.0, 3842.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.832, -5.807, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12951, "number_of_timesteps": 172525, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3842, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3843.0, 1.0, 1.0, 1.0, 3843.0, 3843.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.835, -5.81, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12956, "number_of_timesteps": 172571, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3843, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3844.0, 1.0, 1.0, 1.0, 3844.0, 3844.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.836, -5.81, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12961, "number_of_timesteps": 172623, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"step": 3844, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3845.0, 1.0, 1.0, 1.0, 3845.0, 3845.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.684, 0.0, 0.0, 0.0, -5.834, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12965, "number_of_timesteps": 172660, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3845, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3846.0, 1.0, 1.0, 1.0, 3846.0, 3846.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.683, 0.0, 0.0, 0.0, -5.833, -5.807, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12971, "number_of_timesteps": 172719, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3846, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3847.0, 1.0, 1.0, 1.0, 3847.0, 3847.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.836, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12974, "number_of_timesteps": 172748, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3847, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3848.0, 1.0, 1.0, 1.0, 3848.0, 3848.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.685, 0.0, 0.0, 0.0, -5.834, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12979, "number_of_timesteps": 172798, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3848, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3849.0, 1.0, 1.0, 1.0, 3849.0, 3849.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.833, -5.809, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12983, "number_of_timesteps": 172839, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3849, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3850.0, 1.0, 1.0, 1.0, 3850.0, 3850.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.833, -5.81, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12989, "number_of_timesteps": 172896, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3850, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3851.0, 1.0, 1.0, 1.0, 3851.0, 3851.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.834, -5.81, 0.0, 0.0, 0.0]}
{"step": 3851, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3852.0, 1.0, 1.0, 1.0, 3852.0, 3852.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.834, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 12999, "number_of_timesteps": 172993, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3852, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3853.0, 1.0, 1.0, 1.0, 3853.0, 3853.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.834, -5.81, 0.0, 0.0, 0.0]}
{"eval_score": 10.1, "number_of_episodes": 13002}
{"number_of_episodes": 13002, "number_of_timesteps": 173020, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3853, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3854.0, 1.0, 1.0, 1.0, 3854.0, 3854.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.689, 0.0, 0.0, 0.0, -5.834, -5.811, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13007, "number_of_timesteps": 173068, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3854, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3855.0, 1.0, 1.0, 1.0, 3855.0, 3855.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.838, -5.814, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13012, "number_of_timesteps": 173120, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"step": 3855, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3856.0, 1.0, 1.0, 1.0, 3856.0, 3856.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.838, -5.815, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13016, "number_of_timesteps": 173159, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3856, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3857.0, 1.0, 1.0, 1.0, 3857.0, 3857.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.837, -5.814, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13021, "number_of_timesteps": 173211, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3857, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3858.0, 1.0, 1.0, 1.0, 3858.0, 3858.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.837, -5.815, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13026, "number_of_timesteps": 173257, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3858, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3859.0, 1.0, 1.0, 1.0, 3859.0, 3859.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.84, -5.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13031, "number_of_timesteps": 173301, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3859, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3860.0, 1.0, 1.0, 1.0, 3860.0, 3860.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.841, -5.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13036, "number_of_timesteps": 173349, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3860, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3861.0, 1.0, 1.0, 1.0, 3861.0, 3861.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.841, -5.819, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13041, "number_of_timesteps": 173394, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3861, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3862.0, 1.0, 1.0, 1.0, 3862.0, 3862.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.841, -5.817, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13044, "number_of_timesteps": 173421, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3862, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3863.0, 1.0, 1.0, 1.0, 3863.0, 3863.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.844, -5.821, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13051, "number_of_timesteps": 173492, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3863, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3864.0, 1.0, 1.0, 1.0, 3864.0, 3864.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.844, -5.821, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13054, "number_of_timesteps": 173519, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3864, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3865.0, 1.0, 1.0, 1.0, 3865.0, 3865.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.843, -5.819, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13060, "number_of_timesteps": 173576, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3865, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3866.0, 1.0, 1.0, 1.0, 3866.0, 3866.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.841, -5.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13064, "number_of_timesteps": 173617, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3866, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3867.0, 1.0, 1.0, 1.0, 3867.0, 3867.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.845, -5.821, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13070, "number_of_timesteps": 173672, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3867, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3868.0, 1.0, 1.0, 1.0, 3868.0, 3868.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.843, -5.822, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13073, "number_of_timesteps": 173699, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3868, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3869.0, 1.0, 1.0, 1.0, 3869.0, 3869.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.843, -5.821, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13079, "number_of_timesteps": 173757, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3869, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3870.0, 1.0, 1.0, 1.0, 3870.0, 3870.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.841, -5.82, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13082, "number_of_timesteps": 173786, "per_episode_reward": 10.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"step": 3870, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3871.0, 1.0, 1.0, 1.0, 3871.0, 3871.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.84, -5.818, 0.0, 0.0, 0.0]}
{"step": 3871, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3872.0, 1.0, 1.0, 1.0, 3872.0, 3872.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.838, -5.817, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13092, "number_of_timesteps": 173882, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3872, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3873.0, 1.0, 1.0, 1.0, 3873.0, 3873.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.842, -5.82, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13099, "number_of_timesteps": 173948, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3873, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3874.0, 1.0, 1.0, 1.0, 3874.0, 3874.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.84, -5.821, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13100, "number_of_timesteps": 173957, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3874, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3875.0, 1.0, 1.0, 1.0, 3875.0, 3875.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.841, -5.822, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13109, "number_of_timesteps": 174044, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3875, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3876.0, 1.0, 1.0, 1.0, 3876.0, 3876.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.84, -5.823, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13110, "number_of_timesteps": 174054, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3876, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3877.0, 1.0, 1.0, 1.0, 3877.0, 3877.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.839, -5.822, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13119, "number_of_timesteps": 174136, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3877, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3878.0, 1.0, 1.0, 1.0, 3878.0, 3878.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.838, -5.82, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13120, "number_of_timesteps": 174145, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3878, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3879.0, 1.0, 1.0, 1.0, 3879.0, 3879.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.836, -5.819, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13129, "number_of_timesteps": 174229, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3879, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3880.0, 1.0, 1.0, 1.0, 3880.0, 3880.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.835, -5.818, 0.0, 0.0, 0.0]}
{"eval_score": 9.4, "number_of_episodes": 13130}
{"number_of_episodes": 13130, "number_of_timesteps": 174239, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3880, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3881.0, 1.0, 1.0, 1.0, 3881.0, 3881.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.835, -5.819, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13138, "number_of_timesteps": 174317, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3881, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3882.0, 1.0, 1.0, 1.0, 3882.0, 3882.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.689, 0.0, 0.0, 0.0, -5.839, -5.822, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13140, "number_of_timesteps": 174338, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3882, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3883.0, 1.0, 1.0, 1.0, 3883.0, 3883.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.837, -5.821, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13146, "number_of_timesteps": 174396, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3883, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3884.0, 1.0, 1.0, 1.0, 3884.0, 3884.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.836, -5.819, 0.0, 0.0, 0.0]}
{"step": 3884, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3885.0, 1.0, 1.0, 1.0, 3885.0, 3885.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.837, -5.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13156, "number_of_timesteps": 174491, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3885, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3886.0, 1.0, 1.0, 1.0, 3886.0, 3886.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.835, -5.816, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13160, "number_of_timesteps": 174529, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3886, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3887.0, 1.0, 1.0, 1.0, 3887.0, 3887.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.834, -5.815, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13166, "number_of_timesteps": 174583, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3887, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3888.0, 1.0, 1.0, 1.0, 3888.0, 3888.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.834, -5.815, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13170, "number_of_timesteps": 174619, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3888, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3889.0, 1.0, 1.0, 1.0, 3889.0, 3889.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.686, 0.0, 0.0, 0.0, -5.833, -5.814, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13176, "number_of_timesteps": 174676, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3889, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3890.0, 1.0, 1.0, 1.0, 3890.0, 3890.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.689, 0.0, 0.0, 0.0, -5.836, -5.817, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13180, "number_of_timesteps": 174709, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3890, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3891.0, 1.0, 1.0, 1.0, 3891.0, 3891.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.837, -5.816, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13185, "number_of_timesteps": 174755, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3891, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3892.0, 1.0, 1.0, 1.0, 3892.0, 3892.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.689, 0.0, 0.0, 0.0, -5.835, -5.814, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13190, "number_of_timesteps": 174804, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3892, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3893.0, 1.0, 1.0, 1.0, 3893.0, 3893.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.839, -5.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13194, "number_of_timesteps": 174843, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3893, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3894.0, 1.0, 1.0, 1.0, 3894.0, 3894.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.839, -5.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13199, "number_of_timesteps": 174892, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3894, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3895.0, 1.0, 1.0, 1.0, 3895.0, 3895.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.838, -5.817, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13204, "number_of_timesteps": 174940, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3895, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3896.0, 1.0, 1.0, 1.0, 3896.0, 3896.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.687, 0.0, 0.0, 0.0, -5.837, -5.816, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13208, "number_of_timesteps": 174977, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3896, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3897.0, 1.0, 1.0, 1.0, 3897.0, 3897.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.837, -5.814, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13212, "number_of_timesteps": 175015, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3897, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3898.0, 1.0, 1.0, 1.0, 3898.0, 3898.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.688, 0.0, 0.0, 0.0, -5.838, -5.815, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13218, "number_of_timesteps": 175079, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3898, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3899.0, 1.0, 1.0, 1.0, 3899.0, 3899.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.841, -5.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13221, "number_of_timesteps": 175105, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3899, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3900.0, 1.0, 1.0, 1.0, 3900.0, 3900.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.841, -5.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13228, "number_of_timesteps": 175170, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3900, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3901.0, 1.0, 1.0, 1.0, 3901.0, 3901.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.844, -5.821, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13230, "number_of_timesteps": 175188, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3901, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3902.0, 1.0, 1.0, 1.0, 3902.0, 3902.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.845, -5.822, 0.0, 0.0, 0.0]}
{"step": 3902, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3903.0, 1.0, 1.0, 1.0, 3903.0, 3903.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.848, -5.825, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13239, "number_of_timesteps": 175273, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3903, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3904.0, 1.0, 1.0, 1.0, 3904.0, 3904.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.848, -5.825, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13247, "number_of_timesteps": 175351, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3904, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3905.0, 1.0, 1.0, 1.0, 3905.0, 3905.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.846, -5.823, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13249, "number_of_timesteps": 175372, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3905, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3906.0, 1.0, 1.0, 1.0, 3906.0, 3906.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.845, -5.822, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13256, "number_of_timesteps": 175437, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3906, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3907.0, 1.0, 1.0, 1.0, 3907.0, 3907.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.69, 0.0, 0.0, 0.0, -5.843, -5.82, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13259, "number_of_timesteps": 175466, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3907, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3908.0, 1.0, 1.0, 1.0, 3908.0, 3908.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.689, 0.0, 0.0, 0.0, -5.842, -5.819, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 13266}
{"number_of_episodes": 13266, "number_of_timesteps": 175531, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3908, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3909.0, 1.0, 1.0, 1.0, 3909.0, 3909.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.845, -5.822, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13268, "number_of_timesteps": 175550, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3909, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3910.0, 1.0, 1.0, 1.0, 3910.0, 3910.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.844, -5.823, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13276, "number_of_timesteps": 175630, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3910, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3911.0, 1.0, 1.0, 1.0, 3911.0, 3911.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.844, -5.823, 0.0, 0.0, 0.0]}
{"step": 3911, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3912.0, 1.0, 1.0, 1.0, 3912.0, 3912.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.844, -5.823, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13285, "number_of_timesteps": 175714, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3912, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3913.0, 1.0, 1.0, 1.0, 3913.0, 3913.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.842, -5.823, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13286, "number_of_timesteps": 175726, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3913, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3914.0, 1.0, 1.0, 1.0, 3914.0, 3914.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.841, -5.822, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13293, "number_of_timesteps": 175794, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3914, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3915.0, 1.0, 1.0, 1.0, 3915.0, 3915.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.841, -5.82, 0.0, 0.0, 0.0]}
{"step": 3915, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3916.0, 1.0, 1.0, 1.0, 3916.0, 3916.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.84, -5.819, 0.0, 0.0, 0.0]}
{"step": 3916, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3917.0, 1.0, 1.0, 1.0, 3917.0, 3917.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.841, -5.817, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13305, "number_of_timesteps": 175914, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3917, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3918.0, 1.0, 1.0, 1.0, 3918.0, 3918.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.84, -5.816, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13311, "number_of_timesteps": 175974, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3918, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3919.0, 1.0, 1.0, 1.0, 3919.0, 3919.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.839, -5.814, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13315, "number_of_timesteps": 176010, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3919, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3920.0, 1.0, 1.0, 1.0, 3920.0, 3920.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.842, -5.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13319, "number_of_timesteps": 176048, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3920, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3921.0, 1.0, 1.0, 1.0, 3921.0, 3921.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.842, -5.817, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13325, "number_of_timesteps": 176106, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3921, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3922.0, 1.0, 1.0, 1.0, 3922.0, 3922.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.841, -5.816, 0.0, 0.0, 0.0]}
{"step": 3922, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3923.0, 1.0, 1.0, 1.0, 3923.0, 3923.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.839, -5.817, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13335, "number_of_timesteps": 176200, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3923, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3924.0, 1.0, 1.0, 1.0, 3924.0, 3924.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.84, -5.817, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13338, "number_of_timesteps": 176225, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3924, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3925.0, 1.0, 1.0, 1.0, 3925.0, 3925.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.838, -5.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13345, "number_of_timesteps": 176290, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3925, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3926.0, 1.0, 1.0, 1.0, 3926.0, 3926.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.838, -5.818, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13348, "number_of_timesteps": 176319, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3926, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3927.0, 1.0, 1.0, 1.0, 3927.0, 3927.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.837, -5.819, 0.0, 0.0, 0.0]}
{"step": 3927, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3928.0, 1.0, 1.0, 1.0, 3928.0, 3928.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.837, -5.819, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13358, "number_of_timesteps": 176417, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3928, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3929.0, 1.0, 1.0, 1.0, 3929.0, 3929.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.837, -5.819, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13364, "number_of_timesteps": 176474, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3929, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3930.0, 1.0, 1.0, 1.0, 3930.0, 3930.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.84, -5.822, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13368, "number_of_timesteps": 176513, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3930, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3931.0, 1.0, 1.0, 1.0, 3931.0, 3931.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.843, -5.825, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13373, "number_of_timesteps": 176560, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3931, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3932.0, 1.0, 1.0, 1.0, 3932.0, 3932.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.844, -5.825, 0.0, 0.0, 0.0]}
{"step": 3932, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3933.0, 1.0, 1.0, 1.0, 3933.0, 3933.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.699, 0.0, 0.0, 0.0, -5.844, -5.826, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13381, "number_of_timesteps": 176638, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3933, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3934.0, 1.0, 1.0, 1.0, 3934.0, 3934.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.843, -5.825, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13387, "number_of_timesteps": 176695, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3934, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3935.0, 1.0, 1.0, 1.0, 3935.0, 3935.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.842, -5.823, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 13390}
{"number_of_episodes": 13390, "number_of_timesteps": 176725, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3935, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3936.0, 1.0, 1.0, 1.0, 3936.0, 3936.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.845, -5.826, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13395, "number_of_timesteps": 176775, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3936, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3937.0, 1.0, 1.0, 1.0, 3937.0, 3937.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.843, -5.825, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13398, "number_of_timesteps": 176809, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3937, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3938.0, 1.0, 1.0, 1.0, 3938.0, 3938.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.844, -5.825, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13404, "number_of_timesteps": 176870, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3938, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3939.0, 1.0, 1.0, 1.0, 3939.0, 3939.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.844, -5.826, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13408, "number_of_timesteps": 176910, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3939, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3940.0, 1.0, 1.0, 1.0, 3940.0, 3940.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.843, -5.824, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13414, "number_of_timesteps": 176968, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3940, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3941.0, 1.0, 1.0, 1.0, 3941.0, 3941.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.846, -5.827, 0.0, 0.0, 0.0]}
{"step": 3941, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3942.0, 1.0, 1.0, 1.0, 3942.0, 3942.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.844, -5.826, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13423, "number_of_timesteps": 177052, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3942, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3943.0, 1.0, 1.0, 1.0, 3943.0, 3943.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.846, -5.828, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13426, "number_of_timesteps": 177082, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3943, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3944.0, 1.0, 1.0, 1.0, 3944.0, 3944.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.845, -5.827, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13430, "number_of_timesteps": 177123, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3944, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3945.0, 1.0, 1.0, 1.0, 3945.0, 3945.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.699, 0.0, 0.0, 0.0, -5.848, -5.83, 0.0, 0.0, 0.0]}
{"step": 3945, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3946.0, 1.0, 1.0, 1.0, 3946.0, 3946.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.85, -5.832, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13439, "number_of_timesteps": 177216, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3946, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3947.0, 1.0, 1.0, 1.0, 3947.0, 3947.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.85, -5.832, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13446, "number_of_timesteps": 177280, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3947, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3948.0, 1.0, 1.0, 1.0, 3948.0, 3948.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.853, -5.835, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13449, "number_of_timesteps": 177309, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3948, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3949.0, 1.0, 1.0, 1.0, 3949.0, 3949.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.851, -5.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13453, "number_of_timesteps": 177345, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3949, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3950.0, 1.0, 1.0, 1.0, 3950.0, 3950.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.704, 0.0, 0.0, 0.0, -5.853, -5.838, 0.0, 0.0, 0.0]}
{"step": 3950, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3951.0, 1.0, 1.0, 1.0, 3951.0, 3951.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.707, 0.0, 0.0, 0.0, -5.856, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13463, "number_of_timesteps": 177446, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3951, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3952.0, 1.0, 1.0, 1.0, 3952.0, 3952.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.707, 0.0, 0.0, 0.0, -5.857, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13468, "number_of_timesteps": 177493, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3952, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3953.0, 1.0, 1.0, 1.0, 3953.0, 3953.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.708, 0.0, 0.0, 0.0, -5.857, -5.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13473, "number_of_timesteps": 177542, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3953, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3954.0, 1.0, 1.0, 1.0, 3954.0, 3954.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.858, -5.84, 0.0, 0.0, 0.0]}
{"step": 3954, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3955.0, 1.0, 1.0, 1.0, 3955.0, 3955.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.708, 0.0, 0.0, 0.0, -5.856, -5.839, 0.0, 0.0, 0.0]}
{"step": 3955, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3956.0, 1.0, 1.0, 1.0, 3956.0, 3956.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.857, -5.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13488, "number_of_timesteps": 177677, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3956, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3957.0, 1.0, 1.0, 1.0, 3957.0, 3957.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.707, 0.0, 0.0, 0.0, -5.855, -5.838, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13491, "number_of_timesteps": 177706, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3957, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3958.0, 1.0, 1.0, 1.0, 3958.0, 3958.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.708, 0.0, 0.0, 0.0, -5.856, -5.838, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13497, "number_of_timesteps": 177764, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3958, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3959.0, 1.0, 1.0, 1.0, 3959.0, 3959.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.707, 0.0, 0.0, 0.0, -5.859, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13500, "number_of_timesteps": 177794, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3959, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3960.0, 1.0, 1.0, 1.0, 3960.0, 3960.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.706, 0.0, 0.0, 0.0, -5.857, -5.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13504, "number_of_timesteps": 177835, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3960, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3961.0, 1.0, 1.0, 1.0, 3961.0, 3961.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.704, 0.0, 0.0, 0.0, -5.856, -5.838, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13510, "number_of_timesteps": 177896, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3961, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3962.0, 1.0, 1.0, 1.0, 3962.0, 3962.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.703, 0.0, 0.0, 0.0, -5.854, -5.837, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13514, "number_of_timesteps": 177929, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3962, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3963.0, 1.0, 1.0, 1.0, 3963.0, 3963.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.704, 0.0, 0.0, 0.0, -5.853, -5.837, 0.0, 0.0, 0.0]}
{"step": 3963, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3964.0, 1.0, 1.0, 1.0, 3964.0, 3964.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.703, 0.0, 0.0, 0.0, -5.851, -5.836, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 13524}
{"number_of_episodes": 13524, "number_of_timesteps": 178027, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3964, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3965.0, 1.0, 1.0, 1.0, 3965.0, 3965.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.854, -5.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13528, "number_of_timesteps": 178064, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3965, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3966.0, 1.0, 1.0, 1.0, 3966.0, 3966.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.855, -5.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13534, "number_of_timesteps": 178121, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3966, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3967.0, 1.0, 1.0, 1.0, 3967.0, 3967.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.853, -5.838, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13537, "number_of_timesteps": 178150, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3967, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3968.0, 1.0, 1.0, 1.0, 3968.0, 3968.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.855, -5.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13544, "number_of_timesteps": 178218, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3968, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3969.0, 1.0, 1.0, 1.0, 3969.0, 3969.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.704, 0.0, 0.0, 0.0, -5.858, -5.842, 0.0, 0.0, 0.0]}
{"step": 3969, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3970.0, 1.0, 1.0, 1.0, 3970.0, 3970.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.859, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13554, "number_of_timesteps": 178316, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3970, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3971.0, 1.0, 1.0, 1.0, 3971.0, 3971.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.859, -5.842, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13556, "number_of_timesteps": 178335, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3971, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3972.0, 1.0, 1.0, 1.0, 3972.0, 3972.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.861, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13562, "number_of_timesteps": 178390, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3972, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3973.0, 1.0, 1.0, 1.0, 3973.0, 3973.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.861, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13566, "number_of_timesteps": 178430, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3973, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3974.0, 1.0, 1.0, 1.0, 3974.0, 3974.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.703, 0.0, 0.0, 0.0, -5.862, -5.843, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13571, "number_of_timesteps": 178477, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3974, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3975.0, 1.0, 1.0, 1.0, 3975.0, 3975.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.704, 0.0, 0.0, 0.0, -5.862, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13576, "number_of_timesteps": 178524, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3975, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3976.0, 1.0, 1.0, 1.0, 3976.0, 3976.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.703, 0.0, 0.0, 0.0, -5.861, -5.843, 0.0, 0.0, 0.0]}
{"step": 3976, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3977.0, 1.0, 1.0, 1.0, 3977.0, 3977.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.704, 0.0, 0.0, 0.0, -5.862, -5.843, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13584, "number_of_timesteps": 178601, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3977, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3978.0, 1.0, 1.0, 1.0, 3978.0, 3978.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.703, 0.0, 0.0, 0.0, -5.865, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13588, "number_of_timesteps": 178641, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3978, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3979.0, 1.0, 1.0, 1.0, 3979.0, 3979.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.863, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13594, "number_of_timesteps": 178701, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3979, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3980.0, 1.0, 1.0, 1.0, 3980.0, 3980.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.862, -5.843, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13597, "number_of_timesteps": 178731, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3980, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3981.0, 1.0, 1.0, 1.0, 3981.0, 3981.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.699, 0.0, 0.0, 0.0, -5.86, -5.842, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13604, "number_of_timesteps": 178797, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3981, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3982.0, 1.0, 1.0, 1.0, 3982.0, 3982.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.863, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13607, "number_of_timesteps": 178824, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3982, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3983.0, 1.0, 1.0, 1.0, 3983.0, 3983.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.862, -5.843, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13610, "number_of_timesteps": 178853, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3983, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3984.0, 1.0, 1.0, 1.0, 3984.0, 3984.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.862, -5.842, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13617, "number_of_timesteps": 178928, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3984, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3985.0, 1.0, 1.0, 1.0, 3985.0, 3985.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.861, -5.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13618, "number_of_timesteps": 178937, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3985, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3986.0, 1.0, 1.0, 1.0, 3986.0, 3986.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.861, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13622, "number_of_timesteps": 178979, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3986, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3987.0, 1.0, 1.0, 1.0, 3987.0, 3987.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.86, -5.841, 0.0, 0.0, 0.0]}
{"step": 3987, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3988.0, 1.0, 1.0, 1.0, 3988.0, 3988.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.858, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13630, "number_of_timesteps": 179065, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3988, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3989.0, 1.0, 1.0, 1.0, 3989.0, 3989.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.857, -5.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13636, "number_of_timesteps": 179124, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3989, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3990.0, 1.0, 1.0, 1.0, 3990.0, 3990.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.856, -5.838, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13640, "number_of_timesteps": 179165, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3990, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3991.0, 1.0, 1.0, 1.0, 3991.0, 3991.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.854, -5.838, 0.0, 0.0, 0.0]}
{"step": 3991, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3992.0, 1.0, 1.0, 1.0, 3992.0, 3992.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.853, -5.837, 0.0, 0.0, 0.0]}
{"eval_score": 9.5, "number_of_episodes": 13650}
{"number_of_episodes": 13650, "number_of_timesteps": 179258, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3992, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3993.0, 1.0, 1.0, 1.0, 3993.0, 3993.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.856, -5.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13653, "number_of_timesteps": 179285, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3993, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3994.0, 1.0, 1.0, 1.0, 3994.0, 3994.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.859, -5.843, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13660, "number_of_timesteps": 179355, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3994, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3995.0, 1.0, 1.0, 1.0, 3995.0, 3995.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.859, -5.841, 0.0, 0.0, 0.0]}
{"step": 3995, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3996.0, 1.0, 1.0, 1.0, 3996.0, 3996.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.858, -5.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13667, "number_of_timesteps": 179419, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3996, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3997.0, 1.0, 1.0, 1.0, 3997.0, 3997.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.857, -5.839, 0.0, 0.0, 0.0]}
{"step": 3997, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3998.0, 1.0, 1.0, 1.0, 3998.0, 3998.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.855, -5.837, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13677, "number_of_timesteps": 179523, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3998, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 3999.0, 1.0, 1.0, 1.0, 3999.0, 3999.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.854, -5.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13682, "number_of_timesteps": 179570, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 3999, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4000.0, 1.0, 1.0, 1.0, 4000.0, 4000.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.855, -5.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13685, "number_of_timesteps": 179600, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4000, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4001.0, 1.0, 1.0, 1.0, 4001.0, 4001.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.853, -5.835, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13691, "number_of_timesteps": 179663, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4001, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4002.0, 1.0, 1.0, 1.0, 4002.0, 4002.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.855, -5.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13695, "number_of_timesteps": 179702, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4002, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4003.0, 1.0, 1.0, 1.0, 4003.0, 4003.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.858, -5.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13698, "number_of_timesteps": 179731, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4003, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4004.0, 1.0, 1.0, 1.0, 4004.0, 4004.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.857, -5.838, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13703, "number_of_timesteps": 179783, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4004, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4005.0, 1.0, 1.0, 1.0, 4005.0, 4005.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.857, -5.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13708, "number_of_timesteps": 179837, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4005, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4006.0, 1.0, 1.0, 1.0, 4006.0, 4006.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.856, -5.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13713, "number_of_timesteps": 179883, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4006, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4007.0, 1.0, 1.0, 1.0, 4007.0, 4007.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.856, -5.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13717, "number_of_timesteps": 179920, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4007, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4008.0, 1.0, 1.0, 1.0, 4008.0, 4008.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.856, -5.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13722, "number_of_timesteps": 179969, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4008, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4009.0, 1.0, 1.0, 1.0, 4009.0, 4009.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.857, -5.839, 0.0, 0.0, 0.0]}
{"step": 4009, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4010.0, 1.0, 1.0, 1.0, 4010.0, 4010.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.856, -5.837, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13732, "number_of_timesteps": 180067, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4010, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4011.0, 1.0, 1.0, 1.0, 4011.0, 4011.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.856, -5.838, 0.0, 0.0, 0.0]}
{"step": 4011, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4012.0, 1.0, 1.0, 1.0, 4012.0, 4012.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.856, -5.837, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13742, "number_of_timesteps": 180159, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4012, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4013.0, 1.0, 1.0, 1.0, 4013.0, 4013.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.855, -5.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13744, "number_of_timesteps": 180179, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4013, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4014.0, 1.0, 1.0, 1.0, 4014.0, 4014.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.853, -5.836, 0.0, 0.0, 0.0]}
{"step": 4014, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4015.0, 1.0, 1.0, 1.0, 4015.0, 4015.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.852, -5.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13754, "number_of_timesteps": 180276, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4015, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4016.0, 1.0, 1.0, 1.0, 4016.0, 4016.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.851, -5.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13760, "number_of_timesteps": 180334, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4016, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4017.0, 1.0, 1.0, 1.0, 4017.0, 4017.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.852, -5.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13762, "number_of_timesteps": 180359, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4017, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4018.0, 1.0, 1.0, 1.0, 4018.0, 4018.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.85, -5.835, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13767, "number_of_timesteps": 180409, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4018, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4019.0, 1.0, 1.0, 1.0, 4019.0, 4019.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.853, -5.838, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13772, "number_of_timesteps": 180460, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4019, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4020.0, 1.0, 1.0, 1.0, 4020.0, 4020.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.854, -5.836, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13777, "number_of_timesteps": 180506, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4020, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4021.0, 1.0, 1.0, 1.0, 4021.0, 4021.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.857, -5.839, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 13782}
{"number_of_episodes": 13782, "number_of_timesteps": 180554, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4021, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4022.0, 1.0, 1.0, 1.0, 4022.0, 4022.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.855, -5.838, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13786, "number_of_timesteps": 180593, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4022, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4023.0, 1.0, 1.0, 1.0, 4023.0, 4023.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.855, -5.837, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13792, "number_of_timesteps": 180651, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4023, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4024.0, 1.0, 1.0, 1.0, 4024.0, 4024.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.858, -5.841, 0.0, 0.0, 0.0]}
{"step": 4024, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4025.0, 1.0, 1.0, 1.0, 4025.0, 4025.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.86, -5.842, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13802, "number_of_timesteps": 180747, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4025, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4026.0, 1.0, 1.0, 1.0, 4026.0, 4026.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.86, -5.841, 0.0, 0.0, 0.0]}
{"step": 4026, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4027.0, 1.0, 1.0, 1.0, 4027.0, 4027.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.861, -5.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13808, "number_of_timesteps": 180803, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4027, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4028.0, 1.0, 1.0, 1.0, 4028.0, 4028.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.859, -5.838, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13815, "number_of_timesteps": 180877, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4028, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4029.0, 1.0, 1.0, 1.0, 4029.0, 4029.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.696, 0.0, 0.0, 0.0, -5.862, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13817, "number_of_timesteps": 180895, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4029, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4030.0, 1.0, 1.0, 1.0, 4030.0, 4030.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.862, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13822, "number_of_timesteps": 180944, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4030, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4031.0, 1.0, 1.0, 1.0, 4031.0, 4031.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.86, -5.841, 0.0, 0.0, 0.0]}
{"step": 4031, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4032.0, 1.0, 1.0, 1.0, 4032.0, 4032.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.694, 0.0, 0.0, 0.0, -5.862, -5.842, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13831, "number_of_timesteps": 181040, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4032, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4033.0, 1.0, 1.0, 1.0, 4033.0, 4033.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.86, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13833, "number_of_timesteps": 181061, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4033, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4034.0, 1.0, 1.0, 1.0, 4034.0, 4034.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.859, -5.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13841, "number_of_timesteps": 181140, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4034, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4035.0, 1.0, 1.0, 1.0, 4035.0, 4035.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.863, -5.843, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13843, "number_of_timesteps": 181158, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4035, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4036.0, 1.0, 1.0, 1.0, 4036.0, 4036.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.862, -5.842, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13849, "number_of_timesteps": 181213, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4036, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4037.0, 1.0, 1.0, 1.0, 4037.0, 4037.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.862, -5.843, 0.0, 0.0, 0.0]}
{"step": 4037, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4038.0, 1.0, 1.0, 1.0, 4038.0, 4038.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.862, -5.843, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13859, "number_of_timesteps": 181315, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4038, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4039.0, 1.0, 1.0, 1.0, 4039.0, 4039.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.862, -5.843, 0.0, 0.0, 0.0]}
{"step": 4039, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4040.0, 1.0, 1.0, 1.0, 4040.0, 4040.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.692, 0.0, 0.0, 0.0, -5.862, -5.842, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13868, "number_of_timesteps": 181405, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4040, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4041.0, 1.0, 1.0, 1.0, 4041.0, 4041.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.693, 0.0, 0.0, 0.0, -5.86, -5.843, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13869, "number_of_timesteps": 181416, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4041, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4042.0, 1.0, 1.0, 1.0, 4042.0, 4042.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.691, 0.0, 0.0, 0.0, -5.859, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13877, "number_of_timesteps": 181492, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4042, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4043.0, 1.0, 1.0, 1.0, 4043.0, 4043.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.695, 0.0, 0.0, 0.0, -5.862, -5.844, 0.0, 0.0, 0.0]}
{"step": 4043, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4044.0, 1.0, 1.0, 1.0, 4044.0, 4044.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.863, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13887, "number_of_timesteps": 181591, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4044, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4045.0, 1.0, 1.0, 1.0, 4045.0, 4045.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.697, 0.0, 0.0, 0.0, -5.864, -5.846, 0.0, 0.0, 0.0]}
{"step": 4045, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4046.0, 1.0, 1.0, 1.0, 4046.0, 4046.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.698, 0.0, 0.0, 0.0, -5.864, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13896, "number_of_timesteps": 181673, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4046, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4047.0, 1.0, 1.0, 1.0, 4047.0, 4047.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.699, 0.0, 0.0, 0.0, -5.865, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13898, "number_of_timesteps": 181693, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4047, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4048.0, 1.0, 1.0, 1.0, 4048.0, 4048.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.865, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13906, "number_of_timesteps": 181766, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4048, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4049.0, 1.0, 1.0, 1.0, 4049.0, 4049.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.865, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13908, "number_of_timesteps": 181785, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4049, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4050.0, 1.0, 1.0, 1.0, 4050.0, 4050.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.699, 0.0, 0.0, 0.0, -5.864, -5.845, 0.0, 0.0, 0.0]}
{"eval_score": 9.4, "number_of_episodes": 13915}
{"number_of_episodes": 13915, "number_of_timesteps": 181849, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4050, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4051.0, 1.0, 1.0, 1.0, 4051.0, 4051.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.864, -5.843, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13917, "number_of_timesteps": 181872, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4051, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4052.0, 1.0, 1.0, 1.0, 4052.0, 4052.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.699, 0.0, 0.0, 0.0, -5.864, -5.843, 0.0, 0.0, 0.0]}
{"step": 4052, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4053.0, 1.0, 1.0, 1.0, 4053.0, 4053.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.864, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13927, "number_of_timesteps": 181974, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4053, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4054.0, 1.0, 1.0, 1.0, 4054.0, 4054.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.864, -5.842, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13932, "number_of_timesteps": 182022, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4054, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4055.0, 1.0, 1.0, 1.0, 4055.0, 4055.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.863, -5.842, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13937, "number_of_timesteps": 182072, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4055, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4056.0, 1.0, 1.0, 1.0, 4056.0, 4056.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.702, 0.0, 0.0, 0.0, -5.863, -5.842, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13941, "number_of_timesteps": 182107, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4056, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4057.0, 1.0, 1.0, 1.0, 4057.0, 4057.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.862, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13946, "number_of_timesteps": 182158, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4057, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4058.0, 1.0, 1.0, 1.0, 4058.0, 4058.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.861, -5.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13949, "number_of_timesteps": 182187, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4058, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4059.0, 1.0, 1.0, 1.0, 4059.0, 4059.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.861, -5.84, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13955, "number_of_timesteps": 182247, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4059, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4060.0, 1.0, 1.0, 1.0, 4060.0, 4060.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.86, -5.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13959, "number_of_timesteps": 182286, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4060, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4061.0, 1.0, 1.0, 1.0, 4061.0, 4061.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.86, -5.839, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13964, "number_of_timesteps": 182334, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4061, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4062.0, 1.0, 1.0, 1.0, 4062.0, 4062.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.7, 0.0, 0.0, 0.0, -5.864, -5.843, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13969, "number_of_timesteps": 182381, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4062, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4063.0, 1.0, 1.0, 1.0, 4063.0, 4063.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.701, 0.0, 0.0, 0.0, -5.864, -5.841, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13974, "number_of_timesteps": 182428, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4063, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4064.0, 1.0, 1.0, 1.0, 4064.0, 4064.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.704, 0.0, 0.0, 0.0, -5.867, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13978, "number_of_timesteps": 182466, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4064, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4065.0, 1.0, 1.0, 1.0, 4065.0, 4065.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.705, 0.0, 0.0, 0.0, -5.866, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13984, "number_of_timesteps": 182521, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4065, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4066.0, 1.0, 1.0, 1.0, 4066.0, 4066.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.706, 0.0, 0.0, 0.0, -5.866, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13988, "number_of_timesteps": 182561, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4066, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4067.0, 1.0, 1.0, 1.0, 4067.0, 4067.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.706, 0.0, 0.0, 0.0, -5.867, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13993, "number_of_timesteps": 182610, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4067, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4068.0, 1.0, 1.0, 1.0, 4068.0, 4068.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.706, 0.0, 0.0, 0.0, -5.866, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 13998, "number_of_timesteps": 182662, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4068, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4069.0, 1.0, 1.0, 1.0, 4069.0, 4069.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.707, 0.0, 0.0, 0.0, -5.867, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14003, "number_of_timesteps": 182706, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4069, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4070.0, 1.0, 1.0, 1.0, 4070.0, 4070.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.707, 0.0, 0.0, 0.0, -5.867, -5.844, 0.0, 0.0, 0.0]}
{"step": 4070, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4071.0, 1.0, 1.0, 1.0, 4071.0, 4071.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.708, 0.0, 0.0, 0.0, -5.867, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14012, "number_of_timesteps": 182794, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4071, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4072.0, 1.0, 1.0, 1.0, 4072.0, 4072.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.708, 0.0, 0.0, 0.0, -5.867, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14015, "number_of_timesteps": 182824, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4072, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4073.0, 1.0, 1.0, 1.0, 4073.0, 4073.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.868, -5.843, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14020, "number_of_timesteps": 182871, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4073, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4074.0, 1.0, 1.0, 1.0, 4074.0, 4074.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.871, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14025, "number_of_timesteps": 182922, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4074, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4075.0, 1.0, 1.0, 1.0, 4075.0, 4075.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.871, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14030, "number_of_timesteps": 182967, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4075, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4076.0, 1.0, 1.0, 1.0, 4076.0, 4076.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.87, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14034, "number_of_timesteps": 183005, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4076, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4077.0, 1.0, 1.0, 1.0, 4077.0, 4077.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.873, -5.848, 0.0, 0.0, 0.0]}
{"eval_score": 9.5, "number_of_episodes": 14040}
{"number_of_episodes": 14040, "number_of_timesteps": 183061, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4077, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4078.0, 1.0, 1.0, 1.0, 4078.0, 4078.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.872, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14044, "number_of_timesteps": 183098, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4078, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4079.0, 1.0, 1.0, 1.0, 4079.0, 4079.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.872, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14049, "number_of_timesteps": 183145, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4079, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4080.0, 1.0, 1.0, 1.0, 4080.0, 4080.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.872, -5.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14054, "number_of_timesteps": 183192, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4080, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4081.0, 1.0, 1.0, 1.0, 4081.0, 4081.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.875, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14059, "number_of_timesteps": 183239, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4081, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4082.0, 1.0, 1.0, 1.0, 4082.0, 4082.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.874, -5.85, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14063, "number_of_timesteps": 183275, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4082, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4083.0, 1.0, 1.0, 1.0, 4083.0, 4083.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.874, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14069, "number_of_timesteps": 183331, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4083, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4084.0, 1.0, 1.0, 1.0, 4084.0, 4084.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.715, 0.0, 0.0, 0.0, -5.878, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14073, "number_of_timesteps": 183365, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4084, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4085.0, 1.0, 1.0, 1.0, 4085.0, 4085.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.716, 0.0, 0.0, 0.0, -5.878, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14079, "number_of_timesteps": 183424, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4085, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4086.0, 1.0, 1.0, 1.0, 4086.0, 4086.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.715, 0.0, 0.0, 0.0, -5.876, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14082, "number_of_timesteps": 183452, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4086, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4087.0, 1.0, 1.0, 1.0, 4087.0, 4087.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.88, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14088, "number_of_timesteps": 183511, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4087, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4088.0, 1.0, 1.0, 1.0, 4088.0, 4088.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.878, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14092, "number_of_timesteps": 183553, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4088, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4089.0, 1.0, 1.0, 1.0, 4089.0, 4089.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.877, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14097, "number_of_timesteps": 183601, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4089, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4090.0, 1.0, 1.0, 1.0, 4090.0, 4090.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.876, -5.852, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14101, "number_of_timesteps": 183639, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4090, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4091.0, 1.0, 1.0, 1.0, 4091.0, 4091.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.879, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14105, "number_of_timesteps": 183679, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4091, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4092.0, 1.0, 1.0, 1.0, 4092.0, 4092.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.71, 0.0, 0.0, 0.0, -5.88, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14111, "number_of_timesteps": 183740, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4092, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4093.0, 1.0, 1.0, 1.0, 4093.0, 4093.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.878, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14115, "number_of_timesteps": 183777, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4093, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4094.0, 1.0, 1.0, 1.0, 4094.0, 4094.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.877, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14120, "number_of_timesteps": 183823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4094, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4095.0, 1.0, 1.0, 1.0, 4095.0, 4095.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.877, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14124, "number_of_timesteps": 183860, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4095, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4096.0, 1.0, 1.0, 1.0, 4096.0, 4096.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.71, 0.0, 0.0, 0.0, -5.877, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14129, "number_of_timesteps": 183906, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4096, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4097.0, 1.0, 1.0, 1.0, 4097.0, 4097.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.878, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14134, "number_of_timesteps": 183956, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4097, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4098.0, 1.0, 1.0, 1.0, 4098.0, 4098.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.71, 0.0, 0.0, 0.0, -5.876, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14139, "number_of_timesteps": 184005, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4098, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4099.0, 1.0, 1.0, 1.0, 4099.0, 4099.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.88, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14142, "number_of_timesteps": 184034, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4099, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4100.0, 1.0, 1.0, 1.0, 4100.0, 4100.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.88, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14148, "number_of_timesteps": 184095, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4100, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4101.0, 1.0, 1.0, 1.0, 4101.0, 4101.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.708, 0.0, 0.0, 0.0, -5.878, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14152, "number_of_timesteps": 184135, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4101, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4102.0, 1.0, 1.0, 1.0, 4102.0, 4102.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.879, -5.854, 0.0, 0.0, 0.0]}
{"step": 4102, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4103.0, 1.0, 1.0, 1.0, 4103.0, 4103.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.708, 0.0, 0.0, 0.0, -5.878, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14162, "number_of_timesteps": 184228, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4103, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4104.0, 1.0, 1.0, 1.0, 4104.0, 4104.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.878, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14166, "number_of_timesteps": 184262, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4104, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4105.0, 1.0, 1.0, 1.0, 4105.0, 4105.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.708, 0.0, 0.0, 0.0, -5.877, -5.852, 0.0, 0.0, 0.0]}
{"eval_score": 9.4, "number_of_episodes": 14171}
{"number_of_episodes": 14171, "number_of_timesteps": 184312, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4105, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4106.0, 1.0, 1.0, 1.0, 4106.0, 4106.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.708, 0.0, 0.0, 0.0, -5.877, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14176, "number_of_timesteps": 184361, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4106, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4107.0, 1.0, 1.0, 1.0, 4107.0, 4107.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.707, 0.0, 0.0, 0.0, -5.876, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14180, "number_of_timesteps": 184397, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4107, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4108.0, 1.0, 1.0, 1.0, 4108.0, 4108.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.707, 0.0, 0.0, 0.0, -5.876, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14184, "number_of_timesteps": 184437, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4108, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4109.0, 1.0, 1.0, 1.0, 4109.0, 4109.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.706, 0.0, 0.0, 0.0, -5.874, -5.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14189, "number_of_timesteps": 184487, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4109, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4110.0, 1.0, 1.0, 1.0, 4110.0, 4110.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.707, 0.0, 0.0, 0.0, -5.875, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14194, "number_of_timesteps": 184539, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4110, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4111.0, 1.0, 1.0, 1.0, 4111.0, 4111.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.707, 0.0, 0.0, 0.0, -5.875, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14199, "number_of_timesteps": 184588, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4111, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4112.0, 1.0, 1.0, 1.0, 4112.0, 4112.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.878, -5.85, 0.0, 0.0, 0.0]}
{"step": 4112, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4113.0, 1.0, 1.0, 1.0, 4113.0, 4113.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.71, 0.0, 0.0, 0.0, -5.877, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14207, "number_of_timesteps": 184667, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4113, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4114.0, 1.0, 1.0, 1.0, 4114.0, 4114.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.88, -5.852, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14213, "number_of_timesteps": 184727, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4114, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4115.0, 1.0, 1.0, 1.0, 4115.0, 4115.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.88, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14216, "number_of_timesteps": 184757, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4115, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4116.0, 1.0, 1.0, 1.0, 4116.0, 4116.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.708, 0.0, 0.0, 0.0, -5.879, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14222, "number_of_timesteps": 184817, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4116, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4117.0, 1.0, 1.0, 1.0, 4117.0, 4117.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.879, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14225, "number_of_timesteps": 184850, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4117, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4118.0, 1.0, 1.0, 1.0, 4118.0, 4118.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.882, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14232, "number_of_timesteps": 184914, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4118, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4119.0, 1.0, 1.0, 1.0, 4119.0, 4119.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.881, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14235, "number_of_timesteps": 184942, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4119, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4120.0, 1.0, 1.0, 1.0, 4120.0, 4120.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.883, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14242, "number_of_timesteps": 185008, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4120, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4121.0, 1.0, 1.0, 1.0, 4121.0, 4121.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.882, -5.852, 0.0, 0.0, 0.0]}
{"step": 4121, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4122.0, 1.0, 1.0, 1.0, 4122.0, 4122.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.88, -5.851, 0.0, 0.0, 0.0]}
{"step": 4122, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4123.0, 1.0, 1.0, 1.0, 4123.0, 4123.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.71, 0.0, 0.0, 0.0, -5.879, -5.85, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14253, "number_of_timesteps": 185123, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4123, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4124.0, 1.0, 1.0, 1.0, 4124.0, 4124.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.879, -5.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14258, "number_of_timesteps": 185171, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4124, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4125.0, 1.0, 1.0, 1.0, 4125.0, 4125.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.88, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14263, "number_of_timesteps": 185216, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4125, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4126.0, 1.0, 1.0, 1.0, 4126.0, 4126.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.71, 0.0, 0.0, 0.0, -5.878, -5.847, 0.0, 0.0, 0.0]}
{"step": 4126, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4127.0, 1.0, 1.0, 1.0, 4127.0, 4127.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.709, 0.0, 0.0, 0.0, -5.877, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14271, "number_of_timesteps": 185294, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4127, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4128.0, 1.0, 1.0, 1.0, 4128.0, 4128.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.88, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14276, "number_of_timesteps": 185347, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4128, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4129.0, 1.0, 1.0, 1.0, 4129.0, 4129.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.88, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14280, "number_of_timesteps": 185384, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4129, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4130.0, 1.0, 1.0, 1.0, 4130.0, 4130.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.883, -5.852, 0.0, 0.0, 0.0]}
{"step": 4130, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4131.0, 1.0, 1.0, 1.0, 4131.0, 4131.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.884, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14290, "number_of_timesteps": 185480, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4131, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4132.0, 1.0, 1.0, 1.0, 4132.0, 4132.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.884, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14295, "number_of_timesteps": 185528, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4132, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4133.0, 1.0, 1.0, 1.0, 4133.0, 4133.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.884, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14299, "number_of_timesteps": 185566, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4133, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4134.0, 1.0, 1.0, 1.0, 4134.0, 4134.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.884, -5.853, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 14304}
{"number_of_episodes": 14304, "number_of_timesteps": 185616, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4134, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4135.0, 1.0, 1.0, 1.0, 4135.0, 4135.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.884, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14309, "number_of_timesteps": 185665, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4135, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4136.0, 1.0, 1.0, 1.0, 4136.0, 4136.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.715, 0.0, 0.0, 0.0, -5.883, -5.852, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14313, "number_of_timesteps": 185702, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4136, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4137.0, 1.0, 1.0, 1.0, 4137.0, 4137.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.886, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14318, "number_of_timesteps": 185751, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4137, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4138.0, 1.0, 1.0, 1.0, 4138.0, 4138.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.885, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14322, "number_of_timesteps": 185790, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4138, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4139.0, 1.0, 1.0, 1.0, 4139.0, 4139.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.885, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14328, "number_of_timesteps": 185846, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4139, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4140.0, 1.0, 1.0, 1.0, 4140.0, 4140.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.884, -5.853, 0.0, 0.0, 0.0]}
{"step": 4140, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4141.0, 1.0, 1.0, 1.0, 4141.0, 4141.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.882, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14335, "number_of_timesteps": 185915, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4141, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4142.0, 1.0, 1.0, 1.0, 4142.0, 4142.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.882, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14340, "number_of_timesteps": 185970, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4142, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4143.0, 1.0, 1.0, 1.0, 4143.0, 4143.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.881, -5.85, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14345, "number_of_timesteps": 186016, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4143, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4144.0, 1.0, 1.0, 1.0, 4144.0, 4144.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.881, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14350, "number_of_timesteps": 186062, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4144, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4145.0, 1.0, 1.0, 1.0, 4145.0, 4145.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.71, 0.0, 0.0, 0.0, -5.88, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14354, "number_of_timesteps": 186099, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4145, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4146.0, 1.0, 1.0, 1.0, 4146.0, 4146.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.883, -5.85, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14359, "number_of_timesteps": 186147, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4146, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4147.0, 1.0, 1.0, 1.0, 4147.0, 4147.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.881, -5.849, 0.0, 0.0, 0.0]}
{"step": 4147, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4148.0, 1.0, 1.0, 1.0, 4148.0, 4148.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.88, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14369, "number_of_timesteps": 186243, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4148, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4149.0, 1.0, 1.0, 1.0, 4149.0, 4149.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.71, 0.0, 0.0, 0.0, -5.878, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14373, "number_of_timesteps": 186279, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4149, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4150.0, 1.0, 1.0, 1.0, 4150.0, 4150.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.71, 0.0, 0.0, 0.0, -5.879, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14379, "number_of_timesteps": 186337, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4150, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4151.0, 1.0, 1.0, 1.0, 4151.0, 4151.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.877, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14383, "number_of_timesteps": 186376, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4151, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4152.0, 1.0, 1.0, 1.0, 4152.0, 4152.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.878, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14387, "number_of_timesteps": 186414, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4152, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4153.0, 1.0, 1.0, 1.0, 4153.0, 4153.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.877, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14393, "number_of_timesteps": 186475, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4153, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4154.0, 1.0, 1.0, 1.0, 4154.0, 4154.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.71, 0.0, 0.0, 0.0, -5.878, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14397, "number_of_timesteps": 186511, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4154, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4155.0, 1.0, 1.0, 1.0, 4155.0, 4155.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.713, 0.0, 0.0, 0.0, -5.88, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14401, "number_of_timesteps": 186547, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4155, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4156.0, 1.0, 1.0, 1.0, 4156.0, 4156.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.879, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14405, "number_of_timesteps": 186587, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4156, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4157.0, 1.0, 1.0, 1.0, 4157.0, 4157.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.711, 0.0, 0.0, 0.0, -5.878, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14411, "number_of_timesteps": 186648, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4157, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4158.0, 1.0, 1.0, 1.0, 4158.0, 4158.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.712, 0.0, 0.0, 0.0, -5.878, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14414, "number_of_timesteps": 186678, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4158, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4159.0, 1.0, 1.0, 1.0, 4159.0, 4159.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.88, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14419, "number_of_timesteps": 186727, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4159, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4160.0, 1.0, 1.0, 1.0, 4160.0, 4160.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.88, -5.846, 0.0, 0.0, 0.0]}
{"step": 4160, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4161.0, 1.0, 1.0, 1.0, 4161.0, 4161.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.88, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14429, "number_of_timesteps": 186825, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4161, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4162.0, 1.0, 1.0, 1.0, 4162.0, 4162.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.718, 0.0, 0.0, 0.0, -5.883, -5.849, 0.0, 0.0, 0.0]}
{"eval_score": 9.8, "number_of_episodes": 14432}
{"number_of_episodes": 14432, "number_of_timesteps": 186853, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4162, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4163.0, 1.0, 1.0, 1.0, 4163.0, 4163.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.718, 0.0, 0.0, 0.0, -5.881, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14437, "number_of_timesteps": 186904, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4163, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4164.0, 1.0, 1.0, 1.0, 4164.0, 4164.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.717, 0.0, 0.0, 0.0, -5.883, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14442, "number_of_timesteps": 186957, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4164, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4165.0, 1.0, 1.0, 1.0, 4165.0, 4165.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.718, 0.0, 0.0, 0.0, -5.884, -5.852, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14446, "number_of_timesteps": 186991, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4165, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4166.0, 1.0, 1.0, 1.0, 4166.0, 4166.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.717, 0.0, 0.0, 0.0, -5.882, -5.85, 0.0, 0.0, 0.0]}
{"step": 4166, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4167.0, 1.0, 1.0, 1.0, 4167.0, 4167.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.716, 0.0, 0.0, 0.0, -5.881, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14456, "number_of_timesteps": 187088, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4167, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4168.0, 1.0, 1.0, 1.0, 4168.0, 4168.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.715, 0.0, 0.0, 0.0, -5.879, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14461, "number_of_timesteps": 187136, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4168, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4169.0, 1.0, 1.0, 1.0, 4169.0, 4169.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.882, -5.85, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14464, "number_of_timesteps": 187163, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4169, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4170.0, 1.0, 1.0, 1.0, 4170.0, 4170.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.717, 0.0, 0.0, 0.0, -5.885, -5.853, 0.0, 0.0, 0.0]}
{"step": 4170, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4171.0, 1.0, 1.0, 1.0, 4171.0, 4171.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.889, -5.857, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14473, "number_of_timesteps": 187256, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4171, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4172.0, 1.0, 1.0, 1.0, 4172.0, 4172.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.889, -5.857, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14478, "number_of_timesteps": 187305, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4172, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4173.0, 1.0, 1.0, 1.0, 4173.0, 4173.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.72, 0.0, 0.0, 0.0, -5.892, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14482, "number_of_timesteps": 187343, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4173, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4174.0, 1.0, 1.0, 1.0, 4174.0, 4174.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.892, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14487, "number_of_timesteps": 187392, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4174, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4175.0, 1.0, 1.0, 1.0, 4175.0, 4175.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.719, 0.0, 0.0, 0.0, -5.891, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14492, "number_of_timesteps": 187440, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4175, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4176.0, 1.0, 1.0, 1.0, 4176.0, 4176.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.72, 0.0, 0.0, 0.0, -5.891, -5.859, 0.0, 0.0, 0.0]}
{"step": 4176, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4177.0, 1.0, 1.0, 1.0, 4177.0, 4177.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.892, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14501, "number_of_timesteps": 187529, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4177, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4178.0, 1.0, 1.0, 1.0, 4178.0, 4178.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.72, 0.0, 0.0, 0.0, -5.891, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14506, "number_of_timesteps": 187581, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4178, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4179.0, 1.0, 1.0, 1.0, 4179.0, 4179.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.724, 0.0, 0.0, 0.0, -5.894, -5.862, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14508, "number_of_timesteps": 187601, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4179, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4180.0, 1.0, 1.0, 1.0, 4180.0, 4180.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.724, 0.0, 0.0, 0.0, -5.894, -5.861, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14516, "number_of_timesteps": 187682, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4180, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4181.0, 1.0, 1.0, 1.0, 4181.0, 4181.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.723, 0.0, 0.0, 0.0, -5.892, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14518, "number_of_timesteps": 187699, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4181, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4182.0, 1.0, 1.0, 1.0, 4182.0, 4182.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.723, 0.0, 0.0, 0.0, -5.892, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14526, "number_of_timesteps": 187772, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4182, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4183.0, 1.0, 1.0, 1.0, 4183.0, 4183.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.722, 0.0, 0.0, 0.0, -5.891, -5.858, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14528, "number_of_timesteps": 187791, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4183, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4184.0, 1.0, 1.0, 1.0, 4184.0, 4184.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.72, 0.0, 0.0, 0.0, -5.889, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14535, "number_of_timesteps": 187856, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4184, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4185.0, 1.0, 1.0, 1.0, 4185.0, 4185.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.889, -5.856, 0.0, 0.0, 0.0]}
{"step": 4185, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4186.0, 1.0, 1.0, 1.0, 4186.0, 4186.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.72, 0.0, 0.0, 0.0, -5.888, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14543, "number_of_timesteps": 187933, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4186, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4187.0, 1.0, 1.0, 1.0, 4187.0, 4187.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.887, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14547, "number_of_timesteps": 187974, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4187, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4188.0, 1.0, 1.0, 1.0, 4188.0, 4188.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.887, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14551, "number_of_timesteps": 188012, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4188, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4189.0, 1.0, 1.0, 1.0, 4189.0, 4189.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.72, 0.0, 0.0, 0.0, -5.886, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14555, "number_of_timesteps": 188057, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4189, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4190.0, 1.0, 1.0, 1.0, 4190.0, 4190.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.886, -5.853, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 14561}
{"number_of_episodes": 14561, "number_of_timesteps": 188116, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4190, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4191.0, 1.0, 1.0, 1.0, 4191.0, 4191.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.724, 0.0, 0.0, 0.0, -5.889, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14563, "number_of_timesteps": 188135, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4191, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4192.0, 1.0, 1.0, 1.0, 4192.0, 4192.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.723, 0.0, 0.0, 0.0, -5.892, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14568, "number_of_timesteps": 188186, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4192, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4193.0, 1.0, 1.0, 1.0, 4193.0, 4193.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.723, 0.0, 0.0, 0.0, -5.892, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14573, "number_of_timesteps": 188239, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4193, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4194.0, 1.0, 1.0, 1.0, 4194.0, 4194.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.727, 0.0, 0.0, 0.0, -5.895, -5.863, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14577, "number_of_timesteps": 188275, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4194, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4195.0, 1.0, 1.0, 1.0, 4195.0, 4195.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.728, 0.0, 0.0, 0.0, -5.896, -5.863, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14582, "number_of_timesteps": 188324, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4195, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4196.0, 1.0, 1.0, 1.0, 4196.0, 4196.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.727, 0.0, 0.0, 0.0, -5.899, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14586, "number_of_timesteps": 188365, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4196, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4197.0, 1.0, 1.0, 1.0, 4197.0, 4197.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.725, 0.0, 0.0, 0.0, -5.897, -5.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14591, "number_of_timesteps": 188417, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4197, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4198.0, 1.0, 1.0, 1.0, 4198.0, 4198.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.726, 0.0, 0.0, 0.0, -5.898, -5.863, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14596, "number_of_timesteps": 188467, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4198, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4199.0, 1.0, 1.0, 1.0, 4199.0, 4199.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.729, 0.0, 0.0, 0.0, -5.901, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14600, "number_of_timesteps": 188505, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4199, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4200.0, 1.0, 1.0, 1.0, 4200.0, 4200.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.728, 0.0, 0.0, 0.0, -5.899, -5.865, 0.0, 0.0, 0.0]}
{"step": 4200, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4201.0, 1.0, 1.0, 1.0, 4201.0, 4201.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.727, 0.0, 0.0, 0.0, -5.898, -5.863, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14610, "number_of_timesteps": 188600, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4201, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4202.0, 1.0, 1.0, 1.0, 4202.0, 4202.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.729, 0.0, 0.0, 0.0, -5.899, -5.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14616, "number_of_timesteps": 188655, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4202, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4203.0, 1.0, 1.0, 1.0, 4203.0, 4203.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.727, 0.0, 0.0, 0.0, -5.9, -5.865, 0.0, 0.0, 0.0]}
{"step": 4203, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4204.0, 1.0, 1.0, 1.0, 4204.0, 4204.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.728, 0.0, 0.0, 0.0, -5.9, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14625, "number_of_timesteps": 188742, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4204, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4205.0, 1.0, 1.0, 1.0, 4205.0, 4205.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.729, 0.0, 0.0, 0.0, -5.901, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14629, "number_of_timesteps": 188781, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4205, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4206.0, 1.0, 1.0, 1.0, 4206.0, 4206.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.727, 0.0, 0.0, 0.0, -5.899, -5.865, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14633, "number_of_timesteps": 188818, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4206, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4207.0, 1.0, 1.0, 1.0, 4207.0, 4207.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.726, 0.0, 0.0, 0.0, -5.898, -5.863, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14638, "number_of_timesteps": 188869, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4207, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4208.0, 1.0, 1.0, 1.0, 4208.0, 4208.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.727, 0.0, 0.0, 0.0, -5.898, -5.862, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14643, "number_of_timesteps": 188916, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4208, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4209.0, 1.0, 1.0, 1.0, 4209.0, 4209.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.726, 0.0, 0.0, 0.0, -5.897, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14647, "number_of_timesteps": 188953, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4209, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4210.0, 1.0, 1.0, 1.0, 4210.0, 4210.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.725, 0.0, 0.0, 0.0, -5.9, -5.863, 0.0, 0.0, 0.0]}
{"step": 4210, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4211.0, 1.0, 1.0, 1.0, 4211.0, 4211.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.724, 0.0, 0.0, 0.0, -5.9, -5.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14657, "number_of_timesteps": 189052, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4211, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4212.0, 1.0, 1.0, 1.0, 4212.0, 4212.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.722, 0.0, 0.0, 0.0, -5.899, -5.862, 0.0, 0.0, 0.0]}
{"step": 4212, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4213.0, 1.0, 1.0, 1.0, 4213.0, 4213.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.897, -5.861, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14667, "number_of_timesteps": 189146, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4213, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4214.0, 1.0, 1.0, 1.0, 4214.0, 4214.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.72, 0.0, 0.0, 0.0, -5.896, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14671, "number_of_timesteps": 189181, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4214, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4215.0, 1.0, 1.0, 1.0, 4215.0, 4215.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.896, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14677, "number_of_timesteps": 189240, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4215, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4216.0, 1.0, 1.0, 1.0, 4216.0, 4216.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.896, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14680, "number_of_timesteps": 189269, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4216, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4217.0, 1.0, 1.0, 1.0, 4217.0, 4217.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.72, 0.0, 0.0, 0.0, -5.894, -5.858, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14685, "number_of_timesteps": 189318, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4217, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4218.0, 1.0, 1.0, 1.0, 4218.0, 4218.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.719, 0.0, 0.0, 0.0, -5.893, -5.857, 0.0, 0.0, 0.0]}
{"eval_score": 9.2, "number_of_episodes": 14690}
{"number_of_episodes": 14690, "number_of_timesteps": 189368, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4218, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4219.0, 1.0, 1.0, 1.0, 4219.0, 4219.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.718, 0.0, 0.0, 0.0, -5.892, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14695, "number_of_timesteps": 189412, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4219, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4220.0, 1.0, 1.0, 1.0, 4220.0, 4220.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.718, 0.0, 0.0, 0.0, -5.89, -5.856, 0.0, 0.0, 0.0]}
{"step": 4220, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4221.0, 1.0, 1.0, 1.0, 4221.0, 4221.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.717, 0.0, 0.0, 0.0, -5.889, -5.854, 0.0, 0.0, 0.0]}
{"step": 4221, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4222.0, 1.0, 1.0, 1.0, 4222.0, 4222.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.718, 0.0, 0.0, 0.0, -5.887, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14709, "number_of_timesteps": 189548, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4222, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4223.0, 1.0, 1.0, 1.0, 4223.0, 4223.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.717, 0.0, 0.0, 0.0, -5.886, -5.853, 0.0, 0.0, 0.0]}
{"step": 4223, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4224.0, 1.0, 1.0, 1.0, 4224.0, 4224.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.716, 0.0, 0.0, 0.0, -5.885, -5.852, 0.0, 0.0, 0.0]}
{"step": 4224, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4225.0, 1.0, 1.0, 1.0, 4225.0, 4225.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.883, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14723, "number_of_timesteps": 189684, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4225, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4226.0, 1.0, 1.0, 1.0, 4226.0, 4226.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.715, 0.0, 0.0, 0.0, -5.882, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14726, "number_of_timesteps": 189715, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4226, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4227.0, 1.0, 1.0, 1.0, 4227.0, 4227.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.716, 0.0, 0.0, 0.0, -5.882, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14733, "number_of_timesteps": 189782, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4227, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4228.0, 1.0, 1.0, 1.0, 4228.0, 4228.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.717, 0.0, 0.0, 0.0, -5.883, -5.852, 0.0, 0.0, 0.0]}
{"step": 4228, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4229.0, 1.0, 1.0, 1.0, 4229.0, 4229.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.716, 0.0, 0.0, 0.0, -5.882, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14740, "number_of_timesteps": 189856, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4229, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4230.0, 1.0, 1.0, 1.0, 4230.0, 4230.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.715, 0.0, 0.0, 0.0, -5.886, -5.855, 0.0, 0.0, 0.0]}
{"step": 4230, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4231.0, 1.0, 1.0, 1.0, 4231.0, 4231.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.714, 0.0, 0.0, 0.0, -5.886, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14748, "number_of_timesteps": 189935, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4231, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4232.0, 1.0, 1.0, 1.0, 4232.0, 4232.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.715, 0.0, 0.0, 0.0, -5.886, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14752, "number_of_timesteps": 189975, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4232, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4233.0, 1.0, 1.0, 1.0, 4233.0, 4233.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.716, 0.0, 0.0, 0.0, -5.886, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14758, "number_of_timesteps": 190032, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4233, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4234.0, 1.0, 1.0, 1.0, 4234.0, 4234.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.719, 0.0, 0.0, 0.0, -5.89, -5.859, 0.0, 0.0, 0.0]}
{"step": 4234, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4235.0, 1.0, 1.0, 1.0, 4235.0, 4235.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.891, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14767, "number_of_timesteps": 190120, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4235, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4236.0, 1.0, 1.0, 1.0, 4236.0, 4236.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.891, -5.86, 0.0, 0.0, 0.0]}
{"step": 4236, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4237.0, 1.0, 1.0, 1.0, 4237.0, 4237.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.891, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14775, "number_of_timesteps": 190200, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4237, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4238.0, 1.0, 1.0, 1.0, 4238.0, 4238.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.722, 0.0, 0.0, 0.0, -5.89, -5.861, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14779, "number_of_timesteps": 190244, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4238, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4239.0, 1.0, 1.0, 1.0, 4239.0, 4239.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.723, 0.0, 0.0, 0.0, -5.89, -5.861, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14785, "number_of_timesteps": 190299, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4239, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4240.0, 1.0, 1.0, 1.0, 4240.0, 4240.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.893, -5.864, 0.0, 0.0, 0.0]}
{"step": 4240, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4241.0, 1.0, 1.0, 1.0, 4241.0, 4241.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.72, 0.0, 0.0, 0.0, -5.895, -5.865, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14795, "number_of_timesteps": 190392, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4241, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4242.0, 1.0, 1.0, 1.0, 4242.0, 4242.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.893, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14798, "number_of_timesteps": 190418, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4242, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4243.0, 1.0, 1.0, 1.0, 4243.0, 4243.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.722, 0.0, 0.0, 0.0, -5.894, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14803, "number_of_timesteps": 190468, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4243, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4244.0, 1.0, 1.0, 1.0, 4244.0, 4244.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.722, 0.0, 0.0, 0.0, -5.894, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14807, "number_of_timesteps": 190509, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4244, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4245.0, 1.0, 1.0, 1.0, 4245.0, 4245.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.897, -5.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14810, "number_of_timesteps": 190540, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4245, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4246.0, 1.0, 1.0, 1.0, 4246.0, 4246.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.723, 0.0, 0.0, 0.0, -5.896, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14817, "number_of_timesteps": 190610, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4246, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4247.0, 1.0, 1.0, 1.0, 4247.0, 4247.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.722, 0.0, 0.0, 0.0, -5.894, -5.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14819, "number_of_timesteps": 190629, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4247, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4248.0, 1.0, 1.0, 1.0, 4248.0, 4248.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.72, 0.0, 0.0, 0.0, -5.893, -5.868, 0.0, 0.0, 0.0]}
{"eval_score": 10.0, "number_of_episodes": 14826}
{"number_of_episodes": 14826, "number_of_timesteps": 190703, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4248, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4249.0, 1.0, 1.0, 1.0, 4249.0, 4249.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.893, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14829, "number_of_timesteps": 190734, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4249, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4250.0, 1.0, 1.0, 1.0, 4250.0, 4250.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.722, 0.0, 0.0, 0.0, -5.893, -5.867, 0.0, 0.0, 0.0]}
{"step": 4250, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4251.0, 1.0, 1.0, 1.0, 4251.0, 4251.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.721, 0.0, 0.0, 0.0, -5.893, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14839, "number_of_timesteps": 190831, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4251, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4252.0, 1.0, 1.0, 1.0, 4252.0, 4252.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.72, 0.0, 0.0, 0.0, -5.895, -5.868, 0.0, 0.0, 0.0]}
{"step": 4252, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4253.0, 1.0, 1.0, 1.0, 4253.0, 4253.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.719, 0.0, 0.0, 0.0, -5.898, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14847, "number_of_timesteps": 190909, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4253, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4254.0, 1.0, 1.0, 1.0, 4254.0, 4254.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.722, 0.0, 0.0, 0.0, -5.901, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14851, "number_of_timesteps": 190953, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4254, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4255.0, 1.0, 1.0, 1.0, 4255.0, 4255.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.723, 0.0, 0.0, 0.0, -5.901, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14857, "number_of_timesteps": 191012, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4255, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4256.0, 1.0, 1.0, 1.0, 4256.0, 4256.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.723, 0.0, 0.0, 0.0, -5.902, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14860, "number_of_timesteps": 191040, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4256, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4257.0, 1.0, 1.0, 1.0, 4257.0, 4257.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.724, 0.0, 0.0, 0.0, -5.9, -5.873, 0.0, 0.0, 0.0]}
{"step": 4257, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4258.0, 1.0, 1.0, 1.0, 4258.0, 4258.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.724, 0.0, 0.0, 0.0, -5.899, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14870, "number_of_timesteps": 191139, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4258, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4259.0, 1.0, 1.0, 1.0, 4259.0, 4259.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.724, 0.0, 0.0, 0.0, -5.899, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14874, "number_of_timesteps": 191177, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4259, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4260.0, 1.0, 1.0, 1.0, 4260.0, 4260.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.723, 0.0, 0.0, 0.0, -5.897, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14879, "number_of_timesteps": 191227, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4260, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4261.0, 1.0, 1.0, 1.0, 4261.0, 4261.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.723, 0.0, 0.0, 0.0, -5.898, -5.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14883, "number_of_timesteps": 191265, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4261, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4262.0, 1.0, 1.0, 1.0, 4262.0, 4262.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.727, 0.0, 0.0, 0.0, -5.901, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14889, "number_of_timesteps": 191325, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4262, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4263.0, 1.0, 1.0, 1.0, 4263.0, 4263.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.727, 0.0, 0.0, 0.0, -5.901, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14893, "number_of_timesteps": 191362, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4263, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4264.0, 1.0, 1.0, 1.0, 4264.0, 4264.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.73, 0.0, 0.0, 0.0, -5.904, -5.874, 0.0, 0.0, 0.0]}
{"step": 4264, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4265.0, 1.0, 1.0, 1.0, 4265.0, 4265.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.907, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14902, "number_of_timesteps": 191443, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4265, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4266.0, 1.0, 1.0, 1.0, 4266.0, 4266.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.906, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14907, "number_of_timesteps": 191491, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4266, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4267.0, 1.0, 1.0, 1.0, 4267.0, 4267.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.905, -5.876, 0.0, 0.0, 0.0]}
{"step": 4267, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4268.0, 1.0, 1.0, 1.0, 4268.0, 4268.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.903, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14914, "number_of_timesteps": 191564, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4268, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4269.0, 1.0, 1.0, 1.0, 4269.0, 4269.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.903, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14920, "number_of_timesteps": 191630, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4269, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4270.0, 1.0, 1.0, 1.0, 4270.0, 4270.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.903, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14924, "number_of_timesteps": 191668, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4270, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4271.0, 1.0, 1.0, 1.0, 4271.0, 4271.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.902, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14927, "number_of_timesteps": 191694, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4271, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4272.0, 1.0, 1.0, 1.0, 4272.0, 4272.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.902, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14933, "number_of_timesteps": 191760, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4272, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4273.0, 1.0, 1.0, 1.0, 4273.0, 4273.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.902, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14937, "number_of_timesteps": 191800, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4273, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4274.0, 1.0, 1.0, 1.0, 4274.0, 4274.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.901, -5.872, 0.0, 0.0, 0.0]}
{"step": 4274, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4275.0, 1.0, 1.0, 1.0, 4275.0, 4275.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.73, 0.0, 0.0, 0.0, -5.9, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14946, "number_of_timesteps": 191891, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4275, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4276.0, 1.0, 1.0, 1.0, 4276.0, 4276.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.9, -5.87, 0.0, 0.0, 0.0]}
{"eval_score": 10.4, "number_of_episodes": 14950}
{"number_of_episodes": 14950, "number_of_timesteps": 191930, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4276, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4277.0, 1.0, 1.0, 1.0, 4277.0, 4277.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.901, -5.87, 0.0, 0.0, 0.0]}
{"step": 4277, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4278.0, 1.0, 1.0, 1.0, 4278.0, 4278.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.901, -5.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14959, "number_of_timesteps": 192021, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4278, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4279.0, 1.0, 1.0, 1.0, 4279.0, 4279.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.9, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14965, "number_of_timesteps": 192079, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4279, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4280.0, 1.0, 1.0, 1.0, 4280.0, 4280.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.898, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14968, "number_of_timesteps": 192108, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4280, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4281.0, 1.0, 1.0, 1.0, 4281.0, 4281.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.898, -5.865, 0.0, 0.0, 0.0]}
{"step": 4281, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4282.0, 1.0, 1.0, 1.0, 4282.0, 4282.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.898, -5.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14978, "number_of_timesteps": 192204, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4282, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4283.0, 1.0, 1.0, 1.0, 4283.0, 4283.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.9, -5.865, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14985, "number_of_timesteps": 192271, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4283, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4284.0, 1.0, 1.0, 1.0, 4284.0, 4284.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.902, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14986, "number_of_timesteps": 192280, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4284, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4285.0, 1.0, 1.0, 1.0, 4285.0, 4285.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.901, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14994, "number_of_timesteps": 192360, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4285, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4286.0, 1.0, 1.0, 1.0, 4286.0, 4286.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.901, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 14996, "number_of_timesteps": 192380, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4286, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4287.0, 1.0, 1.0, 1.0, 4287.0, 4287.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.901, -5.867, 0.0, 0.0, 0.0]}
{"step": 4287, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4288.0, 1.0, 1.0, 1.0, 4288.0, 4288.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.901, -5.865, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15004, "number_of_timesteps": 192463, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4288, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4289.0, 1.0, 1.0, 1.0, 4289.0, 4289.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.9, -5.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15012, "number_of_timesteps": 192538, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4289, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4290.0, 1.0, 1.0, 1.0, 4290.0, 4290.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.9, -5.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15013, "number_of_timesteps": 192548, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4290, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4291.0, 1.0, 1.0, 1.0, 4291.0, 4291.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.9, -5.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15021, "number_of_timesteps": 192623, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4291, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4292.0, 1.0, 1.0, 1.0, 4292.0, 4292.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.899, -5.863, 0.0, 0.0, 0.0]}
{"step": 4292, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4293.0, 1.0, 1.0, 1.0, 4293.0, 4293.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.73, 0.0, 0.0, 0.0, -5.897, -5.861, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15027, "number_of_timesteps": 192681, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4293, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4294.0, 1.0, 1.0, 1.0, 4294.0, 4294.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.898, -5.862, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15033, "number_of_timesteps": 192746, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4294, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4295.0, 1.0, 1.0, 1.0, 4295.0, 4295.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.73, 0.0, 0.0, 0.0, -5.896, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15037, "number_of_timesteps": 192784, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4295, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4296.0, 1.0, 1.0, 1.0, 4296.0, 4296.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.897, -5.861, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15043, "number_of_timesteps": 192839, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4296, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4297.0, 1.0, 1.0, 1.0, 4297.0, 4297.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.896, -5.861, 0.0, 0.0, 0.0]}
{"step": 4297, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4298.0, 1.0, 1.0, 1.0, 4298.0, 4298.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.894, -5.861, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15051, "number_of_timesteps": 192910, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4298, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4299.0, 1.0, 1.0, 1.0, 4299.0, 4299.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.895, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15055, "number_of_timesteps": 192952, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4299, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4300.0, 1.0, 1.0, 1.0, 4300.0, 4300.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.893, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15059, "number_of_timesteps": 192992, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4300, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4301.0, 1.0, 1.0, 1.0, 4301.0, 4301.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.894, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15065, "number_of_timesteps": 193055, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4301, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4302.0, 1.0, 1.0, 1.0, 4302.0, 4302.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.892, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15069, "number_of_timesteps": 193093, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4302, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4303.0, 1.0, 1.0, 1.0, 4303.0, 4303.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.893, -5.859, 0.0, 0.0, 0.0]}
{"step": 4303, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4304.0, 1.0, 1.0, 1.0, 4304.0, 4304.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.891, -5.858, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15078, "number_of_timesteps": 193184, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4304, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4305.0, 1.0, 1.0, 1.0, 4305.0, 4305.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.892, -5.858, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 15082}
{"number_of_episodes": 15082, "number_of_timesteps": 193223, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4305, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4306.0, 1.0, 1.0, 1.0, 4306.0, 4306.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.892, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15086, "number_of_timesteps": 193263, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4306, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4307.0, 1.0, 1.0, 1.0, 4307.0, 4307.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.891, -5.858, 0.0, 0.0, 0.0]}
{"step": 4307, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4308.0, 1.0, 1.0, 1.0, 4308.0, 4308.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.89, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15096, "number_of_timesteps": 193361, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4308, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4309.0, 1.0, 1.0, 1.0, 4309.0, 4309.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.73, 0.0, 0.0, 0.0, -5.888, -5.855, 0.0, 0.0, 0.0]}
{"step": 4309, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4310.0, 1.0, 1.0, 1.0, 4310.0, 4310.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.729, 0.0, 0.0, 0.0, -5.887, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15105, "number_of_timesteps": 193447, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4310, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4311.0, 1.0, 1.0, 1.0, 4311.0, 4311.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.89, -5.857, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15112, "number_of_timesteps": 193512, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4311, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4312.0, 1.0, 1.0, 1.0, 4312.0, 4312.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.891, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15114, "number_of_timesteps": 193532, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4312, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4313.0, 1.0, 1.0, 1.0, 4313.0, 4313.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.889, -5.854, 0.0, 0.0, 0.0]}
{"step": 4313, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4314.0, 1.0, 1.0, 1.0, 4314.0, 4314.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.888, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15124, "number_of_timesteps": 193624, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4314, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4315.0, 1.0, 1.0, 1.0, 4315.0, 4315.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.73, 0.0, 0.0, 0.0, -5.889, -5.854, 0.0, 0.0, 0.0]}
{"step": 4315, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4316.0, 1.0, 1.0, 1.0, 4316.0, 4316.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.729, 0.0, 0.0, 0.0, -5.892, -5.857, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15134, "number_of_timesteps": 193719, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4316, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4317.0, 1.0, 1.0, 1.0, 4317.0, 4317.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.896, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15138, "number_of_timesteps": 193758, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4317, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4318.0, 1.0, 1.0, 1.0, 4318.0, 4318.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.899, -5.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15143, "number_of_timesteps": 193811, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4318, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4319.0, 1.0, 1.0, 1.0, 4319.0, 4319.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.899, -5.864, 0.0, 0.0, 0.0]}
{"step": 4319, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4320.0, 1.0, 1.0, 1.0, 4320.0, 4320.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.903, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15151, "number_of_timesteps": 193890, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4320, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4321.0, 1.0, 1.0, 1.0, 4321.0, 4321.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.903, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15157, "number_of_timesteps": 193948, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4321, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4322.0, 1.0, 1.0, 1.0, 4322.0, 4322.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.904, -5.867, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15161, "number_of_timesteps": 193987, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4322, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4323.0, 1.0, 1.0, 1.0, 4323.0, 4323.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.903, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15166, "number_of_timesteps": 194034, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4323, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4324.0, 1.0, 1.0, 1.0, 4324.0, 4324.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.906, -5.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15170, "number_of_timesteps": 194076, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4324, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4325.0, 1.0, 1.0, 1.0, 4325.0, 4325.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.907, -5.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15175, "number_of_timesteps": 194125, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4325, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4326.0, 1.0, 1.0, 1.0, 4326.0, 4326.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.905, -5.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15180, "number_of_timesteps": 194177, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4326, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4327.0, 1.0, 1.0, 1.0, 4327.0, 4327.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.73, 0.0, 0.0, 0.0, -5.904, -5.867, 0.0, 0.0, 0.0]}
{"step": 4327, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4328.0, 1.0, 1.0, 1.0, 4328.0, 4328.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.729, 0.0, 0.0, 0.0, -5.903, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15190, "number_of_timesteps": 194273, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4328, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4329.0, 1.0, 1.0, 1.0, 4329.0, 4329.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.729, 0.0, 0.0, 0.0, -5.903, -5.865, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15194, "number_of_timesteps": 194310, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4329, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4330.0, 1.0, 1.0, 1.0, 4330.0, 4330.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.906, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15199, "number_of_timesteps": 194356, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4330, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4331.0, 1.0, 1.0, 1.0, 4331.0, 4331.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.904, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15202, "number_of_timesteps": 194389, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4331, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4332.0, 1.0, 1.0, 1.0, 4332.0, 4332.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.903, -5.867, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15208, "number_of_timesteps": 194451, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4332, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4333.0, 1.0, 1.0, 1.0, 4333.0, 4333.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.731, 0.0, 0.0, 0.0, -5.906, -5.869, 0.0, 0.0, 0.0]}
{"eval_score": 10.8, "number_of_episodes": 15210}
{"number_of_episodes": 15210, "number_of_timesteps": 194472, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4333, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4334.0, 1.0, 1.0, 1.0, 4334.0, 4334.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.73, 0.0, 0.0, 0.0, -5.904, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15217, "number_of_timesteps": 194540, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4334, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4335.0, 1.0, 1.0, 1.0, 4335.0, 4335.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.907, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15219, "number_of_timesteps": 194562, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4335, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4336.0, 1.0, 1.0, 1.0, 4336.0, 4336.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.907, -5.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15227, "number_of_timesteps": 194639, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4336, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4337.0, 1.0, 1.0, 1.0, 4337.0, 4337.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.907, -5.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15229, "number_of_timesteps": 194657, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4337, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4338.0, 1.0, 1.0, 1.0, 4338.0, 4338.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.907, -5.869, 0.0, 0.0, 0.0]}
{"step": 4338, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4339.0, 1.0, 1.0, 1.0, 4339.0, 4339.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.907, -5.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15239, "number_of_timesteps": 194753, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4339, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4340.0, 1.0, 1.0, 1.0, 4340.0, 4340.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.911, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15244, "number_of_timesteps": 194802, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4340, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4341.0, 1.0, 1.0, 1.0, 4341.0, 4341.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.91, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15247, "number_of_timesteps": 194831, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4341, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4342.0, 1.0, 1.0, 1.0, 4342.0, 4342.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.91, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15252, "number_of_timesteps": 194878, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4342, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4343.0, 1.0, 1.0, 1.0, 4343.0, 4343.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.911, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15256, "number_of_timesteps": 194918, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4343, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4344.0, 1.0, 1.0, 1.0, 4344.0, 4344.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.909, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15260, "number_of_timesteps": 194960, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4344, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4345.0, 1.0, 1.0, 1.0, 4345.0, 4345.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.912, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15266, "number_of_timesteps": 195022, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4345, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4346.0, 1.0, 1.0, 1.0, 4346.0, 4346.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.913, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15270, "number_of_timesteps": 195058, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4346, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4347.0, 1.0, 1.0, 1.0, 4347.0, 4347.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.913, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15276, "number_of_timesteps": 195115, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4347, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4348.0, 1.0, 1.0, 1.0, 4348.0, 4348.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.914, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15279, "number_of_timesteps": 195141, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4348, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4349.0, 1.0, 1.0, 1.0, 4349.0, 4349.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.912, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15286, "number_of_timesteps": 195210, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4349, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4350.0, 1.0, 1.0, 1.0, 4350.0, 4350.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.913, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15286, "number_of_timesteps": 195210, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4350, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4351.0, 1.0, 1.0, 1.0, 4351.0, 4351.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.914, -5.872, 0.0, 0.0, 0.0]}
{"step": 4351, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4352.0, 1.0, 1.0, 1.0, 4352.0, 4352.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.917, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15296, "number_of_timesteps": 195316, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4352, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4353.0, 1.0, 1.0, 1.0, 4353.0, 4353.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.916, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15300, "number_of_timesteps": 195351, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4353, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4354.0, 1.0, 1.0, 1.0, 4354.0, 4354.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.915, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15306, "number_of_timesteps": 195415, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4354, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4355.0, 1.0, 1.0, 1.0, 4355.0, 4355.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.918, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15309, "number_of_timesteps": 195442, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4355, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4356.0, 1.0, 1.0, 1.0, 4356.0, 4356.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.917, -5.875, 0.0, 0.0, 0.0]}
{"step": 4356, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4357.0, 1.0, 1.0, 1.0, 4357.0, 4357.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.92, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15319, "number_of_timesteps": 195537, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4357, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4358.0, 1.0, 1.0, 1.0, 4358.0, 4358.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.919, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15324, "number_of_timesteps": 195583, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4358, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4359.0, 1.0, 1.0, 1.0, 4359.0, 4359.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.92, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15328, "number_of_timesteps": 195624, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4359, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4360.0, 1.0, 1.0, 1.0, 4360.0, 4360.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.918, -5.878, 0.0, 0.0, 0.0]}
{"step": 4360, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4361.0, 1.0, 1.0, 1.0, 4361.0, 4361.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.917, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15336, "number_of_timesteps": 195702, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4361, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4362.0, 1.0, 1.0, 1.0, 4362.0, 4362.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.917, -5.879, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 15343}
{"number_of_episodes": 15343, "number_of_timesteps": 195771, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4362, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4363.0, 1.0, 1.0, 1.0, 4363.0, 4363.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.917, -5.879, 0.0, 0.0, 0.0]}
{"step": 4363, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4364.0, 1.0, 1.0, 1.0, 4364.0, 4364.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.917, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15352, "number_of_timesteps": 195858, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4364, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4365.0, 1.0, 1.0, 1.0, 4365.0, 4365.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.915, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15355, "number_of_timesteps": 195888, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4365, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4366.0, 1.0, 1.0, 1.0, 4366.0, 4366.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.914, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15362, "number_of_timesteps": 195954, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4366, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4367.0, 1.0, 1.0, 1.0, 4367.0, 4367.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.912, -5.876, 0.0, 0.0, 0.0]}
{"step": 4367, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4368.0, 1.0, 1.0, 1.0, 4368.0, 4368.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.911, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15371, "number_of_timesteps": 196035, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4368, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4369.0, 1.0, 1.0, 1.0, 4369.0, 4369.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.91, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15375, "number_of_timesteps": 196074, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4369, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4370.0, 1.0, 1.0, 1.0, 4370.0, 4370.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.91, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15380, "number_of_timesteps": 196122, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4370, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4371.0, 1.0, 1.0, 1.0, 4371.0, 4371.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.911, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15384, "number_of_timesteps": 196161, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4371, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4372.0, 1.0, 1.0, 1.0, 4372.0, 4372.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.912, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15389, "number_of_timesteps": 196208, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4372, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4373.0, 1.0, 1.0, 1.0, 4373.0, 4373.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.91, -5.875, 0.0, 0.0, 0.0]}
{"step": 4373, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4374.0, 1.0, 1.0, 1.0, 4374.0, 4374.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.909, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15399, "number_of_timesteps": 196305, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4374, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4375.0, 1.0, 1.0, 1.0, 4375.0, 4375.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.908, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15404, "number_of_timesteps": 196354, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4375, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4376.0, 1.0, 1.0, 1.0, 4376.0, 4376.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.908, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15409, "number_of_timesteps": 196401, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4376, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4377.0, 1.0, 1.0, 1.0, 4377.0, 4377.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.912, -5.875, 0.0, 0.0, 0.0]}
{"step": 4377, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4378.0, 1.0, 1.0, 1.0, 4378.0, 4378.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.912, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15419, "number_of_timesteps": 196492, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4378, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4379.0, 1.0, 1.0, 1.0, 4379.0, 4379.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.911, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15423, "number_of_timesteps": 196527, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4379, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4380.0, 1.0, 1.0, 1.0, 4380.0, 4380.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.911, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15427, "number_of_timesteps": 196564, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4380, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4381.0, 1.0, 1.0, 1.0, 4381.0, 4381.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.913, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15433, "number_of_timesteps": 196622, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4381, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4382.0, 1.0, 1.0, 1.0, 4382.0, 4382.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.913, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15437, "number_of_timesteps": 196662, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4382, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4383.0, 1.0, 1.0, 1.0, 4383.0, 4383.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.913, -5.876, 0.0, 0.0, 0.0]}
{"step": 4383, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4384.0, 1.0, 1.0, 1.0, 4384.0, 4384.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.912, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15446, "number_of_timesteps": 196754, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4384, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4385.0, 1.0, 1.0, 1.0, 4385.0, 4385.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.91, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15450, "number_of_timesteps": 196793, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4385, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4386.0, 1.0, 1.0, 1.0, 4386.0, 4386.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.909, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15454, "number_of_timesteps": 196829, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4386, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4387.0, 1.0, 1.0, 1.0, 4387.0, 4387.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.908, -5.873, 0.0, 0.0, 0.0]}
{"step": 4387, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4388.0, 1.0, 1.0, 1.0, 4388.0, 4388.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.907, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15464, "number_of_timesteps": 196930, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4388, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4389.0, 1.0, 1.0, 1.0, 4389.0, 4389.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.905, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15469, "number_of_timesteps": 196975, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4389, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4390.0, 1.0, 1.0, 1.0, 4390.0, 4390.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.904, -5.871, 0.0, 0.0, 0.0]}
{"eval_score": 9.9, "number_of_episodes": 15473}
{"number_of_episodes": 15473, "number_of_timesteps": 197013, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4390, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4391.0, 1.0, 1.0, 1.0, 4391.0, 4391.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.904, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15478, "number_of_timesteps": 197060, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4391, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4392.0, 1.0, 1.0, 1.0, 4392.0, 4392.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.908, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15483, "number_of_timesteps": 197107, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4392, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4393.0, 1.0, 1.0, 1.0, 4393.0, 4393.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.907, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15487, "number_of_timesteps": 197147, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4393, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4394.0, 1.0, 1.0, 1.0, 4394.0, 4394.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.907, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15493, "number_of_timesteps": 197205, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4394, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4395.0, 1.0, 1.0, 1.0, 4395.0, 4395.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.908, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15496, "number_of_timesteps": 197231, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4395, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4396.0, 1.0, 1.0, 1.0, 4396.0, 4396.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.906, -5.873, 0.0, 0.0, 0.0]}
{"step": 4396, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4397.0, 1.0, 1.0, 1.0, 4397.0, 4397.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.909, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15505, "number_of_timesteps": 197321, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4397, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4398.0, 1.0, 1.0, 1.0, 4398.0, 4398.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.91, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15511, "number_of_timesteps": 197378, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4398, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4399.0, 1.0, 1.0, 1.0, 4399.0, 4399.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.911, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15515, "number_of_timesteps": 197419, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4399, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4400.0, 1.0, 1.0, 1.0, 4400.0, 4400.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.911, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15520, "number_of_timesteps": 197466, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4400, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4401.0, 1.0, 1.0, 1.0, 4401.0, 4401.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.91, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15524, "number_of_timesteps": 197505, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4401, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4402.0, 1.0, 1.0, 1.0, 4402.0, 4402.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.909, -5.875, 0.0, 0.0, 0.0]}
{"step": 4402, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4403.0, 1.0, 1.0, 1.0, 4403.0, 4403.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.907, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15534, "number_of_timesteps": 197605, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4403, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4404.0, 1.0, 1.0, 1.0, 4404.0, 4404.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.908, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15536, "number_of_timesteps": 197622, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4404, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4405.0, 1.0, 1.0, 1.0, 4405.0, 4405.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.908, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15541, "number_of_timesteps": 197672, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4405, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4406.0, 1.0, 1.0, 1.0, 4406.0, 4406.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.907, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15546, "number_of_timesteps": 197727, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4406, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4407.0, 1.0, 1.0, 1.0, 4407.0, 4407.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.905, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15551, "number_of_timesteps": 197777, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4407, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4408.0, 1.0, 1.0, 1.0, 4408.0, 4408.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.909, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15555, "number_of_timesteps": 197813, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4408, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4409.0, 1.0, 1.0, 1.0, 4409.0, 4409.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.909, -5.876, 0.0, 0.0, 0.0]}
{"step": 4409, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4410.0, 1.0, 1.0, 1.0, 4410.0, 4410.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.912, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15565, "number_of_timesteps": 197916, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4410, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4411.0, 1.0, 1.0, 1.0, 4411.0, 4411.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.912, -5.878, 0.0, 0.0, 0.0]}
{"step": 4411, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4412.0, 1.0, 1.0, 1.0, 4412.0, 4412.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.912, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15574, "number_of_timesteps": 198004, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4412, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4413.0, 1.0, 1.0, 1.0, 4413.0, 4413.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.911, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15577, "number_of_timesteps": 198034, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4413, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4414.0, 1.0, 1.0, 1.0, 4414.0, 4414.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.909, -5.877, 0.0, 0.0, 0.0]}
{"step": 4414, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4415.0, 1.0, 1.0, 1.0, 4415.0, 4415.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.908, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15586, "number_of_timesteps": 198122, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4415, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4416.0, 1.0, 1.0, 1.0, 4416.0, 4416.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.907, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15593, "number_of_timesteps": 198191, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4416, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4417.0, 1.0, 1.0, 1.0, 4417.0, 4417.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.905, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15596, "number_of_timesteps": 198219, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4417, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4418.0, 1.0, 1.0, 1.0, 4418.0, 4418.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.906, -5.875, 0.0, 0.0, 0.0]}
{"eval_score": 9.1, "number_of_episodes": 15603}
{"number_of_episodes": 15603, "number_of_timesteps": 198282, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4418, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4419.0, 1.0, 1.0, 1.0, 4419.0, 4419.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.904, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15606, "number_of_timesteps": 198311, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4419, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4420.0, 1.0, 1.0, 1.0, 4420.0, 4420.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.905, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15612, "number_of_timesteps": 198368, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4420, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4421.0, 1.0, 1.0, 1.0, 4421.0, 4421.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.905, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15616, "number_of_timesteps": 198407, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4421, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4422.0, 1.0, 1.0, 1.0, 4422.0, 4422.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.905, -5.875, 0.0, 0.0, 0.0]}
{"step": 4422, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4423.0, 1.0, 1.0, 1.0, 4423.0, 4423.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.905, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15626, "number_of_timesteps": 198506, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4423, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4424.0, 1.0, 1.0, 1.0, 4424.0, 4424.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.905, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15630, "number_of_timesteps": 198543, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4424, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4425.0, 1.0, 1.0, 1.0, 4425.0, 4425.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.904, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15634, "number_of_timesteps": 198580, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4425, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4426.0, 1.0, 1.0, 1.0, 4426.0, 4426.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.905, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15638, "number_of_timesteps": 198623, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4426, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4427.0, 1.0, 1.0, 1.0, 4427.0, 4427.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.904, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15644, "number_of_timesteps": 198680, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4427, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4428.0, 1.0, 1.0, 1.0, 4428.0, 4428.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.904, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15646, "number_of_timesteps": 198698, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4428, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4429.0, 1.0, 1.0, 1.0, 4429.0, 4429.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.907, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15652, "number_of_timesteps": 198761, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4429, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4430.0, 1.0, 1.0, 1.0, 4430.0, 4430.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.906, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15656, "number_of_timesteps": 198803, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4430, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4431.0, 1.0, 1.0, 1.0, 4431.0, 4431.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.909, -5.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15661, "number_of_timesteps": 198848, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4431, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4432.0, 1.0, 1.0, 1.0, 4432.0, 4432.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.91, -5.88, 0.0, 0.0, 0.0]}
{"step": 4432, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4433.0, 1.0, 1.0, 1.0, 4433.0, 4433.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.91, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15670, "number_of_timesteps": 198938, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4433, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4434.0, 1.0, 1.0, 1.0, 4434.0, 4434.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.909, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15675, "number_of_timesteps": 198986, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4434, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4435.0, 1.0, 1.0, 1.0, 4435.0, 4435.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.909, -5.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15680, "number_of_timesteps": 199032, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4435, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4436.0, 1.0, 1.0, 1.0, 4436.0, 4436.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.908, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15683, "number_of_timesteps": 199058, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4436, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4437.0, 1.0, 1.0, 1.0, 4437.0, 4437.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.907, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15688, "number_of_timesteps": 199112, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4437, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4438.0, 1.0, 1.0, 1.0, 4438.0, 4438.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.907, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15692, "number_of_timesteps": 199154, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4438, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4439.0, 1.0, 1.0, 1.0, 4439.0, 4439.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.906, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15697, "number_of_timesteps": 199202, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4439, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4440.0, 1.0, 1.0, 1.0, 4440.0, 4440.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.909, -5.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15702, "number_of_timesteps": 199251, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4440, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4441.0, 1.0, 1.0, 1.0, 4441.0, 4441.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.909, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15707, "number_of_timesteps": 199296, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4441, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4442.0, 1.0, 1.0, 1.0, 4442.0, 4442.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.91, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15710, "number_of_timesteps": 199324, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4442, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4443.0, 1.0, 1.0, 1.0, 4443.0, 4443.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.909, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15716, "number_of_timesteps": 199382, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4443, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4444.0, 1.0, 1.0, 1.0, 4444.0, 4444.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.911, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15720, "number_of_timesteps": 199419, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4444, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4445.0, 1.0, 1.0, 1.0, 4445.0, 4445.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.912, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15726, "number_of_timesteps": 199472, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4445, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4446.0, 1.0, 1.0, 1.0, 4446.0, 4446.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.91, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15728, "number_of_timesteps": 199491, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4446, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4447.0, 1.0, 1.0, 1.0, 4447.0, 4447.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.91, -5.88, 0.0, 0.0, 0.0]}
{"eval_score": 9.4, "number_of_episodes": 15735}
{"step": 4447, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4448.0, 1.0, 1.0, 1.0, 4448.0, 4448.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.91, -5.879, 0.0, 0.0, 0.0]}
{"step": 4448, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4449.0, 1.0, 1.0, 1.0, 4449.0, 4449.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.91, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15744, "number_of_timesteps": 199649, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4449, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4450.0, 1.0, 1.0, 1.0, 4450.0, 4450.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.911, -5.879, 0.0, 0.0, 0.0]}
{"step": 4450, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4451.0, 1.0, 1.0, 1.0, 4451.0, 4451.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.914, -5.882, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15752, "number_of_timesteps": 199725, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4451, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4452.0, 1.0, 1.0, 1.0, 4452.0, 4452.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.913, -5.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15756, "number_of_timesteps": 199769, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4452, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4453.0, 1.0, 1.0, 1.0, 4453.0, 4453.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.912, -5.879, 0.0, 0.0, 0.0]}
{"step": 4453, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4454.0, 1.0, 1.0, 1.0, 4454.0, 4454.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.911, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15764, "number_of_timesteps": 199846, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4454, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4455.0, 1.0, 1.0, 1.0, 4455.0, 4455.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.914, -5.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15769, "number_of_timesteps": 199899, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4455, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4456.0, 1.0, 1.0, 1.0, 4456.0, 4456.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.914, -5.881, 0.0, 0.0, 0.0]}
{"step": 4456, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4457.0, 1.0, 1.0, 1.0, 4457.0, 4457.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.914, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15776, "number_of_timesteps": 199974, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4457, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4458.0, 1.0, 1.0, 1.0, 4458.0, 4458.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.913, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15783, "number_of_timesteps": 200047, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4458, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4459.0, 1.0, 1.0, 1.0, 4459.0, 4459.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.913, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15784, "number_of_timesteps": 200056, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4459, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4460.0, 1.0, 1.0, 1.0, 4460.0, 4460.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.913, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15793, "number_of_timesteps": 200142, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4460, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4461.0, 1.0, 1.0, 1.0, 4461.0, 4461.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.912, -5.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15794, "number_of_timesteps": 200152, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4461, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4462.0, 1.0, 1.0, 1.0, 4462.0, 4462.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.915, -5.883, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15801, "number_of_timesteps": 200218, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4462, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4463.0, 1.0, 1.0, 1.0, 4463.0, 4463.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.915, -5.883, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15803, "number_of_timesteps": 200243, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4463, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4464.0, 1.0, 1.0, 1.0, 4464.0, 4464.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.916, -5.884, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15809, "number_of_timesteps": 200302, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4464, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4465.0, 1.0, 1.0, 1.0, 4465.0, 4465.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.915, -5.883, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15813, "number_of_timesteps": 200343, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4465, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4466.0, 1.0, 1.0, 1.0, 4466.0, 4466.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.914, -5.882, 0.0, 0.0, 0.0]}
{"step": 4466, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4467.0, 1.0, 1.0, 1.0, 4467.0, 4467.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.913, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15823, "number_of_timesteps": 200442, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4467, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4468.0, 1.0, 1.0, 1.0, 4468.0, 4468.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.913, -5.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15826, "number_of_timesteps": 200470, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4468, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4469.0, 1.0, 1.0, 1.0, 4469.0, 4469.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.912, -5.879, 0.0, 0.0, 0.0]}
{"step": 4469, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4470.0, 1.0, 1.0, 1.0, 4470.0, 4470.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.913, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15836, "number_of_timesteps": 200568, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4470, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4471.0, 1.0, 1.0, 1.0, 4471.0, 4471.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.912, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15840, "number_of_timesteps": 200605, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4471, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4472.0, 1.0, 1.0, 1.0, 4472.0, 4472.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.912, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15845, "number_of_timesteps": 200653, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4472, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4473.0, 1.0, 1.0, 1.0, 4473.0, 4473.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.911, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15850, "number_of_timesteps": 200701, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4473, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4474.0, 1.0, 1.0, 1.0, 4474.0, 4474.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.912, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15855, "number_of_timesteps": 200748, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4474, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4475.0, 1.0, 1.0, 1.0, 4475.0, 4475.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.91, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15858, "number_of_timesteps": 200777, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4475, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4476.0, 1.0, 1.0, 1.0, 4476.0, 4476.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.909, -5.873, 0.0, 0.0, 0.0]}
{"eval_score": 10.0, "number_of_episodes": 15865}
{"number_of_episodes": 15865, "number_of_timesteps": 200845, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4476, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4477.0, 1.0, 1.0, 1.0, 4477.0, 4477.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.908, -5.872, 0.0, 0.0, 0.0]}
{"step": 4477, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4478.0, 1.0, 1.0, 1.0, 4478.0, 4478.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.906, -5.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15874, "number_of_timesteps": 200928, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4478, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4479.0, 1.0, 1.0, 1.0, 4479.0, 4479.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.905, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15877, "number_of_timesteps": 200956, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4479, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4480.0, 1.0, 1.0, 1.0, 4480.0, 4480.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.908, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15883, "number_of_timesteps": 201014, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4480, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4481.0, 1.0, 1.0, 1.0, 4481.0, 4481.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.907, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15887, "number_of_timesteps": 201053, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4481, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4482.0, 1.0, 1.0, 1.0, 4482.0, 4482.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.906, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15892, "number_of_timesteps": 201101, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4482, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4483.0, 1.0, 1.0, 1.0, 4483.0, 4483.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.908, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15897, "number_of_timesteps": 201151, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4483, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4484.0, 1.0, 1.0, 1.0, 4484.0, 4484.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.907, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15899, "number_of_timesteps": 201170, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4484, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4485.0, 1.0, 1.0, 1.0, 4485.0, 4485.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.908, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15905, "number_of_timesteps": 201231, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4485, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4486.0, 1.0, 1.0, 1.0, 4486.0, 4486.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.909, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15909, "number_of_timesteps": 201281, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4486, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4487.0, 1.0, 1.0, 1.0, 4487.0, 4487.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.909, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15912, "number_of_timesteps": 201308, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4487, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4488.0, 1.0, 1.0, 1.0, 4488.0, 4488.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.912, -5.878, 0.0, 0.0, 0.0]}
{"step": 4488, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4489.0, 1.0, 1.0, 1.0, 4489.0, 4489.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.912, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15921, "number_of_timesteps": 201406, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4489, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4490.0, 1.0, 1.0, 1.0, 4490.0, 4490.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.913, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15926, "number_of_timesteps": 201456, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4490, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4491.0, 1.0, 1.0, 1.0, 4491.0, 4491.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.913, -5.877, 0.0, 0.0, 0.0]}
{"step": 4491, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4492.0, 1.0, 1.0, 1.0, 4492.0, 4492.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.913, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15934, "number_of_timesteps": 201542, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4492, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4493.0, 1.0, 1.0, 1.0, 4493.0, 4493.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.915, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15939, "number_of_timesteps": 201593, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4493, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4494.0, 1.0, 1.0, 1.0, 4494.0, 4494.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.916, -5.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15943, "number_of_timesteps": 201631, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4494, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4495.0, 1.0, 1.0, 1.0, 4495.0, 4495.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.914, -5.879, 0.0, 0.0, 0.0]}
{"step": 4495, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4496.0, 1.0, 1.0, 1.0, 4496.0, 4496.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.915, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15953, "number_of_timesteps": 201729, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4496, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4497.0, 1.0, 1.0, 1.0, 4497.0, 4497.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.915, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15958, "number_of_timesteps": 201777, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4497, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4498.0, 1.0, 1.0, 1.0, 4498.0, 4498.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.913, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15962, "number_of_timesteps": 201817, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4498, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4499.0, 1.0, 1.0, 1.0, 4499.0, 4499.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.916, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15966, "number_of_timesteps": 201857, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4499, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4500.0, 1.0, 1.0, 1.0, 4500.0, 4500.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.916, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15972, "number_of_timesteps": 201924, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4500, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4501.0, 1.0, 1.0, 1.0, 4501.0, 4501.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.916, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15974, "number_of_timesteps": 201943, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4501, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4502.0, 1.0, 1.0, 1.0, 4502.0, 4502.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.915, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15981, "number_of_timesteps": 202010, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4502, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4503.0, 1.0, 1.0, 1.0, 4503.0, 4503.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.913, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15983, "number_of_timesteps": 202031, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4503, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4504.0, 1.0, 1.0, 1.0, 4504.0, 4504.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.912, -5.875, 0.0, 0.0, 0.0]}
{"step": 4504, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4505.0, 1.0, 1.0, 1.0, 4505.0, 4505.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.913, -5.876, 0.0, 0.0, 0.0]}
{"eval_score": 9.8, "number_of_episodes": 15992}
{"number_of_episodes": 15992, "number_of_timesteps": 202128, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4505, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4506.0, 1.0, 1.0, 1.0, 4506.0, 4506.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.913, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 15996, "number_of_timesteps": 202167, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4506, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4507.0, 1.0, 1.0, 1.0, 4507.0, 4507.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.912, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16001, "number_of_timesteps": 202220, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4507, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4508.0, 1.0, 1.0, 1.0, 4508.0, 4508.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.912, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16006, "number_of_timesteps": 202268, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4508, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4509.0, 1.0, 1.0, 1.0, 4509.0, 4509.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.911, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16011, "number_of_timesteps": 202316, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4509, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4510.0, 1.0, 1.0, 1.0, 4510.0, 4510.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.909, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16016, "number_of_timesteps": 202363, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4510, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4511.0, 1.0, 1.0, 1.0, 4511.0, 4511.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.909, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16021, "number_of_timesteps": 202407, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4511, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4512.0, 1.0, 1.0, 1.0, 4512.0, 4512.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.908, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16026, "number_of_timesteps": 202455, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4512, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4513.0, 1.0, 1.0, 1.0, 4513.0, 4513.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.908, -5.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16029, "number_of_timesteps": 202485, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4513, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4514.0, 1.0, 1.0, 1.0, 4514.0, 4514.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.907, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16035, "number_of_timesteps": 202544, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4514, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4515.0, 1.0, 1.0, 1.0, 4515.0, 4515.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.91, -5.871, 0.0, 0.0, 0.0]}
{"step": 4515, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4516.0, 1.0, 1.0, 1.0, 4516.0, 4516.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.911, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16045, "number_of_timesteps": 202644, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4516, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4517.0, 1.0, 1.0, 1.0, 4517.0, 4517.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.91, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16049, "number_of_timesteps": 202683, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4517, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4518.0, 1.0, 1.0, 1.0, 4518.0, 4518.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.908, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16053, "number_of_timesteps": 202720, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4518, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4519.0, 1.0, 1.0, 1.0, 4519.0, 4519.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.907, -5.87, 0.0, 0.0, 0.0]}
{"step": 4519, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4520.0, 1.0, 1.0, 1.0, 4520.0, 4520.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.906, -5.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16063, "number_of_timesteps": 202815, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4520, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4521.0, 1.0, 1.0, 1.0, 4521.0, 4521.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.909, -5.872, 0.0, 0.0, 0.0]}
{"step": 4521, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4522.0, 1.0, 1.0, 1.0, 4522.0, 4522.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.908, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16071, "number_of_timesteps": 202895, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4522, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4523.0, 1.0, 1.0, 1.0, 4523.0, 4523.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.908, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16075, "number_of_timesteps": 202936, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4523, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4524.0, 1.0, 1.0, 1.0, 4524.0, 4524.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.907, -5.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16080, "number_of_timesteps": 202987, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4524, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4525.0, 1.0, 1.0, 1.0, 4525.0, 4525.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.908, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16082, "number_of_timesteps": 203006, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4525, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4526.0, 1.0, 1.0, 1.0, 4526.0, 4526.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.908, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16090, "number_of_timesteps": 203092, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4526, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4527.0, 1.0, 1.0, 1.0, 4527.0, 4527.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.907, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16092, "number_of_timesteps": 203110, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4527, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4528.0, 1.0, 1.0, 1.0, 4528.0, 4528.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.906, -5.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16099, "number_of_timesteps": 203174, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4528, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4529.0, 1.0, 1.0, 1.0, 4529.0, 4529.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.905, -5.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16102, "number_of_timesteps": 203205, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4529, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4530.0, 1.0, 1.0, 1.0, 4530.0, 4530.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.903, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16107, "number_of_timesteps": 203252, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4530, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4531.0, 1.0, 1.0, 1.0, 4531.0, 4531.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.904, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16110, "number_of_timesteps": 203282, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4531, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4532.0, 1.0, 1.0, 1.0, 4532.0, 4532.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.903, -5.867, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16117, "number_of_timesteps": 203350, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4532, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4533.0, 1.0, 1.0, 1.0, 4533.0, 4533.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.901, -5.866, 0.0, 0.0, 0.0]}
{"step": 4533, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4534.0, 1.0, 1.0, 1.0, 4534.0, 4534.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.9, -5.864, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 16124}
{"number_of_episodes": 16124, "number_of_timesteps": 203418, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4534, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4535.0, 1.0, 1.0, 1.0, 4535.0, 4535.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.9, -5.865, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16128, "number_of_timesteps": 203461, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4535, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4536.0, 1.0, 1.0, 1.0, 4536.0, 4536.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.903, -5.868, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16133, "number_of_timesteps": 203508, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4536, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4537.0, 1.0, 1.0, 1.0, 4537.0, 4537.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.902, -5.867, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16137, "number_of_timesteps": 203545, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4537, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4538.0, 1.0, 1.0, 1.0, 4538.0, 4538.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.901, -5.866, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16143, "number_of_timesteps": 203602, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4538, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4539.0, 1.0, 1.0, 1.0, 4539.0, 4539.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.9, -5.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16147, "number_of_timesteps": 203639, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4539, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4540.0, 1.0, 1.0, 1.0, 4540.0, 4540.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.9, -5.865, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16151, "number_of_timesteps": 203674, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4540, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4541.0, 1.0, 1.0, 1.0, 4541.0, 4541.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.901, -5.863, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16157, "number_of_timesteps": 203732, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4541, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4542.0, 1.0, 1.0, 1.0, 4542.0, 4542.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.901, -5.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16161, "number_of_timesteps": 203770, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4542, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4543.0, 1.0, 1.0, 1.0, 4543.0, 4543.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.901, -5.863, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16166, "number_of_timesteps": 203816, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4543, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4544.0, 1.0, 1.0, 1.0, 4544.0, 4544.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.9, -5.862, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16170, "number_of_timesteps": 203855, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4544, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4545.0, 1.0, 1.0, 1.0, 4545.0, 4545.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.9, -5.863, 0.0, 0.0, 0.0]}
{"step": 4545, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4546.0, 1.0, 1.0, 1.0, 4546.0, 4546.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.899, -5.862, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16180, "number_of_timesteps": 203955, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4546, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4547.0, 1.0, 1.0, 1.0, 4547.0, 4547.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.898, -5.861, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16183, "number_of_timesteps": 203983, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4547, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4548.0, 1.0, 1.0, 1.0, 4548.0, 4548.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.897, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16189, "number_of_timesteps": 204041, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4548, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4549.0, 1.0, 1.0, 1.0, 4549.0, 4549.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.897, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16193, "number_of_timesteps": 204082, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4549, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4550.0, 1.0, 1.0, 1.0, 4550.0, 4550.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.895, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16198, "number_of_timesteps": 204128, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4550, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4551.0, 1.0, 1.0, 1.0, 4551.0, 4551.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.894, -5.858, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16201, "number_of_timesteps": 204156, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4551, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4552.0, 1.0, 1.0, 1.0, 4552.0, 4552.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.893, -5.857, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16208, "number_of_timesteps": 204227, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4552, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4553.0, 1.0, 1.0, 1.0, 4553.0, 4553.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.893, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16211, "number_of_timesteps": 204255, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4553, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4554.0, 1.0, 1.0, 1.0, 4554.0, 4554.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.892, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16218, "number_of_timesteps": 204322, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4554, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4555.0, 1.0, 1.0, 1.0, 4555.0, 4555.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.892, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16220, "number_of_timesteps": 204341, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4555, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4556.0, 1.0, 1.0, 1.0, 4556.0, 4556.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.891, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16227, "number_of_timesteps": 204411, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4556, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4557.0, 1.0, 1.0, 1.0, 4557.0, 4557.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.889, -5.852, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16230, "number_of_timesteps": 204441, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4557, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4558.0, 1.0, 1.0, 1.0, 4558.0, 4558.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.888, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16236, "number_of_timesteps": 204496, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4558, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4559.0, 1.0, 1.0, 1.0, 4559.0, 4559.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.891, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16240, "number_of_timesteps": 204538, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4559, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4560.0, 1.0, 1.0, 1.0, 4560.0, 4560.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.89, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16245, "number_of_timesteps": 204582, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4560, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4561.0, 1.0, 1.0, 1.0, 4561.0, 4561.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.89, -5.853, 0.0, 0.0, 0.0]}
{"eval_score": 9.4, "number_of_episodes": 16250}
{"number_of_episodes": 16250, "number_of_timesteps": 204633, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4561, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4562.0, 1.0, 1.0, 1.0, 4562.0, 4562.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.889, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16253, "number_of_timesteps": 204659, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4562, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4563.0, 1.0, 1.0, 1.0, 4563.0, 4563.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.887, -5.852, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16259, "number_of_timesteps": 204723, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4563, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4564.0, 1.0, 1.0, 1.0, 4564.0, 4564.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.886, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16263, "number_of_timesteps": 204764, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4564, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4565.0, 1.0, 1.0, 1.0, 4565.0, 4565.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.885, -5.85, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16269, "number_of_timesteps": 204816, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4565, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4566.0, 1.0, 1.0, 1.0, 4566.0, 4566.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.888, -5.852, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16273, "number_of_timesteps": 204853, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4566, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4567.0, 1.0, 1.0, 1.0, 4567.0, 4567.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.886, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16278, "number_of_timesteps": 204899, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4567, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4568.0, 1.0, 1.0, 1.0, 4568.0, 4568.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.885, -5.85, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16282, "number_of_timesteps": 204941, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4568, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4569.0, 1.0, 1.0, 1.0, 4569.0, 4569.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.884, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16287, "number_of_timesteps": 204989, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4569, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4570.0, 1.0, 1.0, 1.0, 4570.0, 4570.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.883, -5.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16291, "number_of_timesteps": 205029, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4570, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4571.0, 1.0, 1.0, 1.0, 4571.0, 4571.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.882, -5.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16294, "number_of_timesteps": 205060, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4571, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4572.0, 1.0, 1.0, 1.0, 4572.0, 4572.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.88, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16301, "number_of_timesteps": 205137, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4572, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4573.0, 1.0, 1.0, 1.0, 4573.0, 4573.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.881, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16304, "number_of_timesteps": 205165, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4573, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4574.0, 1.0, 1.0, 1.0, 4574.0, 4574.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.88, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16311, "number_of_timesteps": 205232, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4574, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4575.0, 1.0, 1.0, 1.0, 4575.0, 4575.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.883, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16314, "number_of_timesteps": 205258, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4575, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4576.0, 1.0, 1.0, 1.0, 4576.0, 4576.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.886, -5.852, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16319, "number_of_timesteps": 205302, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4576, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4577.0, 1.0, 1.0, 1.0, 4577.0, 4577.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.885, -5.85, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16324, "number_of_timesteps": 205356, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4577, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4578.0, 1.0, 1.0, 1.0, 4578.0, 4578.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.885, -5.851, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16329, "number_of_timesteps": 205403, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4578, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4579.0, 1.0, 1.0, 1.0, 4579.0, 4579.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.884, -5.85, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16334, "number_of_timesteps": 205448, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4579, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4580.0, 1.0, 1.0, 1.0, 4580.0, 4580.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.883, -5.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16337, "number_of_timesteps": 205474, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4580, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4581.0, 1.0, 1.0, 1.0, 4581.0, 4581.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.883, -5.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16344, "number_of_timesteps": 205545, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4581, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4582.0, 1.0, 1.0, 1.0, 4582.0, 4582.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.881, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16347, "number_of_timesteps": 205574, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4582, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4583.0, 1.0, 1.0, 1.0, 4583.0, 4583.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.882, -5.846, 0.0, 0.0, 0.0]}
{"step": 4583, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4584.0, 1.0, 1.0, 1.0, 4584.0, 4584.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.881, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16357, "number_of_timesteps": 205667, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4584, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4585.0, 1.0, 1.0, 1.0, 4585.0, 4585.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.882, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16360, "number_of_timesteps": 205695, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4585, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4586.0, 1.0, 1.0, 1.0, 4586.0, 4586.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.88, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16365, "number_of_timesteps": 205750, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4586, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4587.0, 1.0, 1.0, 1.0, 4587.0, 4587.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.883, -5.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16370, "number_of_timesteps": 205798, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4587, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4588.0, 1.0, 1.0, 1.0, 4588.0, 4588.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.882, -5.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16372, "number_of_timesteps": 205816, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4588, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4589.0, 1.0, 1.0, 1.0, 4589.0, 4589.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.883, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16379, "number_of_timesteps": 205892, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4589, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4590.0, 1.0, 1.0, 1.0, 4590.0, 4590.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.883, -5.847, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 16382}
{"number_of_episodes": 16382, "number_of_timesteps": 205927, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4590, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4591.0, 1.0, 1.0, 1.0, 4591.0, 4591.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.883, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16387, "number_of_timesteps": 205974, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4591, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4592.0, 1.0, 1.0, 1.0, 4592.0, 4592.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.882, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16389, "number_of_timesteps": 205998, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4592, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4593.0, 1.0, 1.0, 1.0, 4593.0, 4593.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.881, -5.844, 0.0, 0.0, 0.0]}
{"step": 4593, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4594.0, 1.0, 1.0, 1.0, 4594.0, 4594.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.879, -5.842, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16398, "number_of_timesteps": 206093, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4594, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4595.0, 1.0, 1.0, 1.0, 4595.0, 4595.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.882, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16405, "number_of_timesteps": 206162, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4595, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4596.0, 1.0, 1.0, 1.0, 4596.0, 4596.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.88, -5.844, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16408, "number_of_timesteps": 206193, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4596, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4597.0, 1.0, 1.0, 1.0, 4597.0, 4597.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.883, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16413, "number_of_timesteps": 206237, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4597, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4598.0, 1.0, 1.0, 1.0, 4598.0, 4598.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.882, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16418, "number_of_timesteps": 206287, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4598, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4599.0, 1.0, 1.0, 1.0, 4599.0, 4599.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.884, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16421, "number_of_timesteps": 206314, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4599, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4600.0, 1.0, 1.0, 1.0, 4600.0, 4600.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.884, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16427, "number_of_timesteps": 206374, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4600, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4601.0, 1.0, 1.0, 1.0, 4601.0, 4601.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.883, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16431, "number_of_timesteps": 206416, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4601, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4602.0, 1.0, 1.0, 1.0, 4602.0, 4602.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.881, -5.848, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16436, "number_of_timesteps": 206464, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4602, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4603.0, 1.0, 1.0, 1.0, 4603.0, 4603.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.882, -5.846, 0.0, 0.0, 0.0]}
{"step": 4603, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4604.0, 1.0, 1.0, 1.0, 4604.0, 4604.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.882, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16444, "number_of_timesteps": 206547, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4604, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4605.0, 1.0, 1.0, 1.0, 4605.0, 4605.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.881, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16448, "number_of_timesteps": 206590, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4605, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4606.0, 1.0, 1.0, 1.0, 4606.0, 4606.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.881, -5.846, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16453, "number_of_timesteps": 206636, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4606, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4607.0, 1.0, 1.0, 1.0, 4607.0, 4607.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.882, -5.847, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16457, "number_of_timesteps": 206676, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4607, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4608.0, 1.0, 1.0, 1.0, 4608.0, 4608.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.88, -5.845, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16461, "number_of_timesteps": 206715, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4608, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4609.0, 1.0, 1.0, 1.0, 4609.0, 4609.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.883, -5.848, 0.0, 0.0, 0.0]}
{"step": 4609, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4610.0, 1.0, 1.0, 1.0, 4610.0, 4610.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.885, -5.849, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16470, "number_of_timesteps": 206811, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4610, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4611.0, 1.0, 1.0, 1.0, 4611.0, 4611.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.887, -5.852, 0.0, 0.0, 0.0]}
{"step": 4611, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4612.0, 1.0, 1.0, 1.0, 4612.0, 4612.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.89, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16478, "number_of_timesteps": 206897, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4612, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4613.0, 1.0, 1.0, 1.0, 4613.0, 4613.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.888, -5.854, 0.0, 0.0, 0.0]}
{"step": 4613, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4614.0, 1.0, 1.0, 1.0, 4614.0, 4614.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.887, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16487, "number_of_timesteps": 206987, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4614, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4615.0, 1.0, 1.0, 1.0, 4615.0, 4615.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.886, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16489, "number_of_timesteps": 207006, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4615, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4616.0, 1.0, 1.0, 1.0, 4616.0, 4616.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.885, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16496, "number_of_timesteps": 207080, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4616, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4617.0, 1.0, 1.0, 1.0, 4617.0, 4617.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.885, -5.854, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16498, "number_of_timesteps": 207102, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4617, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4618.0, 1.0, 1.0, 1.0, 4618.0, 4618.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.885, -5.853, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16503, "number_of_timesteps": 207152, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4618, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4619.0, 1.0, 1.0, 1.0, 4619.0, 4619.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.888, -5.855, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16508, "number_of_timesteps": 207203, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4619, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4620.0, 1.0, 1.0, 1.0, 4620.0, 4620.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.887, -5.856, 0.0, 0.0, 0.0]}
{"eval_score": 10.1, "number_of_episodes": 16512}
{"number_of_episodes": 16512, "number_of_timesteps": 207239, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4620, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4621.0, 1.0, 1.0, 1.0, 4621.0, 4621.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.887, -5.856, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16517, "number_of_timesteps": 207288, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4621, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4622.0, 1.0, 1.0, 1.0, 4622.0, 4622.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.89, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16520, "number_of_timesteps": 207318, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4622, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4623.0, 1.0, 1.0, 1.0, 4623.0, 4623.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.889, -5.858, 0.0, 0.0, 0.0]}
{"step": 4623, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4624.0, 1.0, 1.0, 1.0, 4624.0, 4624.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.887, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16530, "number_of_timesteps": 207417, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4624, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4625.0, 1.0, 1.0, 1.0, 4625.0, 4625.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.886, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16535, "number_of_timesteps": 207466, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4625, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4626.0, 1.0, 1.0, 1.0, 4626.0, 4626.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.889, -5.862, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16538, "number_of_timesteps": 207496, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4626, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4627.0, 1.0, 1.0, 1.0, 4627.0, 4627.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.89, -5.861, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16544, "number_of_timesteps": 207557, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4627, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4628.0, 1.0, 1.0, 1.0, 4628.0, 4628.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.893, -5.864, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16548, "number_of_timesteps": 207596, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4628, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4629.0, 1.0, 1.0, 1.0, 4629.0, 4629.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.892, -5.863, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16551, "number_of_timesteps": 207624, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4629, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4630.0, 1.0, 1.0, 1.0, 4630.0, 4630.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.892, -5.862, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16557, "number_of_timesteps": 207685, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4630, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4631.0, 1.0, 1.0, 1.0, 4631.0, 4631.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.891, -5.861, 0.0, 0.0, 0.0]}
{"step": 4631, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4632.0, 1.0, 1.0, 1.0, 4632.0, 4632.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.891, -5.859, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16565, "number_of_timesteps": 207771, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4632, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4633.0, 1.0, 1.0, 1.0, 4633.0, 4633.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.892, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16568, "number_of_timesteps": 207805, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4633, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4634.0, 1.0, 1.0, 1.0, 4634.0, 4634.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.89, -5.858, 0.0, 0.0, 0.0]}
{"step": 4634, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4635.0, 1.0, 1.0, 1.0, 4635.0, 4635.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.89, -5.858, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16577, "number_of_timesteps": 207902, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4635, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4636.0, 1.0, 1.0, 1.0, 4636.0, 4636.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.889, -5.858, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16579, "number_of_timesteps": 207923, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4636, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4637.0, 1.0, 1.0, 1.0, 4637.0, 4637.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.887, -5.857, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16586, "number_of_timesteps": 207999, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4637, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4638.0, 1.0, 1.0, 1.0, 4638.0, 4638.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.891, -5.86, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16588, "number_of_timesteps": 208021, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4638, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4639.0, 1.0, 1.0, 1.0, 4639.0, 4639.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.889, -5.86, 0.0, 0.0, 0.0]}
{"step": 4639, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4640.0, 1.0, 1.0, 1.0, 4640.0, 4640.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.893, -5.863, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16597, "number_of_timesteps": 208116, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4640, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4641.0, 1.0, 1.0, 1.0, 4641.0, 4641.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.896, -5.867, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16602, "number_of_timesteps": 208166, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4641, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4642.0, 1.0, 1.0, 1.0, 4642.0, 4642.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.895, -5.867, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16607, "number_of_timesteps": 208213, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4642, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4643.0, 1.0, 1.0, 1.0, 4643.0, 4643.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.898, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16610, "number_of_timesteps": 208242, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4643, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4644.0, 1.0, 1.0, 1.0, 4644.0, 4644.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.897, -5.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16615, "number_of_timesteps": 208293, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4644, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4645.0, 1.0, 1.0, 1.0, 4645.0, 4645.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.898, -5.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16618, "number_of_timesteps": 208326, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4645, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4646.0, 1.0, 1.0, 1.0, 4646.0, 4646.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.898, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16623, "number_of_timesteps": 208374, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4646, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4647.0, 1.0, 1.0, 1.0, 4647.0, 4647.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.902, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16627, "number_of_timesteps": 208418, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4647, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4648.0, 1.0, 1.0, 1.0, 4648.0, 4648.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.901, -5.873, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16632, "number_of_timesteps": 208467, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4648, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4649.0, 1.0, 1.0, 1.0, 4649.0, 4649.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.899, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16637, "number_of_timesteps": 208516, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4649, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4650.0, 1.0, 1.0, 1.0, 4650.0, 4650.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.902, -5.874, 0.0, 0.0, 0.0]}
{"eval_score": 10.2, "number_of_episodes": 16642}
{"number_of_episodes": 16642, "number_of_timesteps": 208562, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4650, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4651.0, 1.0, 1.0, 1.0, 4651.0, 4651.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.902, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16645, "number_of_timesteps": 208590, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4651, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4652.0, 1.0, 1.0, 1.0, 4652.0, 4652.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.903, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16650, "number_of_timesteps": 208643, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4652, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4653.0, 1.0, 1.0, 1.0, 4653.0, 4653.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.902, -5.875, 0.0, 0.0, 0.0]}
{"step": 4653, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4654.0, 1.0, 1.0, 1.0, 4654.0, 4654.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.904, -5.876, 0.0, 0.0, 0.0]}
{"step": 4654, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4655.0, 1.0, 1.0, 1.0, 4655.0, 4655.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.904, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16662, "number_of_timesteps": 208761, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4655, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4656.0, 1.0, 1.0, 1.0, 4656.0, 4656.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.903, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16667, "number_of_timesteps": 208816, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4656, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4657.0, 1.0, 1.0, 1.0, 4657.0, 4657.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.903, -5.875, 0.0, 0.0, 0.0]}
{"step": 4657, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4658.0, 1.0, 1.0, 1.0, 4658.0, 4658.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.903, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16677, "number_of_timesteps": 208913, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4658, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4659.0, 1.0, 1.0, 1.0, 4659.0, 4659.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.902, -5.874, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16679, "number_of_timesteps": 208933, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4659, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4660.0, 1.0, 1.0, 1.0, 4660.0, 4660.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.902, -5.875, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16686, "number_of_timesteps": 209004, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4660, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4661.0, 1.0, 1.0, 1.0, 4661.0, 4661.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.901, -5.873, 0.0, 0.0, 0.0]}
{"step": 4661, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4662.0, 1.0, 1.0, 1.0, 4662.0, 4662.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.901, -5.873, 0.0, 0.0, 0.0]}
{"step": 4662, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4663.0, 1.0, 1.0, 1.0, 4663.0, 4663.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.9, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16697, "number_of_timesteps": 209112, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4663, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4664.0, 1.0, 1.0, 1.0, 4664.0, 4664.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.899, -5.871, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16702, "number_of_timesteps": 209160, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4664, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4665.0, 1.0, 1.0, 1.0, 4665.0, 4665.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.897, -5.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16707, "number_of_timesteps": 209215, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4665, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4666.0, 1.0, 1.0, 1.0, 4666.0, 4666.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.896, -5.868, 0.0, 0.0, 0.0]}
{"step": 4666, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4667.0, 1.0, 1.0, 1.0, 4667.0, 4667.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.897, -5.87, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16714, "number_of_timesteps": 209290, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4667, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4668.0, 1.0, 1.0, 1.0, 4668.0, 4668.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.896, -5.868, 0.0, 0.0, 0.0]}
{"step": 4668, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4669.0, 1.0, 1.0, 1.0, 4669.0, 4669.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.895, -5.869, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16723, "number_of_timesteps": 209383, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4669, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4670.0, 1.0, 1.0, 1.0, 4670.0, 4670.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.893, -5.867, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16726, "number_of_timesteps": 209415, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4670, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4671.0, 1.0, 1.0, 1.0, 4671.0, 4671.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.896, -5.87, 0.0, 0.0, 0.0]}
{"step": 4671, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4672.0, 1.0, 1.0, 1.0, 4672.0, 4672.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.898, -5.872, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16736, "number_of_timesteps": 209520, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4672, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4673.0, 1.0, 1.0, 1.0, 4673.0, 4673.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.901, -5.875, 0.0, 0.0, 0.0]}
{"step": 4673, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4674.0, 1.0, 1.0, 1.0, 4674.0, 4674.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.902, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16745, "number_of_timesteps": 209609, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4674, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4675.0, 1.0, 1.0, 1.0, 4675.0, 4675.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.902, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16748, "number_of_timesteps": 209640, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4675, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4676.0, 1.0, 1.0, 1.0, 4676.0, 4676.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.903, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16752, "number_of_timesteps": 209679, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4676, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4677.0, 1.0, 1.0, 1.0, 4677.0, 4677.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.903, -5.876, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16756, "number_of_timesteps": 209725, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4677, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4678.0, 1.0, 1.0, 1.0, 4678.0, 4678.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.905, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16761, "number_of_timesteps": 209777, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4678, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4679.0, 1.0, 1.0, 1.0, 4679.0, 4679.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.904, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16766, "number_of_timesteps": 209828, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4679, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4680.0, 1.0, 1.0, 1.0, 4680.0, 4680.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.907, -5.88, 0.0, 0.0, 0.0]}
{"eval_score": 10.3, "number_of_episodes": 16770}
{"step": 4680, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4681.0, 1.0, 1.0, 1.0, 4681.0, 4681.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.906, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16774, "number_of_timesteps": 209908, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4681, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4682.0, 1.0, 1.0, 1.0, 4682.0, 4682.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.906, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16778, "number_of_timesteps": 209949, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4682, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4683.0, 1.0, 1.0, 1.0, 4683.0, 4683.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.905, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16784, "number_of_timesteps": 210011, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4683, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4684.0, 1.0, 1.0, 1.0, 4684.0, 4684.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.905, -5.879, 0.0, 0.0, 0.0]}
{"step": 4684, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4685.0, 1.0, 1.0, 1.0, 4685.0, 4685.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.905, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16792, "number_of_timesteps": 210094, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4685, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4686.0, 1.0, 1.0, 1.0, 4686.0, 4686.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.908, -5.882, 0.0, 0.0, 0.0]}
{"step": 4686, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4687.0, 1.0, 1.0, 1.0, 4687.0, 4687.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.911, -5.885, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16799, "number_of_timesteps": 210170, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4687, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4688.0, 1.0, 1.0, 1.0, 4688.0, 4688.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.914, -5.888, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16804, "number_of_timesteps": 210227, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4688, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4689.0, 1.0, 1.0, 1.0, 4689.0, 4689.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.917, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16808, "number_of_timesteps": 210271, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4689, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4690.0, 1.0, 1.0, 1.0, 4690.0, 4690.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.915, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16813, "number_of_timesteps": 210319, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4690, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4691.0, 1.0, 1.0, 1.0, 4691.0, 4691.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.916, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16816, "number_of_timesteps": 210353, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4691, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4692.0, 1.0, 1.0, 1.0, 4692.0, 4692.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.916, -5.888, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16821, "number_of_timesteps": 210406, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4692, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4693.0, 1.0, 1.0, 1.0, 4693.0, 4693.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.919, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16825, "number_of_timesteps": 210448, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4693, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4694.0, 1.0, 1.0, 1.0, 4694.0, 4694.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.917, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16829, "number_of_timesteps": 210487, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4694, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4695.0, 1.0, 1.0, 1.0, 4695.0, 4695.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.918, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16834, "number_of_timesteps": 210539, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4695, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4696.0, 1.0, 1.0, 1.0, 4696.0, 4696.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.917, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16839, "number_of_timesteps": 210588, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4696, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4697.0, 1.0, 1.0, 1.0, 4697.0, 4697.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.919, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16842, "number_of_timesteps": 210616, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4697, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4698.0, 1.0, 1.0, 1.0, 4698.0, 4698.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.919, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16846, "number_of_timesteps": 210662, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4698, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4699.0, 1.0, 1.0, 1.0, 4699.0, 4699.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.919, -5.892, 0.0, 0.0, 0.0]}
{"step": 4699, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4700.0, 1.0, 1.0, 1.0, 4700.0, 4700.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.919, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16856, "number_of_timesteps": 210768, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4700, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4701.0, 1.0, 1.0, 1.0, 4701.0, 4701.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.918, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16861, "number_of_timesteps": 210811, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4701, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4702.0, 1.0, 1.0, 1.0, 4702.0, 4702.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.919, -5.89, 0.0, 0.0, 0.0]}
{"step": 4702, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4703.0, 1.0, 1.0, 1.0, 4703.0, 4703.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.919, -5.89, 0.0, 0.0, 0.0]}
{"step": 4703, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4704.0, 1.0, 1.0, 1.0, 4704.0, 4704.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.919, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16872, "number_of_timesteps": 210927, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4704, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4705.0, 1.0, 1.0, 1.0, 4705.0, 4705.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.922, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16875, "number_of_timesteps": 210956, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4705, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4706.0, 1.0, 1.0, 1.0, 4706.0, 4706.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.921, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16881, "number_of_timesteps": 211021, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4706, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4707.0, 1.0, 1.0, 1.0, 4707.0, 4707.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.92, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16884, "number_of_timesteps": 211053, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4707, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4708.0, 1.0, 1.0, 1.0, 4708.0, 4708.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.921, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16889, "number_of_timesteps": 211103, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4708, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4709.0, 1.0, 1.0, 1.0, 4709.0, 4709.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.924, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16893, "number_of_timesteps": 211144, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4709, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4710.0, 1.0, 1.0, 1.0, 4710.0, 4710.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.922, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16897, "number_of_timesteps": 211186, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4710, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4711.0, 1.0, 1.0, 1.0, 4711.0, 4711.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.921, -5.891, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 16903}
{"number_of_episodes": 16903, "number_of_timesteps": 211247, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4711, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4712.0, 1.0, 1.0, 1.0, 4712.0, 4712.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.922, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16907, "number_of_timesteps": 211285, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4712, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4713.0, 1.0, 1.0, 1.0, 4713.0, 4713.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.921, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16910, "number_of_timesteps": 211314, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4713, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4714.0, 1.0, 1.0, 1.0, 4714.0, 4714.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.92, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16917, "number_of_timesteps": 211389, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4714, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4715.0, 1.0, 1.0, 1.0, 4715.0, 4715.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.919, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16919, "number_of_timesteps": 211409, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4715, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4716.0, 1.0, 1.0, 1.0, 4716.0, 4716.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.919, -5.889, 0.0, 0.0, 0.0]}
{"step": 4716, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4717.0, 1.0, 1.0, 1.0, 4717.0, 4717.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.919, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16929, "number_of_timesteps": 211510, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4717, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4718.0, 1.0, 1.0, 1.0, 4718.0, 4718.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.922, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16933, "number_of_timesteps": 211548, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4718, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4719.0, 1.0, 1.0, 1.0, 4719.0, 4719.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.923, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16938, "number_of_timesteps": 211600, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4719, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4720.0, 1.0, 1.0, 1.0, 4720.0, 4720.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.921, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16943, "number_of_timesteps": 211645, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4720, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4721.0, 1.0, 1.0, 1.0, 4721.0, 4721.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.924, -5.895, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16948, "number_of_timesteps": 211694, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4721, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4722.0, 1.0, 1.0, 1.0, 4722.0, 4722.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.927, -5.898, 0.0, 0.0, 0.0]}
{"step": 4722, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4723.0, 1.0, 1.0, 1.0, 4723.0, 4723.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.93, -5.9, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16958, "number_of_timesteps": 211797, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4723, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4724.0, 1.0, 1.0, 1.0, 4724.0, 4724.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.929, -5.899, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16960, "number_of_timesteps": 211816, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4724, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4725.0, 1.0, 1.0, 1.0, 4725.0, 4725.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.927, -5.898, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16964, "number_of_timesteps": 211855, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4725, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4726.0, 1.0, 1.0, 1.0, 4726.0, 4726.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.926, -5.897, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16969, "number_of_timesteps": 211909, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4726, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4727.0, 1.0, 1.0, 1.0, 4727.0, 4727.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.925, -5.895, 0.0, 0.0, 0.0]}
{"step": 4727, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4728.0, 1.0, 1.0, 1.0, 4728.0, 4728.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.924, -5.894, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16978, "number_of_timesteps": 212007, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4728, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4729.0, 1.0, 1.0, 1.0, 4729.0, 4729.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.923, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16982, "number_of_timesteps": 212046, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4729, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4730.0, 1.0, 1.0, 1.0, 4730.0, 4730.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.923, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16988, "number_of_timesteps": 212109, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4730, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4731.0, 1.0, 1.0, 1.0, 4731.0, 4731.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.922, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 16992, "number_of_timesteps": 212146, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4731, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4732.0, 1.0, 1.0, 1.0, 4732.0, 4732.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.922, -5.891, 0.0, 0.0, 0.0]}
{"step": 4732, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4733.0, 1.0, 1.0, 1.0, 4733.0, 4733.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.922, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17001, "number_of_timesteps": 212239, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4733, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4734.0, 1.0, 1.0, 1.0, 4734.0, 4734.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.92, -5.888, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17004, "number_of_timesteps": 212269, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4734, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4735.0, 1.0, 1.0, 1.0, 4735.0, 4735.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.919, -5.887, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17011, "number_of_timesteps": 212334, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4735, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4736.0, 1.0, 1.0, 1.0, 4736.0, 4736.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.922, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17013, "number_of_timesteps": 212353, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4736, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4737.0, 1.0, 1.0, 1.0, 4737.0, 4737.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.921, -5.889, 0.0, 0.0, 0.0]}
{"step": 4737, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4738.0, 1.0, 1.0, 1.0, 4738.0, 4738.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.921, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17023, "number_of_timesteps": 212453, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4738, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4739.0, 1.0, 1.0, 1.0, 4739.0, 4739.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.92, -5.888, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17026, "number_of_timesteps": 212482, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4739, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4740.0, 1.0, 1.0, 1.0, 4740.0, 4740.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.923, -5.891, 0.0, 0.0, 0.0]}
{"eval_score": 10.2, "number_of_episodes": 17032}
{"step": 4740, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4741.0, 1.0, 1.0, 1.0, 4741.0, 4741.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.922, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17036, "number_of_timesteps": 212580, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4741, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4742.0, 1.0, 1.0, 1.0, 4742.0, 4742.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.922, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17041, "number_of_timesteps": 212625, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4742, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4743.0, 1.0, 1.0, 1.0, 4743.0, 4743.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.921, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17045, "number_of_timesteps": 212667, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4743, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4744.0, 1.0, 1.0, 1.0, 4744.0, 4744.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.921, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17050, "number_of_timesteps": 212714, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4744, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4745.0, 1.0, 1.0, 1.0, 4745.0, 4745.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.921, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17054, "number_of_timesteps": 212756, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4745, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4746.0, 1.0, 1.0, 1.0, 4746.0, 4746.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.92, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17058, "number_of_timesteps": 212795, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4746, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4747.0, 1.0, 1.0, 1.0, 4747.0, 4747.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.923, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17063, "number_of_timesteps": 212849, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4747, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4748.0, 1.0, 1.0, 1.0, 4748.0, 4748.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.926, -5.896, 0.0, 0.0, 0.0]}
{"step": 4748, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4749.0, 1.0, 1.0, 1.0, 4749.0, 4749.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.929, -5.899, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17069, "number_of_timesteps": 212911, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4749, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4750.0, 1.0, 1.0, 1.0, 4750.0, 4750.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.928, -5.898, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17077, "number_of_timesteps": 212997, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4750, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4751.0, 1.0, 1.0, 1.0, 4751.0, 4751.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.927, -5.898, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17078, "number_of_timesteps": 213007, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4751, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4752.0, 1.0, 1.0, 1.0, 4752.0, 4752.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.927, -5.898, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17085, "number_of_timesteps": 213075, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4752, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4753.0, 1.0, 1.0, 1.0, 4753.0, 4753.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.927, -5.898, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17088, "number_of_timesteps": 213108, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4753, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4754.0, 1.0, 1.0, 1.0, 4754.0, 4754.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.926, -5.898, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17093, "number_of_timesteps": 213153, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4754, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4755.0, 1.0, 1.0, 1.0, 4755.0, 4755.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.926, -5.897, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17097, "number_of_timesteps": 213198, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4755, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4756.0, 1.0, 1.0, 1.0, 4756.0, 4756.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.924, -5.896, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17103, "number_of_timesteps": 213254, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4756, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4757.0, 1.0, 1.0, 1.0, 4757.0, 4757.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.925, -5.895, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17105, "number_of_timesteps": 213272, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4757, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4758.0, 1.0, 1.0, 1.0, 4758.0, 4758.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.926, -5.896, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17113, "number_of_timesteps": 213349, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4758, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4759.0, 1.0, 1.0, 1.0, 4759.0, 4759.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.925, -5.895, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17115, "number_of_timesteps": 213369, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4759, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4760.0, 1.0, 1.0, 1.0, 4760.0, 4760.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.925, -5.895, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17120, "number_of_timesteps": 213418, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4760, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4761.0, 1.0, 1.0, 1.0, 4761.0, 4761.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.924, -5.894, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17125, "number_of_timesteps": 213476, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4761, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4762.0, 1.0, 1.0, 1.0, 4762.0, 4762.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.922, -5.894, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17128, "number_of_timesteps": 213504, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4762, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4763.0, 1.0, 1.0, 1.0, 4763.0, 4763.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.921, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17134, "number_of_timesteps": 213567, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4763, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4764.0, 1.0, 1.0, 1.0, 4764.0, 4764.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.92, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17138, "number_of_timesteps": 213609, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4764, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4765.0, 1.0, 1.0, 1.0, 4765.0, 4765.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.92, -5.891, 0.0, 0.0, 0.0]}
{"step": 4765, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4766.0, 1.0, 1.0, 1.0, 4766.0, 4766.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.92, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17148, "number_of_timesteps": 213703, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4766, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4767.0, 1.0, 1.0, 1.0, 4767.0, 4767.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.923, -5.894, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17150, "number_of_timesteps": 213723, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4767, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4768.0, 1.0, 1.0, 1.0, 4768.0, 4768.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.922, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17158, "number_of_timesteps": 213804, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4768, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4769.0, 1.0, 1.0, 1.0, 4769.0, 4769.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.922, -5.893, 0.0, 0.0, 0.0]}
{"eval_score": 9.9, "number_of_episodes": 17160}
{"number_of_episodes": 17160, "number_of_timesteps": 213822, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4769, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4770.0, 1.0, 1.0, 1.0, 4770.0, 4770.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.922, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17163, "number_of_timesteps": 213850, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4770, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4771.0, 1.0, 1.0, 1.0, 4771.0, 4771.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.922, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17170, "number_of_timesteps": 213927, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4771, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4772.0, 1.0, 1.0, 1.0, 4772.0, 4772.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.922, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17172, "number_of_timesteps": 213946, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4772, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4773.0, 1.0, 1.0, 1.0, 4773.0, 4773.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.921, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17179, "number_of_timesteps": 214014, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4773, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4774.0, 1.0, 1.0, 1.0, 4774.0, 4774.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.922, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17181, "number_of_timesteps": 214037, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4774, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4775.0, 1.0, 1.0, 1.0, 4775.0, 4775.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.922, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17187, "number_of_timesteps": 214095, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4775, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4776.0, 1.0, 1.0, 1.0, 4776.0, 4776.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.921, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17191, "number_of_timesteps": 214140, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4776, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4777.0, 1.0, 1.0, 1.0, 4777.0, 4777.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.921, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17195, "number_of_timesteps": 214179, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4777, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4778.0, 1.0, 1.0, 1.0, 4778.0, 4778.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.921, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17199, "number_of_timesteps": 214218, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4778, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4779.0, 1.0, 1.0, 1.0, 4779.0, 4779.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.92, -5.888, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17204, "number_of_timesteps": 214274, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4779, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4780.0, 1.0, 1.0, 1.0, 4780.0, 4780.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.92, -5.888, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17207, "number_of_timesteps": 214304, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4780, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4781.0, 1.0, 1.0, 1.0, 4781.0, 4781.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.92, -5.887, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17214, "number_of_timesteps": 214377, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4781, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4782.0, 1.0, 1.0, 1.0, 4782.0, 4782.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.92, -5.886, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17214, "number_of_timesteps": 214377, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4782, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4783.0, 1.0, 1.0, 1.0, 4783.0, 4783.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.92, -5.886, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17224, "number_of_timesteps": 214475, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4783, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4784.0, 1.0, 1.0, 1.0, 4784.0, 4784.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.919, -5.885, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17224, "number_of_timesteps": 214475, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4784, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4785.0, 1.0, 1.0, 1.0, 4785.0, 4785.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.923, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17232, "number_of_timesteps": 214552, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4785, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4786.0, 1.0, 1.0, 1.0, 4786.0, 4786.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.922, -5.888, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17234, "number_of_timesteps": 214578, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4786, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4787.0, 1.0, 1.0, 1.0, 4787.0, 4787.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.921, -5.887, 0.0, 0.0, 0.0]}
{"step": 4787, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4788.0, 1.0, 1.0, 1.0, 4788.0, 4788.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.92, -5.886, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17243, "number_of_timesteps": 214662, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4788, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4789.0, 1.0, 1.0, 1.0, 4789.0, 4789.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.923, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17250, "number_of_timesteps": 214731, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4789, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4790.0, 1.0, 1.0, 1.0, 4790.0, 4790.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.922, -5.89, 0.0, 0.0, 0.0]}
{"step": 4790, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4791.0, 1.0, 1.0, 1.0, 4791.0, 4791.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.921, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17260, "number_of_timesteps": 214824, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4791, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4792.0, 1.0, 1.0, 1.0, 4792.0, 4792.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.923, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17262, "number_of_timesteps": 214844, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4792, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4793.0, 1.0, 1.0, 1.0, 4793.0, 4793.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.922, -5.89, 0.0, 0.0, 0.0]}
{"step": 4793, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4794.0, 1.0, 1.0, 1.0, 4794.0, 4794.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.925, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17272, "number_of_timesteps": 214947, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4794, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4795.0, 1.0, 1.0, 1.0, 4795.0, 4795.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.924, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17275, "number_of_timesteps": 214974, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4795, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4796.0, 1.0, 1.0, 1.0, 4796.0, 4796.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.922, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17282, "number_of_timesteps": 215046, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4796, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4797.0, 1.0, 1.0, 1.0, 4797.0, 4797.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.923, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17285, "number_of_timesteps": 215074, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4797, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4798.0, 1.0, 1.0, 1.0, 4798.0, 4798.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.922, -5.89, 0.0, 0.0, 0.0]}
{"eval_score": 9.3, "number_of_episodes": 17291}
{"number_of_episodes": 17291, "number_of_timesteps": 215131, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4798, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4799.0, 1.0, 1.0, 1.0, 4799.0, 4799.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.925, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17295, "number_of_timesteps": 215171, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4799, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4800.0, 1.0, 1.0, 1.0, 4800.0, 4800.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.925, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17300, "number_of_timesteps": 215220, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4800, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4801.0, 1.0, 1.0, 1.0, 4801.0, 4801.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.924, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17305, "number_of_timesteps": 215268, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4801, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4802.0, 1.0, 1.0, 1.0, 4802.0, 4802.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.923, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17307, "number_of_timesteps": 215287, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4802, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4803.0, 1.0, 1.0, 1.0, 4803.0, 4803.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.921, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17315, "number_of_timesteps": 215367, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4803, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4804.0, 1.0, 1.0, 1.0, 4804.0, 4804.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.92, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17316, "number_of_timesteps": 215377, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4804, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4805.0, 1.0, 1.0, 1.0, 4805.0, 4805.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.92, -5.888, 0.0, 0.0, 0.0]}
{"step": 4805, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4806.0, 1.0, 1.0, 1.0, 4806.0, 4806.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.92, -5.888, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17325, "number_of_timesteps": 215463, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4806, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4807.0, 1.0, 1.0, 1.0, 4807.0, 4807.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.919, -5.887, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17334, "number_of_timesteps": 215549, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4807, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4808.0, 1.0, 1.0, 1.0, 4808.0, 4808.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.919, -5.886, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17335, "number_of_timesteps": 215560, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4808, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4809.0, 1.0, 1.0, 1.0, 4809.0, 4809.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.918, -5.885, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17344, "number_of_timesteps": 215641, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4809, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4810.0, 1.0, 1.0, 1.0, 4810.0, 4810.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.917, -5.885, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17345, "number_of_timesteps": 215649, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4810, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4811.0, 1.0, 1.0, 1.0, 4811.0, 4811.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.916, -5.884, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17352, "number_of_timesteps": 215714, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4811, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4812.0, 1.0, 1.0, 1.0, 4812.0, 4812.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.915, -5.883, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17355, "number_of_timesteps": 215747, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4812, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4813.0, 1.0, 1.0, 1.0, 4813.0, 4813.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.914, -5.882, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17362, "number_of_timesteps": 215810, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4813, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4814.0, 1.0, 1.0, 1.0, 4814.0, 4814.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.913, -5.883, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17365, "number_of_timesteps": 215838, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4814, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4815.0, 1.0, 1.0, 1.0, 4815.0, 4815.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.916, -5.886, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17370, "number_of_timesteps": 215884, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4815, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4816.0, 1.0, 1.0, 1.0, 4816.0, 4816.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.916, -5.886, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17375, "number_of_timesteps": 215933, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4816, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4817.0, 1.0, 1.0, 1.0, 4817.0, 4817.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.915, -5.885, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17379, "number_of_timesteps": 215970, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4817, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4818.0, 1.0, 1.0, 1.0, 4818.0, 4818.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.914, -5.884, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17385, "number_of_timesteps": 216028, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4818, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4819.0, 1.0, 1.0, 1.0, 4819.0, 4819.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.912, -5.883, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17387, "number_of_timesteps": 216048, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4819, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4820.0, 1.0, 1.0, 1.0, 4820.0, 4820.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.911, -5.882, 0.0, 0.0, 0.0]}
{"step": 4820, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4821.0, 1.0, 1.0, 1.0, 4821.0, 4821.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.912, -5.882, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17397, "number_of_timesteps": 216147, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4821, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4822.0, 1.0, 1.0, 1.0, 4822.0, 4822.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.911, -5.881, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17404, "number_of_timesteps": 216214, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4822, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4823.0, 1.0, 1.0, 1.0, 4823.0, 4823.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.911, -5.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17407, "number_of_timesteps": 216245, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4823, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4824.0, 1.0, 1.0, 1.0, 4824.0, 4824.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.912, -5.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17412, "number_of_timesteps": 216294, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4824, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4825.0, 1.0, 1.0, 1.0, 4825.0, 4825.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.91, -5.879, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17415, "number_of_timesteps": 216327, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4825, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4826.0, 1.0, 1.0, 1.0, 4826.0, 4826.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.91, -5.879, 0.0, 0.0, 0.0]}
{"eval_score": 10.4, "number_of_episodes": 17422}
{"number_of_episodes": 17422, "number_of_timesteps": 216398, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4826, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4827.0, 1.0, 1.0, 1.0, 4827.0, 4827.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.909, -5.878, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17425, "number_of_timesteps": 216424, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4827, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4828.0, 1.0, 1.0, 1.0, 4828.0, 4828.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.91, -5.877, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17428, "number_of_timesteps": 216452, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4828, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4829.0, 1.0, 1.0, 1.0, 4829.0, 4829.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.913, -5.88, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17435, "number_of_timesteps": 216527, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4829, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4830.0, 1.0, 1.0, 1.0, 4830.0, 4830.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.914, -5.881, 0.0, 0.0, 0.0]}
{"step": 4830, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4831.0, 1.0, 1.0, 1.0, 4831.0, 4831.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.917, -5.884, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17443, "number_of_timesteps": 216603, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4831, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4832.0, 1.0, 1.0, 1.0, 4832.0, 4832.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.917, -5.884, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17446, "number_of_timesteps": 216637, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4832, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4833.0, 1.0, 1.0, 1.0, 4833.0, 4833.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.916, -5.883, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17452, "number_of_timesteps": 216696, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4833, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4834.0, 1.0, 1.0, 1.0, 4834.0, 4834.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.919, -5.886, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17454, "number_of_timesteps": 216716, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4834, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4835.0, 1.0, 1.0, 1.0, 4835.0, 4835.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.918, -5.885, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17462, "number_of_timesteps": 216795, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4835, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4836.0, 1.0, 1.0, 1.0, 4836.0, 4836.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.921, -5.888, 0.0, 0.0, 0.0]}
{"step": 4836, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4837.0, 1.0, 1.0, 1.0, 4837.0, 4837.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.92, -5.887, 0.0, 0.0, 0.0]}
{"step": 4837, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4838.0, 1.0, 1.0, 1.0, 4838.0, 4838.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.923, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17473, "number_of_timesteps": 216906, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4838, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4839.0, 1.0, 1.0, 1.0, 4839.0, 4839.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.924, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17481, "number_of_timesteps": 216979, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4839, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4840.0, 1.0, 1.0, 1.0, 4840.0, 4840.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.922, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17483, "number_of_timesteps": 216998, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4840, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4841.0, 1.0, 1.0, 1.0, 4841.0, 4841.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.923, -5.89, 0.0, 0.0, 0.0]}
{"step": 4841, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4842.0, 1.0, 1.0, 1.0, 4842.0, 4842.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.922, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17491, "number_of_timesteps": 217078, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4842, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4843.0, 1.0, 1.0, 1.0, 4843.0, 4843.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.922, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17498, "number_of_timesteps": 217148, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4843, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4844.0, 1.0, 1.0, 1.0, 4844.0, 4844.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.923, -5.89, 0.0, 0.0, 0.0]}
{"step": 4844, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4845.0, 1.0, 1.0, 1.0, 4845.0, 4845.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.922, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17507, "number_of_timesteps": 217230, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4845, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4846.0, 1.0, 1.0, 1.0, 4846.0, 4846.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.921, -5.888, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17510, "number_of_timesteps": 217259, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4846, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4847.0, 1.0, 1.0, 1.0, 4847.0, 4847.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.92, -5.887, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17516, "number_of_timesteps": 217318, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4847, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4848.0, 1.0, 1.0, 1.0, 4848.0, 4848.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.918, -5.886, 0.0, 0.0, 0.0]}
{"step": 4848, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4849.0, 1.0, 1.0, 1.0, 4849.0, 4849.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.917, -5.885, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17525, "number_of_timesteps": 217404, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4849, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4850.0, 1.0, 1.0, 1.0, 4850.0, 4850.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.918, -5.885, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17528, "number_of_timesteps": 217436, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4850, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4851.0, 1.0, 1.0, 1.0, 4851.0, 4851.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.922, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17534, "number_of_timesteps": 217495, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4851, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4852.0, 1.0, 1.0, 1.0, 4852.0, 4852.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.925, -5.892, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17537, "number_of_timesteps": 217523, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4852, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4853.0, 1.0, 1.0, 1.0, 4853.0, 4853.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.924, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17541, "number_of_timesteps": 217558, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4853, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4854.0, 1.0, 1.0, 1.0, 4854.0, 4854.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.923, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17546, "number_of_timesteps": 217616, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4854, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4855.0, 1.0, 1.0, 1.0, 4855.0, 4855.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.921, -5.889, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 17551}
{"step": 4855, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4856.0, 1.0, 1.0, 1.0, 4856.0, 4856.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.92, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17555, "number_of_timesteps": 217702, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4856, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4857.0, 1.0, 1.0, 1.0, 4857.0, 4857.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.921, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17561, "number_of_timesteps": 217762, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4857, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4858.0, 1.0, 1.0, 1.0, 4858.0, 4858.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.92, -5.889, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17565, "number_of_timesteps": 217798, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4858, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4859.0, 1.0, 1.0, 1.0, 4859.0, 4859.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.92, -5.89, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17571, "number_of_timesteps": 217853, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4859, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4860.0, 1.0, 1.0, 1.0, 4860.0, 4860.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.919, -5.888, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17574, "number_of_timesteps": 217880, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4860, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4861.0, 1.0, 1.0, 1.0, 4861.0, 4861.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.918, -5.888, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17580, "number_of_timesteps": 217939, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4861, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4862.0, 1.0, 1.0, 1.0, 4862.0, 4862.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.922, -5.891, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17583, "number_of_timesteps": 217972, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4862, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4863.0, 1.0, 1.0, 1.0, 4863.0, 4863.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.925, -5.895, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17590, "number_of_timesteps": 218040, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4863, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4864.0, 1.0, 1.0, 1.0, 4864.0, 4864.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.929, -5.898, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17593, "number_of_timesteps": 218066, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4864, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4865.0, 1.0, 1.0, 1.0, 4865.0, 4865.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.927, -5.897, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17600, "number_of_timesteps": 218132, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4865, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4866.0, 1.0, 1.0, 1.0, 4866.0, 4866.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.926, -5.896, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17603, "number_of_timesteps": 218161, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4866, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4867.0, 1.0, 1.0, 1.0, 4867.0, 4867.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.925, -5.894, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17610, "number_of_timesteps": 218225, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4867, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4868.0, 1.0, 1.0, 1.0, 4868.0, 4868.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.924, -5.893, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17612, "number_of_timesteps": 218244, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4868, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4869.0, 1.0, 1.0, 1.0, 4869.0, 4869.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.927, -5.897, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17619, "number_of_timesteps": 218308, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4869, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4870.0, 1.0, 1.0, 1.0, 4870.0, 4870.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.928, -5.897, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17622, "number_of_timesteps": 218338, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4870, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4871.0, 1.0, 1.0, 1.0, 4871.0, 4871.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.928, -5.897, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17628, "number_of_timesteps": 218393, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4871, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4872.0, 1.0, 1.0, 1.0, 4872.0, 4872.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.929, -5.898, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17632, "number_of_timesteps": 218431, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4872, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4873.0, 1.0, 1.0, 1.0, 4873.0, 4873.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.928, -5.897, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17638, "number_of_timesteps": 218486, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4873, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4874.0, 1.0, 1.0, 1.0, 4874.0, 4874.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.926, -5.896, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17642, "number_of_timesteps": 218525, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4874, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4875.0, 1.0, 1.0, 1.0, 4875.0, 4875.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.929, -5.899, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17648, "number_of_timesteps": 218579, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4875, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4876.0, 1.0, 1.0, 1.0, 4876.0, 4876.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.93, -5.899, 0.0, 0.0, 0.0]}
{"step": 4876, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4877.0, 1.0, 1.0, 1.0, 4877.0, 4877.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.933, -5.902, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17657, "number_of_timesteps": 218664, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4877, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4878.0, 1.0, 1.0, 1.0, 4878.0, 4878.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.933, -5.902, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17660, "number_of_timesteps": 218693, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4878, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4879.0, 1.0, 1.0, 1.0, 4879.0, 4879.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.936, -5.905, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17667, "number_of_timesteps": 218762, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4879, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4880.0, 1.0, 1.0, 1.0, 4880.0, 4880.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.936, -5.904, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17670, "number_of_timesteps": 218791, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4880, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4881.0, 1.0, 1.0, 1.0, 4881.0, 4881.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.939, -5.907, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17675, "number_of_timesteps": 218838, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4881, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4882.0, 1.0, 1.0, 1.0, 4882.0, 4882.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.938, -5.906, 0.0, 0.0, 0.0]}
{"eval_score": 9.9, "number_of_episodes": 17680}
{"number_of_episodes": 17680, "number_of_timesteps": 218889, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4882, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4883.0, 1.0, 1.0, 1.0, 4883.0, 4883.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.94, -5.908, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17685, "number_of_timesteps": 218936, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4883, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4884.0, 1.0, 1.0, 1.0, 4884.0, 4884.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.939, -5.909, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17689, "number_of_timesteps": 218973, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4884, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4885.0, 1.0, 1.0, 1.0, 4885.0, 4885.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.938, -5.908, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17695, "number_of_timesteps": 219033, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4885, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4886.0, 1.0, 1.0, 1.0, 4886.0, 4886.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.938, -5.908, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17699, "number_of_timesteps": 219067, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4886, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4887.0, 1.0, 1.0, 1.0, 4887.0, 4887.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.938, -5.907, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17705, "number_of_timesteps": 219123, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4887, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4888.0, 1.0, 1.0, 1.0, 4888.0, 4888.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.936, -5.906, 0.0, 0.0, 0.0]}
{"step": 4888, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4889.0, 1.0, 1.0, 1.0, 4889.0, 4889.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.935, -5.904, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17715, "number_of_timesteps": 219218, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4889, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4890.0, 1.0, 1.0, 1.0, 4890.0, 4890.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.934, -5.903, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17717, "number_of_timesteps": 219236, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4890, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4891.0, 1.0, 1.0, 1.0, 4891.0, 4891.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.933, -5.902, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17724, "number_of_timesteps": 219300, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4891, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4892.0, 1.0, 1.0, 1.0, 4892.0, 4892.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.937, -5.906, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17725, "number_of_timesteps": 219311, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4892, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4893.0, 1.0, 1.0, 1.0, 4893.0, 4893.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.936, -5.904, 0.0, 0.0, 0.0]}
{"step": 4893, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4894.0, 1.0, 1.0, 1.0, 4894.0, 4894.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.939, -5.908, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17735, "number_of_timesteps": 219410, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4894, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4895.0, 1.0, 1.0, 1.0, 4895.0, 4895.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.939, -5.908, 0.0, 0.0, 0.0]}
{"step": 4895, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4896.0, 1.0, 1.0, 1.0, 4896.0, 4896.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.942, -5.911, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17745, "number_of_timesteps": 219504, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4896, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4897.0, 1.0, 1.0, 1.0, 4897.0, 4897.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.943, -5.91, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17751, "number_of_timesteps": 219558, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4897, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4898.0, 1.0, 1.0, 1.0, 4898.0, 4898.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.943, -5.91, 0.0, 0.0, 0.0]}
{"step": 4898, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4899.0, 1.0, 1.0, 1.0, 4899.0, 4899.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.943, -5.91, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17759, "number_of_timesteps": 219637, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4899, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4900.0, 1.0, 1.0, 1.0, 4900.0, 4900.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.943, -5.911, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17764, "number_of_timesteps": 219689, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4900, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4901.0, 1.0, 1.0, 1.0, 4901.0, 4901.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.946, -5.914, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17768, "number_of_timesteps": 219726, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4901, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4902.0, 1.0, 1.0, 1.0, 4902.0, 4902.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.945, -5.912, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17774, "number_of_timesteps": 219787, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4902, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4903.0, 1.0, 1.0, 1.0, 4903.0, 4903.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.944, -5.911, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17777, "number_of_timesteps": 219816, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4903, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4904.0, 1.0, 1.0, 1.0, 4904.0, 4904.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.943, -5.91, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17784, "number_of_timesteps": 219880, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4904, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4905.0, 1.0, 1.0, 1.0, 4905.0, 4905.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.942, -5.909, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17786, "number_of_timesteps": 219899, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4905, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4906.0, 1.0, 1.0, 1.0, 4906.0, 4906.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.942, -5.909, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17794, "number_of_timesteps": 219974, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4906, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4907.0, 1.0, 1.0, 1.0, 4907.0, 4907.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.941, -5.908, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17795, "number_of_timesteps": 219983, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4907, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4908.0, 1.0, 1.0, 1.0, 4908.0, 4908.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.94, -5.908, 0.0, 0.0, 0.0]}
{"step": 4908, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4909.0, 1.0, 1.0, 1.0, 4909.0, 4909.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.938, -5.908, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17804, "number_of_timesteps": 220070, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4909, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4910.0, 1.0, 1.0, 1.0, 4910.0, 4910.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.939, -5.909, 0.0, 0.0, 0.0]}
{"eval_score": 9.1, "number_of_episodes": 17814}
{"number_of_episodes": 17814, "number_of_timesteps": 220166, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4910, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4911.0, 1.0, 1.0, 1.0, 4911.0, 4911.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.94, -5.909, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17814, "number_of_timesteps": 220166, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4911, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4912.0, 1.0, 1.0, 1.0, 4912.0, 4912.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.939, -5.909, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17822, "number_of_timesteps": 220239, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4912, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4913.0, 1.0, 1.0, 1.0, 4913.0, 4913.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.938, -5.908, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17824, "number_of_timesteps": 220264, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4913, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4914.0, 1.0, 1.0, 1.0, 4914.0, 4914.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.937, -5.908, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17830, "number_of_timesteps": 220323, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4914, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4915.0, 1.0, 1.0, 1.0, 4915.0, 4915.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.936, -5.907, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17834, "number_of_timesteps": 220365, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4915, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4916.0, 1.0, 1.0, 1.0, 4916.0, 4916.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.94, -5.912, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17839, "number_of_timesteps": 220410, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4916, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4917.0, 1.0, 1.0, 1.0, 4917.0, 4917.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.939, -5.911, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17843, "number_of_timesteps": 220447, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4917, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4918.0, 1.0, 1.0, 1.0, 4918.0, 4918.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.938, -5.91, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17849, "number_of_timesteps": 220506, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4918, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4919.0, 1.0, 1.0, 1.0, 4919.0, 4919.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.939, -5.91, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17853, "number_of_timesteps": 220545, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4919, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4920.0, 1.0, 1.0, 1.0, 4920.0, 4920.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.938, -5.91, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17859, "number_of_timesteps": 220601, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4920, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4921.0, 1.0, 1.0, 1.0, 4921.0, 4921.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.941, -5.913, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17863, "number_of_timesteps": 220638, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4921, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4922.0, 1.0, 1.0, 1.0, 4922.0, 4922.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.944, -5.916, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17867, "number_of_timesteps": 220677, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4922, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4923.0, 1.0, 1.0, 1.0, 4923.0, 4923.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.943, -5.915, 0.0, 0.0, 0.0]}
{"step": 4923, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4924.0, 1.0, 1.0, 1.0, 4924.0, 4924.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.946, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17877, "number_of_timesteps": 220777, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4924, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4925.0, 1.0, 1.0, 1.0, 4925.0, 4925.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.947, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17881, "number_of_timesteps": 220814, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4925, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4926.0, 1.0, 1.0, 1.0, 4926.0, 4926.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.947, -5.919, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17886, "number_of_timesteps": 220859, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4926, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4927.0, 1.0, 1.0, 1.0, 4927.0, 4927.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.946, -5.918, 0.0, 0.0, 0.0]}
{"step": 4927, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4928.0, 1.0, 1.0, 1.0, 4928.0, 4928.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.945, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17896, "number_of_timesteps": 220955, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4928, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4929.0, 1.0, 1.0, 1.0, 4929.0, 4929.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.948, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17901, "number_of_timesteps": 221002, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4929, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4930.0, 1.0, 1.0, 1.0, 4930.0, 4930.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.948, -5.92, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17905, "number_of_timesteps": 221038, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4930, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4931.0, 1.0, 1.0, 1.0, 4931.0, 4931.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.949, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17911, "number_of_timesteps": 221094, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4931, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4932.0, 1.0, 1.0, 1.0, 4932.0, 4932.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.948, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17914, "number_of_timesteps": 221122, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4932, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4933.0, 1.0, 1.0, 1.0, 4933.0, 4933.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.947, -5.92, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17921, "number_of_timesteps": 221187, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4933, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4934.0, 1.0, 1.0, 1.0, 4934.0, 4934.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.95, -5.923, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17923, "number_of_timesteps": 221206, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4934, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4935.0, 1.0, 1.0, 1.0, 4935.0, 4935.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.949, -5.922, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17931, "number_of_timesteps": 221282, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4935, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4936.0, 1.0, 1.0, 1.0, 4936.0, 4936.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.949, -5.923, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17933, "number_of_timesteps": 221301, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4936, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4937.0, 1.0, 1.0, 1.0, 4937.0, 4937.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.948, -5.922, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 17941}
{"number_of_episodes": 17941, "number_of_timesteps": 221373, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4937, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4938.0, 1.0, 1.0, 1.0, 4938.0, 4938.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.949, -5.922, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17943, "number_of_timesteps": 221391, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4938, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4939.0, 1.0, 1.0, 1.0, 4939.0, 4939.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.948, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17950, "number_of_timesteps": 221457, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4939, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4940.0, 1.0, 1.0, 1.0, 4940.0, 4940.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.947, -5.92, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17953, "number_of_timesteps": 221487, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4940, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4941.0, 1.0, 1.0, 1.0, 4941.0, 4941.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.95, -5.923, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17960, "number_of_timesteps": 221554, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4941, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4942.0, 1.0, 1.0, 1.0, 4942.0, 4942.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.951, -5.922, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17963, "number_of_timesteps": 221584, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4942, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4943.0, 1.0, 1.0, 1.0, 4943.0, 4943.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.949, -5.92, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17969, "number_of_timesteps": 221640, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4943, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4944.0, 1.0, 1.0, 1.0, 4944.0, 4944.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.948, -5.919, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17973, "number_of_timesteps": 221679, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4944, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4945.0, 1.0, 1.0, 1.0, 4945.0, 4945.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.947, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17979, "number_of_timesteps": 221733, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4945, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4946.0, 1.0, 1.0, 1.0, 4946.0, 4946.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.946, -5.917, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17983, "number_of_timesteps": 221769, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4946, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4947.0, 1.0, 1.0, 1.0, 4947.0, 4947.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.945, -5.916, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17987, "number_of_timesteps": 221808, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4947, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4948.0, 1.0, 1.0, 1.0, 4948.0, 4948.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.944, -5.915, 0.0, 0.0, 0.0]}
{"step": 4948, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4949.0, 1.0, 1.0, 1.0, 4949.0, 4949.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.942, -5.915, 0.0, 0.0, 0.0]}
{"number_of_episodes": 17997, "number_of_timesteps": 221905, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4949, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4950.0, 1.0, 1.0, 1.0, 4950.0, 4950.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.941, -5.916, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18002, "number_of_timesteps": 221952, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4950, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4951.0, 1.0, 1.0, 1.0, 4951.0, 4951.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.94, -5.915, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18006, "number_of_timesteps": 221989, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4951, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4952.0, 1.0, 1.0, 1.0, 4952.0, 4952.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.939, -5.914, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18012, "number_of_timesteps": 222046, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4952, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4953.0, 1.0, 1.0, 1.0, 4953.0, 4953.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.94, -5.915, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18015, "number_of_timesteps": 222075, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4953, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4954.0, 1.0, 1.0, 1.0, 4954.0, 4954.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.94, -5.915, 0.0, 0.0, 0.0]}
{"step": 4954, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4955.0, 1.0, 1.0, 1.0, 4955.0, 4955.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.94, -5.914, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18025, "number_of_timesteps": 222174, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4955, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4956.0, 1.0, 1.0, 1.0, 4956.0, 4956.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.938, -5.913, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18029, "number_of_timesteps": 222211, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4956, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4957.0, 1.0, 1.0, 1.0, 4957.0, 4957.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.941, -5.916, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18035, "number_of_timesteps": 222267, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4957, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4958.0, 1.0, 1.0, 1.0, 4958.0, 4958.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.944, -5.919, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18039, "number_of_timesteps": 222306, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4958, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4959.0, 1.0, 1.0, 1.0, 4959.0, 4959.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.943, -5.918, 0.0, 0.0, 0.0]}
{"step": 4959, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4960.0, 1.0, 1.0, 1.0, 4960.0, 4960.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.942, -5.917, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18049, "number_of_timesteps": 222402, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4960, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4961.0, 1.0, 1.0, 1.0, 4961.0, 4961.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.941, -5.916, 0.0, 0.0, 0.0]}
{"step": 4961, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4962.0, 1.0, 1.0, 1.0, 4962.0, 4962.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.941, -5.916, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18059, "number_of_timesteps": 222499, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4962, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4963.0, 1.0, 1.0, 1.0, 4963.0, 4963.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.942, -5.917, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18062, "number_of_timesteps": 222528, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4963, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4964.0, 1.0, 1.0, 1.0, 4964.0, 4964.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.941, -5.916, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18068, "number_of_timesteps": 222588, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4964, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4965.0, 1.0, 1.0, 1.0, 4965.0, 4965.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.94, -5.914, 0.0, 0.0, 0.0]}
{"eval_score": 8.9, "number_of_episodes": 18072}
{"number_of_episodes": 18072, "number_of_timesteps": 222628, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4965, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4966.0, 1.0, 1.0, 1.0, 4966.0, 4966.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.939, -5.913, 0.0, 0.0, 0.0]}
{"step": 4966, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4967.0, 1.0, 1.0, 1.0, 4967.0, 4967.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.937, -5.912, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18081, "number_of_timesteps": 222712, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4967, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4968.0, 1.0, 1.0, 1.0, 4968.0, 4968.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.938, -5.911, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18087, "number_of_timesteps": 222771, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4968, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4969.0, 1.0, 1.0, 1.0, 4969.0, 4969.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.939, -5.912, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18091, "number_of_timesteps": 222811, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4969, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4970.0, 1.0, 1.0, 1.0, 4970.0, 4970.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.939, -5.91, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18096, "number_of_timesteps": 222858, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4970, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4971.0, 1.0, 1.0, 1.0, 4971.0, 4971.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.943, -5.914, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18100, "number_of_timesteps": 222896, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4971, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4972.0, 1.0, 1.0, 1.0, 4972.0, 4972.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.942, -5.913, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18106, "number_of_timesteps": 222952, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4972, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4973.0, 1.0, 1.0, 1.0, 4973.0, 4973.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.945, -5.916, 0.0, 0.0, 0.0]}
{"step": 4973, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4974.0, 1.0, 1.0, 1.0, 4974.0, 4974.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.944, -5.915, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18115, "number_of_timesteps": 223037, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4974, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4975.0, 1.0, 1.0, 1.0, 4975.0, 4975.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.943, -5.914, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18118, "number_of_timesteps": 223069, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4975, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4976.0, 1.0, 1.0, 1.0, 4976.0, 4976.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.946, -5.917, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18125, "number_of_timesteps": 223137, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4976, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4977.0, 1.0, 1.0, 1.0, 4977.0, 4977.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.945, -5.916, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18128, "number_of_timesteps": 223163, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4977, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4978.0, 1.0, 1.0, 1.0, 4978.0, 4978.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.946, -5.917, 0.0, 0.0, 0.0]}
{"step": 4978, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4979.0, 1.0, 1.0, 1.0, 4979.0, 4979.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.949, -5.92, 0.0, 0.0, 0.0]}
{"step": 4979, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4980.0, 1.0, 1.0, 1.0, 4980.0, 4980.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.949, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18142, "number_of_timesteps": 223296, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4980, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4981.0, 1.0, 1.0, 1.0, 4981.0, 4981.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.95, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18147, "number_of_timesteps": 223350, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4981, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4982.0, 1.0, 1.0, 1.0, 4982.0, 4982.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.95, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18152, "number_of_timesteps": 223398, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4982, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4983.0, 1.0, 1.0, 1.0, 4983.0, 4983.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.949, -5.921, 0.0, 0.0, 0.0]}
{"step": 4983, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4984.0, 1.0, 1.0, 1.0, 4984.0, 4984.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.948, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18160, "number_of_timesteps": 223472, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4984, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4985.0, 1.0, 1.0, 1.0, 4985.0, 4985.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.947, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18167, "number_of_timesteps": 223542, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4985, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4986.0, 1.0, 1.0, 1.0, 4986.0, 4986.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.946, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18170, "number_of_timesteps": 223569, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4986, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4987.0, 1.0, 1.0, 1.0, 4987.0, 4987.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.737, 0.0, 0.0, 0.0, -5.945, -5.92, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18176, "number_of_timesteps": 223621, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4987, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4988.0, 1.0, 1.0, 1.0, 4988.0, 4988.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.943, -5.919, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18179, "number_of_timesteps": 223651, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4988, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4989.0, 1.0, 1.0, 1.0, 4989.0, 4989.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.942, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18184, "number_of_timesteps": 223699, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4989, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4990.0, 1.0, 1.0, 1.0, 4990.0, 4990.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.943, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18189, "number_of_timesteps": 223747, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4990, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4991.0, 1.0, 1.0, 1.0, 4991.0, 4991.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.946, -5.921, 0.0, 0.0, 0.0]}
{"step": 4991, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4992.0, 1.0, 1.0, 1.0, 4992.0, 4992.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.946, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18198, "number_of_timesteps": 223832, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4992, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4993.0, 1.0, 1.0, 1.0, 4993.0, 4993.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.947, -5.922, 0.0, 0.0, 0.0]}
{"eval_score": 9.3, "number_of_episodes": 18204}
{"number_of_episodes": 18204, "number_of_timesteps": 223890, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4993, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4994.0, 1.0, 1.0, 1.0, 4994.0, 4994.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.945, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18207, "number_of_timesteps": 223920, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4994, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4995.0, 1.0, 1.0, 1.0, 4995.0, 4995.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.944, -5.92, 0.0, 0.0, 0.0]}
{"step": 4995, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4996.0, 1.0, 1.0, 1.0, 4996.0, 4996.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.943, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18217, "number_of_timesteps": 224017, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4996, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4997.0, 1.0, 1.0, 1.0, 4997.0, 4997.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.943, -5.917, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18221, "number_of_timesteps": 224056, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4997, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4998.0, 1.0, 1.0, 1.0, 4998.0, 4998.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.733, 0.0, 0.0, 0.0, -5.944, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18226, "number_of_timesteps": 224108, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 4998, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 4999.0, 1.0, 1.0, 1.0, 4999.0, 4999.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.943, -5.916, 0.0, 0.0, 0.0]}
{"step": 4999, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5000.0, 1.0, 1.0, 1.0, 5000.0, 5000.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.732, 0.0, 0.0, 0.0, -5.942, -5.915, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18236, "number_of_timesteps": 224207, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5000, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5001.0, 1.0, 1.0, 1.0, 5001.0, 5001.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.944, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18238, "number_of_timesteps": 224225, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5001, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5002.0, 1.0, 1.0, 1.0, 5002.0, 5002.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.945, -5.919, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18246, "number_of_timesteps": 224307, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5002, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5003.0, 1.0, 1.0, 1.0, 5003.0, 5003.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.945, -5.919, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18248, "number_of_timesteps": 224326, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5003, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5004.0, 1.0, 1.0, 1.0, 5004.0, 5004.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.944, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18256, "number_of_timesteps": 224396, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5004, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5005.0, 1.0, 1.0, 1.0, 5005.0, 5005.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.736, 0.0, 0.0, 0.0, -5.945, -5.917, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18258, "number_of_timesteps": 224414, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5005, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5006.0, 1.0, 1.0, 1.0, 5006.0, 5006.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.948, -5.92, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18265, "number_of_timesteps": 224480, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5006, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5007.0, 1.0, 1.0, 1.0, 5007.0, 5007.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.735, 0.0, 0.0, 0.0, -5.947, -5.92, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18268, "number_of_timesteps": 224508, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5007, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5008.0, 1.0, 1.0, 1.0, 5008.0, 5008.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.734, 0.0, 0.0, 0.0, -5.945, -5.919, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18275, "number_of_timesteps": 224571, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5008, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5009.0, 1.0, 1.0, 1.0, 5009.0, 5009.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.948, -5.922, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18276, "number_of_timesteps": 224580, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5009, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5010.0, 1.0, 1.0, 1.0, 5010.0, 5010.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.949, -5.922, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18283, "number_of_timesteps": 224647, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5010, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5011.0, 1.0, 1.0, 1.0, 5011.0, 5011.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.949, -5.923, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18286, "number_of_timesteps": 224679, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5011, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5012.0, 1.0, 1.0, 1.0, 5012.0, 5012.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.738, 0.0, 0.0, 0.0, -5.948, -5.922, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18291, "number_of_timesteps": 224727, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5012, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5013.0, 1.0, 1.0, 1.0, 5013.0, 5013.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.949, -5.922, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18296, "number_of_timesteps": 224779, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5013, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5014.0, 1.0, 1.0, 1.0, 5014.0, 5014.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.949, -5.923, 0.0, 0.0, 0.0]}
{"step": 5014, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5015.0, 1.0, 1.0, 1.0, 5015.0, 5015.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.95, -5.923, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18306, "number_of_timesteps": 224875, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5015, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5016.0, 1.0, 1.0, 1.0, 5016.0, 5016.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.95, -5.922, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18310, "number_of_timesteps": 224913, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5016, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5017.0, 1.0, 1.0, 1.0, 5017.0, 5017.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.95, -5.923, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18314, "number_of_timesteps": 224950, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5017, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5018.0, 1.0, 1.0, 1.0, 5018.0, 5018.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.949, -5.921, 0.0, 0.0, 0.0]}
{"step": 5018, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5019.0, 1.0, 1.0, 1.0, 5019.0, 5019.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.948, -5.92, 0.0, 0.0, 0.0]}
{"step": 5019, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5020.0, 1.0, 1.0, 1.0, 5020.0, 5020.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.947, -5.919, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18328, "number_of_timesteps": 225087, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5020, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5021.0, 1.0, 1.0, 1.0, 5021.0, 5021.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.947, -5.919, 0.0, 0.0, 0.0]}
{"eval_score": 9.2, "number_of_episodes": 18331}
{"number_of_episodes": 18331, "number_of_timesteps": 225115, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5021, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5022.0, 1.0, 1.0, 1.0, 5022.0, 5022.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.946, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18338, "number_of_timesteps": 225183, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5022, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5023.0, 1.0, 1.0, 1.0, 5023.0, 5023.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.947, -5.917, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18340, "number_of_timesteps": 225202, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5023, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5024.0, 1.0, 1.0, 1.0, 5024.0, 5024.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.947, -5.918, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18347, "number_of_timesteps": 225267, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5024, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5025.0, 1.0, 1.0, 1.0, 5025.0, 5025.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.739, 0.0, 0.0, 0.0, -5.95, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18350, "number_of_timesteps": 225298, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5025, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5026.0, 1.0, 1.0, 1.0, 5026.0, 5026.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.951, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18356, "number_of_timesteps": 225354, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5026, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5027.0, 1.0, 1.0, 1.0, 5027.0, 5027.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.951, -5.922, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18360, "number_of_timesteps": 225394, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5027, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5028.0, 1.0, 1.0, 1.0, 5028.0, 5028.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.95, -5.922, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18366, "number_of_timesteps": 225447, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5028, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5029.0, 1.0, 1.0, 1.0, 5029.0, 5029.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.74, 0.0, 0.0, 0.0, -5.949, -5.921, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18368, "number_of_timesteps": 225466, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5029, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5030.0, 1.0, 1.0, 1.0, 5030.0, 5030.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.952, -5.924, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18373, "number_of_timesteps": 225516, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5030, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5031.0, 1.0, 1.0, 1.0, 5031.0, 5031.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.952, -5.925, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18378, "number_of_timesteps": 225570, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5031, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5032.0, 1.0, 1.0, 1.0, 5032.0, 5032.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.952, -5.924, 0.0, 0.0, 0.0]}
{"step": 5032, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5033.0, 1.0, 1.0, 1.0, 5033.0, 5033.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.952, -5.925, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18387, "number_of_timesteps": 225654, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5033, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5034.0, 1.0, 1.0, 1.0, 5034.0, 5034.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.955, -5.928, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18392, "number_of_timesteps": 225703, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5034, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5035.0, 1.0, 1.0, 1.0, 5035.0, 5035.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.956, -5.926, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18397, "number_of_timesteps": 225753, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5035, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5036.0, 1.0, 1.0, 1.0, 5036.0, 5036.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.959, -5.929, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18400, "number_of_timesteps": 225783, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5036, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5037.0, 1.0, 1.0, 1.0, 5037.0, 5037.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.959, -5.93, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18405, "number_of_timesteps": 225836, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5037, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5038.0, 1.0, 1.0, 1.0, 5038.0, 5038.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.748, 0.0, 0.0, 0.0, -5.958, -5.929, 0.0, 0.0, 0.0]}
{"step": 5038, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5039.0, 1.0, 1.0, 1.0, 5039.0, 5039.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.957, -5.928, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18410, "number_of_timesteps": 225891, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5039, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5040.0, 1.0, 1.0, 1.0, 5040.0, 5040.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.958, -5.929, 0.0, 0.0, 0.0]}
{"step": 5040, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5041.0, 1.0, 1.0, 1.0, 5041.0, 5041.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.961, -5.931, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18420, "number_of_timesteps": 225998, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5041, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5042.0, 1.0, 1.0, 1.0, 5042.0, 5042.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.962, -5.932, 0.0, 0.0, 0.0]}
{"step": 5042, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5043.0, 1.0, 1.0, 1.0, 5043.0, 5043.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.964, -5.935, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18430, "number_of_timesteps": 226100, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5043, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5044.0, 1.0, 1.0, 1.0, 5044.0, 5044.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.965, -5.936, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18435, "number_of_timesteps": 226148, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5044, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5045.0, 1.0, 1.0, 1.0, 5045.0, 5045.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.966, -5.936, 0.0, 0.0, 0.0]}
{"step": 5045, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5046.0, 1.0, 1.0, 1.0, 5046.0, 5046.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.964, -5.935, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18445, "number_of_timesteps": 226248, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5046, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5047.0, 1.0, 1.0, 1.0, 5047.0, 5047.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.963, -5.934, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18449, "number_of_timesteps": 226287, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5047, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5048.0, 1.0, 1.0, 1.0, 5048.0, 5048.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.962, -5.934, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18454, "number_of_timesteps": 226333, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5048, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5049.0, 1.0, 1.0, 1.0, 5049.0, 5049.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.741, 0.0, 0.0, 0.0, -5.961, -5.933, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18459, "number_of_timesteps": 226383, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5049, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5050.0, 1.0, 1.0, 1.0, 5050.0, 5050.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.742, 0.0, 0.0, 0.0, -5.962, -5.934, 0.0, 0.0, 0.0]}
{"eval_score": 9.4, "number_of_episodes": 18461}
{"step": 5050, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5051.0, 1.0, 1.0, 1.0, 5051.0, 5051.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.964, -5.937, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18469, "number_of_timesteps": 226485, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5051, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5052.0, 1.0, 1.0, 1.0, 5052.0, 5052.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.963, -5.937, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18470, "number_of_timesteps": 226494, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5052, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5053.0, 1.0, 1.0, 1.0, 5053.0, 5053.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.963, -5.936, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18479, "number_of_timesteps": 226583, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5053, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5054.0, 1.0, 1.0, 1.0, 5054.0, 5054.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.962, -5.935, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18479, "number_of_timesteps": 226583, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5054, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5055.0, 1.0, 1.0, 1.0, 5055.0, 5055.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.962, -5.935, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18485, "number_of_timesteps": 226641, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5055, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5056.0, 1.0, 1.0, 1.0, 5056.0, 5056.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.965, -5.938, 0.0, 0.0, 0.0]}
{"step": 5056, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5057.0, 1.0, 1.0, 1.0, 5057.0, 5057.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.966, -5.939, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18495, "number_of_timesteps": 226744, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5057, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5058.0, 1.0, 1.0, 1.0, 5058.0, 5058.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.965, -5.939, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18499, "number_of_timesteps": 226779, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5058, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5059.0, 1.0, 1.0, 1.0, 5059.0, 5059.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.743, 0.0, 0.0, 0.0, -5.965, -5.94, 0.0, 0.0, 0.0]}
{"step": 5059, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5060.0, 1.0, 1.0, 1.0, 5060.0, 5060.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.964, -5.94, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18509, "number_of_timesteps": 226874, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5060, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5061.0, 1.0, 1.0, 1.0, 5061.0, 5061.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.964, -5.939, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18514, "number_of_timesteps": 226921, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5061, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5062.0, 1.0, 1.0, 1.0, 5062.0, 5062.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.964, -5.938, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18518, "number_of_timesteps": 226960, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5062, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5063.0, 1.0, 1.0, 1.0, 5063.0, 5063.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.963, -5.939, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18523, "number_of_timesteps": 227009, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5063, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5064.0, 1.0, 1.0, 1.0, 5064.0, 5064.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.962, -5.938, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18528, "number_of_timesteps": 227058, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5064, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5065.0, 1.0, 1.0, 1.0, 5065.0, 5065.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.745, 0.0, 0.0, 0.0, -5.962, -5.938, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18533, "number_of_timesteps": 227103, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5065, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5066.0, 1.0, 1.0, 1.0, 5066.0, 5066.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.965, -5.941, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18538, "number_of_timesteps": 227150, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5066, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5067.0, 1.0, 1.0, 1.0, 5067.0, 5067.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.965, -5.941, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18541, "number_of_timesteps": 227177, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5067, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5068.0, 1.0, 1.0, 1.0, 5068.0, 5068.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.744, 0.0, 0.0, 0.0, -5.964, -5.94, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18546, "number_of_timesteps": 227228, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5068, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5069.0, 1.0, 1.0, 1.0, 5069.0, 5069.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.967, -5.943, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18551, "number_of_timesteps": 227279, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5069, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5070.0, 1.0, 1.0, 1.0, 5070.0, 5070.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.966, -5.944, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18554, "number_of_timesteps": 227307, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5070, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5071.0, 1.0, 1.0, 1.0, 5071.0, 5071.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.965, -5.943, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18560, "number_of_timesteps": 227368, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5071, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5072.0, 1.0, 1.0, 1.0, 5072.0, 5072.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.964, -5.941, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18564, "number_of_timesteps": 227408, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5072, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5073.0, 1.0, 1.0, 1.0, 5073.0, 5073.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.964, -5.94, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18570, "number_of_timesteps": 227466, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5073, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5074.0, 1.0, 1.0, 1.0, 5074.0, 5074.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.964, -5.941, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18572, "number_of_timesteps": 227485, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5074, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5075.0, 1.0, 1.0, 1.0, 5075.0, 5075.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.746, 0.0, 0.0, 0.0, -5.963, -5.939, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18579, "number_of_timesteps": 227555, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5075, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5076.0, 1.0, 1.0, 1.0, 5076.0, 5076.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.747, 0.0, 0.0, 0.0, -5.964, -5.938, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18581, "number_of_timesteps": 227575, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5076, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5077.0, 1.0, 1.0, 1.0, 5077.0, 5077.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.75, 0.0, 0.0, 0.0, -5.966, -5.941, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18588, "number_of_timesteps": 227641, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5077, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5078.0, 1.0, 1.0, 1.0, 5078.0, 5078.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.969, -5.944, 0.0, 0.0, 0.0]}
{"eval_score": 9.9, "number_of_episodes": 18591}
{"number_of_episodes": 18591, "number_of_timesteps": 227672, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5078, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5079.0, 1.0, 1.0, 1.0, 5079.0, 5079.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.968, -5.944, 0.0, 0.0, 0.0]}
{"step": 5079, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5080.0, 1.0, 1.0, 1.0, 5080.0, 5080.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.749, 0.0, 0.0, 0.0, -5.967, -5.944, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18601, "number_of_timesteps": 227768, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5080, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5081.0, 1.0, 1.0, 1.0, 5081.0, 5081.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.97, -5.946, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18605, "number_of_timesteps": 227804, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5081, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5082.0, 1.0, 1.0, 1.0, 5082.0, 5082.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.751, 0.0, 0.0, 0.0, -5.968, -5.945, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18610, "number_of_timesteps": 227858, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5082, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5083.0, 1.0, 1.0, 1.0, 5083.0, 5083.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.752, 0.0, 0.0, 0.0, -5.969, -5.944, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18615, "number_of_timesteps": 227905, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5083, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5084.0, 1.0, 1.0, 1.0, 5084.0, 5084.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.972, -5.947, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18620, "number_of_timesteps": 227948, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5084, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5085.0, 1.0, 1.0, 1.0, 5085.0, 5085.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.972, -5.947, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18624, "number_of_timesteps": 227986, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5085, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5086.0, 1.0, 1.0, 1.0, 5086.0, 5086.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.976, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18628, "number_of_timesteps": 228025, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5086, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5087.0, 1.0, 1.0, 1.0, 5087.0, 5087.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.974, -5.949, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18633, "number_of_timesteps": 228076, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5087, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5088.0, 1.0, 1.0, 1.0, 5088.0, 5088.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.977, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18637, "number_of_timesteps": 228116, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5088, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5089.0, 1.0, 1.0, 1.0, 5089.0, 5089.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.98, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18640, "number_of_timesteps": 228145, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5089, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5090.0, 1.0, 1.0, 1.0, 5090.0, 5090.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.978, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18646, "number_of_timesteps": 228207, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5090, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5091.0, 1.0, 1.0, 1.0, 5091.0, 5091.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.977, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18649, "number_of_timesteps": 228237, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5091, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5092.0, 1.0, 1.0, 1.0, 5092.0, 5092.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.977, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18656, "number_of_timesteps": 228308, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5092, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5093.0, 1.0, 1.0, 1.0, 5093.0, 5093.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.98, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18657, "number_of_timesteps": 228318, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5093, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5094.0, 1.0, 1.0, 1.0, 5094.0, 5094.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.979, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18663, "number_of_timesteps": 228380, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5094, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5095.0, 1.0, 1.0, 1.0, 5095.0, 5095.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.979, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18667, "number_of_timesteps": 228423, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5095, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5096.0, 1.0, 1.0, 1.0, 5096.0, 5096.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.978, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18671, "number_of_timesteps": 228460, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5096, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5097.0, 1.0, 1.0, 1.0, 5097.0, 5097.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.978, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18676, "number_of_timesteps": 228508, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5097, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5098.0, 1.0, 1.0, 1.0, 5098.0, 5098.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.978, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18681, "number_of_timesteps": 228557, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5098, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5099.0, 1.0, 1.0, 1.0, 5099.0, 5099.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.98, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18685, "number_of_timesteps": 228594, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5099, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5100.0, 1.0, 1.0, 1.0, 5100.0, 5100.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.979, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18688, "number_of_timesteps": 228622, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5100, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5101.0, 1.0, 1.0, 1.0, 5101.0, 5101.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.98, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18694, "number_of_timesteps": 228687, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5101, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5102.0, 1.0, 1.0, 1.0, 5102.0, 5102.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.983, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18697, "number_of_timesteps": 228718, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5102, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5103.0, 1.0, 1.0, 1.0, 5103.0, 5103.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.985, -5.965, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18704, "number_of_timesteps": 228783, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5103, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5104.0, 1.0, 1.0, 1.0, 5104.0, 5104.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.986, -5.965, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18706, "number_of_timesteps": 228802, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5104, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5105.0, 1.0, 1.0, 1.0, 5105.0, 5105.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.984, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18713, "number_of_timesteps": 228872, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5105, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5106.0, 1.0, 1.0, 1.0, 5106.0, 5106.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.983, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18715, "number_of_timesteps": 228892, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5106, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5107.0, 1.0, 1.0, 1.0, 5107.0, 5107.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.984, -5.964, 0.0, 0.0, 0.0]}
{"eval_score": 10.2, "number_of_episodes": 18721}
{"number_of_episodes": 18721, "number_of_timesteps": 228952, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5107, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5108.0, 1.0, 1.0, 1.0, 5108.0, 5108.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.984, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18725, "number_of_timesteps": 228994, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5108, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5109.0, 1.0, 1.0, 1.0, 5109.0, 5109.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.983, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18730, "number_of_timesteps": 229040, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5109, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5110.0, 1.0, 1.0, 1.0, 5110.0, 5110.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.982, -5.963, 0.0, 0.0, 0.0]}
{"step": 5110, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5111.0, 1.0, 1.0, 1.0, 5111.0, 5111.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.981, -5.961, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18737, "number_of_timesteps": 229109, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5111, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5112.0, 1.0, 1.0, 1.0, 5112.0, 5112.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.982, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18743, "number_of_timesteps": 229171, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5112, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5113.0, 1.0, 1.0, 1.0, 5113.0, 5113.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.982, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18746, "number_of_timesteps": 229197, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5113, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5114.0, 1.0, 1.0, 1.0, 5114.0, 5114.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.982, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18752, "number_of_timesteps": 229256, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5114, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5115.0, 1.0, 1.0, 1.0, 5115.0, 5115.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.982, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18756, "number_of_timesteps": 229293, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5115, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5116.0, 1.0, 1.0, 1.0, 5116.0, 5116.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.983, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18761, "number_of_timesteps": 229339, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5116, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5117.0, 1.0, 1.0, 1.0, 5117.0, 5117.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.982, -5.961, 0.0, 0.0, 0.0]}
{"step": 5117, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5118.0, 1.0, 1.0, 1.0, 5118.0, 5118.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.98, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18770, "number_of_timesteps": 229425, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5118, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5119.0, 1.0, 1.0, 1.0, 5119.0, 5119.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.981, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18775, "number_of_timesteps": 229474, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5119, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5120.0, 1.0, 1.0, 1.0, 5120.0, 5120.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.983, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18779, "number_of_timesteps": 229512, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5120, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5121.0, 1.0, 1.0, 1.0, 5121.0, 5121.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.982, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18783, "number_of_timesteps": 229551, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5121, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5122.0, 1.0, 1.0, 1.0, 5122.0, 5122.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.981, -5.961, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18788, "number_of_timesteps": 229600, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5122, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5123.0, 1.0, 1.0, 1.0, 5123.0, 5123.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.982, -5.961, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18792, "number_of_timesteps": 229641, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5123, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5124.0, 1.0, 1.0, 1.0, 5124.0, 5124.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.982, -5.961, 0.0, 0.0, 0.0]}
{"step": 5124, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5125.0, 1.0, 1.0, 1.0, 5125.0, 5125.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.981, -5.961, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18801, "number_of_timesteps": 229736, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5125, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5126.0, 1.0, 1.0, 1.0, 5126.0, 5126.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.981, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18805, "number_of_timesteps": 229775, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5126, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5127.0, 1.0, 1.0, 1.0, 5127.0, 5127.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.981, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18810, "number_of_timesteps": 229823, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5127, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5128.0, 1.0, 1.0, 1.0, 5128.0, 5128.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.753, 0.0, 0.0, 0.0, -5.98, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18814, "number_of_timesteps": 229865, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5128, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5129.0, 1.0, 1.0, 1.0, 5129.0, 5129.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.754, 0.0, 0.0, 0.0, -5.979, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18820, "number_of_timesteps": 229924, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5129, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5130.0, 1.0, 1.0, 1.0, 5130.0, 5130.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.982, -5.961, 0.0, 0.0, 0.0]}
{"step": 5130, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5131.0, 1.0, 1.0, 1.0, 5131.0, 5131.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.982, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18829, "number_of_timesteps": 230010, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5131, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5132.0, 1.0, 1.0, 1.0, 5132.0, 5132.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.983, -5.961, 0.0, 0.0, 0.0]}
{"step": 5132, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5133.0, 1.0, 1.0, 1.0, 5133.0, 5133.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.982, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18839, "number_of_timesteps": 230107, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5133, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5134.0, 1.0, 1.0, 1.0, 5134.0, 5134.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.981, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18843, "number_of_timesteps": 230143, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5134, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5135.0, 1.0, 1.0, 1.0, 5135.0, 5135.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.981, -5.957, 0.0, 0.0, 0.0]}
{"step": 5135, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5136.0, 1.0, 1.0, 1.0, 5136.0, 5136.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.98, -5.956, 0.0, 0.0, 0.0]}
{"eval_score": 10.1, "number_of_episodes": 18853}
{"number_of_episodes": 18853, "number_of_timesteps": 230241, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5136, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5137.0, 1.0, 1.0, 1.0, 5137.0, 5137.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.979, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18856, "number_of_timesteps": 230269, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5137, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5138.0, 1.0, 1.0, 1.0, 5138.0, 5138.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.978, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18863, "number_of_timesteps": 230333, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5138, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5139.0, 1.0, 1.0, 1.0, 5139.0, 5139.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.981, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18864, "number_of_timesteps": 230343, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5139, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5140.0, 1.0, 1.0, 1.0, 5140.0, 5140.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.98, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18870, "number_of_timesteps": 230405, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5140, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5141.0, 1.0, 1.0, 1.0, 5141.0, 5141.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.979, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18874, "number_of_timesteps": 230453, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5141, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5142.0, 1.0, 1.0, 1.0, 5142.0, 5142.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.979, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18880, "number_of_timesteps": 230511, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5142, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5143.0, 1.0, 1.0, 1.0, 5143.0, 5143.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.755, 0.0, 0.0, 0.0, -5.978, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18884, "number_of_timesteps": 230548, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5143, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5144.0, 1.0, 1.0, 1.0, 5144.0, 5144.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.978, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18890, "number_of_timesteps": 230605, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5144, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5145.0, 1.0, 1.0, 1.0, 5145.0, 5145.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.978, -5.952, 0.0, 0.0, 0.0]}
{"step": 5145, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5146.0, 1.0, 1.0, 1.0, 5146.0, 5146.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.979, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18899, "number_of_timesteps": 230696, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5146, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5147.0, 1.0, 1.0, 1.0, 5147.0, 5147.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.978, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18903, "number_of_timesteps": 230734, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5147, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5148.0, 1.0, 1.0, 1.0, 5148.0, 5148.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.977, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18908, "number_of_timesteps": 230780, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5148, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5149.0, 1.0, 1.0, 1.0, 5149.0, 5149.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.98, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18913, "number_of_timesteps": 230830, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5149, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5150.0, 1.0, 1.0, 1.0, 5150.0, 5150.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.978, -5.953, 0.0, 0.0, 0.0]}
{"step": 5150, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5151.0, 1.0, 1.0, 1.0, 5151.0, 5151.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.977, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18923, "number_of_timesteps": 230925, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5151, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5152.0, 1.0, 1.0, 1.0, 5152.0, 5152.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.976, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18926, "number_of_timesteps": 230953, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5152, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5153.0, 1.0, 1.0, 1.0, 5153.0, 5153.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.975, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18931, "number_of_timesteps": 231004, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5153, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5154.0, 1.0, 1.0, 1.0, 5154.0, 5154.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.978, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18936, "number_of_timesteps": 231054, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5154, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5155.0, 1.0, 1.0, 1.0, 5155.0, 5155.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.978, -5.952, 0.0, 0.0, 0.0]}
{"step": 5155, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5156.0, 1.0, 1.0, 1.0, 5156.0, 5156.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.978, -5.951, 0.0, 0.0, 0.0]}
{"step": 5156, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5157.0, 1.0, 1.0, 1.0, 5157.0, 5157.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.978, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18948, "number_of_timesteps": 231176, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5157, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5158.0, 1.0, 1.0, 1.0, 5158.0, 5158.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.978, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18955, "number_of_timesteps": 231244, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5158, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5159.0, 1.0, 1.0, 1.0, 5159.0, 5159.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.979, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18957, "number_of_timesteps": 231262, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5159, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5160.0, 1.0, 1.0, 1.0, 5160.0, 5160.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.978, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18964, "number_of_timesteps": 231328, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5160, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5161.0, 1.0, 1.0, 1.0, 5161.0, 5161.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.977, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18967, "number_of_timesteps": 231360, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5161, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5162.0, 1.0, 1.0, 1.0, 5162.0, 5162.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.979, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18974, "number_of_timesteps": 231425, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5162, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5163.0, 1.0, 1.0, 1.0, 5163.0, 5163.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.98, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18976, "number_of_timesteps": 231443, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5163, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5164.0, 1.0, 1.0, 1.0, 5164.0, 5164.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.98, -5.953, 0.0, 0.0, 0.0]}
{"eval_score": 9.1, "number_of_episodes": 18983}
{"number_of_episodes": 18983, "number_of_timesteps": 231512, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5164, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5165.0, 1.0, 1.0, 1.0, 5165.0, 5165.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.978, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18984, "number_of_timesteps": 231523, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5165, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5166.0, 1.0, 1.0, 1.0, 5166.0, 5166.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.979, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18992, "number_of_timesteps": 231602, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5166, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5167.0, 1.0, 1.0, 1.0, 5167.0, 5167.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.978, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 18994, "number_of_timesteps": 231623, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5167, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5168.0, 1.0, 1.0, 1.0, 5168.0, 5168.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.981, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19001, "number_of_timesteps": 231687, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5168, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5169.0, 1.0, 1.0, 1.0, 5169.0, 5169.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.981, -5.955, 0.0, 0.0, 0.0]}
{"step": 5169, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5170.0, 1.0, 1.0, 1.0, 5170.0, 5170.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.982, -5.953, 0.0, 0.0, 0.0]}
{"step": 5170, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5171.0, 1.0, 1.0, 1.0, 5171.0, 5171.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.981, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19013, "number_of_timesteps": 231808, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5171, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5172.0, 1.0, 1.0, 1.0, 5172.0, 5172.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.981, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19018, "number_of_timesteps": 231856, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5172, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5173.0, 1.0, 1.0, 1.0, 5173.0, 5173.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.981, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19022, "number_of_timesteps": 231893, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5173, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5174.0, 1.0, 1.0, 1.0, 5174.0, 5174.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.98, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19027, "number_of_timesteps": 231943, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5174, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5175.0, 1.0, 1.0, 1.0, 5175.0, 5175.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.979, -5.949, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19032, "number_of_timesteps": 231992, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5175, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5176.0, 1.0, 1.0, 1.0, 5176.0, 5176.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.978, -5.948, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19037, "number_of_timesteps": 232037, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5176, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5177.0, 1.0, 1.0, 1.0, 5177.0, 5177.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.981, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19042, "number_of_timesteps": 232085, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5177, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5178.0, 1.0, 1.0, 1.0, 5178.0, 5178.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.771, 0.0, 0.0, 0.0, -5.981, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19044, "number_of_timesteps": 232104, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5178, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5179.0, 1.0, 1.0, 1.0, 5179.0, 5179.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.982, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19052, "number_of_timesteps": 232186, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5179, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5180.0, 1.0, 1.0, 1.0, 5180.0, 5180.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.771, 0.0, 0.0, 0.0, -5.982, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19054, "number_of_timesteps": 232205, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5180, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5181.0, 1.0, 1.0, 1.0, 5181.0, 5181.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.771, 0.0, 0.0, 0.0, -5.982, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19062, "number_of_timesteps": 232279, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5181, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5182.0, 1.0, 1.0, 1.0, 5182.0, 5182.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.981, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19064, "number_of_timesteps": 232298, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5182, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5183.0, 1.0, 1.0, 1.0, 5183.0, 5183.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.773, 0.0, 0.0, 0.0, -5.983, -5.954, 0.0, 0.0, 0.0]}
{"step": 5183, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5184.0, 1.0, 1.0, 1.0, 5184.0, 5184.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.774, 0.0, 0.0, 0.0, -5.984, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19074, "number_of_timesteps": 232392, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5184, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5185.0, 1.0, 1.0, 1.0, 5185.0, 5185.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.773, 0.0, 0.0, 0.0, -5.983, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19080, "number_of_timesteps": 232447, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5185, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5186.0, 1.0, 1.0, 1.0, 5186.0, 5186.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.774, 0.0, 0.0, 0.0, -5.982, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19083, "number_of_timesteps": 232477, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5186, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5187.0, 1.0, 1.0, 1.0, 5187.0, 5187.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.774, 0.0, 0.0, 0.0, -5.983, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19088, "number_of_timesteps": 232524, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5187, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5188.0, 1.0, 1.0, 1.0, 5188.0, 5188.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.774, 0.0, 0.0, 0.0, -5.986, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19092, "number_of_timesteps": 232567, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5188, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5189.0, 1.0, 1.0, 1.0, 5189.0, 5189.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.774, 0.0, 0.0, 0.0, -5.986, -5.958, 0.0, 0.0, 0.0]}
{"step": 5189, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5190.0, 1.0, 1.0, 1.0, 5190.0, 5190.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.774, 0.0, 0.0, 0.0, -5.985, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19101, "number_of_timesteps": 232656, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5190, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5191.0, 1.0, 1.0, 1.0, 5191.0, 5191.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.774, 0.0, 0.0, 0.0, -5.986, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19107, "number_of_timesteps": 232714, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5191, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5192.0, 1.0, 1.0, 1.0, 5192.0, 5192.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.775, 0.0, 0.0, 0.0, -5.986, -5.958, 0.0, 0.0, 0.0]}
{"eval_score": 9.5, "number_of_episodes": 19111}
{"number_of_episodes": 19111, "number_of_timesteps": 232752, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5192, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5193.0, 1.0, 1.0, 1.0, 5193.0, 5193.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.775, 0.0, 0.0, 0.0, -5.986, -5.958, 0.0, 0.0, 0.0]}
{"step": 5193, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5194.0, 1.0, 1.0, 1.0, 5194.0, 5194.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.776, 0.0, 0.0, 0.0, -5.987, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19120, "number_of_timesteps": 232838, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5194, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5195.0, 1.0, 1.0, 1.0, 5195.0, 5195.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.775, 0.0, 0.0, 0.0, -5.986, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19126, "number_of_timesteps": 232899, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5195, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5196.0, 1.0, 1.0, 1.0, 5196.0, 5196.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.776, 0.0, 0.0, 0.0, -5.986, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19128, "number_of_timesteps": 232919, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5196, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5197.0, 1.0, 1.0, 1.0, 5197.0, 5197.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.775, 0.0, 0.0, 0.0, -5.985, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19136, "number_of_timesteps": 233000, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5197, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5198.0, 1.0, 1.0, 1.0, 5198.0, 5198.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.775, 0.0, 0.0, 0.0, -5.985, -5.956, 0.0, 0.0, 0.0]}
{"step": 5198, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5199.0, 1.0, 1.0, 1.0, 5199.0, 5199.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.775, 0.0, 0.0, 0.0, -5.984, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19146, "number_of_timesteps": 233089, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5199, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5200.0, 1.0, 1.0, 1.0, 5200.0, 5200.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.774, 0.0, 0.0, 0.0, -5.983, -5.953, 0.0, 0.0, 0.0]}
{"step": 5200, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5201.0, 1.0, 1.0, 1.0, 5201.0, 5201.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.773, 0.0, 0.0, 0.0, -5.982, -5.952, 0.0, 0.0, 0.0]}
{"step": 5201, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5202.0, 1.0, 1.0, 1.0, 5202.0, 5202.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.772, 0.0, 0.0, 0.0, -5.981, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19156, "number_of_timesteps": 233187, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5202, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5203.0, 1.0, 1.0, 1.0, 5203.0, 5203.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.772, 0.0, 0.0, 0.0, -5.981, -5.951, 0.0, 0.0, 0.0]}
{"step": 5203, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5204.0, 1.0, 1.0, 1.0, 5204.0, 5204.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.773, 0.0, 0.0, 0.0, -5.981, -5.951, 0.0, 0.0, 0.0]}
{"step": 5204, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5205.0, 1.0, 1.0, 1.0, 5205.0, 5205.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.773, 0.0, 0.0, 0.0, -5.981, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19172, "number_of_timesteps": 233346, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5205, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5206.0, 1.0, 1.0, 1.0, 5206.0, 5206.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.773, 0.0, 0.0, 0.0, -5.981, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19175, "number_of_timesteps": 233374, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5206, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5207.0, 1.0, 1.0, 1.0, 5207.0, 5207.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.772, 0.0, 0.0, 0.0, -5.982, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19180, "number_of_timesteps": 233421, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5207, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5208.0, 1.0, 1.0, 1.0, 5208.0, 5208.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.773, 0.0, 0.0, 0.0, -5.982, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19184, "number_of_timesteps": 233467, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5208, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5209.0, 1.0, 1.0, 1.0, 5209.0, 5209.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.775, 0.0, 0.0, 0.0, -5.985, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19188, "number_of_timesteps": 233508, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5209, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5210.0, 1.0, 1.0, 1.0, 5210.0, 5210.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.775, 0.0, 0.0, 0.0, -5.984, -5.954, 0.0, 0.0, 0.0]}
{"step": 5210, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5211.0, 1.0, 1.0, 1.0, 5211.0, 5211.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.774, 0.0, 0.0, 0.0, -5.983, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19198, "number_of_timesteps": 233610, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5211, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5212.0, 1.0, 1.0, 1.0, 5212.0, 5212.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.773, 0.0, 0.0, 0.0, -5.985, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19202, "number_of_timesteps": 233647, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5212, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5213.0, 1.0, 1.0, 1.0, 5213.0, 5213.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.774, 0.0, 0.0, 0.0, -5.986, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19207, "number_of_timesteps": 233693, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5213, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5214.0, 1.0, 1.0, 1.0, 5214.0, 5214.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.775, 0.0, 0.0, 0.0, -5.987, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19211, "number_of_timesteps": 233730, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5214, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5215.0, 1.0, 1.0, 1.0, 5215.0, 5215.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.774, 0.0, 0.0, 0.0, -5.985, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19216, "number_of_timesteps": 233777, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5215, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5216.0, 1.0, 1.0, 1.0, 5216.0, 5216.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.773, 0.0, 0.0, 0.0, -5.984, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19220, "number_of_timesteps": 233816, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5216, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5217.0, 1.0, 1.0, 1.0, 5217.0, 5217.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.772, 0.0, 0.0, 0.0, -5.985, -5.954, 0.0, 0.0, 0.0]}
{"step": 5217, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5218.0, 1.0, 1.0, 1.0, 5218.0, 5218.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.771, 0.0, 0.0, 0.0, -5.988, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19229, "number_of_timesteps": 233909, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5218, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5219.0, 1.0, 1.0, 1.0, 5219.0, 5219.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.771, 0.0, 0.0, 0.0, -5.987, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19234, "number_of_timesteps": 233962, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5219, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5220.0, 1.0, 1.0, 1.0, 5220.0, 5220.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.771, 0.0, 0.0, 0.0, -5.986, -5.956, 0.0, 0.0, 0.0]}
{"step": 5220, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5221.0, 1.0, 1.0, 1.0, 5221.0, 5221.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.985, -5.955, 0.0, 0.0, 0.0]}
{"eval_score": 9.5, "number_of_episodes": 19244}
{"number_of_episodes": 19244, "number_of_timesteps": 234063, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5221, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5222.0, 1.0, 1.0, 1.0, 5222.0, 5222.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.771, 0.0, 0.0, 0.0, -5.985, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19245, "number_of_timesteps": 234073, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5222, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5223.0, 1.0, 1.0, 1.0, 5223.0, 5223.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.771, 0.0, 0.0, 0.0, -5.985, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19253, "number_of_timesteps": 234150, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5223, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5224.0, 1.0, 1.0, 1.0, 5224.0, 5224.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.987, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19255, "number_of_timesteps": 234171, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5224, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5225.0, 1.0, 1.0, 1.0, 5225.0, 5225.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.987, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19260, "number_of_timesteps": 234217, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5225, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5226.0, 1.0, 1.0, 1.0, 5226.0, 5226.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.771, 0.0, 0.0, 0.0, -5.988, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19264, "number_of_timesteps": 234261, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5226, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5227.0, 1.0, 1.0, 1.0, 5227.0, 5227.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.986, -5.957, 0.0, 0.0, 0.0]}
{"step": 5227, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5228.0, 1.0, 1.0, 1.0, 5228.0, 5228.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.985, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19274, "number_of_timesteps": 234364, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5228, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5229.0, 1.0, 1.0, 1.0, 5229.0, 5229.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.986, -5.956, 0.0, 0.0, 0.0]}
{"step": 5229, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5230.0, 1.0, 1.0, 1.0, 5230.0, 5230.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.986, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19282, "number_of_timesteps": 234439, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5230, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5231.0, 1.0, 1.0, 1.0, 5231.0, 5231.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.985, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19287, "number_of_timesteps": 234489, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5231, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5232.0, 1.0, 1.0, 1.0, 5232.0, 5232.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.985, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19292, "number_of_timesteps": 234536, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5232, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5233.0, 1.0, 1.0, 1.0, 5233.0, 5233.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.985, -5.955, 0.0, 0.0, 0.0]}
{"step": 5233, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5234.0, 1.0, 1.0, 1.0, 5234.0, 5234.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.985, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19302, "number_of_timesteps": 234631, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5234, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5235.0, 1.0, 1.0, 1.0, 5235.0, 5235.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.984, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19306, "number_of_timesteps": 234667, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5235, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5236.0, 1.0, 1.0, 1.0, 5236.0, 5236.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.987, -5.955, 0.0, 0.0, 0.0]}
{"step": 5236, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5237.0, 1.0, 1.0, 1.0, 5237.0, 5237.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.986, -5.954, 0.0, 0.0, 0.0]}
{"step": 5237, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5238.0, 1.0, 1.0, 1.0, 5238.0, 5238.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.988, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19320, "number_of_timesteps": 234798, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5238, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5239.0, 1.0, 1.0, 1.0, 5239.0, 5239.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.988, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19324, "number_of_timesteps": 234837, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5239, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5240.0, 1.0, 1.0, 1.0, 5240.0, 5240.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.988, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19330, "number_of_timesteps": 234897, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5240, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5241.0, 1.0, 1.0, 1.0, 5241.0, 5241.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.986, -5.955, 0.0, 0.0, 0.0]}
{"step": 5241, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5242.0, 1.0, 1.0, 1.0, 5242.0, 5242.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.985, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19339, "number_of_timesteps": 234983, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5242, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5243.0, 1.0, 1.0, 1.0, 5243.0, 5243.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.984, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19342, "number_of_timesteps": 235013, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5243, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5244.0, 1.0, 1.0, 1.0, 5244.0, 5244.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.985, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19349, "number_of_timesteps": 235081, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5244, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5245.0, 1.0, 1.0, 1.0, 5245.0, 5245.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.987, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19352, "number_of_timesteps": 235109, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5245, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5246.0, 1.0, 1.0, 1.0, 5246.0, 5246.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.988, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19358, "number_of_timesteps": 235162, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5246, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5247.0, 1.0, 1.0, 1.0, 5247.0, 5247.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.987, -5.955, 0.0, 0.0, 0.0]}
{"step": 5247, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5248.0, 1.0, 1.0, 1.0, 5248.0, 5248.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.985, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19366, "number_of_timesteps": 235237, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5248, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5249.0, 1.0, 1.0, 1.0, 5249.0, 5249.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.984, -5.952, 0.0, 0.0, 0.0]}
{"eval_score": 9.6, "number_of_episodes": 19371}
{"number_of_episodes": 19371, "number_of_timesteps": 235284, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5249, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5250.0, 1.0, 1.0, 1.0, 5250.0, 5250.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.987, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19375, "number_of_timesteps": 235323, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5250, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5251.0, 1.0, 1.0, 1.0, 5251.0, 5251.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.987, -5.954, 0.0, 0.0, 0.0]}
{"step": 5251, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5252.0, 1.0, 1.0, 1.0, 5252.0, 5252.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.987, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19385, "number_of_timesteps": 235420, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5252, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5253.0, 1.0, 1.0, 1.0, 5253.0, 5253.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.986, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19390, "number_of_timesteps": 235464, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5253, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5254.0, 1.0, 1.0, 1.0, 5254.0, 5254.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.986, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19395, "number_of_timesteps": 235512, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5254, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5255.0, 1.0, 1.0, 1.0, 5255.0, 5255.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.985, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19400, "number_of_timesteps": 235555, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5255, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5256.0, 1.0, 1.0, 1.0, 5256.0, 5256.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.986, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19405, "number_of_timesteps": 235600, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5256, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5257.0, 1.0, 1.0, 1.0, 5257.0, 5257.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.984, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19410, "number_of_timesteps": 235647, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5257, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5258.0, 1.0, 1.0, 1.0, 5258.0, 5258.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.985, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19415, "number_of_timesteps": 235693, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5258, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5259.0, 1.0, 1.0, 1.0, 5259.0, 5259.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.985, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19420, "number_of_timesteps": 235737, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5259, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5260.0, 1.0, 1.0, 1.0, 5260.0, 5260.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.986, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19425, "number_of_timesteps": 235785, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5260, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5261.0, 1.0, 1.0, 1.0, 5261.0, 5261.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.985, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19429, "number_of_timesteps": 235822, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5261, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5262.0, 1.0, 1.0, 1.0, 5262.0, 5262.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.986, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19434, "number_of_timesteps": 235876, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5262, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5263.0, 1.0, 1.0, 1.0, 5263.0, 5263.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.985, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19439, "number_of_timesteps": 235925, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5263, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5264.0, 1.0, 1.0, 1.0, 5264.0, 5264.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.984, -5.95, 0.0, 0.0, 0.0]}
{"step": 5264, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5265.0, 1.0, 1.0, 1.0, 5265.0, 5265.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.983, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19447, "number_of_timesteps": 236003, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5265, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5266.0, 1.0, 1.0, 1.0, 5266.0, 5266.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.982, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19452, "number_of_timesteps": 236053, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5266, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5267.0, 1.0, 1.0, 1.0, 5267.0, 5267.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.984, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19457, "number_of_timesteps": 236104, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5267, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5268.0, 1.0, 1.0, 1.0, 5268.0, 5268.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.983, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19460, "number_of_timesteps": 236131, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5268, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5269.0, 1.0, 1.0, 1.0, 5269.0, 5269.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.982, -5.952, 0.0, 0.0, 0.0]}
{"step": 5269, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5270.0, 1.0, 1.0, 1.0, 5270.0, 5270.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.981, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19469, "number_of_timesteps": 236223, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5270, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5271.0, 1.0, 1.0, 1.0, 5271.0, 5271.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.983, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19474, "number_of_timesteps": 236273, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5271, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5272.0, 1.0, 1.0, 1.0, 5272.0, 5272.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.984, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19478, "number_of_timesteps": 236311, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5272, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5273.0, 1.0, 1.0, 1.0, 5273.0, 5273.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.984, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19484, "number_of_timesteps": 236368, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5273, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5274.0, 1.0, 1.0, 1.0, 5274.0, 5274.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.985, -5.954, 0.0, 0.0, 0.0]}
{"step": 5274, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5275.0, 1.0, 1.0, 1.0, 5275.0, 5275.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.987, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19491, "number_of_timesteps": 236435, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5275, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5276.0, 1.0, 1.0, 1.0, 5276.0, 5276.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.988, -5.957, 0.0, 0.0, 0.0]}
{"step": 5276, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5277.0, 1.0, 1.0, 1.0, 5277.0, 5277.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.988, -5.957, 0.0, 0.0, 0.0]}
{"eval_score": 9.4, "number_of_episodes": 19500}
{"number_of_episodes": 19500, "number_of_timesteps": 236527, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5277, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5278.0, 1.0, 1.0, 1.0, 5278.0, 5278.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.987, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19508, "number_of_timesteps": 236602, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5278, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5279.0, 1.0, 1.0, 1.0, 5279.0, 5279.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.989, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19508, "number_of_timesteps": 236602, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5279, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5280.0, 1.0, 1.0, 1.0, 5280.0, 5280.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.99, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19512, "number_of_timesteps": 236643, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5280, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5281.0, 1.0, 1.0, 1.0, 5281.0, 5281.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.989, -5.958, 0.0, 0.0, 0.0]}
{"step": 5281, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5282.0, 1.0, 1.0, 1.0, 5282.0, 5282.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.988, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19522, "number_of_timesteps": 236749, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5282, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5283.0, 1.0, 1.0, 1.0, 5283.0, 5283.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.986, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19527, "number_of_timesteps": 236797, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5283, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5284.0, 1.0, 1.0, 1.0, 5284.0, 5284.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.989, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19532, "number_of_timesteps": 236843, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5284, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5285.0, 1.0, 1.0, 1.0, 5285.0, 5285.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.989, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19534, "number_of_timesteps": 236861, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5285, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5286.0, 1.0, 1.0, 1.0, 5286.0, 5286.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.988, -5.956, 0.0, 0.0, 0.0]}
{"step": 5286, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5287.0, 1.0, 1.0, 1.0, 5287.0, 5287.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.989, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19543, "number_of_timesteps": 236951, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5287, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5288.0, 1.0, 1.0, 1.0, 5288.0, 5288.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.987, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19551, "number_of_timesteps": 237035, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5288, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5289.0, 1.0, 1.0, 1.0, 5289.0, 5289.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.988, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19552, "number_of_timesteps": 237043, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5289, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5290.0, 1.0, 1.0, 1.0, 5290.0, 5290.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.987, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19561, "number_of_timesteps": 237131, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5290, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5291.0, 1.0, 1.0, 1.0, 5291.0, 5291.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.987, -5.952, 0.0, 0.0, 0.0]}
{"step": 5291, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5292.0, 1.0, 1.0, 1.0, 5292.0, 5292.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.986, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19570, "number_of_timesteps": 237216, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5292, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5293.0, 1.0, 1.0, 1.0, 5293.0, 5293.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.986, -5.951, 0.0, 0.0, 0.0]}
{"step": 5293, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5294.0, 1.0, 1.0, 1.0, 5294.0, 5294.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.987, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19575, "number_of_timesteps": 237265, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5294, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5295.0, 1.0, 1.0, 1.0, 5295.0, 5295.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.989, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19580, "number_of_timesteps": 237323, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5295, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5296.0, 1.0, 1.0, 1.0, 5296.0, 5296.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.99, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19584, "number_of_timesteps": 237362, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5296, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5297.0, 1.0, 1.0, 1.0, 5297.0, 5297.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.99, -5.953, 0.0, 0.0, 0.0]}
{"step": 5297, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5298.0, 1.0, 1.0, 1.0, 5298.0, 5298.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.99, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19593, "number_of_timesteps": 237454, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5298, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5299.0, 1.0, 1.0, 1.0, 5299.0, 5299.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.989, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19595, "number_of_timesteps": 237475, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5299, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5300.0, 1.0, 1.0, 1.0, 5300.0, 5300.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.989, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19600, "number_of_timesteps": 237526, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5300, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5301.0, 1.0, 1.0, 1.0, 5301.0, 5301.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.989, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19605, "number_of_timesteps": 237579, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5301, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5302.0, 1.0, 1.0, 1.0, 5302.0, 5302.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.988, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19610, "number_of_timesteps": 237623, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5302, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5303.0, 1.0, 1.0, 1.0, 5303.0, 5303.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.988, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19614, "number_of_timesteps": 237659, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5303, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5304.0, 1.0, 1.0, 1.0, 5304.0, 5304.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.987, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19620, "number_of_timesteps": 237716, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5304, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5305.0, 1.0, 1.0, 1.0, 5305.0, 5305.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.99, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19623, "number_of_timesteps": 237745, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5305, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5306.0, 1.0, 1.0, 1.0, 5306.0, 5306.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.989, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19628, "number_of_timesteps": 237796, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5306, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5307.0, 1.0, 1.0, 1.0, 5307.0, 5307.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.988, -5.954, 0.0, 0.0, 0.0]}
{"eval_score": 10.1, "number_of_episodes": 19633}
{"number_of_episodes": 19633, "number_of_timesteps": 237845, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5307, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5308.0, 1.0, 1.0, 1.0, 5308.0, 5308.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.988, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19637, "number_of_timesteps": 237884, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5308, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5309.0, 1.0, 1.0, 1.0, 5309.0, 5309.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.987, -5.955, 0.0, 0.0, 0.0]}
{"step": 5309, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5310.0, 1.0, 1.0, 1.0, 5310.0, 5310.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.986, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19646, "number_of_timesteps": 237972, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5310, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5311.0, 1.0, 1.0, 1.0, 5311.0, 5311.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.984, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19651, "number_of_timesteps": 238020, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5311, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5312.0, 1.0, 1.0, 1.0, 5312.0, 5312.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.983, -5.951, 0.0, 0.0, 0.0]}
{"step": 5312, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5313.0, 1.0, 1.0, 1.0, 5313.0, 5313.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.982, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19659, "number_of_timesteps": 238095, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5313, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5314.0, 1.0, 1.0, 1.0, 5314.0, 5314.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.982, -5.949, 0.0, 0.0, 0.0]}
{"step": 5314, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5315.0, 1.0, 1.0, 1.0, 5315.0, 5315.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.982, -5.948, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19669, "number_of_timesteps": 238197, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5315, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5316.0, 1.0, 1.0, 1.0, 5316.0, 5316.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.981, -5.947, 0.0, 0.0, 0.0]}
{"step": 5316, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5317.0, 1.0, 1.0, 1.0, 5317.0, 5317.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.98, -5.946, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19679, "number_of_timesteps": 238292, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5317, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5318.0, 1.0, 1.0, 1.0, 5318.0, 5318.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.979, -5.946, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19682, "number_of_timesteps": 238321, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5318, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5319.0, 1.0, 1.0, 1.0, 5319.0, 5319.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.978, -5.945, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19689, "number_of_timesteps": 238390, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5319, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5320.0, 1.0, 1.0, 1.0, 5320.0, 5320.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.981, -5.948, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19692, "number_of_timesteps": 238417, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5320, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5321.0, 1.0, 1.0, 1.0, 5321.0, 5321.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.981, -5.947, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19696, "number_of_timesteps": 238454, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5321, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5322.0, 1.0, 1.0, 1.0, 5322.0, 5322.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.98, -5.946, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19702, "number_of_timesteps": 238516, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5322, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5323.0, 1.0, 1.0, 1.0, 5323.0, 5323.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.981, -5.947, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19706, "number_of_timesteps": 238554, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5323, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5324.0, 1.0, 1.0, 1.0, 5324.0, 5324.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.981, -5.946, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19712, "number_of_timesteps": 238613, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5324, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5325.0, 1.0, 1.0, 1.0, 5325.0, 5325.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.983, -5.949, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19716, "number_of_timesteps": 238650, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5325, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5326.0, 1.0, 1.0, 1.0, 5326.0, 5326.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.983, -5.948, 0.0, 0.0, 0.0]}
{"step": 5326, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5327.0, 1.0, 1.0, 1.0, 5327.0, 5327.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.983, -5.949, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19726, "number_of_timesteps": 238745, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5327, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5328.0, 1.0, 1.0, 1.0, 5328.0, 5328.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.983, -5.949, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19730, "number_of_timesteps": 238782, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5328, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5329.0, 1.0, 1.0, 1.0, 5329.0, 5329.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.983, -5.949, 0.0, 0.0, 0.0]}
{"step": 5329, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5330.0, 1.0, 1.0, 1.0, 5330.0, 5330.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.985, -5.951, 0.0, 0.0, 0.0]}
{"step": 5330, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5331.0, 1.0, 1.0, 1.0, 5331.0, 5331.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.986, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19742, "number_of_timesteps": 238905, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5331, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5332.0, 1.0, 1.0, 1.0, 5332.0, 5332.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.988, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19747, "number_of_timesteps": 238956, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5332, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5333.0, 1.0, 1.0, 1.0, 5333.0, 5333.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.987, -5.953, 0.0, 0.0, 0.0]}
{"step": 5333, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5334.0, 1.0, 1.0, 1.0, 5334.0, 5334.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.99, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19754, "number_of_timesteps": 239029, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5334, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5335.0, 1.0, 1.0, 1.0, 5335.0, 5335.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.989, -5.955, 0.0, 0.0, 0.0]}
{"eval_score": 10.0, "number_of_episodes": 19761}
{"number_of_episodes": 19761, "number_of_timesteps": 239098, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5335, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5336.0, 1.0, 1.0, 1.0, 5336.0, 5336.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.992, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19764, "number_of_timesteps": 239125, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5336, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5337.0, 1.0, 1.0, 1.0, 5337.0, 5337.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.991, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19770, "number_of_timesteps": 239184, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5337, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5338.0, 1.0, 1.0, 1.0, 5338.0, 5338.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.99, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19773, "number_of_timesteps": 239215, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5338, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5339.0, 1.0, 1.0, 1.0, 5339.0, 5339.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.993, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19777, "number_of_timesteps": 239255, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5339, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5340.0, 1.0, 1.0, 1.0, 5340.0, 5340.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.993, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19782, "number_of_timesteps": 239310, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5340, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5341.0, 1.0, 1.0, 1.0, 5341.0, 5341.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.992, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19786, "number_of_timesteps": 239348, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5341, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5342.0, 1.0, 1.0, 1.0, 5342.0, 5342.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.994, -5.96, 0.0, 0.0, 0.0]}
{"step": 5342, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5343.0, 1.0, 1.0, 1.0, 5343.0, 5343.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.993, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19792, "number_of_timesteps": 239407, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5343, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5344.0, 1.0, 1.0, 1.0, 5344.0, 5344.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.992, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19800, "number_of_timesteps": 239493, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5344, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5345.0, 1.0, 1.0, 1.0, 5345.0, 5345.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.994, -5.96, 0.0, 0.0, 0.0]}
{"step": 5345, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5346.0, 1.0, 1.0, 1.0, 5346.0, 5346.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.994, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19808, "number_of_timesteps": 239571, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5346, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5347.0, 1.0, 1.0, 1.0, 5347.0, 5347.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.994, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19811, "number_of_timesteps": 239605, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5347, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5348.0, 1.0, 1.0, 1.0, 5348.0, 5348.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.994, -5.959, 0.0, 0.0, 0.0]}
{"step": 5348, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5349.0, 1.0, 1.0, 1.0, 5349.0, 5349.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.995, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19820, "number_of_timesteps": 239691, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5349, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5350.0, 1.0, 1.0, 1.0, 5350.0, 5350.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.995, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19823, "number_of_timesteps": 239722, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5350, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5351.0, 1.0, 1.0, 1.0, 5351.0, 5351.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.994, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19828, "number_of_timesteps": 239778, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5351, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5352.0, 1.0, 1.0, 1.0, 5352.0, 5352.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.994, -5.956, 0.0, 0.0, 0.0]}
{"step": 5352, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5353.0, 1.0, 1.0, 1.0, 5353.0, 5353.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.993, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19838, "number_of_timesteps": 239882, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5353, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5354.0, 1.0, 1.0, 1.0, 5354.0, 5354.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.994, -5.954, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19839, "number_of_timesteps": 239891, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5354, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5355.0, 1.0, 1.0, 1.0, 5355.0, 5355.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.994, -5.955, 0.0, 0.0, 0.0]}
{"step": 5355, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5356.0, 1.0, 1.0, 1.0, 5356.0, 5356.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.997, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19849, "number_of_timesteps": 239999, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5356, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5357.0, 1.0, 1.0, 1.0, 5357.0, 5357.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.997, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19853, "number_of_timesteps": 240036, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5357, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5358.0, 1.0, 1.0, 1.0, 5358.0, 5358.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.997, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19858, "number_of_timesteps": 240085, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5358, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5359.0, 1.0, 1.0, 1.0, 5359.0, 5359.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.996, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19863, "number_of_timesteps": 240134, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5359, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5360.0, 1.0, 1.0, 1.0, 5360.0, 5360.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.996, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19866, "number_of_timesteps": 240162, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5360, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5361.0, 1.0, 1.0, 1.0, 5361.0, 5361.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.996, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19871, "number_of_timesteps": 240215, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5361, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5362.0, 1.0, 1.0, 1.0, 5362.0, 5362.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.996, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19875, "number_of_timesteps": 240256, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5362, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5363.0, 1.0, 1.0, 1.0, 5363.0, 5363.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.994, -5.956, 0.0, 0.0, 0.0]}
{"step": 5363, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5364.0, 1.0, 1.0, 1.0, 5364.0, 5364.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.996, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19882, "number_of_timesteps": 240334, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5364, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5365.0, 1.0, 1.0, 1.0, 5365.0, 5365.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.995, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19887, "number_of_timesteps": 240387, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5365, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5366.0, 1.0, 1.0, 1.0, 5366.0, 5366.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.995, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19888, "number_of_timesteps": 240396, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5366, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5367.0, 1.0, 1.0, 1.0, 5367.0, 5367.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.995, -5.957, 0.0, 0.0, 0.0]}
{"eval_score": 9.2, "number_of_episodes": 19896}
{"number_of_episodes": 19896, "number_of_timesteps": 240480, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5367, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5368.0, 1.0, 1.0, 1.0, 5368.0, 5368.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.998, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19897, "number_of_timesteps": 240491, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5368, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5369.0, 1.0, 1.0, 1.0, 5369.0, 5369.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.998, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19902, "number_of_timesteps": 240538, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5369, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5370.0, 1.0, 1.0, 1.0, 5370.0, 5370.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.997, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19907, "number_of_timesteps": 240591, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5370, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5371.0, 1.0, 1.0, 1.0, 5371.0, 5371.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.996, -5.959, 0.0, 0.0, 0.0]}
{"step": 5371, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5372.0, 1.0, 1.0, 1.0, 5372.0, 5372.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.995, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19915, "number_of_timesteps": 240671, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5372, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5373.0, 1.0, 1.0, 1.0, 5373.0, 5373.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.993, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19920, "number_of_timesteps": 240722, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5373, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5374.0, 1.0, 1.0, 1.0, 5374.0, 5374.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.994, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19921, "number_of_timesteps": 240732, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5374, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5375.0, 1.0, 1.0, 1.0, 5375.0, 5375.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.993, -5.957, 0.0, 0.0, 0.0]}
{"step": 5375, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5376.0, 1.0, 1.0, 1.0, 5376.0, 5376.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.993, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19930, "number_of_timesteps": 240830, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5376, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5377.0, 1.0, 1.0, 1.0, 5377.0, 5377.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.992, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19936, "number_of_timesteps": 240894, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5377, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5378.0, 1.0, 1.0, 1.0, 5378.0, 5378.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.993, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19939, "number_of_timesteps": 240926, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5378, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5379.0, 1.0, 1.0, 1.0, 5379.0, 5379.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.992, -5.956, 0.0, 0.0, 0.0]}
{"step": 5379, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5380.0, 1.0, 1.0, 1.0, 5380.0, 5380.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.99, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19946, "number_of_timesteps": 240996, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5380, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5381.0, 1.0, 1.0, 1.0, 5381.0, 5381.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.993, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19953, "number_of_timesteps": 241069, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5381, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5382.0, 1.0, 1.0, 1.0, 5382.0, 5382.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.992, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19956, "number_of_timesteps": 241105, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5382, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5383.0, 1.0, 1.0, 1.0, 5383.0, 5383.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.992, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19961, "number_of_timesteps": 241152, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5383, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5384.0, 1.0, 1.0, 1.0, 5384.0, 5384.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.992, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19965, "number_of_timesteps": 241196, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5384, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5385.0, 1.0, 1.0, 1.0, 5385.0, 5385.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.992, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19970, "number_of_timesteps": 241243, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5385, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5386.0, 1.0, 1.0, 1.0, 5386.0, 5386.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.991, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19975, "number_of_timesteps": 241289, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5386, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5387.0, 1.0, 1.0, 1.0, 5387.0, 5387.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.991, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19978, "number_of_timesteps": 241319, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5387, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5388.0, 1.0, 1.0, 1.0, 5388.0, 5388.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.991, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19981, "number_of_timesteps": 241348, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5388, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5389.0, 1.0, 1.0, 1.0, 5389.0, 5389.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.991, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19986, "number_of_timesteps": 241411, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5389, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5390.0, 1.0, 1.0, 1.0, 5390.0, 5390.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.992, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19990, "number_of_timesteps": 241452, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5390, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5391.0, 1.0, 1.0, 1.0, 5391.0, 5391.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.995, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 19993, "number_of_timesteps": 241483, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5391, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5392.0, 1.0, 1.0, 1.0, 5392.0, 5392.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.994, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20000, "number_of_timesteps": 241555, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5392, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5393.0, 1.0, 1.0, 1.0, 5393.0, 5393.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.992, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20003, "number_of_timesteps": 241581, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5393, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5394.0, 1.0, 1.0, 1.0, 5394.0, 5394.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.991, -5.956, 0.0, 0.0, 0.0]}
{"step": 5394, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5395.0, 1.0, 1.0, 1.0, 5395.0, 5395.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.99, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20012, "number_of_timesteps": 241668, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5395, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5396.0, 1.0, 1.0, 1.0, 5396.0, 5396.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.991, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20018, "number_of_timesteps": 241728, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5396, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5397.0, 1.0, 1.0, 1.0, 5397.0, 5397.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.989, -5.952, 0.0, 0.0, 0.0]}
{"eval_score": 10.1, "number_of_episodes": 20021}
{"number_of_episodes": 20021, "number_of_timesteps": 241756, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5397, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5398.0, 1.0, 1.0, 1.0, 5398.0, 5398.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.988, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20025, "number_of_timesteps": 241793, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5398, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5399.0, 1.0, 1.0, 1.0, 5399.0, 5399.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.987, -5.952, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20030, "number_of_timesteps": 241846, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5399, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5400.0, 1.0, 1.0, 1.0, 5400.0, 5400.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.986, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20034, "number_of_timesteps": 241891, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5400, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5401.0, 1.0, 1.0, 1.0, 5401.0, 5401.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.989, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20038, "number_of_timesteps": 241928, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5401, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5402.0, 1.0, 1.0, 1.0, 5402.0, 5402.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.988, -5.952, 0.0, 0.0, 0.0]}
{"step": 5402, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5403.0, 1.0, 1.0, 1.0, 5403.0, 5403.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.987, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20048, "number_of_timesteps": 242027, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5403, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5404.0, 1.0, 1.0, 1.0, 5404.0, 5404.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.985, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20052, "number_of_timesteps": 242063, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5404, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5405.0, 1.0, 1.0, 1.0, 5405.0, 5405.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.985, -5.949, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20057, "number_of_timesteps": 242110, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5405, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5406.0, 1.0, 1.0, 1.0, 5406.0, 5406.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.983, -5.948, 0.0, 0.0, 0.0]}
{"step": 5406, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5407.0, 1.0, 1.0, 1.0, 5407.0, 5407.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.985, -5.949, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20066, "number_of_timesteps": 242201, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5407, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5408.0, 1.0, 1.0, 1.0, 5408.0, 5408.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.985, -5.949, 0.0, 0.0, 0.0]}
{"step": 5408, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5409.0, 1.0, 1.0, 1.0, 5409.0, 5409.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.985, -5.95, 0.0, 0.0, 0.0]}
{"step": 5409, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5410.0, 1.0, 1.0, 1.0, 5410.0, 5410.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.986, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20078, "number_of_timesteps": 242331, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5410, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5411.0, 1.0, 1.0, 1.0, 5411.0, 5411.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.986, -5.95, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20083, "number_of_timesteps": 242385, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5411, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5412.0, 1.0, 1.0, 1.0, 5412.0, 5412.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.986, -5.95, 0.0, 0.0, 0.0]}
{"step": 5412, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5413.0, 1.0, 1.0, 1.0, 5413.0, 5413.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.986, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20092, "number_of_timesteps": 242469, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5413, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5414.0, 1.0, 1.0, 1.0, 5414.0, 5414.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.987, -5.95, 0.0, 0.0, 0.0]}
{"step": 5414, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5415.0, 1.0, 1.0, 1.0, 5415.0, 5415.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.987, -5.948, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20098, "number_of_timesteps": 242530, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5415, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5416.0, 1.0, 1.0, 1.0, 5416.0, 5416.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.987, -5.949, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20104, "number_of_timesteps": 242594, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5416, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5417.0, 1.0, 1.0, 1.0, 5417.0, 5417.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.987, -5.948, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20108, "number_of_timesteps": 242633, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5417, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5418.0, 1.0, 1.0, 1.0, 5418.0, 5418.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.987, -5.947, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20112, "number_of_timesteps": 242670, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5418, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5419.0, 1.0, 1.0, 1.0, 5419.0, 5419.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.986, -5.946, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20117, "number_of_timesteps": 242720, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5419, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5420.0, 1.0, 1.0, 1.0, 5420.0, 5420.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.985, -5.945, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20121, "number_of_timesteps": 242760, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5420, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5421.0, 1.0, 1.0, 1.0, 5421.0, 5421.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.984, -5.944, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20127, "number_of_timesteps": 242819, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5421, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5422.0, 1.0, 1.0, 1.0, 5422.0, 5422.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.983, -5.943, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20129, "number_of_timesteps": 242836, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5422, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5423.0, 1.0, 1.0, 1.0, 5423.0, 5423.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.985, -5.945, 0.0, 0.0, 0.0]}
{"step": 5423, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5424.0, 1.0, 1.0, 1.0, 5424.0, 5424.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.984, -5.944, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20139, "number_of_timesteps": 242936, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5424, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5425.0, 1.0, 1.0, 1.0, 5425.0, 5425.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.983, -5.943, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20145, "number_of_timesteps": 242989, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5425, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5426.0, 1.0, 1.0, 1.0, 5426.0, 5426.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.983, -5.944, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20148, "number_of_timesteps": 243020, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5426, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5427.0, 1.0, 1.0, 1.0, 5427.0, 5427.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.982, -5.943, 0.0, 0.0, 0.0]}
{"eval_score": 10.3, "number_of_episodes": 20154}
{"number_of_episodes": 20154, "number_of_timesteps": 243076, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5427, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5428.0, 1.0, 1.0, 1.0, 5428.0, 5428.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.981, -5.943, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20156, "number_of_timesteps": 243098, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5428, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5429.0, 1.0, 1.0, 1.0, 5429.0, 5429.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.982, -5.942, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20162, "number_of_timesteps": 243159, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5429, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5430.0, 1.0, 1.0, 1.0, 5430.0, 5430.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.98, -5.941, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20165, "number_of_timesteps": 243190, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5430, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5431.0, 1.0, 1.0, 1.0, 5431.0, 5431.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.983, -5.944, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20171, "number_of_timesteps": 243244, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5431, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5432.0, 1.0, 1.0, 1.0, 5432.0, 5432.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.986, -5.947, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20175, "number_of_timesteps": 243285, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5432, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5433.0, 1.0, 1.0, 1.0, 5433.0, 5433.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.985, -5.946, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20180, "number_of_timesteps": 243333, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5433, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5434.0, 1.0, 1.0, 1.0, 5434.0, 5434.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.984, -5.945, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20185, "number_of_timesteps": 243380, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5434, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5435.0, 1.0, 1.0, 1.0, 5435.0, 5435.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.985, -5.945, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20188, "number_of_timesteps": 243408, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5435, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5436.0, 1.0, 1.0, 1.0, 5436.0, 5436.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.984, -5.944, 0.0, 0.0, 0.0]}
{"step": 5436, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5437.0, 1.0, 1.0, 1.0, 5437.0, 5437.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.984, -5.945, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20198, "number_of_timesteps": 243505, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5437, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5438.0, 1.0, 1.0, 1.0, 5438.0, 5438.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.984, -5.944, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20203, "number_of_timesteps": 243550, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5438, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5439.0, 1.0, 1.0, 1.0, 5439.0, 5439.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.982, -5.943, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20207, "number_of_timesteps": 243591, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5439, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5440.0, 1.0, 1.0, 1.0, 5440.0, 5440.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.983, -5.943, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20213, "number_of_timesteps": 243649, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5440, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5441.0, 1.0, 1.0, 1.0, 5441.0, 5441.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.983, -5.944, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20217, "number_of_timesteps": 243686, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5441, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5442.0, 1.0, 1.0, 1.0, 5442.0, 5442.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.986, -5.947, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20222, "number_of_timesteps": 243734, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5442, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5443.0, 1.0, 1.0, 1.0, 5443.0, 5443.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.985, -5.946, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20227, "number_of_timesteps": 243783, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5443, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5444.0, 1.0, 1.0, 1.0, 5444.0, 5444.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.984, -5.945, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20232, "number_of_timesteps": 243830, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5444, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5445.0, 1.0, 1.0, 1.0, 5445.0, 5445.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.988, -5.948, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20235, "number_of_timesteps": 243859, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5445, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5446.0, 1.0, 1.0, 1.0, 5446.0, 5446.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.987, -5.947, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20240, "number_of_timesteps": 243913, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5446, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5447.0, 1.0, 1.0, 1.0, 5447.0, 5447.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.986, -5.948, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20245, "number_of_timesteps": 243964, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5447, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5448.0, 1.0, 1.0, 1.0, 5448.0, 5448.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.989, -5.951, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20250, "number_of_timesteps": 244010, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5448, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5449.0, 1.0, 1.0, 1.0, 5449.0, 5449.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.991, -5.953, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20255, "number_of_timesteps": 244059, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5449, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5450.0, 1.0, 1.0, 1.0, 5450.0, 5450.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.994, -5.956, 0.0, 0.0, 0.0]}
{"step": 5450, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5451.0, 1.0, 1.0, 1.0, 5451.0, 5451.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.994, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20265, "number_of_timesteps": 244155, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5451, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5452.0, 1.0, 1.0, 1.0, 5452.0, 5452.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.992, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20267, "number_of_timesteps": 244173, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5452, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5453.0, 1.0, 1.0, 1.0, 5453.0, 5453.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.994, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20273, "number_of_timesteps": 244235, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5453, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5454.0, 1.0, 1.0, 1.0, 5454.0, 5454.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.992, -5.955, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20277, "number_of_timesteps": 244284, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5454, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5455.0, 1.0, 1.0, 1.0, 5455.0, 5455.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.993, -5.955, 0.0, 0.0, 0.0]}
{"eval_score": 10.0, "number_of_episodes": 20282}
{"number_of_episodes": 20282, "number_of_timesteps": 244331, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5455, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5456.0, 1.0, 1.0, 1.0, 5456.0, 5456.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.995, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20285, "number_of_timesteps": 244358, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5456, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5457.0, 1.0, 1.0, 1.0, 5457.0, 5457.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.995, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20291, "number_of_timesteps": 244420, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5457, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5458.0, 1.0, 1.0, 1.0, 5458.0, 5458.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.998, -5.96, 0.0, 0.0, 0.0]}
{"step": 5458, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5459.0, 1.0, 1.0, 1.0, 5459.0, 5459.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.998, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20300, "number_of_timesteps": 244510, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5459, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5460.0, 1.0, 1.0, 1.0, 5460.0, 5460.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.997, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20304, "number_of_timesteps": 244549, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5460, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5461.0, 1.0, 1.0, 1.0, 5461.0, 5461.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.997, -5.959, 0.0, 0.0, 0.0]}
{"step": 5461, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5462.0, 1.0, 1.0, 1.0, 5462.0, 5462.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.996, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20313, "number_of_timesteps": 244634, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5462, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5463.0, 1.0, 1.0, 1.0, 5463.0, 5463.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.999, -5.961, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20316, "number_of_timesteps": 244664, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5463, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5464.0, 1.0, 1.0, 1.0, 5464.0, 5464.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.999, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20322, "number_of_timesteps": 244725, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5464, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5465.0, 1.0, 1.0, 1.0, 5465.0, 5465.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.998, -5.961, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20325, "number_of_timesteps": 244755, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5465, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5466.0, 1.0, 1.0, 1.0, 5466.0, 5466.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.997, -5.961, 0.0, 0.0, 0.0]}
{"step": 5466, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5467.0, 1.0, 1.0, 1.0, 5467.0, 5467.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.996, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20335, "number_of_timesteps": 244856, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5467, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5468.0, 1.0, 1.0, 1.0, 5468.0, 5468.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.996, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20339, "number_of_timesteps": 244895, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5468, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5469.0, 1.0, 1.0, 1.0, 5469.0, 5469.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.999, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20344, "number_of_timesteps": 244945, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5469, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5470.0, 1.0, 1.0, 1.0, 5470.0, 5470.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.998, -5.961, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20348, "number_of_timesteps": 244987, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5470, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5471.0, 1.0, 1.0, 1.0, 5471.0, 5471.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -6.0, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20351, "number_of_timesteps": 245021, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5471, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5472.0, 1.0, 1.0, 1.0, 5472.0, 5472.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -6.0, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20356, "number_of_timesteps": 245074, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5472, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5473.0, 1.0, 1.0, 1.0, 5473.0, 5473.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -6.0, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20361, "number_of_timesteps": 245125, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5473, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5474.0, 1.0, 1.0, 1.0, 5474.0, 5474.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -6.002, -5.966, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20364, "number_of_timesteps": 245155, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5474, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5475.0, 1.0, 1.0, 1.0, 5475.0, 5475.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -6.001, -5.967, 0.0, 0.0, 0.0]}
{"step": 5475, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5476.0, 1.0, 1.0, 1.0, 5476.0, 5476.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.771, 0.0, 0.0, 0.0, -6.0, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20373, "number_of_timesteps": 245246, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5476, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5477.0, 1.0, 1.0, 1.0, 5477.0, 5477.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.999, -5.966, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20381, "number_of_timesteps": 245325, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5477, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5478.0, 1.0, 1.0, 1.0, 5478.0, 5478.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.998, -5.965, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20383, "number_of_timesteps": 245344, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5478, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5479.0, 1.0, 1.0, 1.0, 5479.0, 5479.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.77, 0.0, 0.0, 0.0, -5.999, -5.965, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20389, "number_of_timesteps": 245402, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5479, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5480.0, 1.0, 1.0, 1.0, 5480.0, 5480.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.769, 0.0, 0.0, 0.0, -5.997, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20392, "number_of_timesteps": 245434, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5480, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5481.0, 1.0, 1.0, 1.0, 5481.0, 5481.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.996, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20396, "number_of_timesteps": 245473, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5481, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5482.0, 1.0, 1.0, 1.0, 5482.0, 5482.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.996, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20401, "number_of_timesteps": 245526, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5482, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5483.0, 1.0, 1.0, 1.0, 5483.0, 5483.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.996, -5.962, 0.0, 0.0, 0.0]}
{"step": 5483, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5484.0, 1.0, 1.0, 1.0, 5484.0, 5484.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.996, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20409, "number_of_timesteps": 245601, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5484, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5485.0, 1.0, 1.0, 1.0, 5485.0, 5485.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.995, -5.961, 0.0, 0.0, 0.0]}
{"eval_score": 9.8, "number_of_episodes": 20414}
{"number_of_episodes": 20414, "number_of_timesteps": 245652, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5485, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5486.0, 1.0, 1.0, 1.0, 5486.0, 5486.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.994, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20418, "number_of_timesteps": 245692, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5486, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5487.0, 1.0, 1.0, 1.0, 5487.0, 5487.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.994, -5.961, 0.0, 0.0, 0.0]}
{"step": 5487, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5488.0, 1.0, 1.0, 1.0, 5488.0, 5488.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -5.995, -5.961, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20427, "number_of_timesteps": 245781, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5488, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5489.0, 1.0, 1.0, 1.0, 5489.0, 5489.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -5.997, -5.964, 0.0, 0.0, 0.0]}
{"step": 5489, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5490.0, 1.0, 1.0, 1.0, 5490.0, 5490.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -5.998, -5.964, 0.0, 0.0, 0.0]}
{"step": 5490, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5491.0, 1.0, 1.0, 1.0, 5491.0, 5491.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.0, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20441, "number_of_timesteps": 245915, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5491, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5492.0, 1.0, 1.0, 1.0, 5492.0, 5492.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -5.999, -5.966, 0.0, 0.0, 0.0]}
{"step": 5492, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5493.0, 1.0, 1.0, 1.0, 5493.0, 5493.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.998, -5.965, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20450, "number_of_timesteps": 246003, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5493, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5494.0, 1.0, 1.0, 1.0, 5494.0, 5494.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -5.999, -5.965, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20454, "number_of_timesteps": 246042, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5494, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5495.0, 1.0, 1.0, 1.0, 5495.0, 5495.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -5.997, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20459, "number_of_timesteps": 246093, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5495, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5496.0, 1.0, 1.0, 1.0, 5496.0, 5496.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.0, -5.967, 0.0, 0.0, 0.0]}
{"step": 5496, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5497.0, 1.0, 1.0, 1.0, 5497.0, 5497.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.999, -5.966, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20469, "number_of_timesteps": 246194, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5497, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5498.0, 1.0, 1.0, 1.0, 5498.0, 5498.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.998, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20470, "number_of_timesteps": 246204, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5498, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5499.0, 1.0, 1.0, 1.0, 5499.0, 5499.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.997, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20477, "number_of_timesteps": 246273, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5499, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5500.0, 1.0, 1.0, 1.0, 5500.0, 5500.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.997, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20480, "number_of_timesteps": 246306, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5500, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5501.0, 1.0, 1.0, 1.0, 5501.0, 5501.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.996, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20485, "number_of_timesteps": 246354, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5501, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5502.0, 1.0, 1.0, 1.0, 5502.0, 5502.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.997, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20489, "number_of_timesteps": 246397, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5502, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5503.0, 1.0, 1.0, 1.0, 5503.0, 5503.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.997, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20495, "number_of_timesteps": 246454, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5503, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5504.0, 1.0, 1.0, 1.0, 5504.0, 5504.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.998, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20499, "number_of_timesteps": 246492, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5504, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5505.0, 1.0, 1.0, 1.0, 5505.0, 5505.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.997, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20504, "number_of_timesteps": 246539, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5505, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5506.0, 1.0, 1.0, 1.0, 5506.0, 5506.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.996, -5.961, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20508, "number_of_timesteps": 246579, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5506, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5507.0, 1.0, 1.0, 1.0, 5507.0, 5507.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -5.997, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20513, "number_of_timesteps": 246631, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5507, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5508.0, 1.0, 1.0, 1.0, 5508.0, 5508.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.996, -5.959, 0.0, 0.0, 0.0]}
{"step": 5508, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5509.0, 1.0, 1.0, 1.0, 5509.0, 5509.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.995, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20521, "number_of_timesteps": 246708, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5509, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5510.0, 1.0, 1.0, 1.0, 5510.0, 5510.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.994, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20526, "number_of_timesteps": 246760, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5510, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5511.0, 1.0, 1.0, 1.0, 5511.0, 5511.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.994, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20530, "number_of_timesteps": 246804, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5511, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5512.0, 1.0, 1.0, 1.0, 5512.0, 5512.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -5.994, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20535, "number_of_timesteps": 246852, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5512, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5513.0, 1.0, 1.0, 1.0, 5513.0, 5513.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.994, -5.957, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20539, "number_of_timesteps": 246892, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5513, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5514.0, 1.0, 1.0, 1.0, 5514.0, 5514.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.993, -5.956, 0.0, 0.0, 0.0]}
{"eval_score": 9.5, "number_of_episodes": 20545}
{"number_of_episodes": 20545, "number_of_timesteps": 246949, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5514, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5515.0, 1.0, 1.0, 1.0, 5515.0, 5515.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.991, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20549, "number_of_timesteps": 246985, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5515, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5516.0, 1.0, 1.0, 1.0, 5516.0, 5516.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.991, -5.956, 0.0, 0.0, 0.0]}
{"step": 5516, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5517.0, 1.0, 1.0, 1.0, 5517.0, 5517.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.991, -5.956, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20558, "number_of_timesteps": 247071, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5517, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5518.0, 1.0, 1.0, 1.0, 5518.0, 5518.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.994, -5.959, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20564, "number_of_timesteps": 247131, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5518, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5519.0, 1.0, 1.0, 1.0, 5519.0, 5519.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.994, -5.958, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20568, "number_of_timesteps": 247168, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5519, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5520.0, 1.0, 1.0, 1.0, 5520.0, 5520.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.997, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20573, "number_of_timesteps": 247215, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5520, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5521.0, 1.0, 1.0, 1.0, 5521.0, 5521.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.998, -5.961, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20578, "number_of_timesteps": 247265, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5521, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5522.0, 1.0, 1.0, 1.0, 5522.0, 5522.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -5.996, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20582, "number_of_timesteps": 247302, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5522, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5523.0, 1.0, 1.0, 1.0, 5523.0, 5523.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -5.997, -5.96, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20587, "number_of_timesteps": 247351, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5523, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5524.0, 1.0, 1.0, 1.0, 5524.0, 5524.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -6.0, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20592, "number_of_timesteps": 247400, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5524, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5525.0, 1.0, 1.0, 1.0, 5525.0, 5525.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.756, 0.0, 0.0, 0.0, -5.999, -5.962, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20596, "number_of_timesteps": 247436, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5525, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5526.0, 1.0, 1.0, 1.0, 5526.0, 5526.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -6.001, -5.965, 0.0, 0.0, 0.0]}
{"step": 5526, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5527.0, 1.0, 1.0, 1.0, 5527.0, 5527.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -6.001, -5.964, 0.0, 0.0, 0.0]}
{"step": 5527, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5528.0, 1.0, 1.0, 1.0, 5528.0, 5528.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.004, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20610, "number_of_timesteps": 247571, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5528, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5529.0, 1.0, 1.0, 1.0, 5529.0, 5529.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.002, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20614, "number_of_timesteps": 247610, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5529, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5530.0, 1.0, 1.0, 1.0, 5530.0, 5530.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -6.001, -5.966, 0.0, 0.0, 0.0]}
{"step": 5530, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5531.0, 1.0, 1.0, 1.0, 5531.0, 5531.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.0, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20623, "number_of_timesteps": 247699, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5531, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5532.0, 1.0, 1.0, 1.0, 5532.0, 5532.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.001, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20626, "number_of_timesteps": 247731, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5532, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5533.0, 1.0, 1.0, 1.0, 5533.0, 5533.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.0, -5.966, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20632, "number_of_timesteps": 247791, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5533, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5534.0, 1.0, 1.0, 1.0, 5534.0, 5534.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.998, -5.965, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20634, "number_of_timesteps": 247814, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5534, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5535.0, 1.0, 1.0, 1.0, 5535.0, 5535.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -5.999, -5.964, 0.0, 0.0, 0.0]}
{"step": 5535, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5536.0, 1.0, 1.0, 1.0, 5536.0, 5536.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -5.998, -5.963, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20644, "number_of_timesteps": 247914, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5536, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5537.0, 1.0, 1.0, 1.0, 5537.0, 5537.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -6.0, -5.965, 0.0, 0.0, 0.0]}
{"step": 5537, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5538.0, 1.0, 1.0, 1.0, 5538.0, 5538.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -6.0, -5.965, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20654, "number_of_timesteps": 248008, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5538, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5539.0, 1.0, 1.0, 1.0, 5539.0, 5539.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -6.003, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20659, "number_of_timesteps": 248054, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5539, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5540.0, 1.0, 1.0, 1.0, 5540.0, 5540.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -6.002, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20663, "number_of_timesteps": 248093, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5540, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5541.0, 1.0, 1.0, 1.0, 5541.0, 5541.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.004, -5.971, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20668, "number_of_timesteps": 248140, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5541, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5542.0, 1.0, 1.0, 1.0, 5542.0, 5542.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.005, -5.971, 0.0, 0.0, 0.0]}
{"eval_score": 9.5, "number_of_episodes": 20671}
{"number_of_episodes": 20671, "number_of_timesteps": 248170, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5542, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5543.0, 1.0, 1.0, 1.0, 5543.0, 5543.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.005, -5.97, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20677, "number_of_timesteps": 248231, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5543, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5544.0, 1.0, 1.0, 1.0, 5544.0, 5544.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.004, -5.969, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20681, "number_of_timesteps": 248269, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5544, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5545.0, 1.0, 1.0, 1.0, 5545.0, 5545.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -6.003, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20686, "number_of_timesteps": 248315, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5545, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5546.0, 1.0, 1.0, 1.0, 5546.0, 5546.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.003, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20690, "number_of_timesteps": 248356, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5546, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5547.0, 1.0, 1.0, 1.0, 5547.0, 5547.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.003, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20694, "number_of_timesteps": 248398, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5547, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5548.0, 1.0, 1.0, 1.0, 5548.0, 5548.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.003, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20699, "number_of_timesteps": 248453, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5548, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5549.0, 1.0, 1.0, 1.0, 5549.0, 5549.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -6.006, -5.97, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20703, "number_of_timesteps": 248490, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5549, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5550.0, 1.0, 1.0, 1.0, 5550.0, 5550.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -6.005, -5.969, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20709, "number_of_timesteps": 248545, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5550, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5551.0, 1.0, 1.0, 1.0, 5551.0, 5551.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -6.008, -5.971, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20711, "number_of_timesteps": 248565, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5551, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5552.0, 1.0, 1.0, 1.0, 5552.0, 5552.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -6.007, -5.97, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20718, "number_of_timesteps": 248635, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5552, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5553.0, 1.0, 1.0, 1.0, 5553.0, 5553.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -6.006, -5.969, 0.0, 0.0, 0.0]}
{"step": 5553, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5554.0, 1.0, 1.0, 1.0, 5554.0, 5554.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.757, 0.0, 0.0, 0.0, -6.005, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20728, "number_of_timesteps": 248735, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5554, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5555.0, 1.0, 1.0, 1.0, 5555.0, 5555.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.758, 0.0, 0.0, 0.0, -6.005, -5.967, 0.0, 0.0, 0.0]}
{"step": 5555, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5556.0, 1.0, 1.0, 1.0, 5556.0, 5556.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -6.006, -5.966, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20735, "number_of_timesteps": 248804, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5556, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5557.0, 1.0, 1.0, 1.0, 5557.0, 5557.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.009, -5.969, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20739, "number_of_timesteps": 248846, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5557, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5558.0, 1.0, 1.0, 1.0, 5558.0, 5558.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.009, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20745, "number_of_timesteps": 248900, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5558, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5559.0, 1.0, 1.0, 1.0, 5559.0, 5559.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.008, -5.968, 0.0, 0.0, 0.0]}
{"step": 5559, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5560.0, 1.0, 1.0, 1.0, 5560.0, 5560.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.009, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20755, "number_of_timesteps": 248991, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5560, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5561.0, 1.0, 1.0, 1.0, 5561.0, 5561.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.008, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20757, "number_of_timesteps": 249011, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5561, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5562.0, 1.0, 1.0, 1.0, 5562.0, 5562.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.007, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20764, "number_of_timesteps": 249077, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5562, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5563.0, 1.0, 1.0, 1.0, 5563.0, 5563.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.007, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20767, "number_of_timesteps": 249106, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5563, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5564.0, 1.0, 1.0, 1.0, 5564.0, 5564.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.006, -5.966, 0.0, 0.0, 0.0]}
{"step": 5564, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5565.0, 1.0, 1.0, 1.0, 5565.0, 5565.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.005, -5.965, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20777, "number_of_timesteps": 249201, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5565, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5566.0, 1.0, 1.0, 1.0, 5566.0, 5566.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.004, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20782, "number_of_timesteps": 249247, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5566, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5567.0, 1.0, 1.0, 1.0, 5567.0, 5567.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.006, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20787, "number_of_timesteps": 249297, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5567, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5568.0, 1.0, 1.0, 1.0, 5568.0, 5568.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.005, -5.966, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20792, "number_of_timesteps": 249342, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5568, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5569.0, 1.0, 1.0, 1.0, 5569.0, 5569.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.008, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20796, "number_of_timesteps": 249381, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5569, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5570.0, 1.0, 1.0, 1.0, 5570.0, 5570.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.008, -5.969, 0.0, 0.0, 0.0]}
{"eval_score": 9.7, "number_of_episodes": 20801}
{"number_of_episodes": 20801, "number_of_timesteps": 249430, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5570, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5571.0, 1.0, 1.0, 1.0, 5571.0, 5571.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.009, -5.969, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20805, "number_of_timesteps": 249469, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5571, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5572.0, 1.0, 1.0, 1.0, 5572.0, 5572.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.011, -5.972, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20811, "number_of_timesteps": 249525, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5572, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5573.0, 1.0, 1.0, 1.0, 5573.0, 5573.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.011, -5.97, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20815, "number_of_timesteps": 249565, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5573, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5574.0, 1.0, 1.0, 1.0, 5574.0, 5574.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.011, -5.971, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20818, "number_of_timesteps": 249594, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5574, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5575.0, 1.0, 1.0, 1.0, 5575.0, 5575.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.01, -5.97, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20824, "number_of_timesteps": 249659, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5575, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5576.0, 1.0, 1.0, 1.0, 5576.0, 5576.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.012, -5.972, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20828, "number_of_timesteps": 249700, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5576, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5577.0, 1.0, 1.0, 1.0, 5577.0, 5577.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -6.011, -5.971, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20832, "number_of_timesteps": 249737, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5577, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5578.0, 1.0, 1.0, 1.0, 5578.0, 5578.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.761, 0.0, 0.0, 0.0, -6.011, -5.97, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20838, "number_of_timesteps": 249799, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5578, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5579.0, 1.0, 1.0, 1.0, 5579.0, 5579.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.76, 0.0, 0.0, 0.0, -6.01, -5.969, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20842, "number_of_timesteps": 249837, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5579, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5580.0, 1.0, 1.0, 1.0, 5580.0, 5580.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.759, 0.0, 0.0, 0.0, -6.009, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20847, "number_of_timesteps": 249884, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5580, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5581.0, 1.0, 1.0, 1.0, 5581.0, 5581.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.762, 0.0, 0.0, 0.0, -6.011, -5.971, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20849, "number_of_timesteps": 249906, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5581, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5582.0, 1.0, 1.0, 1.0, 5582.0, 5582.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.012, -5.971, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20857, "number_of_timesteps": 249987, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5582, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5583.0, 1.0, 1.0, 1.0, 5583.0, 5583.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.763, 0.0, 0.0, 0.0, -6.012, -5.972, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20859, "number_of_timesteps": 250007, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5583, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5584.0, 1.0, 1.0, 1.0, 5584.0, 5584.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.012, -5.972, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20866, "number_of_timesteps": 250070, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5584, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5585.0, 1.0, 1.0, 1.0, 5585.0, 5585.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.013, -5.971, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20867, "number_of_timesteps": 250081, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5585, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5586.0, 1.0, 1.0, 1.0, 5586.0, 5586.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.013, -5.972, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20875, "number_of_timesteps": 250159, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5586, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5587.0, 1.0, 1.0, 1.0, 5587.0, 5587.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.012, -5.971, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20877, "number_of_timesteps": 250179, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5587, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5588.0, 1.0, 1.0, 1.0, 5588.0, 5588.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.013, -5.971, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20883, "number_of_timesteps": 250235, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5588, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5589.0, 1.0, 1.0, 1.0, 5589.0, 5589.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.012, -5.97, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20886, "number_of_timesteps": 250268, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5589, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5590.0, 1.0, 1.0, 1.0, 5590.0, 5590.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.012, -5.97, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20892, "number_of_timesteps": 250326, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5590, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5591.0, 1.0, 1.0, 1.0, 5591.0, 5591.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.012, -5.969, 0.0, 0.0, 0.0]}
{"step": 5591, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5592.0, 1.0, 1.0, 1.0, 5592.0, 5592.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.012, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20901, "number_of_timesteps": 250414, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5592, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5593.0, 1.0, 1.0, 1.0, 5593.0, 5593.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -6.011, -5.969, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20904, "number_of_timesteps": 250443, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5593, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5594.0, 1.0, 1.0, 1.0, 5594.0, 5594.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.01, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20909, "number_of_timesteps": 250492, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5594, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5595.0, 1.0, 1.0, 1.0, 5595.0, 5595.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -6.01, -5.966, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20913, "number_of_timesteps": 250533, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5595, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5596.0, 1.0, 1.0, 1.0, 5596.0, 5596.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -6.01, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20915, "number_of_timesteps": 250553, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5596, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5597.0, 1.0, 1.0, 1.0, 5597.0, 5597.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.009, -5.966, 0.0, 0.0, 0.0]}
{"step": 5597, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5598.0, 1.0, 1.0, 1.0, 5598.0, 5598.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -6.01, -5.966, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20925, "number_of_timesteps": 250659, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5598, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5599.0, 1.0, 1.0, 1.0, 5599.0, 5599.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.012, -5.968, 0.0, 0.0, 0.0]}
{"step": 5599, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5600.0, 1.0, 1.0, 1.0, 5600.0, 5600.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.013, -5.969, 0.0, 0.0, 0.0]}
{"eval_score": 10.5, "number_of_episodes": 20935}
{"number_of_episodes": 20935, "number_of_timesteps": 250763, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5600, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5601.0, 1.0, 1.0, 1.0, 5601.0, 5601.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.013, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20936, "number_of_timesteps": 250772, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5601, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5602.0, 1.0, 1.0, 1.0, 5602.0, 5602.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.012, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20943, "number_of_timesteps": 250842, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5602, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5603.0, 1.0, 1.0, 1.0, 5603.0, 5603.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.012, -5.968, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20946, "number_of_timesteps": 250876, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5603, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5604.0, 1.0, 1.0, 1.0, 5604.0, 5604.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -6.013, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20950, "number_of_timesteps": 250915, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5604, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5605.0, 1.0, 1.0, 1.0, 5605.0, 5605.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.012, -5.965, 0.0, 0.0, 0.0]}
{"step": 5605, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5606.0, 1.0, 1.0, 1.0, 5606.0, 5606.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.764, 0.0, 0.0, 0.0, -6.011, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20959, "number_of_timesteps": 251012, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5606, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5607.0, 1.0, 1.0, 1.0, 5607.0, 5607.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -6.013, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20963, "number_of_timesteps": 251050, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5607, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5608.0, 1.0, 1.0, 1.0, 5608.0, 5608.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -6.012, -5.966, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20968, "number_of_timesteps": 251106, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5608, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5609.0, 1.0, 1.0, 1.0, 5609.0, 5609.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.011, -5.965, 0.0, 0.0, 0.0]}
{"step": 5609, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5610.0, 1.0, 1.0, 1.0, 5610.0, 5610.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -6.012, -5.965, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20978, "number_of_timesteps": 251202, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5610, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5611.0, 1.0, 1.0, 1.0, 5611.0, 5611.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -6.012, -5.966, 0.0, 0.0, 0.0]}
{"step": 5611, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5612.0, 1.0, 1.0, 1.0, 5612.0, 5612.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.767, 0.0, 0.0, 0.0, -6.012, -5.966, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20986, "number_of_timesteps": 251286, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5612, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5613.0, 1.0, 1.0, 1.0, 5613.0, 5613.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.766, 0.0, 0.0, 0.0, -6.011, -5.965, 0.0, 0.0, 0.0]}
{"step": 5613, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5614.0, 1.0, 1.0, 1.0, 5614.0, 5614.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.765, 0.0, 0.0, 0.0, -6.01, -5.964, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20992, "number_of_timesteps": 251357, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5614, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5615.0, 1.0, 1.0, 1.0, 5615.0, 5615.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -6.013, -5.967, 0.0, 0.0, 0.0]}
{"number_of_episodes": 20996, "number_of_timesteps": 251405, "per_episode_reward": 10.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"step": 5615, "filter_choice": [0, 1, 0, 0, 0, 1, 1, 0, 0, 0], "process_temp_banned_count": [1.0, 5616.0, 1.0, 1.0, 1.0, 5616.0, 5616.0, 1.0, 1.0, 1.0], "q_vals": [0.0, -4.768, 0.0, 0.0, 0.0, -6.013, -5.966, 0.0, 0.0, 0.0]}
exited at individual_updates_contributed_barrier.wait(): 3, error = 
None
exited at individual_updates_contributed_barrier.wait(): 0, error = 
None
exited at individual_updates_contributed_barrier.wait(): 4, error = 
None
exited at individual_updates_ready_barrier.wait(): 8, error = 
None
exited at individual_updates_ready_barrier.wait(): 9, error = 
None
exited at individual_updates_ready_barrier.wait(): 1, error = 
None
exited at individual_updates_ready_barrier.wait(): 5, error = 
None
exited at individual_updates_ready_barrier.wait(): 2, error = 
None
exited at individual_updates_ready_barrier.wait(): 7, error = 
None
[done calling async_.run_async()]
Traceback (most recent call last):
  File "/home/jeffhykin/repos/bizav/examples/atari/reproduction/a3c/comparison.py", line 79, in main
    fitness_values = [ float(train_a3c.train_a3c(args)) for each in range(runs_for_comparison) ]
  File "/home/jeffhykin/repos/bizav/examples/atari/reproduction/a3c/comparison.py", line 79, in <listcomp>
    fitness_values = [ float(train_a3c.train_a3c(args)) for each in range(runs_for_comparison) ]
  File "/home/jeffhykin/repos/bizav/examples/atari/reproduction/a3c/train_a3c.py", line 288, in train_a3c
    mean_reward = sum(output.median_episode_rewards)/len(output.median_episode_rewards)
ZeroDivisionError: division by zero
