config = {
    "evaluation": {
        "enabled": True, 
        "number_of_episodes_before_eval": 130, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": 125000, 
            "number_of_episodes": None, 
        }, 
    }, 
    "verbose": True, 
    "number_of_processes": 7, 
    "number_of_malicious_processes": 0, 
    "expected_number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": {
        0: 0.1, 
        1: 0.08, 
        2: 0.063, 
        3: 0.05, 
        4: 0.04, 
        5: 0.032, 
        6: 0.025, 
        7: 0.02, 
        8: 0.016, 
        9: 0.012, 
        10: 0.01, 
        11: 0.008, 
        12: 0.0063, 
        13: 0.005, 
        14: 0.004, 
        15: 0.0032, 
        16: 0.0025, 
        17: 0.002, 
        18: 0.0016, 
        19: 0.0012, 
        20: 0.001, 
        21: 0.0008, 
        22: 0.00063, 
        23: 0.0005, 
        24: 0.0004, 
        25: 0.00032, 
        26: 0.00025, 
        27: 0.0002, 
        28: 0.00016, 
        29: 0.00012, 
        30: 1e-05, 
        31: 8e-06, 
        32: 6.3e-06, 
        33: 5e-06, 
        34: 4e-06, 
        35: 3.2e-06, 
        36: 2.5e-06, 
        37: 2e-06, 
        38: 1.6e-06, 
        39: 1.2e-06, 
    }, 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": {0: 0, }, 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0, 
        "min_number_of_episodes": 30, 
        "thresholds": {}, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": {0: 0, 1: 1, 2: 2, }, }, 
            "sequential_options": {
                "t_max": {0: 3, 1: 5, 2: 10, 3: 20, 4: 30, 5: 50, }, 
                "hidden_size": {0: 16, 1: 32, 2: 64, 3: 128, }, 
                "learning_rate": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
                "beta": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
                "beta": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 40000, }, 
    "env_config": {
        "env_name": "LunarLander-v2", 
        "learning_rate": 0.0009, 
        "beta": 2e-05, 
        "t_max": 10, 
        "activation": 1, 
        "hidden_size": 128, 
        "permaban_threshold": 500, 
        "variance_scaling_factor": 1, 
    }, 
}
args = {
    "processes": 7, 
    "env": "LunarLander-v2", 
    "seed": 3379991284, 
    "outdir": "results", 
    "t_max": 10, 
    "beta": 2e-05, 
    "profile": False, 
    "steps": 40000, 
    "max_frames": (108000, ), 
    "lr": 0.0009, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 500, 
    "malicious": 0, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 128, 
    "activation": 1, 
}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting train_loop()]
Step 0 0 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]Step 1 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-11.111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]Step 2 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-11.111, -5.863, 0.0, 0.0, 0.0, 0.0, 0.0]Step 3 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-11.111, -5.863, -11.111, 0.0, 0.0, 0.0, 0.0]Step 4 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-11.111, -5.863, -11.111, 0.0, 0.0, 0.0, 0.0]Step 5 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 0 q_vals: [-11.111, -5.863, -11.111, 0.0, 0.0, 0.0, 0.0]Step 6 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 0 q_vals: [-11.111, -5.863, -11.111, 0.0, 0.0, -11.111, 0.0]Step 7 6 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 0 q_vals: [-11.111, -5.863, -11.111, 0.0, 0.0, -11.111, -4.824]Step 8 3 visits [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0]  episode_count: 0 q_vals: [-11.111, -5.863, -11.111, -5.556, 0.0, -11.111, -4.824]Step 9 4 visits [1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0]  episode_count: 6 q_vals: [-11.111, -5.863, -11.111, -5.556, -5.556, -11.111, -4.824]Step 10 6 visits [1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0]  episode_count: 7 q_vals: [-11.111, -5.863, -11.111, -5.556, -5.556, -11.111, -7.967]Step 11 1 visits [1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0]  episode_count: 7 q_vals: [-11.111, -8.487, -11.111, -5.556, -5.556, -11.111, -7.967]Step 12 3 visits [1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0]  episode_count: 7 q_vals: [-11.111, -8.487, -11.111, -7.407, -5.556, -11.111, -7.967]Step 13 4 visits [1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 2.0]  episode_count: 7 q_vals: [-11.111, -8.487, -11.111, -7.407, -7.407, -11.111, -7.967]Step 14 3 visits [1.0, 2.0, 1.0, 4.0, 3.0, 1.0, 2.0]  episode_count: 7 q_vals: [-11.111, -8.487, -11.111, -5.556, -7.407, -11.111, -7.967]Step 15 3 visits [1.0, 2.0, 1.0, 5.0, 3.0, 1.0, 2.0]  episode_count: 7 q_vals: [-11.111, -8.487, -11.111, -6.667, -7.407, -11.111, -7.967]Step 16 3 visits [1.0, 2.0, 1.0, 6.0, 3.0, 1.0, 2.0]  episode_count: 7 q_vals: [-11.111, -8.487, -11.111, -5.556, -7.407, -11.111, -7.967]Step 17 3 visits [1.0, 2.0, 1.0, 7.0, 3.0, 1.0, 2.0]  episode_count: 8 q_vals: [-11.111, -8.487, -11.111, -4.762, -7.407, -11.111, -7.967]Step 18 3 visits [1.0, 2.0, 1.0, 8.0, 3.0, 1.0, 2.0]  episode_count: 10 q_vals: [-11.111, -8.487, -11.111, -5.556, -7.407, -11.111, -7.967]Step 19 3 visits [1.0, 2.0, 1.0, 9.0, 3.0, 1.0, 2.0]  episode_count: 11 q_vals: [-11.111, -8.487, -11.111, -6.173, -7.407, -11.111, -7.967]Step 20 3 visits [1.0, 2.0, 1.0, 10.0, 3.0, 1.0, 2.0]  episode_count: 12 q_vals: [-11.111, -8.487, -11.111, -6.667, -7.407, -11.111, -7.967]Step 21 3 visits [1.0, 2.0, 1.0, 11.0, 3.0, 1.0, 2.0]  episode_count: 13 q_vals: [-11.111, -8.487, -11.111, -6.606, -7.407, -11.111, -7.967]Step 22 3 visits [1.0, 2.0, 1.0, 12.0, 3.0, 1.0, 2.0]  episode_count: 14 q_vals: [-11.111, -8.487, -11.111, -6.982, -7.407, -11.111, -7.967]Step 23 4 visits [1.0, 2.0, 1.0, 12.0, 4.0, 1.0, 2.0]  episode_count: 14 q_vals: [-11.111, -8.487, -11.111, -6.982, -8.333, -11.111, -7.967]Step 24 3 visits [1.0, 2.0, 1.0, 13.0, 4.0, 1.0, 2.0]  episode_count: 14 q_vals: [-11.111, -8.487, -11.111, -7.299, -8.333, -11.111, -7.967]Step 25 6 visits [1.0, 2.0, 1.0, 13.0, 4.0, 1.0, 3.0]  episode_count: 14 q_vals: [-11.111, -8.487, -11.111, -7.299, -8.333, -11.111, -9.015]Step 26 3 visits [1.0, 2.0, 1.0, 14.0, 4.0, 1.0, 3.0]  episode_count: 16 q_vals: [-11.111, -8.487, -11.111, -7.571, -8.333, -11.111, -9.015]Step 27 3 visits [1.0, 2.0, 1.0, 15.0, 4.0, 1.0, 3.0]  episode_count: 16 q_vals: [-11.111, -8.487, -11.111, -7.067, -8.333, -11.111, -9.015]Step 28 3 visits [1.0, 2.0, 1.0, 16.0, 4.0, 1.0, 3.0]  episode_count: 16 q_vals: [-11.111, -8.487, -11.111, -7.319, -8.333, -11.111, -9.015]Step 29 3 visits [1.0, 2.0, 1.0, 17.0, 4.0, 1.0, 3.0]  episode_count: 17 q_vals: [-11.111, -8.487, -11.111, -7.543, -8.333, -11.111, -9.015]Step 30 3 visits [1.0, 2.0, 1.0, 18.0, 4.0, 1.0, 3.0]  episode_count: 19 q_vals: [-11.111, -8.487, -11.111, -7.123, -8.333, -11.111, -9.015]Step 31 3 visits [1.0, 2.0, 1.0, 19.0, 4.0, 1.0, 3.0]  episode_count: 19 q_vals: [-11.111, -8.487, -11.111, -7.223, -8.333, -11.111, -9.015]Step 32 3 visits [1.0, 2.0, 1.0, 20.0, 4.0, 1.0, 3.0]  episode_count: 20 q_vals: [-11.111, -8.487, -11.111, -7.417, -8.333, -11.111, -9.015]Step 33 3 visits [1.0, 2.0, 1.0, 21.0, 4.0, 1.0, 3.0]  episode_count: 21 q_vals: [-11.111, -8.487, -11.111, -7.593, -8.333, -11.111, -9.015]Step 34 1 visits [1.0, 3.0, 1.0, 21.0, 4.0, 1.0, 3.0]  episode_count: 22 q_vals: [-11.111, -9.362, -11.111, -7.593, -8.333, -11.111, -9.015]Step 35 3 visits [1.0, 3.0, 1.0, 22.0, 4.0, 1.0, 3.0]  episode_count: 22 q_vals: [-11.111, -9.362, -11.111, -7.753, -8.333, -11.111, -9.015]Step 36 3 visits [1.0, 3.0, 1.0, 23.0, 4.0, 1.0, 3.0]  episode_count: 22 q_vals: [-11.111, -9.362, -11.111, -7.899, -8.333, -11.111, -9.015]Step 37 4 visits [1.0, 3.0, 1.0, 23.0, 5.0, 1.0, 3.0]  episode_count: 23 q_vals: [-11.111, -9.362, -11.111, -7.899, -8.889, -11.111, -9.015]Step 38 3 visits [1.0, 3.0, 1.0, 24.0, 5.0, 1.0, 3.0]  episode_count: 23 q_vals: [-11.111, -9.362, -11.111, -8.033, -8.889, -11.111, -9.015]Step 39 3 visits [1.0, 3.0, 1.0, 25.0, 5.0, 1.0, 3.0]  episode_count: 23 q_vals: [-11.111, -9.362, -11.111, -8.156, -8.889, -11.111, -9.015]Step 40 3 visits [1.0, 3.0, 1.0, 26.0, 5.0, 1.0, 3.0]  episode_count: 24 q_vals: [-11.111, -9.362, -11.111, -7.842, -8.889, -11.111, -9.015]Step 41 3 visits [1.0, 3.0, 1.0, 27.0, 5.0, 1.0, 3.0]  episode_count: 24 q_vals: [-11.111, -9.362, -11.111, -7.963, -8.889, -11.111, -9.015]Step 42 3 visits [1.0, 3.0, 1.0, 28.0, 5.0, 1.0, 3.0]  episode_count: 25 q_vals: [-11.111, -9.362, -11.111, -8.076, -8.889, -11.111, -9.015]Step 43 3 visits [1.0, 3.0, 1.0, 29.0, 5.0, 1.0, 3.0]  episode_count: 26 q_vals: [-11.111, -9.362, -11.111, -8.18, -8.889, -11.111, -9.015]Step 44 3 visits [1.0, 3.0, 1.0, 30.0, 5.0, 1.0, 3.0]  episode_count: 27 q_vals: [-11.111, -9.362, -11.111, -8.278, -8.889, -11.111, -9.015]Step 45 6 visits [1.0, 3.0, 1.0, 30.0, 5.0, 1.0, 4.0]  episode_count: 28 q_vals: [-11.111, -9.362, -11.111, -8.278, -8.889, -11.111, -9.539]Step 46 3 visits [1.0, 3.0, 1.0, 31.0, 5.0, 1.0, 4.0]  episode_count: 28 q_vals: [-11.111, -9.362, -11.111, -8.369, -8.889, -11.111, -9.539]Step 47 4 visits [1.0, 3.0, 1.0, 31.0, 6.0, 1.0, 4.0]  episode_count: 30 q_vals: [-11.111, -9.362, -11.111, -8.369, -9.259, -11.111, -9.539]Step 48 3 visits [1.0, 3.0, 1.0, 32.0, 6.0, 1.0, 4.0]  episode_count: 30 q_vals: [-11.111, -9.362, -11.111, -8.455, -9.259, -11.111, -9.539]Step 49 3 visits [1.0, 3.0, 1.0, 33.0, 6.0, 1.0, 4.0]  episode_count: 30 q_vals: [-11.111, -9.362, -11.111, -8.536, -9.259, -11.111, -9.539]{"total_number_of_episodes": 31, "number_of_timesteps": 3017, "per_episode_reward": -248.61, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Step 50 3 visits [1.0, 3.0, 1.0, 34.0, 6.0, 1.0, 4.0]  episode_count: 31 q_vals: [-11.111, -9.362, -11.111, -8.611, -9.259, -11.111, -9.539]Step 51 1 visits [1.0, 4.0, 1.0, 34.0, 6.0, 1.0, 4.0]  episode_count: 31 q_vals: [-11.111, -9.799, -11.111, -8.611, -9.259, -11.111, -9.539]Step 52 3 visits [1.0, 4.0, 1.0, 35.0, 6.0, 1.0, 4.0]  episode_count: 31 q_vals: [-11.111, -9.799, -11.111, -8.683, -9.259, -11.111, -9.539]Step 53 3 visits [1.0, 4.0, 1.0, 36.0, 6.0, 1.0, 4.0]  episode_count: 32 q_vals: [-11.111, -9.799, -11.111, -8.75, -9.259, -11.111, -9.539]Step 54 3 visits [1.0, 4.0, 1.0, 37.0, 6.0, 1.0, 4.0]  episode_count: 33 q_vals: [-11.111, -9.799, -11.111, -8.814, -9.259, -11.111, -9.539]Step 55 4 visits [1.0, 4.0, 1.0, 37.0, 7.0, 1.0, 4.0]  episode_count: 33 q_vals: [-11.111, -9.799, -11.111, -8.814, -9.524, -11.111, -9.539]Step 56 3 visits [1.0, 4.0, 1.0, 38.0, 7.0, 1.0, 4.0]  episode_count: 34 q_vals: [-11.111, -9.799, -11.111, -8.874, -9.524, -11.111, -9.539]Step 57 6 visits [1.0, 4.0, 1.0, 38.0, 7.0, 1.0, 5.0]  episode_count: 35 q_vals: [-11.111, -9.799, -11.111, -8.874, -9.524, -11.111, -9.854]Step 58 3 visits [1.0, 4.0, 1.0, 39.0, 7.0, 1.0, 5.0]  episode_count: 35 q_vals: [-11.111, -9.799, -11.111, -8.932, -9.524, -11.111, -9.854]Step 59 3 visits [1.0, 4.0, 1.0, 40.0, 7.0, 1.0, 5.0]  episode_count: 36 q_vals: [-11.111, -9.799, -11.111, -8.708, -9.524, -11.111, -9.854]Step 60 3 visits [1.0, 4.0, 1.0, 41.0, 7.0, 1.0, 5.0]  episode_count: 36 q_vals: [-11.111, -9.799, -11.111, -8.767, -9.524, -11.111, -9.854]Step 61 3 visits [1.0, 4.0, 1.0, 42.0, 7.0, 1.0, 5.0]  episode_count: 37 q_vals: [-11.111, -9.799, -11.111, -8.558, -9.524, -11.111, -9.854]Step 62 3 visits [1.0, 4.0, 1.0, 43.0, 7.0, 1.0, 5.0]  episode_count: 38 q_vals: [-11.111, -9.799, -11.111, -8.618, -9.524, -11.111, -9.854]Step 63 3 visits [1.0, 4.0, 1.0, 44.0, 7.0, 1.0, 5.0]  episode_count: 40 q_vals: [-11.111, -9.799, -11.111, -8.674, -9.524, -11.111, -9.854]Step 64 3 visits [1.0, 4.0, 1.0, 45.0, 7.0, 1.0, 5.0]  episode_count: 40 q_vals: [-11.111, -9.799, -11.111, -8.729, -9.524, -11.111, -9.854]Step 65 3 visits [1.0, 4.0, 1.0, 46.0, 7.0, 1.0, 5.0]  episode_count: 40 q_vals: [-11.111, -9.799, -11.111, -8.78, -9.524, -11.111, -9.854]{"total_number_of_episodes": 42, "number_of_timesteps": 4222, "per_episode_reward": -289.34, "episode_reward_trend_value": -4.072529528580032, "biggest_recent_change": NaN},
Step 66 3 visits [1.0, 4.0, 1.0, 47.0, 7.0, 1.0, 5.0]  episode_count: 42 q_vals: [-11.111, -9.799, -11.111, -8.83, -9.524, -11.111, -9.854]Step 67 3 visits [1.0, 4.0, 1.0, 48.0, 7.0, 1.0, 5.0]  episode_count: 42 q_vals: [-11.111, -9.799, -11.111, -8.877, -9.524, -11.111, -9.854]Step 68 3 visits [1.0, 4.0, 1.0, 49.0, 7.0, 1.0, 5.0]  episode_count: 42 q_vals: [-11.111, -9.799, -11.111, -8.923, -9.524, -11.111, -9.854]Step 69 3 visits [1.0, 4.0, 1.0, 50.0, 7.0, 1.0, 5.0]  episode_count: 42 q_vals: [-11.111, -9.799, -11.111, -8.967, -9.524, -11.111, -9.854]Step 70 3 visits [1.0, 4.0, 1.0, 51.0, 7.0, 1.0, 5.0]  episode_count: 44 q_vals: [-11.111, -9.799, -11.111, -9.009, -9.524, -11.111, -9.854]Step 71 3 visits [1.0, 4.0, 1.0, 52.0, 7.0, 1.0, 5.0]  episode_count: 45 q_vals: [-11.111, -9.799, -11.111, -9.049, -9.524, -11.111, -9.854]Step 72 4 visits [1.0, 4.0, 1.0, 52.0, 8.0, 1.0, 5.0]  episode_count: 45 q_vals: [-11.111, -9.799, -11.111, -9.049, -9.722, -11.111, -9.854]Step 73 3 visits [1.0, 4.0, 1.0, 53.0, 8.0, 1.0, 5.0]  episode_count: 45 q_vals: [-11.111, -9.799, -11.111, -9.088, -9.722, -11.111, -9.854]Step 74 1 visits [1.0, 5.0, 1.0, 53.0, 8.0, 1.0, 5.0]  episode_count: 45 q_vals: [-11.111, -10.061, -11.111, -9.088, -9.722, -11.111, -9.854]Step 75 3 visits [1.0, 5.0, 1.0, 54.0, 8.0, 1.0, 5.0]  episode_count: 47 q_vals: [-11.111, -10.061, -11.111, -9.126, -9.722, -11.111, -9.854]Step 76 3 visits [1.0, 5.0, 1.0, 55.0, 8.0, 1.0, 5.0]  episode_count: 48 q_vals: [-11.111, -10.061, -11.111, -9.162, -9.722, -11.111, -9.854]Step 77 3 visits [1.0, 5.0, 1.0, 56.0, 8.0, 1.0, 5.0]  episode_count: 48 q_vals: [-11.111, -10.061, -11.111, -9.197, -9.722, -11.111, -9.854]Step 78 3 visits [1.0, 5.0, 1.0, 57.0, 8.0, 1.0, 5.0]  episode_count: 49 q_vals: [-11.111, -10.061, -11.111, -9.23, -9.722, -11.111, -9.854]Step 79 6 visits [1.0, 5.0, 1.0, 57.0, 8.0, 1.0, 6.0]  episode_count: 50 q_vals: [-11.111, -10.061, -11.111, -9.23, -9.722, -11.111, -10.063]Step 80 3 visits [1.0, 5.0, 1.0, 58.0, 8.0, 1.0, 6.0]  episode_count: 50 q_vals: [-11.111, -10.061, -11.111, -9.071, -9.722, -11.111, -10.063]{"total_number_of_episodes": 52, "number_of_timesteps": 5212, "per_episode_reward": -337.71, "episode_reward_trend_value": -4.454917723002671, "biggest_recent_change": NaN},
Step 81 3 visits [1.0, 5.0, 1.0, 59.0, 8.0, 1.0, 6.0]  episode_count: 52 q_vals: [-11.111, -10.061, -11.111, -9.106, -9.722, -11.111, -10.063]Step 82 3 visits [1.0, 5.0, 1.0, 60.0, 8.0, 1.0, 6.0]  episode_count: 52 q_vals: [-11.111, -10.061, -11.111, -9.139, -9.722, -11.111, -10.063]Step 83 3 visits [1.0, 5.0, 1.0, 61.0, 8.0, 1.0, 6.0]  episode_count: 52 q_vals: [-11.111, -10.061, -11.111, -8.989, -9.722, -11.111, -10.063]Step 84 3 visits [1.0, 5.0, 1.0, 62.0, 8.0, 1.0, 6.0]  episode_count: 53 q_vals: [-11.111, -10.061, -11.111, -9.023, -9.722, -11.111, -10.063]Step 85 3 visits [1.0, 5.0, 1.0, 63.0, 8.0, 1.0, 6.0]  episode_count: 54 q_vals: [-11.111, -10.061, -11.111, -8.88, -9.722, -11.111, -10.063]Step 86 3 visits [1.0, 5.0, 1.0, 64.0, 8.0, 1.0, 6.0]  episode_count: 54 q_vals: [-11.111, -10.061, -11.111, -8.915, -9.722, -11.111, -10.063]Step 87 3 visits [1.0, 5.0, 1.0, 65.0, 8.0, 1.0, 6.0]  episode_count: 54 q_vals: [-11.111, -10.061, -11.111, -8.949, -9.722, -11.111, -10.063]Step 88 3 visits [1.0, 5.0, 1.0, 66.0, 8.0, 1.0, 6.0]  episode_count: 55 q_vals: [-11.111, -10.061, -11.111, -8.982, -9.722, -11.111, -10.063]Step 89 3 visits [1.0, 5.0, 1.0, 67.0, 8.0, 1.0, 6.0]  episode_count: 55 q_vals: [-11.111, -10.061, -11.111, -9.013, -9.722, -11.111, -10.063]Step 90 3 visits [1.0, 5.0, 1.0, 68.0, 8.0, 1.0, 6.0]  episode_count: 55 q_vals: [-11.111, -10.061, -11.111, -9.044, -9.722, -11.111, -10.063]Step 91 3 visits [1.0, 5.0, 1.0, 69.0, 8.0, 1.0, 6.0]  episode_count: 56 q_vals: [-11.111, -10.061, -11.111, -9.074, -9.722, -11.111, -10.063]Step 92 3 visits [1.0, 5.0, 1.0, 70.0, 8.0, 1.0, 6.0]  episode_count: 56 q_vals: [-11.111, -10.061, -11.111, -9.103, -9.722, -11.111, -10.063]Step 93 3 visits [1.0, 5.0, 1.0, 71.0, 8.0, 1.0, 6.0]  episode_count: 57 q_vals: [-11.111, -10.061, -11.111, -9.132, -9.722, -11.111, -10.063]Step 94 3 visits [1.0, 5.0, 1.0, 72.0, 8.0, 1.0, 6.0]  episode_count: 59 q_vals: [-11.111, -10.061, -11.111, -9.159, -9.722, -11.111, -10.063]Step 95 3 visits [1.0, 5.0, 1.0, 73.0, 8.0, 1.0, 6.0]  episode_count: 60 q_vals: [-11.111, -10.061, -11.111, -9.186, -9.722, -11.111, -10.063]Step 96 3 visits [1.0, 5.0, 1.0, 74.0, 8.0, 1.0, 6.0]  episode_count: 60 q_vals: [-11.111, -10.061, -11.111, -9.212, -9.722, -11.111, -10.063]Step 97 3 visits [1.0, 5.0, 1.0, 75.0, 8.0, 1.0, 6.0]  episode_count: 60 q_vals: [-11.111, -10.061, -11.111, -9.237, -9.722, -11.111, -10.063]Step 98 4 visits [1.0, 5.0, 1.0, 75.0, 9.0, 1.0, 6.0]  episode_count: 61 q_vals: [-11.111, -10.061, -11.111, -9.237, -9.877, -11.111, -10.063]Step 99 5 visits [1.0, 5.0, 1.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 61 q_vals: [-11.111, -10.061, -11.111, -9.237, -9.877, -11.111, -10.063]Step 100 0 visits [2.0, 5.0, 1.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 61 q_vals: [-11.111, -10.061, -11.111, -9.237, -9.877, -11.111, -10.063]{"total_number_of_episodes": 62, "number_of_timesteps": 6256, "per_episode_reward": -390.26, "episode_reward_trend_value": -4.721522542629286, "biggest_recent_change": NaN},
Step 101 2 visits [2.0, 5.0, 2.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 62 q_vals: [-11.111, -10.061, -5.556, -9.237, -9.877, -11.111, -10.063]Step 102 2 visits [2.0, 5.0, 3.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 63 q_vals: [-11.111, -10.061, -7.407, -9.237, -9.877, -11.111, -10.063]Step 103 2 visits [2.0, 5.0, 4.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 63 q_vals: [-11.111, -10.061, -8.333, -9.237, -9.877, -11.111, -10.063]Step 104 2 visits [2.0, 5.0, 5.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 66 q_vals: [-11.111, -10.061, -8.889, -9.237, -9.877, -11.111, -10.063]Step 105 2 visits [2.0, 5.0, 6.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 67 q_vals: [-11.111, -10.061, -9.259, -9.237, -9.877, -11.111, -10.063]Step 106 2 visits [2.0, 5.0, 7.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 67 q_vals: [-11.111, -10.061, -9.524, -9.237, -9.877, -11.111, -10.063]Step 107 2 visits [2.0, 5.0, 8.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 67 q_vals: [-11.111, -10.061, -8.333, -9.237, -9.877, -11.111, -10.063]Step 108 2 visits [2.0, 5.0, 9.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 67 q_vals: [-11.111, -10.061, -8.642, -9.237, -9.877, -11.111, -10.063]Step 109 2 visits [2.0, 5.0, 10.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 67 q_vals: [-11.111, -10.061, -8.889, -9.237, -9.877, -11.111, -10.063]Step 110 2 visits [2.0, 5.0, 11.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 67 q_vals: [-11.111, -10.061, -9.091, -9.237, -9.877, -11.111, -10.063]Step 111 2 visits [2.0, 5.0, 12.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 67 q_vals: [-11.111, -10.061, -9.259, -9.237, -9.877, -11.111, -10.063]Step 112 2 visits [2.0, 5.0, 13.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 68 q_vals: [-11.111, -10.061, -9.402, -9.237, -9.877, -11.111, -10.063]Step 113 2 visits [2.0, 5.0, 14.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 70 q_vals: [-11.111, -10.061, -9.524, -9.237, -9.877, -11.111, -10.063]Step 114 2 visits [2.0, 5.0, 15.0, 75.0, 9.0, 2.0, 6.0]  episode_count: 70 q_vals: [-11.111, -10.061, -9.63, -9.237, -9.877, -11.111, -10.063]Step 115 3 visits [2.0, 5.0, 15.0, 76.0, 9.0, 2.0, 6.0]  episode_count: 71 q_vals: [-11.111, -10.061, -9.63, -9.262, -9.877, -11.111, -10.063]{"total_number_of_episodes": 72, "number_of_timesteps": 7435, "per_episode_reward": -442.89, "episode_reward_trend_value": -4.856834277145921, "biggest_recent_change": NaN},
Step 116 3 visits [2.0, 5.0, 15.0, 77.0, 9.0, 2.0, 6.0]  episode_count: 72 q_vals: [-11.111, -10.061, -9.63, -9.286, -9.877, -11.111, -10.063]Step 117 3 visits [2.0, 5.0, 15.0, 78.0, 9.0, 2.0, 6.0]  episode_count: 72 q_vals: [-11.111, -10.061, -9.63, -9.309, -9.877, -11.111, -10.063]Step 118 3 visits [2.0, 5.0, 15.0, 79.0, 9.0, 2.0, 6.0]  episode_count: 72 q_vals: [-11.111, -10.061, -9.63, -9.332, -9.877, -11.111, -10.063]Step 119 2 visits [2.0, 5.0, 16.0, 79.0, 9.0, 2.0, 6.0]  episode_count: 73 q_vals: [-11.111, -10.061, -9.722, -9.332, -9.877, -11.111, -10.063]Step 120 1 visits [2.0, 6.0, 16.0, 79.0, 9.0, 2.0, 6.0]  episode_count: 73 q_vals: [-11.111, -10.236, -9.722, -9.332, -9.877, -11.111, -10.063]Step 121 3 visits [2.0, 6.0, 16.0, 80.0, 9.0, 2.0, 6.0]  episode_count: 73 q_vals: [-11.111, -10.236, -9.722, -9.354, -9.877, -11.111, -10.063]Step 122 3 visits [2.0, 6.0, 16.0, 81.0, 9.0, 2.0, 6.0]  episode_count: 74 q_vals: [-11.111, -10.236, -9.722, -9.376, -9.877, -11.111, -10.063]Step 123 3 visits [2.0, 6.0, 16.0, 82.0, 9.0, 2.0, 6.0]  episode_count: 75 q_vals: [-11.111, -10.236, -9.722, -9.397, -9.877, -11.111, -10.063]Step 124 4 visits [2.0, 6.0, 16.0, 82.0, 10.0, 2.0, 6.0]  episode_count: 76 q_vals: [-11.111, -10.236, -9.722, -9.397, -8.889, -11.111, -10.063]Step 125 4 visits [2.0, 6.0, 16.0, 82.0, 11.0, 2.0, 6.0]  episode_count: 77 q_vals: [-11.111, -10.236, -9.722, -9.397, -9.091, -11.111, -10.063]Step 126 4 visits [2.0, 6.0, 16.0, 82.0, 12.0, 2.0, 6.0]  episode_count: 77 q_vals: [-11.111, -10.236, -9.722, -9.397, -9.259, -11.111, -10.063]Step 127 4 visits [2.0, 6.0, 16.0, 82.0, 13.0, 2.0, 6.0]  episode_count: 78 q_vals: [-11.111, -10.236, -9.722, -9.397, -9.402, -11.111, -10.063]Step 128 4 visits [2.0, 6.0, 16.0, 82.0, 14.0, 2.0, 6.0]  episode_count: 79 q_vals: [-11.111, -10.236, -9.722, -9.397, -9.524, -11.111, -10.063]Step 129 4 visits [2.0, 6.0, 16.0, 82.0, 15.0, 2.0, 6.0]  episode_count: 79 q_vals: [-11.111, -10.236, -9.722, -9.397, -9.63, -11.111, -10.063]Step 130 4 visits [2.0, 6.0, 16.0, 82.0, 16.0, 2.0, 6.0]  episode_count: 79 q_vals: [-11.111, -10.236, -9.722, -9.397, -9.722, -11.111, -10.063]Step 131 3 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 6.0]  episode_count: 81 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -10.063]{"total_number_of_episodes": 82, "number_of_timesteps": 8597, "per_episode_reward": -474.29, "episode_reward_trend_value": -4.513479324496761, "biggest_recent_change": NaN},
Step 132 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 7.0]  episode_count: 82 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.626]Step 133 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 8.0]  episode_count: 83 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.936]Step 134 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 9.0]  episode_count: 83 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -7.943]Step 135 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 10.0]  episode_count: 83 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.26]Step 136 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 11.0]  episode_count: 83 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.519]Step 137 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 12.0]  episode_count: 84 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -7.809]Step 138 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 13.0]  episode_count: 85 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.063]Step 139 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 14.0]  episode_count: 87 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.281]Step 140 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 15.0]  episode_count: 88 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.47]Step 141 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 16.0]  episode_count: 89 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.635]Step 142 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 17.0]  episode_count: 89 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.78]Step 143 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 18.0]  episode_count: 89 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.293]Step 144 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 19.0]  episode_count: 90 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.441]Step 145 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 20.0]  episode_count: 90 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.019]Step 146 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 21.0]  episode_count: 90 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.166]Step 147 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 22.0]  episode_count: 91 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.3]Step 148 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 23.0]  episode_count: 91 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.422]{"total_number_of_episodes": 92, "number_of_timesteps": 9554, "per_episode_reward": -496.34, "episode_reward_trend_value": -4.128740289956093, "biggest_recent_change": NaN},
Step 149 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 24.0]  episode_count: 92 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.071]Step 150 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 25.0]  episode_count: 94 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.193]Step 151 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 26.0]  episode_count: 95 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.305]Step 152 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 27.0]  episode_count: 96 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.409]Step 153 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 28.0]  episode_count: 97 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.109]Step 154 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 29.0]  episode_count: 98 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.212]Step 155 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 30.0]  episode_count: 98 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.309]Step 156 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 31.0]  episode_count: 98 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.041]Step 157 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 32.0]  episode_count: 98 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.137]Step 158 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 33.0]  episode_count: 98 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.227]Step 159 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 34.0]  episode_count: 99 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.312]Step 160 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 35.0]  episode_count: 100 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.392]{"total_number_of_episodes": 103, "number_of_timesteps": 10586, "per_episode_reward": -515.48, "episode_reward_trend_value": -3.812376270797934, "biggest_recent_change": NaN},
Step 161 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 36.0]  episode_count: 103 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.467]Step 162 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 37.0]  episode_count: 104 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.539]Step 163 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 38.0]  episode_count: 104 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.606]Step 164 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 39.0]  episode_count: 104 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.671]Step 165 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 40.0]  episode_count: 104 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.732]Step 166 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 41.0]  episode_count: 104 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.79]Step 167 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 42.0]  episode_count: 104 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.845]Step 168 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 43.0]  episode_count: 105 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.898]Step 169 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 44.0]  episode_count: 107 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.948]Step 170 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 45.0]  episode_count: 107 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.996]Step 171 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 46.0]  episode_count: 107 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.801]Step 172 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 47.0]  episode_count: 110 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.613]Step 173 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 48.0]  episode_count: 111 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.665]Step 174 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 49.0]  episode_count: 111 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.715]Step 175 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 50.0]  episode_count: 111 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.763]Step 176 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 51.0]  episode_count: 111 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.809]Step 177 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 52.0]  episode_count: 111 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.853]Step 178 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 53.0]  episode_count: 111 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.896]Step 179 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 54.0]  episode_count: 112 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.937]{"total_number_of_episodes": 113, "number_of_timesteps": 11607, "per_episode_reward": -524.61, "episode_reward_trend_value": -3.450024490891429, "biggest_recent_change": NaN},
Step 180 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 55.0]  episode_count: 113 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.977]Step 181 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 56.0]  episode_count: 115 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.015]Step 182 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 57.0]  episode_count: 116 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.857]Step 183 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 58.0]  episode_count: 117 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.704]Step 184 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 59.0]  episode_count: 118 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.556]Step 185 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 60.0]  episode_count: 118 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.599]Step 186 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 61.0]  episode_count: 118 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.64]Step 187 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 62.0]  episode_count: 118 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.501]Step 188 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 63.0]  episode_count: 118 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.542]Step 189 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 64.0]  episode_count: 120 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.582]Step 190 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 65.0]  episode_count: 120 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.621]Step 191 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 66.0]  episode_count: 121 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.491]Step 192 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 67.0]  episode_count: 122 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.53]{"total_number_of_episodes": 123, "number_of_timesteps": 12620, "per_episode_reward": -542.25, "episode_reward_trend_value": -3.2626606524411934, "biggest_recent_change": 52.62769480695829},
Step 193 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 68.0]  episode_count: 123 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.568]Step 194 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 69.0]  episode_count: 123 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.444]Step 195 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 70.0]  episode_count: 124 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.482]Step 196 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 71.0]  episode_count: 124 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.362]Step 197 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 72.0]  episode_count: 125 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.246]Step 198 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 73.0]  episode_count: 125 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.285]Step 199 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 74.0]  episode_count: 126 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.323]Step 200 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 75.0]  episode_count: 126 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.361]Step 201 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 76.0]  episode_count: 127 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.397]Step 202 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 77.0]  episode_count: 127 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.432]Step 203 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 78.0]  episode_count: 128 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.466]Step 204 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 79.0]  episode_count: 129 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.5]Step 205 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 80.0]  episode_count: 130 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.533]Step 206 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 81.0]  episode_count: 131 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.564]Step 207 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 82.0]  episode_count: 132 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.595]{"total_number_of_episodes": 133, "number_of_timesteps": 13729, "per_episode_reward": -557.45, "episode_reward_trend_value": -2.978990685593673, "biggest_recent_change": 52.62769480695829},
Step 208 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 83.0]  episode_count: 133 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.626]Step 209 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 84.0]  episode_count: 134 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.655]Step 210 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 85.0]  episode_count: 134 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.684]Step 211 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 86.0]  episode_count: 135 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.712]Step 212 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 87.0]  episode_count: 135 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.74]Step 213 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 88.0]  episode_count: 135 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.767]Step 214 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 89.0]  episode_count: 138 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.793]Step 215 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 90.0]  episode_count: 139 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.696]Step 216 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 91.0]  episode_count: 141 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.722]Step 217 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 92.0]  episode_count: 141 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.748]Step 218 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 93.0]  episode_count: 141 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.773]Step 219 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 94.0]  episode_count: 141 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.798]Step 220 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 95.0]  episode_count: 142 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.823]Step 221 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 96.0]  episode_count: 142 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.731]{"total_number_of_episodes": 143, "number_of_timesteps": 14532, "per_episode_reward": -561.91, "episode_reward_trend_value": -2.4910762656496703, "biggest_recent_change": 52.62769480695829},
Step 222 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 97.0]  episode_count: 143 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.641]Step 223 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 98.0]  episode_count: 146 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.666]Step 224 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 99.0]  episode_count: 146 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.691]Step 225 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 100.0]  episode_count: 148 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.715]Step 226 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 101.0]  episode_count: 148 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.739]Step 227 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 102.0]  episode_count: 149 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.762]Step 228 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 103.0]  episode_count: 149 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.785]Step 229 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 104.0]  episode_count: 149 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.807]Step 230 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 105.0]  episode_count: 150 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.829]Step 231 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 106.0]  episode_count: 151 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.851]{"total_number_of_episodes": 153, "number_of_timesteps": 15320, "per_episode_reward": -557.76, "episode_reward_trend_value": -1.8611014035681634, "biggest_recent_change": 52.62769480695829},
Step 232 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 107.0]  episode_count: 153 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.872]Step 233 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 108.0]  episode_count: 153 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.79]Step 234 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 109.0]  episode_count: 155 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.811]Step 235 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 110.0]  episode_count: 156 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.832]Step 236 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 111.0]  episode_count: 156 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.852]Step 237 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 112.0]  episode_count: 156 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.872]Step 238 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 113.0]  episode_count: 156 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.892]Step 239 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 114.0]  episode_count: 157 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.912]Step 240 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 115.0]  episode_count: 160 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.931]Step 241 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 116.0]  episode_count: 161 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.95]Step 242 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 117.0]  episode_count: 162 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.873]{"total_number_of_episodes": 163, "number_of_timesteps": 16130, "per_episode_reward": -559.48, "episode_reward_trend_value": -1.2954478176116475, "biggest_recent_change": 31.40059513900121},
Step 243 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 118.0]  episode_count: 163 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.892]Step 244 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 119.0]  episode_count: 163 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.911]Step 245 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 120.0]  episode_count: 163 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.929]Step 246 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 121.0]  episode_count: 165 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.947]Step 247 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 122.0]  episode_count: 166 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.965]Step 248 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 123.0]  episode_count: 168 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.982]Step 249 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 124.0]  episode_count: 169 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.999]Step 250 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 125.0]  episode_count: 170 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.927]Step 251 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 126.0]  episode_count: 170 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.945]Step 252 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 127.0]  episode_count: 170 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.962]Step 253 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 128.0]  episode_count: 170 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.892]Step 254 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 129.0]  episode_count: 171 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.909]{"total_number_of_episodes": 173, "number_of_timesteps": 16825, "per_episode_reward": -562.76, "episode_reward_trend_value": -0.9830873137425803, "biggest_recent_change": 22.050451172527573},
Step 255 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 130.0]  episode_count: 173 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.926]Step 256 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 131.0]  episode_count: 176 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.943]Step 257 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 132.0]  episode_count: 177 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.875]Step 258 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 133.0]  episode_count: 177 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.892]Step 259 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 134.0]  episode_count: 177 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.908]Step 260 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 135.0]  episode_count: 178 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.925]Step 261 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 136.0]  episode_count: 178 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.941]Step 262 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 137.0]  episode_count: 179 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.875]Step 263 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 138.0]  episode_count: 181 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.892]{"total_number_of_episodes": 184, "number_of_timesteps": 17605, "per_episode_reward": -561.23, "episode_reward_trend_value": -0.7209821768441802, "biggest_recent_change": 19.14192155848974},
Step 264 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 139.0]  episode_count: 184 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.908]Step 265 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 140.0]  episode_count: 184 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.844]Step 266 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 141.0]  episode_count: 184 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.86]Step 267 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 142.0]  episode_count: 185 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.876]Step 268 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 143.0]  episode_count: 185 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.892]Step 269 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 144.0]  episode_count: 186 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.907]Step 270 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 145.0]  episode_count: 188 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.922]Step 271 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 146.0]  episode_count: 189 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.937]Step 272 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 147.0]  episode_count: 190 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.876]Step 273 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 148.0]  episode_count: 191 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.891]Step 274 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 149.0]  episode_count: 191 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.906]Step 275 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 150.0]  episode_count: 192 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.921]{"total_number_of_episodes": 194, "number_of_timesteps": 18299, "per_episode_reward": -555.74, "episode_reward_trend_value": -0.4473439144079167, "biggest_recent_change": 17.6374994483931},
Step 276 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 151.0]  episode_count: 194 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.936]Step 277 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 152.0]  episode_count: 196 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.95]Step 278 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 153.0]  episode_count: 196 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.964]Step 279 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 154.0]  episode_count: 196 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.978]Step 280 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 155.0]  episode_count: 197 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.992]Step 281 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 156.0]  episode_count: 198 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.934]Step 282 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 157.0]  episode_count: 198 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.948]Step 283 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 158.0]  episode_count: 199 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.962]Step 284 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 159.0]  episode_count: 199 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.975]Step 285 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 160.0]  episode_count: 202 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.988]Step 286 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 161.0]  episode_count: 203 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.002]{"total_number_of_episodes": 204, "number_of_timesteps": 19041, "per_episode_reward": -561.16, "episode_reward_trend_value": -0.40602351849847135, "biggest_recent_change": 17.6374994483931},
Step 287 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 162.0]  episode_count: 204 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.015]Step 288 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 163.0]  episode_count: 205 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.028]Step 289 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 164.0]  episode_count: 205 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.04]Step 290 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 165.0]  episode_count: 205 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.053]Step 291 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 166.0]  episode_count: 206 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.065]Step 292 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 167.0]  episode_count: 207 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.077]Step 293 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 168.0]  episode_count: 210 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.09]Step 294 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 169.0]  episode_count: 211 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.102]Step 295 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 170.0]  episode_count: 212 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.048]Step 296 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 171.0]  episode_count: 212 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.06]Step 297 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 172.0]  episode_count: 212 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.072]Step 298 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 173.0]  episode_count: 212 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.02]Step 299 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 174.0]  episode_count: 213 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.032]{"total_number_of_episodes": 215, "number_of_timesteps": 19809, "per_episode_reward": -563.44, "episode_reward_trend_value": -0.23537780915647014, "biggest_recent_change": 15.194998269523467},
Step 300 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 175.0]  episode_count: 215 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.043]Step 301 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 176.0]  episode_count: 215 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.992]Step 302 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 177.0]  episode_count: 216 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.004]Step 303 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 178.0]  episode_count: 218 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.016]Step 304 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 179.0]  episode_count: 218 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.028]Step 305 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 180.0]  episode_count: 219 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.977]Step 306 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 181.0]  episode_count: 221 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.989]Step 307 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 182.0]  episode_count: 221 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.001]Step 308 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 183.0]  episode_count: 222 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.012]Step 309 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 184.0]  episode_count: 222 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.024]Step 310 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 185.0]  episode_count: 223 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.035]Step 311 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 186.0]  episode_count: 223 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.046]Step 312 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 187.0]  episode_count: 224 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.057]{"total_number_of_episodes": 227, "number_of_timesteps": 20755, "per_episode_reward": -563.87, "episode_reward_trend_value": -0.07131121969980667, "biggest_recent_change": 5.485522060773974},
Step 313 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 188.0]  episode_count: 227 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.068]Step 314 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 189.0]  episode_count: 227 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.079]Step 315 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 190.0]  episode_count: 228 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.09]Step 316 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 191.0]  episode_count: 228 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.1]Step 317 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 192.0]  episode_count: 229 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.111]Step 318 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 193.0]  episode_count: 230 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.121]Step 319 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 194.0]  episode_count: 230 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.131]Step 320 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 195.0]  episode_count: 231 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.142]Step 321 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 196.0]  episode_count: 232 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.152]Step 322 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 197.0]  episode_count: 233 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.105]Step 323 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 198.0]  episode_count: 234 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.115]Step 324 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 199.0]  episode_count: 235 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.125]Step 325 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 200.0]  episode_count: 235 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.135]Step 326 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 201.0]  episode_count: 235 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.145]Step 327 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 202.0]  episode_count: 236 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.1]{"total_number_of_episodes": 238, "number_of_timesteps": 21668, "per_episode_reward": -564.58, "episode_reward_trend_value": -0.02963521549541055, "biggest_recent_change": 5.485522060773974},
Step 328 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 203.0]  episode_count: 238 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.11]Step 329 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 204.0]  episode_count: 238 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.12]Step 330 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 205.0]  episode_count: 240 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.129]Step 331 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 206.0]  episode_count: 241 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.085]Step 332 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 207.0]  episode_count: 241 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.095]Step 333 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 208.0]  episode_count: 241 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.051]Step 334 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 209.0]  episode_count: 241 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.061]Step 335 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 210.0]  episode_count: 243 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.071]Step 336 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 211.0]  episode_count: 245 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.028]Step 337 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 212.0]  episode_count: 245 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.037]Step 338 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 213.0]  episode_count: 247 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.047]Step 339 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 214.0]  episode_count: 247 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.057]{"total_number_of_episodes": 248, "number_of_timesteps": 22476, "per_episode_reward": -568.24, "episode_reward_trend_value": -0.11646014446658279, "biggest_recent_change": 5.485522060773974},
Step 340 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 215.0]  episode_count: 248 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.066]Step 341 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 216.0]  episode_count: 248 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.076]Step 342 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 217.0]  episode_count: 248 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.085]Step 343 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 218.0]  episode_count: 250 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.044]Step 344 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 219.0]  episode_count: 251 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.053]Step 345 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 220.0]  episode_count: 252 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.012]Step 346 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 221.0]  episode_count: 254 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.021]Step 347 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 222.0]  episode_count: 254 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.031]Step 348 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 223.0]  episode_count: 254 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.04]Step 349 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 224.0]  episode_count: 254 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.0]Step 350 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 225.0]  episode_count: 254 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.96]Step 351 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 226.0]  episode_count: 255 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.969]Step 352 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 227.0]  episode_count: 255 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.979]Step 353 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 228.0]  episode_count: 256 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.988]Step 354 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 229.0]  episode_count: 257 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.949]{"total_number_of_episodes": 259, "number_of_timesteps": 23441, "per_episode_reward": -566.98, "episode_reward_trend_value": -0.08336691889041832, "biggest_recent_change": 5.485522060773974},
Step 355 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 230.0]  episode_count: 259 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.91]Step 356 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 231.0]  episode_count: 260 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.919]Step 357 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 232.0]  episode_count: 260 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.929]Step 358 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 233.0]  episode_count: 261 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.938]Step 359 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 234.0]  episode_count: 261 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.947]Step 360 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 235.0]  episode_count: 261 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.957]Step 361 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 236.0]  episode_count: 261 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.966]Step 362 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 237.0]  episode_count: 262 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.928]Step 363 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 238.0]  episode_count: 263 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.937]Step 364 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 239.0]  episode_count: 265 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.9]Step 365 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 240.0]  episode_count: 266 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.909]Step 366 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 241.0]  episode_count: 267 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.918]Step 367 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 242.0]  episode_count: 268 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.927]Step 368 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 243.0]  episode_count: 268 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.89]Step 369 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 244.0]  episode_count: 268 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.9]Step 370 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 245.0]  episode_count: 268 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.909]{"total_number_of_episodes": 269, "number_of_timesteps": 24383, "per_episode_reward": -571.65, "episode_reward_trend_value": -0.0987394780471656, "biggest_recent_change": 5.485522060773974},
Step 371 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 246.0]  episode_count: 269 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.918]Step 372 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 247.0]  episode_count: 269 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.926]Step 373 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 248.0]  episode_count: 272 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.89]Step 374 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 249.0]  episode_count: 273 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.899]Step 375 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 250.0]  episode_count: 274 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.908]Step 376 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 251.0]  episode_count: 274 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.917]Step 377 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 252.0]  episode_count: 275 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.926]Step 378 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 253.0]  episode_count: 275 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.934]Step 379 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 254.0]  episode_count: 277 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.899]Step 380 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 255.0]  episode_count: 277 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.908]{"total_number_of_episodes": 279, "number_of_timesteps": 25184, "per_episode_reward": -572.83, "episode_reward_trend_value": -0.12898169179304028, "biggest_recent_change": 5.485522060773974},
Step 381 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 256.0]  episode_count: 279 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.916]Step 382 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 257.0]  episode_count: 281 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.925]Step 383 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 258.0]  episode_count: 281 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.933]Step 384 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 259.0]  episode_count: 281 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.942]Step 385 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 260.0]  episode_count: 282 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.907]Step 386 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 261.0]  episode_count: 282 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.916]Step 387 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 262.0]  episode_count: 283 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.882]Step 388 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 263.0]  episode_count: 284 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.89]Step 389 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 264.0]  episode_count: 285 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.857]Step 390 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 265.0]  episode_count: 287 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.865]Step 391 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 266.0]  episode_count: 287 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.874]Step 392 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 267.0]  episode_count: 288 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.882]{"total_number_of_episodes": 290, "number_of_timesteps": 26061, "per_episode_reward": -574.95, "episode_reward_trend_value": -0.21339063041779002, "biggest_recent_change": 5.416784683608853},
Step 393 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 268.0]  episode_count: 290 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.89]Step 394 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 269.0]  episode_count: 290 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.899]Step 395 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 270.0]  episode_count: 290 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.866]Step 396 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 271.0]  episode_count: 290 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.874]Step 397 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 272.0]  episode_count: 293 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.882]Step 398 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 273.0]  episode_count: 294 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.89]Step 399 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 274.0]  episode_count: 295 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.898]Step 400 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 275.0]  episode_count: 295 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.906]Step 401 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 276.0]  episode_count: 296 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.874]Step 402 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 277.0]  episode_count: 297 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.882]Step 403 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 278.0]  episode_count: 298 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.89]Step 404 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 279.0]  episode_count: 299 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.898]{"total_number_of_episodes": 300, "number_of_timesteps": 26783, "per_episode_reward": -572.52, "episode_reward_trend_value": -0.12621410119560955, "biggest_recent_change": 4.6716801148924105},
Step 405 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 280.0]  episode_count: 300 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.906]Step 406 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 281.0]  episode_count: 301 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.914]Step 407 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 282.0]  episode_count: 301 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.882]Step 408 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 283.0]  episode_count: 301 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.851]Step 409 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 284.0]  episode_count: 305 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.859]Step 410 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 285.0]  episode_count: 305 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.867]Step 411 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 286.0]  episode_count: 306 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.875]Step 412 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 287.0]  episode_count: 306 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.882]Step 413 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 288.0]  episode_count: 307 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.89]Step 414 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 289.0]  episode_count: 307 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.859]Step 415 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 290.0]  episode_count: 307 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.829]Step 416 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 291.0]  episode_count: 309 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.837]{"total_number_of_episodes": 311, "number_of_timesteps": 27625, "per_episode_reward": -568.92, "episode_reward_trend_value": -0.060884984712484116, "biggest_recent_change": 4.6716801148924105},
Step 417 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 292.0]  episode_count: 311 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.845]Step 418 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 293.0]  episode_count: 313 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.852]Step 419 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 294.0]  episode_count: 313 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.86]Step 420 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 295.0]  episode_count: 313 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.868]Step 421 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 296.0]  episode_count: 313 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.875]Step 422 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 297.0]  episode_count: 313 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.883]Step 423 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 298.0]  episode_count: 314 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.853]Step 424 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 299.0]  episode_count: 317 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.86]Step 425 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 300.0]  episode_count: 317 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.868]Step 426 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 301.0]  episode_count: 317 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.875]Step 427 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 302.0]  episode_count: 319 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.883]Step 428 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 303.0]  episode_count: 319 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.89]Step 429 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 304.0]  episode_count: 320 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.861]{"total_number_of_episodes": 322, "number_of_timesteps": 28501, "per_episode_reward": -569.91, "episode_reward_trend_value": -0.0671869566982006, "biggest_recent_change": 4.6716801148924105},
Step 430 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 305.0]  episode_count: 322 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.868]Step 431 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 306.0]  episode_count: 323 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.839]Step 432 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 307.0]  episode_count: 323 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.847]Step 433 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 308.0]  episode_count: 323 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.854]Step 434 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 309.0]  episode_count: 325 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.861]Step 435 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 310.0]  episode_count: 325 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.869]Step 436 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 311.0]  episode_count: 326 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.876]Step 437 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 312.0]  episode_count: 329 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.883]Step 438 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 313.0]  episode_count: 329 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.855]Step 439 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 314.0]  episode_count: 329 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.826]Step 440 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 315.0]  episode_count: 331 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.834]Step 441 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 316.0]  episode_count: 331 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.841]{"total_number_of_episodes": 332, "number_of_timesteps": 29214, "per_episode_reward": -567.28, "episode_reward_trend_value": -0.03009404370913621, "biggest_recent_change": 4.6716801148924105},
Step 442 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 317.0]  episode_count: 332 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.848]Step 443 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 318.0]  episode_count: 333 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.82]Step 444 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 319.0]  episode_count: 333 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.827]Step 445 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 320.0]  episode_count: 334 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.835]Step 446 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 321.0]  episode_count: 336 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.842]Step 447 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 322.0]  episode_count: 337 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.849]Step 448 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 323.0]  episode_count: 337 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.856]Step 449 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 324.0]  episode_count: 339 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.863]Step 450 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 325.0]  episode_count: 339 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.87]Step 451 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 326.0]  episode_count: 339 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.876]Step 452 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 327.0]  episode_count: 340 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.883]Step 453 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 328.0]  episode_count: 341 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.89]Step 454 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 329.0]  episode_count: 341 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.897]{"total_number_of_episodes": 342, "number_of_timesteps": 30008, "per_episode_reward": -566.0, "episode_reward_trend_value": 0.024914774843107855, "biggest_recent_change": 4.6716801148924105},
Step 455 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 330.0]  episode_count: 342 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.904]Step 456 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 331.0]  episode_count: 344 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.91]Step 457 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 332.0]  episode_count: 345 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.883]Step 458 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 333.0]  episode_count: 346 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.89]Step 459 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 334.0]  episode_count: 346 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.897]Step 460 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 335.0]  episode_count: 346 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.903]Step 461 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 336.0]  episode_count: 347 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.877]Step 462 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 337.0]  episode_count: 348 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.883]Step 463 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 338.0]  episode_count: 348 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.857]Step 464 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 339.0]  episode_count: 348 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.864]Step 465 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 340.0]  episode_count: 349 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.87]Step 466 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 341.0]  episode_count: 350 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.844]{"total_number_of_episodes": 352, "number_of_timesteps": 30903, "per_episode_reward": -568.01, "episode_reward_trend_value": -0.011414671853886678, "biggest_recent_change": 4.6716801148924105},
Step 467 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 342.0]  episode_count: 352 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.819]Step 468 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 343.0]  episode_count: 352 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.825]Step 469 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 344.0]  episode_count: 354 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.832]Step 470 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 345.0]  episode_count: 355 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.838]Step 471 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 346.0]  episode_count: 355 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.813]Step 472 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 347.0]  episode_count: 355 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.82]Step 473 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 348.0]  episode_count: 356 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.826]Step 474 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 349.0]  episode_count: 356 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.833]Step 475 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 350.0]  episode_count: 357 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.839]Step 476 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 351.0]  episode_count: 358 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.814]Step 477 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 352.0]  episode_count: 359 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.821]Step 478 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 353.0]  episode_count: 360 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.827]Step 479 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 354.0]  episode_count: 360 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.833]{"total_number_of_episodes": 362, "number_of_timesteps": 31802, "per_episode_reward": -574.19, "episode_reward_trend_value": -0.028191390965160833, "biggest_recent_change": 6.181584834907085},
Step 480 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 355.0]  episode_count: 362 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.84]Step 481 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 356.0]  episode_count: 362 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.846]Step 482 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 357.0]  episode_count: 362 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.853]Step 483 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 358.0]  episode_count: 362 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.859]Step 484 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 359.0]  episode_count: 362 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.865]Step 485 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 360.0]  episode_count: 364 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.841]Step 486 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 361.0]  episode_count: 364 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.816]Step 487 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 362.0]  episode_count: 367 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.822]Step 488 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 363.0]  episode_count: 367 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.829]Step 489 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 364.0]  episode_count: 368 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.835]Step 490 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 365.0]  episode_count: 368 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.841]Step 491 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 366.0]  episode_count: 368 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.847]Step 492 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 367.0]  episode_count: 368 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.854]Step 493 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 368.0]  episode_count: 368 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.86]Step 494 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 369.0]  episode_count: 369 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.866]Step 495 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 370.0]  episode_count: 369 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.872]Step 496 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 371.0]  episode_count: 369 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.878]Step 497 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 372.0]  episode_count: 370 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.884]Step 498 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 373.0]  episode_count: 371 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.89]Step 499 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 374.0]  episode_count: 371 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.896]{"total_number_of_episodes": 372, "number_of_timesteps": 32791, "per_episode_reward": -569.46, "episode_reward_trend_value": 0.037487220734897166, "biggest_recent_change": 6.181584834907085},
Step 500 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 375.0]  episode_count: 372 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.902]Step 501 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 376.0]  episode_count: 372 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.908]Step 502 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 377.0]  episode_count: 373 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.913]Step 503 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 378.0]  episode_count: 373 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.919]Step 504 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 379.0]  episode_count: 373 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.925]Step 505 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 380.0]  episode_count: 374 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.931]Step 506 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 381.0]  episode_count: 374 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.907]Step 507 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 382.0]  episode_count: 375 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.913]Step 508 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 383.0]  episode_count: 376 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.919]Step 509 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 384.0]  episode_count: 377 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.925]Step 510 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 385.0]  episode_count: 377 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.93]Step 511 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 386.0]  episode_count: 379 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.936]Step 512 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 387.0]  episode_count: 380 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.942]Step 513 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 388.0]  episode_count: 381 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.947]Step 514 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 389.0]  episode_count: 381 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.953]Step 515 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 390.0]  episode_count: 381 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.93]{"total_number_of_episodes": 382, "number_of_timesteps": 34147, "per_episode_reward": -575.35, "episode_reward_trend_value": -0.004503980918010105, "biggest_recent_change": 6.181584834907085},
Step 516 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 391.0]  episode_count: 382 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.935]Step 517 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 392.0]  episode_count: 383 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.941]Step 518 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 393.0]  episode_count: 383 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.946]Step 519 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 394.0]  episode_count: 383 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.952]Step 520 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 395.0]  episode_count: 385 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.957]Step 521 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 396.0]  episode_count: 386 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.963]Step 522 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 397.0]  episode_count: 386 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.968]Step 523 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 398.0]  episode_count: 386 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.974]Step 524 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 399.0]  episode_count: 388 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.979]Step 525 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 400.0]  episode_count: 389 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.957]Step 526 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 401.0]  episode_count: 389 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.962]Step 527 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 402.0]  episode_count: 389 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.967]Step 528 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 403.0]  episode_count: 391 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.973]Step 529 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 404.0]  episode_count: 391 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.978]{"total_number_of_episodes": 392, "number_of_timesteps": 35040, "per_episode_reward": -578.2, "episode_reward_trend_value": -0.06318186327172018, "biggest_recent_change": 6.181584834907085},
Step 530 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 405.0]  episode_count: 392 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.983]Step 531 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 406.0]  episode_count: 392 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.988]Step 532 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 407.0]  episode_count: 393 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.994]Step 533 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 408.0]  episode_count: 394 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -8.999]Step 534 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 409.0]  episode_count: 395 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.004]Step 535 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 410.0]  episode_count: 396 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.009]Step 536 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 411.0]  episode_count: 396 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.014]Step 537 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 412.0]  episode_count: 396 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.019]Step 538 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 413.0]  episode_count: 397 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.024]Step 539 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 414.0]  episode_count: 398 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.029]Step 540 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 415.0]  episode_count: 399 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.034]Step 541 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 416.0]  episode_count: 400 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.039]Step 542 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 417.0]  episode_count: 401 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.044]{"total_number_of_episodes": 403, "number_of_timesteps": 36080, "per_episode_reward": -581.1, "episode_reward_trend_value": -0.1353349798995724, "biggest_recent_change": 6.181584834907085},
Step 543 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 418.0]  episode_count: 403 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.023]Step 544 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 419.0]  episode_count: 403 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.028]Step 545 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 420.0]  episode_count: 403 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.033]Step 546 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 421.0]  episode_count: 403 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.038]Step 547 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 422.0]  episode_count: 404 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.042]Step 548 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 423.0]  episode_count: 404 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.047]Step 549 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 424.0]  episode_count: 404 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.052]Step 550 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 425.0]  episode_count: 407 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.057]Step 551 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 426.0]  episode_count: 408 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.062]Step 552 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 427.0]  episode_count: 409 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.041]Step 553 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 428.0]  episode_count: 409 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.046]Step 554 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 429.0]  episode_count: 409 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.05]Step 555 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 430.0]  episode_count: 410 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.055]Step 556 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 431.0]  episode_count: 410 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.06]Step 557 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 432.0]  episode_count: 410 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.065]{"total_number_of_episodes": 414, "number_of_timesteps": 37069, "per_episode_reward": -585.66, "episode_reward_trend_value": -0.17501817200375552, "biggest_recent_change": 6.181584834907085},
Step 558 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 433.0]  episode_count: 414 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.044]Step 559 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 434.0]  episode_count: 416 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.023]Step 560 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 435.0]  episode_count: 416 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.028]Step 561 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 436.0]  episode_count: 416 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.032]Step 562 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 437.0]  episode_count: 417 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.037]Step 563 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 438.0]  episode_count: 417 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.021]Step 564 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 439.0]  episode_count: 417 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.026]Step 565 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 440.0]  episode_count: 417 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.03]Step 566 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 441.0]  episode_count: 419 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.035]Step 567 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 442.0]  episode_count: 422 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.04]Step 568 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 443.0]  episode_count: 422 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.044]Step 569 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 444.0]  episode_count: 422 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.049]Step 570 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 445.0]  episode_count: 422 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.054]Step 571 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 446.0]  episode_count: 422 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.058]Step 572 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 447.0]  episode_count: 423 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.063]Step 573 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 448.0]  episode_count: 423 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.067]{"total_number_of_episodes": 424, "number_of_timesteps": 37900, "per_episode_reward": -585.67, "episode_reward_trend_value": -0.20433637945598854, "biggest_recent_change": 6.181584834907085},
Step 574 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 449.0]  episode_count: 424 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.072]Step 575 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 450.0]  episode_count: 425 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.077]Step 576 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 451.0]  episode_count: 425 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.081]Step 577 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 452.0]  episode_count: 426 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.086]Step 578 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 453.0]  episode_count: 426 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.09]Step 579 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 454.0]  episode_count: 428 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.094]Step 580 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 455.0]  episode_count: 429 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.099]Step 581 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 456.0]  episode_count: 430 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.103]Step 582 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 457.0]  episode_count: 430 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.108]Step 583 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 458.0]  episode_count: 431 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.112]Step 584 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 459.0]  episode_count: 431 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.092]Step 585 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 460.0]  episode_count: 432 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.097]Step 586 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 461.0]  episode_count: 432 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.077]Step 587 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 462.0]  episode_count: 432 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.081]Step 588 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 463.0]  episode_count: 433 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.086]{"total_number_of_episodes": 434, "number_of_timesteps": 38889, "per_episode_reward": -584.86, "episode_reward_trend_value": -0.2096431709453163, "biggest_recent_change": 6.181584834907085},
Step 589 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 464.0]  episode_count: 434 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.09]Step 590 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 465.0]  episode_count: 436 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.094]Step 591 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 466.0]  episode_count: 436 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.099]Step 592 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 467.0]  episode_count: 436 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.103]Step 593 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 468.0]  episode_count: 437 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.107]Step 594 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 469.0]  episode_count: 437 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.112]Step 595 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 470.0]  episode_count: 438 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.092]Step 596 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 471.0]  episode_count: 438 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.073]Step 597 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 472.0]  episode_count: 440 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.077]Step 598 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 473.0]  episode_count: 441 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.082]Step 599 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 474.0]  episode_count: 442 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.086]Step 600 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 475.0]  episode_count: 442 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.09]Step 601 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 476.0]  episode_count: 442 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.094]Step 602 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 477.0]  episode_count: 442 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.099]{"total_number_of_episodes": 445, "number_of_timesteps": 40044, "per_episode_reward": -590.66, "episode_reward_trend_value": -0.25173453080948827, "biggest_recent_change": 6.181584834907085},
Step 603 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 478.0]  episode_count: 445 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.103]Step 604 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 479.0]  episode_count: 445 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.107]Step 605 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 480.0]  episode_count: 445 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.111]Step 606 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 481.0]  episode_count: 446 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.115]Step 607 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 482.0]  episode_count: 446 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.119]Step 608 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 483.0]  episode_count: 447 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.124]Step 609 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 484.0]  episode_count: 448 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.128]Step 610 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 485.0]  episode_count: 448 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.132]Step 611 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 486.0]  episode_count: 450 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.136]Step 612 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 487.0]  episode_count: 450 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.14]Step 613 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 488.0]  episode_count: 451 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.144]Step 614 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 489.0]  episode_count: 451 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.125]Step 615 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 490.0]  episode_count: 451 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.129]Step 616 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 491.0]  episode_count: 451 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.133]Step 617 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 492.0]  episode_count: 454 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.137]{"total_number_of_episodes": 455, "number_of_timesteps": 40986, "per_episode_reward": -594.32, "episode_reward_trend_value": -0.22372529940451816, "biggest_recent_change": 5.890490564215156},
Step 618 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 493.0]  episode_count: 455 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.141]Step 619 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 494.0]  episode_count: 456 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.145]Step 620 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 495.0]  episode_count: 456 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.149]Step 621 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 496.0]  episode_count: 456 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.153]Step 622 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 497.0]  episode_count: 457 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.157]Step 623 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 498.0]  episode_count: 457 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.139]Step 624 6 visits [2.0, 6.0, 16.0, 83.0, 16.0, 2.0, 499.0]  episode_count: 457 q_vals: [-11.111, -10.236, -9.722, -9.418, -9.722, -11.111, -9.143]Step 625 6 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 457 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf]Step 626 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 459 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf]Step 627 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 460 q_vals: [0.0, -12.8, 0.0, 0.0, 0.0, 0.0, -inf]Step 628 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 460 q_vals: [0.0, -12.8, -12.8, 0.0, 0.0, 0.0, -inf]Step 629 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 500.0]  episode_count: 461 q_vals: [0.0, -12.8, -12.8, -12.8, 0.0, 0.0, -inf]Step 630 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 500.0]  episode_count: 462 q_vals: [0.0, -12.8, -12.8, -12.8, -12.8, 0.0, -inf]Step 631 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 463 q_vals: [0.0, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 632 0 visits [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 464 q_vals: [-6.4, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 633 0 visits [3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 464 q_vals: [-4.267, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 634 0 visits [4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 464 q_vals: [-6.4, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 635 0 visits [5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 464 q_vals: [-5.12, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 465, "number_of_timesteps": 42034, "per_episode_reward": -507.76, "episode_reward_trend_value": 0.6855773174196094, "biggest_recent_change": 86.56552247837641},
Step 636 0 visits [6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 465 q_vals: [-6.4, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 637 0 visits [7.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 465 q_vals: [-5.486, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 638 0 visits [8.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 465 q_vals: [-6.4, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 639 0 visits [9.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 466 q_vals: [-7.111, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 640 0 visits [10.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 466 q_vals: [-6.4, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 641 0 visits [11.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 467 q_vals: [-6.982, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 642 0 visits [12.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 469 q_vals: [-7.467, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 643 0 visits [13.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 471 q_vals: [-6.892, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 644 0 visits [14.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 471 q_vals: [-7.314, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 645 0 visits [15.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 471 q_vals: [-7.68, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 646 0 visits [16.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 471 q_vals: [-8.0, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 647 0 visits [17.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 471 q_vals: [-8.282, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 648 0 visits [18.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 473 q_vals: [-8.533, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 649 0 visits [19.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 473 q_vals: [-8.758, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 475, "number_of_timesteps": 43120, "per_episode_reward": -512.05, "episode_reward_trend_value": 0.7033043961166261, "biggest_recent_change": 86.56552247837641},
Step 650 0 visits [20.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 475 q_vals: [-8.32, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 651 0 visits [21.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 476 q_vals: [-8.533, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 652 0 visits [22.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 478 q_vals: [-8.727, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 653 0 visits [23.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 478 q_vals: [-8.904, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 654 0 visits [24.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 479 q_vals: [-8.533, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 655 0 visits [25.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 480 q_vals: [-8.192, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 656 0 visits [26.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 481 q_vals: [-8.369, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 657 0 visits [27.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 481 q_vals: [-8.533, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 658 0 visits [28.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 482 q_vals: [-8.686, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 659 0 visits [29.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 482 q_vals: [-8.386, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 660 0 visits [30.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 482 q_vals: [-8.107, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 661 0 visits [31.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 483 q_vals: [-8.258, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 486, "number_of_timesteps": 43993, "per_episode_reward": -510.24, "episode_reward_trend_value": 0.7551137394160814, "biggest_recent_change": 86.56552247837641},
Step 662 0 visits [32.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 486 q_vals: [-8.4, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 663 0 visits [33.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 487 q_vals: [-8.533, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 664 0 visits [34.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 488 q_vals: [-8.659, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 665 0 visits [35.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 488 q_vals: [-8.777, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 666 0 visits [36.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 488 q_vals: [-8.889, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 667 0 visits [37.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 488 q_vals: [-8.649, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 668 0 visits [38.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 490 q_vals: [-8.758, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 669 0 visits [39.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 491 q_vals: [-8.533, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 670 0 visits [40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 493 q_vals: [-8.64, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 671 0 visits [41.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 493 q_vals: [-8.741, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 672 0 visits [42.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 495 q_vals: [-8.838, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 673 0 visits [43.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 495 q_vals: [-8.633, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 674 0 visits [44.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 495 q_vals: [-8.436, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 496, "number_of_timesteps": 44740, "per_episode_reward": -508.69, "episode_reward_trend_value": 0.8044905084406416, "biggest_recent_change": 86.56552247837641},
Step 675 0 visits [45.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 496 q_vals: [-8.533, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 676 0 visits [46.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 497 q_vals: [-8.626, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 677 0 visits [47.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 497 q_vals: [-8.715, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 678 0 visits [48.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 498 q_vals: [-8.533, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 679 0 visits [49.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 498 q_vals: [-8.62, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 680 0 visits [50.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 501 q_vals: [-8.704, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 681 0 visits [51.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 502 q_vals: [-8.784, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 682 0 visits [52.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 502 q_vals: [-8.615, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 683 0 visits [53.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 502 q_vals: [-8.694, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 684 0 visits [54.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 503 q_vals: [-8.77, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 685 0 visits [55.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 503 q_vals: [-8.844, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 686 0 visits [56.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 504 q_vals: [-8.914, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 506, "number_of_timesteps": 45588, "per_episode_reward": -511.0, "episode_reward_trend_value": 0.8295949966325098, "biggest_recent_change": 86.56552247837641},
Step 687 0 visits [57.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 506 q_vals: [-8.982, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 688 0 visits [58.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 507 q_vals: [-8.828, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 689 0 visits [59.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 507 q_vals: [-8.895, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 690 0 visits [60.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 509 q_vals: [-8.96, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 691 0 visits [61.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 509 q_vals: [-9.023, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 692 0 visits [62.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 509 q_vals: [-8.877, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 693 0 visits [63.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 510 q_vals: [-8.94, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 694 0 visits [64.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 510 q_vals: [-9.0, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 695 0 visits [65.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 511 q_vals: [-9.058, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 696 0 visits [66.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 513 q_vals: [-9.115, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 697 0 visits [67.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 513 q_vals: [-9.17, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 698 0 visits [68.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 514 q_vals: [-9.224, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 516, "number_of_timesteps": 46452, "per_episode_reward": -511.95, "episode_reward_trend_value": 0.8191782832167949, "biggest_recent_change": 86.56552247837641},
Step 699 0 visits [69.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 516 q_vals: [-9.275, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 700 0 visits [70.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 516 q_vals: [-9.326, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 701 0 visits [71.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 517 q_vals: [-9.194, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 702 0 visits [72.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 517 q_vals: [-9.244, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 703 0 visits [73.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 519 q_vals: [-9.293, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 704 0 visits [74.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 519 q_vals: [-9.341, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 705 0 visits [75.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 519 q_vals: [-9.387, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 706 0 visits [76.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 520 q_vals: [-9.432, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 707 0 visits [77.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 521 q_vals: [-9.475, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 708 0 visits [78.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 521 q_vals: [-9.518, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 709 0 visits [79.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 522 q_vals: [-9.559, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 710 0 visits [80.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 523 q_vals: [-9.6, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 711 0 visits [81.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 523 q_vals: [-9.64, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 712 0 visits [82.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 523 q_vals: [-9.678, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 713 0 visits [83.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 524 q_vals: [-9.716, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 714 0 visits [84.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 524 q_vals: [-9.752, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 715 0 visits [85.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 525 q_vals: [-9.638, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 527, "number_of_timesteps": 47507, "per_episode_reward": -511.8, "episode_reward_trend_value": 0.8118512835965463, "biggest_recent_change": 86.56552247837641},
Step 716 0 visits [86.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 527 q_vals: [-9.674, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 717 0 visits [87.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 528 q_vals: [-9.563, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 718 0 visits [88.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 529 q_vals: [-9.6, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 719 0 visits [89.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 530 q_vals: [-9.492, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 720 0 visits [90.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 530 q_vals: [-9.529, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 721 0 visits [91.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 531 q_vals: [-9.565, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 722 0 visits [92.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 531 q_vals: [-9.6, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 723 0 visits [93.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 532 q_vals: [-9.634, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 724 0 visits [94.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 533 q_vals: [-9.668, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 725 0 visits [95.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 534 q_vals: [-9.701, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 726 0 visits [96.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 534 q_vals: [-9.733, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 727 0 visits [97.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 535 q_vals: [-9.633, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 728 0 visits [98.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 535 q_vals: [-9.665, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 537, "number_of_timesteps": 48341, "per_episode_reward": -512.86, "episode_reward_trend_value": 0.8645257167522686, "biggest_recent_change": 86.56552247837641},
Step 729 0 visits [99.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 537 q_vals: [-9.697, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 730 0 visits [100.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 537 q_vals: [-9.728, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 731 0 visits [101.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 538 q_vals: [-9.758, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 732 0 visits [102.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 539 q_vals: [-9.788, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 733 0 visits [103.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 541 q_vals: [-9.817, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 734 0 visits [104.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 541 q_vals: [-9.723, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 735 0 visits [105.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 542 q_vals: [-9.63, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 736 0 visits [106.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 542 q_vals: [-9.66, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 737 0 visits [107.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 543 q_vals: [-9.69, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 738 0 visits [108.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 544 q_vals: [-9.6, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 739 0 visits [109.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 546 q_vals: [-9.629, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 740 0 visits [110.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 546 q_vals: [-9.658, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 741 0 visits [111.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 546 q_vals: [-9.686, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 548, "number_of_timesteps": 49273, "per_episode_reward": -511.44, "episode_reward_trend_value": 0.9209452663536423, "biggest_recent_change": 86.56552247837641},
Step 742 0 visits [112.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 548 q_vals: [-9.6, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 743 0 visits [113.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 549 q_vals: [-9.515, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 744 0 visits [114.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 549 q_vals: [-9.432, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 745 0 visits [115.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 550 q_vals: [-9.461, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 746 0 visits [116.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 550 q_vals: [-9.49, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 747 0 visits [117.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 552 q_vals: [-9.518, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 748 0 visits [118.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 552 q_vals: [-9.437, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 749 0 visits [119.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 552 q_vals: [-9.466, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 750 0 visits [120.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 552 q_vals: [-9.493, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 751 0 visits [121.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 553 q_vals: [-9.521, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 752 0 visits [122.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 556 q_vals: [-9.548, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 753 0 visits [123.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 557 q_vals: [-9.47, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 754 0 visits [124.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 557 q_vals: [-9.497, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 755 0 visits [125.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 557 q_vals: [-9.523, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 756 0 visits [126.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 557 q_vals: [-9.549, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 558, "number_of_timesteps": 50149, "per_episode_reward": -513.63, "episode_reward_trend_value": -0.06527233229527446, "biggest_recent_change": 4.295053481483649},
Step 757 0 visits [127.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 558 q_vals: [-9.575, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 758 0 visits [128.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 559 q_vals: [-9.6, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 759 0 visits [129.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 560 q_vals: [-9.526, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 760 0 visits [130.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 562 q_vals: [-9.452, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 761 0 visits [131.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 562 q_vals: [-9.478, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 762 0 visits [132.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 564 q_vals: [-9.503, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 763 0 visits [133.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 564 q_vals: [-9.528, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 764 0 visits [134.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 564 q_vals: [-9.552, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 765 0 visits [135.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 565 q_vals: [-9.576, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 766 0 visits [136.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 566 q_vals: [-9.506, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 767 0 visits [137.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 567 q_vals: [-9.53, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 768 0 visits [138.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 567 q_vals: [-9.554, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 769 0 visits [139.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 567 q_vals: [-9.485, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 568, "number_of_timesteps": 50967, "per_episode_reward": -513.06, "episode_reward_trend_value": -0.011178234422818099, "biggest_recent_change": 2.3082660492465834},
Step 770 0 visits [140.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 568 q_vals: [-9.509, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 771 0 visits [141.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 570 q_vals: [-9.441, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 772 0 visits [142.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 571 q_vals: [-9.465, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 773 0 visits [143.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 571 q_vals: [-9.399, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 774 0 visits [144.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 571 q_vals: [-9.422, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 775 0 visits [145.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 572 q_vals: [-9.446, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 776 0 visits [146.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 572 q_vals: [-9.468, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 777 0 visits [147.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 574 q_vals: [-9.404, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 778 0 visits [148.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 576 q_vals: [-9.427, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 779 0 visits [149.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 576 q_vals: [-9.45, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 780 0 visits [150.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 576 q_vals: [-9.472, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 781 0 visits [151.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 576 q_vals: [-9.494, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 579, "number_of_timesteps": 51989, "per_episode_reward": -513.82, "episode_reward_trend_value": -0.0397020538316604, "biggest_recent_change": 2.3082660492465834},
Step 782 0 visits [152.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 579 q_vals: [-9.516, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 783 0 visits [153.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 579 q_vals: [-9.537, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 784 0 visits [154.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 579 q_vals: [-9.475, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 785 0 visits [155.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 579 q_vals: [-9.497, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 786 0 visits [156.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 581 q_vals: [-9.436, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 787 0 visits [157.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 582 q_vals: [-9.457, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 788 0 visits [158.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 582 q_vals: [-9.397, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 789 0 visits [159.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 582 q_vals: [-9.419, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 790 0 visits [160.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 582 q_vals: [-9.44, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 791 0 visits [161.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 583 q_vals: [-9.461, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 792 0 visits [162.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 583 q_vals: [-9.481, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 793 0 visits [163.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 585 q_vals: [-9.502, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 794 0 visits [164.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 585 q_vals: [-9.444, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 795 0 visits [165.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 585 q_vals: [-9.387, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 796 0 visits [166.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 586 q_vals: [-9.407, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 797 0 visits [167.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 586 q_vals: [-9.428, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 798 0 visits [168.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 586 q_vals: [-9.448, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 799 0 visits [169.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 587 q_vals: [-9.467, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 800 0 visits [170.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 588 q_vals: [-9.487, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 589, "number_of_timesteps": 53072, "per_episode_reward": -512.41, "episode_reward_trend_value": -0.041308734332865374, "biggest_recent_change": 2.3082660492465834},
Step 801 0 visits [171.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 589 q_vals: [-9.506, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 802 0 visits [172.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 589 q_vals: [-9.526, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 803 0 visits [173.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 590 q_vals: [-9.545, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 804 0 visits [174.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 590 q_vals: [-9.563, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 805 0 visits [175.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 590 q_vals: [-9.582, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 806 0 visits [176.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 590 q_vals: [-9.6, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 807 0 visits [177.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 590 q_vals: [-9.618, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 808 0 visits [178.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 590 q_vals: [-9.564, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 809 0 visits [179.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 591 q_vals: [-9.582, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 810 0 visits [180.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 593 q_vals: [-9.529, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 811 0 visits [181.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 595 q_vals: [-9.476, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 812 0 visits [182.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 595 q_vals: [-9.424, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 813 0 visits [183.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 596 q_vals: [-9.443, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 814 0 visits [184.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 596 q_vals: [-9.461, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 815 0 visits [185.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 596 q_vals: [-9.479, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 816 0 visits [186.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 596 q_vals: [-9.428, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 817 0 visits [187.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 596 q_vals: [-9.378, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 818 0 visits [188.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 596 q_vals: [-9.396, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 599, "number_of_timesteps": 54375, "per_episode_reward": -513.48, "episode_reward_trend_value": -0.027600301292920904, "biggest_recent_change": 2.1940614000261007},
Step 819 0 visits [189.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 599 q_vals: [-9.414, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 820 0 visits [190.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 600 q_vals: [-9.432, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 821 0 visits [191.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 601 q_vals: [-9.449, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 822 0 visits [192.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 602 q_vals: [-9.4, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 823 0 visits [193.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 602 q_vals: [-9.418, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 824 0 visits [194.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 602 q_vals: [-9.435, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 825 0 visits [195.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 602 q_vals: [-9.452, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 826 0 visits [196.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 603 q_vals: [-9.469, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 827 0 visits [197.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 603 q_vals: [-9.486, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 828 0 visits [198.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 604 q_vals: [-9.438, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 829 0 visits [199.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 604 q_vals: [-9.455, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 830 0 visits [200.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 604 q_vals: [-9.472, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 831 0 visits [201.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 604 q_vals: [-9.489, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 832 0 visits [202.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 605 q_vals: [-9.505, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 833 0 visits [203.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 605 q_vals: [-9.458, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 834 0 visits [204.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 608 q_vals: [-9.412, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 835 0 visits [205.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 608 q_vals: [-9.366, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 836 0 visits [206.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 608 q_vals: [-9.383, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 609, "number_of_timesteps": 55421, "per_episode_reward": -513.72, "episode_reward_trend_value": -0.019727770307657818, "biggest_recent_change": 2.1940614000261007},
Step 837 0 visits [207.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 609 q_vals: [-9.399, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 838 0 visits [208.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 609 q_vals: [-9.415, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 839 0 visits [209.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 610 q_vals: [-9.432, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 840 0 visits [210.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 610 q_vals: [-9.387, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 841 0 visits [211.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 612 q_vals: [-9.403, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 842 0 visits [212.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 614 q_vals: [-9.358, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 843 0 visits [213.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 614 q_vals: [-9.375, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 844 0 visits [214.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 614 q_vals: [-9.391, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 845 0 visits [215.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 614 q_vals: [-9.407, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 846 0 visits [216.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 616 q_vals: [-9.422, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 847 0 visits [217.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 617 q_vals: [-9.438, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 848 0 visits [218.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 617 q_vals: [-9.453, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 849 0 visits [219.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 617 q_vals: [-9.41, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 619, "number_of_timesteps": 56493, "per_episode_reward": -513.63, "episode_reward_trend_value": -0.020373255358228766, "biggest_recent_change": 2.1940614000261007},
Step 850 0 visits [220.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 619 q_vals: [-9.425, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 851 0 visits [221.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 619 q_vals: [-9.441, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 852 0 visits [222.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 619 q_vals: [-9.398, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 853 0 visits [223.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 620 q_vals: [-9.413, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 854 0 visits [224.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 620 q_vals: [-9.429, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 855 0 visits [225.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 621 q_vals: [-9.444, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 856 0 visits [226.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 621 q_vals: [-9.458, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 857 0 visits [227.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 622 q_vals: [-9.417, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 858 0 visits [228.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 623 q_vals: [-9.432, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 859 0 visits [229.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 623 q_vals: [-9.446, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 860 0 visits [230.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 623 q_vals: [-9.461, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 861 0 visits [231.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 625 q_vals: [-9.475, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 862 0 visits [232.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 626 q_vals: [-9.49, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 863 0 visits [233.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 626 q_vals: [-9.449, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 864 0 visits [234.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 626 q_vals: [-9.463, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 865 0 visits [235.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 627 q_vals: [-9.472, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 866 0 visits [236.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 628 q_vals: [-9.486, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 867 0 visits [237.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 628 q_vals: [-9.5, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 629, "number_of_timesteps": 57625, "per_episode_reward": -512.71, "episode_reward_trend_value": 0.0016366757440550827, "biggest_recent_change": 2.1940614000261007},
Step 868 0 visits [238.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 629 q_vals: [-9.514, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 869 0 visits [239.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 630 q_vals: [-9.527, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 870 0 visits [240.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 631 q_vals: [-9.541, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 871 0 visits [241.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 631 q_vals: [-9.555, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 872 0 visits [242.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 632 q_vals: [-9.568, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 873 0 visits [243.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 632 q_vals: [-9.581, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 874 0 visits [244.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 634 q_vals: [-9.594, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 875 0 visits [245.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 634 q_vals: [-9.608, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 876 0 visits [246.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 634 q_vals: [-9.621, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 877 0 visits [247.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 634 q_vals: [-9.633, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 878 0 visits [248.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 634 q_vals: [-9.646, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 879 0 visits [249.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 638 q_vals: [-9.659, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 880 0 visits [250.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 638 q_vals: [-9.671, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 881 0 visits [251.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 638 q_vals: [-9.684, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 882 0 visits [252.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 638 q_vals: [-9.645, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 883 0 visits [253.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 638 q_vals: [-9.658, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 639, "number_of_timesteps": 58678, "per_episode_reward": -514.16, "episode_reward_trend_value": -0.030236031812409515, "biggest_recent_change": 2.1940614000261007},
Step 884 0 visits [254.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 639 q_vals: [-9.67, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 885 0 visits [255.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 641 q_vals: [-9.683, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 886 0 visits [256.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 641 q_vals: [-9.645, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 887 0 visits [257.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 641 q_vals: [-9.657, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 888 0 visits [258.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 643 q_vals: [-9.669, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 889 0 visits [259.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 644 q_vals: [-9.632, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 890 0 visits [260.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 644 q_vals: [-9.644, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 891 0 visits [261.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 645 q_vals: [-9.656, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 892 0 visits [262.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 647 q_vals: [-9.668, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 893 0 visits [263.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 648 q_vals: [-9.68, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 894 0 visits [264.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 648 q_vals: [-9.643, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 895 0 visits [265.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 648 q_vals: [-9.655, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 649, "number_of_timesteps": 59535, "per_episode_reward": -514.19, "episode_reward_trend_value": -0.006207362472789807, "biggest_recent_change": 1.451538224417959},
Step 896 0 visits [266.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 649 q_vals: [-9.667, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 897 0 visits [267.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 649 q_vals: [-9.631, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 898 0 visits [268.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 651 q_vals: [-9.643, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 899 0 visits [269.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 652 q_vals: [-9.654, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 900 0 visits [270.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 653 q_vals: [-9.619, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 901 0 visits [271.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 653 q_vals: [-9.583, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 902 0 visits [272.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 653 q_vals: [-9.548, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 903 0 visits [273.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 653 q_vals: [-9.513, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 904 0 visits [274.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 654 q_vals: [-9.525, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 905 0 visits [275.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 655 q_vals: [-9.49, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 906 0 visits [276.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 655 q_vals: [-9.502, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 907 0 visits [277.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 657 q_vals: [-9.468, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 659, "number_of_timesteps": 60448, "per_episode_reward": -514.59, "episode_reward_trend_value": -0.016967242013591507, "biggest_recent_change": 1.451538224417959},
Step 908 0 visits [278.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 659 q_vals: [-9.48, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 909 0 visits [279.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 659 q_vals: [-9.446, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 910 0 visits [280.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 660 q_vals: [-9.412, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 911 0 visits [281.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 660 q_vals: [-9.424, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 912 0 visits [282.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 660 q_vals: [-9.436, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 913 0 visits [283.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 661 q_vals: [-9.448, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 914 0 visits [284.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 663 q_vals: [-9.46, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 915 0 visits [285.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 663 q_vals: [-9.472, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 916 0 visits [286.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 663 q_vals: [-9.483, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 917 0 visits [287.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 663 q_vals: [-9.495, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 918 0 visits [288.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 666 q_vals: [-9.506, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 919 0 visits [289.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 667 q_vals: [-9.518, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 920 0 visits [290.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 667 q_vals: [-9.529, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 921 0 visits [291.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 668 q_vals: [-9.54, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 922 0 visits [292.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 668 q_vals: [-9.552, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 923 0 visits [293.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 668 q_vals: [-9.519, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 924 0 visits [294.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 668 q_vals: [-9.487, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 670, "number_of_timesteps": 61472, "per_episode_reward": -514.36, "episode_reward_trend_value": -0.006015661245130054, "biggest_recent_change": 1.451538224417959},
Step 925 0 visits [295.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 670 q_vals: [-9.454, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 926 0 visits [296.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 670 q_vals: [-9.422, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 927 0 visits [297.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 670 q_vals: [-9.434, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 928 0 visits [298.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 671 q_vals: [-9.445, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 929 0 visits [299.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 671 q_vals: [-9.456, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 930 0 visits [300.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 673 q_vals: [-9.468, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 931 0 visits [301.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 675 q_vals: [-9.479, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 932 0 visits [302.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 675 q_vals: [-9.49, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 933 0 visits [303.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 675 q_vals: [-9.458, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 934 0 visits [304.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 675 q_vals: [-9.469, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 935 0 visits [305.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 675 q_vals: [-9.48, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 936 0 visits [306.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 675 q_vals: [-9.449, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 937 0 visits [307.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 675 q_vals: [-9.46, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 938 0 visits [308.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 676 q_vals: [-9.471, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 939 0 visits [309.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 678 q_vals: [-9.44, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 940 0 visits [310.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 679 q_vals: [-9.451, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 941 0 visits [311.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 679 q_vals: [-9.462, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 942 0 visits [312.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 679 q_vals: [-9.473, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 943 0 visits [313.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 679 q_vals: [-9.483, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 680, "number_of_timesteps": 62560, "per_episode_reward": -514.06, "episode_reward_trend_value": -0.018347469213503904, "biggest_recent_change": 1.451538224417959},
Step 944 0 visits [314.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 680 q_vals: [-9.494, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 945 0 visits [315.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 680 q_vals: [-9.464, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 946 0 visits [316.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 680 q_vals: [-9.474, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 947 0 visits [317.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 680 q_vals: [-9.485, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 948 0 visits [318.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 681 q_vals: [-9.495, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 949 0 visits [319.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 682 q_vals: [-9.505, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 950 0 visits [320.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 683 q_vals: [-9.516, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 951 0 visits [321.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 684 q_vals: [-9.526, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 952 0 visits [322.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 685 q_vals: [-9.536, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 953 0 visits [323.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 686 q_vals: [-9.507, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 954 0 visits [324.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 687 q_vals: [-9.477, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 955 0 visits [325.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 687 q_vals: [-9.488, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 956 0 visits [326.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 688 q_vals: [-9.458, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 957 0 visits [327.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 689 q_vals: [-9.469, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 958 0 visits [328.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 689 q_vals: [-9.44, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 690, "number_of_timesteps": 63718, "per_episode_reward": -512.49, "episode_reward_trend_value": 0.011092522987034196, "biggest_recent_change": 1.5750922223968473},
Step 959 0 visits [329.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 690 q_vals: [-9.411, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 960 0 visits [330.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 690 q_vals: [-9.383, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 961 0 visits [331.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 690 q_vals: [-9.393, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 962 0 visits [332.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 690 q_vals: [-9.403, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 963 0 visits [333.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 690 q_vals: [-9.413, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 964 0 visits [334.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 692 q_vals: [-9.385, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 965 0 visits [335.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 694 q_vals: [-9.395, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 966 0 visits [336.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 695 q_vals: [-9.406, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 967 0 visits [337.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 695 q_vals: [-9.416, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 968 0 visits [338.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 696 q_vals: [-9.426, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 969 0 visits [339.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 697 q_vals: [-9.436, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 970 0 visits [340.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 697 q_vals: [-9.445, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 971 0 visits [341.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 697 q_vals: [-9.455, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 972 0 visits [342.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 698 q_vals: [-9.428, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 973 0 visits [343.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 699 q_vals: [-9.437, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 700, "number_of_timesteps": 64731, "per_episode_reward": -510.61, "episode_reward_trend_value": 0.0345571567550697, "biggest_recent_change": 1.8726431178001235},
Step 974 0 visits [344.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 700 q_vals: [-9.41, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 975 0 visits [345.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 701 q_vals: [-9.42, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 976 0 visits [346.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 701 q_vals: [-9.43, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 977 0 visits [347.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 702 q_vals: [-9.439, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 978 0 visits [348.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 703 q_vals: [-9.449, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 979 0 visits [349.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 703 q_vals: [-9.459, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 980 0 visits [350.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 703 q_vals: [-9.468, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 981 0 visits [351.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 703 q_vals: [-9.478, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 982 0 visits [352.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 705 q_vals: [-9.487, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 983 0 visits [353.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 705 q_vals: [-9.46, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 984 0 visits [354.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 706 q_vals: [-9.47, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 985 0 visits [355.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 706 q_vals: [-9.443, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 986 0 visits [356.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 706 q_vals: [-9.452, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 987 0 visits [357.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 707 q_vals: [-9.462, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 988 0 visits [358.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 707 q_vals: [-9.435, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 989 0 visits [359.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 707 q_vals: [-9.409, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 990 0 visits [360.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 707 q_vals: [-9.418, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 991 0 visits [361.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 707 q_vals: [-9.428, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 992 0 visits [362.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 707 q_vals: [-9.402, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 993 0 visits [363.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 707 q_vals: [-9.411, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 994 0 visits [364.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 708 q_vals: [-9.42, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 710, "number_of_timesteps": 65873, "per_episode_reward": -509.82, "episode_reward_trend_value": 0.04231154843826883, "biggest_recent_change": 1.8726431178001235},
Step 995 0 visits [365.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 710 q_vals: [-9.43, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 996 0 visits [366.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 711 q_vals: [-9.439, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 997 0 visits [367.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 713 q_vals: [-9.448, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 998 0 visits [368.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 713 q_vals: [-9.457, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 999 0 visits [369.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 714 q_vals: [-9.466, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1000 0 visits [370.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 714 q_vals: [-9.475, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1001 0 visits [371.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 714 q_vals: [-9.484, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1002 0 visits [372.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 714 q_vals: [-9.459, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1003 0 visits [373.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 714 q_vals: [-9.468, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1004 0 visits [374.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 715 q_vals: [-9.442, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1005 0 visits [375.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 715 q_vals: [-9.417, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1006 0 visits [376.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 715 q_vals: [-9.392, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1007 0 visits [377.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 715 q_vals: [-9.401, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1008 0 visits [378.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 717 q_vals: [-9.41, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1009 0 visits [379.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 718 q_vals: [-9.419, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1010 0 visits [380.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 718 q_vals: [-9.394, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1011 0 visits [381.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 719 q_vals: [-9.37, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1012 0 visits [382.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 719 q_vals: [-9.379, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1013 0 visits [383.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 719 q_vals: [-9.388, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1014 0 visits [384.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 719 q_vals: [-9.396, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 721, "number_of_timesteps": 67380, "per_episode_reward": -509.21, "episode_reward_trend_value": 0.03885834901097509, "biggest_recent_change": 1.8726431178001235},
Step 1015 0 visits [385.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 721 q_vals: [-9.405, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1016 0 visits [386.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 721 q_vals: [-9.414, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1017 0 visits [387.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 724 q_vals: [-9.39, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1018 0 visits [388.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 724 q_vals: [-9.399, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1019 0 visits [389.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 725 q_vals: [-9.407, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1020 0 visits [390.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 725 q_vals: [-9.416, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1021 0 visits [391.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 726 q_vals: [-9.392, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1022 0 visits [392.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 726 q_vals: [-9.401, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1023 0 visits [393.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 727 q_vals: [-9.409, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1024 0 visits [394.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 727 q_vals: [-9.418, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1025 0 visits [395.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 730 q_vals: [-9.426, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1026 0 visits [396.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 730 q_vals: [-9.435, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1027 0 visits [397.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 730 q_vals: [-9.443, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 733, "number_of_timesteps": 68520, "per_episode_reward": -507.16, "episode_reward_trend_value": 0.07772938262101926, "biggest_recent_change": 2.0468548004860168},
Step 1028 0 visits [398.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 733 q_vals: [-9.452, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1029 0 visits [399.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 733 q_vals: [-9.46, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1030 0 visits [400.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 733 q_vals: [-9.437, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1031 0 visits [401.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 733 q_vals: [-9.445, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1032 0 visits [402.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 734 q_vals: [-9.451, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1033 0 visits [403.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 735 q_vals: [-9.459, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1034 0 visits [404.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 738 q_vals: [-9.468, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1035 0 visits [405.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 739 q_vals: [-9.476, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1036 0 visits [406.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 739 q_vals: [-9.484, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1037 0 visits [407.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 739 q_vals: [-9.461, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1038 0 visits [408.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 739 q_vals: [-9.438, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1039 0 visits [409.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 740 q_vals: [-9.414, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1040 0 visits [410.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 740 q_vals: [-9.423, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1041 0 visits [411.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 740 q_vals: [-9.431, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1042 0 visits [412.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 740 q_vals: [-9.408, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1043 0 visits [413.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 742 q_vals: [-9.385, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1044 0 visits [414.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 742 q_vals: [-9.393, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 745, "number_of_timesteps": 69595, "per_episode_reward": -504.92, "episode_reward_trend_value": 0.10304237919614759, "biggest_recent_change": 2.2466885323012207},
Step 1045 0 visits [415.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 745 q_vals: [-9.371, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1046 0 visits [416.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 745 q_vals: [-9.379, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1047 0 visits [417.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 745 q_vals: [-9.387, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1048 0 visits [418.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 745 q_vals: [-9.365, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1049 0 visits [419.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 745 q_vals: [-9.342, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1050 0 visits [420.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 746 q_vals: [-9.32, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1051 0 visits [421.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 746 q_vals: [-9.298, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1052 0 visits [422.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 746 q_vals: [-9.306, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1053 0 visits [423.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 746 q_vals: [-9.284, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1054 0 visits [424.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 746 q_vals: [-9.263, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1055 0 visits [425.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 749 q_vals: [-9.271, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1056 0 visits [426.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 750 q_vals: [-9.249, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1057 0 visits [427.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 750 q_vals: [-9.227, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1058 0 visits [428.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 750 q_vals: [-9.236, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1059 0 visits [429.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 750 q_vals: [-9.214, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1060 0 visits [430.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 751 q_vals: [-9.223, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1061 0 visits [431.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 751 q_vals: [-9.231, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1062 0 visits [432.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 751 q_vals: [-9.209, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1063 0 visits [433.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 753 q_vals: [-9.218, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1064 0 visits [434.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 753 q_vals: [-9.226, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1065 0 visits [435.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 754 q_vals: [-9.234, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1066 0 visits [436.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 754 q_vals: [-9.213, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 756, "number_of_timesteps": 70989, "per_episode_reward": -503.23, "episode_reward_trend_value": 0.1261723689438371, "biggest_recent_change": 2.2466885323012207},
Step 1067 0 visits [437.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 756 q_vals: [-9.192, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1068 0 visits [438.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 756 q_vals: [-9.2, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1069 0 visits [439.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 756 q_vals: [-9.179, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1070 0 visits [440.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 756 q_vals: [-9.158, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1071 0 visits [441.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 756 q_vals: [-9.167, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1072 0 visits [442.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 758 q_vals: [-9.175, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1073 0 visits [443.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 759 q_vals: [-9.183, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1074 0 visits [444.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 760 q_vals: [-9.191, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1075 0 visits [445.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 761 q_vals: [-9.199, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1076 0 visits [446.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 762 q_vals: [-9.207, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1077 0 visits [447.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 763 q_vals: [-9.215, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1078 0 visits [448.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 763 q_vals: [-9.223, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1079 0 visits [449.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 763 q_vals: [-9.231, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1080 0 visits [450.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 764 q_vals: [-9.239, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1081 0 visits [451.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 765 q_vals: [-9.247, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1082 0 visits [452.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 765 q_vals: [-9.255, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1083 0 visits [453.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 765 q_vals: [-9.263, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1084 0 visits [454.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 765 q_vals: [-9.271, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1085 0 visits [455.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 765 q_vals: [-9.278, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 768, "number_of_timesteps": 72222, "per_episode_reward": -501.66, "episode_reward_trend_value": 0.14108325347674824, "biggest_recent_change": 2.2466885323012207},
Step 1086 0 visits [456.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 768 q_vals: [-9.286, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1087 0 visits [457.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 769 q_vals: [-9.266, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1088 0 visits [458.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 769 q_vals: [-9.246, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1089 0 visits [459.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 771 q_vals: [-9.253, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1090 0 visits [460.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 772 q_vals: [-9.261, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1091 0 visits [461.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 772 q_vals: [-9.269, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1092 0 visits [462.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 772 q_vals: [-9.276, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1093 0 visits [463.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 772 q_vals: [-9.284, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1094 0 visits [464.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 773 q_vals: [-9.292, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1095 0 visits [465.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 773 q_vals: [-9.272, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1096 0 visits [466.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 774 q_vals: [-9.279, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1097 0 visits [467.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 774 q_vals: [-9.287, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1098 0 visits [468.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 775 q_vals: [-9.267, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1099 0 visits [469.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 776 q_vals: [-9.274, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1100 0 visits [470.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 777 q_vals: [-9.255, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 778, "number_of_timesteps": 73236, "per_episode_reward": -501.17, "episode_reward_trend_value": 0.14323320173840684, "biggest_recent_change": 2.2466885323012207},
Step 1101 0 visits [471.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 778 q_vals: [-9.262, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1102 0 visits [472.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 778 q_vals: [-9.243, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1103 0 visits [473.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 779 q_vals: [-9.25, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1104 0 visits [474.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 779 q_vals: [-9.258, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1105 0 visits [475.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 780 q_vals: [-9.265, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1106 0 visits [476.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 780 q_vals: [-9.272, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1107 0 visits [477.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 781 q_vals: [-9.253, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1108 0 visits [478.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 782 q_vals: [-9.26, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1109 0 visits [479.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 782 q_vals: [-9.268, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1110 0 visits [480.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 782 q_vals: [-9.275, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1111 0 visits [481.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 783 q_vals: [-9.283, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1112 0 visits [482.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 783 q_vals: [-9.29, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1113 0 visits [483.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 783 q_vals: [-9.297, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1114 0 visits [484.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 784 q_vals: [-9.304, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1115 0 visits [485.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 786 q_vals: [-9.312, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1116 0 visits [486.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 786 q_vals: [-9.319, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1117 0 visits [487.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 786 q_vals: [-9.326, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1118 0 visits [488.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 786 q_vals: [-9.307, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1119 0 visits [489.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 787 q_vals: [-9.314, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]{"total_number_of_episodes": 788, "number_of_timesteps": 74389, "per_episode_reward": -500.12, "episode_reward_trend_value": 0.13744312300329525, "biggest_recent_change": 2.2466885323012207},
Step 1120 0 visits [490.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 788 q_vals: [-9.321, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1121 0 visits [491.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 788 q_vals: [-9.328, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1122 0 visits [492.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 788 q_vals: [-9.335, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1123 0 visits [493.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 789 q_vals: [-9.316, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1124 0 visits [494.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 789 q_vals: [-9.323, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1125 0 visits [495.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 789 q_vals: [-9.33, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1126 0 visits [496.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 791 q_vals: [-9.337, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1127 0 visits [497.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 792 q_vals: [-9.344, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1128 0 visits [498.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 795 q_vals: [-9.351, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1129 0 visits [499.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 795 q_vals: [-9.358, -12.8, -12.8, -12.8, -12.8, -12.8, -inf]Step 1130 0 visits [500.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 795 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, -inf]Step 1131 1 visits [500.0, 1.0, 0.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 795 q_vals: [-inf, -15.0, 0.0, 0.0, 0.0, 0.0, -inf]Step 1132 2 visits [500.0, 1.0, 1.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 795 q_vals: [-inf, -15.0, 0.0, 0.0, 0.0, 0.0, -inf]Step 1133 3 visits [500.0, 1.0, 1.0, 1.0, 0.0, 0.0, 500.0]  episode_count: 797 q_vals: [-inf, -15.0, 0.0, -15.0, 0.0, 0.0, -inf]Step 1134 4 visits [500.0, 1.0, 1.0, 1.0, 1.0, 0.0, 500.0]  episode_count: 797 q_vals: [-inf, -15.0, 0.0, -15.0, -15.0, 0.0, -inf]Step 1135 5 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 797 q_vals: [-inf, -15.0, 0.0, -15.0, -15.0, 0.0, -inf]Step 1136 2 visits [500.0, 1.0, 2.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 797 q_vals: [-inf, -15.0, 0.0, -15.0, -15.0, 0.0, -inf]{"total_number_of_episodes": 798, "number_of_timesteps": 75477, "per_episode_reward": -413.31, "episode_reward_trend_value": 1.081147214610726, "biggest_recent_change": 86.8060113624689},
Step 1137 5 visits [500.0, 1.0, 2.0, 1.0, 1.0, 2.0, 500.0]  episode_count: 798 q_vals: [-inf, -15.0, 0.0, -15.0, -15.0, -7.5, -inf]Step 1138 2 visits [500.0, 1.0, 3.0, 1.0, 1.0, 2.0, 500.0]  episode_count: 799 q_vals: [-inf, -15.0, -5.0, -15.0, -15.0, -7.5, -inf]Step 1139 2 visits [500.0, 1.0, 4.0, 1.0, 1.0, 2.0, 500.0]  episode_count: 800 q_vals: [-inf, -15.0, -3.75, -15.0, -15.0, -7.5, -inf]Step 1140 2 visits [500.0, 1.0, 5.0, 1.0, 1.0, 2.0, 500.0]  episode_count: 801 q_vals: [-inf, -15.0, -6.0, -15.0, -15.0, -7.5, -inf]Step 1141 2 visits [500.0, 1.0, 6.0, 1.0, 1.0, 2.0, 500.0]  episode_count: 802 q_vals: [-inf, -15.0, -5.0, -15.0, -15.0, -7.5, -inf]Step 1142 2 visits [500.0, 1.0, 7.0, 1.0, 1.0, 2.0, 500.0]  episode_count: 803 q_vals: [-inf, -15.0, -6.429, -15.0, -15.0, -7.5, -inf]Step 1143 2 visits [500.0, 1.0, 8.0, 1.0, 1.0, 2.0, 500.0]  episode_count: 804 q_vals: [-inf, -15.0, -7.5, -15.0, -15.0, -7.5, -inf]Step 1144 5 visits [500.0, 1.0, 8.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 804 q_vals: [-inf, -15.0, -7.5, -15.0, -15.0, -10.0, -inf]Step 1145 2 visits [500.0, 1.0, 9.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 804 q_vals: [-inf, -15.0, -8.333, -15.0, -15.0, -10.0, -inf]Step 1146 2 visits [500.0, 1.0, 10.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 805 q_vals: [-inf, -15.0, -9.0, -15.0, -15.0, -10.0, -inf]Step 1147 2 visits [500.0, 1.0, 11.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 805 q_vals: [-inf, -15.0, -8.182, -15.0, -15.0, -10.0, -inf]Step 1148 2 visits [500.0, 1.0, 12.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 805 q_vals: [-inf, -15.0, -7.5, -15.0, -15.0, -10.0, -inf]Step 1149 2 visits [500.0, 1.0, 13.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 806 q_vals: [-inf, -15.0, -8.077, -15.0, -15.0, -10.0, -inf]Step 1150 2 visits [500.0, 1.0, 14.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 807 q_vals: [-inf, -15.0, -8.571, -15.0, -15.0, -10.0, -inf]Step 1151 2 visits [500.0, 1.0, 15.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 807 q_vals: [-inf, -15.0, -8.0, -15.0, -15.0, -10.0, -inf]Step 1152 2 visits [500.0, 1.0, 16.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 807 q_vals: [-inf, -15.0, -8.438, -15.0, -15.0, -10.0, -inf]Step 1153 2 visits [500.0, 1.0, 17.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 807 q_vals: [-inf, -15.0, -7.941, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 809, "number_of_timesteps": 76673, "per_episode_reward": -412.7, "episode_reward_trend_value": 1.0791484821505637, "biggest_recent_change": 86.8060113624689},
Step 1154 2 visits [500.0, 1.0, 18.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 809 q_vals: [-inf, -15.0, -7.5, -15.0, -15.0, -10.0, -inf]Step 1155 2 visits [500.0, 1.0, 19.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 809 q_vals: [-inf, -15.0, -7.895, -15.0, -15.0, -10.0, -inf]Step 1156 2 visits [500.0, 1.0, 20.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 810 q_vals: [-inf, -15.0, -7.5, -15.0, -15.0, -10.0, -inf]Step 1157 2 visits [500.0, 1.0, 21.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 810 q_vals: [-inf, -15.0, -7.143, -15.0, -15.0, -10.0, -inf]Step 1158 2 visits [500.0, 1.0, 22.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 811 q_vals: [-inf, -15.0, -6.818, -15.0, -15.0, -10.0, -inf]Step 1159 2 visits [500.0, 1.0, 23.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 811 q_vals: [-inf, -15.0, -6.522, -15.0, -15.0, -10.0, -inf]Step 1160 2 visits [500.0, 1.0, 24.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 811 q_vals: [-inf, -15.0, -6.25, -15.0, -15.0, -10.0, -inf]Step 1161 2 visits [500.0, 1.0, 25.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 811 q_vals: [-inf, -15.0, -6.6, -15.0, -15.0, -10.0, -inf]Step 1162 2 visits [500.0, 1.0, 26.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 811 q_vals: [-inf, -15.0, -6.346, -15.0, -15.0, -10.0, -inf]Step 1163 2 visits [500.0, 1.0, 27.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 814 q_vals: [-inf, -15.0, -6.667, -15.0, -15.0, -10.0, -inf]Step 1164 2 visits [500.0, 1.0, 28.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 814 q_vals: [-inf, -15.0, -6.429, -15.0, -15.0, -10.0, -inf]Step 1165 2 visits [500.0, 1.0, 29.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 814 q_vals: [-inf, -15.0, -6.207, -15.0, -15.0, -10.0, -inf]Step 1166 2 visits [500.0, 1.0, 30.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 814 q_vals: [-inf, -15.0, -6.5, -15.0, -15.0, -10.0, -inf]Step 1167 2 visits [500.0, 1.0, 31.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 814 q_vals: [-inf, -15.0, -6.29, -15.0, -15.0, -10.0, -inf]Step 1168 2 visits [500.0, 1.0, 32.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 815 q_vals: [-inf, -15.0, -6.094, -15.0, -15.0, -10.0, -inf]Step 1169 2 visits [500.0, 1.0, 33.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 815 q_vals: [-inf, -15.0, -6.364, -15.0, -15.0, -10.0, -inf]Step 1170 2 visits [500.0, 1.0, 34.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 815 q_vals: [-inf, -15.0, -6.176, -15.0, -15.0, -10.0, -inf]Step 1171 2 visits [500.0, 1.0, 35.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 815 q_vals: [-inf, -15.0, -6.429, -15.0, -15.0, -10.0, -inf]Step 1172 2 visits [500.0, 1.0, 36.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 816 q_vals: [-inf, -15.0, -6.25, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 820, "number_of_timesteps": 78018, "per_episode_reward": -412.42, "episode_reward_trend_value": 1.0754512785568737, "biggest_recent_change": 86.8060113624689},
Step 1173 2 visits [500.0, 1.0, 37.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 820 q_vals: [-inf, -15.0, -6.081, -15.0, -15.0, -10.0, -inf]Step 1174 2 visits [500.0, 1.0, 38.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 820 q_vals: [-inf, -15.0, -5.921, -15.0, -15.0, -10.0, -inf]Step 1175 2 visits [500.0, 1.0, 39.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 820 q_vals: [-inf, -15.0, -6.154, -15.0, -15.0, -10.0, -inf]Step 1176 2 visits [500.0, 1.0, 40.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 822 q_vals: [-inf, -15.0, -6.0, -15.0, -15.0, -10.0, -inf]Step 1177 2 visits [500.0, 1.0, 41.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 822 q_vals: [-inf, -15.0, -5.854, -15.0, -15.0, -10.0, -inf]Step 1178 2 visits [500.0, 1.0, 42.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 822 q_vals: [-inf, -15.0, -6.071, -15.0, -15.0, -10.0, -inf]Step 1179 2 visits [500.0, 1.0, 43.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 822 q_vals: [-inf, -15.0, -6.279, -15.0, -15.0, -10.0, -inf]Step 1180 2 visits [500.0, 1.0, 44.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 822 q_vals: [-inf, -15.0, -6.136, -15.0, -15.0, -10.0, -inf]Step 1181 2 visits [500.0, 1.0, 45.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 822 q_vals: [-inf, -15.0, -6.333, -15.0, -15.0, -10.0, -inf]Step 1182 2 visits [500.0, 1.0, 46.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 823 q_vals: [-inf, -15.0, -6.196, -15.0, -15.0, -10.0, -inf]Step 1183 2 visits [500.0, 1.0, 47.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 824 q_vals: [-inf, -15.0, -6.064, -15.0, -15.0, -10.0, -inf]Step 1184 2 visits [500.0, 1.0, 48.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 827 q_vals: [-inf, -15.0, -5.937, -15.0, -15.0, -10.0, -inf]Step 1185 2 visits [500.0, 1.0, 49.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 828 q_vals: [-inf, -15.0, -6.122, -15.0, -15.0, -10.0, -inf]Step 1186 2 visits [500.0, 1.0, 50.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 829 q_vals: [-inf, -15.0, -6.3, -15.0, -15.0, -10.0, -inf]Step 1187 2 visits [500.0, 1.0, 51.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 829 q_vals: [-inf, -15.0, -6.471, -15.0, -15.0, -10.0, -inf]Step 1188 2 visits [500.0, 1.0, 52.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 829 q_vals: [-inf, -15.0, -6.346, -15.0, -15.0, -10.0, -inf]Step 1189 2 visits [500.0, 1.0, 53.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 829 q_vals: [-inf, -15.0, -6.226, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 830, "number_of_timesteps": 79216, "per_episode_reward": -411.86, "episode_reward_trend_value": 1.0589627496571754, "biggest_recent_change": 86.8060113624689},
Step 1190 2 visits [500.0, 1.0, 54.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 830 q_vals: [-inf, -15.0, -6.389, -15.0, -15.0, -10.0, -inf]Step 1191 2 visits [500.0, 1.0, 55.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 830 q_vals: [-inf, -15.0, -6.273, -15.0, -15.0, -10.0, -inf]Step 1192 2 visits [500.0, 1.0, 56.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 831 q_vals: [-inf, -15.0, -6.429, -15.0, -15.0, -10.0, -inf]Step 1193 2 visits [500.0, 1.0, 57.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 834 q_vals: [-inf, -15.0, -6.579, -15.0, -15.0, -10.0, -inf]Step 1194 2 visits [500.0, 1.0, 58.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 834 q_vals: [-inf, -15.0, -6.466, -15.0, -15.0, -10.0, -inf]Step 1195 2 visits [500.0, 1.0, 59.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 835 q_vals: [-inf, -15.0, -6.356, -15.0, -15.0, -10.0, -inf]Step 1196 2 visits [500.0, 1.0, 60.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 835 q_vals: [-inf, -15.0, -6.5, -15.0, -15.0, -10.0, -inf]Step 1197 2 visits [500.0, 1.0, 61.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 836 q_vals: [-inf, -15.0, -6.639, -15.0, -15.0, -10.0, -inf]Step 1198 2 visits [500.0, 1.0, 62.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 836 q_vals: [-inf, -15.0, -6.532, -15.0, -15.0, -10.0, -inf]Step 1199 2 visits [500.0, 1.0, 63.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 836 q_vals: [-inf, -15.0, -6.429, -15.0, -15.0, -10.0, -inf]Step 1200 2 visits [500.0, 1.0, 64.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 837 q_vals: [-inf, -15.0, -6.563, -15.0, -15.0, -10.0, -inf]Step 1201 2 visits [500.0, 1.0, 65.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 839 q_vals: [-inf, -15.0, -6.692, -15.0, -15.0, -10.0, -inf]Step 1202 2 visits [500.0, 1.0, 66.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 839 q_vals: [-inf, -15.0, -6.591, -15.0, -15.0, -10.0, -inf]Step 1203 2 visits [500.0, 1.0, 67.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 839 q_vals: [-inf, -15.0, -6.716, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 840, "number_of_timesteps": 80105, "per_episode_reward": -411.52, "episode_reward_trend_value": 1.0377251607455744, "biggest_recent_change": 86.8060113624689},
Step 1204 2 visits [500.0, 1.0, 68.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 840 q_vals: [-inf, -15.0, -6.618, -15.0, -15.0, -10.0, -inf]Step 1205 2 visits [500.0, 1.0, 69.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 842 q_vals: [-inf, -15.0, -6.739, -15.0, -15.0, -10.0, -inf]Step 1206 2 visits [500.0, 1.0, 70.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 842 q_vals: [-inf, -15.0, -6.643, -15.0, -15.0, -10.0, -inf]Step 1207 2 visits [500.0, 1.0, 71.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 843 q_vals: [-inf, -15.0, -6.761, -15.0, -15.0, -10.0, -inf]Step 1208 2 visits [500.0, 1.0, 72.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 843 q_vals: [-inf, -15.0, -6.875, -15.0, -15.0, -10.0, -inf]Step 1209 2 visits [500.0, 1.0, 73.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 843 q_vals: [-inf, -15.0, -6.781, -15.0, -15.0, -10.0, -inf]Step 1210 2 visits [500.0, 1.0, 74.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 843 q_vals: [-inf, -15.0, -6.892, -15.0, -15.0, -10.0, -inf]Step 1211 2 visits [500.0, 1.0, 75.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 845 q_vals: [-inf, -15.0, -7.0, -15.0, -15.0, -10.0, -inf]Step 1212 2 visits [500.0, 1.0, 76.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 846 q_vals: [-inf, -15.0, -6.908, -15.0, -15.0, -10.0, -inf]Step 1213 2 visits [500.0, 1.0, 77.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 847 q_vals: [-inf, -15.0, -6.818, -15.0, -15.0, -10.0, -inf]Step 1214 2 visits [500.0, 1.0, 78.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 847 q_vals: [-inf, -15.0, -6.923, -15.0, -15.0, -10.0, -inf]Step 1215 2 visits [500.0, 1.0, 79.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 848 q_vals: [-inf, -15.0, -7.025, -15.0, -15.0, -10.0, -inf]Step 1216 2 visits [500.0, 1.0, 80.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 848 q_vals: [-inf, -15.0, -7.125, -15.0, -15.0, -10.0, -inf]Step 1217 2 visits [500.0, 1.0, 81.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 848 q_vals: [-inf, -15.0, -7.037, -15.0, -15.0, -10.0, -inf]Step 1218 2 visits [500.0, 1.0, 82.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 849 q_vals: [-inf, -15.0, -6.951, -15.0, -15.0, -10.0, -inf]Step 1219 2 visits [500.0, 1.0, 83.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 849 q_vals: [-inf, -15.0, -6.867, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 852, "number_of_timesteps": 81338, "per_episode_reward": -410.7, "episode_reward_trend_value": 1.028113420580746, "biggest_recent_change": 86.8060113624689},
Step 1220 2 visits [500.0, 1.0, 84.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 852 q_vals: [-inf, -15.0, -6.786, -15.0, -15.0, -10.0, -inf]Step 1221 2 visits [500.0, 1.0, 85.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 854 q_vals: [-inf, -15.0, -6.706, -15.0, -15.0, -10.0, -inf]Step 1222 2 visits [500.0, 1.0, 86.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 855 q_vals: [-inf, -15.0, -6.628, -15.0, -15.0, -10.0, -inf]Step 1223 2 visits [500.0, 1.0, 87.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 855 q_vals: [-inf, -15.0, -6.724, -15.0, -15.0, -10.0, -inf]Step 1224 2 visits [500.0, 1.0, 88.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 855 q_vals: [-inf, -15.0, -6.648, -15.0, -15.0, -10.0, -inf]Step 1225 2 visits [500.0, 1.0, 89.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 855 q_vals: [-inf, -15.0, -6.742, -15.0, -15.0, -10.0, -inf]Step 1226 2 visits [500.0, 1.0, 90.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 856 q_vals: [-inf, -15.0, -6.667, -15.0, -15.0, -10.0, -inf]Step 1227 2 visits [500.0, 1.0, 91.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 857 q_vals: [-inf, -15.0, -6.593, -15.0, -15.0, -10.0, -inf]Step 1228 2 visits [500.0, 1.0, 92.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 857 q_vals: [-inf, -15.0, -6.522, -15.0, -15.0, -10.0, -inf]Step 1229 2 visits [500.0, 1.0, 93.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 857 q_vals: [-inf, -15.0, -6.452, -15.0, -15.0, -10.0, -inf]Step 1230 2 visits [500.0, 1.0, 94.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 858 q_vals: [-inf, -15.0, -6.543, -15.0, -15.0, -10.0, -inf]Step 1231 2 visits [500.0, 1.0, 95.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 860 q_vals: [-inf, -15.0, -6.632, -15.0, -15.0, -10.0, -inf]Step 1232 2 visits [500.0, 1.0, 96.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 860 q_vals: [-inf, -15.0, -6.719, -15.0, -15.0, -10.0, -inf]Step 1233 2 visits [500.0, 1.0, 97.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 861 q_vals: [-inf, -15.0, -6.804, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 863, "number_of_timesteps": 82304, "per_episode_reward": -410.64, "episode_reward_trend_value": 1.0113050408068225, "biggest_recent_change": 86.8060113624689},
Step 1234 2 visits [500.0, 1.0, 98.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 863 q_vals: [-inf, -15.0, -6.735, -15.0, -15.0, -10.0, -inf]Step 1235 2 visits [500.0, 1.0, 99.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 863 q_vals: [-inf, -15.0, -6.818, -15.0, -15.0, -10.0, -inf]Step 1236 2 visits [500.0, 1.0, 100.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 864 q_vals: [-inf, -15.0, -6.9, -15.0, -15.0, -10.0, -inf]Step 1237 2 visits [500.0, 1.0, 101.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 864 q_vals: [-inf, -15.0, -6.98, -15.0, -15.0, -10.0, -inf]Step 1238 2 visits [500.0, 1.0, 102.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 864 q_vals: [-inf, -15.0, -7.059, -15.0, -15.0, -10.0, -inf]Step 1239 2 visits [500.0, 1.0, 103.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 864 q_vals: [-inf, -15.0, -7.136, -15.0, -15.0, -10.0, -inf]Step 1240 2 visits [500.0, 1.0, 104.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 864 q_vals: [-inf, -15.0, -7.212, -15.0, -15.0, -10.0, -inf]Step 1241 2 visits [500.0, 1.0, 105.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 866 q_vals: [-inf, -15.0, -7.286, -15.0, -15.0, -10.0, -inf]Step 1242 2 visits [500.0, 1.0, 106.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 867 q_vals: [-inf, -15.0, -7.358, -15.0, -15.0, -10.0, -inf]Step 1243 2 visits [500.0, 1.0, 107.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 867 q_vals: [-inf, -15.0, -7.43, -15.0, -15.0, -10.0, -inf]Step 1244 2 visits [500.0, 1.0, 108.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 868 q_vals: [-inf, -15.0, -7.361, -15.0, -15.0, -10.0, -inf]Step 1245 2 visits [500.0, 1.0, 109.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 868 q_vals: [-inf, -15.0, -7.431, -15.0, -15.0, -10.0, -inf]Step 1246 2 visits [500.0, 1.0, 110.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 868 q_vals: [-inf, -15.0, -7.364, -15.0, -15.0, -10.0, -inf]Step 1247 2 visits [500.0, 1.0, 111.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 869 q_vals: [-inf, -15.0, -7.432, -15.0, -15.0, -10.0, -inf]Step 1248 2 visits [500.0, 1.0, 112.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 870 q_vals: [-inf, -15.0, -7.366, -15.0, -15.0, -10.0, -inf]Step 1249 2 visits [500.0, 1.0, 113.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 871 q_vals: [-inf, -15.0, -7.434, -15.0, -15.0, -10.0, -inf]Step 1250 2 visits [500.0, 1.0, 114.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 872 q_vals: [-inf, -15.0, -7.5, -15.0, -15.0, -10.0, -inf]Step 1251 2 visits [500.0, 1.0, 115.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 872 q_vals: [-inf, -15.0, -7.565, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 873, "number_of_timesteps": 83383, "per_episode_reward": -409.3, "episode_reward_trend_value": 1.0207695493000586, "biggest_recent_change": 86.8060113624689},
Step 1252 2 visits [500.0, 1.0, 116.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 873 q_vals: [-inf, -15.0, -7.629, -15.0, -15.0, -10.0, -inf]Step 1253 2 visits [500.0, 1.0, 117.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 873 q_vals: [-inf, -15.0, -7.692, -15.0, -15.0, -10.0, -inf]Step 1254 2 visits [500.0, 1.0, 118.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 874 q_vals: [-inf, -15.0, -7.754, -15.0, -15.0, -10.0, -inf]Step 1255 2 visits [500.0, 1.0, 119.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 875 q_vals: [-inf, -15.0, -7.689, -15.0, -15.0, -10.0, -inf]Step 1256 2 visits [500.0, 1.0, 120.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 876 q_vals: [-inf, -15.0, -7.625, -15.0, -15.0, -10.0, -inf]Step 1257 2 visits [500.0, 1.0, 121.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 876 q_vals: [-inf, -15.0, -7.686, -15.0, -15.0, -10.0, -inf]Step 1258 2 visits [500.0, 1.0, 122.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 877 q_vals: [-inf, -15.0, -7.623, -15.0, -15.0, -10.0, -inf]Step 1259 2 visits [500.0, 1.0, 123.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 877 q_vals: [-inf, -15.0, -7.683, -15.0, -15.0, -10.0, -inf]Step 1260 2 visits [500.0, 1.0, 124.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 877 q_vals: [-inf, -15.0, -7.742, -15.0, -15.0, -10.0, -inf]Step 1261 2 visits [500.0, 1.0, 125.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 877 q_vals: [-inf, -15.0, -7.68, -15.0, -15.0, -10.0, -inf]Step 1262 2 visits [500.0, 1.0, 126.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 878 q_vals: [-inf, -15.0, -7.738, -15.0, -15.0, -10.0, -inf]Step 1263 2 visits [500.0, 1.0, 127.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 879 q_vals: [-inf, -15.0, -7.795, -15.0, -15.0, -10.0, -inf]Step 1264 2 visits [500.0, 1.0, 128.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 879 q_vals: [-inf, -15.0, -7.852, -15.0, -15.0, -10.0, -inf]Step 1265 2 visits [500.0, 1.0, 129.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 881 q_vals: [-inf, -15.0, -7.907, -15.0, -15.0, -10.0, -inf]Step 1266 2 visits [500.0, 1.0, 130.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 882 q_vals: [-inf, -15.0, -7.846, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 883, "number_of_timesteps": 84486, "per_episode_reward": -405.76, "episode_reward_trend_value": 1.0483754777763195, "biggest_recent_change": 86.8060113624689},
Step 1267 2 visits [500.0, 1.0, 131.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 883 q_vals: [-inf, -15.0, -7.901, -15.0, -15.0, -10.0, -inf]Step 1268 2 visits [500.0, 1.0, 132.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 883 q_vals: [-inf, -15.0, -7.955, -15.0, -15.0, -10.0, -inf]Step 1269 2 visits [500.0, 1.0, 133.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 883 q_vals: [-inf, -15.0, -7.895, -15.0, -15.0, -10.0, -inf]Step 1270 2 visits [500.0, 1.0, 134.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 884 q_vals: [-inf, -15.0, -7.948, -15.0, -15.0, -10.0, -inf]Step 1271 2 visits [500.0, 1.0, 135.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 885 q_vals: [-inf, -15.0, -7.889, -15.0, -15.0, -10.0, -inf]Step 1272 2 visits [500.0, 1.0, 136.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 885 q_vals: [-inf, -15.0, -7.831, -15.0, -15.0, -10.0, -inf]Step 1273 2 visits [500.0, 1.0, 137.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 886 q_vals: [-inf, -15.0, -7.883, -15.0, -15.0, -10.0, -inf]Step 1274 2 visits [500.0, 1.0, 138.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 887 q_vals: [-inf, -15.0, -7.826, -15.0, -15.0, -10.0, -inf]Step 1275 2 visits [500.0, 1.0, 139.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 887 q_vals: [-inf, -15.0, -7.878, -15.0, -15.0, -10.0, -inf]Step 1276 2 visits [500.0, 1.0, 140.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 887 q_vals: [-inf, -15.0, -7.929, -15.0, -15.0, -10.0, -inf]Step 1277 2 visits [500.0, 1.0, 141.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 887 q_vals: [-inf, -15.0, -7.94, -15.0, -15.0, -10.0, -inf]Step 1278 2 visits [500.0, 1.0, 142.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 889 q_vals: [-inf, -15.0, -7.99, -15.0, -15.0, -10.0, -inf]Step 1279 2 visits [500.0, 1.0, 143.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 889 q_vals: [-inf, -15.0, -8.039, -15.0, -15.0, -10.0, -inf]Step 1280 2 visits [500.0, 1.0, 144.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 889 q_vals: [-inf, -15.0, -8.087, -15.0, -15.0, -10.0, -inf]Step 1281 2 visits [500.0, 1.0, 145.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 890 q_vals: [-inf, -15.0, -8.075, -15.0, -15.0, -10.0, -inf]Step 1282 2 visits [500.0, 1.0, 146.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 891 q_vals: [-inf, -15.0, -8.122, -15.0, -15.0, -10.0, -inf]Step 1283 2 visits [500.0, 1.0, 147.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 891 q_vals: [-inf, -15.0, -8.169, -15.0, -15.0, -10.0, -inf]Step 1284 2 visits [500.0, 1.0, 148.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 891 q_vals: [-inf, -15.0, -8.114, -15.0, -15.0, -10.0, -inf]Step 1285 2 visits [500.0, 1.0, 149.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 891 q_vals: [-inf, -15.0, -8.102, -15.0, -15.0, -10.0, -inf]Step 1286 2 visits [500.0, 1.0, 150.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 892 q_vals: [-inf, -15.0, -8.048, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 893, "number_of_timesteps": 85626, "per_episode_reward": -403.04, "episode_reward_trend_value": 0.11410859108393398, "biggest_recent_change": 3.5385186991002797},
Step 1287 2 visits [500.0, 1.0, 151.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 893 q_vals: [-inf, -15.0, -7.995, -15.0, -15.0, -10.0, -inf]Step 1288 2 visits [500.0, 1.0, 152.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 893 q_vals: [-inf, -15.0, -8.041, -15.0, -15.0, -10.0, -inf]Step 1289 2 visits [500.0, 1.0, 153.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 894 q_vals: [-inf, -15.0, -8.086, -15.0, -15.0, -10.0, -inf]Step 1290 2 visits [500.0, 1.0, 154.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 896 q_vals: [-inf, -15.0, -8.034, -15.0, -15.0, -10.0, -inf]Step 1291 2 visits [500.0, 1.0, 155.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 896 q_vals: [-inf, -15.0, -7.982, -15.0, -15.0, -10.0, -inf]Step 1292 2 visits [500.0, 1.0, 156.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 897 q_vals: [-inf, -15.0, -7.931, -15.0, -15.0, -10.0, -inf]Step 1293 2 visits [500.0, 1.0, 157.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 897 q_vals: [-inf, -15.0, -7.88, -15.0, -15.0, -10.0, -inf]Step 1294 2 visits [500.0, 1.0, 158.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 897 q_vals: [-inf, -15.0, -7.83, -15.0, -15.0, -10.0, -inf]Step 1295 2 visits [500.0, 1.0, 159.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 898 q_vals: [-inf, -15.0, -7.875, -15.0, -15.0, -10.0, -inf]Step 1296 2 visits [500.0, 1.0, 160.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 898 q_vals: [-inf, -15.0, -7.92, -15.0, -15.0, -10.0, -inf]Step 1297 2 visits [500.0, 1.0, 161.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 898 q_vals: [-inf, -15.0, -7.964, -15.0, -15.0, -10.0, -inf]Step 1298 2 visits [500.0, 1.0, 162.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 899 q_vals: [-inf, -15.0, -8.007, -15.0, -15.0, -10.0, -inf]Step 1299 2 visits [500.0, 1.0, 163.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 899 q_vals: [-inf, -15.0, -7.958, -15.0, -15.0, -10.0, -inf]Step 1300 2 visits [500.0, 1.0, 164.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 901 q_vals: [-inf, -15.0, -7.91, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 903, "number_of_timesteps": 86795, "per_episode_reward": -400.95, "episode_reward_trend_value": 0.13060398073591525, "biggest_recent_change": 3.5385186991002797},
Step 1301 2 visits [500.0, 1.0, 165.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 903 q_vals: [-inf, -15.0, -7.862, -15.0, -15.0, -10.0, -inf]Step 1302 2 visits [500.0, 1.0, 166.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 903 q_vals: [-inf, -15.0, -7.905, -15.0, -15.0, -10.0, -inf]Step 1303 2 visits [500.0, 1.0, 167.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 903 q_vals: [-inf, -15.0, -7.947, -15.0, -15.0, -10.0, -inf]Step 1304 2 visits [500.0, 1.0, 168.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 904 q_vals: [-inf, -15.0, -7.989, -15.0, -15.0, -10.0, -inf]Step 1305 2 visits [500.0, 1.0, 169.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 904 q_vals: [-inf, -15.0, -8.031, -15.0, -15.0, -10.0, -inf]Step 1306 2 visits [500.0, 1.0, 170.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 904 q_vals: [-inf, -15.0, -8.072, -15.0, -15.0, -10.0, -inf]Step 1307 2 visits [500.0, 1.0, 171.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 905 q_vals: [-inf, -15.0, -8.112, -15.0, -15.0, -10.0, -inf]Step 1308 2 visits [500.0, 1.0, 172.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 907 q_vals: [-inf, -15.0, -8.152, -15.0, -15.0, -10.0, -inf]Step 1309 2 visits [500.0, 1.0, 173.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 907 q_vals: [-inf, -15.0, -8.192, -15.0, -15.0, -10.0, -inf]Step 1310 2 visits [500.0, 1.0, 174.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 908 q_vals: [-inf, -15.0, -8.145, -15.0, -15.0, -10.0, -inf]Step 1311 2 visits [500.0, 1.0, 175.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 910 q_vals: [-inf, -15.0, -8.098, -15.0, -15.0, -10.0, -inf]Step 1312 2 visits [500.0, 1.0, 176.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 910 q_vals: [-inf, -15.0, -8.137, -15.0, -15.0, -10.0, -inf]Step 1313 2 visits [500.0, 1.0, 177.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 910 q_vals: [-inf, -15.0, -8.176, -15.0, -15.0, -10.0, -inf]Step 1314 2 visits [500.0, 1.0, 178.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 910 q_vals: [-inf, -15.0, -8.214, -15.0, -15.0, -10.0, -inf]Step 1315 2 visits [500.0, 1.0, 179.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 910 q_vals: [-inf, -15.0, -8.252, -15.0, -15.0, -10.0, -inf]Step 1316 2 visits [500.0, 1.0, 180.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 911 q_vals: [-inf, -15.0, -8.207, -15.0, -15.0, -10.0, -inf]Step 1317 2 visits [500.0, 1.0, 181.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 911 q_vals: [-inf, -15.0, -8.244, -15.0, -15.0, -10.0, -inf]Step 1318 2 visits [500.0, 1.0, 182.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 911 q_vals: [-inf, -15.0, -8.281, -15.0, -15.0, -10.0, -inf]Step 1319 2 visits [500.0, 1.0, 183.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 911 q_vals: [-inf, -15.0, -8.318, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 914, "number_of_timesteps": 87917, "per_episode_reward": -399.1, "episode_reward_trend_value": 0.1479795711045679, "biggest_recent_change": 3.5385186991002797},
Step 1320 2 visits [500.0, 1.0, 184.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 914 q_vals: [-inf, -15.0, -8.273, -15.0, -15.0, -10.0, -inf]Step 1321 2 visits [500.0, 1.0, 185.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 914 q_vals: [-inf, -15.0, -8.228, -15.0, -15.0, -10.0, -inf]Step 1322 2 visits [500.0, 1.0, 186.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 914 q_vals: [-inf, -15.0, -8.184, -15.0, -15.0, -10.0, -inf]Step 1323 2 visits [500.0, 1.0, 187.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 915 q_vals: [-inf, -15.0, -8.14, -15.0, -15.0, -10.0, -inf]Step 1324 2 visits [500.0, 1.0, 188.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 915 q_vals: [-inf, -15.0, -8.097, -15.0, -15.0, -10.0, -inf]Step 1325 2 visits [500.0, 1.0, 189.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 915 q_vals: [-inf, -15.0, -8.133, -15.0, -15.0, -10.0, -inf]Step 1326 2 visits [500.0, 1.0, 190.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 915 q_vals: [-inf, -15.0, -8.169, -15.0, -15.0, -10.0, -inf]Step 1327 2 visits [500.0, 1.0, 191.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 916 q_vals: [-inf, -15.0, -8.127, -15.0, -15.0, -10.0, -inf]Step 1328 2 visits [500.0, 1.0, 192.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 918 q_vals: [-inf, -15.0, -8.162, -15.0, -15.0, -10.0, -inf]Step 1329 2 visits [500.0, 1.0, 193.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 918 q_vals: [-inf, -15.0, -8.12, -15.0, -15.0, -10.0, -inf]Step 1330 2 visits [500.0, 1.0, 194.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 919 q_vals: [-inf, -15.0, -8.078, -15.0, -15.0, -10.0, -inf]Step 1331 2 visits [500.0, 1.0, 195.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 919 q_vals: [-inf, -15.0, -8.114, -15.0, -15.0, -10.0, -inf]Step 1332 2 visits [500.0, 1.0, 196.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 920 q_vals: [-inf, -15.0, -8.072, -15.0, -15.0, -10.0, -inf]Step 1333 2 visits [500.0, 1.0, 197.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 920 q_vals: [-inf, -15.0, -8.108, -15.0, -15.0, -10.0, -inf]Step 1334 2 visits [500.0, 1.0, 198.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 921 q_vals: [-inf, -15.0, -8.067, -15.0, -15.0, -10.0, -inf]Step 1335 2 visits [500.0, 1.0, 199.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 921 q_vals: [-inf, -15.0, -8.101, -15.0, -15.0, -10.0, -inf]Step 1336 2 visits [500.0, 1.0, 200.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 921 q_vals: [-inf, -15.0, -8.136, -15.0, -15.0, -10.0, -inf]Step 1337 2 visits [500.0, 1.0, 201.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 922 q_vals: [-inf, -15.0, -8.095, -15.0, -15.0, -10.0, -inf]Step 1338 2 visits [500.0, 1.0, 202.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 922 q_vals: [-inf, -15.0, -8.13, -15.0, -15.0, -10.0, -inf]Step 1339 2 visits [500.0, 1.0, 203.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 923 q_vals: [-inf, -15.0, -8.163, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 924, "number_of_timesteps": 89156, "per_episode_reward": -398.29, "episode_reward_trend_value": 0.15073598838188787, "biggest_recent_change": 3.5385186991002797},
Step 1340 2 visits [500.0, 1.0, 204.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 924 q_vals: [-inf, -15.0, -8.123, -15.0, -15.0, -10.0, -inf]Step 1341 2 visits [500.0, 1.0, 205.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 925 q_vals: [-inf, -15.0, -8.087, -15.0, -15.0, -10.0, -inf]Step 1342 2 visits [500.0, 1.0, 206.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 925 q_vals: [-inf, -15.0, -8.048, -15.0, -15.0, -10.0, -inf]Step 1343 2 visits [500.0, 1.0, 207.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 926 q_vals: [-inf, -15.0, -8.009, -15.0, -15.0, -10.0, -inf]Step 1344 2 visits [500.0, 1.0, 208.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 928 q_vals: [-inf, -15.0, -8.018, -15.0, -15.0, -10.0, -inf]Step 1345 2 visits [500.0, 1.0, 209.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 928 q_vals: [-inf, -15.0, -7.98, -15.0, -15.0, -10.0, -inf]Step 1346 2 visits [500.0, 1.0, 210.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 928 q_vals: [-inf, -15.0, -8.013, -15.0, -15.0, -10.0, -inf]Step 1347 2 visits [500.0, 1.0, 211.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 929 q_vals: [-inf, -15.0, -8.046, -15.0, -15.0, -10.0, -inf]Step 1348 2 visits [500.0, 1.0, 212.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 929 q_vals: [-inf, -15.0, -8.008, -15.0, -15.0, -10.0, -inf]Step 1349 2 visits [500.0, 1.0, 213.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 931 q_vals: [-inf, -15.0, -8.041, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 934, "number_of_timesteps": 90186, "per_episode_reward": -397.75, "episode_reward_trend_value": 0.15299831876472153, "biggest_recent_change": 3.5385186991002797},
Step 1350 2 visits [500.0, 1.0, 214.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 934 q_vals: [-inf, -15.0, -8.074, -15.0, -15.0, -10.0, -inf]Step 1351 2 visits [500.0, 1.0, 215.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 935 q_vals: [-inf, -15.0, -8.036, -15.0, -15.0, -10.0, -inf]Step 1352 2 visits [500.0, 1.0, 216.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 935 q_vals: [-inf, -15.0, -8.068, -15.0, -15.0, -10.0, -inf]Step 1353 2 visits [500.0, 1.0, 217.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 935 q_vals: [-inf, -15.0, -8.1, -15.0, -15.0, -10.0, -inf]Step 1354 2 visits [500.0, 1.0, 218.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 935 q_vals: [-inf, -15.0, -8.132, -15.0, -15.0, -10.0, -inf]Step 1355 2 visits [500.0, 1.0, 219.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 935 q_vals: [-inf, -15.0, -8.163, -15.0, -15.0, -10.0, -inf]Step 1356 2 visits [500.0, 1.0, 220.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 936 q_vals: [-inf, -15.0, -8.194, -15.0, -15.0, -10.0, -inf]Step 1357 2 visits [500.0, 1.0, 221.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 936 q_vals: [-inf, -15.0, -8.225, -15.0, -15.0, -10.0, -inf]Step 1358 2 visits [500.0, 1.0, 222.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 938 q_vals: [-inf, -15.0, -8.188, -15.0, -15.0, -10.0, -inf]Step 1359 2 visits [500.0, 1.0, 223.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 938 q_vals: [-inf, -15.0, -8.219, -15.0, -15.0, -10.0, -inf]Step 1360 2 visits [500.0, 1.0, 224.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 940 q_vals: [-inf, -15.0, -8.182, -15.0, -15.0, -10.0, -inf]Step 1361 2 visits [500.0, 1.0, 225.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 942 q_vals: [-inf, -15.0, -8.212, -15.0, -15.0, -10.0, -inf]Step 1362 2 visits [500.0, 1.0, 226.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 942 q_vals: [-inf, -15.0, -8.242, -15.0, -15.0, -10.0, -inf]Step 1363 2 visits [500.0, 1.0, 227.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 942 q_vals: [-inf, -15.0, -8.272, -15.0, -15.0, -10.0, -inf]Step 1364 2 visits [500.0, 1.0, 228.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 942 q_vals: [-inf, -15.0, -8.302, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 944, "number_of_timesteps": 91056, "per_episode_reward": -397.06, "episode_reward_trend_value": 0.15151729075901318, "biggest_recent_change": 3.5385186991002797},
Step 1365 2 visits [500.0, 1.0, 229.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 944 q_vals: [-inf, -15.0, -8.331, -15.0, -15.0, -10.0, -inf]Step 1366 2 visits [500.0, 1.0, 230.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 944 q_vals: [-inf, -15.0, -8.295, -15.0, -15.0, -10.0, -inf]Step 1367 2 visits [500.0, 1.0, 231.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 945 q_vals: [-inf, -15.0, -8.324, -15.0, -15.0, -10.0, -inf]Step 1368 2 visits [500.0, 1.0, 232.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 945 q_vals: [-inf, -15.0, -8.324, -15.0, -15.0, -10.0, -inf]Step 1369 2 visits [500.0, 1.0, 233.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 945 q_vals: [-inf, -15.0, -8.353, -15.0, -15.0, -10.0, -inf]Step 1370 2 visits [500.0, 1.0, 234.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 946 q_vals: [-inf, -15.0, -8.381, -15.0, -15.0, -10.0, -inf]Step 1371 2 visits [500.0, 1.0, 235.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 947 q_vals: [-inf, -15.0, -8.41, -15.0, -15.0, -10.0, -inf]Step 1372 2 visits [500.0, 1.0, 236.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 947 q_vals: [-inf, -15.0, -8.438, -15.0, -15.0, -10.0, -inf]Step 1373 2 visits [500.0, 1.0, 237.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 948 q_vals: [-inf, -15.0, -8.465, -15.0, -15.0, -10.0, -inf]Step 1374 2 visits [500.0, 1.0, 238.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 949 q_vals: [-inf, -15.0, -8.493, -15.0, -15.0, -10.0, -inf]Step 1375 2 visits [500.0, 1.0, 239.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 949 q_vals: [-inf, -15.0, -8.457, -15.0, -15.0, -10.0, -inf]Step 1376 2 visits [500.0, 1.0, 240.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 951 q_vals: [-inf, -15.0, -8.484, -15.0, -15.0, -10.0, -inf]Step 1377 2 visits [500.0, 1.0, 241.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 951 q_vals: [-inf, -15.0, -8.449, -15.0, -15.0, -10.0, -inf]Step 1378 2 visits [500.0, 1.0, 242.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 951 q_vals: [-inf, -15.0, -8.476, -15.0, -15.0, -10.0, -inf]Step 1379 2 visits [500.0, 1.0, 243.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 951 q_vals: [-inf, -15.0, -8.503, -15.0, -15.0, -10.0, -inf]Step 1380 2 visits [500.0, 1.0, 244.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 953 q_vals: [-inf, -15.0, -8.468, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 954, "number_of_timesteps": 92108, "per_episode_reward": -395.85, "episode_reward_trend_value": 0.1643294071881573, "biggest_recent_change": 3.5385186991002797},
Step 1381 2 visits [500.0, 1.0, 245.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 954 q_vals: [-inf, -15.0, -8.495, -15.0, -15.0, -10.0, -inf]Step 1382 2 visits [500.0, 1.0, 246.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 954 q_vals: [-inf, -15.0, -8.521, -15.0, -15.0, -10.0, -inf]Step 1383 2 visits [500.0, 1.0, 247.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 955 q_vals: [-inf, -15.0, -8.531, -15.0, -15.0, -10.0, -inf]Step 1384 2 visits [500.0, 1.0, 248.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 955 q_vals: [-inf, -15.0, -8.496, -15.0, -15.0, -10.0, -inf]Step 1385 2 visits [500.0, 1.0, 249.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 956 q_vals: [-inf, -15.0, -8.522, -15.0, -15.0, -10.0, -inf]Step 1386 2 visits [500.0, 1.0, 250.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 957 q_vals: [-inf, -15.0, -8.548, -15.0, -15.0, -10.0, -inf]Step 1387 2 visits [500.0, 1.0, 251.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 960 q_vals: [-inf, -15.0, -8.574, -15.0, -15.0, -10.0, -inf]Step 1388 2 visits [500.0, 1.0, 252.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 961 q_vals: [-inf, -15.0, -8.54, -15.0, -15.0, -10.0, -inf]Step 1389 2 visits [500.0, 1.0, 253.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 961 q_vals: [-inf, -15.0, -8.506, -15.0, -15.0, -10.0, -inf]Step 1390 2 visits [500.0, 1.0, 254.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 962 q_vals: [-inf, -15.0, -8.473, -15.0, -15.0, -10.0, -inf]Step 1391 2 visits [500.0, 1.0, 255.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 963 q_vals: [-inf, -15.0, -8.498, -15.0, -15.0, -10.0, -inf]Step 1392 2 visits [500.0, 1.0, 256.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 963 q_vals: [-inf, -15.0, -8.465, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 964, "number_of_timesteps": 92895, "per_episode_reward": -394.71, "episode_reward_trend_value": 0.16214445861582538, "biggest_recent_change": 3.5385186991002797},
Step 1393 2 visits [500.0, 1.0, 257.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 964 q_vals: [-inf, -15.0, -8.432, -15.0, -15.0, -10.0, -inf]Step 1394 2 visits [500.0, 1.0, 258.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 966 q_vals: [-inf, -15.0, -8.458, -15.0, -15.0, -10.0, -inf]Step 1395 2 visits [500.0, 1.0, 259.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 967 q_vals: [-inf, -15.0, -8.483, -15.0, -15.0, -10.0, -inf]Step 1396 2 visits [500.0, 1.0, 260.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 968 q_vals: [-inf, -15.0, -8.45, -15.0, -15.0, -10.0, -inf]Step 1397 2 visits [500.0, 1.0, 261.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 968 q_vals: [-inf, -15.0, -8.475, -15.0, -15.0, -10.0, -inf]Step 1398 2 visits [500.0, 1.0, 262.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 969 q_vals: [-inf, -15.0, -8.5, -15.0, -15.0, -10.0, -inf]Step 1399 2 visits [500.0, 1.0, 263.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 970 q_vals: [-inf, -15.0, -8.468, -15.0, -15.0, -10.0, -inf]Step 1400 2 visits [500.0, 1.0, 264.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 970 q_vals: [-inf, -15.0, -8.493, -15.0, -15.0, -10.0, -inf]Step 1401 2 visits [500.0, 1.0, 265.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 970 q_vals: [-inf, -15.0, -8.517, -15.0, -15.0, -10.0, -inf]Step 1402 2 visits [500.0, 1.0, 266.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 970 q_vals: [-inf, -15.0, -8.542, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 974, "number_of_timesteps": 93668, "per_episode_reward": -393.98, "episode_reward_trend_value": 0.13093525792158403, "biggest_recent_change": 2.7219915601542084},
Step 1403 2 visits [500.0, 1.0, 267.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 974 q_vals: [-inf, -15.0, -8.566, -15.0, -15.0, -10.0, -inf]Step 1404 2 visits [500.0, 1.0, 268.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 975 q_vals: [-inf, -15.0, -8.534, -15.0, -15.0, -10.0, -inf]Step 1405 2 visits [500.0, 1.0, 269.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 975 q_vals: [-inf, -15.0, -8.502, -15.0, -15.0, -10.0, -inf]Step 1406 2 visits [500.0, 1.0, 270.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 975 q_vals: [-inf, -15.0, -8.471, -15.0, -15.0, -10.0, -inf]Step 1407 2 visits [500.0, 1.0, 271.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 975 q_vals: [-inf, -15.0, -8.495, -15.0, -15.0, -10.0, -inf]Step 1408 2 visits [500.0, 1.0, 272.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 975 q_vals: [-inf, -15.0, -8.464, -15.0, -15.0, -10.0, -inf]Step 1409 2 visits [500.0, 1.0, 273.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 976 q_vals: [-inf, -15.0, -8.487, -15.0, -15.0, -10.0, -inf]Step 1410 2 visits [500.0, 1.0, 274.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 977 q_vals: [-inf, -15.0, -8.456, -15.0, -15.0, -10.0, -inf]Step 1411 2 visits [500.0, 1.0, 275.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 977 q_vals: [-inf, -15.0, -8.48, -15.0, -15.0, -10.0, -inf]Step 1412 2 visits [500.0, 1.0, 276.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 978 q_vals: [-inf, -15.0, -8.45, -15.0, -15.0, -10.0, -inf]Step 1413 2 visits [500.0, 1.0, 277.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 979 q_vals: [-inf, -15.0, -8.473, -15.0, -15.0, -10.0, -inf]Step 1414 2 visits [500.0, 1.0, 278.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 981 q_vals: [-inf, -15.0, -8.443, -15.0, -15.0, -10.0, -inf]Step 1415 2 visits [500.0, 1.0, 279.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 981 q_vals: [-inf, -15.0, -8.412, -15.0, -15.0, -10.0, -inf]Step 1416 2 visits [500.0, 1.0, 280.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 981 q_vals: [-inf, -15.0, -8.382, -15.0, -15.0, -10.0, -inf]Step 1417 2 visits [500.0, 1.0, 281.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 981 q_vals: [-inf, -15.0, -8.406, -15.0, -15.0, -10.0, -inf]Step 1418 2 visits [500.0, 1.0, 282.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 982 q_vals: [-inf, -15.0, -8.376, -15.0, -15.0, -10.0, -inf]Step 1419 2 visits [500.0, 1.0, 283.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 983 q_vals: [-inf, -15.0, -8.4, -15.0, -15.0, -10.0, -inf]Step 1420 2 visits [500.0, 1.0, 284.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 983 q_vals: [-inf, -15.0, -8.37, -15.0, -15.0, -10.0, -inf]Step 1421 2 visits [500.0, 1.0, 285.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 983 q_vals: [-inf, -15.0, -8.393, -15.0, -15.0, -10.0, -inf]Step 1422 2 visits [500.0, 1.0, 286.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 983 q_vals: [-inf, -15.0, -8.416, -15.0, -15.0, -10.0, -inf]Step 1423 2 visits [500.0, 1.0, 287.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 983 q_vals: [-inf, -15.0, -8.439, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 985, "number_of_timesteps": 94673, "per_episode_reward": -392.99, "episode_reward_trend_value": 0.11163272204468058, "biggest_recent_change": 2.094425375145306},
Step 1424 2 visits [500.0, 1.0, 288.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 985 q_vals: [-inf, -15.0, -8.462, -15.0, -15.0, -10.0, -inf]Step 1425 2 visits [500.0, 1.0, 289.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 985 q_vals: [-inf, -15.0, -8.485, -15.0, -15.0, -10.0, -inf]Step 1426 2 visits [500.0, 1.0, 290.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 985 q_vals: [-inf, -15.0, -8.507, -15.0, -15.0, -10.0, -inf]Step 1427 2 visits [500.0, 1.0, 291.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 985 q_vals: [-inf, -15.0, -8.529, -15.0, -15.0, -10.0, -inf]Step 1428 2 visits [500.0, 1.0, 292.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 985 q_vals: [-inf, -15.0, -8.552, -15.0, -15.0, -10.0, -inf]Step 1429 2 visits [500.0, 1.0, 293.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 985 q_vals: [-inf, -15.0, -8.574, -15.0, -15.0, -10.0, -inf]Step 1430 2 visits [500.0, 1.0, 294.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 987 q_vals: [-inf, -15.0, -8.544, -15.0, -15.0, -10.0, -inf]Step 1431 2 visits [500.0, 1.0, 295.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 988 q_vals: [-inf, -15.0, -8.516, -15.0, -15.0, -10.0, -inf]Step 1432 2 visits [500.0, 1.0, 296.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 988 q_vals: [-inf, -15.0, -8.487, -15.0, -15.0, -10.0, -inf]Step 1433 2 visits [500.0, 1.0, 297.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 989 q_vals: [-inf, -15.0, -8.458, -15.0, -15.0, -10.0, -inf]Step 1434 2 visits [500.0, 1.0, 298.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 990 q_vals: [-inf, -15.0, -8.48, -15.0, -15.0, -10.0, -inf]Step 1435 2 visits [500.0, 1.0, 299.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 991 q_vals: [-inf, -15.0, -8.502, -15.0, -15.0, -10.0, -inf]Step 1436 2 visits [500.0, 1.0, 300.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 991 q_vals: [-inf, -15.0, -8.474, -15.0, -15.0, -10.0, -inf]Step 1437 2 visits [500.0, 1.0, 301.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 991 q_vals: [-inf, -15.0, -8.445, -15.0, -15.0, -10.0, -inf]Step 1438 2 visits [500.0, 1.0, 302.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 992 q_vals: [-inf, -15.0, -8.417, -15.0, -15.0, -10.0, -inf]Step 1439 2 visits [500.0, 1.0, 303.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 992 q_vals: [-inf, -15.0, -8.39, -15.0, -15.0, -10.0, -inf]Step 1440 2 visits [500.0, 1.0, 304.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 992 q_vals: [-inf, -15.0, -8.411, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 996, "number_of_timesteps": 96235, "per_episode_reward": -392.09, "episode_reward_trend_value": 0.09840837071207412, "biggest_recent_change": 1.843505284988737},
Step 1441 2 visits [500.0, 1.0, 305.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 996 q_vals: [-inf, -15.0, -8.433, -15.0, -15.0, -10.0, -inf]Step 1442 2 visits [500.0, 1.0, 306.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 996 q_vals: [-inf, -15.0, -8.405, -15.0, -15.0, -10.0, -inf]Step 1443 2 visits [500.0, 1.0, 307.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 997 q_vals: [-inf, -15.0, -8.378, -15.0, -15.0, -10.0, -inf]Step 1444 2 visits [500.0, 1.0, 308.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 997 q_vals: [-inf, -15.0, -8.351, -15.0, -15.0, -10.0, -inf]Step 1445 2 visits [500.0, 1.0, 309.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 997 q_vals: [-inf, -15.0, -8.324, -15.0, -15.0, -10.0, -inf]Step 1446 2 visits [500.0, 1.0, 310.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 998 q_vals: [-inf, -15.0, -8.297, -15.0, -15.0, -10.0, -inf]Step 1447 2 visits [500.0, 1.0, 311.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 998 q_vals: [-inf, -15.0, -8.27, -15.0, -15.0, -10.0, -inf]Step 1448 2 visits [500.0, 1.0, 312.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1000 q_vals: [-inf, -15.0, -8.244, -15.0, -15.0, -10.0, -inf]Step 1449 2 visits [500.0, 1.0, 313.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1002 q_vals: [-inf, -15.0, -8.217, -15.0, -15.0, -10.0, -inf]Step 1450 2 visits [500.0, 1.0, 314.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1002 q_vals: [-inf, -15.0, -8.239, -15.0, -15.0, -10.0, -inf]Step 1451 2 visits [500.0, 1.0, 315.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1003 q_vals: [-inf, -15.0, -8.213, -15.0, -15.0, -10.0, -inf]Step 1452 2 visits [500.0, 1.0, 316.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1003 q_vals: [-inf, -15.0, -8.234, -15.0, -15.0, -10.0, -inf]Step 1453 2 visits [500.0, 1.0, 317.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1004 q_vals: [-inf, -15.0, -8.256, -15.0, -15.0, -10.0, -inf]Step 1454 2 visits [500.0, 1.0, 318.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1004 q_vals: [-inf, -15.0, -8.23, -15.0, -15.0, -10.0, -inf]Step 1455 2 visits [500.0, 1.0, 319.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1005 q_vals: [-inf, -15.0, -8.251, -15.0, -15.0, -10.0, -inf]Step 1456 2 visits [500.0, 1.0, 320.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1005 q_vals: [-inf, -15.0, -8.272, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 1006, "number_of_timesteps": 97104, "per_episode_reward": -390.82, "episode_reward_trend_value": 0.09201619404383715, "biggest_recent_change": 1.2682093848474096},
Step 1457 2 visits [500.0, 1.0, 321.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1006 q_vals: [-inf, -15.0, -8.246, -15.0, -15.0, -10.0, -inf]Step 1458 2 visits [500.0, 1.0, 322.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1007 q_vals: [-inf, -15.0, -8.267, -15.0, -15.0, -10.0, -inf]Step 1459 2 visits [500.0, 1.0, 323.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1007 q_vals: [-inf, -15.0, -8.288, -15.0, -15.0, -10.0, -inf]Step 1460 2 visits [500.0, 1.0, 324.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1007 q_vals: [-inf, -15.0, -8.309, -15.0, -15.0, -10.0, -inf]Step 1461 2 visits [500.0, 1.0, 325.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1008 q_vals: [-inf, -15.0, -8.283, -15.0, -15.0, -10.0, -inf]Step 1462 2 visits [500.0, 1.0, 326.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1008 q_vals: [-inf, -15.0, -8.258, -15.0, -15.0, -10.0, -inf]Step 1463 2 visits [500.0, 1.0, 327.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1009 q_vals: [-inf, -15.0, -8.279, -15.0, -15.0, -10.0, -inf]Step 1464 2 visits [500.0, 1.0, 328.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1010 q_vals: [-inf, -15.0, -8.299, -15.0, -15.0, -10.0, -inf]Step 1465 2 visits [500.0, 1.0, 329.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1010 q_vals: [-inf, -15.0, -8.319, -15.0, -15.0, -10.0, -inf]Step 1466 2 visits [500.0, 1.0, 330.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1010 q_vals: [-inf, -15.0, -8.34, -15.0, -15.0, -10.0, -inf]Step 1467 2 visits [500.0, 1.0, 331.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1011 q_vals: [-inf, -15.0, -8.36, -15.0, -15.0, -10.0, -inf]Step 1468 2 visits [500.0, 1.0, 332.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1011 q_vals: [-inf, -15.0, -8.38, -15.0, -15.0, -10.0, -inf]Step 1469 2 visits [500.0, 1.0, 333.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1013 q_vals: [-inf, -15.0, -8.4, -15.0, -15.0, -10.0, -inf]Step 1470 2 visits [500.0, 1.0, 334.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1014 q_vals: [-inf, -15.0, -8.374, -15.0, -15.0, -10.0, -inf]Step 1471 2 visits [500.0, 1.0, 335.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1014 q_vals: [-inf, -15.0, -8.394, -15.0, -15.0, -10.0, -inf]Step 1472 2 visits [500.0, 1.0, 336.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1015 q_vals: [-inf, -15.0, -8.369, -15.0, -15.0, -10.0, -inf]Step 1473 2 visits [500.0, 1.0, 337.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1015 q_vals: [-inf, -15.0, -8.389, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 1016, "number_of_timesteps": 98228, "per_episode_reward": -389.95, "episode_reward_trend_value": 0.09266190451108654, "biggest_recent_change": 1.2682093848474096},
Step 1474 2 visits [500.0, 1.0, 338.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1016 q_vals: [-inf, -15.0, -8.409, -15.0, -15.0, -10.0, -inf]Step 1475 2 visits [500.0, 1.0, 339.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1017 q_vals: [-inf, -15.0, -8.428, -15.0, -15.0, -10.0, -inf]Step 1476 2 visits [500.0, 1.0, 340.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1018 q_vals: [-inf, -15.0, -8.447, -15.0, -15.0, -10.0, -inf]Step 1477 2 visits [500.0, 1.0, 341.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1020 q_vals: [-inf, -15.0, -8.466, -15.0, -15.0, -10.0, -inf]Step 1478 2 visits [500.0, 1.0, 342.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1021 q_vals: [-inf, -15.0, -8.486, -15.0, -15.0, -10.0, -inf]Step 1479 2 visits [500.0, 1.0, 343.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1021 q_vals: [-inf, -15.0, -8.505, -15.0, -15.0, -10.0, -inf]Step 1480 2 visits [500.0, 1.0, 344.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1021 q_vals: [-inf, -15.0, -8.523, -15.0, -15.0, -10.0, -inf]Step 1481 2 visits [500.0, 1.0, 345.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1021 q_vals: [-inf, -15.0, -8.542, -15.0, -15.0, -10.0, -inf]Step 1482 2 visits [500.0, 1.0, 346.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1023 q_vals: [-inf, -15.0, -8.561, -15.0, -15.0, -10.0, -inf]Step 1483 2 visits [500.0, 1.0, 347.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1023 q_vals: [-inf, -15.0, -8.536, -15.0, -15.0, -10.0, -inf]Step 1484 2 visits [500.0, 1.0, 348.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1024 q_vals: [-inf, -15.0, -8.512, -15.0, -15.0, -10.0, -inf]Step 1485 2 visits [500.0, 1.0, 349.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1024 q_vals: [-inf, -15.0, -8.487, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 1027, "number_of_timesteps": 99215, "per_episode_reward": -388.98, "episode_reward_trend_value": 0.09750505145321679, "biggest_recent_change": 1.2682093848474096},
Step 1486 2 visits [500.0, 1.0, 350.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1027 q_vals: [-inf, -15.0, -8.463, -15.0, -15.0, -10.0, -inf]Step 1487 2 visits [500.0, 1.0, 351.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1027 q_vals: [-inf, -15.0, -8.439, -15.0, -15.0, -10.0, -inf]Step 1488 2 visits [500.0, 1.0, 352.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1027 q_vals: [-inf, -15.0, -8.415, -15.0, -15.0, -10.0, -inf]Step 1489 2 visits [500.0, 1.0, 353.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1028 q_vals: [-inf, -15.0, -8.434, -15.0, -15.0, -10.0, -inf]Step 1490 2 visits [500.0, 1.0, 354.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1028 q_vals: [-inf, -15.0, -8.452, -15.0, -15.0, -10.0, -inf]Step 1491 2 visits [500.0, 1.0, 355.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1028 q_vals: [-inf, -15.0, -8.428, -15.0, -15.0, -10.0, -inf]Step 1492 2 visits [500.0, 1.0, 356.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1031 q_vals: [-inf, -15.0, -8.405, -15.0, -15.0, -10.0, -inf]Step 1493 2 visits [500.0, 1.0, 357.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1031 q_vals: [-inf, -15.0, -8.423, -15.0, -15.0, -10.0, -inf]Step 1494 2 visits [500.0, 1.0, 358.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1032 q_vals: [-inf, -15.0, -8.4, -15.0, -15.0, -10.0, -inf]Step 1495 2 visits [500.0, 1.0, 359.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1032 q_vals: [-inf, -15.0, -8.418, -15.0, -15.0, -10.0, -inf]Step 1496 2 visits [500.0, 1.0, 360.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1033 q_vals: [-inf, -15.0, -8.395, -15.0, -15.0, -10.0, -inf]Step 1497 2 visits [500.0, 1.0, 361.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1033 q_vals: [-inf, -15.0, -8.413, -15.0, -15.0, -10.0, -inf]Step 1498 2 visits [500.0, 1.0, 362.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1034 q_vals: [-inf, -15.0, -8.39, -15.0, -15.0, -10.0, -inf]Step 1499 2 visits [500.0, 1.0, 363.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1035 q_vals: [-inf, -15.0, -8.408, -15.0, -15.0, -10.0, -inf]Step 1500 2 visits [500.0, 1.0, 364.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1036 q_vals: [-inf, -15.0, -8.385, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 1038, "number_of_timesteps": 100221, "per_episode_reward": -386.83, "episode_reward_trend_value": 0.1137276586203964, "biggest_recent_change": 2.1484107553552008},
Step 1501 2 visits [500.0, 1.0, 365.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1038 q_vals: [-inf, -15.0, -8.403, -15.0, -15.0, -10.0, -inf]Step 1502 2 visits [500.0, 1.0, 366.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1038 q_vals: [-inf, -15.0, -8.421, -15.0, -15.0, -10.0, -inf]Step 1503 2 visits [500.0, 1.0, 367.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1038 q_vals: [-inf, -15.0, -8.398, -15.0, -15.0, -10.0, -inf]Step 1504 2 visits [500.0, 1.0, 368.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1038 q_vals: [-inf, -15.0, -8.416, -15.0, -15.0, -10.0, -inf]Step 1505 2 visits [500.0, 1.0, 369.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1039 q_vals: [-inf, -15.0, -8.434, -15.0, -15.0, -10.0, -inf]Step 1506 2 visits [500.0, 1.0, 370.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1040 q_vals: [-inf, -15.0, -8.452, -15.0, -15.0, -10.0, -inf]Step 1507 2 visits [500.0, 1.0, 371.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1040 q_vals: [-inf, -15.0, -8.429, -15.0, -15.0, -10.0, -inf]Step 1508 2 visits [500.0, 1.0, 372.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1041 q_vals: [-inf, -15.0, -8.446, -15.0, -15.0, -10.0, -inf]Step 1509 2 visits [500.0, 1.0, 373.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1041 q_vals: [-inf, -15.0, -8.424, -15.0, -15.0, -10.0, -inf]Step 1510 2 visits [500.0, 1.0, 374.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1041 q_vals: [-inf, -15.0, -8.441, -15.0, -15.0, -10.0, -inf]Step 1511 2 visits [500.0, 1.0, 375.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1042 q_vals: [-inf, -15.0, -8.419, -15.0, -15.0, -10.0, -inf]Step 1512 2 visits [500.0, 1.0, 376.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1044 q_vals: [-inf, -15.0, -8.436, -15.0, -15.0, -10.0, -inf]Step 1513 2 visits [500.0, 1.0, 377.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1044 q_vals: [-inf, -15.0, -8.414, -15.0, -15.0, -10.0, -inf]Step 1514 2 visits [500.0, 1.0, 378.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1044 q_vals: [-inf, -15.0, -8.431, -15.0, -15.0, -10.0, -inf]Step 1515 2 visits [500.0, 1.0, 379.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1044 q_vals: [-inf, -15.0, -8.409, -15.0, -15.0, -10.0, -inf]Step 1516 2 visits [500.0, 1.0, 380.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1046 q_vals: [-inf, -15.0, -8.387, -15.0, -15.0, -10.0, -inf]Step 1517 2 visits [500.0, 1.0, 381.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1047 q_vals: [-inf, -15.0, -8.404, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 1049, "number_of_timesteps": 101379, "per_episode_reward": -382.71, "episode_reward_trend_value": 0.14599064785328122, "biggest_recent_change": 4.115417891761638},
Step 1518 2 visits [500.0, 1.0, 382.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1049 q_vals: [-inf, -15.0, -8.422, -15.0, -15.0, -10.0, -inf]Step 1519 2 visits [500.0, 1.0, 383.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1049 q_vals: [-inf, -15.0, -8.439, -15.0, -15.0, -10.0, -inf]Step 1520 2 visits [500.0, 1.0, 384.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1050 q_vals: [-inf, -15.0, -8.456, -15.0, -15.0, -10.0, -inf]Step 1521 2 visits [500.0, 1.0, 385.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1050 q_vals: [-inf, -15.0, -8.434, -15.0, -15.0, -10.0, -inf]Step 1522 2 visits [500.0, 1.0, 386.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1050 q_vals: [-inf, -15.0, -8.412, -15.0, -15.0, -10.0, -inf]Step 1523 2 visits [500.0, 1.0, 387.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1051 q_vals: [-inf, -15.0, -8.429, -15.0, -15.0, -10.0, -inf]Step 1524 2 visits [500.0, 1.0, 388.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1051 q_vals: [-inf, -15.0, -8.407, -15.0, -15.0, -10.0, -inf]Step 1525 2 visits [500.0, 1.0, 389.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1051 q_vals: [-inf, -15.0, -8.424, -15.0, -15.0, -10.0, -inf]Step 1526 2 visits [500.0, 1.0, 390.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1052 q_vals: [-inf, -15.0, -8.403, -15.0, -15.0, -10.0, -inf]Step 1527 2 visits [500.0, 1.0, 391.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1053 q_vals: [-inf, -15.0, -8.42, -15.0, -15.0, -10.0, -inf]Step 1528 2 visits [500.0, 1.0, 392.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1053 q_vals: [-inf, -15.0, -8.398, -15.0, -15.0, -10.0, -inf]Step 1529 2 visits [500.0, 1.0, 393.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1055 q_vals: [-inf, -15.0, -8.415, -15.0, -15.0, -10.0, -inf]Step 1530 2 visits [500.0, 1.0, 394.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1055 q_vals: [-inf, -15.0, -8.432, -15.0, -15.0, -10.0, -inf]Step 1531 2 visits [500.0, 1.0, 395.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1055 q_vals: [-inf, -15.0, -8.448, -15.0, -15.0, -10.0, -inf]Step 1532 2 visits [500.0, 1.0, 396.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1055 q_vals: [-inf, -15.0, -8.427, -15.0, -15.0, -10.0, -inf]Step 1533 2 visits [500.0, 1.0, 397.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1056 q_vals: [-inf, -15.0, -8.444, -15.0, -15.0, -10.0, -inf]Step 1534 2 visits [500.0, 1.0, 398.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1056 q_vals: [-inf, -15.0, -8.46, -15.0, -15.0, -10.0, -inf]Step 1535 2 visits [500.0, 1.0, 399.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1058 q_vals: [-inf, -15.0, -8.476, -15.0, -15.0, -10.0, -inf]Step 1536 2 visits [500.0, 1.0, 400.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1058 q_vals: [-inf, -15.0, -8.455, -15.0, -15.0, -10.0, -inf]Step 1537 2 visits [500.0, 1.0, 401.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1058 q_vals: [-inf, -15.0, -8.434, -15.0, -15.0, -10.0, -inf]Step 1538 2 visits [500.0, 1.0, 402.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1058 q_vals: [-inf, -15.0, -8.413, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 1059, "number_of_timesteps": 102493, "per_episode_reward": -381.56, "episode_reward_trend_value": 0.14613391068658138, "biggest_recent_change": 4.115417891761638},
Step 1539 2 visits [500.0, 1.0, 403.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1059 q_vals: [-inf, -15.0, -8.429, -15.0, -15.0, -10.0, -inf]Step 1540 2 visits [500.0, 1.0, 404.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1059 q_vals: [-inf, -15.0, -8.446, -15.0, -15.0, -10.0, -inf]Step 1541 2 visits [500.0, 1.0, 405.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1060 q_vals: [-inf, -15.0, -8.462, -15.0, -15.0, -10.0, -inf]Step 1542 2 visits [500.0, 1.0, 406.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1061 q_vals: [-inf, -15.0, -8.478, -15.0, -15.0, -10.0, -inf]Step 1543 2 visits [500.0, 1.0, 407.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1061 q_vals: [-inf, -15.0, -8.457, -15.0, -15.0, -10.0, -inf]Step 1544 2 visits [500.0, 1.0, 408.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1062 q_vals: [-inf, -15.0, -8.473, -15.0, -15.0, -10.0, -inf]Step 1545 2 visits [500.0, 1.0, 409.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1064 q_vals: [-inf, -15.0, -8.489, -15.0, -15.0, -10.0, -inf]Step 1546 2 visits [500.0, 1.0, 410.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1064 q_vals: [-inf, -15.0, -8.505, -15.0, -15.0, -10.0, -inf]Step 1547 2 visits [500.0, 1.0, 411.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1064 q_vals: [-inf, -15.0, -8.484, -15.0, -15.0, -10.0, -inf]Step 1548 2 visits [500.0, 1.0, 412.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1064 q_vals: [-inf, -15.0, -8.464, -15.0, -15.0, -10.0, -inf]Step 1549 2 visits [500.0, 1.0, 413.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1065 q_vals: [-inf, -15.0, -8.443, -15.0, -15.0, -10.0, -inf]Step 1550 2 visits [500.0, 1.0, 414.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1066 q_vals: [-inf, -15.0, -8.459, -15.0, -15.0, -10.0, -inf]Step 1551 2 visits [500.0, 1.0, 415.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1067 q_vals: [-inf, -15.0, -8.475, -15.0, -15.0, -10.0, -inf]Step 1552 2 visits [500.0, 1.0, 416.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1068 q_vals: [-inf, -15.0, -8.455, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 1069, "number_of_timesteps": 103654, "per_episode_reward": -379.66, "episode_reward_trend_value": 0.15906770462462733, "biggest_recent_change": 4.115417891761638},
Step 1553 2 visits [500.0, 1.0, 417.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1069 q_vals: [-inf, -15.0, -8.47, -15.0, -15.0, -10.0, -inf]Step 1554 2 visits [500.0, 1.0, 418.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1070 q_vals: [-inf, -15.0, -8.486, -15.0, -15.0, -10.0, -inf]Step 1555 2 visits [500.0, 1.0, 419.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1071 q_vals: [-inf, -15.0, -8.466, -15.0, -15.0, -10.0, -inf]Step 1556 2 visits [500.0, 1.0, 420.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1071 q_vals: [-inf, -15.0, -8.445, -15.0, -15.0, -10.0, -inf]Step 1557 2 visits [500.0, 1.0, 421.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1071 q_vals: [-inf, -15.0, -8.425, -15.0, -15.0, -10.0, -inf]Step 1558 2 visits [500.0, 1.0, 422.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1072 q_vals: [-inf, -15.0, -8.441, -15.0, -15.0, -10.0, -inf]Step 1559 2 visits [500.0, 1.0, 423.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1072 q_vals: [-inf, -15.0, -8.421, -15.0, -15.0, -10.0, -inf]Step 1560 2 visits [500.0, 1.0, 424.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1072 q_vals: [-inf, -15.0, -8.401, -15.0, -15.0, -10.0, -inf]Step 1561 2 visits [500.0, 1.0, 425.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1072 q_vals: [-inf, -15.0, -8.381, -15.0, -15.0, -10.0, -inf]Step 1562 2 visits [500.0, 1.0, 426.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1073 q_vals: [-inf, -15.0, -8.397, -15.0, -15.0, -10.0, -inf]Step 1563 2 visits [500.0, 1.0, 427.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1074 q_vals: [-inf, -15.0, -8.412, -15.0, -15.0, -10.0, -inf]Step 1564 2 visits [500.0, 1.0, 428.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1075 q_vals: [-inf, -15.0, -8.428, -15.0, -15.0, -10.0, -inf]Step 1565 2 visits [500.0, 1.0, 429.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1076 q_vals: [-inf, -15.0, -8.408, -15.0, -15.0, -10.0, -inf]Step 1566 2 visits [500.0, 1.0, 430.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1076 q_vals: [-inf, -15.0, -8.423, -15.0, -15.0, -10.0, -inf]Step 1567 2 visits [500.0, 1.0, 431.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1076 q_vals: [-inf, -15.0, -8.439, -15.0, -15.0, -10.0, -inf]Step 1568 2 visits [500.0, 1.0, 432.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1076 q_vals: [-inf, -15.0, -8.454, -15.0, -15.0, -10.0, -inf]Step 1569 2 visits [500.0, 1.0, 433.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1076 q_vals: [-inf, -15.0, -8.469, -15.0, -15.0, -10.0, -inf]Step 1570 2 visits [500.0, 1.0, 434.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1076 q_vals: [-inf, -15.0, -8.484, -15.0, -15.0, -10.0, -inf]Step 1571 2 visits [500.0, 1.0, 435.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1076 q_vals: [-inf, -15.0, -8.465, -15.0, -15.0, -10.0, -inf]Step 1572 2 visits [500.0, 1.0, 436.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1078 q_vals: [-inf, -15.0, -8.48, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 1080, "number_of_timesteps": 104933, "per_episode_reward": -378.23, "episode_reward_trend_value": 0.16406606990664413, "biggest_recent_change": 4.115417891761638},
Step 1573 2 visits [500.0, 1.0, 437.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1080 q_vals: [-inf, -15.0, -8.494, -15.0, -15.0, -10.0, -inf]Step 1574 2 visits [500.0, 1.0, 438.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1080 q_vals: [-inf, -15.0, -8.475, -15.0, -15.0, -10.0, -inf]Step 1575 2 visits [500.0, 1.0, 439.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1082 q_vals: [-inf, -15.0, -8.49, -15.0, -15.0, -10.0, -inf]Step 1576 2 visits [500.0, 1.0, 440.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1083 q_vals: [-inf, -15.0, -8.471, -15.0, -15.0, -10.0, -inf]Step 1577 2 visits [500.0, 1.0, 441.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1083 q_vals: [-inf, -15.0, -8.451, -15.0, -15.0, -10.0, -inf]Step 1578 2 visits [500.0, 1.0, 442.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1083 q_vals: [-inf, -15.0, -8.432, -15.0, -15.0, -10.0, -inf]Step 1579 2 visits [500.0, 1.0, 443.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1083 q_vals: [-inf, -15.0, -8.447, -15.0, -15.0, -10.0, -inf]Step 1580 2 visits [500.0, 1.0, 444.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1083 q_vals: [-inf, -15.0, -8.428, -15.0, -15.0, -10.0, -inf]Step 1581 2 visits [500.0, 1.0, 445.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1083 q_vals: [-inf, -15.0, -8.409, -15.0, -15.0, -10.0, -inf]Step 1582 2 visits [500.0, 1.0, 446.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1083 q_vals: [-inf, -15.0, -8.424, -15.0, -15.0, -10.0, -inf]Step 1583 2 visits [500.0, 1.0, 447.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1083 q_vals: [-inf, -15.0, -8.405, -15.0, -15.0, -10.0, -inf]Step 1584 2 visits [500.0, 1.0, 448.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1084 q_vals: [-inf, -15.0, -8.42, -15.0, -15.0, -10.0, -inf]Step 1585 2 visits [500.0, 1.0, 449.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1085 q_vals: [-inf, -15.0, -8.401, -15.0, -15.0, -10.0, -inf]Step 1586 2 visits [500.0, 1.0, 450.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1085 q_vals: [-inf, -15.0, -8.382, -15.0, -15.0, -10.0, -inf]Step 1587 2 visits [500.0, 1.0, 451.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1085 q_vals: [-inf, -15.0, -8.397, -15.0, -15.0, -10.0, -inf]Step 1588 2 visits [500.0, 1.0, 452.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1087 q_vals: [-inf, -15.0, -8.412, -15.0, -15.0, -10.0, -inf]Step 1589 2 visits [500.0, 1.0, 453.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1087 q_vals: [-inf, -15.0, -8.393, -15.0, -15.0, -10.0, -inf]Step 1590 2 visits [500.0, 1.0, 454.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1088 q_vals: [-inf, -15.0, -8.408, -15.0, -15.0, -10.0, -inf]Step 1591 2 visits [500.0, 1.0, 455.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1088 q_vals: [-inf, -15.0, -8.389, -15.0, -15.0, -10.0, -inf]Step 1592 2 visits [500.0, 1.0, 456.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1089 q_vals: [-inf, -15.0, -8.404, -15.0, -15.0, -10.0, -inf]Step 1593 2 visits [500.0, 1.0, 457.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1089 q_vals: [-inf, -15.0, -8.418, -15.0, -15.0, -10.0, -inf]Step 1594 2 visits [500.0, 1.0, 458.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1089 q_vals: [-inf, -15.0, -8.4, -15.0, -15.0, -10.0, -inf]Step 1595 2 visits [500.0, 1.0, 459.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1089 q_vals: [-inf, -15.0, -8.403, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 1091, "number_of_timesteps": 106330, "per_episode_reward": -376.31, "episode_reward_trend_value": 0.17537395463083005, "biggest_recent_change": 4.115417891761638},
Step 1596 2 visits [500.0, 1.0, 460.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1091 q_vals: [-inf, -15.0, -8.384, -15.0, -15.0, -10.0, -inf]Step 1597 2 visits [500.0, 1.0, 461.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1091 q_vals: [-inf, -15.0, -8.366, -15.0, -15.0, -10.0, -inf]Step 1598 2 visits [500.0, 1.0, 462.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1094 q_vals: [-inf, -15.0, -8.348, -15.0, -15.0, -10.0, -inf]Step 1599 2 visits [500.0, 1.0, 463.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1094 q_vals: [-inf, -15.0, -8.362, -15.0, -15.0, -10.0, -inf]Step 1600 2 visits [500.0, 1.0, 464.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1096 q_vals: [-inf, -15.0, -8.344, -15.0, -15.0, -10.0, -inf]Step 1601 2 visits [500.0, 1.0, 465.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1096 q_vals: [-inf, -15.0, -8.326, -15.0, -15.0, -10.0, -inf]Step 1602 2 visits [500.0, 1.0, 466.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1096 q_vals: [-inf, -15.0, -8.309, -15.0, -15.0, -10.0, -inf]Step 1603 2 visits [500.0, 1.0, 467.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1096 q_vals: [-inf, -15.0, -8.323, -15.0, -15.0, -10.0, -inf]Step 1604 2 visits [500.0, 1.0, 468.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1096 q_vals: [-inf, -15.0, -8.337, -15.0, -15.0, -10.0, -inf]Step 1605 2 visits [500.0, 1.0, 469.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1096 q_vals: [-inf, -15.0, -8.351, -15.0, -15.0, -10.0, -inf]Step 1606 2 visits [500.0, 1.0, 470.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1096 q_vals: [-inf, -15.0, -8.334, -15.0, -15.0, -10.0, -inf]Step 1607 2 visits [500.0, 1.0, 471.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1099 q_vals: [-inf, -15.0, -8.316, -15.0, -15.0, -10.0, -inf]Step 1608 2 visits [500.0, 1.0, 472.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1100 q_vals: [-inf, -15.0, -8.33, -15.0, -15.0, -10.0, -inf]Step 1609 2 visits [500.0, 1.0, 473.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1100 q_vals: [-inf, -15.0, -8.344, -15.0, -15.0, -10.0, -inf]Step 1610 2 visits [500.0, 1.0, 474.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1100 q_vals: [-inf, -15.0, -8.358, -15.0, -15.0, -10.0, -inf]Step 1611 2 visits [500.0, 1.0, 475.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1100 q_vals: [-inf, -15.0, -8.372, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 1102, "number_of_timesteps": 107594, "per_episode_reward": -373.78, "episode_reward_trend_value": 0.1893375261833607, "biggest_recent_change": 4.115417891761638},
Step 1612 2 visits [500.0, 1.0, 476.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1102 q_vals: [-inf, -15.0, -8.355, -15.0, -15.0, -10.0, -inf]Step 1613 2 visits [500.0, 1.0, 477.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1102 q_vals: [-inf, -15.0, -8.337, -15.0, -15.0, -10.0, -inf]Step 1614 2 visits [500.0, 1.0, 478.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1102 q_vals: [-inf, -15.0, -8.32, -15.0, -15.0, -10.0, -inf]Step 1615 2 visits [500.0, 1.0, 479.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1102 q_vals: [-inf, -15.0, -8.334, -15.0, -15.0, -10.0, -inf]Step 1616 2 visits [500.0, 1.0, 480.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1102 q_vals: [-inf, -15.0, -8.347, -15.0, -15.0, -10.0, -inf]Step 1617 2 visits [500.0, 1.0, 481.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1102 q_vals: [-inf, -15.0, -8.33, -15.0, -15.0, -10.0, -inf]Step 1618 2 visits [500.0, 1.0, 482.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1104 q_vals: [-inf, -15.0, -8.313, -15.0, -15.0, -10.0, -inf]Step 1619 2 visits [500.0, 1.0, 483.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1104 q_vals: [-inf, -15.0, -8.296, -15.0, -15.0, -10.0, -inf]Step 1620 2 visits [500.0, 1.0, 484.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1104 q_vals: [-inf, -15.0, -8.309, -15.0, -15.0, -10.0, -inf]Step 1621 2 visits [500.0, 1.0, 485.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1105 q_vals: [-inf, -15.0, -8.292, -15.0, -15.0, -10.0, -inf]Step 1622 2 visits [500.0, 1.0, 486.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1107 q_vals: [-inf, -15.0, -8.306, -15.0, -15.0, -10.0, -inf]Step 1623 2 visits [500.0, 1.0, 487.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1107 q_vals: [-inf, -15.0, -8.32, -15.0, -15.0, -10.0, -inf]Step 1624 2 visits [500.0, 1.0, 488.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1108 q_vals: [-inf, -15.0, -8.334, -15.0, -15.0, -10.0, -inf]Step 1625 2 visits [500.0, 1.0, 489.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1109 q_vals: [-inf, -15.0, -8.347, -15.0, -15.0, -10.0, -inf]Step 1626 2 visits [500.0, 1.0, 490.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1109 q_vals: [-inf, -15.0, -8.361, -15.0, -15.0, -10.0, -inf]Step 1627 2 visits [500.0, 1.0, 491.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1109 q_vals: [-inf, -15.0, -8.374, -15.0, -15.0, -10.0, -inf]Step 1628 2 visits [500.0, 1.0, 492.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1109 q_vals: [-inf, -15.0, -8.388, -15.0, -15.0, -10.0, -inf]Step 1629 2 visits [500.0, 1.0, 493.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1110 q_vals: [-inf, -15.0, -8.401, -15.0, -15.0, -10.0, -inf]Step 1630 2 visits [500.0, 1.0, 494.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1111 q_vals: [-inf, -15.0, -8.384, -15.0, -15.0, -10.0, -inf]{"total_number_of_episodes": 1112, "number_of_timesteps": 108855, "per_episode_reward": -372.18, "episode_reward_trend_value": 0.19744822363118902, "biggest_recent_change": 4.115417891761638},
Step 1631 2 visits [500.0, 1.0, 495.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1112 q_vals: [-inf, -15.0, -8.386, -15.0, -15.0, -10.0, -inf]Step 1632 2 visits [500.0, 1.0, 496.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1112 q_vals: [-inf, -15.0, -8.399, -15.0, -15.0, -10.0, -inf]Step 1633 2 visits [500.0, 1.0, 497.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1112 q_vals: [-inf, -15.0, -8.382, -15.0, -15.0, -10.0, -inf]Step 1634 2 visits [500.0, 1.0, 498.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1113 q_vals: [-inf, -15.0, -8.393, -15.0, -15.0, -10.0, -inf]Step 1635 2 visits [500.0, 1.0, 499.0, 1.0, 1.0, 3.0, 500.0]  episode_count: 1113 q_vals: [-inf, -15.0, -8.392, -15.0, -15.0, -10.0, -inf]Step 1636 2 visits [500.0, 0.0, 500.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 1115 q_vals: [-inf, 0.0, -inf, 0.0, 0.0, 0.0, -inf]{"total_number_of_episodes": 1122, "number_of_timesteps": 109888, "per_episode_reward": -293.28, "episode_reward_trend_value": 1.0632954060228144, "biggest_recent_change": 78.90104490475017},
{"total_number_of_episodes": 1132, "number_of_timesteps": 110888, "per_episode_reward": -292.62, "episode_reward_trend_value": 1.0467667469855964, "biggest_recent_change": 78.90104490475017},
{"total_number_of_episodes": 1142, "number_of_timesteps": 112329, "per_episode_reward": -292.33, "episode_reward_trend_value": 1.0042589495281073, "biggest_recent_change": 78.90104490475017},
{"total_number_of_episodes": 1152, "number_of_timesteps": 113651, "per_episode_reward": -292.25, "episode_reward_trend_value": 0.9922307295610595, "biggest_recent_change": 78.90104490475017},
{"total_number_of_episodes": 1162, "number_of_timesteps": 114703, "per_episode_reward": -291.63, "episode_reward_trend_value": 0.9780864544278541, "biggest_recent_change": 78.90104490475017},
{"total_number_of_episodes": 1172, "number_of_timesteps": 115791, "per_episode_reward": -290.4, "episode_reward_trend_value": 0.9758030257741318, "biggest_recent_change": 78.90104490475017},
{"total_number_of_episodes": 1182, "number_of_timesteps": 116945, "per_episode_reward": -286.82, "episode_reward_trend_value": 0.9943039905106111, "biggest_recent_change": 78.90104490475017},
{"total_number_of_episodes": 1193, "number_of_timesteps": 118386, "per_episode_reward": -284.53, "episode_reward_trend_value": 0.9916488648026454, "biggest_recent_change": 78.90104490475017},
{"total_number_of_episodes": 1203, "number_of_timesteps": 119557, "per_episode_reward": -282.38, "episode_reward_trend_value": 0.9977687081141356, "biggest_recent_change": 78.90104490475017},
{"total_number_of_episodes": 1215, "number_of_timesteps": 120729, "per_episode_reward": -280.31, "episode_reward_trend_value": 0.14412246937214188, "biggest_recent_change": 3.5870302066705904},
{"total_number_of_episodes": 1225, "number_of_timesteps": 122032, "per_episode_reward": -279.22, "episode_reward_trend_value": 0.14891864295086005, "biggest_recent_change": 3.5870302066705904},
{"total_number_of_episodes": 1235, "number_of_timesteps": 123182, "per_episode_reward": -277.33, "episode_reward_trend_value": 0.16663763652320668, "biggest_recent_change": 3.5870302066705904},
{"total_number_of_episodes": 1245, "number_of_timesteps": 124407, "per_episode_reward": -276.13, "episode_reward_trend_value": 0.17919871213146432, "biggest_recent_change": 3.5870302066705904},
{"total_number_of_episodes": 1255, "number_of_timesteps": 125560, "per_episode_reward": -273.68, "episode_reward_trend_value": 0.1995363295262949, "biggest_recent_change": 3.5870302066705904},
{"total_number_of_episodes": 1265, "number_of_timesteps": 126822, "per_episode_reward": -271.94, "episode_reward_trend_value": 0.2051425467871392, "biggest_recent_change": 3.5870302066705904},
{"total_number_of_episodes": 1276, "number_of_timesteps": 128571, "per_episode_reward": -270.75, "episode_reward_trend_value": 0.17852654364157022, "biggest_recent_change": 2.451132894588966},
{"total_number_of_episodes": 1286, "number_of_timesteps": 129438, "per_episode_reward": -269.86, "episode_reward_trend_value": 0.16304471599705783, "biggest_recent_change": 2.451132894588966},
{"total_number_of_episodes": 1297, "number_of_timesteps": 130346, "per_episode_reward": -268.31, "episode_reward_trend_value": 0.1563020409304992, "biggest_recent_change": 2.451132894588966},
{"total_number_of_episodes": 1307, "number_of_timesteps": 131352, "per_episode_reward": -267.2, "episode_reward_trend_value": 0.145680980225775, "biggest_recent_change": 2.451132894588966},
{"total_number_of_episodes": 1317, "number_of_timesteps": 132486, "per_episode_reward": -266.0, "episode_reward_trend_value": 0.14689678331771144, "biggest_recent_change": 2.451132894588966},
{"total_number_of_episodes": 1328, "number_of_timesteps": 133945, "per_episode_reward": -265.33, "episode_reward_trend_value": 0.1333511407446325, "biggest_recent_change": 2.451132894588966},
{"total_number_of_episodes": 1339, "number_of_timesteps": 135163, "per_episode_reward": -263.61, "episode_reward_trend_value": 0.13903314342034984, "biggest_recent_change": 2.451132894588966},
{"total_number_of_episodes": 1350, "number_of_timesteps": 136501, "per_episode_reward": -262.91, "episode_reward_trend_value": 0.11961789092691914, "biggest_recent_change": 1.7336671812553845},
{"total_number_of_episodes": 1360, "number_of_timesteps": 137437, "per_episode_reward": -261.44, "episode_reward_trend_value": 0.11668051964133497, "biggest_recent_change": 1.7167862692610356},
{"total_number_of_episodes": 1370, "number_of_timesteps": 138476, "per_episode_reward": -260.08, "episode_reward_trend_value": 0.11858177584428833, "biggest_recent_change": 1.7167862692610356},
{"total_number_of_episodes": 1382, "number_of_timesteps": 139654, "per_episode_reward": -259.18, "episode_reward_trend_value": 0.11867601876990205, "biggest_recent_change": 1.7167862692610356},
{"total_number_of_episodes": 1392, "number_of_timesteps": 140640, "per_episode_reward": -258.34, "episode_reward_trend_value": 0.11082495046668442, "biggest_recent_change": 1.7167862692610356},
{"total_number_of_episodes": 1402, "number_of_timesteps": 141504, "per_episode_reward": -257.75, "episode_reward_trend_value": 0.10493086178676284, "biggest_recent_change": 1.7167862692610356},
{"total_number_of_episodes": 1412, "number_of_timesteps": 142650, "per_episode_reward": -256.83, "episode_reward_trend_value": 0.10180000397592279, "biggest_recent_change": 1.7167862692610356},
{"total_number_of_episodes": 1422, "number_of_timesteps": 143927, "per_episode_reward": -256.22, "episode_reward_trend_value": 0.10127315650783228, "biggest_recent_change": 1.7167862692610356},
{"total_number_of_episodes": 1433, "number_of_timesteps": 145011, "per_episode_reward": -255.0, "episode_reward_trend_value": 0.09570207790949356, "biggest_recent_change": 1.4693037655528087},
{"total_number_of_episodes": 1443, "number_of_timesteps": 145913, "per_episode_reward": -252.74, "episode_reward_trend_value": 0.11302708497051159, "biggest_recent_change": 2.2630108056718257},
{"total_number_of_episodes": 1453, "number_of_timesteps": 146685, "per_episode_reward": -251.54, "episode_reward_trend_value": 0.110028481926889, "biggest_recent_change": 2.2630108056718257},
{"total_number_of_episodes": 1463, "number_of_timesteps": 147668, "per_episode_reward": -249.98, "episode_reward_trend_value": 0.11220014341888632, "biggest_recent_change": 2.2630108056718257},
{"total_number_of_episodes": 1474, "number_of_timesteps": 148870, "per_episode_reward": -249.03, "episode_reward_trend_value": 0.11276685105334978, "biggest_recent_change": 2.2630108056718257},
{"total_number_of_episodes": 1484, "number_of_timesteps": 150117, "per_episode_reward": -247.69, "episode_reward_trend_value": 0.11832320762063628, "biggest_recent_change": 2.2630108056718257},
{"total_number_of_episodes": 1494, "number_of_timesteps": 151101, "per_episode_reward": -245.11, "episode_reward_trend_value": 0.14043872393735468, "biggest_recent_change": 2.5769164418572643},
{"total_number_of_episodes": 1504, "number_of_timesteps": 152171, "per_episode_reward": -244.21, "episode_reward_trend_value": 0.14031431217628126, "biggest_recent_change": 2.5769164418572643},
{"total_number_of_episodes": 1514, "number_of_timesteps": 153479, "per_episode_reward": -240.41, "episode_reward_trend_value": 0.17558480364909979, "biggest_recent_change": 3.7922456709472385},
{"total_number_of_episodes": 1524, "number_of_timesteps": 154985, "per_episode_reward": -239.4, "episode_reward_trend_value": 0.17334657104963627, "biggest_recent_change": 3.7922456709472385},
{"total_number_of_episodes": 1534, "number_of_timesteps": 155981, "per_episode_reward": -237.89, "episode_reward_trend_value": 0.1649246451117032, "biggest_recent_change": 3.7922456709472385},
{"total_number_of_episodes": 1544, "number_of_timesteps": 157047, "per_episode_reward": -236.47, "episode_reward_trend_value": 0.16737096893200457, "biggest_recent_change": 3.7922456709472385},
{"total_number_of_episodes": 1554, "number_of_timesteps": 158258, "per_episode_reward": -235.04, "episode_reward_trend_value": 0.16597470816985865, "biggest_recent_change": 3.7922456709472385},
{"total_number_of_episodes": 1564, "number_of_timesteps": 159317, "per_episode_reward": -233.79, "episode_reward_trend_value": 0.16926431822438953, "biggest_recent_change": 3.7922456709472385},
{"total_number_of_episodes": 1574, "number_of_timesteps": 160330, "per_episode_reward": -231.02, "episode_reward_trend_value": 0.18523491046374038, "biggest_recent_change": 3.7922456709472385},
{"total_number_of_episodes": 1584, "number_of_timesteps": 161382, "per_episode_reward": -229.88, "episode_reward_trend_value": 0.16923859070561775, "biggest_recent_change": 3.7922456709472385},
{"total_number_of_episodes": 1594, "number_of_timesteps": 162531, "per_episode_reward": -228.6, "episode_reward_trend_value": 0.17334253549721299, "biggest_recent_change": 3.7922456709472385},
{"total_number_of_episodes": 1604, "number_of_timesteps": 163711, "per_episode_reward": -228.08, "episode_reward_trend_value": 0.1369994148528933, "biggest_recent_change": 2.773815854180583},
{"total_number_of_episodes": 1616, "number_of_timesteps": 165095, "per_episode_reward": -227.51, "episode_reward_trend_value": 0.13212595600605698, "biggest_recent_change": 2.773815854180583},
{"total_number_of_episodes": 1628, "number_of_timesteps": 166243, "per_episode_reward": -224.32, "episode_reward_trend_value": 0.15077390622496378, "biggest_recent_change": 3.183352990959463},
{"total_number_of_episodes": 1638, "number_of_timesteps": 167171, "per_episode_reward": -223.51, "episode_reward_trend_value": 0.1441023349390248, "biggest_recent_change": 3.183352990959463},
{"total_number_of_episodes": 1648, "number_of_timesteps": 168325, "per_episode_reward": -223.45, "episode_reward_trend_value": 0.1287857299368647, "biggest_recent_change": 3.183352990959463},
{"total_number_of_episodes": 1658, "number_of_timesteps": 169458, "per_episode_reward": -222.98, "episode_reward_trend_value": 0.12012624309381863, "biggest_recent_change": 3.183352990959463},
{"total_number_of_episodes": 1669, "number_of_timesteps": 170382, "per_episode_reward": -220.92, "episode_reward_trend_value": 0.11221214339453145, "biggest_recent_change": 3.183352990959463},
{"total_number_of_episodes": 1679, "number_of_timesteps": 171407, "per_episode_reward": -220.31, "episode_reward_trend_value": 0.10636921178810736, "biggest_recent_change": 3.183352990959463},
{"total_number_of_episodes": 1689, "number_of_timesteps": 172538, "per_episode_reward": -221.6, "episode_reward_trend_value": 0.07787100865360672, "biggest_recent_change": 3.183352990959463},
{"total_number_of_episodes": 1699, "number_of_timesteps": 173740, "per_episode_reward": -219.97, "episode_reward_trend_value": 0.09017312186436313, "biggest_recent_change": 3.183352990959463},
{"total_number_of_episodes": 1709, "number_of_timesteps": 174727, "per_episode_reward": -219.25, "episode_reward_trend_value": 0.09173447623591895, "biggest_recent_change": 3.183352990959463},
{"total_number_of_episodes": 1719, "number_of_timesteps": 175885, "per_episode_reward": -218.61, "episode_reward_trend_value": 0.0634574804361525, "biggest_recent_change": 2.0615468812447375},
{"total_number_of_episodes": 1729, "number_of_timesteps": 177024, "per_episode_reward": -218.16, "episode_reward_trend_value": 0.05935458149635969, "biggest_recent_change": 2.0615468812447375},
{"total_number_of_episodes": 1739, "number_of_timesteps": 178002, "per_episode_reward": -217.43, "episode_reward_trend_value": 0.06689785228700203, "biggest_recent_change": 2.0615468812447375},
{"total_number_of_episodes": 1749, "number_of_timesteps": 178895, "per_episode_reward": -215.53, "episode_reward_trend_value": 0.0827830215894835, "biggest_recent_change": 2.0615468812447375},
{"total_number_of_episodes": 1759, "number_of_timesteps": 179946, "per_episode_reward": -216.69, "episode_reward_trend_value": 0.047058271551763495, "biggest_recent_change": 1.8984668995160519},
{"total_number_of_episodes": 1771, "number_of_timesteps": 181462, "per_episode_reward": -216.69, "episode_reward_trend_value": 0.040265118006785075, "biggest_recent_change": 1.8984668995160519},
{"total_number_of_episodes": 1781, "number_of_timesteps": 182495, "per_episode_reward": -215.14, "episode_reward_trend_value": 0.07173642259487564, "biggest_recent_change": 1.8984668995160519},
{"total_number_of_episodes": 1791, "number_of_timesteps": 183633, "per_episode_reward": -213.2, "episode_reward_trend_value": 0.07524231948613078, "biggest_recent_change": 1.944085722139505},
{"total_number_of_episodes": 1801, "number_of_timesteps": 184790, "per_episode_reward": -212.9, "episode_reward_trend_value": 0.07060210517182353, "biggest_recent_change": 1.944085722139505},
{"total_number_of_episodes": 1811, "number_of_timesteps": 185988, "per_episode_reward": -212.45, "episode_reward_trend_value": 0.06851422650211893, "biggest_recent_change": 1.944085722139505},
{"total_number_of_episodes": 1821, "number_of_timesteps": 186990, "per_episode_reward": -212.11, "episode_reward_trend_value": 0.0672172420086838, "biggest_recent_change": 1.944085722139505},
{"total_number_of_episodes": 1833, "number_of_timesteps": 188572, "per_episode_reward": -212.15, "episode_reward_trend_value": 0.0586685968718181, "biggest_recent_change": 1.944085722139505},
{"total_number_of_episodes": 1843, "number_of_timesteps": 189527, "per_episode_reward": -211.35, "episode_reward_trend_value": 0.04644569369147196, "biggest_recent_change": 1.944085722139505},
{"total_number_of_episodes": 1853, "number_of_timesteps": 190467, "per_episode_reward": -209.34, "episode_reward_trend_value": 0.0816456390662195, "biggest_recent_change": 2.0143144615772144},
{"total_number_of_episodes": 1863, "number_of_timesteps": 191601, "per_episode_reward": -208.88, "episode_reward_trend_value": 0.08669583156678143, "biggest_recent_change": 2.0143144615772144},
{"total_number_of_episodes": 1873, "number_of_timesteps": 192358, "per_episode_reward": -208.42, "episode_reward_trend_value": 0.07467259647385226, "biggest_recent_change": 2.0143144615772144},
{"total_number_of_episodes": 1883, "number_of_timesteps": 193413, "per_episode_reward": -208.22, "episode_reward_trend_value": 0.055326252928004596, "biggest_recent_change": 2.0143144615772144},
{"total_number_of_episodes": 1893, "number_of_timesteps": 194549, "per_episode_reward": -207.71, "episode_reward_trend_value": 0.057691950334710085, "biggest_recent_change": 2.0143144615772144},
{"total_number_of_episodes": 1903, "number_of_timesteps": 195475, "per_episode_reward": -206.77, "episode_reward_trend_value": 0.0630675031860736, "biggest_recent_change": 2.0143144615772144},
{"total_number_of_episodes": 1913, "number_of_timesteps": 196724, "per_episode_reward": -205.91, "episode_reward_trend_value": 0.06893702673509033, "biggest_recent_change": 2.0143144615772144},
{"total_number_of_episodes": 1923, "number_of_timesteps": 197969, "per_episode_reward": -205.33, "episode_reward_trend_value": 0.07577378411630555, "biggest_recent_change": 2.0143144615772144},
{"total_number_of_episodes": 1933, "number_of_timesteps": 198919, "per_episode_reward": -204.08, "episode_reward_trend_value": 0.08075330057395938, "biggest_recent_change": 2.0143144615772144},
{"total_number_of_episodes": 1943, "number_of_timesteps": 200093, "per_episode_reward": -203.94, "episode_reward_trend_value": 0.060020252021544394, "biggest_recent_change": 1.2465620944737452},
{"total_number_of_episodes": 1953, "number_of_timesteps": 201217, "per_episode_reward": -203.49, "episode_reward_trend_value": 0.059962577251377214, "biggest_recent_change": 1.2465620944737452},
{"total_number_of_episodes": 1963, "number_of_timesteps": 202558, "per_episode_reward": -203.05, "episode_reward_trend_value": 0.059644933881229024, "biggest_recent_change": 1.2465620944737452},
{"total_number_of_episodes": 1973, "number_of_timesteps": 203469, "per_episode_reward": -202.11, "episode_reward_trend_value": 0.06782173514682294, "biggest_recent_change": 1.2465620944737452},
{"total_number_of_episodes": 1983, "number_of_timesteps": 204499, "per_episode_reward": -201.23, "episode_reward_trend_value": 0.07191925104464379, "biggest_recent_change": 1.2465620944737452},
{"total_number_of_episodes": 1994, "number_of_timesteps": 205484, "per_episode_reward": -200.73, "episode_reward_trend_value": 0.06709871909762784, "biggest_recent_change": 1.2465620944737452},
{"total_number_of_episodes": 2004, "number_of_timesteps": 206572, "per_episode_reward": -200.02, "episode_reward_trend_value": 0.06542572974666175, "biggest_recent_change": 1.2465620944737452},
{"total_number_of_episodes": 2015, "number_of_timesteps": 207830, "per_episode_reward": -199.74, "episode_reward_trend_value": 0.06208655995373343, "biggest_recent_change": 1.2465620944737452},
{"total_number_of_episodes": 2025, "number_of_timesteps": 208935, "per_episode_reward": -199.97, "episode_reward_trend_value": 0.04576633009174821, "biggest_recent_change": 0.9388269169166676},
{"total_number_of_episodes": 2035, "number_of_timesteps": 210361, "per_episode_reward": -200.26, "episode_reward_trend_value": 0.04082786701424684, "biggest_recent_change": 0.9388269169166676},
{"total_number_of_episodes": 2045, "number_of_timesteps": 211620, "per_episode_reward": -199.39, "episode_reward_trend_value": 0.04553627451458245, "biggest_recent_change": 0.9388269169166676},
{"total_number_of_episodes": 2055, "number_of_timesteps": 212667, "per_episode_reward": -199.9, "episode_reward_trend_value": 0.035059031268749485, "biggest_recent_change": 0.9388269169166676},
{"total_number_of_episodes": 2065, "number_of_timesteps": 213788, "per_episode_reward": -199.26, "episode_reward_trend_value": 0.03172399361831203, "biggest_recent_change": 0.8799287678033068},
{"total_number_of_episodes": 2075, "number_of_timesteps": 214801, "per_episode_reward": -198.72, "episode_reward_trend_value": 0.02786558791295211, "biggest_recent_change": 0.8730832707657328},
{"total_number_of_episodes": 2085, "number_of_timesteps": 216054, "per_episode_reward": -198.99, "episode_reward_trend_value": 0.019354335147641816, "biggest_recent_change": 0.8730832707657328},
{"total_number_of_episodes": 2095, "number_of_timesteps": 217226, "per_episode_reward": -198.73, "episode_reward_trend_value": 0.014333103120512508, "biggest_recent_change": 0.8730832707657328},
{"total_number_of_episodes": 2105, "number_of_timesteps": 218575, "per_episode_reward": -198.68, "episode_reward_trend_value": 0.011772327629634876, "biggest_recent_change": 0.8730832707657328},
{"total_number_of_episodes": 2115, "number_of_timesteps": 219640, "per_episode_reward": -198.5, "episode_reward_trend_value": 0.016317436280779578, "biggest_recent_change": 0.8730832707657328},
{"total_number_of_episodes": 2125, "number_of_timesteps": 220872, "per_episode_reward": -198.67, "episode_reward_trend_value": 0.017655078289309737, "biggest_recent_change": 0.8730832707657328},
{"total_number_of_episodes": 2135, "number_of_timesteps": 222138, "per_episode_reward": -198.53, "episode_reward_trend_value": 0.009538111179592572, "biggest_recent_change": 0.6386735283772964},
{"total_number_of_episodes": 2145, "number_of_timesteps": 223057, "per_episode_reward": -198.55, "episode_reward_trend_value": 0.014906099314665276, "biggest_recent_change": 0.6386735283772964},
{"total_number_of_episodes": 2155, "number_of_timesteps": 223872, "per_episode_reward": -197.95, "episode_reward_trend_value": 0.014495310501940317, "biggest_recent_change": 0.6017025352320502},
{"total_number_of_episodes": 2165, "number_of_timesteps": 224904, "per_episode_reward": -197.76, "episode_reward_trend_value": 0.010714048668443372, "biggest_recent_change": 0.6017025352320502},
{"total_number_of_episodes": 2175, "number_of_timesteps": 226194, "per_episode_reward": -198.01, "episode_reward_trend_value": 0.010867596122649086, "biggest_recent_change": 0.6017025352320502},
{"total_number_of_episodes": 2185, "number_of_timesteps": 227415, "per_episode_reward": -197.48, "episode_reward_trend_value": 0.013881916607978282, "biggest_recent_change": 0.6017025352320502},
{"total_number_of_episodes": 2195, "number_of_timesteps": 228684, "per_episode_reward": -197.14, "episode_reward_trend_value": 0.01716948206116216, "biggest_recent_change": 0.6017025352320502},
{"total_number_of_episodes": 2205, "number_of_timesteps": 229702, "per_episode_reward": -197.19, "episode_reward_trend_value": 0.0145603189998888, "biggest_recent_change": 0.6017025352320502},
{"total_number_of_episodes": 2215, "number_of_timesteps": 230646, "per_episode_reward": -195.78, "episode_reward_trend_value": 0.0321248747205058, "biggest_recent_change": 1.4050762105079855},
{"total_number_of_episodes": 2226, "number_of_timesteps": 231580, "per_episode_reward": -195.21, "episode_reward_trend_value": 0.036878588602975056, "biggest_recent_change": 1.4050762105079855},
{"total_number_of_episodes": 2237, "number_of_timesteps": 232553, "per_episode_reward": -194.52, "episode_reward_trend_value": 0.04479774146762831, "biggest_recent_change": 1.4050762105079855},
{"total_number_of_episodes": 2247, "number_of_timesteps": 233561, "per_episode_reward": -194.48, "episode_reward_trend_value": 0.03860106479595452, "biggest_recent_change": 1.4050762105079855},
{"total_number_of_episodes": 2257, "number_of_timesteps": 234688, "per_episode_reward": -195.0, "episode_reward_trend_value": 0.030680737681824943, "biggest_recent_change": 1.4050762105079855},
{"total_number_of_episodes": 2268, "number_of_timesteps": 236036, "per_episode_reward": -195.27, "episode_reward_trend_value": 0.03049390828626631, "biggest_recent_change": 1.4050762105079855},
{"total_number_of_episodes": 2278, "number_of_timesteps": 237427, "per_episode_reward": -195.28, "episode_reward_trend_value": 0.024521234645702192, "biggest_recent_change": 1.4050762105079855},
{"total_number_of_episodes": 2288, "number_of_timesteps": 238439, "per_episode_reward": -194.71, "episode_reward_trend_value": 0.02699413316899779, "biggest_recent_change": 1.4050762105079855},
{"total_number_of_episodes": 2299, "number_of_timesteps": 239509, "per_episode_reward": -193.88, "episode_reward_trend_value": 0.03674521733266134, "biggest_recent_change": 1.4050762105079855},
{"total_number_of_episodes": 2309, "number_of_timesteps": 240454, "per_episode_reward": -193.61, "episode_reward_trend_value": 0.024179355127907344, "biggest_recent_change": 0.8295740847132151},
{"total_number_of_episodes": 2320, "number_of_timesteps": 241766, "per_episode_reward": -193.31, "episode_reward_trend_value": 0.021091976263783684, "biggest_recent_change": 0.8295740847132151},
{"total_number_of_episodes": 2331, "number_of_timesteps": 242893, "per_episode_reward": -192.97, "episode_reward_trend_value": 0.017237467578172527, "biggest_recent_change": 0.8295740847132151},
{"total_number_of_episodes": 2342, "number_of_timesteps": 243961, "per_episode_reward": -192.44, "episode_reward_trend_value": 0.022642359950170506, "biggest_recent_change": 0.8295740847132151},
{"total_number_of_episodes": 2352, "number_of_timesteps": 244984, "per_episode_reward": -191.3, "episode_reward_trend_value": 0.0411292887294034, "biggest_recent_change": 1.1433528391654875},
{"total_number_of_episodes": 2362, "number_of_timesteps": 246077, "per_episode_reward": -190.68, "episode_reward_trend_value": 0.0509608356823779, "biggest_recent_change": 1.1433528391654875},
{"total_number_of_episodes": 2372, "number_of_timesteps": 246950, "per_episode_reward": -190.51, "episode_reward_trend_value": 0.05295561450711735, "biggest_recent_change": 1.1433528391654875},
{"total_number_of_episodes": 2383, "number_of_timesteps": 248129, "per_episode_reward": -190.21, "episode_reward_trend_value": 0.04997791526553057, "biggest_recent_change": 1.1433528391654875},
{"total_number_of_episodes": 2393, "number_of_timesteps": 249098, "per_episode_reward": -189.91, "episode_reward_trend_value": 0.04410471116361016, "biggest_recent_change": 1.1433528391654875},
{"total_number_of_episodes": 2403, "number_of_timesteps": 249977, "per_episode_reward": -188.79, "episode_reward_trend_value": 0.05346812513808806, "biggest_recent_change": 1.1433528391654875},
{"total_number_of_episodes": 2413, "number_of_timesteps": 251081, "per_episode_reward": -188.27, "episode_reward_trend_value": 0.056057400151605444, "biggest_recent_change": 1.1433528391654875},
{"total_number_of_episodes": 2423, "number_of_timesteps": 252129, "per_episode_reward": -187.97, "episode_reward_trend_value": 0.05559489618849859, "biggest_recent_change": 1.1433528391654875},
{"total_number_of_episodes": 2433, "number_of_timesteps": 252875, "per_episode_reward": -187.47, "episode_reward_trend_value": 0.055267202161074794, "biggest_recent_change": 1.1433528391654875},
{"total_number_of_episodes": 2443, "number_of_timesteps": 253846, "per_episode_reward": -186.81, "episode_reward_trend_value": 0.04982746736080357, "biggest_recent_change": 1.1168558697831372},
{"total_number_of_episodes": 2453, "number_of_timesteps": 254934, "per_episode_reward": -186.22, "episode_reward_trend_value": 0.049617846761457765, "biggest_recent_change": 1.1168558697831372},
{"total_number_of_episodes": 2463, "number_of_timesteps": 255944, "per_episode_reward": -185.12, "episode_reward_trend_value": 0.05986805052989817, "biggest_recent_change": 1.1168558697831372},
{"total_number_of_episodes": 2473, "number_of_timesteps": 256982, "per_episode_reward": -184.85, "episode_reward_trend_value": 0.059559510426969574, "biggest_recent_change": 1.1168558697831372},
{"total_number_of_episodes": 2483, "number_of_timesteps": 257825, "per_episode_reward": -184.26, "episode_reward_trend_value": 0.06278897181962356, "biggest_recent_change": 1.1168558697831372},
{"total_number_of_episodes": 2494, "number_of_timesteps": 258986, "per_episode_reward": -184.01, "episode_reward_trend_value": 0.05317548659256899, "biggest_recent_change": 1.0947415555268378},
{"total_number_of_episodes": 2504, "number_of_timesteps": 260311, "per_episode_reward": -183.87, "episode_reward_trend_value": 0.04883312203045212, "biggest_recent_change": 1.0947415555268378},
{"total_number_of_episodes": 2514, "number_of_timesteps": 261547, "per_episode_reward": -183.87, "episode_reward_trend_value": 0.045520935154696456, "biggest_recent_change": 1.0947415555268378},
{"total_number_of_episodes": 2524, "number_of_timesteps": 262563, "per_episode_reward": -183.34, "episode_reward_trend_value": 0.04588961473150069, "biggest_recent_change": 1.0947415555268378},
{"total_number_of_episodes": 2535, "number_of_timesteps": 263662, "per_episode_reward": -182.75, "episode_reward_trend_value": 0.045148991146072605, "biggest_recent_change": 1.0947415555268378},
{"total_number_of_episodes": 2545, "number_of_timesteps": 264909, "per_episode_reward": -182.33, "episode_reward_trend_value": 0.04318747276358642, "biggest_recent_change": 1.0947415555268378},
{"total_number_of_episodes": 2556, "number_of_timesteps": 265928, "per_episode_reward": -181.62, "episode_reward_trend_value": 0.038910232520291604, "biggest_recent_change": 0.7097899336303044},
{"total_number_of_episodes": 2566, "number_of_timesteps": 266803, "per_episode_reward": -181.11, "episode_reward_trend_value": 0.041555962117545656, "biggest_recent_change": 0.7097899336303044},
{"total_number_of_episodes": 2577, "number_of_timesteps": 268042, "per_episode_reward": -180.9, "episode_reward_trend_value": 0.037276108279342184, "biggest_recent_change": 0.7097899336303044},
{"total_number_of_episodes": 2587, "number_of_timesteps": 269356, "per_episode_reward": -181.14, "episode_reward_trend_value": 0.03188065682268189, "biggest_recent_change": 0.7097899336303044},
{"total_number_of_episodes": 2597, "number_of_timesteps": 270461, "per_episode_reward": -181.01, "episode_reward_trend_value": 0.031850911767040836, "biggest_recent_change": 0.7097899336303044},
{"total_number_of_episodes": 2608, "number_of_timesteps": 271804, "per_episode_reward": -180.83, "episode_reward_trend_value": 0.033833300001116284, "biggest_recent_change": 0.7097899336303044},
{"total_number_of_episodes": 2618, "number_of_timesteps": 272808, "per_episode_reward": -180.12, "episode_reward_trend_value": 0.03575211174308777, "biggest_recent_change": 0.7097899336303044},
{"total_number_of_episodes": 2628, "number_of_timesteps": 273891, "per_episode_reward": -179.74, "episode_reward_trend_value": 0.03349216097914949, "biggest_recent_change": 0.7097899336303044},
{"total_number_of_episodes": 2638, "number_of_timesteps": 274612, "per_episode_reward": -179.28, "episode_reward_trend_value": 0.03382652509034219, "biggest_recent_change": 0.7097899336303044},
{"total_number_of_episodes": 2648, "number_of_timesteps": 275418, "per_episode_reward": -178.96, "episode_reward_trend_value": 0.02955379676601208, "biggest_recent_change": 0.7068237044829004},
{"total_number_of_episodes": 2658, "number_of_timesteps": 276298, "per_episode_reward": -178.33, "episode_reward_trend_value": 0.030842938867033036, "biggest_recent_change": 0.7068237044829004},
{"total_number_of_episodes": 2670, "number_of_timesteps": 277660, "per_episode_reward": -178.37, "episode_reward_trend_value": 0.02810692745163092, "biggest_recent_change": 0.7068237044829004},
{"total_number_of_episodes": 2682, "number_of_timesteps": 278904, "per_episode_reward": -177.86, "episode_reward_trend_value": 0.03639251449984644, "biggest_recent_change": 0.7068237044829004},
{"total_number_of_episodes": 2692, "number_of_timesteps": 279586, "per_episode_reward": -177.39, "episode_reward_trend_value": 0.040123975789014645, "biggest_recent_change": 0.7068237044829004},
{"total_number_of_episodes": 2702, "number_of_timesteps": 280449, "per_episode_reward": -176.46, "episode_reward_trend_value": 0.04855976910118487, "biggest_recent_change": 0.9390893610918454},
{"total_number_of_episodes": 2712, "number_of_timesteps": 281738, "per_episode_reward": -176.6, "episode_reward_trend_value": 0.03915850722177904, "biggest_recent_change": 0.9390893610918454},
{"total_number_of_episodes": 2722, "number_of_timesteps": 282546, "per_episode_reward": -175.77, "episode_reward_trend_value": 0.044059840398405624, "biggest_recent_change": 0.9390893610918454},
{"total_number_of_episodes": 2732, "number_of_timesteps": 283350, "per_episode_reward": -175.19, "episode_reward_trend_value": 0.04547505414237428, "biggest_recent_change": 0.9390893610918454},
{"total_number_of_episodes": 2742, "number_of_timesteps": 285225, "per_episode_reward": -174.56, "episode_reward_trend_value": 0.04893026885036136, "biggest_recent_change": 0.9390893610918454},
{"total_number_of_episodes": 2753, "number_of_timesteps": 286409, "per_episode_reward": -174.26, "episode_reward_trend_value": 0.04526896164075127, "biggest_recent_change": 0.9390893610918454},
{"total_number_of_episodes": 2764, "number_of_timesteps": 287891, "per_episode_reward": -173.67, "episode_reward_trend_value": 0.0522202821705207, "biggest_recent_change": 0.9390893610918454},
{"total_number_of_episodes": 2774, "number_of_timesteps": 289011, "per_episode_reward": -173.82, "episode_reward_trend_value": 0.04492993881469008, "biggest_recent_change": 0.9390893610918454},
{"total_number_of_episodes": 2785, "number_of_timesteps": 290473, "per_episode_reward": -173.61, "episode_reward_trend_value": 0.04202861980849914, "biggest_recent_change": 0.9390893610918454},
{"total_number_of_episodes": 2795, "number_of_timesteps": 291510, "per_episode_reward": -173.74, "episode_reward_trend_value": 0.030167501358697123, "biggest_recent_change": 0.8248450015944968},
{"total_number_of_episodes": 2805, "number_of_timesteps": 292920, "per_episode_reward": -173.36, "episode_reward_trend_value": 0.03597735692604292, "biggest_recent_change": 0.8248450015944968},
{"total_number_of_episodes": 2815, "number_of_timesteps": 293914, "per_episode_reward": -173.7, "episode_reward_trend_value": 0.0230354523604575, "biggest_recent_change": 0.6362137081594312},
{"total_number_of_episodes": 2825, "number_of_timesteps": 294759, "per_episode_reward": -173.34, "episode_reward_trend_value": 0.020577792013716588, "biggest_recent_change": 0.6362137081594312},
{"total_number_of_episodes": 2835, "number_of_timesteps": 295772, "per_episode_reward": -173.08, "episode_reward_trend_value": 0.016449968626573903, "biggest_recent_change": 0.5858282157339829},
{"total_number_of_episodes": 2845, "number_of_timesteps": 296915, "per_episode_reward": -173.4, "episode_reward_trend_value": 0.00951074504620269, "biggest_recent_change": 0.5858282157339829},
{"total_number_of_episodes": 2855, "number_of_timesteps": 298355, "per_episode_reward": -172.92, "episode_reward_trend_value": 0.00841302144414821, "biggest_recent_change": 0.4870330915490797},
{"total_number_of_episodes": 2866, "number_of_timesteps": 300061, "per_episode_reward": -172.29, "episode_reward_trend_value": 0.016984039231303743, "biggest_recent_change": 0.6270151014074372},
{"total_number_of_episodes": 2876, "number_of_timesteps": 300987, "per_episode_reward": -171.81, "episode_reward_trend_value": 0.020014303258718277, "biggest_recent_change": 0.6270151014074372},
{"total_number_of_episodes": 2886, "number_of_timesteps": 301862, "per_episode_reward": -170.78, "episode_reward_trend_value": 0.032905332495956445, "biggest_recent_change": 1.0317813319610991},
{"total_number_of_episodes": 2897, "number_of_timesteps": 303041, "per_episode_reward": -170.8, "episode_reward_trend_value": 0.02841098903088866, "biggest_recent_change": 1.0317813319610991},
{"total_number_of_episodes": 2908, "number_of_timesteps": 303990, "per_episode_reward": -169.74, "episode_reward_trend_value": 0.043978283973022614, "biggest_recent_change": 1.0611301354838645},
{"total_number_of_episodes": 2918, "number_of_timesteps": 305033, "per_episode_reward": -169.5, "episode_reward_trend_value": 0.042609907980573146, "biggest_recent_change": 1.0611301354838645},
{"total_number_of_episodes": 2928, "number_of_timesteps": 306151, "per_episode_reward": -170.42, "episode_reward_trend_value": 0.02945633851365225, "biggest_recent_change": 1.0611301354838645},
{"total_number_of_episodes": 2938, "number_of_timesteps": 307137, "per_episode_reward": -170.11, "episode_reward_trend_value": 0.0366408333594115, "biggest_recent_change": 1.0611301354838645},
{"total_number_of_episodes": 2948, "number_of_timesteps": 308105, "per_episode_reward": -168.96, "episode_reward_trend_value": 0.04401470149204083, "biggest_recent_change": 1.1506812234857193},
{"total_number_of_episodes": 2958, "number_of_timesteps": 309231, "per_episode_reward": -168.17, "episode_reward_trend_value": 0.0457390600723468, "biggest_recent_change": 1.1506812234857193},
{"total_number_of_episodes": 2968, "number_of_timesteps": 310627, "per_episode_reward": -168.13, "episode_reward_trend_value": 0.04089640105725386, "biggest_recent_change": 1.1506812234857193},
{"total_number_of_episodes": 2978, "number_of_timesteps": 311970, "per_episode_reward": -167.59, "episode_reward_trend_value": 0.03539997938731132, "biggest_recent_change": 1.1506812234857193},
{"total_number_of_episodes": 2988, "number_of_timesteps": 313997, "per_episode_reward": -167.55, "episode_reward_trend_value": 0.036166009348205345, "biggest_recent_change": 1.1506812234857193},
{"total_number_of_episodes": 2998, "number_of_timesteps": 314905, "per_episode_reward": -167.03, "episode_reward_trend_value": 0.030094710328081142, "biggest_recent_change": 1.1506812234857193},
{"total_number_of_episodes": 3008, "number_of_timesteps": 315993, "per_episode_reward": -167.28, "episode_reward_trend_value": 0.0247376793007561, "biggest_recent_change": 1.1506812234857193},
{"total_number_of_episodes": 3019, "number_of_timesteps": 317330, "per_episode_reward": -167.17, "episode_reward_trend_value": 0.036195020078947794, "biggest_recent_change": 1.1506812234857193},
{"total_number_of_episodes": 3029, "number_of_timesteps": 318475, "per_episode_reward": -167.25, "episode_reward_trend_value": 0.03179299226739829, "biggest_recent_change": 1.1506812234857193},
{"total_number_of_episodes": 3039, "number_of_timesteps": 319576, "per_episode_reward": -167.06, "episode_reward_trend_value": 0.021016708535619148, "biggest_recent_change": 0.7822073736349751},
{"total_number_of_episodes": 3049, "number_of_timesteps": 320663, "per_episode_reward": -167.15, "episode_reward_trend_value": 0.011363562493345587, "biggest_recent_change": 0.5371033816662703},
{"total_number_of_episodes": 3060, "number_of_timesteps": 321995, "per_episode_reward": -167.54, "episode_reward_trend_value": 0.006601793608574111, "biggest_recent_change": 0.5371033816662703},
{"total_number_of_episodes": 3070, "number_of_timesteps": 323407, "per_episode_reward": -166.91, "episode_reward_trend_value": 0.007570298392188748, "biggest_recent_change": 0.6242688121915876},
{"total_number_of_episodes": 3080, "number_of_timesteps": 324586, "per_episode_reward": -166.72, "episode_reward_trend_value": 0.00915630307556196, "biggest_recent_change": 0.6242688121915876},
{"total_number_of_episodes": 3090, "number_of_timesteps": 325749, "per_episode_reward": -166.64, "episode_reward_trend_value": 0.0043641495896641425, "biggest_recent_change": 0.6242688121915876},
{"total_number_of_episodes": 3101, "number_of_timesteps": 326961, "per_episode_reward": -166.35, "episode_reward_trend_value": 0.01036843988035514, "biggest_recent_change": 0.6242688121915876},
{"total_number_of_episodes": 3111, "number_of_timesteps": 327980, "per_episode_reward": -166.35, "episode_reward_trend_value": 0.009123450754455576, "biggest_recent_change": 0.6242688121915876},
{"total_number_of_episodes": 3122, "number_of_timesteps": 329368, "per_episode_reward": -166.43, "episode_reward_trend_value": 0.00906040424494405, "biggest_recent_change": 0.6242688121915876},
{"total_number_of_episodes": 3132, "number_of_timesteps": 330494, "per_episode_reward": -166.92, "episode_reward_trend_value": 0.0016595771711182452, "biggest_recent_change": 0.6242688121915876},
{"total_number_of_episodes": 3144, "number_of_timesteps": 331631, "per_episode_reward": -166.67, "episode_reward_trend_value": 0.005334454535037973, "biggest_recent_change": 0.6242688121915876},
{"total_number_of_episodes": 3154, "number_of_timesteps": 332499, "per_episode_reward": -166.47, "episode_reward_trend_value": 0.011900931808927833, "biggest_recent_change": 0.6242688121915876},
{"total_number_of_episodes": 3164, "number_of_timesteps": 333627, "per_episode_reward": -166.3, "episode_reward_trend_value": 0.006824388173979894, "biggest_recent_change": 0.4852587490187261},
{"total_number_of_episodes": 3174, "number_of_timesteps": 335169, "per_episode_reward": -166.2, "episode_reward_trend_value": 0.005784215265770361, "biggest_recent_change": 0.4852587490187261},
{"total_number_of_episodes": 3184, "number_of_timesteps": 336556, "per_episode_reward": -166.24, "episode_reward_trend_value": 0.004458221143742473, "biggest_recent_change": 0.4852587490187261},
{"total_number_of_episodes": 3194, "number_of_timesteps": 337908, "per_episode_reward": -166.3, "episode_reward_trend_value": 0.0005117438799250825, "biggest_recent_change": 0.4852587490187261},
{"total_number_of_episodes": 3204, "number_of_timesteps": 339163, "per_episode_reward": -166.25, "episode_reward_trend_value": 0.0011032682875284964, "biggest_recent_change": 0.4852587490187261},
{"total_number_of_episodes": 3214, "number_of_timesteps": 340504, "per_episode_reward": -166.37, "episode_reward_trend_value": 0.0006756226220125605, "biggest_recent_change": 0.4852587490187261},
{"total_number_of_episodes": 3224, "number_of_timesteps": 341690, "per_episode_reward": -166.47, "episode_reward_trend_value": 0.004981316401915277, "biggest_recent_change": 0.24416319258313024},
{"total_number_of_episodes": 3234, "number_of_timesteps": 343312, "per_episode_reward": -166.64, "episode_reward_trend_value": 0.00030236406644740374, "biggest_recent_change": 0.20609227975819522},
{"total_number_of_episodes": 3244, "number_of_timesteps": 344444, "per_episode_reward": -166.64, "episode_reward_trend_value": -0.0019620826184118794, "biggest_recent_change": 0.17694251760897828},
{"total_number_of_episodes": 3254, "number_of_timesteps": 345312, "per_episode_reward": -166.28, "episode_reward_trend_value": 0.0002266275345533586, "biggest_recent_change": 0.3643637988131445},
{"total_number_of_episodes": 3264, "number_of_timesteps": 346953, "per_episode_reward": -166.02, "episode_reward_trend_value": 0.0020603283780297314, "biggest_recent_change": 0.3643637988131445},
{"total_number_of_episodes": 3274, "number_of_timesteps": 348542, "per_episode_reward": -166.27, "episode_reward_trend_value": -0.0003336940621289209, "biggest_recent_change": 0.3643637988131445},
{"total_number_of_episodes": 3284, "number_of_timesteps": 349648, "per_episode_reward": -165.89, "episode_reward_trend_value": 0.004579570900348687, "biggest_recent_change": 0.37927772692123085},
{"total_number_of_episodes": 3294, "number_of_timesteps": 350889, "per_episode_reward": -165.78, "episode_reward_trend_value": 0.005200662760644074, "biggest_recent_change": 0.37927772692123085},
{"total_number_of_episodes": 3304, "number_of_timesteps": 351984, "per_episode_reward": -165.55, "episode_reward_trend_value": 0.009092010033640147, "biggest_recent_change": 0.37927772692123085},
{"total_number_of_episodes": 3315, "number_of_timesteps": 352926, "per_episode_reward": -165.33, "episode_reward_trend_value": 0.012580121841241344, "biggest_recent_change": 0.37927772692123085},
{"total_number_of_episodes": 3325, "number_of_timesteps": 353743, "per_episode_reward": -165.06, "episode_reward_trend_value": 0.01757137874150424, "biggest_recent_change": 0.37927772692123085},
{"total_number_of_episodes": 3336, "number_of_timesteps": 354961, "per_episode_reward": -165.02, "episode_reward_trend_value": 0.017977615064362518, "biggest_recent_change": 0.37927772692123085},
{"total_number_of_episodes": 3346, "number_of_timesteps": 356370, "per_episode_reward": -165.28, "episode_reward_trend_value": 0.011120488733624256, "biggest_recent_change": 0.37927772692123085},
{"total_number_of_episodes": 3357, "number_of_timesteps": 357658, "per_episode_reward": -165.1, "episode_reward_trend_value": 0.010116763384799141, "biggest_recent_change": 0.37927772692123085},
{"total_number_of_episodes": 3367, "number_of_timesteps": 358689, "per_episode_reward": -165.04, "episode_reward_trend_value": 0.013637803305322096, "biggest_recent_change": 0.37927772692123085},
{"total_number_of_episodes": 3377, "number_of_timesteps": 359548, "per_episode_reward": -164.47, "episode_reward_trend_value": 0.01570246909910477, "biggest_recent_change": 0.5650976483616716},
{"total_number_of_episodes": 3387, "number_of_timesteps": 360558, "per_episode_reward": -164.23, "episode_reward_trend_value": 0.017190450756776145, "biggest_recent_change": 0.5650976483616716},
{"total_number_of_episodes": 3397, "number_of_timesteps": 361588, "per_episode_reward": -163.93, "episode_reward_trend_value": 0.018037730522354738, "biggest_recent_change": 0.5650976483616716},
{"total_number_of_episodes": 3408, "number_of_timesteps": 362506, "per_episode_reward": -163.58, "episode_reward_trend_value": 0.019523772987747, "biggest_recent_change": 0.5650976483616716},
{"total_number_of_episodes": 3418, "number_of_timesteps": 363624, "per_episode_reward": -163.45, "episode_reward_trend_value": 0.017881019288721392, "biggest_recent_change": 0.5650976483616716},
{"total_number_of_episodes": 3428, "number_of_timesteps": 364782, "per_episode_reward": -163.95, "episode_reward_trend_value": 0.01196705601810019, "biggest_recent_change": 0.5650976483616716},
{"total_number_of_episodes": 3438, "number_of_timesteps": 366389, "per_episode_reward": -163.58, "episode_reward_trend_value": 0.01882384430368644, "biggest_recent_change": 0.5650976483616716},
{"total_number_of_episodes": 3448, "number_of_timesteps": 367480, "per_episode_reward": -163.08, "episode_reward_trend_value": 0.022464959953585308, "biggest_recent_change": 0.5650976483616716},
{"total_number_of_episodes": 3458, "number_of_timesteps": 368347, "per_episode_reward": -162.76, "episode_reward_trend_value": 0.02531377437664541, "biggest_recent_change": 0.5650976483616716},
{"total_number_of_episodes": 3468, "number_of_timesteps": 369592, "per_episode_reward": -162.66, "episode_reward_trend_value": 0.020106896083683524, "biggest_recent_change": 0.4995719837961019},
{"total_number_of_episodes": 3479, "number_of_timesteps": 370959, "per_episode_reward": -162.62, "episode_reward_trend_value": 0.017914754289508197, "biggest_recent_change": 0.4995719837961019},
{"total_number_of_episodes": 3489, "number_of_timesteps": 371991, "per_episode_reward": -162.54, "episode_reward_trend_value": 0.015453715792042999, "biggest_recent_change": 0.4995719837961019},
{"total_number_of_episodes": 3499, "number_of_timesteps": 373047, "per_episode_reward": -162.75, "episode_reward_trend_value": 0.009214528618701933, "biggest_recent_change": 0.4995719837961019},
{"total_number_of_episodes": 3509, "number_of_timesteps": 374396, "per_episode_reward": -162.8, "episode_reward_trend_value": 0.0072921253506055776, "biggest_recent_change": 0.4995719837961019},
{"total_number_of_episodes": 3520, "number_of_timesteps": 375780, "per_episode_reward": -162.62, "episode_reward_trend_value": 0.014793168812384275, "biggest_recent_change": 0.4995719837961019},
{"total_number_of_episodes": 3530, "number_of_timesteps": 376841, "per_episode_reward": -162.66, "episode_reward_trend_value": 0.010248274318344543, "biggest_recent_change": 0.4995719837961019},
{"total_number_of_episodes": 3540, "number_of_timesteps": 377672, "per_episode_reward": -162.41, "episode_reward_trend_value": 0.007510633966739988, "biggest_recent_change": 0.32190481026756856},
{"total_number_of_episodes": 3550, "number_of_timesteps": 378984, "per_episode_reward": -162.53, "episode_reward_trend_value": 0.0026166174084658505, "biggest_recent_change": 0.2531843521516919},
{"total_number_of_episodes": 3561, "number_of_timesteps": 380120, "per_episode_reward": -162.2, "episode_reward_trend_value": 0.005144365928125201, "biggest_recent_change": 0.3239759687644437},
{"total_number_of_episodes": 3572, "number_of_timesteps": 380981, "per_episode_reward": -161.86, "episode_reward_trend_value": 0.008388025805160421, "biggest_recent_change": 0.33769044075870625},
{"total_number_of_episodes": 3582, "number_of_timesteps": 382018, "per_episode_reward": -161.29, "episode_reward_trend_value": 0.013804474307093844, "biggest_recent_change": 0.5693179647576017},
{"total_number_of_episodes": 3593, "number_of_timesteps": 383337, "per_episode_reward": -161.7, "episode_reward_trend_value": 0.011650176017073476, "biggest_recent_change": 0.5693179647576017},
{"total_number_of_episodes": 3604, "number_of_timesteps": 384598, "per_episode_reward": -160.9, "episode_reward_trend_value": 0.02109034580507638, "biggest_recent_change": 0.8010217572939666},
{"total_number_of_episodes": 3615, "number_of_timesteps": 386219, "per_episode_reward": -161.63, "episode_reward_trend_value": 0.010916904111675762, "biggest_recent_change": 0.8010217572939666},
{"total_number_of_episodes": 3625, "number_of_timesteps": 387921, "per_episode_reward": -161.21, "episode_reward_trend_value": 0.016149339615182296, "biggest_recent_change": 0.8010217572939666},
{"total_number_of_episodes": 3635, "number_of_timesteps": 388808, "per_episode_reward": -160.73, "episode_reward_trend_value": 0.018674592117919688, "biggest_recent_change": 0.8010217572939666},
{"total_number_of_episodes": 3645, "number_of_timesteps": 390025, "per_episode_reward": -161.28, "episode_reward_trend_value": 0.01384801857542944, "biggest_recent_change": 0.8010217572939666},
{"total_number_of_episodes": 3655, "number_of_timesteps": 391158, "per_episode_reward": -161.34, "episode_reward_trend_value": 0.009605089845068922, "biggest_recent_change": 0.8010217572939666},
{"total_number_of_episodes": 3665, "number_of_timesteps": 392116, "per_episode_reward": -160.94, "episode_reward_trend_value": 0.010286375309802843, "biggest_recent_change": 0.8010217572939666},
{"total_number_of_episodes": 3675, "number_of_timesteps": 392960, "per_episode_reward": -160.31, "episode_reward_trend_value": 0.01091228156947371, "biggest_recent_change": 0.8010217572939666},
{"total_number_of_episodes": 3685, "number_of_timesteps": 394312, "per_episode_reward": -160.35, "episode_reward_trend_value": 0.01495975288805861, "biggest_recent_change": 0.8010217572939666},
{"total_number_of_episodes": 3696, "number_of_timesteps": 395524, "per_episode_reward": -160.35, "episode_reward_trend_value": 0.006102375679349356, "biggest_recent_change": 0.7339191880237763},
{"total_number_of_episodes": 3706, "number_of_timesteps": 396654, "per_episode_reward": -160.5, "episode_reward_trend_value": 0.012619926618221988, "biggest_recent_change": 0.6256495281279797},
{"total_number_of_episodes": 3716, "number_of_timesteps": 397734, "per_episode_reward": -160.04, "episode_reward_trend_value": 0.012972939314428483, "biggest_recent_change": 0.6256495281279797},
{"total_number_of_episodes": 3726, "number_of_timesteps": 398570, "per_episode_reward": -159.71, "episode_reward_trend_value": 0.011282675897450644, "biggest_recent_change": 0.6256495281279797},
{"total_number_of_episodes": 3736, "number_of_timesteps": 399381, "per_episode_reward": -159.54, "episode_reward_trend_value": 0.01927260625069683, "biggest_recent_change": 0.6256495281279797},
{"total_number_of_episodes": 3746, "number_of_timesteps": 400350, "per_episode_reward": -159.47, "episode_reward_trend_value": 0.02075529856248453, "biggest_recent_change": 0.6256495281279797},
{"total_number_of_episodes": 3757, "number_of_timesteps": 401498, "per_episode_reward": -159.41, "episode_reward_trend_value": 0.01697984290874596, "biggest_recent_change": 0.6256495281279797},
{"total_number_of_episodes": 3768, "number_of_timesteps": 402906, "per_episode_reward": -159.4, "episode_reward_trend_value": 0.010157562621323122, "biggest_recent_change": 0.45798320826006034},
{"total_number_of_episodes": 3778, "number_of_timesteps": 404147, "per_episode_reward": -159.23, "episode_reward_trend_value": 0.01251664602284816, "biggest_recent_change": 0.45798320826006034},
{"total_number_of_episodes": 3788, "number_of_timesteps": 405327, "per_episode_reward": -159.08, "episode_reward_trend_value": 0.014097588996736793, "biggest_recent_change": 0.45798320826006034},
{"total_number_of_episodes": 3798, "number_of_timesteps": 406486, "per_episode_reward": -158.74, "episode_reward_trend_value": 0.019495668829581328, "biggest_recent_change": 0.45798320826006034},
{"total_number_of_episodes": 3808, "number_of_timesteps": 407819, "per_episode_reward": -158.31, "episode_reward_trend_value": 0.01921535251109895, "biggest_recent_change": 0.43275473959664623},
{"total_number_of_episodes": 3819, "number_of_timesteps": 408723, "per_episode_reward": -157.89, "episode_reward_trend_value": 0.020206371386045578, "biggest_recent_change": 0.43275473959664623},
{"total_number_of_episodes": 3830, "number_of_timesteps": 409660, "per_episode_reward": -157.68, "episode_reward_trend_value": 0.02071679560342956, "biggest_recent_change": 0.43275473959664623},
{"total_number_of_episodes": 3842, "number_of_timesteps": 411013, "per_episode_reward": -157.7, "episode_reward_trend_value": 0.019706333478273073, "biggest_recent_change": 0.43275473959664623},
{"total_number_of_episodes": 3852, "number_of_timesteps": 412348, "per_episode_reward": -157.82, "episode_reward_trend_value": 0.017627506237002107, "biggest_recent_change": 0.43275473959664623},
{"total_number_of_episodes": 3862, "number_of_timesteps": 413361, "per_episode_reward": -157.91, "episode_reward_trend_value": 0.016528954046522257, "biggest_recent_change": 0.43275473959664623},
{"total_number_of_episodes": 3873, "number_of_timesteps": 414185, "per_episode_reward": -157.45, "episode_reward_trend_value": 0.019732983169907924, "biggest_recent_change": 0.45946642995400566},
{"total_number_of_episodes": 3883, "number_of_timesteps": 415058, "per_episode_reward": -157.26, "episode_reward_trend_value": 0.020229231174798835, "biggest_recent_change": 0.45946642995400566},
{"total_number_of_episodes": 3893, "number_of_timesteps": 416072, "per_episode_reward": -157.16, "episode_reward_trend_value": 0.017560371848680097, "biggest_recent_change": 0.45946642995400566},
{"total_number_of_episodes": 3903, "number_of_timesteps": 417053, "per_episode_reward": -157.1, "episode_reward_trend_value": 0.013429204313250884, "biggest_recent_change": 0.45946642995400566},
{"total_number_of_episodes": 3913, "number_of_timesteps": 417827, "per_episode_reward": -156.43, "episode_reward_trend_value": 0.01624995182820991, "biggest_recent_change": 0.6713923449615606},
{"total_number_of_episodes": 3923, "number_of_timesteps": 418778, "per_episode_reward": -156.35, "episode_reward_trend_value": 0.014782561406275995, "biggest_recent_change": 0.6713923449615606},
{"total_number_of_episodes": 3933, "number_of_timesteps": 420641, "per_episode_reward": -156.46, "episode_reward_trend_value": 0.013738195206249137, "biggest_recent_change": 0.6713923449615606},
{"total_number_of_episodes": 3943, "number_of_timesteps": 421939, "per_episode_reward": -156.31, "episode_reward_trend_value": 0.016859692953611078, "biggest_recent_change": 0.6713923449615606},
{"total_number_of_episodes": 3953, "number_of_timesteps": 423123, "per_episode_reward": -156.23, "episode_reward_trend_value": 0.018616598957972505, "biggest_recent_change": 0.6713923449615606},
{"total_number_of_episodes": 3963, "number_of_timesteps": 424419, "per_episode_reward": -156.16, "episode_reward_trend_value": 0.014390512536234861, "biggest_recent_change": 0.6713923449615606},
{"total_number_of_episodes": 3973, "number_of_timesteps": 425626, "per_episode_reward": -156.53, "episode_reward_trend_value": 0.00815653371518642, "biggest_recent_change": 0.6713923449615606},
{"total_number_of_episodes": 3985, "number_of_timesteps": 427001, "per_episode_reward": -156.36, "episode_reward_trend_value": 0.008862068265162924, "biggest_recent_change": 0.6713923449615606},
{"total_number_of_episodes": 3996, "number_of_timesteps": 428470, "per_episode_reward": -156.49, "episode_reward_trend_value": 0.006758802791253199, "biggest_recent_change": 0.6713923449615606},
{"total_number_of_episodes": 4006, "number_of_timesteps": 429644, "per_episode_reward": -156.47, "episode_reward_trend_value": -0.00047365909042614224, "biggest_recent_change": 0.37025309729406786},
{"total_number_of_episodes": 4016, "number_of_timesteps": 431440, "per_episode_reward": -156.69, "episode_reward_trend_value": -0.003819371628862692, "biggest_recent_change": 0.37025309729406786},
{"total_number_of_episodes": 4026, "number_of_timesteps": 432467, "per_episode_reward": -156.89, "episode_reward_trend_value": -0.004738516724648574, "biggest_recent_change": 0.37025309729406786},
{"total_number_of_episodes": 4038, "number_of_timesteps": 433695, "per_episode_reward": -156.1, "episode_reward_trend_value": 0.002311952250207759, "biggest_recent_change": 0.7875976770335456},
{"total_number_of_episodes": 4048, "number_of_timesteps": 434822, "per_episode_reward": -155.88, "episode_reward_trend_value": 0.003921861191599558, "biggest_recent_change": 0.7875976770335456},
{"total_number_of_episodes": 4058, "number_of_timesteps": 436131, "per_episode_reward": -156.15, "episode_reward_trend_value": 6.300298846832044e-05, "biggest_recent_change": 0.7875976770335456},
{"total_number_of_episodes": 4068, "number_of_timesteps": 437255, "per_episode_reward": -155.95, "episode_reward_trend_value": 0.006402795990839157, "biggest_recent_change": 0.7875976770335456},
{"total_number_of_episodes": 4078, "number_of_timesteps": 438441, "per_episode_reward": -155.96, "episode_reward_trend_value": 0.004491392070704276, "biggest_recent_change": 0.7875976770335456},
{"total_number_of_episodes": 4088, "number_of_timesteps": 439546, "per_episode_reward": -156.06, "episode_reward_trend_value": 0.004753940993533155, "biggest_recent_change": 0.7875976770335456},
{"total_number_of_episodes": 4098, "number_of_timesteps": 440786, "per_episode_reward": -155.81, "episode_reward_trend_value": 0.007405515419265878, "biggest_recent_change": 0.7875976770335456},
{"total_number_of_episodes": 4110, "number_of_timesteps": 441932, "per_episode_reward": -155.67, "episode_reward_trend_value": 0.01136806935645988, "biggest_recent_change": 0.7875976770335456},
{"total_number_of_episodes": 4121, "number_of_timesteps": 443119, "per_episode_reward": -155.68, "episode_reward_trend_value": 0.013361466416948057, "biggest_recent_change": 0.7875976770335456},
{"total_number_of_episodes": 4131, "number_of_timesteps": 444321, "per_episode_reward": -155.42, "episode_reward_trend_value": 0.007490691075211152, "biggest_recent_change": 0.26817858628419344},
{"total_number_of_episodes": 4141, "number_of_timesteps": 445572, "per_episode_reward": -155.65, "episode_reward_trend_value": 0.0026032236695752117, "biggest_recent_change": 0.26817858628419344},
{"total_number_of_episodes": 4151, "number_of_timesteps": 446610, "per_episode_reward": -155.76, "episode_reward_trend_value": 0.004310405811381202, "biggest_recent_change": 0.2592278962772241},
{"total_number_of_episodes": 4161, "number_of_timesteps": 447588, "per_episode_reward": -155.73, "episode_reward_trend_value": 0.002403846215708288, "biggest_recent_change": 0.2592278962772241},
{"total_number_of_episodes": 4172, "number_of_timesteps": 448921, "per_episode_reward": -156.07, "episode_reward_trend_value": -0.0011865883240283715, "biggest_recent_change": 0.33337710981047053},
{"total_number_of_episodes": 4182, "number_of_timesteps": 450269, "per_episode_reward": -156.3, "episode_reward_trend_value": -0.0026394463766346615, "biggest_recent_change": 0.33337710981047053},
{"total_number_of_episodes": 4194, "number_of_timesteps": 451711, "per_episode_reward": -155.83, "episode_reward_trend_value": -0.0003236020099453501, "biggest_recent_change": 0.46753846692840284},
{"total_number_of_episodes": 4204, "number_of_timesteps": 453002, "per_episode_reward": -155.8, "episode_reward_trend_value": -0.001496037149541015, "biggest_recent_change": 0.46753846692840284},
{"total_number_of_episodes": 4214, "number_of_timesteps": 454273, "per_episode_reward": -155.76, "episode_reward_trend_value": -0.0008975103540223017, "biggest_recent_change": 0.46753846692840284},
{"total_number_of_episodes": 4224, "number_of_timesteps": 455928, "per_episode_reward": -155.77, "episode_reward_trend_value": -0.003818364321286241, "biggest_recent_change": 0.46753846692840284},
{"total_number_of_episodes": 4234, "number_of_timesteps": 456958, "per_episode_reward": -155.24, "episode_reward_trend_value": 0.004581336090959098, "biggest_recent_change": 0.531888920829374},
{"total_number_of_episodes": 4244, "number_of_timesteps": 457904, "per_episode_reward": -155.26, "episode_reward_trend_value": 0.0056169167487332234, "biggest_recent_change": 0.531888920829374},
{"total_number_of_episodes": 4254, "number_of_timesteps": 459019, "per_episode_reward": -155.04, "episode_reward_trend_value": 0.0076866954080881235, "biggest_recent_change": 0.531888920829374},
{"total_number_of_episodes": 4264, "number_of_timesteps": 460257, "per_episode_reward": -154.6, "episode_reward_trend_value": 0.01630163401722863, "biggest_recent_change": 0.531888920829374},
{"total_number_of_episodes": 4274, "number_of_timesteps": 461218, "per_episode_reward": -154.82, "episode_reward_trend_value": 0.016442017062269405, "biggest_recent_change": 0.531888920829374},
{"total_number_of_episodes": 4284, "number_of_timesteps": 462297, "per_episode_reward": -154.58, "episode_reward_trend_value": 0.013887869134969972, "biggest_recent_change": 0.531888920829374},
{"total_number_of_episodes": 4294, "number_of_timesteps": 463310, "per_episode_reward": -154.24, "episode_reward_trend_value": 0.017422304118997544, "biggest_recent_change": 0.531888920829374},
{"total_number_of_episodes": 4304, "number_of_timesteps": 464573, "per_episode_reward": -154.54, "episode_reward_trend_value": 0.01357121889846869, "biggest_recent_change": 0.531888920829374},
{"total_number_of_episodes": 4315, "number_of_timesteps": 465747, "per_episode_reward": -154.58, "episode_reward_trend_value": 0.013140242815101524, "biggest_recent_change": 0.531888920829374},
{"total_number_of_episodes": 4325, "number_of_timesteps": 466893, "per_episode_reward": -154.31, "episode_reward_trend_value": 0.010305452578662274, "biggest_recent_change": 0.44196736501217515},
{"total_number_of_episodes": 4335, "number_of_timesteps": 468003, "per_episode_reward": -154.23, "episode_reward_trend_value": 0.01141582021387377, "biggest_recent_change": 0.44196736501217515},
{"total_number_of_episodes": 4345, "number_of_timesteps": 469212, "per_episode_reward": -153.65, "episode_reward_trend_value": 0.015472628655576337, "biggest_recent_change": 0.5801307484039171},
{"total_number_of_episodes": 4355, "number_of_timesteps": 470180, "per_episode_reward": -153.22, "episode_reward_trend_value": 0.01529492767148655, "biggest_recent_change": 0.5801307484039171},
{"total_number_of_episodes": 4365, "number_of_timesteps": 471238, "per_episode_reward": -153.06, "episode_reward_trend_value": 0.019576926214584015, "biggest_recent_change": 0.5801307484039171},
{"total_number_of_episodes": 4376, "number_of_timesteps": 472288, "per_episode_reward": -152.84, "episode_reward_trend_value": 0.019389542810185706, "biggest_recent_change": 0.5801307484039171},
{"total_number_of_episodes": 4386, "number_of_timesteps": 473468, "per_episode_reward": -152.79, "episode_reward_trend_value": 0.01605439704994593, "biggest_recent_change": 0.5801307484039171},
{"total_number_of_episodes": 4396, "number_of_timesteps": 474601, "per_episode_reward": -152.87, "episode_reward_trend_value": 0.018614870301875423, "biggest_recent_change": 0.5801307484039171},
{"total_number_of_episodes": 4406, "number_of_timesteps": 475802, "per_episode_reward": -153.45, "episode_reward_trend_value": 0.012622117484168093, "biggest_recent_change": 0.5817845618732349},
{"total_number_of_episodes": 4416, "number_of_timesteps": 477076, "per_episode_reward": -153.83, "episode_reward_trend_value": 0.005353926022471948, "biggest_recent_change": 0.5817845618732349},
{"total_number_of_episodes": 4426, "number_of_timesteps": 478644, "per_episode_reward": -154.25, "episode_reward_trend_value": -0.00024943828102045196, "biggest_recent_change": 0.5817845618732349},
{"total_number_of_episodes": 4436, "number_of_timesteps": 479721, "per_episode_reward": -155.02, "episode_reward_trend_value": -0.015235703080474472, "biggest_recent_change": 0.7686330835469448},
{"total_number_of_episodes": 4446, "number_of_timesteps": 480855, "per_episode_reward": -154.81, "episode_reward_trend_value": -0.01763385347607564, "biggest_recent_change": 0.7686330835469448},
{"total_number_of_episodes": 4456, "number_of_timesteps": 481849, "per_episode_reward": -154.68, "episode_reward_trend_value": -0.01804609572146679, "biggest_recent_change": 0.7686330835469448},
{"total_number_of_episodes": 4466, "number_of_timesteps": 482840, "per_episode_reward": -154.35, "episode_reward_trend_value": -0.016753523353720982, "biggest_recent_change": 0.7686330835469448},
{"total_number_of_episodes": 4476, "number_of_timesteps": 483854, "per_episode_reward": -154.04, "episode_reward_trend_value": -0.013840682633920664, "biggest_recent_change": 0.7686330835469448},
{"total_number_of_episodes": 4486, "number_of_timesteps": 484875, "per_episode_reward": -153.66, "episode_reward_trend_value": -0.00886408411486741, "biggest_recent_change": 0.7686330835469448},
{"total_number_of_episodes": 4496, "number_of_timesteps": 485876, "per_episode_reward": -153.59, "episode_reward_trend_value": -0.0015180922147853457, "biggest_recent_change": 0.7686330835469448},
{"total_number_of_episodes": 4506, "number_of_timesteps": 486936, "per_episode_reward": -153.24, "episode_reward_trend_value": 0.006505498131702818, "biggest_recent_change": 0.7686330835469448},
{"total_number_of_episodes": 4516, "number_of_timesteps": 488205, "per_episode_reward": -153.28, "episode_reward_trend_value": 0.010782289450358779, "biggest_recent_change": 0.7686330835469448},
{"total_number_of_episodes": 4526, "number_of_timesteps": 488981, "per_episode_reward": -153.03, "episode_reward_trend_value": 0.022156564321554446, "biggest_recent_change": 0.3729090197871301},
{"total_number_of_episodes": 4536, "number_of_timesteps": 489877, "per_episode_reward": -152.79, "episode_reward_trend_value": 0.0224452804442652, "biggest_recent_change": 0.3729090197871301},
{"total_number_of_episodes": 4546, "number_of_timesteps": 490810, "per_episode_reward": -152.7, "episode_reward_trend_value": 0.022017641788873256, "biggest_recent_change": 0.3729090197871301},
{"total_number_of_episodes": 4556, "number_of_timesteps": 491815, "per_episode_reward": -152.05, "episode_reward_trend_value": 0.025514342029316593, "biggest_recent_change": 0.6518351818126291},
{"total_number_of_episodes": 4567, "number_of_timesteps": 493043, "per_episode_reward": -152.02, "episode_reward_trend_value": 0.022373889432272323, "biggest_recent_change": 0.6518351818126291},
{"total_number_of_episodes": 4577, "number_of_timesteps": 494143, "per_episode_reward": -152.02, "episode_reward_trend_value": 0.018277193180302083, "biggest_recent_change": 0.6518351818126291},
{"total_number_of_episodes": 4587, "number_of_timesteps": 495528, "per_episode_reward": -151.66, "episode_reward_trend_value": 0.021382378331883466, "biggest_recent_change": 0.6518351818126291},
{"total_number_of_episodes": 4598, "number_of_timesteps": 496680, "per_episode_reward": -151.57, "episode_reward_trend_value": 0.018568547847930165, "biggest_recent_change": 0.6518351818126291},
{"total_number_of_episodes": 4608, "number_of_timesteps": 497978, "per_episode_reward": -151.83, "episode_reward_trend_value": 0.016156938687797783, "biggest_recent_change": 0.6518351818126291},
{"total_number_of_episodes": 4619, "number_of_timesteps": 499305, "per_episode_reward": -151.88, "episode_reward_trend_value": 0.012777629376262528, "biggest_recent_change": 0.6518351818126291},
{"total_number_of_episodes": 4629, "number_of_timesteps": 500886, "per_episode_reward": -151.79, "episode_reward_trend_value": 0.01112518261398255, "biggest_recent_change": 0.6518351818126291},
{"total_number_of_episodes": 4640, "number_of_timesteps": 502288, "per_episode_reward": -151.9, "episode_reward_trend_value": 0.00892687981318324, "biggest_recent_change": 0.6518351818126291},
{"total_number_of_episodes": 4650, "number_of_timesteps": 503551, "per_episode_reward": -151.88, "episode_reward_trend_value": 0.0018920070912214568, "biggest_recent_change": 0.3588213727764753},
{"total_number_of_episodes": 4661, "number_of_timesteps": 504512, "per_episode_reward": -151.82, "episode_reward_trend_value": 0.0022112682759575994, "biggest_recent_change": 0.3588213727764753},
{"total_number_of_episodes": 4671, "number_of_timesteps": 505445, "per_episode_reward": -151.51, "episode_reward_trend_value": 0.00562209383897962, "biggest_recent_change": 0.3588213727764753},
{"total_number_of_episodes": 4681, "number_of_timesteps": 506512, "per_episode_reward": -151.43, "episode_reward_trend_value": 0.0025750828035897813, "biggest_recent_change": 0.31118065778179016},
{"total_number_of_episodes": 4691, "number_of_timesteps": 507668, "per_episode_reward": -151.34, "episode_reward_trend_value": 0.0025235320591125146, "biggest_recent_change": 0.31118065778179016},
{"total_number_of_episodes": 4702, "number_of_timesteps": 508751, "per_episode_reward": -151.17, "episode_reward_trend_value": 0.007309509135942626, "biggest_recent_change": 0.31118065778179016},
{"total_number_of_episodes": 4712, "number_of_timesteps": 509838, "per_episode_reward": -150.74, "episode_reward_trend_value": 0.012647331976649589, "biggest_recent_change": 0.43131787248611886},
{"total_number_of_episodes": 4722, "number_of_timesteps": 511656, "per_episode_reward": -150.73, "episode_reward_trend_value": 0.011744952036964504, "biggest_recent_change": 0.43131787248611886},
{"total_number_of_episodes": 4733, "number_of_timesteps": 512914, "per_episode_reward": -151.28, "episode_reward_trend_value": 0.006925617059754233, "biggest_recent_change": 0.5446343910827238},
{"total_number_of_episodes": 4743, "number_of_timesteps": 513705, "per_episode_reward": -150.31, "episode_reward_trend_value": 0.017413869076497373, "biggest_recent_change": 0.9626393183429514},
{"total_number_of_episodes": 4753, "number_of_timesteps": 514554, "per_episode_reward": -150.17, "episode_reward_trend_value": 0.01834191665021573, "biggest_recent_change": 0.9626393183429514},
{"total_number_of_episodes": 4763, "number_of_timesteps": 515641, "per_episode_reward": -150.17, "episode_reward_trend_value": 0.014935439321454977, "biggest_recent_change": 0.9626393183429514},
{"total_number_of_episodes": 4773, "number_of_timesteps": 516425, "per_episode_reward": -149.95, "episode_reward_trend_value": 0.016470157440019763, "biggest_recent_change": 0.9626393183429514},
{"total_number_of_episodes": 4784, "number_of_timesteps": 517684, "per_episode_reward": -149.76, "episode_reward_trend_value": 0.017626274808560854, "biggest_recent_change": 0.9626393183429514},
{"total_number_of_episodes": 4794, "number_of_timesteps": 518963, "per_episode_reward": -149.75, "episode_reward_trend_value": 0.015793929154540996, "biggest_recent_change": 0.9626393183429514},
{"total_number_of_episodes": 4804, "number_of_timesteps": 520321, "per_episode_reward": -149.77, "episode_reward_trend_value": 0.010750400921002917, "biggest_recent_change": 0.9626393183429514},
{"total_number_of_episodes": 4814, "number_of_timesteps": 521344, "per_episode_reward": -150.03, "episode_reward_trend_value": 0.00781564797379733, "biggest_recent_change": 0.9626393183429514},
{"total_number_of_episodes": 4824, "number_of_timesteps": 522755, "per_episode_reward": -150.17, "episode_reward_trend_value": 0.01224648028478599, "biggest_recent_change": 0.9626393183429514},
{"total_number_of_episodes": 4834, "number_of_timesteps": 523983, "per_episode_reward": -150.36, "episode_reward_trend_value": -0.0004806178970198971, "biggest_recent_change": 0.25793697654140146},
{"total_number_of_episodes": 4844, "number_of_timesteps": 525047, "per_episode_reward": -150.09, "episode_reward_trend_value": 0.0009286347204080257, "biggest_recent_change": 0.26655652292436116},
{"total_number_of_episodes": 4854, "number_of_timesteps": 526279, "per_episode_reward": -150.04, "episode_reward_trend_value": 0.0014250144185884513, "biggest_recent_change": 0.26655652292436116},
{"total_number_of_episodes": 4864, "number_of_timesteps": 527366, "per_episode_reward": -150.13, "episode_reward_trend_value": -0.002053284194358677, "biggest_recent_change": 0.26655652292436116},
{"total_number_of_episodes": 4875, "number_of_timesteps": 528461, "per_episode_reward": -149.93, "episode_reward_trend_value": -0.0019064108020504338, "biggest_recent_change": 0.26655652292436116},
{"total_number_of_episodes": 4887, "number_of_timesteps": 529420, "per_episode_reward": -149.67, "episode_reward_trend_value": 0.0008440877125034755, "biggest_recent_change": 0.26655652292436116},
{"total_number_of_episodes": 4897, "number_of_timesteps": 530473, "per_episode_reward": -149.42, "episode_reward_trend_value": 0.003876284156663701, "biggest_recent_change": 0.26655652292436116},
{"total_number_of_episodes": 4908, "number_of_timesteps": 531867, "per_episode_reward": -149.41, "episode_reward_trend_value": 0.00683262446877835, "biggest_recent_change": 0.26655652292436116},
{"total_number_of_episodes": 4918, "number_of_timesteps": 532920, "per_episode_reward": -149.26, "episode_reward_trend_value": 0.010178315372860108, "biggest_recent_change": 0.26655652292436116},
{"total_number_of_episodes": 4928, "number_of_timesteps": 533927, "per_episode_reward": -149.3, "episode_reward_trend_value": 0.011793177286552412, "biggest_recent_change": 0.26655652292436116},
{"total_number_of_episodes": 4939, "number_of_timesteps": 535545, "per_episode_reward": -149.41, "episode_reward_trend_value": 0.0076003523948729584, "biggest_recent_change": 0.25553845416263243},
{"total_number_of_episodes": 4949, "number_of_timesteps": 536458, "per_episode_reward": -149.33, "episode_reward_trend_value": 0.007932357629769626, "biggest_recent_change": 0.25553845416263243},
{"total_number_of_episodes": 4959, "number_of_timesteps": 537701, "per_episode_reward": -149.48, "episode_reward_trend_value": 0.0072259454619973615, "biggest_recent_change": 0.25553845416263243},
{"total_number_of_episodes": 4970, "number_of_timesteps": 538805, "per_episode_reward": -149.15, "episode_reward_trend_value": 0.0086184572232993, "biggest_recent_change": 0.32945461561598677},
{"total_number_of_episodes": 4981, "number_of_timesteps": 539946, "per_episode_reward": -148.81, "episode_reward_trend_value": 0.009593277186262602, "biggest_recent_change": 0.34327225082932955},
{"total_number_of_episodes": 4991, "number_of_timesteps": 541021, "per_episode_reward": -148.82, "episode_reward_trend_value": 0.0066904227553878735, "biggest_recent_change": 0.34327225082932955},
{"total_number_of_episodes": 5001, "number_of_timesteps": 542280, "per_episode_reward": -148.67, "episode_reward_trend_value": 0.00829148989708699, "biggest_recent_change": 0.34327225082932955},
{"total_number_of_episodes": 5012, "number_of_timesteps": 543910, "per_episode_reward": -148.88, "episode_reward_trend_value": 0.004174667151188297, "biggest_recent_change": 0.34327225082932955},
{"total_number_of_episodes": 5023, "number_of_timesteps": 545153, "per_episode_reward": -148.68, "episode_reward_trend_value": 0.0068272159488300425, "biggest_recent_change": 0.34327225082932955},
{"total_number_of_episodes": 5034, "number_of_timesteps": 546133, "per_episode_reward": -148.54, "episode_reward_trend_value": 0.009598882482563277, "biggest_recent_change": 0.34327225082932955},
{"total_number_of_episodes": 5044, "number_of_timesteps": 546978, "per_episode_reward": -147.89, "episode_reward_trend_value": 0.015974410308837467, "biggest_recent_change": 0.6529498465349377},
{"total_number_of_episodes": 5054, "number_of_timesteps": 547775, "per_episode_reward": -147.72, "episode_reward_trend_value": 0.019581122040416846, "biggest_recent_change": 0.6529498465349377},
{"total_number_of_episodes": 5064, "number_of_timesteps": 548835, "per_episode_reward": -147.78, "episode_reward_trend_value": 0.015246373914213981, "biggest_recent_change": 0.6529498465349377},
{"total_number_of_episodes": 5074, "number_of_timesteps": 550494, "per_episode_reward": -148.06, "episode_reward_trend_value": 0.008320560324865294, "biggest_recent_change": 0.6529498465349377},
{"total_number_of_episodes": 5085, "number_of_timesteps": 551554, "per_episode_reward": -147.31, "episode_reward_trend_value": 0.016783142566095283, "biggest_recent_change": 0.7506735143740855},
{"total_number_of_episodes": 5095, "number_of_timesteps": 552487, "per_episode_reward": -147.15, "episode_reward_trend_value": 0.01687104156013485, "biggest_recent_change": 0.7506735143740855},
{"total_number_of_episodes": 5106, "number_of_timesteps": 553459, "per_episode_reward": -147.03, "episode_reward_trend_value": 0.020611123812065875, "biggest_recent_change": 0.7506735143740855},
{"total_number_of_episodes": 5116, "number_of_timesteps": 554561, "per_episode_reward": -147.07, "episode_reward_trend_value": 0.0178739995361266, "biggest_recent_change": 0.7506735143740855},
{"total_number_of_episodes": 5126, "number_of_timesteps": 555548, "per_episode_reward": -147.0, "episode_reward_trend_value": 0.017132390679912155, "biggest_recent_change": 0.7506735143740855},
{"total_number_of_episodes": 5138, "number_of_timesteps": 556651, "per_episode_reward": -146.98, "episode_reward_trend_value": 0.010152208748061121, "biggest_recent_change": 0.7506735143740855},
{"total_number_of_episodes": 5150, "number_of_timesteps": 557806, "per_episode_reward": -146.9, "episode_reward_trend_value": 0.009089517579842424, "biggest_recent_change": 0.7506735143740855},
{"total_number_of_episodes": 5160, "number_of_timesteps": 558985, "per_episode_reward": -146.76, "episode_reward_trend_value": 0.01137160752594563, "biggest_recent_change": 0.7506735143740855},
{"total_number_of_episodes": 5172, "number_of_timesteps": 560169, "per_episode_reward": -146.63, "episode_reward_trend_value": 0.01585975099596434, "biggest_recent_change": 0.7506735143740855},
{"total_number_of_episodes": 5182, "number_of_timesteps": 561211, "per_episode_reward": -146.53, "episode_reward_trend_value": 0.00869347574203232, "biggest_recent_change": 0.16014060376539874},
{"total_number_of_episodes": 5193, "number_of_timesteps": 562680, "per_episode_reward": -146.36, "episode_reward_trend_value": 0.008781418959814699, "biggest_recent_change": 0.16805549336581294},
{"total_number_of_episodes": 5203, "number_of_timesteps": 563945, "per_episode_reward": -146.36, "episode_reward_trend_value": 0.007468205550305622, "biggest_recent_change": 0.16805549336581294},
{"total_number_of_episodes": 5213, "number_of_timesteps": 565176, "per_episode_reward": -146.42, "episode_reward_trend_value": 0.007214292438639329, "biggest_recent_change": 0.16805549336581294},
{"total_number_of_episodes": 5223, "number_of_timesteps": 566279, "per_episode_reward": -146.4, "episode_reward_trend_value": 0.006718908453060774, "biggest_recent_change": 0.16805549336581294},
{"total_number_of_episodes": 5233, "number_of_timesteps": 567428, "per_episode_reward": -146.32, "episode_reward_trend_value": 0.007277337119890287, "biggest_recent_change": 0.16805549336581294},
{"total_number_of_episodes": 5245, "number_of_timesteps": 568605, "per_episode_reward": -146.15, "episode_reward_trend_value": 0.008298617525350476, "biggest_recent_change": 0.16805549336581294},
{"total_number_of_episodes": 5255, "number_of_timesteps": 569728, "per_episode_reward": -146.07, "episode_reward_trend_value": 0.007613125883743363, "biggest_recent_change": 0.16805549336581294},
{"total_number_of_episodes": 5265, "number_of_timesteps": 571304, "per_episode_reward": -145.93, "episode_reward_trend_value": 0.007785774895528322, "biggest_recent_change": 0.16805549336581294},
{"total_number_of_episodes": 5276, "number_of_timesteps": 572291, "per_episode_reward": -146.0, "episode_reward_trend_value": 0.005832536903083173, "biggest_recent_change": 0.16805549336581294},
{"total_number_of_episodes": 5286, "number_of_timesteps": 573266, "per_episode_reward": -145.97, "episode_reward_trend_value": 0.004294699130733508, "biggest_recent_change": 0.16696812719135323},
{"total_number_of_episodes": 5296, "number_of_timesteps": 574307, "per_episode_reward": -145.76, "episode_reward_trend_value": 0.006632179040889241, "biggest_recent_change": 0.21353003887472255},
{"total_number_of_episodes": 5308, "number_of_timesteps": 575501, "per_episode_reward": -145.74, "episode_reward_trend_value": 0.007616690108253642, "biggest_recent_change": 0.21353003887472255},
{"total_number_of_episodes": 5318, "number_of_timesteps": 576397, "per_episode_reward": -145.57, "episode_reward_trend_value": 0.009152034072984191, "biggest_recent_change": 0.21353003887472255},
{"total_number_of_episodes": 5328, "number_of_timesteps": 577463, "per_episode_reward": -145.35, "episode_reward_trend_value": 0.010799852041033217, "biggest_recent_change": 0.22329566980741333},
{"total_number_of_episodes": 5339, "number_of_timesteps": 578654, "per_episode_reward": -144.48, "episode_reward_trend_value": 0.018647189856124808, "biggest_recent_change": 0.8732285305495964},
{"total_number_of_episodes": 5349, "number_of_timesteps": 579792, "per_episode_reward": -144.35, "episode_reward_trend_value": 0.019167345114048988, "biggest_recent_change": 0.8732285305495964},
{"total_number_of_episodes": 5359, "number_of_timesteps": 580848, "per_episode_reward": -144.16, "episode_reward_trend_value": 0.019680491193516836, "biggest_recent_change": 0.8732285305495964},
{"total_number_of_episodes": 5369, "number_of_timesteps": 581624, "per_episode_reward": -144.03, "episode_reward_trend_value": 0.021886204866186178, "biggest_recent_change": 0.8732285305495964},
{"total_number_of_episodes": 5380, "number_of_timesteps": 582896, "per_episode_reward": -143.74, "episode_reward_trend_value": 0.024820515559381483, "biggest_recent_change": 0.8732285305495964},
{"total_number_of_episodes": 5390, "number_of_timesteps": 583736, "per_episode_reward": -143.46, "episode_reward_trend_value": 0.02553946352503513, "biggest_recent_change": 0.8732285305495964},
{"total_number_of_episodes": 5400, "number_of_timesteps": 584540, "per_episode_reward": -143.05, "episode_reward_trend_value": 0.029870755282269103, "biggest_recent_change": 0.8732285305495964},
{"total_number_of_episodes": 5410, "number_of_timesteps": 585376, "per_episode_reward": -143.0, "episode_reward_trend_value": 0.02859922650479771, "biggest_recent_change": 0.8732285305495964},
{"total_number_of_episodes": 5420, "number_of_timesteps": 586638, "per_episode_reward": -142.97, "episode_reward_trend_value": 0.026477090342363063, "biggest_recent_change": 0.8732285305495964},
{"total_number_of_episodes": 5430, "number_of_timesteps": 587787, "per_episode_reward": -142.94, "episode_reward_trend_value": 0.017083635365177152, "biggest_recent_change": 0.41049633532983876},
{"total_number_of_episodes": 5440, "number_of_timesteps": 589178, "per_episode_reward": -143.02, "episode_reward_trend_value": 0.014734648755293733, "biggest_recent_change": 0.41049633532983876},
{"total_number_of_episodes": 5450, "number_of_timesteps": 590424, "per_episode_reward": -142.87, "episode_reward_trend_value": 0.014346561013809378, "biggest_recent_change": 0.41049633532983876},
{"total_number_of_episodes": 5460, "number_of_timesteps": 591629, "per_episode_reward": -142.73, "episode_reward_trend_value": 0.01442013701650732, "biggest_recent_change": 0.41049633532983876},
{"total_number_of_episodes": 5470, "number_of_timesteps": 592946, "per_episode_reward": -142.88, "episode_reward_trend_value": 0.009567090299980426, "biggest_recent_change": 0.41049633532983876},
{"total_number_of_episodes": 5481, "number_of_timesteps": 594512, "per_episode_reward": -142.84, "episode_reward_trend_value": 0.006862900377879555, "biggest_recent_change": 0.41049633532983876},
{"total_number_of_episodes": 5491, "number_of_timesteps": 595617, "per_episode_reward": -142.79, "episode_reward_trend_value": 0.002911898090019665, "biggest_recent_change": 0.15067560156879267},
{"total_number_of_episodes": 5501, "number_of_timesteps": 596965, "per_episode_reward": -142.67, "episode_reward_trend_value": 0.003609697784862457, "biggest_recent_change": 0.15067560156879267},
{"total_number_of_episodes": 5511, "number_of_timesteps": 597924, "per_episode_reward": -142.58, "episode_reward_trend_value": 0.004331247901289556, "biggest_recent_change": 0.15067560156879267},
{"total_number_of_episodes": 5521, "number_of_timesteps": 599184, "per_episode_reward": -142.56, "episode_reward_trend_value": 0.004181690722371753, "biggest_recent_change": 0.15067560156879267},
{"total_number_of_episodes": 5531, "number_of_timesteps": 600367, "per_episode_reward": -142.59, "episode_reward_trend_value": 0.004765079063643737, "biggest_recent_change": 0.15067560156879267},
{"total_number_of_episodes": 5541, "number_of_timesteps": 601406, "per_episode_reward": -142.44, "episode_reward_trend_value": 0.004730592550089657, "biggest_recent_change": 0.14757181534892538},
{"total_number_of_episodes": 5552, "number_of_timesteps": 602469, "per_episode_reward": -142.37, "episode_reward_trend_value": 0.004092616657639622, "biggest_recent_change": 0.14757181534892538},
{"total_number_of_episodes": 5562, "number_of_timesteps": 603584, "per_episode_reward": -142.36, "episode_reward_trend_value": 0.005768317682382139, "biggest_recent_change": 0.14757181534892538},
{"total_number_of_episodes": 5572, "number_of_timesteps": 604666, "per_episode_reward": -142.28, "episode_reward_trend_value": 0.006297094430895653, "biggest_recent_change": 0.14757181534892538},
{"total_number_of_episodes": 5582, "number_of_timesteps": 606061, "per_episode_reward": -142.37, "episode_reward_trend_value": 0.00465397312014362, "biggest_recent_change": 0.14757181534892538},
{"total_number_of_episodes": 5594, "number_of_timesteps": 607603, "per_episode_reward": -142.32, "episode_reward_trend_value": 0.0038893660882365565, "biggest_recent_change": 0.14757181534892538},
{"total_number_of_episodes": 5604, "number_of_timesteps": 608781, "per_episode_reward": -142.36, "episode_reward_trend_value": 0.0024082154335872017, "biggest_recent_change": 0.14757181534892538},
{"total_number_of_episodes": 5615, "number_of_timesteps": 609824, "per_episode_reward": -142.25, "episode_reward_trend_value": 0.0035062768605131273, "biggest_recent_change": 0.14757181534892538},
{"total_number_of_episodes": 5625, "number_of_timesteps": 611288, "per_episode_reward": -142.23, "episode_reward_trend_value": 0.003992795953510293, "biggest_recent_change": 0.14757181534892538},
{"total_number_of_episodes": 5635, "number_of_timesteps": 612634, "per_episode_reward": -142.11, "episode_reward_trend_value": 0.0037113738609917844, "biggest_recent_change": 0.12224382702225967},
{"total_number_of_episodes": 5645, "number_of_timesteps": 613566, "per_episode_reward": -142.12, "episode_reward_trend_value": 0.0027339411691627903, "biggest_recent_change": 0.12224382702225967},
{"total_number_of_episodes": 5656, "number_of_timesteps": 614800, "per_episode_reward": -142.15, "episode_reward_trend_value": 0.002363115901646514, "biggest_recent_change": 0.12224382702225967},
{"total_number_of_episodes": 5668, "number_of_timesteps": 616150, "per_episode_reward": -142.14, "episode_reward_trend_value": 0.0015287916724736937, "biggest_recent_change": 0.12224382702225967},
{"total_number_of_episodes": 5678, "number_of_timesteps": 617433, "per_episode_reward": -142.12, "episode_reward_trend_value": 0.0027078160146841255, "biggest_recent_change": 0.12224382702225967},
{"total_number_of_episodes": 5688, "number_of_timesteps": 618820, "per_episode_reward": -142.05, "episode_reward_trend_value": 0.003019314622636671, "biggest_recent_change": 0.12224382702225967},
{"total_number_of_episodes": 5698, "number_of_timesteps": 620341, "per_episode_reward": -142.07, "episode_reward_trend_value": 0.0031815036424723705, "biggest_recent_change": 0.12224382702225967},
{"total_number_of_episodes": 5708, "number_of_timesteps": 621542, "per_episode_reward": -141.91, "episode_reward_trend_value": 0.0037864379705676277, "biggest_recent_change": 0.16762705445216852},
{"total_number_of_episodes": 5718, "number_of_timesteps": 622829, "per_episode_reward": -141.9, "episode_reward_trend_value": 0.003679695157496591, "biggest_recent_change": 0.16762705445216852},
{"total_number_of_episodes": 5728, "number_of_timesteps": 624365, "per_episode_reward": -142.07, "episode_reward_trend_value": 0.00047440374769552006, "biggest_recent_change": 0.16762705445216852},
{"total_number_of_episodes": 5738, "number_of_timesteps": 626477, "per_episode_reward": -142.14, "episode_reward_trend_value": -0.0002574787410897746, "biggest_recent_change": 0.16762705445216852},
{"total_number_of_episodes": 5748, "number_of_timesteps": 627240, "per_episode_reward": -141.99, "episode_reward_trend_value": 0.001723489130460128, "biggest_recent_change": 0.16762705445216852},
{"total_number_of_episodes": 5758, "number_of_timesteps": 628090, "per_episode_reward": -141.82, "episode_reward_trend_value": 0.0035484342339973155, "biggest_recent_change": 0.17160404885348157},
{"total_number_of_episodes": 5769, "number_of_timesteps": 629598, "per_episode_reward": -141.68, "episode_reward_trend_value": 0.004981782111316749, "biggest_recent_change": 0.17160404885348157},
{"total_number_of_episodes": 5779, "number_of_timesteps": 630904, "per_episode_reward": -141.52, "episode_reward_trend_value": 0.005954813147935864, "biggest_recent_change": 0.17160404885348157},
{"total_number_of_episodes": 5789, "number_of_timesteps": 632530, "per_episode_reward": -141.63, "episode_reward_trend_value": 0.0049040346633720195, "biggest_recent_change": 0.17160404885348157},
{"total_number_of_episodes": 5799, "number_of_timesteps": 633609, "per_episode_reward": -141.33, "episode_reward_trend_value": 0.006433755150903646, "biggest_recent_change": 0.30530189833001486},
{"total_number_of_episodes": 5809, "number_of_timesteps": 634878, "per_episode_reward": -141.28, "episode_reward_trend_value": 0.006845095447136235, "biggest_recent_change": 0.30530189833001486},
{"total_number_of_episodes": 5819, "number_of_timesteps": 636200, "per_episode_reward": -141.12, "episode_reward_trend_value": 0.010572801886231924, "biggest_recent_change": 0.30530189833001486},
{"total_number_of_episodes": 5829, "number_of_timesteps": 637372, "per_episode_reward": -141.02, "episode_reward_trend_value": 0.012421553151837215, "biggest_recent_change": 0.30530189833001486},
{"total_number_of_episodes": 5839, "number_of_timesteps": 638528, "per_episode_reward": -141.02, "episode_reward_trend_value": 0.010769851412775071, "biggest_recent_change": 0.30530189833001486},
{"total_number_of_episodes": 5851, "number_of_timesteps": 640203, "per_episode_reward": -141.07, "episode_reward_trend_value": 0.008290249871678649, "biggest_recent_change": 0.30530189833001486},
{"total_number_of_episodes": 5861, "number_of_timesteps": 641272, "per_episode_reward": -140.97, "episode_reward_trend_value": 0.007855086110079254, "biggest_recent_change": 0.30530189833001486},
{"total_number_of_episodes": 5872, "number_of_timesteps": 642932, "per_episode_reward": -140.44, "episode_reward_trend_value": 0.011930070983711655, "biggest_recent_change": 0.5274099281037365},
{"total_number_of_episodes": 5883, "number_of_timesteps": 644064, "per_episode_reward": -140.27, "episode_reward_trend_value": 0.015157401284730554, "biggest_recent_change": 0.5274099281037365},
{"total_number_of_episodes": 5894, "number_of_timesteps": 645505, "per_episode_reward": -140.32, "episode_reward_trend_value": 0.011177545418554915, "biggest_recent_change": 0.5274099281037365},
{"total_number_of_episodes": 5904, "number_of_timesteps": 646503, "per_episode_reward": -139.97, "episode_reward_trend_value": 0.014603029973228368, "biggest_recent_change": 0.5274099281037365},
{"total_number_of_episodes": 5914, "number_of_timesteps": 647760, "per_episode_reward": -139.93, "episode_reward_trend_value": 0.013158036193894735, "biggest_recent_change": 0.5274099281037365},
{"total_number_of_episodes": 5924, "number_of_timesteps": 649293, "per_episode_reward": -139.66, "episode_reward_trend_value": 0.015133962484262676, "biggest_recent_change": 0.5274099281037365},
{"total_number_of_episodes": 5934, "number_of_timesteps": 650481, "per_episode_reward": -139.22, "episode_reward_trend_value": 0.019992236202691062, "biggest_recent_change": 0.5274099281037365},
{"total_number_of_episodes": 5944, "number_of_timesteps": 651281, "per_episode_reward": -138.98, "episode_reward_trend_value": 0.02325333575712294, "biggest_recent_change": 0.5274099281037365},
{"total_number_of_episodes": 5954, "number_of_timesteps": 652187, "per_episode_reward": -138.66, "episode_reward_trend_value": 0.02561241562551181, "biggest_recent_change": 0.5274099281037365},
{"total_number_of_episodes": 5964, "number_of_timesteps": 653252, "per_episode_reward": -138.55, "episode_reward_trend_value": 0.021045133331968675, "biggest_recent_change": 0.441281256487315},
{"total_number_of_episodes": 5974, "number_of_timesteps": 654283, "per_episode_reward": -138.51, "episode_reward_trend_value": 0.019474376058292997, "biggest_recent_change": 0.441281256487315},
{"total_number_of_episodes": 5984, "number_of_timesteps": 655366, "per_episode_reward": -138.39, "episode_reward_trend_value": 0.021402613628211813, "biggest_recent_change": 0.441281256487315},
{"total_number_of_episodes": 5994, "number_of_timesteps": 656548, "per_episode_reward": -138.17, "episode_reward_trend_value": 0.020038569958480128, "biggest_recent_change": 0.441281256487315},
{"total_number_of_episodes": 6004, "number_of_timesteps": 658028, "per_episode_reward": -137.95, "episode_reward_trend_value": 0.022027269392304382, "biggest_recent_change": 0.441281256487315},
{"total_number_of_episodes": 6014, "number_of_timesteps": 659460, "per_episode_reward": -137.88, "episode_reward_trend_value": 0.019806258546716686, "biggest_recent_change": 0.441281256487315},
{"total_number_of_episodes": 6026, "number_of_timesteps": 660383, "per_episode_reward": -137.57, "episode_reward_trend_value": 0.0183484991387085, "biggest_recent_change": 0.31529116082350583},
{"total_number_of_episodes": 6037, "number_of_timesteps": 661218, "per_episode_reward": -137.38, "episode_reward_trend_value": 0.0178094731274039, "biggest_recent_change": 0.31529116082350583},
{"total_number_of_episodes": 6047, "number_of_timesteps": 662151, "per_episode_reward": -137.12, "episode_reward_trend_value": 0.017185124417228317, "biggest_recent_change": 0.31008290976657804},
{"total_number_of_episodes": 6057, "number_of_timesteps": 663204, "per_episode_reward": -136.79, "episode_reward_trend_value": 0.019499007993728255, "biggest_recent_change": 0.32460404356984895},
{"total_number_of_episodes": 6068, "number_of_timesteps": 664054, "per_episode_reward": -136.62, "episode_reward_trend_value": 0.021020312446502012, "biggest_recent_change": 0.32460404356984895},
{"total_number_of_episodes": 6078, "number_of_timesteps": 665084, "per_episode_reward": -136.48, "episode_reward_trend_value": 0.021247915689762132, "biggest_recent_change": 0.32460404356984895},
{"total_number_of_episodes": 6089, "number_of_timesteps": 667611, "per_episode_reward": -136.64, "episode_reward_trend_value": 0.016981396123692448, "biggest_recent_change": 0.32460404356984895},
{"total_number_of_episodes": 6099, "number_of_timesteps": 668997, "per_episode_reward": -136.34, "episode_reward_trend_value": 0.01786623961812034, "biggest_recent_change": 0.32460404356984895},
{"total_number_of_episodes": 6109, "number_of_timesteps": 670140, "per_episode_reward": -136.32, "episode_reward_trend_value": 0.017333557901729555, "biggest_recent_change": 0.32460404356984895},
{"total_number_of_episodes": 6119, "number_of_timesteps": 671425, "per_episode_reward": -135.86, "episode_reward_trend_value": 0.01894983028622682, "biggest_recent_change": 0.455547424371332},
{"total_number_of_episodes": 6130, "number_of_timesteps": 672489, "per_episode_reward": -135.67, "episode_reward_trend_value": 0.01898393979525679, "biggest_recent_change": 0.455547424371332},
{"total_number_of_episodes": 6140, "number_of_timesteps": 673314, "per_episode_reward": -135.36, "episode_reward_trend_value": 0.01949729712283891, "biggest_recent_change": 0.455547424371332},
{"total_number_of_episodes": 6152, "number_of_timesteps": 674462, "per_episode_reward": -135.12, "episode_reward_trend_value": 0.018546715111465537, "biggest_recent_change": 0.455547424371332},
{"total_number_of_episodes": 6162, "number_of_timesteps": 675509, "per_episode_reward": -134.91, "episode_reward_trend_value": 0.019061831155871938, "biggest_recent_change": 0.455547424371332},
{"total_number_of_episodes": 6172, "number_of_timesteps": 676680, "per_episode_reward": -134.62, "episode_reward_trend_value": 0.02073198584521789, "biggest_recent_change": 0.455547424371332},
{"total_number_of_episodes": 6184, "number_of_timesteps": 678196, "per_episode_reward": -134.44, "episode_reward_trend_value": 0.02447739870131361, "biggest_recent_change": 0.455547424371332},
{"total_number_of_episodes": 6194, "number_of_timesteps": 679281, "per_episode_reward": -134.26, "episode_reward_trend_value": 0.023105317846619754, "biggest_recent_change": 0.455547424371332},
{"total_number_of_episodes": 6205, "number_of_timesteps": 680363, "per_episode_reward": -134.07, "episode_reward_trend_value": 0.024992981661393465, "biggest_recent_change": 0.455547424371332},
{"total_number_of_episodes": 6216, "number_of_timesteps": 681519, "per_episode_reward": -133.85, "episode_reward_trend_value": 0.022434885161582464, "biggest_recent_change": 0.3053019363900944},
{"total_number_of_episodes": 6226, "number_of_timesteps": 682792, "per_episode_reward": -133.74, "episode_reward_trend_value": 0.021468807902314462, "biggest_recent_change": 0.3053019363900944},
{"total_number_of_episodes": 6236, "number_of_timesteps": 684053, "per_episode_reward": -133.7, "episode_reward_trend_value": 0.01849921475293286, "biggest_recent_change": 0.29145446560144705},
{"total_number_of_episodes": 6247, "number_of_timesteps": 685100, "per_episode_reward": -133.63, "episode_reward_trend_value": 0.01659979143103227, "biggest_recent_change": 0.29145446560144705},
{"total_number_of_episodes": 6257, "number_of_timesteps": 686233, "per_episode_reward": -133.47, "episode_reward_trend_value": 0.01591884230956598, "biggest_recent_change": 0.29145446560144705},
{"total_number_of_episodes": 6267, "number_of_timesteps": 687317, "per_episode_reward": -133.33, "episode_reward_trend_value": 0.014273001729894316, "biggest_recent_change": 0.22531873938834224},
{"total_number_of_episodes": 6277, "number_of_timesteps": 688301, "per_episode_reward": -133.18, "episode_reward_trend_value": 0.013911855291775372, "biggest_recent_change": 0.22531873938834224},
{"total_number_of_episodes": 6287, "number_of_timesteps": 689438, "per_episode_reward": -133.04, "episode_reward_trend_value": 0.01351861248947191, "biggest_recent_change": 0.22531873938834224},
{"total_number_of_episodes": 6297, "number_of_timesteps": 690798, "per_episode_reward": -133.0, "episode_reward_trend_value": 0.011934078157921767, "biggest_recent_change": 0.22531873938834224},
{"total_number_of_episodes": 6308, "number_of_timesteps": 692548, "per_episode_reward": -132.81, "episode_reward_trend_value": 0.011490676762205807, "biggest_recent_change": 0.18541261377390583},
{"total_number_of_episodes": 6318, "number_of_timesteps": 694081, "per_episode_reward": -132.82, "episode_reward_trend_value": 0.01022469792755108, "biggest_recent_change": 0.18541261377390583},
{"total_number_of_episodes": 6328, "number_of_timesteps": 695822, "per_episode_reward": -132.63, "episode_reward_trend_value": 0.01181167455684652, "biggest_recent_change": 0.18541261377390583},
{"total_number_of_episodes": 6339, "number_of_timesteps": 697362, "per_episode_reward": -132.46, "episode_reward_trend_value": 0.012968501481189618, "biggest_recent_change": 0.18541261377390583},
{"total_number_of_episodes": 6349, "number_of_timesteps": 698241, "per_episode_reward": -132.27, "episode_reward_trend_value": 0.013374715404091514, "biggest_recent_change": 0.1916095642590676},
{"total_number_of_episodes": 6359, "number_of_timesteps": 699306, "per_episode_reward": -132.18, "episode_reward_trend_value": 0.012795987562551481, "biggest_recent_change": 0.1916095642590676},
{"total_number_of_episodes": 6370, "number_of_timesteps": 700513, "per_episode_reward": -132.04, "episode_reward_trend_value": 0.012697625941995878, "biggest_recent_change": 0.1916095642590676},
{"total_number_of_episodes": 6381, "number_of_timesteps": 701726, "per_episode_reward": -132.02, "episode_reward_trend_value": 0.011412451592849492, "biggest_recent_change": 0.1916095642590676},
{"total_number_of_episodes": 6391, "number_of_timesteps": 703330, "per_episode_reward": -131.93, "episode_reward_trend_value": 0.011799091279653517, "biggest_recent_change": 0.1916095642590676},
{"total_number_of_episodes": 6402, "number_of_timesteps": 704896, "per_episode_reward": -131.85, "episode_reward_trend_value": 0.010705756006432744, "biggest_recent_change": 0.1916095642590676},
{"total_number_of_episodes": 6412, "number_of_timesteps": 706697, "per_episode_reward": -131.6, "episode_reward_trend_value": 0.01347775338086371, "biggest_recent_change": 0.24509110009469737},
{"total_number_of_episodes": 6422, "number_of_timesteps": 707675, "per_episode_reward": -131.43, "episode_reward_trend_value": 0.013423145177533988, "biggest_recent_change": 0.24509110009469737},
{"total_number_of_episodes": 6432, "number_of_timesteps": 708574, "per_episode_reward": -131.27, "episode_reward_trend_value": 0.01328642721741081, "biggest_recent_change": 0.24509110009469737},
{"total_number_of_episodes": 6442, "number_of_timesteps": 709635, "per_episode_reward": -131.05, "episode_reward_trend_value": 0.013545588241451708, "biggest_recent_change": 0.24509110009469737},
{"total_number_of_episodes": 6454, "number_of_timesteps": 710769, "per_episode_reward": -130.71, "episode_reward_trend_value": 0.01627955219725834, "biggest_recent_change": 0.33730006371499144},
{"total_number_of_episodes": 6465, "number_of_timesteps": 711812, "per_episode_reward": -130.51, "episode_reward_trend_value": 0.016985954097249432, "biggest_recent_change": 0.33730006371499144},
{"total_number_of_episodes": 6475, "number_of_timesteps": 712871, "per_episode_reward": -130.36, "episode_reward_trend_value": 0.01840395519328979, "biggest_recent_change": 0.33730006371499144},
{"total_number_of_episodes": 6485, "number_of_timesteps": 713988, "per_episode_reward": -130.34, "episode_reward_trend_value": 0.017716377957145507, "biggest_recent_change": 0.33730006371499144},
{"total_number_of_episodes": 6495, "number_of_timesteps": 715166, "per_episode_reward": -130.22, "episode_reward_trend_value": 0.018094207869667873, "biggest_recent_change": 0.33730006371499144},
{"total_number_of_episodes": 6506, "number_of_timesteps": 716138, "per_episode_reward": -129.67, "episode_reward_trend_value": 0.021478336590596177, "biggest_recent_change": 0.5496626849782444},
{"total_number_of_episodes": 6517, "number_of_timesteps": 717221, "per_episode_reward": -129.48, "episode_reward_trend_value": 0.02161950273298443, "biggest_recent_change": 0.5496626849782444},
{"total_number_of_episodes": 6527, "number_of_timesteps": 718186, "per_episode_reward": -129.3, "episode_reward_trend_value": 0.02180102191173761, "biggest_recent_change": 0.5496626849782444},
{"total_number_of_episodes": 6537, "number_of_timesteps": 719340, "per_episode_reward": -129.04, "episode_reward_trend_value": 0.022308329230993865, "biggest_recent_change": 0.5496626849782444},
{"total_number_of_episodes": 6547, "number_of_timesteps": 720175, "per_episode_reward": -128.94, "episode_reward_trend_value": 0.019756206534731292, "biggest_recent_change": 0.5496626849782444},
{"total_number_of_episodes": 6557, "number_of_timesteps": 721339, "per_episode_reward": -128.85, "episode_reward_trend_value": 0.01843969241714755, "biggest_recent_change": 0.5496626849782444},
{"total_number_of_episodes": 6567, "number_of_timesteps": 722366, "per_episode_reward": -128.6, "episode_reward_trend_value": 0.01959315303805877, "biggest_recent_change": 0.5496626849782444},
{"total_number_of_episodes": 6577, "number_of_timesteps": 723463, "per_episode_reward": -128.39, "episode_reward_trend_value": 0.021661443463194197, "biggest_recent_change": 0.5496626849782444},
{"total_number_of_episodes": 6588, "number_of_timesteps": 724995, "per_episode_reward": -128.34, "episode_reward_trend_value": 0.020908914414754853, "biggest_recent_change": 0.5496626849782444},
{"total_number_of_episodes": 6598, "number_of_timesteps": 725914, "per_episode_reward": -128.21, "episode_reward_trend_value": 0.016199115331698977, "biggest_recent_change": 0.2605917151558117},
{"total_number_of_episodes": 6609, "number_of_timesteps": 727111, "per_episode_reward": -128.1, "episode_reward_trend_value": 0.01537097531761194, "biggest_recent_change": 0.2605917151558117},
{"total_number_of_episodes": 6619, "number_of_timesteps": 728109, "per_episode_reward": -127.79, "episode_reward_trend_value": 0.016799755471524395, "biggest_recent_change": 0.30484031029489245},
{"total_number_of_episodes": 6629, "number_of_timesteps": 729115, "per_episode_reward": -127.59, "episode_reward_trend_value": 0.01612251393423144, "biggest_recent_change": 0.30484031029489245},
{"total_number_of_episodes": 6639, "number_of_timesteps": 730321, "per_episode_reward": -127.47, "episode_reward_trend_value": 0.016248882789753023, "biggest_recent_change": 0.30484031029489245},
{"total_number_of_episodes": 6650, "number_of_timesteps": 731632, "per_episode_reward": -127.42, "episode_reward_trend_value": 0.015879079557990394, "biggest_recent_change": 0.30484031029489245},
{"total_number_of_episodes": 6660, "number_of_timesteps": 732880, "per_episode_reward": -127.45, "episode_reward_trend_value": 0.012781994253643505, "biggest_recent_change": 0.30484031029489245},
{"total_number_of_episodes": 6670, "number_of_timesteps": 734358, "per_episode_reward": -127.31, "episode_reward_trend_value": 0.01196724945249138, "biggest_recent_change": 0.30484031029489245},
{"total_number_of_episodes": 6680, "number_of_timesteps": 735552, "per_episode_reward": -127.22, "episode_reward_trend_value": 0.01236814098976977, "biggest_recent_change": 0.30484031029489245},
{"total_number_of_episodes": 6690, "number_of_timesteps": 736618, "per_episode_reward": -127.1, "episode_reward_trend_value": 0.012334296900879355, "biggest_recent_change": 0.30484031029489245},
{"total_number_of_episodes": 6701, "number_of_timesteps": 737749, "per_episode_reward": -126.92, "episode_reward_trend_value": 0.01304494792995238, "biggest_recent_change": 0.30484031029489245},
{"total_number_of_episodes": 6711, "number_of_timesteps": 738725, "per_episode_reward": -126.57, "episode_reward_trend_value": 0.01356861772771983, "biggest_recent_change": 0.35197059209396286},
{"total_number_of_episodes": 6721, "number_of_timesteps": 739974, "per_episode_reward": -126.47, "episode_reward_trend_value": 0.012476434299118466, "biggest_recent_change": 0.35197059209396286},
{"total_number_of_episodes": 6731, "number_of_timesteps": 741000, "per_episode_reward": -126.34, "episode_reward_trend_value": 0.01259201712557143, "biggest_recent_change": 0.35197059209396286},
{"total_number_of_episodes": 6741, "number_of_timesteps": 741897, "per_episode_reward": -126.27, "episode_reward_trend_value": 0.012762654120128206, "biggest_recent_change": 0.35197059209396286},
{"total_number_of_episodes": 6751, "number_of_timesteps": 742938, "per_episode_reward": -126.01, "episode_reward_trend_value": 0.0159671322830857, "biggest_recent_change": 0.35197059209396286},
{"total_number_of_episodes": 6761, "number_of_timesteps": 743868, "per_episode_reward": -125.72, "episode_reward_trend_value": 0.017666774674223184, "biggest_recent_change": 0.35197059209396286},
{"total_number_of_episodes": 6771, "number_of_timesteps": 744675, "per_episode_reward": -125.58, "episode_reward_trend_value": 0.01825425382155967, "biggest_recent_change": 0.35197059209396286},
{"total_number_of_episodes": 6781, "number_of_timesteps": 745907, "per_episode_reward": -125.44, "episode_reward_trend_value": 0.018462527204197464, "biggest_recent_change": 0.35197059209396286},
{"total_number_of_episodes": 6791, "number_of_timesteps": 746901, "per_episode_reward": -125.31, "episode_reward_trend_value": 0.017976299421919053, "biggest_recent_change": 0.35197059209396286},
{"total_number_of_episodes": 6801, "number_of_timesteps": 748026, "per_episode_reward": -125.17, "episode_reward_trend_value": 0.015584354717283273, "biggest_recent_change": 0.28617004127730183},
{"total_number_of_episodes": 6811, "number_of_timesteps": 749165, "per_episode_reward": -125.03, "episode_reward_trend_value": 0.015949078436132108, "biggest_recent_change": 0.28617004127730183},
{"total_number_of_episodes": 6823, "number_of_timesteps": 750181, "per_episode_reward": -124.5, "episode_reward_trend_value": 0.020499696471974006, "biggest_recent_change": 0.5389402956548395},
{"total_number_of_episodes": 6835, "number_of_timesteps": 751159, "per_episode_reward": -123.94, "episode_reward_trend_value": 0.025967758752212928, "biggest_recent_change": 0.558696647310839},
{"total_number_of_episodes": 6845, "number_of_timesteps": 751924, "per_episode_reward": -123.75, "episode_reward_trend_value": 0.025092038174105054, "biggest_recent_change": 0.558696647310839},
{"total_number_of_episodes": 6856, "number_of_timesteps": 752876, "per_episode_reward": -123.62, "episode_reward_trend_value": 0.023424701714617413, "biggest_recent_change": 0.558696647310839},
{"total_number_of_episodes": 6868, "number_of_timesteps": 753870, "per_episode_reward": -123.47, "episode_reward_trend_value": 0.023486742258258492, "biggest_recent_change": 0.558696647310839},
{"total_number_of_episodes": 6878, "number_of_timesteps": 754867, "per_episode_reward": -123.32, "episode_reward_trend_value": 0.023573734763188588, "biggest_recent_change": 0.558696647310839},
{"total_number_of_episodes": 6888, "number_of_timesteps": 755742, "per_episode_reward": -123.05, "episode_reward_trend_value": 0.025080792902428883, "biggest_recent_change": 0.558696647310839},
{"total_number_of_episodes": 6898, "number_of_timesteps": 756969, "per_episode_reward": -122.96, "episode_reward_trend_value": 0.02455615127319801, "biggest_recent_change": 0.558696647310839},
{"total_number_of_episodes": 6908, "number_of_timesteps": 757957, "per_episode_reward": -122.33, "episode_reward_trend_value": 0.0301085579213754, "biggest_recent_change": 0.6338852012576837},
{"total_number_of_episodes": 6919, "number_of_timesteps": 758894, "per_episode_reward": -122.2, "episode_reward_trend_value": 0.02547782273718424, "biggest_recent_change": 0.6338852012576837},
{"total_number_of_episodes": 6930, "number_of_timesteps": 759783, "per_episode_reward": -121.92, "episode_reward_trend_value": 0.02239541260398773, "biggest_recent_change": 0.6338852012576837},
{"total_number_of_episodes": 6940, "number_of_timesteps": 760696, "per_episode_reward": -121.69, "episode_reward_trend_value": 0.022865598558769466, "biggest_recent_change": 0.6338852012576837},
{"total_number_of_episodes": 6950, "number_of_timesteps": 761523, "per_episode_reward": -121.58, "episode_reward_trend_value": 0.022633119327119606, "biggest_recent_change": 0.6338852012576837},
{"total_number_of_episodes": 6960, "number_of_timesteps": 762525, "per_episode_reward": -121.45, "episode_reward_trend_value": 0.022431822442635824, "biggest_recent_change": 0.6338852012576837},
{"total_number_of_episodes": 6970, "number_of_timesteps": 763507, "per_episode_reward": -121.32, "episode_reward_trend_value": 0.02219648853014762, "biggest_recent_change": 0.6338852012576837},
{"total_number_of_episodes": 6980, "number_of_timesteps": 764366, "per_episode_reward": -121.07, "episode_reward_trend_value": 0.021982104834234108, "biggest_recent_change": 0.6338852012576837},
{"total_number_of_episodes": 6991, "number_of_timesteps": 765315, "per_episode_reward": -120.87, "episode_reward_trend_value": 0.02317922312842392, "biggest_recent_change": 0.6338852012576837},
{"total_number_of_episodes": 7002, "number_of_timesteps": 766463, "per_episode_reward": -120.7, "episode_reward_trend_value": 0.01809014789508344, "biggest_recent_change": 0.2812797353231531},
{"total_number_of_episodes": 7012, "number_of_timesteps": 767422, "per_episode_reward": -120.51, "episode_reward_trend_value": 0.01886211612257114, "biggest_recent_change": 0.2812797353231531},
{"total_number_of_episodes": 7022, "number_of_timesteps": 768537, "per_episode_reward": -120.39, "episode_reward_trend_value": 0.017032869561619337, "biggest_recent_change": 0.25066285494069973},
{"total_number_of_episodes": 7033, "number_of_timesteps": 769879, "per_episode_reward": -120.11, "episode_reward_trend_value": 0.017544988911244275, "biggest_recent_change": 0.27397531967599775},
{"total_number_of_episodes": 7043, "number_of_timesteps": 771057, "per_episode_reward": -119.94, "episode_reward_trend_value": 0.018202361767153896, "biggest_recent_change": 0.27397531967599775},
{"total_number_of_episodes": 7053, "number_of_timesteps": 772232, "per_episode_reward": -119.74, "episode_reward_trend_value": 0.019025628645460792, "biggest_recent_change": 0.27397531967599775},
{"total_number_of_episodes": 7064, "number_of_timesteps": 773520, "per_episode_reward": -119.67, "episode_reward_trend_value": 0.018396221463308392, "biggest_recent_change": 0.27397531967599775},
{"total_number_of_episodes": 7075, "number_of_timesteps": 774870, "per_episode_reward": -119.46, "episode_reward_trend_value": 0.01784092784633376, "biggest_recent_change": 0.27397531967599775},
{"total_number_of_episodes": 7085, "number_of_timesteps": 775677, "per_episode_reward": -119.23, "episode_reward_trend_value": 0.018218730894574105, "biggest_recent_change": 0.27397531967599775},
{"total_number_of_episodes": 7096, "number_of_timesteps": 776837, "per_episode_reward": -119.09, "episode_reward_trend_value": 0.017803472865449678, "biggest_recent_change": 0.27397531967599775},
{"total_number_of_episodes": 7106, "number_of_timesteps": 777613, "per_episode_reward": -118.9, "episode_reward_trend_value": 0.017839356577000524, "biggest_recent_change": 0.27397531967599775},
{"total_number_of_episodes": 7117, "number_of_timesteps": 778607, "per_episode_reward": -118.8, "episode_reward_trend_value": 0.017656240656467523, "biggest_recent_change": 0.27397531967599775},
{"total_number_of_episodes": 7127, "number_of_timesteps": 779492, "per_episode_reward": -118.74, "episode_reward_trend_value": 0.01527251434186575, "biggest_recent_change": 0.23122074286467864},
{"total_number_of_episodes": 7137, "number_of_timesteps": 780359, "per_episode_reward": -118.41, "episode_reward_trend_value": 0.016969163438641032, "biggest_recent_change": 0.32704860481656794},
{"total_number_of_episodes": 7147, "number_of_timesteps": 781347, "per_episode_reward": -118.05, "episode_reward_trend_value": 0.01870115972475585, "biggest_recent_change": 0.3596834926889585},
{"total_number_of_episodes": 7158, "number_of_timesteps": 782371, "per_episode_reward": -117.41, "episode_reward_trend_value": 0.025094404281741985, "biggest_recent_change": 0.6468740409952858},
{"total_number_of_episodes": 7168, "number_of_timesteps": 783180, "per_episode_reward": -117.33, "episode_reward_trend_value": 0.02374578742383212, "biggest_recent_change": 0.6468740409952858},
{"total_number_of_episodes": 7178, "number_of_timesteps": 783980, "per_episode_reward": -117.2, "episode_reward_trend_value": 0.02253714226298721, "biggest_recent_change": 0.6468740409952858},
{"total_number_of_episodes": 7188, "number_of_timesteps": 784710, "per_episode_reward": -117.09, "episode_reward_trend_value": 0.022275856827636335, "biggest_recent_change": 0.6468740409952858},
{"total_number_of_episodes": 7198, "number_of_timesteps": 785462, "per_episode_reward": -116.98, "episode_reward_trend_value": 0.02137736218190977, "biggest_recent_change": 0.6468740409952858},
{"total_number_of_episodes": 7208, "number_of_timesteps": 786237, "per_episode_reward": -116.75, "episode_reward_trend_value": 0.022772666333742267, "biggest_recent_change": 0.6468740409952858},
{"total_number_of_episodes": 7218, "number_of_timesteps": 787246, "per_episode_reward": -116.58, "episode_reward_trend_value": 0.023964303772440746, "biggest_recent_change": 0.6468740409952858},
{"total_number_of_episodes": 7228, "number_of_timesteps": 788076, "per_episode_reward": -116.26, "episode_reward_trend_value": 0.02390112431653364, "biggest_recent_change": 0.6468740409952858},
{"total_number_of_episodes": 7238, "number_of_timesteps": 788974, "per_episode_reward": -116.05, "episode_reward_trend_value": 0.02222168208974248, "biggest_recent_change": 0.6468740409952858},
{"total_number_of_episodes": 7248, "number_of_timesteps": 789791, "per_episode_reward": -115.89, "episode_reward_trend_value": 0.01689284490481558, "biggest_recent_change": 0.32136245378492845},
{"total_number_of_episodes": 7259, "number_of_timesteps": 790907, "per_episode_reward": -115.52, "episode_reward_trend_value": 0.02005732065665345, "biggest_recent_change": 0.3641137298665029},
{"total_number_of_episodes": 7269, "number_of_timesteps": 791783, "per_episode_reward": -115.39, "episode_reward_trend_value": 0.020157725510310184, "biggest_recent_change": 0.3641137298665029},
{"total_number_of_episodes": 7279, "number_of_timesteps": 792500, "per_episode_reward": -115.11, "episode_reward_trend_value": 0.02196365932567422, "biggest_recent_change": 0.3641137298665029},
{"total_number_of_episodes": 7289, "number_of_timesteps": 793281, "per_episode_reward": -114.93, "episode_reward_trend_value": 0.022692373895369634, "biggest_recent_change": 0.3641137298665029},
{"total_number_of_episodes": 7299, "number_of_timesteps": 794028, "per_episode_reward": -114.74, "episode_reward_trend_value": 0.022342516935718808, "biggest_recent_change": 0.3641137298665029},
{"total_number_of_episodes": 7309, "number_of_timesteps": 794852, "per_episode_reward": -114.63, "episode_reward_trend_value": 0.021740474315858828, "biggest_recent_change": 0.3641137298665029},
{"total_number_of_episodes": 7319, "number_of_timesteps": 795632, "per_episode_reward": -114.48, "episode_reward_trend_value": 0.019853806776452623, "biggest_recent_change": 0.3641137298665029},
{"total_number_of_episodes": 7330, "number_of_timesteps": 796530, "per_episode_reward": -114.3, "episode_reward_trend_value": 0.019486456875228774, "biggest_recent_change": 0.3641137298665029},
{"total_number_of_episodes": 7340, "number_of_timesteps": 797287, "per_episode_reward": -114.16, "episode_reward_trend_value": 0.019144589951803917, "biggest_recent_change": 0.3641137298665029},
{"total_number_of_episodes": 7351, "number_of_timesteps": 798231, "per_episode_reward": -113.89, "episode_reward_trend_value": 0.018142212911490672, "biggest_recent_change": 0.2775135618370257},
{"total_number_of_episodes": 7363, "number_of_timesteps": 799200, "per_episode_reward": -113.69, "episode_reward_trend_value": 0.01891416724166469, "biggest_recent_change": 0.2775135618370257},
{"total_number_of_episodes": 7373, "number_of_timesteps": 800038, "per_episode_reward": -113.34, "episode_reward_trend_value": 0.019757261014822645, "biggest_recent_change": 0.3533920014212413},
{"total_number_of_episodes": 7383, "number_of_timesteps": 801188, "per_episode_reward": -113.23, "episode_reward_trend_value": 0.018905592209254488, "biggest_recent_change": 0.3533920014212413},
{"total_number_of_episodes": 7393, "number_of_timesteps": 802115, "per_episode_reward": -113.14, "episode_reward_trend_value": 0.017750694669796018, "biggest_recent_change": 0.3533920014212413},
{"total_number_of_episodes": 7404, "number_of_timesteps": 802948, "per_episode_reward": -112.95, "episode_reward_trend_value": 0.018626257324039684, "biggest_recent_change": 0.3533920014212413},
{"total_number_of_episodes": 7415, "number_of_timesteps": 803754, "per_episode_reward": -112.87, "episode_reward_trend_value": 0.017792982841396722, "biggest_recent_change": 0.3533920014212413},
{"total_number_of_episodes": 7425, "number_of_timesteps": 804708, "per_episode_reward": -111.97, "episode_reward_trend_value": 0.02593333197786778, "biggest_recent_change": 0.9081036234500033},
{"total_number_of_episodes": 7436, "number_of_timesteps": 805735, "per_episode_reward": -111.6, "episode_reward_trend_value": 0.02843373771338299, "biggest_recent_change": 0.9081036234500033},
{"total_number_of_episodes": 7447, "number_of_timesteps": 806741, "per_episode_reward": -111.38, "episode_reward_trend_value": 0.027869621586033743, "biggest_recent_change": 0.9081036234500033},
{"total_number_of_episodes": 7457, "number_of_timesteps": 807490, "per_episode_reward": -111.14, "episode_reward_trend_value": 0.028309245149310096, "biggest_recent_change": 0.9081036234500033},
{"total_number_of_episodes": 7468, "number_of_timesteps": 808312, "per_episode_reward": -110.76, "episode_reward_trend_value": 0.028595619323060834, "biggest_recent_change": 0.9081036234500033},
{"total_number_of_episodes": 7478, "number_of_timesteps": 809043, "per_episode_reward": -110.67, "episode_reward_trend_value": 0.028470733494923982, "biggest_recent_change": 0.9081036234500033},
{"total_number_of_episodes": 7488, "number_of_timesteps": 809829, "per_episode_reward": -110.5, "episode_reward_trend_value": 0.02933788909235599, "biggest_recent_change": 0.9081036234500033},
{"total_number_of_episodes": 7498, "number_of_timesteps": 810687, "per_episode_reward": -110.38, "episode_reward_trend_value": 0.028553202825330005, "biggest_recent_change": 0.9081036234500033},
{"total_number_of_episodes": 7508, "number_of_timesteps": 811448, "per_episode_reward": -110.3, "episode_reward_trend_value": 0.028584889334794167, "biggest_recent_change": 0.9081036234500033},
{"total_number_of_episodes": 7519, "number_of_timesteps": 812358, "per_episode_reward": -110.18, "episode_reward_trend_value": 0.019840045050471784, "biggest_recent_change": 0.37916567705880766},
{"total_number_of_episodes": 7530, "number_of_timesteps": 813246, "per_episode_reward": -110.08, "episode_reward_trend_value": 0.016987919340561555, "biggest_recent_change": 0.37916567705880766},
{"total_number_of_episodes": 7541, "number_of_timesteps": 814168, "per_episode_reward": -109.88, "episode_reward_trend_value": 0.016712415637925915, "biggest_recent_change": 0.37916567705880766},
{"total_number_of_episodes": 7551, "number_of_timesteps": 815102, "per_episode_reward": -109.66, "episode_reward_trend_value": 0.016488186021221908, "biggest_recent_change": 0.37916567705880766},
{"total_number_of_episodes": 7561, "number_of_timesteps": 816079, "per_episode_reward": -109.43, "episode_reward_trend_value": 0.014762970547923734, "biggest_recent_change": 0.22389628446197207},
{"total_number_of_episodes": 7571, "number_of_timesteps": 817373, "per_episode_reward": -109.56, "episode_reward_trend_value": 0.012354329400308946, "biggest_recent_change": 0.22389628446197207},
{"total_number_of_episodes": 7581, "number_of_timesteps": 818688, "per_episode_reward": -109.45, "episode_reward_trend_value": 0.011723902798160503, "biggest_recent_change": 0.22389628446197207},
{"total_number_of_episodes": 7591, "number_of_timesteps": 820303, "per_episode_reward": -109.32, "episode_reward_trend_value": 0.011772621283311304, "biggest_recent_change": 0.22389628446197207},
{"total_number_of_episodes": 7601, "number_of_timesteps": 821328, "per_episode_reward": -109.19, "episode_reward_trend_value": 0.012378135304323874, "biggest_recent_change": 0.22389628446197207},
{"total_number_of_episodes": 7611, "number_of_timesteps": 822364, "per_episode_reward": -109.22, "episode_reward_trend_value": 0.010701740506410021, "biggest_recent_change": 0.22389628446197207},
{"total_number_of_episodes": 7621, "number_of_timesteps": 823579, "per_episode_reward": -109.11, "episode_reward_trend_value": 0.010758222824227125, "biggest_recent_change": 0.22389628446197207},
{"total_number_of_episodes": 7632, "number_of_timesteps": 824778, "per_episode_reward": -109.03, "episode_reward_trend_value": 0.009448567042898365, "biggest_recent_change": 0.22389628446197207},
{"total_number_of_episodes": 7642, "number_of_timesteps": 826143, "per_episode_reward": -108.95, "episode_reward_trend_value": 0.007825713975247102, "biggest_recent_change": 0.22389628446197207},
{"total_number_of_episodes": 7652, "number_of_timesteps": 827799, "per_episode_reward": -109.07, "episode_reward_trend_value": 0.004014079244059746, "biggest_recent_change": 0.13391571954340975},
{"total_number_of_episodes": 7662, "number_of_timesteps": 829089, "per_episode_reward": -109.04, "episode_reward_trend_value": 0.0057364412448892375, "biggest_recent_change": 0.13391571954340975},
{"total_number_of_episodes": 7673, "number_of_timesteps": 830741, "per_episode_reward": -109.1, "episode_reward_trend_value": 0.003854117395673187, "biggest_recent_change": 0.13391571954340975},
{"total_number_of_episodes": 7683, "number_of_timesteps": 832188, "per_episode_reward": -109.03, "episode_reward_trend_value": 0.003224685505958765, "biggest_recent_change": 0.13391571954340975},
{"total_number_of_episodes": 7693, "number_of_timesteps": 834208, "per_episode_reward": -109.16, "episode_reward_trend_value": 0.00035258124471874275, "biggest_recent_change": 0.12457366396819225},
{"total_number_of_episodes": 7705, "number_of_timesteps": 835576, "per_episode_reward": -109.04, "episode_reward_trend_value": 0.0019390041385629313, "biggest_recent_change": 0.12457366396819225},
{"total_number_of_episodes": 7715, "number_of_timesteps": 836633, "per_episode_reward": -109.01, "episode_reward_trend_value": 0.001130889255971902, "biggest_recent_change": 0.12457366396819225},
{"total_number_of_episodes": 7726, "number_of_timesteps": 837920, "per_episode_reward": -108.87, "episode_reward_trend_value": 0.0017304639658151347, "biggest_recent_change": 0.13442671510597393},
{"total_number_of_episodes": 7737, "number_of_timesteps": 839812, "per_episode_reward": -108.89, "episode_reward_trend_value": 0.00067021785283793, "biggest_recent_change": 0.13442671510597393},
{"total_number_of_episodes": 7748, "number_of_timesteps": 841202, "per_episode_reward": -108.87, "episode_reward_trend_value": 0.0022232392844731266, "biggest_recent_change": 0.13442671510597393},
{"total_number_of_episodes": 7758, "number_of_timesteps": 842381, "per_episode_reward": -108.67, "episode_reward_trend_value": 0.0040734630106386924, "biggest_recent_change": 0.1964656918590748},
{"total_number_of_episodes": 7768, "number_of_timesteps": 843604, "per_episode_reward": -108.56, "episode_reward_trend_value": 0.006027917213607263, "biggest_recent_change": 0.1964656918590748},
{"total_number_of_episodes": 7779, "number_of_timesteps": 844967, "per_episode_reward": -108.35, "episode_reward_trend_value": 0.007530095094821515, "biggest_recent_change": 0.20361416280545086},
{"total_number_of_episodes": 7789, "number_of_timesteps": 846221, "per_episode_reward": -108.26, "episode_reward_trend_value": 0.01000496879491095, "biggest_recent_change": 0.20361416280545086},
{"total_number_of_episodes": 7799, "number_of_timesteps": 847446, "per_episode_reward": -108.02, "episode_reward_trend_value": 0.011307607234288735, "biggest_recent_change": 0.23020762603871958},
{"total_number_of_episodes": 7809, "number_of_timesteps": 848530, "per_episode_reward": -107.66, "episode_reward_trend_value": 0.014905538361764078, "biggest_recent_change": 0.36102274419120306},
{"total_number_of_episodes": 7820, "number_of_timesteps": 849615, "per_episode_reward": -107.47, "episode_reward_trend_value": 0.015543083580445543, "biggest_recent_change": 0.36102274419120306},
{"total_number_of_episodes": 7830, "number_of_timesteps": 850779, "per_episode_reward": -107.3, "episode_reward_trend_value": 0.017678706581556174, "biggest_recent_change": 0.36102274419120306},
{"total_number_of_episodes": 7840, "number_of_timesteps": 851680, "per_episode_reward": -107.11, "episode_reward_trend_value": 0.019573245104265245, "biggest_recent_change": 0.36102274419120306},
{"total_number_of_episodes": 7850, "number_of_timesteps": 852495, "per_episode_reward": -107.02, "episode_reward_trend_value": 0.01835064040995399, "biggest_recent_change": 0.36102274419120306},
{"total_number_of_episodes": 7860, "number_of_timesteps": 854062, "per_episode_reward": -106.94, "episode_reward_trend_value": 0.017926972371240246, "biggest_recent_change": 0.36102274419120306},
{"total_number_of_episodes": 7871, "number_of_timesteps": 855591, "per_episode_reward": -106.69, "episode_reward_trend_value": 0.018469743227181982, "biggest_recent_change": 0.36102274419120306},
{"total_number_of_episodes": 7881, "number_of_timesteps": 856401, "per_episode_reward": -106.53, "episode_reward_trend_value": 0.019115223923545623, "biggest_recent_change": 0.36102274419120306},
{"total_number_of_episodes": 7891, "number_of_timesteps": 857263, "per_episode_reward": -106.45, "episode_reward_trend_value": 0.01745895074898177, "biggest_recent_change": 0.36102274419120306},
{"total_number_of_episodes": 7901, "number_of_timesteps": 858172, "per_episode_reward": -106.18, "episode_reward_trend_value": 0.016506813033481175, "biggest_recent_change": 0.2753303497961497},
{"total_number_of_episodes": 7911, "number_of_timesteps": 858958, "per_episode_reward": -106.02, "episode_reward_trend_value": 0.016102962897944433, "biggest_recent_change": 0.2753303497961497},
{"total_number_of_episodes": 7921, "number_of_timesteps": 859744, "per_episode_reward": -106.01, "episode_reward_trend_value": 0.01439075649127738, "biggest_recent_change": 0.2753303497961497},
{"total_number_of_episodes": 7932, "number_of_timesteps": 860549, "per_episode_reward": -105.93, "episode_reward_trend_value": 0.013120389292848561, "biggest_recent_change": 0.2753303497961497},
{"total_number_of_episodes": 7942, "number_of_timesteps": 861342, "per_episode_reward": -105.48, "episode_reward_trend_value": 0.01718257345637113, "biggest_recent_change": 0.45202784408809293},
{"total_number_of_episodes": 7953, "number_of_timesteps": 862246, "per_episode_reward": -105.23, "episode_reward_trend_value": 0.01905453815775012, "biggest_recent_change": 0.45202784408809293},
{"total_number_of_episodes": 7964, "number_of_timesteps": 863231, "per_episode_reward": -105.1, "episode_reward_trend_value": 0.017629548376770287, "biggest_recent_change": 0.45202784408809293},
{"total_number_of_episodes": 7974, "number_of_timesteps": 864138, "per_episode_reward": -105.06, "episode_reward_trend_value": 0.01636175323153408, "biggest_recent_change": 0.45202784408809293},
{"total_number_of_episodes": 7985, "number_of_timesteps": 865016, "per_episode_reward": -104.91, "episode_reward_trend_value": 0.017147779481844656, "biggest_recent_change": 0.45202784408809293},
{"total_number_of_episodes": 7995, "number_of_timesteps": 865838, "per_episode_reward": -104.7, "episode_reward_trend_value": 0.01640267997643608, "biggest_recent_change": 0.45202784408809293},
{"total_number_of_episodes": 8005, "number_of_timesteps": 866745, "per_episode_reward": -104.59, "episode_reward_trend_value": 0.015968408371740534, "biggest_recent_change": 0.45202784408809293},
{"total_number_of_episodes": 8016, "number_of_timesteps": 867791, "per_episode_reward": -104.57, "episode_reward_trend_value": 0.01598373400553454, "biggest_recent_change": 0.45202784408809293},
{"total_number_of_episodes": 8028, "number_of_timesteps": 869405, "per_episode_reward": -104.51, "episode_reward_trend_value": 0.015756258076486538, "biggest_recent_change": 0.45202784408809293},
{"total_number_of_episodes": 8038, "number_of_timesteps": 870864, "per_episode_reward": -104.45, "episode_reward_trend_value": 0.011368563493935193, "biggest_recent_change": 0.24846062178772854},
{"total_number_of_episodes": 8049, "number_of_timesteps": 872264, "per_episode_reward": -104.42, "episode_reward_trend_value": 0.00899367594687735, "biggest_recent_change": 0.2082713943093779},
{"total_number_of_episodes": 8059, "number_of_timesteps": 873919, "per_episode_reward": -104.46, "episode_reward_trend_value": 0.007203721300293056, "biggest_recent_change": 0.2082713943093779},
{"total_number_of_episodes": 8070, "number_of_timesteps": 875399, "per_episode_reward": -104.38, "episode_reward_trend_value": 0.00762340498227145, "biggest_recent_change": 0.2082713943093779},
{"total_number_of_episodes": 8080, "number_of_timesteps": 876694, "per_episode_reward": -104.35, "episode_reward_trend_value": 0.006202795948968445, "biggest_recent_change": 0.2082713943093779},
{"total_number_of_episodes": 8090, "number_of_timesteps": 878283, "per_episode_reward": -104.18, "episode_reward_trend_value": 0.005851993911006383, "biggest_recent_change": 0.17669921089279228},
{"total_number_of_episodes": 8100, "number_of_timesteps": 879758, "per_episode_reward": -104.13, "episode_reward_trend_value": 0.005110282247516315, "biggest_recent_change": 0.17669921089279228},
{"total_number_of_episodes": 8110, "number_of_timesteps": 880653, "per_episode_reward": -103.98, "episode_reward_trend_value": 0.006470936126600829, "biggest_recent_change": 0.17669921089279228},
{"total_number_of_episodes": 8120, "number_of_timesteps": 881648, "per_episode_reward": -103.92, "episode_reward_trend_value": 0.006522662991950136, "biggest_recent_change": 0.17669921089279228},
{"total_number_of_episodes": 8131, "number_of_timesteps": 882706, "per_episode_reward": -103.8, "episode_reward_trend_value": 0.007294290086128935, "biggest_recent_change": 0.17669921089279228},
{"total_number_of_episodes": 8141, "number_of_timesteps": 883620, "per_episode_reward": -103.74, "episode_reward_trend_value": 0.007584022994937653, "biggest_recent_change": 0.17669921089279228},
{"total_number_of_episodes": 8151, "number_of_timesteps": 884791, "per_episode_reward": -103.7, "episode_reward_trend_value": 0.008385059979490943, "biggest_recent_change": 0.17669921089279228},
{"total_number_of_episodes": 8161, "number_of_timesteps": 885943, "per_episode_reward": -103.64, "episode_reward_trend_value": 0.008202808578842596, "biggest_recent_change": 0.17669921089279228},
{"total_number_of_episodes": 8172, "number_of_timesteps": 886888, "per_episode_reward": -103.54, "episode_reward_trend_value": 0.00906741675397724, "biggest_recent_change": 0.17669921089279228},
{"total_number_of_episodes": 8183, "number_of_timesteps": 887863, "per_episode_reward": -103.33, "episode_reward_trend_value": 0.0094398008392659, "biggest_recent_change": 0.21021377856877166},
{"total_number_of_episodes": 8193, "number_of_timesteps": 888769, "per_episode_reward": -103.21, "episode_reward_trend_value": 0.01013289126402286, "biggest_recent_change": 0.21021377856877166},
{"total_number_of_episodes": 8204, "number_of_timesteps": 889712, "per_episode_reward": -102.98, "episode_reward_trend_value": 0.011193661673799543, "biggest_recent_change": 0.23627652040724456},
{"total_number_of_episodes": 8214, "number_of_timesteps": 890634, "per_episode_reward": -102.8, "episode_reward_trend_value": 0.012505147266636938, "biggest_recent_change": 0.23627652040724456},
{"total_number_of_episodes": 8224, "number_of_timesteps": 891721, "per_episode_reward": -102.74, "episode_reward_trend_value": 0.011758968017694826, "biggest_recent_change": 0.23627652040724456},
{"total_number_of_episodes": 8234, "number_of_timesteps": 892961, "per_episode_reward": -102.67, "episode_reward_trend_value": 0.011827179699494334, "biggest_recent_change": 0.23627652040724456},
{"total_number_of_episodes": 8244, "number_of_timesteps": 894135, "per_episode_reward": -102.65, "episode_reward_trend_value": 0.011669010852992458, "biggest_recent_change": 0.23627652040724456},
{"total_number_of_episodes": 8254, "number_of_timesteps": 895548, "per_episode_reward": -102.54, "episode_reward_trend_value": 0.012216251685558966, "biggest_recent_change": 0.23627652040724456},
{"total_number_of_episodes": 8264, "number_of_timesteps": 897249, "per_episode_reward": -102.6, "episode_reward_trend_value": 0.010390801394094417, "biggest_recent_change": 0.23627652040724456},
{"total_number_of_episodes": 8275, "number_of_timesteps": 898676, "per_episode_reward": -102.55, "episode_reward_trend_value": 0.00864141695136848, "biggest_recent_change": 0.23627652040724456},
{"total_number_of_episodes": 8285, "number_of_timesteps": 899858, "per_episode_reward": -102.55, "episode_reward_trend_value": 0.007417239904357586, "biggest_recent_change": 0.23627652040724456},
{"total_number_of_episodes": 8295, "number_of_timesteps": 901003, "per_episode_reward": -102.51, "episode_reward_trend_value": 0.005196253625633397, "biggest_recent_change": 0.1790127943099833},
{"total_number_of_episodes": 8305, "number_of_timesteps": 902173, "per_episode_reward": -102.47, "episode_reward_trend_value": 0.0036328124689861047, "biggest_recent_change": 0.11277724889201579},
{"total_number_of_episodes": 8315, "number_of_timesteps": 903227, "per_episode_reward": -102.35, "episode_reward_trend_value": 0.004319531401491538, "biggest_recent_change": 0.12123034165526292},
{"total_number_of_episodes": 8325, "number_of_timesteps": 904620, "per_episode_reward": -102.34, "episode_reward_trend_value": 0.0037258799152307155, "biggest_recent_change": 0.12123034165526292},
{"total_number_of_episodes": 8336, "number_of_timesteps": 905905, "per_episode_reward": -102.17, "episode_reward_trend_value": 0.005393189798779632, "biggest_recent_change": 0.1710345633034649},
{"total_number_of_episodes": 8346, "number_of_timesteps": 907067, "per_episode_reward": -101.97, "episode_reward_trend_value": 0.006302704287473186, "biggest_recent_change": 0.19463355287443562},
{"total_number_of_episodes": 8356, "number_of_timesteps": 908141, "per_episode_reward": -101.88, "episode_reward_trend_value": 0.008014519434576073, "biggest_recent_change": 0.19463355287443562},
{"total_number_of_episodes": 8366, "number_of_timesteps": 909199, "per_episode_reward": -101.81, "episode_reward_trend_value": 0.008211196824182171, "biggest_recent_change": 0.19463355287443562},
{"total_number_of_episodes": 8376, "number_of_timesteps": 910061, "per_episode_reward": -101.75, "episode_reward_trend_value": 0.008901628310142781, "biggest_recent_change": 0.19463355287443562},
{"total_number_of_episodes": 8386, "number_of_timesteps": 911145, "per_episode_reward": -101.67, "episode_reward_trend_value": 0.009369738428809645, "biggest_recent_change": 0.19463355287443562},
{"total_number_of_episodes": 8396, "number_of_timesteps": 912154, "per_episode_reward": -101.52, "episode_reward_trend_value": 0.010592508527616297, "biggest_recent_change": 0.19463355287443562},
{"total_number_of_episodes": 8406, "number_of_timesteps": 913113, "per_episode_reward": -101.45, "episode_reward_trend_value": 0.00995505918456969, "biggest_recent_change": 0.19463355287443562},
{"total_number_of_episodes": 8416, "number_of_timesteps": 914320, "per_episode_reward": -101.41, "episode_reward_trend_value": 0.010320086576082747, "biggest_recent_change": 0.19463355287443562},
{"total_number_of_episodes": 8426, "number_of_timesteps": 915364, "per_episode_reward": -101.4, "episode_reward_trend_value": 0.008543435453541786, "biggest_recent_change": 0.19463355287443562},
{"total_number_of_episodes": 8436, "number_of_timesteps": 916284, "per_episode_reward": -101.38, "episode_reward_trend_value": 0.0066006994678195, "biggest_recent_change": 0.14835239910432563},
{"total_number_of_episodes": 8446, "number_of_timesteps": 917235, "per_episode_reward": -101.32, "episode_reward_trend_value": 0.006210959819452929, "biggest_recent_change": 0.14835239910432563},
{"total_number_of_episodes": 8457, "number_of_timesteps": 918282, "per_episode_reward": -101.28, "episode_reward_trend_value": 0.005906536634362504, "biggest_recent_change": 0.14835239910432563},
{"total_number_of_episodes": 8467, "number_of_timesteps": 919535, "per_episode_reward": -101.18, "episode_reward_trend_value": 0.006287493240316956, "biggest_recent_change": 0.14835239910432563},
{"total_number_of_episodes": 8477, "number_of_timesteps": 920923, "per_episode_reward": -101.13, "episode_reward_trend_value": 0.006008829674576867, "biggest_recent_change": 0.14835239910432563},
{"total_number_of_episodes": 8487, "number_of_timesteps": 922575, "per_episode_reward": -101.15, "episode_reward_trend_value": 0.004047649020277157, "biggest_recent_change": 0.0982479107217955},
{"total_number_of_episodes": 8497, "number_of_timesteps": 923638, "per_episode_reward": -100.99, "episode_reward_trend_value": 0.005144525032261842, "biggest_recent_change": 0.16257874185969},
{"total_number_of_episodes": 8507, "number_of_timesteps": 924959, "per_episode_reward": -100.95, "episode_reward_trend_value": 0.005062925409365467, "biggest_recent_change": 0.16257874185969},
{"total_number_of_episodes": 8517, "number_of_timesteps": 926202, "per_episode_reward": -100.82, "episode_reward_trend_value": 0.0064325169857884, "biggest_recent_change": 0.16257874185969},
{"total_number_of_episodes": 8527, "number_of_timesteps": 927449, "per_episode_reward": -100.68, "episode_reward_trend_value": 0.007770723163742982, "biggest_recent_change": 0.16257874185969},
{"total_number_of_episodes": 8537, "number_of_timesteps": 928787, "per_episode_reward": -100.64, "episode_reward_trend_value": 0.007578750170695041, "biggest_recent_change": 0.16257874185969},
{"total_number_of_episodes": 8547, "number_of_timesteps": 930159, "per_episode_reward": -100.66, "episode_reward_trend_value": 0.006853478916167432, "biggest_recent_change": 0.16257874185969},
{"total_number_of_episodes": 8558, "number_of_timesteps": 931731, "per_episode_reward": -100.59, "episode_reward_trend_value": 0.006584152961502336, "biggest_recent_change": 0.16257874185969},
{"total_number_of_episodes": 8568, "number_of_timesteps": 933374, "per_episode_reward": -100.57, "episode_reward_trend_value": 0.006141590527948577, "biggest_recent_change": 0.16257874185969},
{"total_number_of_episodes": 8578, "number_of_timesteps": 934700, "per_episode_reward": -100.54, "episode_reward_trend_value": 0.0068532309876841975, "biggest_recent_change": 0.16257874185969},
{"total_number_of_episodes": 8588, "number_of_timesteps": 936051, "per_episode_reward": -100.53, "episode_reward_trend_value": 0.005122318608853189, "biggest_recent_change": 0.1402258701753425},
{"total_number_of_episodes": 8598, "number_of_timesteps": 937656, "per_episode_reward": -100.48, "episode_reward_trend_value": 0.005230859484064846, "biggest_recent_change": 0.1402258701753425},
{"total_number_of_episodes": 8608, "number_of_timesteps": 939586, "per_episode_reward": -100.43, "episode_reward_trend_value": 0.004288725953828355, "biggest_recent_change": 0.1402258701753425},
{"total_number_of_episodes": 8618, "number_of_timesteps": 940943, "per_episode_reward": -100.39, "episode_reward_trend_value": 0.003146517920074467, "biggest_recent_change": 0.07400857480193679},
{"total_number_of_episodes": 8628, "number_of_timesteps": 942457, "per_episode_reward": -100.25, "episode_reward_trend_value": 0.00433607893584088, "biggest_recent_change": 0.1463245163198934},
{"total_number_of_episodes": 8638, "number_of_timesteps": 944157, "per_episode_reward": -100.18, "episode_reward_trend_value": 0.005383621037239392, "biggest_recent_change": 0.1463245163198934},
{"total_number_of_episodes": 8648, "number_of_timesteps": 945813, "per_episode_reward": -100.15, "episode_reward_trend_value": 0.004823373993665175, "biggest_recent_change": 0.1463245163198934},
{"total_number_of_episodes": 8658, "number_of_timesteps": 947277, "per_episode_reward": -100.08, "episode_reward_trend_value": 0.005476834038652593, "biggest_recent_change": 0.1463245163198934},
{"total_number_of_episodes": 8668, "number_of_timesteps": 950174, "per_episode_reward": -99.99, "episode_reward_trend_value": 0.006070933130581895, "biggest_recent_change": 0.1463245163198934},
{"total_number_of_episodes": 8678, "number_of_timesteps": 951385, "per_episode_reward": -99.89, "episode_reward_trend_value": 0.007103351605924975, "biggest_recent_change": 0.1463245163198934},
{"total_number_of_episodes": 8690, "number_of_timesteps": 952443, "per_episode_reward": -99.77, "episode_reward_trend_value": 0.00789723390851849, "biggest_recent_change": 0.1463245163198934},
{"total_number_of_episodes": 8700, "number_of_timesteps": 953272, "per_episode_reward": -99.62, "episode_reward_trend_value": 0.008970064641004033, "biggest_recent_change": 0.1463245163198934},
{"total_number_of_episodes": 8710, "number_of_timesteps": 955157, "per_episode_reward": -99.54, "episode_reward_trend_value": 0.009473704537533618, "biggest_recent_change": 0.1463245163198934},
{"total_number_of_episodes": 8720, "number_of_timesteps": 955930, "per_episode_reward": -99.42, "episode_reward_trend_value": 0.00923182570631648, "biggest_recent_change": 0.14616195235525709},
{"total_number_of_episodes": 8731, "number_of_timesteps": 956853, "per_episode_reward": -99.23, "episode_reward_trend_value": 0.010560238118637875, "biggest_recent_change": 0.1916335504571549},
{"total_number_of_episodes": 8741, "number_of_timesteps": 957848, "per_episode_reward": -99.13, "episode_reward_trend_value": 0.011323978790809344, "biggest_recent_change": 0.1916335504571549},
{"total_number_of_episodes": 8751, "number_of_timesteps": 958982, "per_episode_reward": -99.08, "episode_reward_trend_value": 0.011112367536688181, "biggest_recent_change": 0.1916335504571549},
{"total_number_of_episodes": 8761, "number_of_timesteps": 960100, "per_episode_reward": -98.99, "episode_reward_trend_value": 0.011066727200019482, "biggest_recent_change": 0.1916335504571549},
{"total_number_of_episodes": 8771, "number_of_timesteps": 961484, "per_episode_reward": -98.73, "episode_reward_trend_value": 0.012851134238636538, "biggest_recent_change": 0.2603109240213115},
{"total_number_of_episodes": 8782, "number_of_timesteps": 962934, "per_episode_reward": -98.79, "episode_reward_trend_value": 0.010867591082559455, "biggest_recent_change": 0.2603109240213115},
{"total_number_of_episodes": 8792, "number_of_timesteps": 964051, "per_episode_reward": -98.68, "episode_reward_trend_value": 0.010512153342642232, "biggest_recent_change": 0.2603109240213115},
{"total_number_of_episodes": 8802, "number_of_timesteps": 965298, "per_episode_reward": -98.64, "episode_reward_trend_value": 0.010003560261127437, "biggest_recent_change": 0.2603109240213115},
{"total_number_of_episodes": 8812, "number_of_timesteps": 966132, "per_episode_reward": -98.51, "episode_reward_trend_value": 0.010087126163555303, "biggest_recent_change": 0.2603109240213115},
{"total_number_of_episodes": 8824, "number_of_timesteps": 968121, "per_episode_reward": -98.31, "episode_reward_trend_value": 0.010152456097040859, "biggest_recent_change": 0.2603109240213115},
{"total_number_of_episodes": 8835, "number_of_timesteps": 968996, "per_episode_reward": -98.26, "episode_reward_trend_value": 0.009682658842194927, "biggest_recent_change": 0.2603109240213115},
{"total_number_of_episodes": 8845, "number_of_timesteps": 970018, "per_episode_reward": -98.17, "episode_reward_trend_value": 0.010122085827023694, "biggest_recent_change": 0.2603109240213115},
{"total_number_of_episodes": 8855, "number_of_timesteps": 971103, "per_episode_reward": -98.03, "episode_reward_trend_value": 0.010737103608132594, "biggest_recent_change": 0.2603109240213115},
{"total_number_of_episodes": 8865, "number_of_timesteps": 972420, "per_episode_reward": -97.95, "episode_reward_trend_value": 0.0087423660609943, "biggest_recent_change": 0.19751324447085494},
{"total_number_of_episodes": 8875, "number_of_timesteps": 974546, "per_episode_reward": -97.91, "episode_reward_trend_value": 0.009827006539044527, "biggest_recent_change": 0.19751324447085494},
{"total_number_of_episodes": 8885, "number_of_timesteps": 976017, "per_episode_reward": -97.79, "episode_reward_trend_value": 0.009882662602908158, "biggest_recent_change": 0.19751324447085494},
{"total_number_of_episodes": 8895, "number_of_timesteps": 979192, "per_episode_reward": -97.64, "episode_reward_trend_value": 0.011167812724203764, "biggest_recent_change": 0.19751324447085494},
{"total_number_of_episodes": 8905, "number_of_timesteps": 981421, "per_episode_reward": -97.56, "episode_reward_trend_value": 0.010555211666542164, "biggest_recent_change": 0.19751324447085494},
{"total_number_of_episodes": 8915, "number_of_timesteps": 983150, "per_episode_reward": -97.44, "episode_reward_trend_value": 0.009693608743781428, "biggest_recent_change": 0.15264487140542826},
{"total_number_of_episodes": 8925, "number_of_timesteps": 987026, "per_episode_reward": -97.39, "episode_reward_trend_value": 0.009706665999143303, "biggest_recent_change": 0.15264487140542826},
{"total_number_of_episodes": 8935, "number_of_timesteps": 989515, "per_episode_reward": -97.29, "episode_reward_trend_value": 0.009737452501859738, "biggest_recent_change": 0.15264487140542826},
{"total_number_of_episodes": 8945, "number_of_timesteps": 990984, "per_episode_reward": -97.16, "episode_reward_trend_value": 0.009635192897743946, "biggest_recent_change": 0.15264487140542826},
{"total_number_of_episodes": 8955, "number_of_timesteps": 993675, "per_episode_reward": -97.05, "episode_reward_trend_value": 0.009954213954780914, "biggest_recent_change": 0.15264487140542826},
{"total_number_of_episodes": 8965, "number_of_timesteps": 995094, "per_episode_reward": -96.87, "episode_reward_trend_value": 0.011569100688357833, "biggest_recent_change": 0.18467227212126147},
{"total_number_of_episodes": 8976, "number_of_timesteps": 996730, "per_episode_reward": -96.74, "episode_reward_trend_value": 0.011669464532021973, "biggest_recent_change": 0.18467227212126147},
{"total_number_of_episodes": 8986, "number_of_timesteps": 998490, "per_episode_reward": -96.63, "episode_reward_trend_value": 0.01116132417495158, "biggest_recent_change": 0.18467227212126147},
{"total_number_of_episodes": 8997, "number_of_timesteps": 1000481, "per_episode_reward": -96.56, "episode_reward_trend_value": 0.0111049955596425, "biggest_recent_change": 0.18467227212126147},
{"total_number_of_episodes": 9007, "number_of_timesteps": 1002488, "per_episode_reward": -96.46, "episode_reward_trend_value": 0.01083964804015112, "biggest_recent_change": 0.18467227212126147},
{"total_number_of_episodes": 9017, "number_of_timesteps": 1004377, "per_episode_reward": -96.4, "episode_reward_trend_value": 0.01096904045198149, "biggest_recent_change": 0.18467227212126147},
{"total_number_of_episodes": 9027, "number_of_timesteps": 1005792, "per_episode_reward": -96.26, "episode_reward_trend_value": 0.011468780577828694, "biggest_recent_change": 0.18467227212126147},
{"total_number_of_episodes": 9037, "number_of_timesteps": 1007862, "per_episode_reward": -96.09, "episode_reward_trend_value": 0.011853939947285615, "biggest_recent_change": 0.18467227212126147},
{"total_number_of_episodes": 9047, "number_of_timesteps": 1010179, "per_episode_reward": -96.04, "episode_reward_trend_value": 0.011241615070789931, "biggest_recent_change": 0.18467227212126147},
{"total_number_of_episodes": 9057, "number_of_timesteps": 1011932, "per_episode_reward": -95.95, "episode_reward_trend_value": 0.010223920727308825, "biggest_recent_change": 0.16606764874751434},
{"total_number_of_episodes": 9067, "number_of_timesteps": 1013906, "per_episode_reward": -95.89, "episode_reward_trend_value": 0.009481508956640204, "biggest_recent_change": 0.16606764874751434},
{"total_number_of_episodes": 9077, "number_of_timesteps": 1016478, "per_episode_reward": -95.8, "episode_reward_trend_value": 0.009289999681048282, "biggest_recent_change": 0.16606764874751434},
{"total_number_of_episodes": 9087, "number_of_timesteps": 1019981, "per_episode_reward": -95.73, "episode_reward_trend_value": 0.009226954934381443, "biggest_recent_change": 0.16606764874751434},
{"total_number_of_episodes": 9098, "number_of_timesteps": 1021830, "per_episode_reward": -95.7, "episode_reward_trend_value": 0.008469477446573295, "biggest_recent_change": 0.16606764874751434},
{"total_number_of_episodes": 9108, "number_of_timesteps": 1023656, "per_episode_reward": -95.4, "episode_reward_trend_value": 0.011068365253391398, "biggest_recent_change": 0.29676162110048665},
{"total_number_of_episodes": 9119, "number_of_timesteps": 1026201, "per_episode_reward": -95.28, "episode_reward_trend_value": 0.010864724818140954, "biggest_recent_change": 0.29676162110048665},
{"total_number_of_episodes": 9130, "number_of_timesteps": 1028343, "per_episode_reward": -95.2, "episode_reward_trend_value": 0.009893065655700185, "biggest_recent_change": 0.29676162110048665},
{"total_number_of_episodes": 9140, "number_of_timesteps": 1029951, "per_episode_reward": -95.18, "episode_reward_trend_value": 0.009574209992678738, "biggest_recent_change": 0.29676162110048665},
{"total_number_of_episodes": 9150, "number_of_timesteps": 1031656, "per_episode_reward": -95.16, "episode_reward_trend_value": 0.008772868513786926, "biggest_recent_change": 0.29676162110048665},
{"total_number_of_episodes": 9160, "number_of_timesteps": 1033234, "per_episode_reward": -94.88, "episode_reward_trend_value": 0.011152054960085265, "biggest_recent_change": 0.29676162110048665},
{"total_number_of_episodes": 9170, "number_of_timesteps": 1035278, "per_episode_reward": -94.86, "episode_reward_trend_value": 0.010375656126497764, "biggest_recent_change": 0.29676162110048665},
{"total_number_of_episodes": 9180, "number_of_timesteps": 1038000, "per_episode_reward": -94.8, "episode_reward_trend_value": 0.010377098016284947, "biggest_recent_change": 0.29676162110048665},
{"total_number_of_episodes": 9190, "number_of_timesteps": 1040648, "per_episode_reward": -94.67, "episode_reward_trend_value": 0.011514526029753351, "biggest_recent_change": 0.29676162110048665},
{"total_number_of_episodes": 9200, "number_of_timesteps": 1042761, "per_episode_reward": -94.49, "episode_reward_trend_value": 0.010122968084685467, "biggest_recent_change": 0.2755240682468809},
{"total_number_of_episodes": 9210, "number_of_timesteps": 1046768, "per_episode_reward": -94.41, "episode_reward_trend_value": 0.009732316285756958, "biggest_recent_change": 0.2755240682468809},
{"total_number_of_episodes": 9220, "number_of_timesteps": 1049463, "per_episode_reward": -94.35, "episode_reward_trend_value": 0.009446674389695254, "biggest_recent_change": 0.2755240682468809},
{"total_number_of_episodes": 9230, "number_of_timesteps": 1052101, "per_episode_reward": -94.32, "episode_reward_trend_value": 0.009490971177073327, "biggest_recent_change": 0.2755240682468809},
{"total_number_of_episodes": 9240, "number_of_timesteps": 1054439, "per_episode_reward": -94.36, "episode_reward_trend_value": 0.008909263549741947, "biggest_recent_change": 0.2755240682468809},
{"total_number_of_episodes": 9250, "number_of_timesteps": 1056637, "per_episode_reward": -94.3, "episode_reward_trend_value": 0.0064854722592304235, "biggest_recent_change": 0.17152140604437704},
{"total_number_of_episodes": 9260, "number_of_timesteps": 1058944, "per_episode_reward": -94.25, "episode_reward_trend_value": 0.006787489553048924, "biggest_recent_change": 0.17152140604437704},
{"total_number_of_episodes": 9270, "number_of_timesteps": 1061601, "per_episode_reward": -94.12, "episode_reward_trend_value": 0.007452136256528125, "biggest_recent_change": 0.17152140604437704},
{"total_number_of_episodes": 9280, "number_of_timesteps": 1063860, "per_episode_reward": -94.08, "episode_reward_trend_value": 0.00650284576591389, "biggest_recent_change": 0.17152140604437704},
{"total_number_of_episodes": 9290, "number_of_timesteps": 1066215, "per_episode_reward": -93.83, "episode_reward_trend_value": 0.007425463227073692, "biggest_recent_change": 0.2545569775487593},
{"total_number_of_episodes": 9300, "number_of_timesteps": 1067935, "per_episode_reward": -93.71, "episode_reward_trend_value": 0.007755212658858726, "biggest_recent_change": 0.2545569775487593},
{"total_number_of_episodes": 9311, "number_of_timesteps": 1070131, "per_episode_reward": -93.58, "episode_reward_trend_value": 0.008559672292511146, "biggest_recent_change": 0.2545569775487593},
{"total_number_of_episodes": 9321, "number_of_timesteps": 1071848, "per_episode_reward": -93.48, "episode_reward_trend_value": 0.009431349383597699, "biggest_recent_change": 0.2545569775487593},
{"total_number_of_episodes": 9331, "number_of_timesteps": 1073919, "per_episode_reward": -93.33, "episode_reward_trend_value": 0.011352660831289382, "biggest_recent_change": 0.2545569775487593},
{"total_number_of_episodes": 9341, "number_of_timesteps": 1077142, "per_episode_reward": -93.19, "episode_reward_trend_value": 0.012268827306840535, "biggest_recent_change": 0.2545569775487593},
{"total_number_of_episodes": 9351, "number_of_timesteps": 1080382, "per_episode_reward": -93.19, "episode_reward_trend_value": 0.01179113488447617, "biggest_recent_change": 0.2545569775487593},
{"total_number_of_episodes": 9361, "number_of_timesteps": 1083169, "per_episode_reward": -93.15, "episode_reward_trend_value": 0.010846299298834417, "biggest_recent_change": 0.2545569775487593},
{"total_number_of_episodes": 9371, "number_of_timesteps": 1085923, "per_episode_reward": -93.14, "episode_reward_trend_value": 0.010494187317933917, "biggest_recent_change": 0.2545569775487593},
{"total_number_of_episodes": 9381, "number_of_timesteps": 1088045, "per_episode_reward": -93.08, "episode_reward_trend_value": 0.00827047174425025, "biggest_recent_change": 0.14152339194012598},
{"total_number_of_episodes": 9391, "number_of_timesteps": 1089839, "per_episode_reward": -93.08, "episode_reward_trend_value": 0.007009775542456333, "biggest_recent_change": 0.14152339194012598},
{"total_number_of_episodes": 9402, "number_of_timesteps": 1092930, "per_episode_reward": -92.96, "episode_reward_trend_value": 0.006907809384453697, "biggest_recent_change": 0.14152339194012598},
{"total_number_of_episodes": 9412, "number_of_timesteps": 1094729, "per_episode_reward": -92.83, "episode_reward_trend_value": 0.007117572175765158, "biggest_recent_change": 0.14152339194012598},
{"total_number_of_episodes": 9423, "number_of_timesteps": 1097218, "per_episode_reward": -92.81, "episode_reward_trend_value": 0.00577232331886282, "biggest_recent_change": 0.13983783490044743},
{"total_number_of_episodes": 9433, "number_of_timesteps": 1101028, "per_episode_reward": -92.77, "episode_reward_trend_value": 0.004660884042730768, "biggest_recent_change": 0.12700649163549826},
{"total_number_of_episodes": 9443, "number_of_timesteps": 1105693, "per_episode_reward": -92.77, "episode_reward_trend_value": 0.004617445154161241, "biggest_recent_change": 0.12700649163549826},
{"total_number_of_episodes": 9453, "number_of_timesteps": 1111464, "per_episode_reward": -92.7, "episode_reward_trend_value": 0.004952545603822184, "biggest_recent_change": 0.12700649163549826},
{"total_number_of_episodes": 9463, "number_of_timesteps": 1115290, "per_episode_reward": -92.69, "episode_reward_trend_value": 0.0049388979861052775, "biggest_recent_change": 0.12700649163549826},
{"total_number_of_episodes": 9473, "number_of_timesteps": 1121179, "per_episode_reward": -92.58, "episode_reward_trend_value": 0.005569115830765586, "biggest_recent_change": 0.12700649163549826},
{"total_number_of_episodes": 9483, "number_of_timesteps": 1125641, "per_episode_reward": -92.46, "episode_reward_trend_value": 0.0068327588530114735, "biggest_recent_change": 0.12700649163549826},
{"total_number_of_episodes": 9494, "number_of_timesteps": 1131579, "per_episode_reward": -92.24, "episode_reward_trend_value": 0.008027552224140777, "biggest_recent_change": 0.22366636969240972},
{"total_number_of_episodes": 9504, "number_of_timesteps": 1135734, "per_episode_reward": -92.21, "episode_reward_trend_value": 0.0069311189494355415, "biggest_recent_change": 0.22366636969240972},
{"total_number_of_episodes": 9514, "number_of_timesteps": 1139793, "per_episode_reward": -92.03, "episode_reward_trend_value": 0.008722498869476977, "biggest_recent_change": 0.22366636969240972},
{"total_number_of_episodes": 9524, "number_of_timesteps": 1141659, "per_episode_reward": -92.0, "episode_reward_trend_value": 0.008642421388085273, "biggest_recent_change": 0.22366636969240972},
{"total_number_of_episodes": 9534, "number_of_timesteps": 1144344, "per_episode_reward": -91.98, "episode_reward_trend_value": 0.008829577139919643, "biggest_recent_change": 0.22366636969240972},
{"total_number_of_episodes": 9544, "number_of_timesteps": 1147568, "per_episode_reward": -91.86, "episode_reward_trend_value": 0.009360388676902668, "biggest_recent_change": 0.22366636969240972},
{"total_number_of_episodes": 9554, "number_of_timesteps": 1150756, "per_episode_reward": -91.86, "episode_reward_trend_value": 0.009189755810794824, "biggest_recent_change": 0.22366636969240972},
{"total_number_of_episodes": 9564, "number_of_timesteps": 1152526, "per_episode_reward": -91.73, "episode_reward_trend_value": 0.009457252665386464, "biggest_recent_change": 0.22366636969240972},
{"total_number_of_episodes": 9574, "number_of_timesteps": 1154655, "per_episode_reward": -91.7, "episode_reward_trend_value": 0.008500715374029728, "biggest_recent_change": 0.22366636969240972},
{"total_number_of_episodes": 9584, "number_of_timesteps": 1157098, "per_episode_reward": -91.67, "episode_reward_trend_value": 0.006319678785944266, "biggest_recent_change": 0.18167518762264478},
{"total_number_of_episodes": 9594, "number_of_timesteps": 1160497, "per_episode_reward": -91.55, "episode_reward_trend_value": 0.007365491478283401, "biggest_recent_change": 0.18167518762264478},
{"total_number_of_episodes": 9604, "number_of_timesteps": 1164115, "per_episode_reward": -91.4, "episode_reward_trend_value": 0.007022355156895482, "biggest_recent_change": 0.15079291869773215},
{"total_number_of_episodes": 9614, "number_of_timesteps": 1167323, "per_episode_reward": -91.36, "episode_reward_trend_value": 0.007109910138013554, "biggest_recent_change": 0.15079291869773215},
{"total_number_of_episodes": 9624, "number_of_timesteps": 1171525, "per_episode_reward": -91.29, "episode_reward_trend_value": 0.007622642025209814, "biggest_recent_change": 0.15079291869773215},
{"total_number_of_episodes": 9634, "number_of_timesteps": 1175733, "per_episode_reward": -91.19, "episode_reward_trend_value": 0.0074830984424356945, "biggest_recent_change": 0.15079291869773215},
{"total_number_of_episodes": 9644, "number_of_timesteps": 1180315, "per_episode_reward": -91.15, "episode_reward_trend_value": 0.007914383980339324, "biggest_recent_change": 0.15079291869773215},
{"total_number_of_episodes": 9654, "number_of_timesteps": 1186274, "per_episode_reward": -91.1, "episode_reward_trend_value": 0.006958662653783814, "biggest_recent_change": 0.15079291869773215},
{"total_number_of_episodes": 9664, "number_of_timesteps": 1193457, "per_episode_reward": -91.03, "episode_reward_trend_value": 0.007387645628375436, "biggest_recent_change": 0.15079291869773215},
{"total_number_of_episodes": 9674, "number_of_timesteps": 1200660, "per_episode_reward": -90.95, "episode_reward_trend_value": 0.007963987951328811, "biggest_recent_change": 0.15079291869773215},
{"total_number_of_episodes": 9684, "number_of_timesteps": 1205338, "per_episode_reward": -90.91, "episode_reward_trend_value": 0.007103093122137712, "biggest_recent_change": 0.15079291869773215},
{"total_number_of_episodes": 9694, "number_of_timesteps": 1208580, "per_episode_reward": -90.83, "episode_reward_trend_value": 0.006273911967181631, "biggest_recent_change": 0.10648458199598565},
{"total_number_of_episodes": 9704, "number_of_timesteps": 1212795, "per_episode_reward": -90.75, "episode_reward_trend_value": 0.0067046683297663084, "biggest_recent_change": 0.10648458199598565},
{"total_number_of_episodes": 9714, "number_of_timesteps": 1217110, "per_episode_reward": -90.71, "episode_reward_trend_value": 0.0064983459298365645, "biggest_recent_change": 0.10648458199598565},
{"total_number_of_episodes": 9724, "number_of_timesteps": 1222243, "per_episode_reward": -90.62, "episode_reward_trend_value": 0.006253939551636575, "biggest_recent_change": 0.08448800795798661},
{"total_number_of_episodes": 9734, "number_of_timesteps": 1226650, "per_episode_reward": -90.54, "episode_reward_trend_value": 0.006852039607363578, "biggest_recent_change": 0.08921648942379079},
{"total_number_of_episodes": 9744, "number_of_timesteps": 1230276, "per_episode_reward": -90.48, "episode_reward_trend_value": 0.0069338959331045336, "biggest_recent_change": 0.08921648942379079},
{"total_number_of_episodes": 9754, "number_of_timesteps": 1235652, "per_episode_reward": -90.42, "episode_reward_trend_value": 0.0067565743615694545, "biggest_recent_change": 0.08921648942379079},
{"total_number_of_episodes": 9764, "number_of_timesteps": 1244216, "per_episode_reward": -90.32, "episode_reward_trend_value": 0.007058336930999569, "biggest_recent_change": 0.10640251707923198},
{"total_number_of_episodes": 9774, "number_of_timesteps": 1252602, "per_episode_reward": -90.27, "episode_reward_trend_value": 0.007099347470506718, "biggest_recent_change": 0.10640251707923198},
{"total_number_of_episodes": 9785, "number_of_timesteps": 1256986, "per_episode_reward": -90.12, "episode_reward_trend_value": 0.007906180399729281, "biggest_recent_change": 0.14878157838171546},
{"total_number_of_episodes": 9796, "number_of_timesteps": 1259835, "per_episode_reward": -89.97, "episode_reward_trend_value": 0.008669865785916248, "biggest_recent_change": 0.14878157838171546},
{"total_number_of_episodes": 9806, "number_of_timesteps": 1262322, "per_episode_reward": -89.92, "episode_reward_trend_value": 0.00881396392084639, "biggest_recent_change": 0.14878157838171546},
{"total_number_of_episodes": 9816, "number_of_timesteps": 1269292, "per_episode_reward": -89.8, "episode_reward_trend_value": 0.009123628741003939, "biggest_recent_change": 0.14878157838171546},
{"total_number_of_episodes": 9826, "number_of_timesteps": 1272605, "per_episode_reward": -89.74, "episode_reward_trend_value": 0.008817293542333163, "biggest_recent_change": 0.14878157838171546},
{"total_number_of_episodes": 9836, "number_of_timesteps": 1275968, "per_episode_reward": -89.59, "episode_reward_trend_value": 0.009918892628442994, "biggest_recent_change": 0.1557129665264796},
{"total_number_of_episodes": 9846, "number_of_timesteps": 1278737, "per_episode_reward": -89.48, "episode_reward_trend_value": 0.010546035478361342, "biggest_recent_change": 0.1557129665264796},
{"total_number_of_episodes": 9856, "number_of_timesteps": 1283345, "per_episode_reward": -89.4, "episode_reward_trend_value": 0.010156585375655424, "biggest_recent_change": 0.1557129665264796},
{"total_number_of_episodes": 9867, "number_of_timesteps": 1290662, "per_episode_reward": -89.41, "episode_reward_trend_value": 0.009572786492847582, "biggest_recent_change": 0.1557129665264796},
{"total_number_of_episodes": 9877, "number_of_timesteps": 1294128, "per_episode_reward": -89.42, "episode_reward_trend_value": 0.007735914955272626, "biggest_recent_change": 0.1557129665264796},
{"total_number_of_episodes": 9887, "number_of_timesteps": 1302224, "per_episode_reward": -89.38, "episode_reward_trend_value": 0.006630587221315427, "biggest_recent_change": 0.1557129665264796},
{"total_number_of_episodes": 9897, "number_of_timesteps": 1311355, "per_episode_reward": -89.31, "episode_reward_trend_value": 0.006701138317310217, "biggest_recent_change": 0.1557129665264796},
{"total_number_of_episodes": 9907, "number_of_timesteps": 1318916, "per_episode_reward": -89.27, "episode_reward_trend_value": 0.00587539906190639, "biggest_recent_change": 0.1557129665264796},
{"total_number_of_episodes": 9917, "number_of_timesteps": 1326637, "per_episode_reward": -89.17, "episode_reward_trend_value": 0.006372932582172079, "biggest_recent_change": 0.1557129665264796},
{"total_number_of_episodes": 9927, "number_of_timesteps": 1331052, "per_episode_reward": -89.05, "episode_reward_trend_value": 0.006005437997389941, "biggest_recent_change": 0.12263845389608719},
{"total_number_of_episodes": 9937, "number_of_timesteps": 1335596, "per_episode_reward": -88.99, "episode_reward_trend_value": 0.005380751782616737, "biggest_recent_change": 0.12263845389608719},
{"total_number_of_episodes": 9947, "number_of_timesteps": 1342962, "per_episode_reward": -88.89, "episode_reward_trend_value": 0.005709824502655497, "biggest_recent_change": 0.12263845389608719},
{"total_number_of_episodes": 9957, "number_of_timesteps": 1349628, "per_episode_reward": -88.82, "episode_reward_trend_value": 0.006514550129807775, "biggest_recent_change": 0.12263845389608719},
{"total_number_of_episodes": 9967, "number_of_timesteps": 1358014, "per_episode_reward": -88.78, "episode_reward_trend_value": 0.007117287293261792, "biggest_recent_change": 0.12263845389608719},
{"total_number_of_episodes": 9977, "number_of_timesteps": 1366920, "per_episode_reward": -88.67, "episode_reward_trend_value": 0.007810389823873247, "biggest_recent_change": 0.12263845389608719},
{"total_number_of_episodes": 9987, "number_of_timesteps": 1373334, "per_episode_reward": -88.58, "episode_reward_trend_value": 0.008101032238163618, "biggest_recent_change": 0.12263845389608719},
{"total_number_of_episodes": 9997, "number_of_timesteps": 1383135, "per_episode_reward": -88.55, "episode_reward_trend_value": 0.00808859011016349, "biggest_recent_change": 0.12263845389608719},
{"total_number_of_episodes": 10007, "number_of_timesteps": 1391870, "per_episode_reward": -88.47, "episode_reward_trend_value": 0.0077682230772064525, "biggest_recent_change": 0.12263845389608719},
{"total_number_of_episodes": 10017, "number_of_timesteps": 1401287, "per_episode_reward": -88.4, "episode_reward_trend_value": 0.007141815261676893, "biggest_recent_change": 0.11088076411226666},
{"total_number_of_episodes": 10027, "number_of_timesteps": 1407707, "per_episode_reward": -88.34, "episode_reward_trend_value": 0.007286091695671991, "biggest_recent_change": 0.11088076411226666},
{"total_number_of_episodes": 10037, "number_of_timesteps": 1413727, "per_episode_reward": -88.32, "episode_reward_trend_value": 0.006347592129489972, "biggest_recent_change": 0.11088076411226666},
{"total_number_of_episodes": 10047, "number_of_timesteps": 1420735, "per_episode_reward": -88.23, "episode_reward_trend_value": 0.006624657287134521, "biggest_recent_change": 0.11088076411226666},
{"total_number_of_episodes": 10057, "number_of_timesteps": 1429828, "per_episode_reward": -88.13, "episode_reward_trend_value": 0.007235510192659137, "biggest_recent_change": 0.11088076411226666},
{"total_number_of_episodes": 10067, "number_of_timesteps": 1439531, "per_episode_reward": -88.04, "episode_reward_trend_value": 0.0070319165873044655, "biggest_recent_change": 0.09348032433000242},
{"total_number_of_episodes": 10077, "number_of_timesteps": 1449531, "per_episode_reward": -87.98, "episode_reward_trend_value": 0.006752914493593841, "biggest_recent_change": 0.09348032433000242},
{"total_number_of_episodes": 10087, "number_of_timesteps": 1456658, "per_episode_reward": -87.91, "episode_reward_trend_value": 0.007105877991268825, "biggest_recent_change": 0.09348032433000242},
{"total_number_of_episodes": 10097, "number_of_timesteps": 1461280, "per_episode_reward": -87.85, "episode_reward_trend_value": 0.006836750540531335, "biggest_recent_change": 0.09348032433000242},
{"total_number_of_episodes": 10107, "number_of_timesteps": 1466823, "per_episode_reward": -87.77, "episode_reward_trend_value": 0.006978112003203624, "biggest_recent_change": 0.09348032433000242},
{"total_number_of_episodes": 10117, "number_of_timesteps": 1471960, "per_episode_reward": -87.73, "episode_reward_trend_value": 0.00675230562411176, "biggest_recent_change": 0.09348032433000242},
{"total_number_of_episodes": 10127, "number_of_timesteps": 1476706, "per_episode_reward": -87.64, "episode_reward_trend_value": 0.007591309184370232, "biggest_recent_change": 0.09348032433000242},
{"total_number_of_episodes": 10138, "number_of_timesteps": 1487391, "per_episode_reward": -87.59, "episode_reward_trend_value": 0.007024522306035881, "biggest_recent_change": 0.09268624620804644},
{"total_number_of_episodes": 10149, "number_of_timesteps": 1496168, "per_episode_reward": -87.56, "episode_reward_trend_value": 0.006343754052884442, "biggest_recent_change": 0.09255733963034629},
{"total_number_of_episodes": 10159, "number_of_timesteps": 1500299, "per_episode_reward": -87.5, "episode_reward_trend_value": 0.005971697122459179, "biggest_recent_change": 0.09201391210606857},
{"total_number_of_episodes": 10169, "number_of_timesteps": 1504111, "per_episode_reward": -87.39, "episode_reward_trend_value": 0.0065235841936770265, "biggest_recent_change": 0.1145370154666665},
{"total_number_of_episodes": 10179, "number_of_timesteps": 1508198, "per_episode_reward": -87.33, "episode_reward_trend_value": 0.00641147458483352, "biggest_recent_change": 0.1145370154666665},
{"total_number_of_episodes": 10189, "number_of_timesteps": 1518198, "per_episode_reward": -87.28, "episode_reward_trend_value": 0.006393417716902485, "biggest_recent_change": 0.1145370154666665},
{"total_number_of_episodes": 10199, "number_of_timesteps": 1527066, "per_episode_reward": -87.25, "episode_reward_trend_value": 0.005844946465422475, "biggest_recent_change": 0.1145370154666665},
{"total_number_of_episodes": 10209, "number_of_timesteps": 1532722, "per_episode_reward": -87.15, "episode_reward_trend_value": 0.006373576384459215, "biggest_recent_change": 0.1145370154666665},
{"total_number_of_episodes": 10219, "number_of_timesteps": 1536397, "per_episode_reward": -87.1, "episode_reward_trend_value": 0.005960441699307732, "biggest_recent_change": 0.1145370154666665},
{"total_number_of_episodes": 10229, "number_of_timesteps": 1539472, "per_episode_reward": -87.05, "episode_reward_trend_value": 0.006013141865150987, "biggest_recent_change": 0.1145370154666665},
{"total_number_of_episodes": 10239, "number_of_timesteps": 1543210, "per_episode_reward": -87.0, "episode_reward_trend_value": 0.006231240646446186, "biggest_recent_change": 0.1145370154666665},
{"total_number_of_episodes": 10249, "number_of_timesteps": 1547204, "per_episode_reward": -86.95, "episode_reward_trend_value": 0.0061932772248806285, "biggest_recent_change": 0.1145370154666665},
{"total_number_of_episodes": 10259, "number_of_timesteps": 1550002, "per_episode_reward": -86.9, "episode_reward_trend_value": 0.0054078309709571695, "biggest_recent_change": 0.09414716894478659},
{"total_number_of_episodes": 10269, "number_of_timesteps": 1552894, "per_episode_reward": -86.83, "episode_reward_trend_value": 0.005596004649976452, "biggest_recent_change": 0.09414716894478659},
{"total_number_of_episodes": 10279, "number_of_timesteps": 1556619, "per_episode_reward": -86.68, "episode_reward_trend_value": 0.006652081492917243, "biggest_recent_change": 0.14679163258570327},
{"total_number_of_episodes": 10289, "number_of_timesteps": 1559715, "per_episode_reward": -86.61, "episode_reward_trend_value": 0.007134985884196175, "biggest_recent_change": 0.14679163258570327},
{"total_number_of_episodes": 10299, "number_of_timesteps": 1564952, "per_episode_reward": -86.53, "episode_reward_trend_value": 0.00691088927299022, "biggest_recent_change": 0.14679163258570327},
{"total_number_of_episodes": 10309, "number_of_timesteps": 1570985, "per_episode_reward": -86.49, "episode_reward_trend_value": 0.0068149605725188345, "biggest_recent_change": 0.14679163258570327},
{"total_number_of_episodes": 10319, "number_of_timesteps": 1578488, "per_episode_reward": -86.48, "episode_reward_trend_value": 0.006355545307936142, "biggest_recent_change": 0.14679163258570327},
{"total_number_of_episodes": 10329, "number_of_timesteps": 1585353, "per_episode_reward": -86.44, "episode_reward_trend_value": 0.0061910401989671805, "biggest_recent_change": 0.14679163258570327},
{"total_number_of_episodes": 10339, "number_of_timesteps": 1590563, "per_episode_reward": -86.42, "episode_reward_trend_value": 0.005885205103689531, "biggest_recent_change": 0.14679163258570327},
{"total_number_of_episodes": 10349, "number_of_timesteps": 1594509, "per_episode_reward": -86.36, "episode_reward_trend_value": 0.006051417308024535, "biggest_recent_change": 0.14679163258570327},
{"total_number_of_episodes": 10359, "number_of_timesteps": 1598465, "per_episode_reward": -86.29, "episode_reward_trend_value": 0.005977734464284702, "biggest_recent_change": 0.14679163258570327},
{"total_number_of_episodes": 10369, "number_of_timesteps": 1601639, "per_episode_reward": -86.09, "episode_reward_trend_value": 0.006574563291853824, "biggest_recent_change": 0.20050622706692423},
{"total_number_of_episodes": 10379, "number_of_timesteps": 1604844, "per_episode_reward": -85.93, "episode_reward_trend_value": 0.007569571229518443, "biggest_recent_change": 0.20050622706692423},
{"total_number_of_episodes": 10389, "number_of_timesteps": 1608011, "per_episode_reward": -85.89, "episode_reward_trend_value": 0.007140426173889441, "biggest_recent_change": 0.20050622706692423},
{"total_number_of_episodes": 10399, "number_of_timesteps": 1611860, "per_episode_reward": -85.85, "episode_reward_trend_value": 0.007086354952339807, "biggest_recent_change": 0.20050622706692423},
{"total_number_of_episodes": 10409, "number_of_timesteps": 1617256, "per_episode_reward": -85.7, "episode_reward_trend_value": 0.008645346743146359, "biggest_recent_change": 0.20050622706692423},
{"total_number_of_episodes": 10419, "number_of_timesteps": 1623859, "per_episode_reward": -85.64, "episode_reward_trend_value": 0.008933208479008511, "biggest_recent_change": 0.20050622706692423},
{"total_number_of_episodes": 10429, "number_of_timesteps": 1631272, "per_episode_reward": -85.6, "episode_reward_trend_value": 0.009022000704638976, "biggest_recent_change": 0.20050622706692423},
{"total_number_of_episodes": 10439, "number_of_timesteps": 1640108, "per_episode_reward": -85.58, "episode_reward_trend_value": 0.008603018455933567, "biggest_recent_change": 0.20050622706692423},
{"total_number_of_episodes": 10449, "number_of_timesteps": 1647184, "per_episode_reward": -85.53, "episode_reward_trend_value": 0.008393218110607689, "biggest_recent_change": 0.20050622706692423},
{"total_number_of_episodes": 10459, "number_of_timesteps": 1650875, "per_episode_reward": -85.49, "episode_reward_trend_value": 0.006601096905844707, "biggest_recent_change": 0.1626339791106517},
{"total_number_of_episodes": 10469, "number_of_timesteps": 1655038, "per_episode_reward": -85.46, "episode_reward_trend_value": 0.00515384571269332, "biggest_recent_change": 0.14617440756595101},
{"total_number_of_episodes": 10479, "number_of_timesteps": 1659313, "per_episode_reward": -85.39, "episode_reward_trend_value": 0.005588314586964632, "biggest_recent_change": 0.14617440756595101},
{"total_number_of_episodes": 10489, "number_of_timesteps": 1662682, "per_episode_reward": -85.3, "episode_reward_trend_value": 0.006142580999488069, "biggest_recent_change": 0.14617440756595101},
{"total_number_of_episodes": 10499, "number_of_timesteps": 1667205, "per_episode_reward": -85.24, "episode_reward_trend_value": 0.00514121454331931, "biggest_recent_change": 0.09121577458765273},
{"total_number_of_episodes": 10509, "number_of_timesteps": 1671572, "per_episode_reward": -85.19, "episode_reward_trend_value": 0.005017280305799766, "biggest_recent_change": 0.09121577458765273},
{"total_number_of_episodes": 10519, "number_of_timesteps": 1676270, "per_episode_reward": -85.11, "episode_reward_trend_value": 0.005438875290369557, "biggest_recent_change": 0.09121577458765273},
{"total_number_of_episodes": 10529, "number_of_timesteps": 1679401, "per_episode_reward": -85.07, "episode_reward_trend_value": 0.0057390595022896364, "biggest_recent_change": 0.09121577458765273},
{"total_number_of_episodes": 10539, "number_of_timesteps": 1682623, "per_episode_reward": -84.93, "episode_reward_trend_value": 0.006682658795923639, "biggest_recent_change": 0.13494444778352488},
{"total_number_of_episodes": 10549, "number_of_timesteps": 1689313, "per_episode_reward": -84.89, "episode_reward_trend_value": 0.006722035306859514, "biggest_recent_change": 0.13494444778352488},
{"total_number_of_episodes": 10559, "number_of_timesteps": 1697989, "per_episode_reward": -84.83, "episode_reward_trend_value": 0.007061202866751949, "biggest_recent_change": 0.13494444778352488},
{"total_number_of_episodes": 10569, "number_of_timesteps": 1706422, "per_episode_reward": -84.73, "episode_reward_trend_value": 0.0073194322434037284, "biggest_recent_change": 0.13494444778352488},
{"total_number_of_episodes": 10579, "number_of_timesteps": 1715874, "per_episode_reward": -84.62, "episode_reward_trend_value": 0.007495723090451318, "biggest_recent_change": 0.13494444778352488},
{"total_number_of_episodes": 10589, "number_of_timesteps": 1724207, "per_episode_reward": -84.6, "episode_reward_trend_value": 0.007122188550351577, "biggest_recent_change": 0.13494444778352488},
{"total_number_of_episodes": 10599, "number_of_timesteps": 1729248, "per_episode_reward": -84.58, "episode_reward_trend_value": 0.006756949345060864, "biggest_recent_change": 0.13494444778352488},
{"total_number_of_episodes": 10609, "number_of_timesteps": 1734768, "per_episode_reward": -84.53, "episode_reward_trend_value": 0.006534794556484434, "biggest_recent_change": 0.13494444778352488},
{"total_number_of_episodes": 10619, "number_of_timesteps": 1743911, "per_episode_reward": -84.4, "episode_reward_trend_value": 0.007349100945152208, "biggest_recent_change": 0.13494444778352488},
{"total_number_of_episodes": 10629, "number_of_timesteps": 1749609, "per_episode_reward": -84.3, "episode_reward_trend_value": 0.00705272794543248, "biggest_recent_change": 0.12140170267312556},
{"total_number_of_episodes": 10639, "number_of_timesteps": 1755692, "per_episode_reward": -84.23, "episode_reward_trend_value": 0.007283599081359979, "biggest_recent_change": 0.12140170267312556},
{"total_number_of_episodes": 10650, "number_of_timesteps": 1760915, "per_episode_reward": -84.15, "episode_reward_trend_value": 0.007454413989647751, "biggest_recent_change": 0.12140170267312556},
{"total_number_of_episodes": 10660, "number_of_timesteps": 1764350, "per_episode_reward": -84.11, "episode_reward_trend_value": 0.006886552982604144, "biggest_recent_change": 0.12140170267312556},
{"total_number_of_episodes": 10670, "number_of_timesteps": 1766741, "per_episode_reward": -83.98, "episode_reward_trend_value": 0.007074910051957614, "biggest_recent_change": 0.12403408706374819},
{"total_number_of_episodes": 10680, "number_of_timesteps": 1769055, "per_episode_reward": -83.92, "episode_reward_trend_value": 0.007576915266907729, "biggest_recent_change": 0.12403408706374819},
{"total_number_of_episodes": 10690, "number_of_timesteps": 1772298, "per_episode_reward": -83.81, "episode_reward_trend_value": 0.008588833948744599, "biggest_recent_change": 0.12403408706374819},
{"total_number_of_episodes": 10700, "number_of_timesteps": 1774872, "per_episode_reward": -83.71, "episode_reward_trend_value": 0.009036348145907248, "biggest_recent_change": 0.12403408706374819},
{"total_number_of_episodes": 10710, "number_of_timesteps": 1777275, "per_episode_reward": -83.65, "episode_reward_trend_value": 0.00838044901344593, "biggest_recent_change": 0.12403408706374819},
{"total_number_of_episodes": 10720, "number_of_timesteps": 1780496, "per_episode_reward": -83.67, "episode_reward_trend_value": 0.007005286899042397, "biggest_recent_change": 0.12403408706374819},
{"total_number_of_episodes": 10730, "number_of_timesteps": 1786624, "per_episode_reward": -83.61, "episode_reward_trend_value": 0.006927339576011901, "biggest_recent_change": 0.12403408706374819},
{"total_number_of_episodes": 10740, "number_of_timesteps": 1791521, "per_episode_reward": -83.46, "episode_reward_trend_value": 0.007750973534594784, "biggest_recent_change": 0.15240685013570499},
{"total_number_of_episodes": 10750, "number_of_timesteps": 1799972, "per_episode_reward": -83.39, "episode_reward_trend_value": 0.00802044193179954, "biggest_recent_change": 0.15240685013570499},
{"total_number_of_episodes": 10760, "number_of_timesteps": 1806864, "per_episode_reward": -83.31, "episode_reward_trend_value": 0.007530113432519493, "biggest_recent_change": 0.15240685013570499},
{"total_number_of_episodes": 10770, "number_of_timesteps": 1811327, "per_episode_reward": -83.28, "episode_reward_trend_value": 0.0070408904650060816, "biggest_recent_change": 0.15240685013570499},
{"total_number_of_episodes": 10780, "number_of_timesteps": 1814558, "per_episode_reward": -83.26, "episode_reward_trend_value": 0.0061032968177515716, "biggest_recent_change": 0.15240685013570499},
{"total_number_of_episodes": 10790, "number_of_timesteps": 1818003, "per_episode_reward": -83.17, "episode_reward_trend_value": 0.006072061437074044, "biggest_recent_change": 0.15240685013570499},
{"total_number_of_episodes": 10800, "number_of_timesteps": 1823121, "per_episode_reward": -83.02, "episode_reward_trend_value": 0.007052530090067598, "biggest_recent_change": 0.15240685013570499},
{"total_number_of_episodes": 10810, "number_of_timesteps": 1827923, "per_episode_reward": -82.97, "episode_reward_trend_value": 0.007693345776558955, "biggest_recent_change": 0.15240685013570499},
{"total_number_of_episodes": 10820, "number_of_timesteps": 1833634, "per_episode_reward": -82.94, "episode_reward_trend_value": 0.007390067981423304, "biggest_recent_change": 0.15240685013570499},
{"total_number_of_episodes": 10830, "number_of_timesteps": 1839034, "per_episode_reward": -82.87, "episode_reward_trend_value": 0.006559917178341992, "biggest_recent_change": 0.15061295952102682},
{"total_number_of_episodes": 10840, "number_of_timesteps": 1842505, "per_episode_reward": -82.77, "episode_reward_trend_value": 0.006824782666778775, "biggest_recent_change": 0.15061295952102682},
{"total_number_of_episodes": 10850, "number_of_timesteps": 1847213, "per_episode_reward": -82.66, "episode_reward_trend_value": 0.007158712490710666, "biggest_recent_change": 0.15061295952102682},
{"total_number_of_episodes": 10860, "number_of_timesteps": 1850588, "per_episode_reward": -82.63, "episode_reward_trend_value": 0.007294227543510267, "biggest_recent_change": 0.15061295952102682},
{"total_number_of_episodes": 10870, "number_of_timesteps": 1853809, "per_episode_reward": -82.6, "episode_reward_trend_value": 0.007363748070577161, "biggest_recent_change": 0.15061295952102682},
{"total_number_of_episodes": 10881, "number_of_timesteps": 1858400, "per_episode_reward": -82.53, "episode_reward_trend_value": 0.007074300351485381, "biggest_recent_change": 0.15061295952102682},
{"total_number_of_episodes": 10892, "number_of_timesteps": 1861643, "per_episode_reward": -82.48, "episode_reward_trend_value": 0.005935725985747177, "biggest_recent_change": 0.10995820628241404},
{"total_number_of_episodes": 10903, "number_of_timesteps": 1864746, "per_episode_reward": -82.42, "episode_reward_trend_value": 0.006194918521012482, "biggest_recent_change": 0.10995820628241404},
{"total_number_of_episodes": 10913, "number_of_timesteps": 1867058, "per_episode_reward": -82.38, "episode_reward_trend_value": 0.0062776141311164544, "biggest_recent_change": 0.10995820628241404},
{"total_number_of_episodes": 10923, "number_of_timesteps": 1869920, "per_episode_reward": -82.41, "episode_reward_trend_value": 0.005118425869641561, "biggest_recent_change": 0.10995820628241404},
{"total_number_of_episodes": 10933, "number_of_timesteps": 1872645, "per_episode_reward": -82.45, "episode_reward_trend_value": 0.003560352225915153, "biggest_recent_change": 0.10995820628241404},
{"total_number_of_episodes": 10943, "number_of_timesteps": 1874879, "per_episode_reward": -82.43, "episode_reward_trend_value": 0.0025255353153163978, "biggest_recent_change": 0.06550702747053094},
{"total_number_of_episodes": 10953, "number_of_timesteps": 1877277, "per_episode_reward": -82.38, "episode_reward_trend_value": 0.002758562217518406, "biggest_recent_change": 0.06550702747053094},
{"total_number_of_episodes": 10963, "number_of_timesteps": 1880202, "per_episode_reward": -82.32, "episode_reward_trend_value": 0.0030892227763377237, "biggest_recent_change": 0.06550702747053094},
{"total_number_of_episodes": 10973, "number_of_timesteps": 1882531, "per_episode_reward": -82.16, "episode_reward_trend_value": 0.004056318975361566, "biggest_recent_change": 0.15252472399987482},
{"total_number_of_episodes": 10983, "number_of_timesteps": 1885971, "per_episode_reward": -82.03, "episode_reward_trend_value": 0.0050657072117563946, "biggest_recent_change": 0.15252472399987482},
{"total_number_of_episodes": 10993, "number_of_timesteps": 1888965, "per_episode_reward": -81.96, "episode_reward_trend_value": 0.005113131279040001, "biggest_recent_change": 0.15252472399987482},
{"total_number_of_episodes": 11004, "number_of_timesteps": 1891461, "per_episode_reward": -81.93, "episode_reward_trend_value": 0.005030685298649947, "biggest_recent_change": 0.15252472399987482},
{"total_number_of_episodes": 11014, "number_of_timesteps": 1894782, "per_episode_reward": -81.9, "episode_reward_trend_value": 0.0056482484775341076, "biggest_recent_change": 0.15252472399987482},
{"total_number_of_episodes": 11024, "number_of_timesteps": 1897136, "per_episode_reward": -81.81, "episode_reward_trend_value": 0.007111064107262482, "biggest_recent_change": 0.15252472399987482},
{"total_number_of_episodes": 11034, "number_of_timesteps": 1900463, "per_episode_reward": -81.77, "episode_reward_trend_value": 0.007435696739540908, "biggest_recent_change": 0.15252472399987482},
{"total_number_of_episodes": 11044, "number_of_timesteps": 1904171, "per_episode_reward": -81.7, "episode_reward_trend_value": 0.00755279597936212, "biggest_recent_change": 0.15252472399987482},
{"total_number_of_episodes": 11054, "number_of_timesteps": 1908368, "per_episode_reward": -81.63, "episode_reward_trend_value": 0.007612502899948639, "biggest_recent_change": 0.15252472399987482},
{"total_number_of_episodes": 11064, "number_of_timesteps": 1914486, "per_episode_reward": -81.53, "episode_reward_trend_value": 0.007034371138091603, "biggest_recent_change": 0.13898620788012295},
{"total_number_of_episodes": 11074, "number_of_timesteps": 1919691, "per_episode_reward": -81.47, "episode_reward_trend_value": 0.0062120602908242025, "biggest_recent_change": 0.1004928654327415},
{"total_number_of_episodes": 11084, "number_of_timesteps": 1922042, "per_episode_reward": -81.37, "episode_reward_trend_value": 0.006507826626439339, "biggest_recent_change": 0.1004928654327415},
{"total_number_of_episodes": 11094, "number_of_timesteps": 1925525, "per_episode_reward": -81.35, "episode_reward_trend_value": 0.006386958445849365, "biggest_recent_change": 0.1004928654327415},
{"total_number_of_episodes": 11104, "number_of_timesteps": 1929018, "per_episode_reward": -81.29, "episode_reward_trend_value": 0.006733896996337939, "biggest_recent_change": 0.1004928654327415},
{"total_number_of_episodes": 11114, "number_of_timesteps": 1931908, "per_episode_reward": -81.19, "episode_reward_trend_value": 0.006889062529953411, "biggest_recent_change": 0.1004928654327415},
{"total_number_of_episodes": 11124, "number_of_timesteps": 1937273, "per_episode_reward": -81.15, "episode_reward_trend_value": 0.006786517698809608, "biggest_recent_change": 0.1004928654327415},
{"total_number_of_episodes": 11134, "number_of_timesteps": 1943973, "per_episode_reward": -81.12, "episode_reward_trend_value": 0.006400457372309315, "biggest_recent_change": 0.1004928654327415},
{"total_number_of_episodes": 11144, "number_of_timesteps": 1951278, "per_episode_reward": -81.1, "episode_reward_trend_value": 0.00593509888798612, "biggest_recent_change": 0.1004928654327415},
{"total_number_of_episodes": 11154, "number_of_timesteps": 1956476, "per_episode_reward": -81.04, "episode_reward_trend_value": 0.005451471271632298, "biggest_recent_change": 0.10007249735210166},
{"total_number_of_episodes": 11164, "number_of_timesteps": 1961561, "per_episode_reward": -80.99, "episode_reward_trend_value": 0.005300354166937559, "biggest_recent_change": 0.10007249735210166},
{"total_number_of_episodes": 11174, "number_of_timesteps": 1967391, "per_episode_reward": -80.94, "episode_reward_trend_value": 0.004833453718770247, "biggest_recent_change": 0.10007249735210166},
{"total_number_of_episodes": 11184, "number_of_timesteps": 1974114, "per_episode_reward": -80.88, "episode_reward_trend_value": 0.005216271889346539, "biggest_recent_change": 0.10007249735210166},
{"total_number_of_episodes": 11194, "number_of_timesteps": 1979378, "per_episode_reward": -80.85, "episode_reward_trend_value": 0.004938368972015104, "biggest_recent_change": 0.10007249735210166},
{"total_number_of_episodes": 11204, "number_of_timesteps": 1982994, "per_episode_reward": -80.81, "episode_reward_trend_value": 0.004256448217793244, "biggest_recent_change": 0.056966379960897484},
{"total_number_of_episodes": 11214, "number_of_timesteps": 1985276, "per_episode_reward": -80.76, "episode_reward_trend_value": 0.004376493773559136, "biggest_recent_change": 0.056966379960897484},
{"total_number_of_episodes": 11224, "number_of_timesteps": 1988652, "per_episode_reward": -80.69, "episode_reward_trend_value": 0.004773241113438252, "biggest_recent_change": 0.0682532589092375},
{"total_number_of_episodes": 11234, "number_of_timesteps": 1991091, "per_episode_reward": -80.61, "episode_reward_trend_value": 0.005458740451728911, "biggest_recent_change": 0.08601433086047905},
{"total_number_of_episodes": 11244, "number_of_timesteps": 1992960, "per_episode_reward": -80.57, "episode_reward_trend_value": 0.005284035818077055, "biggest_recent_change": 0.08601433086047905},
{"total_number_of_episodes": 11254, "number_of_timesteps": 1995051, "per_episode_reward": -80.52, "episode_reward_trend_value": 0.005237594589045279, "biggest_recent_change": 0.08601433086047905},
{"total_number_of_episodes": 11264, "number_of_timesteps": 1996980, "per_episode_reward": -80.47, "episode_reward_trend_value": 0.005118867930856968, "biggest_recent_change": 0.08601433086047905},
{"total_number_of_episodes": 11274, "number_of_timesteps": 1998906, "per_episode_reward": -80.44, "episode_reward_trend_value": 0.0049070894052650575, "biggest_recent_change": 0.08601433086047905},
{"total_number_of_episodes": 11284, "number_of_timesteps": 2000826, "per_episode_reward": -80.39, "episode_reward_trend_value": 0.0050542327658228536, "biggest_recent_change": 0.08601433086047905},
{"total_number_of_episodes": 11294, "number_of_timesteps": 2003637, "per_episode_reward": -80.27, "episode_reward_trend_value": 0.0060139044722294305, "biggest_recent_change": 0.12507008304872613},
{"total_number_of_episodes": 11304, "number_of_timesteps": 2007377, "per_episode_reward": -80.2, "episode_reward_trend_value": 0.006242707260619321, "biggest_recent_change": 0.12507008304872613},
{"total_number_of_episodes": 11314, "number_of_timesteps": 2010402, "per_episode_reward": -80.16, "episode_reward_trend_value": 0.005955510891541217, "biggest_recent_change": 0.12507008304872613},
{"total_number_of_episodes": 11324, "number_of_timesteps": 2015581, "per_episode_reward": -80.01, "episode_reward_trend_value": 0.006594991991055584, "biggest_recent_change": 0.14356762981677207},
{"total_number_of_episodes": 11334, "number_of_timesteps": 2020129, "per_episode_reward": -79.89, "episode_reward_trend_value": 0.00753233607710955, "biggest_recent_change": 0.14356762981677207},
{"total_number_of_episodes": 11344, "number_of_timesteps": 2025025, "per_episode_reward": -79.83, "episode_reward_trend_value": 0.007664632045309992, "biggest_recent_change": 0.14356762981677207},
{"total_number_of_episodes": 11354, "number_of_timesteps": 2031739, "per_episode_reward": -79.8, "episode_reward_trend_value": 0.007524347176660405, "biggest_recent_change": 0.14356762981677207},
{"total_number_of_episodes": 11364, "number_of_timesteps": 2035576, "per_episode_reward": -79.76, "episode_reward_trend_value": 0.0075436320152432595, "biggest_recent_change": 0.14356762981677207},
{"total_number_of_episodes": 11374, "number_of_timesteps": 2039308, "per_episode_reward": -79.69, "episode_reward_trend_value": 0.0077938807849397065, "biggest_recent_change": 0.14356762981677207},
{"total_number_of_episodes": 11384, "number_of_timesteps": 2043677, "per_episode_reward": -79.67, "episode_reward_trend_value": 0.006659935538459333, "biggest_recent_change": 0.14356762981677207},
{"total_number_of_episodes": 11394, "number_of_timesteps": 2047187, "per_episode_reward": -79.56, "episode_reward_trend_value": 0.007087817836258302, "biggest_recent_change": 0.14356762981677207},
{"total_number_of_episodes": 11404, "number_of_timesteps": 2053125, "per_episode_reward": -79.53, "episode_reward_trend_value": 0.006993411568269575, "biggest_recent_change": 0.14356762981677207},
{"total_number_of_episodes": 11414, "number_of_timesteps": 2059201, "per_episode_reward": -79.48, "episode_reward_trend_value": 0.005881370712320372, "biggest_recent_change": 0.1256039306770873},
{"total_number_of_episodes": 11424, "number_of_timesteps": 2062449, "per_episode_reward": -79.44, "episode_reward_trend_value": 0.005007268872145529, "biggest_recent_change": 0.10671834420656978},
{"total_number_of_episodes": 11434, "number_of_timesteps": 2065485, "per_episode_reward": -79.37, "episode_reward_trend_value": 0.0050835331746288005, "biggest_recent_change": 0.10671834420656978},
{"total_number_of_episodes": 11444, "number_of_timesteps": 2068261, "per_episode_reward": -79.33, "episode_reward_trend_value": 0.005215168526426655, "biggest_recent_change": 0.10671834420656978},
{"total_number_of_episodes": 11455, "number_of_timesteps": 2070905, "per_episode_reward": -79.15, "episode_reward_trend_value": 0.006753324606078574, "biggest_recent_change": 0.1739349273318851},
{"total_number_of_episodes": 11465, "number_of_timesteps": 2073456, "per_episode_reward": -79.14, "episode_reward_trend_value": 0.006132791641576634, "biggest_recent_change": 0.1739349273318851},
{"total_number_of_episodes": 11476, "number_of_timesteps": 2076601, "per_episode_reward": -79.11, "episode_reward_trend_value": 0.006217384395055584, "biggest_recent_change": 0.1739349273318851},
{"total_number_of_episodes": 11486, "number_of_timesteps": 2079391, "per_episode_reward": -79.07, "episode_reward_trend_value": 0.0054850429536581185, "biggest_recent_change": 0.1739349273318851},
{"total_number_of_episodes": 11496, "number_of_timesteps": 2081844, "per_episode_reward": -79.03, "episode_reward_trend_value": 0.005566927089006413, "biggest_recent_change": 0.1739349273318851},
{"total_number_of_episodes": 11506, "number_of_timesteps": 2085237, "per_episode_reward": -78.98, "episode_reward_trend_value": 0.0055619210230159095, "biggest_recent_change": 0.1739349273318851},
{"total_number_of_episodes": 11516, "number_of_timesteps": 2089027, "per_episode_reward": -78.95, "episode_reward_trend_value": 0.0054283834953745705, "biggest_recent_change": 0.1739349273318851},
{"total_number_of_episodes": 11526, "number_of_timesteps": 2092745, "per_episode_reward": -78.92, "episode_reward_trend_value": 0.005043532703271106, "biggest_recent_change": 0.1739349273318851},
{"total_number_of_episodes": 11536, "number_of_timesteps": 2098445, "per_episode_reward": -78.88, "episode_reward_trend_value": 0.004969097686454423, "biggest_recent_change": 0.1739349273318851},
{"total_number_of_episodes": 11546, "number_of_timesteps": 2105127, "per_episode_reward": -78.85, "episode_reward_trend_value": 0.003397031815825042, "biggest_recent_change": 0.043033406842198474},
{"total_number_of_episodes": 11556, "number_of_timesteps": 2110386, "per_episode_reward": -78.77, "episode_reward_trend_value": 0.0040979650106212125, "biggest_recent_change": 0.07816153985872631},
{"total_number_of_episodes": 11567, "number_of_timesteps": 2116025, "per_episode_reward": -78.75, "episode_reward_trend_value": 0.004030950838701921, "biggest_recent_change": 0.07816153985872631},
{"total_number_of_episodes": 11577, "number_of_timesteps": 2121482, "per_episode_reward": -78.69, "episode_reward_trend_value": 0.0041428400467392774, "biggest_recent_change": 0.07816153985872631},
{"total_number_of_episodes": 11587, "number_of_timesteps": 2126994, "per_episode_reward": -78.52, "episode_reward_trend_value": 0.005585596718097937, "biggest_recent_change": 0.17112669417684856},
{"total_number_of_episodes": 11597, "number_of_timesteps": 2130921, "per_episode_reward": -78.45, "episode_reward_trend_value": 0.00596271627916091, "biggest_recent_change": 0.17112669417684856},
{"total_number_of_episodes": 11607, "number_of_timesteps": 2135354, "per_episode_reward": -78.41, "episode_reward_trend_value": 0.005928000148723021, "biggest_recent_change": 0.17112669417684856},
{"total_number_of_episodes": 11617, "number_of_timesteps": 2138977, "per_episode_reward": -78.27, "episode_reward_trend_value": 0.007141793061551817, "biggest_recent_change": 0.17112669417684856},
{"total_number_of_episodes": 11627, "number_of_timesteps": 2142616, "per_episode_reward": -78.23, "episode_reward_trend_value": 0.007179226587422091, "biggest_recent_change": 0.17112669417684856},
{"total_number_of_episodes": 11637, "number_of_timesteps": 2147489, "per_episode_reward": -78.21, "episode_reward_trend_value": 0.0071224621110287795, "biggest_recent_change": 0.17112669417684856},
{"total_number_of_episodes": 11647, "number_of_timesteps": 2153942, "per_episode_reward": -78.16, "episode_reward_trend_value": 0.006727502961729373, "biggest_recent_change": 0.17112669417684856},
{"total_number_of_episodes": 11657, "number_of_timesteps": 2162258, "per_episode_reward": -78.1, "episode_reward_trend_value": 0.007132183526797557, "biggest_recent_change": 0.17112669417684856},
{"total_number_of_episodes": 11667, "number_of_timesteps": 2167673, "per_episode_reward": -78.07, "episode_reward_trend_value": 0.006994031240847044, "biggest_recent_change": 0.17112669417684856},
{"total_number_of_episodes": 11678, "number_of_timesteps": 2173019, "per_episode_reward": -78.04, "episode_reward_trend_value": 0.005366094394483411, "biggest_recent_change": 0.1405731968174848},
{"total_number_of_episodes": 11688, "number_of_timesteps": 2178082, "per_episode_reward": -77.99, "episode_reward_trend_value": 0.005021953964564969, "biggest_recent_change": 0.1405731968174848},
{"total_number_of_episodes": 11698, "number_of_timesteps": 2183858, "per_episode_reward": -77.95, "episode_reward_trend_value": 0.00520299253238679, "biggest_recent_change": 0.1405731968174848},
{"total_number_of_episodes": 11708, "number_of_timesteps": 2188818, "per_episode_reward": -77.88, "episode_reward_trend_value": 0.004341283417235786, "biggest_recent_change": 0.06301937645389444},
{"total_number_of_episodes": 11718, "number_of_timesteps": 2193227, "per_episode_reward": -77.83, "episode_reward_trend_value": 0.004544467473025154, "biggest_recent_change": 0.06301937645389444},
{"total_number_of_episodes": 11728, "number_of_timesteps": 2196902, "per_episode_reward": -77.76, "episode_reward_trend_value": 0.004962914720477664, "biggest_recent_change": 0.06500044837056862},
{"total_number_of_episodes": 11738, "number_of_timesteps": 2199679, "per_episode_reward": -77.71, "episode_reward_trend_value": 0.005009470143277718, "biggest_recent_change": 0.06500044837056862},
{"total_number_of_episodes": 11748, "number_of_timesteps": 2202421, "per_episode_reward": -77.66, "episode_reward_trend_value": 0.004913155588189335, "biggest_recent_change": 0.06500044837056862},
{"total_number_of_episodes": 11758, "number_of_timesteps": 2205799, "per_episode_reward": -77.61, "episode_reward_trend_value": 0.005046922130155293, "biggest_recent_change": 0.06500044837056862},
{"total_number_of_episodes": 11768, "number_of_timesteps": 2209301, "per_episode_reward": -77.59, "episode_reward_trend_value": 0.005036972570973969, "biggest_recent_change": 0.06500044837056862},
{"total_number_of_episodes": 11778, "number_of_timesteps": 2214674, "per_episode_reward": -77.53, "episode_reward_trend_value": 0.005133580205825518, "biggest_recent_change": 0.06500044837056862},
{"total_number_of_episodes": 11788, "number_of_timesteps": 2222973, "per_episode_reward": -77.41, "episode_reward_trend_value": 0.005967962170015698, "biggest_recent_change": 0.12317978371530103},
{"total_number_of_episodes": 11798, "number_of_timesteps": 2229749, "per_episode_reward": -77.27, "episode_reward_trend_value": 0.00685356007349785, "biggest_recent_change": 0.1427231877672881},
{"total_number_of_episodes": 11808, "number_of_timesteps": 2236905, "per_episode_reward": -77.23, "episode_reward_trend_value": 0.006632060063414258, "biggest_recent_change": 0.1427231877672881},
{"total_number_of_episodes": 11818, "number_of_timesteps": 2242229, "per_episode_reward": -77.15, "episode_reward_trend_value": 0.006761810249913304, "biggest_recent_change": 0.1427231877672881},
{"total_number_of_episodes": 11828, "number_of_timesteps": 2249289, "per_episode_reward": -77.1, "episode_reward_trend_value": 0.006820055076310894, "biggest_recent_change": 0.1427231877672881},
{"total_number_of_episodes": 11838, "number_of_timesteps": 2254776, "per_episode_reward": -77.05, "episode_reward_trend_value": 0.006744963082299193, "biggest_recent_change": 0.1427231877672881},
{"total_number_of_episodes": 11848, "number_of_timesteps": 2257849, "per_episode_reward": -77.01, "episode_reward_trend_value": 0.006727685372258445, "biggest_recent_change": 0.1427231877672881},
{"total_number_of_episodes": 11859, "number_of_timesteps": 2261710, "per_episode_reward": -76.9, "episode_reward_trend_value": 0.007605057425651927, "biggest_recent_change": 0.1427231877672881},
{"total_number_of_episodes": 11869, "number_of_timesteps": 2266644, "per_episode_reward": -76.84, "episode_reward_trend_value": 0.007679633631994737, "biggest_recent_change": 0.1427231877672881},
{"total_number_of_episodes": 11879, "number_of_timesteps": 2275111, "per_episode_reward": -76.83, "episode_reward_trend_value": 0.006493674996834248, "biggest_recent_change": 0.1427231877672881},
{"total_number_of_episodes": 11889, "number_of_timesteps": 2282080, "per_episode_reward": -76.7, "episode_reward_trend_value": 0.006318727861782098, "biggest_recent_change": 0.12697794561259457},
{"total_number_of_episodes": 11899, "number_of_timesteps": 2286665, "per_episode_reward": -76.64, "episode_reward_trend_value": 0.006524090783071301, "biggest_recent_change": 0.12697794561259457},
{"total_number_of_episodes": 11909, "number_of_timesteps": 2291806, "per_episode_reward": -76.58, "episode_reward_trend_value": 0.0063403268971226915, "biggest_recent_change": 0.12697794561259457},
{"total_number_of_episodes": 11919, "number_of_timesteps": 2297482, "per_episode_reward": -76.48, "episode_reward_trend_value": 0.006934411693582535, "biggest_recent_change": 0.12697794561259457},
{"total_number_of_episodes": 11929, "number_of_timesteps": 2303535, "per_episode_reward": -76.44, "episode_reward_trend_value": 0.00686806528078784, "biggest_recent_change": 0.12697794561259457},
{"total_number_of_episodes": 11939, "number_of_timesteps": 2310418, "per_episode_reward": -76.36, "episode_reward_trend_value": 0.007149283764740883, "biggest_recent_change": 0.12697794561259457},
{"total_number_of_episodes": 11949, "number_of_timesteps": 2317457, "per_episode_reward": -76.33, "episode_reward_trend_value": 0.006376996773868547, "biggest_recent_change": 0.12697794561259457},
{"total_number_of_episodes": 11959, "number_of_timesteps": 2323880, "per_episode_reward": -76.29, "episode_reward_trend_value": 0.006078160736040653, "biggest_recent_change": 0.12697794561259457},
{"total_number_of_episodes": 11969, "number_of_timesteps": 2330800, "per_episode_reward": -76.28, "episode_reward_trend_value": 0.006088095135984241, "biggest_recent_change": 0.12697794561259457},
{"total_number_of_episodes": 11979, "number_of_timesteps": 2340013, "per_episode_reward": -76.2, "episode_reward_trend_value": 0.005554618868703345, "biggest_recent_change": 0.10551487053095343},
{"total_number_of_episodes": 11989, "number_of_timesteps": 2345623, "per_episode_reward": -76.13, "episode_reward_trend_value": 0.005637309177055114, "biggest_recent_change": 0.10551487053095343},
{"total_number_of_episodes": 11999, "number_of_timesteps": 2349741, "per_episode_reward": -76.08, "episode_reward_trend_value": 0.0055288575565691014, "biggest_recent_change": 0.10551487053095343},
{"total_number_of_episodes": 12009, "number_of_timesteps": 2355168, "per_episode_reward": -76.06, "episode_reward_trend_value": 0.004667077414911584, "biggest_recent_change": 0.07896508155731397},
{"total_number_of_episodes": 12020, "number_of_timesteps": 2358894, "per_episode_reward": -75.99, "episode_reward_trend_value": 0.004944946599803915, "biggest_recent_change": 0.07896508155731397},
{"total_number_of_episodes": 12030, "number_of_timesteps": 2361572, "per_episode_reward": -75.94, "episode_reward_trend_value": 0.004703116499768909, "biggest_recent_change": 0.07896508155731397},
{"total_number_of_episodes": 12041, "number_of_timesteps": 2364232, "per_episode_reward": -75.8, "episode_reward_trend_value": 0.00582863282427771, "biggest_recent_change": 0.1344710425104978},
{"total_number_of_episodes": 12051, "number_of_timesteps": 2366799, "per_episode_reward": -75.71, "episode_reward_trend_value": 0.006442454342920535, "biggest_recent_change": 0.1344710425104978},
{"total_number_of_episodes": 12061, "number_of_timesteps": 2370164, "per_episode_reward": -75.61, "episode_reward_trend_value": 0.007443544473311666, "biggest_recent_change": 0.1344710425104978},
{"total_number_of_episodes": 12071, "number_of_timesteps": 2373047, "per_episode_reward": -75.56, "episode_reward_trend_value": 0.007137897033072863, "biggest_recent_change": 0.1344710425104978},
{"total_number_of_episodes": 12081, "number_of_timesteps": 2375700, "per_episode_reward": -75.49, "episode_reward_trend_value": 0.007149841387728707, "biggest_recent_change": 0.1344710425104978},
{"total_number_of_episodes": 12092, "number_of_timesteps": 2378417, "per_episode_reward": -75.42, "episode_reward_trend_value": 0.007360189952038196, "biggest_recent_change": 0.1344710425104978},
{"total_number_of_episodes": 12102, "number_of_timesteps": 2381125, "per_episode_reward": -75.37, "episode_reward_trend_value": 0.007593381058408492, "biggest_recent_change": 0.1344710425104978},
{"total_number_of_episodes": 12112, "number_of_timesteps": 2384078, "per_episode_reward": -75.34, "episode_reward_trend_value": 0.007271764621951604, "biggest_recent_change": 0.1344710425104978},
{"total_number_of_episodes": 12122, "number_of_timesteps": 2386991, "per_episode_reward": -75.25, "episode_reward_trend_value": 0.007609098472757599, "biggest_recent_change": 0.1344710425104978},
{"total_number_of_episodes": 12132, "number_of_timesteps": 2389501, "per_episode_reward": -75.16, "episode_reward_trend_value": 0.0071222958022933835, "biggest_recent_change": 0.10743571428098164},
{"total_number_of_episodes": 12142, "number_of_timesteps": 2392046, "per_episode_reward": -75.12, "episode_reward_trend_value": 0.006580263988141629, "biggest_recent_change": 0.10743571428098164},
{"total_number_of_episodes": 12152, "number_of_timesteps": 2394795, "per_episode_reward": -75.08, "episode_reward_trend_value": 0.005834925759971554, "biggest_recent_change": 0.09065880216871847},
{"total_number_of_episodes": 12162, "number_of_timesteps": 2397174, "per_episode_reward": -75.05, "episode_reward_trend_value": 0.005635907623866229, "biggest_recent_change": 0.09065880216871847},
{"total_number_of_episodes": 12172, "number_of_timesteps": 2401029, "per_episode_reward": -74.99, "episode_reward_trend_value": 0.005562287006616708, "biggest_recent_change": 0.09065880216871847},
{"total_number_of_episodes": 12182, "number_of_timesteps": 2404131, "per_episode_reward": -74.95, "episode_reward_trend_value": 0.005253097594744974, "biggest_recent_change": 0.09065880216871847},
{"total_number_of_episodes": 12192, "number_of_timesteps": 2407814, "per_episode_reward": -74.89, "episode_reward_trend_value": 0.0053559799132247895, "biggest_recent_change": 0.09065880216871847},
{"total_number_of_episodes": 12202, "number_of_timesteps": 2411279, "per_episode_reward": -74.87, "episode_reward_trend_value": 0.005233347993710424, "biggest_recent_change": 0.09065880216871847},
{"total_number_of_episodes": 12212, "number_of_timesteps": 2414744, "per_episode_reward": -74.84, "episode_reward_trend_value": 0.004615979460312442, "biggest_recent_change": 0.09065880216871847},
{"total_number_of_episodes": 12222, "number_of_timesteps": 2418367, "per_episode_reward": -74.79, "episode_reward_trend_value": 0.004148257557259979, "biggest_recent_change": 0.05830462460535557},
{"total_number_of_episodes": 12232, "number_of_timesteps": 2420963, "per_episode_reward": -74.66, "episode_reward_trend_value": 0.005113533607911967, "biggest_recent_change": 0.12784874891106313},
{"total_number_of_episodes": 12242, "number_of_timesteps": 2424401, "per_episode_reward": -74.62, "episode_reward_trend_value": 0.005143323154544058, "biggest_recent_change": 0.12784874891106313},
{"total_number_of_episodes": 12252, "number_of_timesteps": 2428720, "per_episode_reward": -74.59, "episode_reward_trend_value": 0.005118021782859709, "biggest_recent_change": 0.12784874891106313},
{"total_number_of_episodes": 12262, "number_of_timesteps": 2432215, "per_episode_reward": -74.57, "episode_reward_trend_value": 0.004629359778955214, "biggest_recent_change": 0.12784874891106313},
{"total_number_of_episodes": 12272, "number_of_timesteps": 2436671, "per_episode_reward": -74.57, "episode_reward_trend_value": 0.004174049454341381, "biggest_recent_change": 0.12784874891106313},
{"total_number_of_episodes": 12282, "number_of_timesteps": 2439525, "per_episode_reward": -74.52, "episode_reward_trend_value": 0.004080951005094214, "biggest_recent_change": 0.12784874891106313},
{"total_number_of_episodes": 12292, "number_of_timesteps": 2441491, "per_episode_reward": -74.44, "episode_reward_trend_value": 0.004746262072584449, "biggest_recent_change": 0.12784874891106313},
{"total_number_of_episodes": 12302, "number_of_timesteps": 2444033, "per_episode_reward": -74.37, "episode_reward_trend_value": 0.0051602175514947, "biggest_recent_change": 0.12784874891106313},
{"total_number_of_episodes": 12312, "number_of_timesteps": 2446104, "per_episode_reward": -74.3, "episode_reward_trend_value": 0.005497337852270334, "biggest_recent_change": 0.12784874891106313},
{"total_number_of_episodes": 12322, "number_of_timesteps": 2448298, "per_episode_reward": -74.24, "episode_reward_trend_value": 0.004642390618935602, "biggest_recent_change": 0.08452443816848643},
{"total_number_of_episodes": 12333, "number_of_timesteps": 2450948, "per_episode_reward": -74.21, "episode_reward_trend_value": 0.004498240074747963, "biggest_recent_change": 0.08452443816848643},
{"total_number_of_episodes": 12343, "number_of_timesteps": 2452975, "per_episode_reward": -74.17, "episode_reward_trend_value": 0.0046026201032576515, "biggest_recent_change": 0.08452443816848643},
{"total_number_of_episodes": 12353, "number_of_timesteps": 2454903, "per_episode_reward": -74.15, "episode_reward_trend_value": 0.004714857754023664, "biggest_recent_change": 0.08452443816848643},
{"total_number_of_episodes": 12363, "number_of_timesteps": 2457195, "per_episode_reward": -74.11, "episode_reward_trend_value": 0.00516687754706453, "biggest_recent_change": 0.08452443816848643},
{"total_number_of_episodes": 12373, "number_of_timesteps": 2459781, "per_episode_reward": -74.04, "episode_reward_trend_value": 0.00540215561975275, "biggest_recent_change": 0.08452443816848643},
{"total_number_of_episodes": 12383, "number_of_timesteps": 2462040, "per_episode_reward": -73.95, "episode_reward_trend_value": 0.005386225172923452, "biggest_recent_change": 0.08309069795384971},
{"total_number_of_episodes": 12393, "number_of_timesteps": 2464344, "per_episode_reward": -73.9, "episode_reward_trend_value": 0.005305328357534242, "biggest_recent_change": 0.08309069795384971},
{"total_number_of_episodes": 12403, "number_of_timesteps": 2466849, "per_episode_reward": -73.83, "episode_reward_trend_value": 0.005120862417259926, "biggest_recent_change": 0.08309069795384971},
{"total_number_of_episodes": 12413, "number_of_timesteps": 2469689, "per_episode_reward": -73.8, "episode_reward_trend_value": 0.004907082790721518, "biggest_recent_change": 0.08309069795384971},
{"total_number_of_episodes": 12423, "number_of_timesteps": 2472917, "per_episode_reward": -73.78, "episode_reward_trend_value": 0.004837609350122799, "biggest_recent_change": 0.08309069795384971},
{"total_number_of_episodes": 12433, "number_of_timesteps": 2477010, "per_episode_reward": -73.72, "episode_reward_trend_value": 0.005072000729275791, "biggest_recent_change": 0.08309069795384971},
{"total_number_of_episodes": 12443, "number_of_timesteps": 2482129, "per_episode_reward": -73.63, "episode_reward_trend_value": 0.005804062857717124, "biggest_recent_change": 0.09031202438261232},
{"total_number_of_episodes": 12453, "number_of_timesteps": 2488731, "per_episode_reward": -73.55, "episode_reward_trend_value": 0.00617437613606771, "biggest_recent_change": 0.09031202438261232},
{"total_number_of_episodes": 12463, "number_of_timesteps": 2496245, "per_episode_reward": -73.49, "episode_reward_trend_value": 0.0060897207274415955, "biggest_recent_change": 0.09031202438261232},
{"total_number_of_episodes": 12473, "number_of_timesteps": 2502661, "per_episode_reward": -73.38, "episode_reward_trend_value": 0.006391164588298181, "biggest_recent_change": 0.11022064543094245},
{"total_number_of_episodes": 12483, "number_of_timesteps": 2505876, "per_episode_reward": -73.32, "episode_reward_trend_value": 0.0064417346966193475, "biggest_recent_change": 0.11022064543094245},
{"total_number_of_episodes": 12493, "number_of_timesteps": 2508837, "per_episode_reward": -73.19, "episode_reward_trend_value": 0.00720406456087722, "biggest_recent_change": 0.1309124111223241},
{"total_number_of_episodes": 12503, "number_of_timesteps": 2512360, "per_episode_reward": -73.17, "episode_reward_trend_value": 0.007064305091540114, "biggest_recent_change": 0.1309124111223241},
{"total_number_of_episodes": 12513, "number_of_timesteps": 2516367, "per_episode_reward": -73.1, "episode_reward_trend_value": 0.007534830659038663, "biggest_recent_change": 0.1309124111223241},
{"total_number_of_episodes": 12523, "number_of_timesteps": 2521624, "per_episode_reward": -73.07, "episode_reward_trend_value": 0.007165320904449225, "biggest_recent_change": 0.1309124111223241},
{"total_number_of_episodes": 12533, "number_of_timesteps": 2526394, "per_episode_reward": -72.98, "episode_reward_trend_value": 0.007222669798109552, "biggest_recent_change": 0.1309124111223241},
{"total_number_of_episodes": 12543, "number_of_timesteps": 2528687, "per_episode_reward": -72.91, "episode_reward_trend_value": 0.0071846720016089365, "biggest_recent_change": 0.1309124111223241},
{"total_number_of_episodes": 12553, "number_of_timesteps": 2531064, "per_episode_reward": -72.88, "episode_reward_trend_value": 0.006780169858129644, "biggest_recent_change": 0.1309124111223241},
{"total_number_of_episodes": 12563, "number_of_timesteps": 2533326, "per_episode_reward": -72.86, "episode_reward_trend_value": 0.0057451799004458815, "biggest_recent_change": 0.1309124111223241},
{"total_number_of_episodes": 12573, "number_of_timesteps": 2536389, "per_episode_reward": -72.82, "episode_reward_trend_value": 0.005511515672063657, "biggest_recent_change": 0.1309124111223241},
{"total_number_of_episodes": 12584, "number_of_timesteps": 2539190, "per_episode_reward": -72.79, "episode_reward_trend_value": 0.0043892705833176, "biggest_recent_change": 0.09547342481204169},
{"total_number_of_episodes": 12594, "number_of_timesteps": 2541310, "per_episode_reward": -72.72, "episode_reward_trend_value": 0.004951283407371913, "biggest_recent_change": 0.09547342481204169},
{"total_number_of_episodes": 12604, "number_of_timesteps": 2543087, "per_episode_reward": -72.64, "episode_reward_trend_value": 0.005084691897873168, "biggest_recent_change": 0.09547342481204169},
{"total_number_of_episodes": 12614, "number_of_timesteps": 2545209, "per_episode_reward": -72.57, "episode_reward_trend_value": 0.005553652604930272, "biggest_recent_change": 0.09547342481204169},
{"total_number_of_episodes": 12624, "number_of_timesteps": 2547934, "per_episode_reward": -72.54, "episode_reward_trend_value": 0.004843383500568008, "biggest_recent_change": 0.0781642395317732},
{"total_number_of_episodes": 12634, "number_of_timesteps": 2549605, "per_episode_reward": -72.42, "episode_reward_trend_value": 0.00538769716956706, "biggest_recent_change": 0.12008336903060979},
{"total_number_of_episodes": 12645, "number_of_timesteps": 2551692, "per_episode_reward": -72.38, "episode_reward_trend_value": 0.005593389709040114, "biggest_recent_change": 0.12008336903060979},
{"total_number_of_episodes": 12655, "number_of_timesteps": 2553983, "per_episode_reward": -72.33, "episode_reward_trend_value": 0.005899700869125487, "biggest_recent_change": 0.12008336903060979},
{"total_number_of_episodes": 12665, "number_of_timesteps": 2555841, "per_episode_reward": -72.27, "episode_reward_trend_value": 0.006176211717122094, "biggest_recent_change": 0.12008336903060979},
{"total_number_of_episodes": 12676, "number_of_timesteps": 2558255, "per_episode_reward": -72.19, "episode_reward_trend_value": 0.006679889458435657, "biggest_recent_change": 0.12008336903060979},
{"total_number_of_episodes": 12686, "number_of_timesteps": 2560976, "per_episode_reward": -72.11, "episode_reward_trend_value": 0.006810692671716051, "biggest_recent_change": 0.12008336903060979},
{"total_number_of_episodes": 12696, "number_of_timesteps": 2563716, "per_episode_reward": -72.08, "episode_reward_trend_value": 0.006300783371721902, "biggest_recent_change": 0.12008336903060979},
{"total_number_of_episodes": 12706, "number_of_timesteps": 2566618, "per_episode_reward": -72.05, "episode_reward_trend_value": 0.0058368535290292635, "biggest_recent_change": 0.12008336903060979},
{"total_number_of_episodes": 12716, "number_of_timesteps": 2569815, "per_episode_reward": -71.99, "episode_reward_trend_value": 0.006159230211947096, "biggest_recent_change": 0.12008336903060979},
{"total_number_of_episodes": 12726, "number_of_timesteps": 2574165, "per_episode_reward": -71.93, "episode_reward_trend_value": 0.005477890004190379, "biggest_recent_change": 0.08143842264226464},
{"total_number_of_episodes": 12736, "number_of_timesteps": 2577972, "per_episode_reward": -71.88, "episode_reward_trend_value": 0.0054765631896619505, "biggest_recent_change": 0.08143842264226464},
{"total_number_of_episodes": 12746, "number_of_timesteps": 2581260, "per_episode_reward": -71.82, "episode_reward_trend_value": 0.005648005984087471, "biggest_recent_change": 0.08143842264226464},
{"total_number_of_episodes": 12756, "number_of_timesteps": 2585416, "per_episode_reward": -71.69, "episode_reward_trend_value": 0.006416361718306657, "biggest_recent_change": 0.134804566772047},
{"total_number_of_episodes": 12766, "number_of_timesteps": 2589274, "per_episode_reward": -71.6, "episode_reward_trend_value": 0.0066014043977295, "biggest_recent_change": 0.134804566772047},
{"total_number_of_episodes": 12776, "number_of_timesteps": 2593348, "per_episode_reward": -71.58, "episode_reward_trend_value": 0.00592483848659779, "biggest_recent_change": 0.134804566772047},
{"total_number_of_episodes": 12786, "number_of_timesteps": 2596036, "per_episode_reward": -71.49, "episode_reward_trend_value": 0.00648269177859125, "biggest_recent_change": 0.134804566772047},
{"total_number_of_episodes": 12796, "number_of_timesteps": 2600284, "per_episode_reward": -71.47, "episode_reward_trend_value": 0.006384370786539743, "biggest_recent_change": 0.134804566772047},
{"total_number_of_episodes": 12806, "number_of_timesteps": 2604426, "per_episode_reward": -71.41, "episode_reward_trend_value": 0.006412588332604071, "biggest_recent_change": 0.134804566772047},
{"total_number_of_episodes": 12816, "number_of_timesteps": 2609914, "per_episode_reward": -71.38, "episode_reward_trend_value": 0.006105098463775013, "biggest_recent_change": 0.134804566772047},
{"total_number_of_episodes": 12826, "number_of_timesteps": 2614093, "per_episode_reward": -71.36, "episode_reward_trend_value": 0.005837500809527461, "biggest_recent_change": 0.134804566772047},
{"total_number_of_episodes": 12836, "number_of_timesteps": 2616898, "per_episode_reward": -71.28, "episode_reward_trend_value": 0.006059997298256943, "biggest_recent_change": 0.134804566772047},
{"total_number_of_episodes": 12846, "number_of_timesteps": 2619130, "per_episode_reward": -71.26, "episode_reward_trend_value": 0.004752876727735453, "biggest_recent_change": 0.0918951910014556},
{"total_number_of_episodes": 12856, "number_of_timesteps": 2622211, "per_episode_reward": -71.24, "episode_reward_trend_value": 0.0039784456642331005, "biggest_recent_change": 0.08247919881171129},
{"total_number_of_episodes": 12866, "number_of_timesteps": 2626567, "per_episode_reward": -71.23, "episode_reward_trend_value": 0.0038820843298831655, "biggest_recent_change": 0.08247919881171129},
{"total_number_of_episodes": 12876, "number_of_timesteps": 2630273, "per_episode_reward": -71.02, "episode_reward_trend_value": 0.005306725821256306, "biggest_recent_change": 0.2106969330352939},
{"total_number_of_episodes": 12886, "number_of_timesteps": 2634086, "per_episode_reward": -70.97, "episode_reward_trend_value": 0.005609629317100939, "biggest_recent_change": 0.2106969330352939},
{"total_number_of_episodes": 12896, "number_of_timesteps": 2639280, "per_episode_reward": -70.85, "episode_reward_trend_value": 0.0062709624838848625, "biggest_recent_change": 0.2106969330352939},
{"total_number_of_episodes": 12906, "number_of_timesteps": 2641670, "per_episode_reward": -70.8, "episode_reward_trend_value": 0.0064544438062842215, "biggest_recent_change": 0.2106969330352939},
{"total_number_of_episodes": 12916, "number_of_timesteps": 2644000, "per_episode_reward": -70.76, "episode_reward_trend_value": 0.0066394312337922975, "biggest_recent_change": 0.2106969330352939},
{"total_number_of_episodes": 12926, "number_of_timesteps": 2646430, "per_episode_reward": -70.7, "episode_reward_trend_value": 0.006370104771615735, "biggest_recent_change": 0.2106969330352939},
{"total_number_of_episodes": 12936, "number_of_timesteps": 2649077, "per_episode_reward": -70.66, "episode_reward_trend_value": 0.006615379547016352, "biggest_recent_change": 0.2106969330352939},
{"total_number_of_episodes": 12946, "number_of_timesteps": 2652368, "per_episode_reward": -70.59, "episode_reward_trend_value": 0.007169677686212595, "biggest_recent_change": 0.2106969330352939},
{"total_number_of_episodes": 12956, "number_of_timesteps": 2655385, "per_episode_reward": -70.48, "episode_reward_trend_value": 0.008257287966538879, "biggest_recent_change": 0.2106969330352939},
{"total_number_of_episodes": 12966, "number_of_timesteps": 2658951, "per_episode_reward": -70.46, "episode_reward_trend_value": 0.006168210225494559, "biggest_recent_change": 0.12262267103838553},
{"total_number_of_episodes": 12976, "number_of_timesteps": 2663861, "per_episode_reward": -70.39, "episode_reward_trend_value": 0.006433736554901909, "biggest_recent_change": 0.12262267103838553},
{"total_number_of_episodes": 12986, "number_of_timesteps": 2668722, "per_episode_reward": -70.33, "episode_reward_trend_value": 0.005763842201760225, "biggest_recent_change": 0.10975989577828216},
{"total_number_of_episodes": 12997, "number_of_timesteps": 2673466, "per_episode_reward": -70.27, "episode_reward_trend_value": 0.005862819057671547, "biggest_recent_change": 0.10975989577828216},
{"total_number_of_episodes": 13007, "number_of_timesteps": 2676871, "per_episode_reward": -70.24, "episode_reward_trend_value": 0.005815058999382453, "biggest_recent_change": 0.10975989577828216},
{"total_number_of_episodes": 13017, "number_of_timesteps": 2681327, "per_episode_reward": -70.14, "episode_reward_trend_value": 0.0062547576489511885, "biggest_recent_change": 0.10975989577828216},
{"total_number_of_episodes": 13027, "number_of_timesteps": 2685096, "per_episode_reward": -70.08, "episode_reward_trend_value": 0.0064813447208412825, "biggest_recent_change": 0.10975989577828216},
{"total_number_of_episodes": 13038, "number_of_timesteps": 2688662, "per_episode_reward": -70.0, "episode_reward_trend_value": 0.00662171007847942, "biggest_recent_change": 0.10975989577828216},
{"total_number_of_episodes": 13048, "number_of_timesteps": 2691525, "per_episode_reward": -69.9, "episode_reward_trend_value": 0.006444895146053714, "biggest_recent_change": 0.09542758599633316},
{"total_number_of_episodes": 13058, "number_of_timesteps": 2694291, "per_episode_reward": -69.89, "episode_reward_trend_value": 0.006365456176519046, "biggest_recent_change": 0.09542758599633316},
{"total_number_of_episodes": 13068, "number_of_timesteps": 2697066, "per_episode_reward": -69.85, "episode_reward_trend_value": 0.006034181692193228, "biggest_recent_change": 0.09542758599633316},
{"total_number_of_episodes": 13078, "number_of_timesteps": 2700452, "per_episode_reward": -69.8, "episode_reward_trend_value": 0.0058613605119418825, "biggest_recent_change": 0.09542758599633316},
{"total_number_of_episodes": 13088, "number_of_timesteps": 2703646, "per_episode_reward": -69.78, "episode_reward_trend_value": 0.005449568417069549, "biggest_recent_change": 0.09542758599633316},
{"total_number_of_episodes": 13098, "number_of_timesteps": 2709787, "per_episode_reward": -69.76, "episode_reward_trend_value": 0.005316588946894759, "biggest_recent_change": 0.09542758599633316},
{"total_number_of_episodes": 13108, "number_of_timesteps": 2715852, "per_episode_reward": -69.72, "episode_reward_trend_value": 0.004686161504915591, "biggest_recent_change": 0.09384655185996849},
{"total_number_of_episodes": 13118, "number_of_timesteps": 2721754, "per_episode_reward": -69.69, "episode_reward_trend_value": 0.004302604367280575, "biggest_recent_change": 0.09384655185996849},
{"total_number_of_episodes": 13128, "number_of_timesteps": 2726207, "per_episode_reward": -69.64, "episode_reward_trend_value": 0.003974550653219921, "biggest_recent_change": 0.09384655185996849},
{"total_number_of_episodes": 13138, "number_of_timesteps": 2730551, "per_episode_reward": -69.58, "episode_reward_trend_value": 0.003622448786373411, "biggest_recent_change": 0.062157383843782554},
{"total_number_of_episodes": 13148, "number_of_timesteps": 2735526, "per_episode_reward": -69.43, "episode_reward_trend_value": 0.005045416823954143, "biggest_recent_change": 0.14359755246545092},
{"total_number_of_episodes": 13158, "number_of_timesteps": 2739658, "per_episode_reward": -69.35, "episode_reward_trend_value": 0.005546814740071366, "biggest_recent_change": 0.14359755246545092},
{"total_number_of_episodes": 13168, "number_of_timesteps": 2745420, "per_episode_reward": -69.29, "episode_reward_trend_value": 0.005654553850492524, "biggest_recent_change": 0.14359755246545092},
{"total_number_of_episodes": 13178, "number_of_timesteps": 2749125, "per_episode_reward": -69.23, "episode_reward_trend_value": 0.006103087442722534, "biggest_recent_change": 0.14359755246545092},
{"total_number_of_episodes": 13188, "number_of_timesteps": 2752791, "per_episode_reward": -69.18, "episode_reward_trend_value": 0.00644542722867843, "biggest_recent_change": 0.14359755246545092},
{"total_number_of_episodes": 13198, "number_of_timesteps": 2756090, "per_episode_reward": -69.1, "episode_reward_trend_value": 0.006931838692839499, "biggest_recent_change": 0.14359755246545092},
{"total_number_of_episodes": 13208, "number_of_timesteps": 2758782, "per_episode_reward": -69.05, "episode_reward_trend_value": 0.0072012363764865014, "biggest_recent_change": 0.14359755246545092},
{"total_number_of_episodes": 13218, "number_of_timesteps": 2761463, "per_episode_reward": -69.0, "episode_reward_trend_value": 0.007151213917751103, "biggest_recent_change": 0.14359755246545092},
{"total_number_of_episodes": 13228, "number_of_timesteps": 2764147, "per_episode_reward": -68.9, "episode_reward_trend_value": 0.007554083860160826, "biggest_recent_change": 0.14359755246545092},
{"total_number_of_episodes": 13239, "number_of_timesteps": 2768005, "per_episode_reward": -68.78, "episode_reward_trend_value": 0.007256365743688302, "biggest_recent_change": 0.11680292198292364},
{"total_number_of_episodes": 13249, "number_of_timesteps": 2771793, "per_episode_reward": -68.7, "episode_reward_trend_value": 0.007139950982461901, "biggest_recent_change": 0.11680292198292364},
{"total_number_of_episodes": 13259, "number_of_timesteps": 2776589, "per_episode_reward": -68.6, "episode_reward_trend_value": 0.007691364641248949, "biggest_recent_change": 0.11680292198292364},
{"total_number_of_episodes": 13269, "number_of_timesteps": 2780105, "per_episode_reward": -68.48, "episode_reward_trend_value": 0.008327361711612014, "biggest_recent_change": 0.11705636928071783},
{"total_number_of_episodes": 13279, "number_of_timesteps": 2784529, "per_episode_reward": -68.47, "episode_reward_trend_value": 0.007815330129882784, "biggest_recent_change": 0.11705636928071783},
{"total_number_of_episodes": 13289, "number_of_timesteps": 2787479, "per_episode_reward": -68.42, "episode_reward_trend_value": 0.007514097404042433, "biggest_recent_change": 0.11705636928071783},
{"total_number_of_episodes": 13299, "number_of_timesteps": 2790243, "per_episode_reward": -68.38, "episode_reward_trend_value": 0.0074047952109629655, "biggest_recent_change": 0.11705636928071783},
{"total_number_of_episodes": 13309, "number_of_timesteps": 2793138, "per_episode_reward": -68.32, "episode_reward_trend_value": 0.007535451523190772, "biggest_recent_change": 0.11705636928071783},
{"total_number_of_episodes": 13319, "number_of_timesteps": 2795729, "per_episode_reward": -68.26, "episode_reward_trend_value": 0.007020065784998211, "biggest_recent_change": 0.11705636928071783},
{"total_number_of_episodes": 13329, "number_of_timesteps": 2798726, "per_episode_reward": -68.23, "episode_reward_trend_value": 0.006124734694425626, "biggest_recent_change": 0.11705636928071783},
{"total_number_of_episodes": 13340, "number_of_timesteps": 2802581, "per_episode_reward": -68.19, "episode_reward_trend_value": 0.005658185271405279, "biggest_recent_change": 0.11705636928071783},
{"total_number_of_episodes": 13351, "number_of_timesteps": 2807566, "per_episode_reward": -68.16, "episode_reward_trend_value": 0.004835596074998073, "biggest_recent_change": 0.11705636928071783},
{"total_number_of_episodes": 13361, "number_of_timesteps": 2810969, "per_episode_reward": -68.09, "episode_reward_trend_value": 0.004331936712814707, "biggest_recent_change": 0.07172702668421493},
{"total_number_of_episodes": 13371, "number_of_timesteps": 2815808, "per_episode_reward": -68.06, "episode_reward_trend_value": 0.004606559422724229, "biggest_recent_change": 0.07172702668421493},
{"total_number_of_episodes": 13381, "number_of_timesteps": 2820886, "per_episode_reward": -68.03, "episode_reward_trend_value": 0.004330057889177081, "biggest_recent_change": 0.07172702668421493},
{"total_number_of_episodes": 13391, "number_of_timesteps": 2826319, "per_episode_reward": -67.92, "episode_reward_trend_value": 0.005050326941610371, "biggest_recent_change": 0.10434394816419967},
{"total_number_of_episodes": 13401, "number_of_timesteps": 2830497, "per_episode_reward": -67.77, "episode_reward_trend_value": 0.006101609777186607, "biggest_recent_change": 0.15706377775205738},
{"total_number_of_episodes": 13411, "number_of_timesteps": 2835978, "per_episode_reward": -67.71, "episode_reward_trend_value": 0.006206556318268023, "biggest_recent_change": 0.15706377775205738},
{"total_number_of_episodes": 13421, "number_of_timesteps": 2843119, "per_episode_reward": -67.66, "episode_reward_trend_value": 0.006352034100844467, "biggest_recent_change": 0.15706377775205738},
{"total_number_of_episodes": 13431, "number_of_timesteps": 2848293, "per_episode_reward": -67.63, "episode_reward_trend_value": 0.006318264141496696, "biggest_recent_change": 0.15706377775205738},
{"total_number_of_episodes": 13441, "number_of_timesteps": 2853979, "per_episode_reward": -67.6, "episode_reward_trend_value": 0.006198232021110231, "biggest_recent_change": 0.15706377775205738},
{"total_number_of_episodes": 13451, "number_of_timesteps": 2858897, "per_episode_reward": -67.59, "episode_reward_trend_value": 0.0055377257744604926, "biggest_recent_change": 0.15706377775205738},
{"total_number_of_episodes": 13461, "number_of_timesteps": 2862631, "per_episode_reward": -67.54, "episode_reward_trend_value": 0.00579867048976597, "biggest_recent_change": 0.15706377775205738},
{"total_number_of_episodes": 13471, "number_of_timesteps": 2869167, "per_episode_reward": -67.45, "episode_reward_trend_value": 0.006441562416346851, "biggest_recent_change": 0.15706377775205738},
{"total_number_of_episodes": 13481, "number_of_timesteps": 2873656, "per_episode_reward": -67.37, "episode_reward_trend_value": 0.006146500057852696, "biggest_recent_change": 0.15706377775205738},
{"total_number_of_episodes": 13491, "number_of_timesteps": 2878225, "per_episode_reward": -67.34, "episode_reward_trend_value": 0.004757086240311202, "biggest_recent_change": 0.08833033804010881},
{"total_number_of_episodes": 13502, "number_of_timesteps": 2886814, "per_episode_reward": -67.29, "episode_reward_trend_value": 0.0046256152854855116, "biggest_recent_change": 0.08833033804010881},
{"total_number_of_episodes": 13512, "number_of_timesteps": 2893579, "per_episode_reward": -67.27, "episode_reward_trend_value": 0.00431874067839999, "biggest_recent_change": 0.08833033804010881},
{"total_number_of_episodes": 13522, "number_of_timesteps": 2899881, "per_episode_reward": -67.2, "episode_reward_trend_value": 0.004780774553528192, "biggest_recent_change": 0.08833033804010881},
{"total_number_of_episodes": 13532, "number_of_timesteps": 2907695, "per_episode_reward": -67.2, "episode_reward_trend_value": 0.004528734767062935, "biggest_recent_change": 0.08833033804010881},
{"total_number_of_episodes": 13542, "number_of_timesteps": 2914553, "per_episode_reward": -67.13, "episode_reward_trend_value": 0.005112252437246904, "biggest_recent_change": 0.08833033804010881},
{"total_number_of_episodes": 13552, "number_of_timesteps": 2921216, "per_episode_reward": -66.95, "episode_reward_trend_value": 0.006475447414382056, "biggest_recent_change": 0.17728104430712222},
{"total_number_of_episodes": 13562, "number_of_timesteps": 2927796, "per_episode_reward": -66.88, "episode_reward_trend_value": 0.006327713080614058, "biggest_recent_change": 0.17728104430712222},
{"total_number_of_episodes": 13572, "number_of_timesteps": 2931757, "per_episode_reward": -66.85, "episode_reward_trend_value": 0.005762198605543429, "biggest_recent_change": 0.17728104430712222},
{"total_number_of_episodes": 13582, "number_of_timesteps": 2938251, "per_episode_reward": -66.81, "episode_reward_trend_value": 0.005865115647461829, "biggest_recent_change": 0.17728104430712222},
{"total_number_of_episodes": 13592, "number_of_timesteps": 2943175, "per_episode_reward": -66.73, "episode_reward_trend_value": 0.0062626247034393775, "biggest_recent_change": 0.17728104430712222},
{"total_number_of_episodes": 13602, "number_of_timesteps": 2949929, "per_episode_reward": -66.67, "episode_reward_trend_value": 0.006648683141648506, "biggest_recent_change": 0.17728104430712222},
{"total_number_of_episodes": 13612, "number_of_timesteps": 2954280, "per_episode_reward": -66.63, "episode_reward_trend_value": 0.006314056721687361, "biggest_recent_change": 0.17728104430712222},
{"total_number_of_episodes": 13622, "number_of_timesteps": 2958235, "per_episode_reward": -66.57, "episode_reward_trend_value": 0.006983619700591406, "biggest_recent_change": 0.17728104430712222},
{"total_number_of_episodes": 13632, "number_of_timesteps": 2962519, "per_episode_reward": -66.52, "episode_reward_trend_value": 0.0067969955054457565, "biggest_recent_change": 0.17728104430712222},
{"total_number_of_episodes": 13642, "number_of_timesteps": 2967667, "per_episode_reward": -66.45, "episode_reward_trend_value": 0.005587153468438702, "biggest_recent_change": 0.08541958002432182},
{"total_number_of_episodes": 13652, "number_of_timesteps": 2971255, "per_episode_reward": -66.41, "episode_reward_trend_value": 0.005166597797329567, "biggest_recent_change": 0.08541958002432182},
{"total_number_of_episodes": 13662, "number_of_timesteps": 2975265, "per_episode_reward": -66.19, "episode_reward_trend_value": 0.007422180481858555, "biggest_recent_change": 0.2298944747509779},
{"total_number_of_episodes": 13672, "number_of_timesteps": 2980664, "per_episode_reward": -66.08, "episode_reward_trend_value": 0.008100660045992766, "biggest_recent_change": 0.2298944747509779},
{"total_number_of_episodes": 13682, "number_of_timesteps": 2987356, "per_episode_reward": -66.03, "episode_reward_trend_value": 0.007706006508285018, "biggest_recent_change": 0.2298944747509779},
{"total_number_of_episodes": 13692, "number_of_timesteps": 2990420, "per_episode_reward": -66.0, "episode_reward_trend_value": 0.007490577351337259, "biggest_recent_change": 0.2298944747509779},
{"total_number_of_episodes": 13702, "number_of_timesteps": 2995193, "per_episode_reward": -65.9, "episode_reward_trend_value": 0.008105222588687077, "biggest_recent_change": 0.2298944747509779},
{"total_number_of_episodes": 13712, "number_of_timesteps": 2998049, "per_episode_reward": -65.83, "episode_reward_trend_value": 0.008188620920072746, "biggest_recent_change": 0.2298944747509779},
{"total_number_of_episodes": 13722, "number_of_timesteps": 3002045, "per_episode_reward": -65.8, "episode_reward_trend_value": 0.007955243894838936, "biggest_recent_change": 0.2298944747509779},
{"total_number_of_episodes": 13732, "number_of_timesteps": 3007330, "per_episode_reward": -65.73, "episode_reward_trend_value": 0.00807526837048095, "biggest_recent_change": 0.2298944747509779},
{"total_number_of_episodes": 13743, "number_of_timesteps": 3012058, "per_episode_reward": -65.67, "episode_reward_trend_value": 0.008252967837192829, "biggest_recent_change": 0.2298944747509779},
{"total_number_of_episodes": 13753, "number_of_timesteps": 3014195, "per_episode_reward": -65.66, "episode_reward_trend_value": 0.005841325322038434, "biggest_recent_change": 0.10234222871805798},
{"total_number_of_episodes": 13763, "number_of_timesteps": 3019373, "per_episode_reward": -65.65, "episode_reward_trend_value": 0.004800016852749738, "biggest_recent_change": 0.09785395605642577},
{"total_number_of_episodes": 13773, "number_of_timesteps": 3020946, "per_episode_reward": -65.62, "episode_reward_trend_value": 0.0045455067141287175, "biggest_recent_change": 0.09785395605642577},
{"total_number_of_episodes": 13783, "number_of_timesteps": 3024399, "per_episode_reward": -65.62, "episode_reward_trend_value": 0.004188776571863349, "biggest_recent_change": 0.09785395605642577},
{"total_number_of_episodes": 13793, "number_of_timesteps": 3027605, "per_episode_reward": -65.52, "episode_reward_trend_value": 0.0041868275241134885, "biggest_recent_change": 0.09767854175893831},
{"total_number_of_episodes": 13803, "number_of_timesteps": 3029328, "per_episode_reward": -65.5, "episode_reward_trend_value": 0.0037043436102003903, "biggest_recent_change": 0.09767854175893831},
{"total_number_of_episodes": 13813, "number_of_timesteps": 3031598, "per_episode_reward": -65.45, "episode_reward_trend_value": 0.00395039110307604, "biggest_recent_change": 0.09767854175893831},
{"total_number_of_episodes": 13823, "number_of_timesteps": 3035455, "per_episode_reward": -65.37, "episode_reward_trend_value": 0.003921346728711386, "biggest_recent_change": 0.09767854175893831},
{"total_number_of_episodes": 13833, "number_of_timesteps": 3037703, "per_episode_reward": -65.3, "episode_reward_trend_value": 0.004112772319704226, "biggest_recent_change": 0.09767854175893831},
{"total_number_of_episodes": 13843, "number_of_timesteps": 3040353, "per_episode_reward": -65.26, "episode_reward_trend_value": 0.004400287777670542, "biggest_recent_change": 0.09767854175893831},
{"total_number_of_episodes": 13853, "number_of_timesteps": 3044099, "per_episode_reward": -65.26, "episode_reward_trend_value": 0.004382259077271537, "biggest_recent_change": 0.09767854175893831},
{"total_number_of_episodes": 13863, "number_of_timesteps": 3046250, "per_episode_reward": -65.23, "episode_reward_trend_value": 0.004357088724934815, "biggest_recent_change": 0.09767854175893831},
{"total_number_of_episodes": 13873, "number_of_timesteps": 3050223, "per_episode_reward": -65.18, "episode_reward_trend_value": 0.0049166704708031575, "biggest_recent_change": 0.09767854175893831},
{"total_number_of_episodes": 13883, "number_of_timesteps": 3051931, "per_episode_reward": -65.09, "episode_reward_trend_value": 0.004774798068526012, "biggest_recent_change": 0.08491002555399518},
{"total_number_of_episodes": 13893, "number_of_timesteps": 3054073, "per_episode_reward": -64.97, "episode_reward_trend_value": 0.005813066417056865, "biggest_recent_change": 0.11636964001012018},
{"total_number_of_episodes": 13904, "number_of_timesteps": 3058685, "per_episode_reward": -64.9, "episode_reward_trend_value": 0.006105154381634589, "biggest_recent_change": 0.11636964001012018},
{"total_number_of_episodes": 13914, "number_of_timesteps": 3061396, "per_episode_reward": -64.81, "episode_reward_trend_value": 0.006251974228292864, "biggest_recent_change": 0.11636964001012018},
{"total_number_of_episodes": 13924, "number_of_timesteps": 3063126, "per_episode_reward": -64.65, "episode_reward_trend_value": 0.007286878489231678, "biggest_recent_change": 0.16354687627908504},
{"total_number_of_episodes": 13934, "number_of_timesteps": 3065455, "per_episode_reward": -64.6, "episode_reward_trend_value": 0.007373207895725405, "biggest_recent_change": 0.16354687627908504},
{"total_number_of_episodes": 13944, "number_of_timesteps": 3067286, "per_episode_reward": -64.54, "episode_reward_trend_value": 0.007991559447250848, "biggest_recent_change": 0.16354687627908504},
{"total_number_of_episodes": 13954, "number_of_timesteps": 3068798, "per_episode_reward": -64.45, "episode_reward_trend_value": 0.008703948801660349, "biggest_recent_change": 0.16354687627908504},
{"total_number_of_episodes": 13965, "number_of_timesteps": 3070406, "per_episode_reward": -64.4, "episode_reward_trend_value": 0.00864969523044484, "biggest_recent_change": 0.16354687627908504},
{"total_number_of_episodes": 13975, "number_of_timesteps": 3071974, "per_episode_reward": -64.33, "episode_reward_trend_value": 0.008406619115474395, "biggest_recent_change": 0.16354687627908504},
{"total_number_of_episodes": 13985, "number_of_timesteps": 3073437, "per_episode_reward": -64.31, "episode_reward_trend_value": 0.007370532867228026, "biggest_recent_change": 0.16354687627908504},
{"total_number_of_episodes": 13995, "number_of_timesteps": 3075115, "per_episode_reward": -64.25, "episode_reward_trend_value": 0.0072194087085406975, "biggest_recent_change": 0.16354687627908504},
{"total_number_of_episodes": 14005, "number_of_timesteps": 3077005, "per_episode_reward": -64.13, "episode_reward_trend_value": 0.0075188086119393595, "biggest_recent_change": 0.16354687627908504},
{"total_number_of_episodes": 14015, "number_of_timesteps": 3079003, "per_episode_reward": -64.08, "episode_reward_trend_value": 0.006308283445230087, "biggest_recent_change": 0.11674324759657395},
{"total_number_of_episodes": 14025, "number_of_timesteps": 3081280, "per_episode_reward": -64.01, "episode_reward_trend_value": 0.006533280163693355, "biggest_recent_change": 0.11674324759657395},
{"total_number_of_episodes": 14035, "number_of_timesteps": 3082690, "per_episode_reward": -63.94, "episode_reward_trend_value": 0.0066729865537500325, "biggest_recent_change": 0.11674324759657395},
{"total_number_of_episodes": 14045, "number_of_timesteps": 3084336, "per_episode_reward": -63.86, "episode_reward_trend_value": 0.00654748250988809, "biggest_recent_change": 0.11674324759657395},
{"total_number_of_episodes": 14055, "number_of_timesteps": 3085743, "per_episode_reward": -63.67, "episode_reward_trend_value": 0.008079959579648804, "biggest_recent_change": 0.18835080413243332},
{"total_number_of_episodes": 14066, "number_of_timesteps": 3087255, "per_episode_reward": -63.61, "episode_reward_trend_value": 0.008082418487847163, "biggest_recent_change": 0.18835080413243332},
{"total_number_of_episodes": 14076, "number_of_timesteps": 3088655, "per_episode_reward": -63.57, "episode_reward_trend_value": 0.008244739605623469, "biggest_recent_change": 0.18835080413243332},
{"total_number_of_episodes": 14087, "number_of_timesteps": 3091374, "per_episode_reward": -63.54, "episode_reward_trend_value": 0.007894124868814838, "biggest_recent_change": 0.18835080413243332},
{"total_number_of_episodes": 14097, "number_of_timesteps": 3093260, "per_episode_reward": -63.43, "episode_reward_trend_value": 0.007792355090324952, "biggest_recent_change": 0.18835080413243332},
{"total_number_of_episodes": 14107, "number_of_timesteps": 3094992, "per_episode_reward": -63.4, "episode_reward_trend_value": 0.007590797635573665, "biggest_recent_change": 0.18835080413243332},
{"total_number_of_episodes": 14117, "number_of_timesteps": 3097565, "per_episode_reward": -63.35, "episode_reward_trend_value": 0.007367723254235001, "biggest_recent_change": 0.18835080413243332},
{"total_number_of_episodes": 14127, "number_of_timesteps": 3099040, "per_episode_reward": -63.34, "episode_reward_trend_value": 0.006646236313401251, "biggest_recent_change": 0.18835080413243332},
{"total_number_of_episodes": 14138, "number_of_timesteps": 3101680, "per_episode_reward": -63.27, "episode_reward_trend_value": 0.00654197943364115, "biggest_recent_change": 0.18835080413243332},
{"total_number_of_episodes": 14148, "number_of_timesteps": 3103283, "per_episode_reward": -63.18, "episode_reward_trend_value": 0.005444126393549769, "biggest_recent_change": 0.10758396753248434},
{"total_number_of_episodes": 14158, "number_of_timesteps": 3105097, "per_episode_reward": -63.13, "episode_reward_trend_value": 0.005263423048409601, "biggest_recent_change": 0.10758396753248434},
{"total_number_of_episodes": 14168, "number_of_timesteps": 3106877, "per_episode_reward": -63.03, "episode_reward_trend_value": 0.005988363780580781, "biggest_recent_change": 0.10758396753248434},
{"total_number_of_episodes": 14178, "number_of_timesteps": 3108863, "per_episode_reward": -62.84, "episode_reward_trend_value": 0.007752498540519149, "biggest_recent_change": 0.18904576393876482},
{"total_number_of_episodes": 14188, "number_of_timesteps": 3110385, "per_episode_reward": -62.61, "episode_reward_trend_value": 0.009144186551587394, "biggest_recent_change": 0.23283588852862636},
{"total_number_of_episodes": 14198, "number_of_timesteps": 3112233, "per_episode_reward": -62.58, "episode_reward_trend_value": 0.009062497969111485, "biggest_recent_change": 0.23283588852862636},
{"total_number_of_episodes": 14208, "number_of_timesteps": 3113859, "per_episode_reward": -62.51, "episode_reward_trend_value": 0.009320987072150505, "biggest_recent_change": 0.23283588852862636},
{"total_number_of_episodes": 14218, "number_of_timesteps": 3115444, "per_episode_reward": -62.45, "episode_reward_trend_value": 0.009914172628446336, "biggest_recent_change": 0.23283588852862636},
{"total_number_of_episodes": 14228, "number_of_timesteps": 3117337, "per_episode_reward": -62.34, "episode_reward_trend_value": 0.010313425142921299, "biggest_recent_change": 0.23283588852862636},
{"total_number_of_episodes": 14238, "number_of_timesteps": 3119248, "per_episode_reward": -62.24, "episode_reward_trend_value": 0.010469545558819408, "biggest_recent_change": 0.23283588852862636},
{"total_number_of_episodes": 14248, "number_of_timesteps": 3123294, "per_episode_reward": -62.21, "episode_reward_trend_value": 0.01029709100363713, "biggest_recent_change": 0.23283588852862636},
{"total_number_of_episodes": 14258, "number_of_timesteps": 3128496, "per_episode_reward": -62.13, "episode_reward_trend_value": 0.009968454866214277, "biggest_recent_change": 0.23283588852862636},
{"total_number_of_episodes": 14269, "number_of_timesteps": 3133546, "per_episode_reward": -62.08, "episode_reward_trend_value": 0.008448119513565899, "biggest_recent_change": 0.23283588852862636},
{"total_number_of_episodes": 14279, "number_of_timesteps": 3138822, "per_episode_reward": -62.04, "episode_reward_trend_value": 0.00630300322382477, "biggest_recent_change": 0.10409880251804537},
{"total_number_of_episodes": 14289, "number_of_timesteps": 3147727, "per_episode_reward": -61.98, "episode_reward_trend_value": 0.006617089285279103, "biggest_recent_change": 0.10409880251804537},
{"total_number_of_episodes": 14299, "number_of_timesteps": 3155319, "per_episode_reward": -61.93, "episode_reward_trend_value": 0.0063963976723482256, "biggest_recent_change": 0.10409880251804537},
{"total_number_of_episodes": 14309, "number_of_timesteps": 3162196, "per_episode_reward": -61.75, "episode_reward_trend_value": 0.00773773616481953, "biggest_recent_change": 0.18440043790256055},
{"total_number_of_episodes": 14319, "number_of_timesteps": 3167353, "per_episode_reward": -61.69, "episode_reward_trend_value": 0.007291111033044079, "biggest_recent_change": 0.18440043790256055},
{"total_number_of_episodes": 14329, "number_of_timesteps": 3171456, "per_episode_reward": -61.63, "episode_reward_trend_value": 0.006761049055005704, "biggest_recent_change": 0.18440043790256055},
{"total_number_of_episodes": 14339, "number_of_timesteps": 3176248, "per_episode_reward": -61.58, "episode_reward_trend_value": 0.006915796212155022, "biggest_recent_change": 0.18440043790256055},
{"total_number_of_episodes": 14349, "number_of_timesteps": 3183340, "per_episode_reward": -61.54, "episode_reward_trend_value": 0.006576188446685114, "biggest_recent_change": 0.18440043790256055},
{"total_number_of_episodes": 14359, "number_of_timesteps": 3186633, "per_episode_reward": -61.37, "episode_reward_trend_value": 0.007909889600909202, "biggest_recent_change": 0.18440043790256055},
{"total_number_of_episodes": 14369, "number_of_timesteps": 3192720, "per_episode_reward": -61.29, "episode_reward_trend_value": 0.008298112321277371, "biggest_recent_change": 0.18440043790256055},
{"total_number_of_episodes": 14379, "number_of_timesteps": 3197906, "per_episode_reward": -61.29, "episode_reward_trend_value": 0.007743388601976165, "biggest_recent_change": 0.18440043790256055},
{"total_number_of_episodes": 14389, "number_of_timesteps": 3201037, "per_episode_reward": -61.24, "episode_reward_trend_value": 0.007682563244601761, "biggest_recent_change": 0.18440043790256055},
{"total_number_of_episodes": 14399, "number_of_timesteps": 3203648, "per_episode_reward": -61.22, "episode_reward_trend_value": 0.005878100434248997, "biggest_recent_change": 0.17224868608057875},
{"total_number_of_episodes": 14409, "number_of_timesteps": 3208551, "per_episode_reward": -61.16, "episode_reward_trend_value": 0.005789470913584675, "biggest_recent_change": 0.17224868608057875},
{"total_number_of_episodes": 14419, "number_of_timesteps": 3216133, "per_episode_reward": -61.15, "episode_reward_trend_value": 0.0053534594481225405, "biggest_recent_change": 0.17224868608057875},
{"total_number_of_episodes": 14429, "number_of_timesteps": 3219598, "per_episode_reward": -61.11, "episode_reward_trend_value": 0.005264806006810592, "biggest_recent_change": 0.17224868608057875},
{"total_number_of_episodes": 14439, "number_of_timesteps": 3225026, "per_episode_reward": -61.04, "episode_reward_trend_value": 0.005600984799612499, "biggest_recent_change": 0.17224868608057875},
{"total_number_of_episodes": 14449, "number_of_timesteps": 3230712, "per_episode_reward": -60.96, "episode_reward_trend_value": 0.00449386231174521, "biggest_recent_change": 0.07471546728505984},
{"total_number_of_episodes": 14459, "number_of_timesteps": 3234508, "per_episode_reward": -60.93, "episode_reward_trend_value": 0.004008904529711622, "biggest_recent_change": 0.07308958425504386},
{"total_number_of_episodes": 14469, "number_of_timesteps": 3239375, "per_episode_reward": -60.89, "episode_reward_trend_value": 0.0043911257066110605, "biggest_recent_change": 0.07308958425504386},
{"total_number_of_episodes": 14480, "number_of_timesteps": 3243257, "per_episode_reward": -60.85, "episode_reward_trend_value": 0.004325006079226689, "biggest_recent_change": 0.07308958425504386},
{"total_number_of_episodes": 14490, "number_of_timesteps": 3248372, "per_episode_reward": -60.78, "episode_reward_trend_value": 0.0049410514820429794, "biggest_recent_change": 0.07744287122427806},
{"total_number_of_episodes": 14500, "number_of_timesteps": 3252867, "per_episode_reward": -60.7, "episode_reward_trend_value": 0.005148957410230537, "biggest_recent_change": 0.07744287122427806},
{"total_number_of_episodes": 14510, "number_of_timesteps": 3256631, "per_episode_reward": -60.67, "episode_reward_trend_value": 0.0053632542904018185, "biggest_recent_change": 0.07744287122427806},
{"total_number_of_episodes": 14520, "number_of_timesteps": 3265071, "per_episode_reward": -60.62, "episode_reward_trend_value": 0.00540897076621418, "biggest_recent_change": 0.07744287122427806},
{"total_number_of_episodes": 14530, "number_of_timesteps": 3269304, "per_episode_reward": -60.6, "episode_reward_trend_value": 0.0048252693641228145, "biggest_recent_change": 0.07744287122427806},
{"total_number_of_episodes": 14540, "number_of_timesteps": 3272716, "per_episode_reward": -60.57, "episode_reward_trend_value": 0.004350996317842181, "biggest_recent_change": 0.07744287122427806},
{"total_number_of_episodes": 14550, "number_of_timesteps": 3277297, "per_episode_reward": -60.54, "episode_reward_trend_value": 0.004400931365377561, "biggest_recent_change": 0.07744287122427806},
{"total_number_of_episodes": 14560, "number_of_timesteps": 3284171, "per_episode_reward": -60.51, "episode_reward_trend_value": 0.0042362556763970525, "biggest_recent_change": 0.07744287122427806},
{"total_number_of_episodes": 14570, "number_of_timesteps": 3288493, "per_episode_reward": -60.43, "episode_reward_trend_value": 0.004663987000253655, "biggest_recent_change": 0.07744287122427806},
{"total_number_of_episodes": 14580, "number_of_timesteps": 3292605, "per_episode_reward": -60.35, "episode_reward_trend_value": 0.004711632136232583, "biggest_recent_change": 0.08173093346238147},
{"total_number_of_episodes": 14590, "number_of_timesteps": 3298773, "per_episode_reward": -60.3, "episode_reward_trend_value": 0.004446037120858963, "biggest_recent_change": 0.08173093346238147},
{"total_number_of_episodes": 14600, "number_of_timesteps": 3303672, "per_episode_reward": -60.25, "episode_reward_trend_value": 0.00463302862295644, "biggest_recent_change": 0.08173093346238147},
{"total_number_of_episodes": 14610, "number_of_timesteps": 3310321, "per_episode_reward": -60.2, "episode_reward_trend_value": 0.004739011980315411, "biggest_recent_change": 0.08173093346238147},
{"total_number_of_episodes": 14620, "number_of_timesteps": 3315283, "per_episode_reward": -60.17, "episode_reward_trend_value": 0.004779954876510967, "biggest_recent_change": 0.08173093346238147},
{"total_number_of_episodes": 14630, "number_of_timesteps": 3322748, "per_episode_reward": -60.14, "episode_reward_trend_value": 0.004792508987427545, "biggest_recent_change": 0.08173093346238147},
{"total_number_of_episodes": 14640, "number_of_timesteps": 3327859, "per_episode_reward": -60.12, "episode_reward_trend_value": 0.0046393314634592285, "biggest_recent_change": 0.08173093346238147},
{"total_number_of_episodes": 14650, "number_of_timesteps": 3331936, "per_episode_reward": -60.07, "episode_reward_trend_value": 0.004926244580495304, "biggest_recent_change": 0.08173093346238147},
{"total_number_of_episodes": 14660, "number_of_timesteps": 3334319, "per_episode_reward": -60.01, "episode_reward_trend_value": 0.004690014876363099, "biggest_recent_change": 0.08173093346238147},
{"total_number_of_episodes": 14670, "number_of_timesteps": 3337491, "per_episode_reward": -60.02, "episode_reward_trend_value": 0.0037290056374406472, "biggest_recent_change": 0.055877567786339455},
{"total_number_of_episodes": 14681, "number_of_timesteps": 3342597, "per_episode_reward": -59.98, "episode_reward_trend_value": 0.0035502764053347057, "biggest_recent_change": 0.055877567786339455},
{"total_number_of_episodes": 14691, "number_of_timesteps": 3345121, "per_episode_reward": -59.96, "episode_reward_trend_value": 0.003200277124020169, "biggest_recent_change": 0.055877567786339455},
{"total_number_of_episodes": 14701, "number_of_timesteps": 3347909, "per_episode_reward": -59.81, "episode_reward_trend_value": 0.004330834232989547, "biggest_recent_change": 0.15282182513351472},
{"total_number_of_episodes": 14712, "number_of_timesteps": 3351426, "per_episode_reward": -59.8, "episode_reward_trend_value": 0.004179741184503646, "biggest_recent_change": 0.15282182513351472},
{"total_number_of_episodes": 14723, "number_of_timesteps": 3357334, "per_episode_reward": -59.74, "episode_reward_trend_value": 0.004492681818544497, "biggest_recent_change": 0.15282182513351472},
{"total_number_of_episodes": 14735, "number_of_timesteps": 3361429, "per_episode_reward": -59.65, "episode_reward_trend_value": 0.00525666469715481, "biggest_recent_change": 0.15282182513351472},
{"total_number_of_episodes": 14745, "number_of_timesteps": 3365895, "per_episode_reward": -59.62, "episode_reward_trend_value": 0.004937914216945671, "biggest_recent_change": 0.15282182513351472},
{"total_number_of_episodes": 14755, "number_of_timesteps": 3370097, "per_episode_reward": -59.58, "episode_reward_trend_value": 0.004840141803073392, "biggest_recent_change": 0.15282182513351472},
{"total_number_of_episodes": 14765, "number_of_timesteps": 3373903, "per_episode_reward": -59.52, "episode_reward_trend_value": 0.005545690307592347, "biggest_recent_change": 0.15282182513351472},
{"total_number_of_episodes": 14775, "number_of_timesteps": 3377490, "per_episode_reward": -59.48, "episode_reward_trend_value": 0.005526462201886614, "biggest_recent_change": 0.15282182513351472},
{"total_number_of_episodes": 14785, "number_of_timesteps": 3380457, "per_episode_reward": -59.45, "episode_reward_trend_value": 0.005706394242145684, "biggest_recent_change": 0.15282182513351472},
{"total_number_of_episodes": 14795, "number_of_timesteps": 3383376, "per_episode_reward": -59.42, "episode_reward_trend_value": 0.004276511824322584, "biggest_recent_change": 0.09053590309800086},
{"total_number_of_episodes": 14805, "number_of_timesteps": 3385259, "per_episode_reward": -59.36, "episode_reward_trend_value": 0.004899906549485107, "biggest_recent_change": 0.09053590309800086},
{"total_number_of_episodes": 14815, "number_of_timesteps": 3388263, "per_episode_reward": -59.28, "episode_reward_trend_value": 0.005035003757784137, "biggest_recent_change": 0.09053590309800086},
{"total_number_of_episodes": 14825, "number_of_timesteps": 3390506, "per_episode_reward": -59.04, "episode_reward_trend_value": 0.006732335744280722, "biggest_recent_change": 0.24329578188269352},
{"total_number_of_episodes": 14835, "number_of_timesteps": 3393537, "per_episode_reward": -58.95, "episode_reward_trend_value": 0.0074301561701902745, "biggest_recent_change": 0.24329578188269352},
{"total_number_of_episodes": 14846, "number_of_timesteps": 3396043, "per_episode_reward": -58.89, "episode_reward_trend_value": 0.007589076682664597, "biggest_recent_change": 0.24329578188269352},
{"total_number_of_episodes": 14856, "number_of_timesteps": 3398475, "per_episode_reward": -58.83, "episode_reward_trend_value": 0.00764156228036299, "biggest_recent_change": 0.24329578188269352},
{"total_number_of_episodes": 14867, "number_of_timesteps": 3400616, "per_episode_reward": -58.72, "episode_reward_trend_value": 0.008465350745521584, "biggest_recent_change": 0.24329578188269352},
{"total_number_of_episodes": 14877, "number_of_timesteps": 3402498, "per_episode_reward": -58.7, "episode_reward_trend_value": 0.008289563340774464, "biggest_recent_change": 0.24329578188269352},
{"total_number_of_episodes": 14887, "number_of_timesteps": 3404480, "per_episode_reward": -58.64, "episode_reward_trend_value": 0.008661590426716022, "biggest_recent_change": 0.24329578188269352},
{"total_number_of_episodes": 14897, "number_of_timesteps": 3406385, "per_episode_reward": -58.52, "episode_reward_trend_value": 0.009234259038291823, "biggest_recent_change": 0.24329578188269352},
{"total_number_of_episodes": 14908, "number_of_timesteps": 3408989, "per_episode_reward": -58.45, "episode_reward_trend_value": 0.00932463989838431, "biggest_recent_change": 0.24329578188269352},
{"total_number_of_episodes": 14918, "number_of_timesteps": 3411052, "per_episode_reward": -58.38, "episode_reward_trend_value": 0.0073226552579341506, "biggest_recent_change": 0.11828864466713895},
{"total_number_of_episodes": 14928, "number_of_timesteps": 3413010, "per_episode_reward": -58.34, "episode_reward_trend_value": 0.006858233585812298, "biggest_recent_change": 0.11828864466713895},
{"total_number_of_episodes": 14938, "number_of_timesteps": 3414985, "per_episode_reward": -58.29, "episode_reward_trend_value": 0.006751690494457484, "biggest_recent_change": 0.11828864466713895},
{"total_number_of_episodes": 14948, "number_of_timesteps": 3416821, "per_episode_reward": -58.22, "episode_reward_trend_value": 0.006824129672139713, "biggest_recent_change": 0.11828864466713895},
{"total_number_of_episodes": 14958, "number_of_timesteps": 3418587, "per_episode_reward": -58.07, "episode_reward_trend_value": 0.007264590234374818, "biggest_recent_change": 0.14670011801410254},
{"total_number_of_episodes": 14968, "number_of_timesteps": 3421773, "per_episode_reward": -57.98, "episode_reward_trend_value": 0.007970903324869265, "biggest_recent_change": 0.14670011801410254},
{"total_number_of_episodes": 14978, "number_of_timesteps": 3424197, "per_episode_reward": -57.95, "episode_reward_trend_value": 0.007691267571142963, "biggest_recent_change": 0.14670011801410254},
{"total_number_of_episodes": 14988, "number_of_timesteps": 3426395, "per_episode_reward": -57.88, "episode_reward_trend_value": 0.007171323374595159, "biggest_recent_change": 0.14670011801410254},
{"total_number_of_episodes": 14998, "number_of_timesteps": 3428884, "per_episode_reward": -57.82, "episode_reward_trend_value": 0.006958239507731258, "biggest_recent_change": 0.14670011801410254},
{"total_number_of_episodes": 15008, "number_of_timesteps": 3431561, "per_episode_reward": -57.71, "episode_reward_trend_value": 0.007477449447430631, "biggest_recent_change": 0.14670011801410254},
{"total_number_of_episodes": 15018, "number_of_timesteps": 3434602, "per_episode_reward": -57.7, "episode_reward_trend_value": 0.007118796203989003, "biggest_recent_change": 0.14670011801410254},
{"total_number_of_episodes": 15029, "number_of_timesteps": 3438117, "per_episode_reward": -57.67, "episode_reward_trend_value": 0.006861103691930263, "biggest_recent_change": 0.14670011801410254},
{"total_number_of_episodes": 15039, "number_of_timesteps": 3442013, "per_episode_reward": -57.65, "episode_reward_trend_value": 0.006231942996175535, "biggest_recent_change": 0.14670011801410254},
{"total_number_of_episodes": 15049, "number_of_timesteps": 3447653, "per_episode_reward": -57.6, "episode_reward_trend_value": 0.005206578561115154, "biggest_recent_change": 0.10984605881512266},
{"total_number_of_episodes": 15060, "number_of_timesteps": 3452083, "per_episode_reward": -57.61, "episode_reward_trend_value": 0.004177428260280812, "biggest_recent_change": 0.10984605881512266},
{"total_number_of_episodes": 15070, "number_of_timesteps": 3459313, "per_episode_reward": -57.59, "episode_reward_trend_value": 0.0040089707603710185, "biggest_recent_change": 0.10984605881512266},
{"total_number_of_episodes": 15080, "number_of_timesteps": 3464530, "per_episode_reward": -57.52, "episode_reward_trend_value": 0.003971369532926714, "biggest_recent_change": 0.10984605881512266},
{"total_number_of_episodes": 15090, "number_of_timesteps": 3468620, "per_episode_reward": -57.37, "episode_reward_trend_value": 0.004987908118003048, "biggest_recent_change": 0.15182156584778994},
{"total_number_of_episodes": 15100, "number_of_timesteps": 3473370, "per_episode_reward": -57.34, "episode_reward_trend_value": 0.004147410091018836, "biggest_recent_change": 0.15182156584778994},
{"total_number_of_episodes": 15110, "number_of_timesteps": 3477484, "per_episode_reward": -57.31, "episode_reward_trend_value": 0.0043223083705977985, "biggest_recent_change": 0.15182156584778994},
{"total_number_of_episodes": 15120, "number_of_timesteps": 3485113, "per_episode_reward": -57.22, "episode_reward_trend_value": 0.004955626719111135, "biggest_recent_change": 0.15182156584778994},
{"total_number_of_episodes": 15130, "number_of_timesteps": 3493965, "per_episode_reward": -57.19, "episode_reward_trend_value": 0.005134289276819004, "biggest_recent_change": 0.15182156584778994},
{"total_number_of_episodes": 15140, "number_of_timesteps": 3498636, "per_episode_reward": -57.14, "episode_reward_trend_value": 0.005075095141692208, "biggest_recent_change": 0.15182156584778994},
{"total_number_of_episodes": 15150, "number_of_timesteps": 3501737, "per_episode_reward": -57.1, "episode_reward_trend_value": 0.005679827440830584, "biggest_recent_change": 0.15182156584778994},
{"total_number_of_episodes": 15160, "number_of_timesteps": 3507564, "per_episode_reward": -57.09, "episode_reward_trend_value": 0.005585489123693637, "biggest_recent_change": 0.15182156584778994},
{"total_number_of_episodes": 15170, "number_of_timesteps": 3510952, "per_episode_reward": -57.06, "episode_reward_trend_value": 0.005114225207398388, "biggest_recent_change": 0.15182156584778994},
{"total_number_of_episodes": 15180, "number_of_timesteps": 3514677, "per_episode_reward": -57.04, "episode_reward_trend_value": 0.003679202480029807, "biggest_recent_change": 0.08559834371950359},
{"total_number_of_episodes": 15190, "number_of_timesteps": 3519156, "per_episode_reward": -57.01, "episode_reward_trend_value": 0.0035682621276413957, "biggest_recent_change": 0.08559834371950359},
{"total_number_of_episodes": 15200, "number_of_timesteps": 3524973, "per_episode_reward": -56.94, "episode_reward_trend_value": 0.0040296503374022226, "biggest_recent_change": 0.08559834371950359},
{"total_number_of_episodes": 15210, "number_of_timesteps": 3529051, "per_episode_reward": -56.89, "episode_reward_trend_value": 0.003639318274219426, "biggest_recent_change": 0.07015668991743951},
{"total_number_of_episodes": 15220, "number_of_timesteps": 3532104, "per_episode_reward": -56.83, "episode_reward_trend_value": 0.00401611317448077, "biggest_recent_change": 0.07015668991743951},
{"total_number_of_episodes": 15230, "number_of_timesteps": 3535915, "per_episode_reward": -56.73, "episode_reward_trend_value": 0.004593489371618789, "biggest_recent_change": 0.10105370443967843},
{"total_number_of_episodes": 15240, "number_of_timesteps": 3539984, "per_episode_reward": -56.62, "episode_reward_trend_value": 0.005251960458578805, "biggest_recent_change": 0.10627025014021285},
{"total_number_of_episodes": 15250, "number_of_timesteps": 3543957, "per_episode_reward": -56.56, "episode_reward_trend_value": 0.0059097823127275875, "biggest_recent_change": 0.10627025014021285},
{"total_number_of_episodes": 15260, "number_of_timesteps": 3547942, "per_episode_reward": -56.54, "episode_reward_trend_value": 0.00583655202826334, "biggest_recent_change": 0.10627025014021285},
{"total_number_of_episodes": 15270, "number_of_timesteps": 3552692, "per_episode_reward": -56.46, "episode_reward_trend_value": 0.006464628354103831, "biggest_recent_change": 0.10627025014021285},
{"total_number_of_episodes": 15281, "number_of_timesteps": 3556434, "per_episode_reward": -56.39, "episode_reward_trend_value": 0.006975191787616887, "biggest_recent_change": 0.10627025014021285},
{"total_number_of_episodes": 15291, "number_of_timesteps": 3560509, "per_episode_reward": -56.35, "episode_reward_trend_value": 0.006567164121393414, "biggest_recent_change": 0.10627025014021285},
{"total_number_of_episodes": 15301, "number_of_timesteps": 3565224, "per_episode_reward": -56.31, "episode_reward_trend_value": 0.006477780806770283, "biggest_recent_change": 0.10627025014021285},
{"total_number_of_episodes": 15312, "number_of_timesteps": 3569313, "per_episode_reward": -56.27, "episode_reward_trend_value": 0.006201954316698514, "biggest_recent_change": 0.10627025014021285},
{"total_number_of_episodes": 15322, "number_of_timesteps": 3572640, "per_episode_reward": -56.18, "episode_reward_trend_value": 0.006067427465434921, "biggest_recent_change": 0.10627025014021285},
{"total_number_of_episodes": 15332, "number_of_timesteps": 3577139, "per_episode_reward": -56.09, "episode_reward_trend_value": 0.00597207884433999, "biggest_recent_change": 0.09768887424166905},
{"total_number_of_episodes": 15342, "number_of_timesteps": 3582250, "per_episode_reward": -56.0, "episode_reward_trend_value": 0.006167500743865636, "biggest_recent_change": 0.09768887424166905},
{"total_number_of_episodes": 15352, "number_of_timesteps": 3586152, "per_episode_reward": -55.85, "episode_reward_trend_value": 0.0076735172100084025, "biggest_recent_change": 0.1546465603923437},
{"total_number_of_episodes": 15362, "number_of_timesteps": 3589469, "per_episode_reward": -55.78, "episode_reward_trend_value": 0.007529721332450062, "biggest_recent_change": 0.1546465603923437},
{"total_number_of_episodes": 15372, "number_of_timesteps": 3593480, "per_episode_reward": -55.72, "episode_reward_trend_value": 0.0074099854739545085, "biggest_recent_change": 0.1546465603923437},
{"total_number_of_episodes": 15382, "number_of_timesteps": 3597871, "per_episode_reward": -55.68, "episode_reward_trend_value": 0.007452807883170859, "biggest_recent_change": 0.1546465603923437},
{"total_number_of_episodes": 15392, "number_of_timesteps": 3603297, "per_episode_reward": -55.62, "episode_reward_trend_value": 0.007729251229370249, "biggest_recent_change": 0.1546465603923437},
{"total_number_of_episodes": 15402, "number_of_timesteps": 3606592, "per_episode_reward": -55.57, "episode_reward_trend_value": 0.007759379229236647, "biggest_recent_change": 0.1546465603923437},
{"total_number_of_episodes": 15413, "number_of_timesteps": 3610421, "per_episode_reward": -55.52, "episode_reward_trend_value": 0.007368916377952356, "biggest_recent_change": 0.1546465603923437},
{"total_number_of_episodes": 15423, "number_of_timesteps": 3612694, "per_episode_reward": -55.43, "episode_reward_trend_value": 0.007271366789099826, "biggest_recent_change": 0.1546465603923437},
{"total_number_of_episodes": 15433, "number_of_timesteps": 3615276, "per_episode_reward": -55.32, "episode_reward_trend_value": 0.007564429557378105, "biggest_recent_change": 0.1546465603923437},
{"total_number_of_episodes": 15443, "number_of_timesteps": 3618466, "per_episode_reward": -55.24, "episode_reward_trend_value": 0.006771654369637364, "biggest_recent_change": 0.1119635908703458},
{"total_number_of_episodes": 15453, "number_of_timesteps": 3623148, "per_episode_reward": -55.18, "episode_reward_trend_value": 0.006697378837413165, "biggest_recent_change": 0.1119635908703458},
{"total_number_of_episodes": 15463, "number_of_timesteps": 3628286, "per_episode_reward": -55.01, "episode_reward_trend_value": 0.007878131568672033, "biggest_recent_change": 0.16565883223645983},
{"total_number_of_episodes": 15473, "number_of_timesteps": 3630580, "per_episode_reward": -54.86, "episode_reward_trend_value": 0.009145475524158226, "biggest_recent_change": 0.16565883223645983},
{"total_number_of_episodes": 15483, "number_of_timesteps": 3633149, "per_episode_reward": -54.79, "episode_reward_trend_value": 0.009169428994765303, "biggest_recent_change": 0.16565883223645983},
{"total_number_of_episodes": 15495, "number_of_timesteps": 3636893, "per_episode_reward": -54.76, "episode_reward_trend_value": 0.009060076500964935, "biggest_recent_change": 0.16565883223645983},
{"total_number_of_episodes": 15505, "number_of_timesteps": 3639973, "per_episode_reward": -54.71, "episode_reward_trend_value": 0.00902715496086191, "biggest_recent_change": 0.16565883223645983},
{"total_number_of_episodes": 15515, "number_of_timesteps": 3642811, "per_episode_reward": -54.65, "episode_reward_trend_value": 0.008684789868915981, "biggest_recent_change": 0.16565883223645983},
{"total_number_of_episodes": 15526, "number_of_timesteps": 3646639, "per_episode_reward": -54.58, "episode_reward_trend_value": 0.00826267237831107, "biggest_recent_change": 0.16565883223645983},
{"total_number_of_episodes": 15536, "number_of_timesteps": 3650468, "per_episode_reward": -54.49, "episode_reward_trend_value": 0.008312524425674973, "biggest_recent_change": 0.16565883223645983},
{"total_number_of_episodes": 15546, "number_of_timesteps": 3654667, "per_episode_reward": -54.42, "episode_reward_trend_value": 0.008375915942578712, "biggest_recent_change": 0.16565883223645983},
{"total_number_of_episodes": 15557, "number_of_timesteps": 3659788, "per_episode_reward": -54.38, "episode_reward_trend_value": 0.006990477396873335, "biggest_recent_change": 0.15134917278055582},
{"total_number_of_episodes": 15567, "number_of_timesteps": 3662124, "per_episode_reward": -54.35, "episode_reward_trend_value": 0.0056147764597015105, "biggest_recent_change": 0.08778347775842832},
{"total_number_of_episodes": 15577, "number_of_timesteps": 3665498, "per_episode_reward": -54.3, "episode_reward_trend_value": 0.005434698848682255, "biggest_recent_change": 0.08778347775842832},
{"total_number_of_episodes": 15587, "number_of_timesteps": 3667649, "per_episode_reward": -54.24, "episode_reward_trend_value": 0.005712823454400015, "biggest_recent_change": 0.08778347775842832},
{"total_number_of_episodes": 15598, "number_of_timesteps": 3669947, "per_episode_reward": -54.19, "episode_reward_trend_value": 0.005726983427388177, "biggest_recent_change": 0.08778347775842832},
{"total_number_of_episodes": 15608, "number_of_timesteps": 3672078, "per_episode_reward": -54.15, "episode_reward_trend_value": 0.005555396836252018, "biggest_recent_change": 0.08778347775842832},
{"total_number_of_episodes": 15618, "number_of_timesteps": 3674249, "per_episode_reward": -54.07, "episode_reward_trend_value": 0.005633889008063243, "biggest_recent_change": 0.08778347775842832},
{"total_number_of_episodes": 15628, "number_of_timesteps": 3677138, "per_episode_reward": -54.04, "episode_reward_trend_value": 0.005002816815798797, "biggest_recent_change": 0.08103731217891408},
{"total_number_of_episodes": 15638, "number_of_timesteps": 3679635, "per_episode_reward": -53.99, "episode_reward_trend_value": 0.004774451611324556, "biggest_recent_change": 0.08103731217891408},
{"total_number_of_episodes": 15648, "number_of_timesteps": 3682039, "per_episode_reward": -53.94, "episode_reward_trend_value": 0.004935563931534167, "biggest_recent_change": 0.08103731217891408},
{"total_number_of_episodes": 15658, "number_of_timesteps": 3686396, "per_episode_reward": -53.91, "episode_reward_trend_value": 0.004935982967008654, "biggest_recent_change": 0.08103731217891408},
{"total_number_of_episodes": 15668, "number_of_timesteps": 3689038, "per_episode_reward": -53.95, "episode_reward_trend_value": 0.003953955021371138, "biggest_recent_change": 0.08103731217891408},
{"total_number_of_episodes": 15678, "number_of_timesteps": 3692322, "per_episode_reward": -53.87, "episode_reward_trend_value": 0.0041505065074338805, "biggest_recent_change": 0.08103731217891408},
{"total_number_of_episodes": 15688, "number_of_timesteps": 3695874, "per_episode_reward": -53.86, "episode_reward_trend_value": 0.0036702875310518994, "biggest_recent_change": 0.08103731217891408},
{"total_number_of_episodes": 15698, "number_of_timesteps": 3699040, "per_episode_reward": -53.84, "episode_reward_trend_value": 0.003434934093514544, "biggest_recent_change": 0.08103731217891408},
{"total_number_of_episodes": 15708, "number_of_timesteps": 3704275, "per_episode_reward": -53.83, "episode_reward_trend_value": 0.002698414260605375, "biggest_recent_change": 0.0741156654493551},
{"total_number_of_episodes": 15718, "number_of_timesteps": 3708200, "per_episode_reward": -53.75, "episode_reward_trend_value": 0.0031462242244421484, "biggest_recent_change": 0.0741156654493551},
{"total_number_of_episodes": 15728, "number_of_timesteps": 3713262, "per_episode_reward": -53.7, "episode_reward_trend_value": 0.0032114746604577247, "biggest_recent_change": 0.0741156654493551},
{"total_number_of_episodes": 15738, "number_of_timesteps": 3716854, "per_episode_reward": -53.59, "episode_reward_trend_value": 0.0038142435334318887, "biggest_recent_change": 0.10971867050951545},
{"total_number_of_episodes": 15748, "number_of_timesteps": 3720764, "per_episode_reward": -53.62, "episode_reward_trend_value": 0.0032051153595925065, "biggest_recent_change": 0.10971867050951545},
{"total_number_of_episodes": 15758, "number_of_timesteps": 3724907, "per_episode_reward": -53.53, "episode_reward_trend_value": 0.0045850107248020956, "biggest_recent_change": 0.10971867050951545},
{"total_number_of_episodes": 15769, "number_of_timesteps": 3728264, "per_episode_reward": -53.44, "episode_reward_trend_value": 0.004736359734130878, "biggest_recent_change": 0.10971867050951545},
{"total_number_of_episodes": 15779, "number_of_timesteps": 3733668, "per_episode_reward": -53.38, "episode_reward_trend_value": 0.005405318608416505, "biggest_recent_change": 0.10971867050951545},
{"total_number_of_episodes": 15789, "number_of_timesteps": 3738790, "per_episode_reward": -53.34, "episode_reward_trend_value": 0.005566137488615416, "biggest_recent_change": 0.10971867050951545},
{"total_number_of_episodes": 15799, "number_of_timesteps": 3741971, "per_episode_reward": -53.31, "episode_reward_trend_value": 0.005682405171752928, "biggest_recent_change": 0.10971867050951545},
{"total_number_of_episodes": 15809, "number_of_timesteps": 3745915, "per_episode_reward": -53.27, "episode_reward_trend_value": 0.0053527411828144505, "biggest_recent_change": 0.10971867050951545},
{"total_number_of_episodes": 15819, "number_of_timesteps": 3748940, "per_episode_reward": -53.18, "episode_reward_trend_value": 0.005846469234079955, "biggest_recent_change": 0.10971867050951545},
{"total_number_of_episodes": 15829, "number_of_timesteps": 3751883, "per_episode_reward": -53.13, "episode_reward_trend_value": 0.0051725114068025685, "biggest_recent_change": 0.09503039480378561},
{"total_number_of_episodes": 15839, "number_of_timesteps": 3754616, "per_episode_reward": -53.08, "episode_reward_trend_value": 0.0060088936755590796, "biggest_recent_change": 0.09503039480378561},
{"total_number_of_episodes": 15849, "number_of_timesteps": 3759056, "per_episode_reward": -52.99, "episode_reward_trend_value": 0.006063215553365274, "biggest_recent_change": 0.09503039480378561},
{"total_number_of_episodes": 15859, "number_of_timesteps": 3761967, "per_episode_reward": -52.92, "episode_reward_trend_value": 0.00579630063928486, "biggest_recent_change": 0.09503039480378561},
{"total_number_of_episodes": 15869, "number_of_timesteps": 3764311, "per_episode_reward": -52.93, "episode_reward_trend_value": 0.005004023457293746, "biggest_recent_change": 0.09503039480378561},
{"total_number_of_episodes": 15879, "number_of_timesteps": 3769250, "per_episode_reward": -52.85, "episode_reward_trend_value": 0.0054636639040041585, "biggest_recent_change": 0.09503039480378561},
{"total_number_of_episodes": 15889, "number_of_timesteps": 3773427, "per_episode_reward": -52.83, "episode_reward_trend_value": 0.005436764899703582, "biggest_recent_change": 0.09503039480378561},
{"total_number_of_episodes": 15899, "number_of_timesteps": 3777334, "per_episode_reward": -52.76, "episode_reward_trend_value": 0.005713740163479189, "biggest_recent_change": 0.09503039480378561},
{"total_number_of_episodes": 15909, "number_of_timesteps": 3781151, "per_episode_reward": -52.74, "episode_reward_trend_value": 0.004917633966301417, "biggest_recent_change": 0.09394972500186327},
{"total_number_of_episodes": 15919, "number_of_timesteps": 3785366, "per_episode_reward": -52.66, "episode_reward_trend_value": 0.0051815658897257635, "biggest_recent_change": 0.09394972500186327},
{"total_number_of_episodes": 15929, "number_of_timesteps": 3793041, "per_episode_reward": -52.58, "episode_reward_trend_value": 0.005537259108410177, "biggest_recent_change": 0.09394972500186327},
{"total_number_of_episodes": 15939, "number_of_timesteps": 3800888, "per_episode_reward": -52.62, "episode_reward_trend_value": 0.004085556207804883, "biggest_recent_change": 0.08003905985193427},
{"total_number_of_episodes": 15949, "number_of_timesteps": 3806759, "per_episode_reward": -52.61, "episode_reward_trend_value": 0.0034621791805472904, "biggest_recent_change": 0.08003905985193427},
{"total_number_of_episodes": 15959, "number_of_timesteps": 3810702, "per_episode_reward": -52.52, "episode_reward_trend_value": 0.004519017022117092, "biggest_recent_change": 0.09291314034344111},
{"total_number_of_episodes": 15969, "number_of_timesteps": 3813950, "per_episode_reward": -52.47, "episode_reward_trend_value": 0.004246170728427264, "biggest_recent_change": 0.09291314034344111},
{"total_number_of_episodes": 15979, "number_of_timesteps": 3819049, "per_episode_reward": -52.38, "episode_reward_trend_value": 0.004967404409225651, "biggest_recent_change": 0.09291314034344111},
{"total_number_of_episodes": 15989, "number_of_timesteps": 3822575, "per_episode_reward": -52.27, "episode_reward_trend_value": 0.005391011867973026, "biggest_recent_change": 0.10467256322254315},
{"total_number_of_episodes": 15999, "number_of_timesteps": 3826204, "per_episode_reward": -52.19, "episode_reward_trend_value": 0.006024012671010265, "biggest_recent_change": 0.10467256322254315},
{"total_number_of_episodes": 16009, "number_of_timesteps": 3829004, "per_episode_reward": -52.02, "episode_reward_trend_value": 0.007105104669694778, "biggest_recent_change": 0.1701146190443481},
{"total_number_of_episodes": 16019, "number_of_timesteps": 3832413, "per_episode_reward": -52.01, "episode_reward_trend_value": 0.006407246566242325, "biggest_recent_change": 0.1701146190443481},
{"total_number_of_episodes": 16029, "number_of_timesteps": 3834937, "per_episode_reward": -51.96, "episode_reward_trend_value": 0.007376860020783009, "biggest_recent_change": 0.1701146190443481},
{"total_number_of_episodes": 16039, "number_of_timesteps": 3838732, "per_episode_reward": -51.91, "episode_reward_trend_value": 0.007787691793641945, "biggest_recent_change": 0.1701146190443481},
{"total_number_of_episodes": 16049, "number_of_timesteps": 3842038, "per_episode_reward": -51.83, "episode_reward_trend_value": 0.00769642557864682, "biggest_recent_change": 0.1701146190443481},
{"total_number_of_episodes": 16059, "number_of_timesteps": 3844659, "per_episode_reward": -51.79, "episode_reward_trend_value": 0.007529875407642726, "biggest_recent_change": 0.1701146190443481},
{"total_number_of_episodes": 16070, "number_of_timesteps": 3847948, "per_episode_reward": -51.73, "episode_reward_trend_value": 0.007161239643055634, "biggest_recent_change": 0.1701146190443481},
{"total_number_of_episodes": 16080, "number_of_timesteps": 3850891, "per_episode_reward": -51.72, "episode_reward_trend_value": 0.006204065736537166, "biggest_recent_change": 0.1701146190443481},
{"total_number_of_episodes": 16090, "number_of_timesteps": 3853845, "per_episode_reward": -51.65, "episode_reward_trend_value": 0.0060283178660611725, "biggest_recent_change": 0.1701146190443481},
{"total_number_of_episodes": 16100, "number_of_timesteps": 3856973, "per_episode_reward": -51.65, "episode_reward_trend_value": 0.004169594338455735, "biggest_recent_change": 0.08469918099387996},
{"total_number_of_episodes": 16110, "number_of_timesteps": 3859621, "per_episode_reward": -51.61, "episode_reward_trend_value": 0.0044319008796418775, "biggest_recent_change": 0.08469918099387996},
{"total_number_of_episodes": 16120, "number_of_timesteps": 3863114, "per_episode_reward": -51.49, "episode_reward_trend_value": 0.005162580316112692, "biggest_recent_change": 0.11632282413842177},
{"total_number_of_episodes": 16130, "number_of_timesteps": 3868335, "per_episode_reward": -51.44, "episode_reward_trend_value": 0.005180598802117941, "biggest_recent_change": 0.11632282413842177},
{"total_number_of_episodes": 16140, "number_of_timesteps": 3872835, "per_episode_reward": -51.37, "episode_reward_trend_value": 0.005082111893176252, "biggest_recent_change": 0.11632282413842177},
{"total_number_of_episodes": 16150, "number_of_timesteps": 3876180, "per_episode_reward": -51.33, "episode_reward_trend_value": 0.005134927732470452, "biggest_recent_change": 0.11632282413842177},
{"total_number_of_episodes": 16160, "number_of_timesteps": 3880180, "per_episode_reward": -51.3, "episode_reward_trend_value": 0.004863726671107571, "biggest_recent_change": 0.11632282413842177},
{"total_number_of_episodes": 16170, "number_of_timesteps": 3883812, "per_episode_reward": -51.26, "episode_reward_trend_value": 0.005112758824636801, "biggest_recent_change": 0.11632282413842177},
{"total_number_of_episodes": 16180, "number_of_timesteps": 3887590, "per_episode_reward": -51.2, "episode_reward_trend_value": 0.005038346095167631, "biggest_recent_change": 0.11632282413842177},
{"total_number_of_episodes": 16190, "number_of_timesteps": 3890372, "per_episode_reward": -51.13, "episode_reward_trend_value": 0.005791593740157136, "biggest_recent_change": 0.11632282413842177},
{"total_number_of_episodes": 16200, "number_of_timesteps": 3893399, "per_episode_reward": -51.06, "episode_reward_trend_value": 0.006098723116902091, "biggest_recent_change": 0.11632282413842177},
{"total_number_of_episodes": 16210, "number_of_timesteps": 3895676, "per_episode_reward": -51.0, "episode_reward_trend_value": 0.005480757964847606, "biggest_recent_change": 0.07583535918912787},
{"total_number_of_episodes": 16220, "number_of_timesteps": 3898320, "per_episode_reward": -50.94, "episode_reward_trend_value": 0.005552134543220038, "biggest_recent_change": 0.07583535918912787},
{"total_number_of_episodes": 16230, "number_of_timesteps": 3900580, "per_episode_reward": -50.86, "episode_reward_trend_value": 0.005602791752365732, "biggest_recent_change": 0.08039450801224035},
{"total_number_of_episodes": 16241, "number_of_timesteps": 3902696, "per_episode_reward": -50.78, "episode_reward_trend_value": 0.006101861956437205, "biggest_recent_change": 0.08743735189148794},
{"total_number_of_episodes": 16251, "number_of_timesteps": 3904663, "per_episode_reward": -50.76, "episode_reward_trend_value": 0.006009038719320061, "biggest_recent_change": 0.08743735189148794},
{"total_number_of_episodes": 16261, "number_of_timesteps": 3906848, "per_episode_reward": -50.65, "episode_reward_trend_value": 0.006736594633503204, "biggest_recent_change": 0.10641983772999453},
{"total_number_of_episodes": 16271, "number_of_timesteps": 3909242, "per_episode_reward": -50.56, "episode_reward_trend_value": 0.007048640052642538, "biggest_recent_change": 0.10641983772999453},
{"total_number_of_episodes": 16281, "number_of_timesteps": 3911421, "per_episode_reward": -50.42, "episode_reward_trend_value": 0.007836087874075304, "biggest_recent_change": 0.14149209353786318},
{"total_number_of_episodes": 16291, "number_of_timesteps": 3913853, "per_episode_reward": -50.38, "episode_reward_trend_value": 0.007544198417779866, "biggest_recent_change": 0.14149209353786318},
{"total_number_of_episodes": 16301, "number_of_timesteps": 3916276, "per_episode_reward": -50.34, "episode_reward_trend_value": 0.007315199231162871, "biggest_recent_change": 0.14149209353786318},
{"total_number_of_episodes": 16311, "number_of_timesteps": 3919110, "per_episode_reward": -50.28, "episode_reward_trend_value": 0.007435305461283942, "biggest_recent_change": 0.14149209353786318},
{"total_number_of_episodes": 16321, "number_of_timesteps": 3921762, "per_episode_reward": -50.21, "episode_reward_trend_value": 0.0072487264532516815, "biggest_recent_change": 0.14149209353786318},
{"total_number_of_episodes": 16331, "number_of_timesteps": 3924314, "per_episode_reward": -50.13, "episode_reward_trend_value": 0.0072093314480645805, "biggest_recent_change": 0.14149209353786318},
{"total_number_of_episodes": 16341, "number_of_timesteps": 3925838, "per_episode_reward": -50.03, "episode_reward_trend_value": 0.008103648800107522, "biggest_recent_change": 0.14149209353786318},
{"total_number_of_episodes": 16352, "number_of_timesteps": 3927605, "per_episode_reward": -49.98, "episode_reward_trend_value": 0.007430262630630263, "biggest_recent_change": 0.14149209353786318},
{"total_number_of_episodes": 16362, "number_of_timesteps": 3929084, "per_episode_reward": -49.92, "episode_reward_trend_value": 0.007109297545210877, "biggest_recent_change": 0.14149209353786318},
{"total_number_of_episodes": 16373, "number_of_timesteps": 3931021, "per_episode_reward": -49.87, "episode_reward_trend_value": 0.006117851300290608, "biggest_recent_change": 0.10225389559209219},
{"total_number_of_episodes": 16383, "number_of_timesteps": 3932741, "per_episode_reward": -49.84, "episode_reward_trend_value": 0.005980434763892677, "biggest_recent_change": 0.10225389559209219},
{"total_number_of_episodes": 16393, "number_of_timesteps": 3934747, "per_episode_reward": -49.81, "episode_reward_trend_value": 0.005856350597208465, "biggest_recent_change": 0.10225389559209219},
{"total_number_of_episodes": 16403, "number_of_timesteps": 3937213, "per_episode_reward": -49.79, "episode_reward_trend_value": 0.0054011084707683375, "biggest_recent_change": 0.10225389559209219},
{"total_number_of_episodes": 16413, "number_of_timesteps": 3939801, "per_episode_reward": -49.75, "episode_reward_trend_value": 0.005144874580408201, "biggest_recent_change": 0.10225389559209219},
{"total_number_of_episodes": 16423, "number_of_timesteps": 3943141, "per_episode_reward": -49.72, "episode_reward_trend_value": 0.004520696596974716, "biggest_recent_change": 0.10225389559209219},
{"total_number_of_episodes": 16433, "number_of_timesteps": 3947540, "per_episode_reward": -49.7, "episode_reward_trend_value": 0.0036569709727364364, "biggest_recent_change": 0.05703368537086817},
{"total_number_of_episodes": 16443, "number_of_timesteps": 3951754, "per_episode_reward": -49.64, "episode_reward_trend_value": 0.0037828741895250713, "biggest_recent_change": 0.05714637198801853},
{"total_number_of_episodes": 16453, "number_of_timesteps": 3957446, "per_episode_reward": -49.61, "episode_reward_trend_value": 0.0035213150915238437, "biggest_recent_change": 0.05714637198801853},
{"total_number_of_episodes": 16463, "number_of_timesteps": 3961426, "per_episode_reward": -49.53, "episode_reward_trend_value": 0.003839238992135642, "biggest_recent_change": 0.08087508255010079},
{"total_number_of_episodes": 16473, "number_of_timesteps": 3965063, "per_episode_reward": -49.42, "episode_reward_trend_value": 0.004688088250292882, "biggest_recent_change": 0.10623995704676048},
{"total_number_of_episodes": 16483, "number_of_timesteps": 3969653, "per_episode_reward": -49.35, "episode_reward_trend_value": 0.005124640485802069, "biggest_recent_change": 0.10623995704676048},
{"total_number_of_episodes": 16493, "number_of_timesteps": 3971943, "per_episode_reward": -49.27, "episode_reward_trend_value": 0.005751281921186546, "biggest_recent_change": 0.10623995704676048},
{"total_number_of_episodes": 16503, "number_of_timesteps": 3973923, "per_episode_reward": -49.24, "episode_reward_trend_value": 0.00569915902996401, "biggest_recent_change": 0.10623995704676048},
{"total_number_of_episodes": 16513, "number_of_timesteps": 3977399, "per_episode_reward": -49.22, "episode_reward_trend_value": 0.005574934791573108, "biggest_recent_change": 0.10623995704676048},
{"total_number_of_episodes": 16523, "number_of_timesteps": 3981415, "per_episode_reward": -49.13, "episode_reward_trend_value": 0.0062557660673622836, "biggest_recent_change": 0.10623995704676048},
{"total_number_of_episodes": 16533, "number_of_timesteps": 3983786, "per_episode_reward": -49.06, "episode_reward_trend_value": 0.006399365734633971, "biggest_recent_change": 0.10623995704676048},
{"total_number_of_episodes": 16543, "number_of_timesteps": 3988565, "per_episode_reward": -49.04, "episode_reward_trend_value": 0.006341375982174451, "biggest_recent_change": 0.10623995704676048},
{"total_number_of_episodes": 16553, "number_of_timesteps": 3991893, "per_episode_reward": -48.99, "episode_reward_trend_value": 0.005986519632381339, "biggest_recent_change": 0.10623995704676048},
{"total_number_of_episodes": 16563, "number_of_timesteps": 3995034, "per_episode_reward": -48.94, "episode_reward_trend_value": 0.005368571077148232, "biggest_recent_change": 0.08579340423167281},
{"total_number_of_episodes": 16574, "number_of_timesteps": 3998497, "per_episode_reward": -48.77, "episode_reward_trend_value": 0.0063981787127007795, "biggest_recent_change": 0.16088284705196543},
{"total_number_of_episodes": 16584, "number_of_timesteps": 4001288, "per_episode_reward": -48.74, "episode_reward_trend_value": 0.005899499400417814, "biggest_recent_change": 0.16088284705196543},
{"total_number_of_episodes": 16594, "number_of_timesteps": 4003688, "per_episode_reward": -48.7, "episode_reward_trend_value": 0.005956680800906058, "biggest_recent_change": 0.16088284705196543},
{"total_number_of_episodes": 16604, "number_of_timesteps": 4006608, "per_episode_reward": -48.69, "episode_reward_trend_value": 0.005939369779785627, "biggest_recent_change": 0.16088284705196543},
{"total_number_of_episodes": 16614, "number_of_timesteps": 4009968, "per_episode_reward": -48.63, "episode_reward_trend_value": 0.005577600027903015, "biggest_recent_change": 0.16088284705196543},
{"total_number_of_episodes": 16624, "number_of_timesteps": 4014442, "per_episode_reward": -48.52, "episode_reward_trend_value": 0.005999002072861023, "biggest_recent_change": 0.16088284705196543},
{"total_number_of_episodes": 16634, "number_of_timesteps": 4017571, "per_episode_reward": -48.43, "episode_reward_trend_value": 0.006681192080951507, "biggest_recent_change": 0.16088284705196543},
{"total_number_of_episodes": 16644, "number_of_timesteps": 4020026, "per_episode_reward": -48.41, "episode_reward_trend_value": 0.006407290257945103, "biggest_recent_change": 0.16088284705196543},
{"total_number_of_episodes": 16654, "number_of_timesteps": 4023007, "per_episode_reward": -48.37, "episode_reward_trend_value": 0.006322234675310926, "biggest_recent_change": 0.16088284705196543},
{"total_number_of_episodes": 16664, "number_of_timesteps": 4025761, "per_episode_reward": -48.31, "episode_reward_trend_value": 0.005121420030871033, "biggest_recent_change": 0.10799652608869081},
{"total_number_of_episodes": 16674, "number_of_timesteps": 4027765, "per_episode_reward": -48.3, "episode_reward_trend_value": 0.0049148228831526804, "biggest_recent_change": 0.10799652608869081},
{"total_number_of_episodes": 16684, "number_of_timesteps": 4029875, "per_episode_reward": -48.26, "episode_reward_trend_value": 0.004932615914989134, "biggest_recent_change": 0.10799652608869081},
{"total_number_of_episodes": 16694, "number_of_timesteps": 4032199, "per_episode_reward": -48.21, "episode_reward_trend_value": 0.00523038953382324, "biggest_recent_change": 0.10799652608869081},
{"total_number_of_episodes": 16704, "number_of_timesteps": 4034442, "per_episode_reward": -48.14, "episode_reward_trend_value": 0.0054789548272991175, "biggest_recent_change": 0.10799652608869081},
{"total_number_of_episodes": 16714, "number_of_timesteps": 4037861, "per_episode_reward": -48.06, "episode_reward_trend_value": 0.005120317975113093, "biggest_recent_change": 0.0896713895575445},
{"total_number_of_episodes": 16724, "number_of_timesteps": 4041090, "per_episode_reward": -47.99, "episode_reward_trend_value": 0.0049803204963400245, "biggest_recent_change": 0.07707161646796834},
{"total_number_of_episodes": 16734, "number_of_timesteps": 4045184, "per_episode_reward": -47.93, "episode_reward_trend_value": 0.005320920231440359, "biggest_recent_change": 0.07707161646796834},
{"total_number_of_episodes": 16745, "number_of_timesteps": 4048130, "per_episode_reward": -47.86, "episode_reward_trend_value": 0.005654361175439801, "biggest_recent_change": 0.07707161646796834},
{"total_number_of_episodes": 16755, "number_of_timesteps": 4051831, "per_episode_reward": -47.83, "episode_reward_trend_value": 0.005326736436217535, "biggest_recent_change": 0.07707161646796834},
{"total_number_of_episodes": 16765, "number_of_timesteps": 4055944, "per_episode_reward": -47.78, "episode_reward_trend_value": 0.005748087240313124, "biggest_recent_change": 0.07707161646796834},
{"total_number_of_episodes": 16775, "number_of_timesteps": 4059286, "per_episode_reward": -47.73, "episode_reward_trend_value": 0.005810238135755223, "biggest_recent_change": 0.07707161646796834},
{"total_number_of_episodes": 16785, "number_of_timesteps": 4061200, "per_episode_reward": -47.64, "episode_reward_trend_value": 0.006332393654128844, "biggest_recent_change": 0.08877123190831071},
{"total_number_of_episodes": 16795, "number_of_timesteps": 4063813, "per_episode_reward": -47.63, "episode_reward_trend_value": 0.0056612657714429325, "biggest_recent_change": 0.08877123190831071},
{"total_number_of_episodes": 16806, "number_of_timesteps": 4068525, "per_episode_reward": -47.56, "episode_reward_trend_value": 0.005637383180264995, "biggest_recent_change": 0.08877123190831071},
{"total_number_of_episodes": 16816, "number_of_timesteps": 4071276, "per_episode_reward": -47.52, "episode_reward_trend_value": 0.005208642628575669, "biggest_recent_change": 0.08877123190831071},
{"total_number_of_episodes": 16826, "number_of_timesteps": 4073791, "per_episode_reward": -47.49, "episode_reward_trend_value": 0.004943636834809063, "biggest_recent_change": 0.08877123190831071},
{"total_number_of_episodes": 16836, "number_of_timesteps": 4076480, "per_episode_reward": -47.42, "episode_reward_trend_value": 0.004825155223590846, "biggest_recent_change": 0.08877123190831071},
{"total_number_of_episodes": 16846, "number_of_timesteps": 4079242, "per_episode_reward": -47.38, "episode_reward_trend_value": 0.005030467259407425, "biggest_recent_change": 0.08877123190831071},
{"total_number_of_episodes": 16856, "number_of_timesteps": 4084834, "per_episode_reward": -47.34, "episode_reward_trend_value": 0.0048697661780147585, "biggest_recent_change": 0.08877123190831071},
{"total_number_of_episodes": 16867, "number_of_timesteps": 4087763, "per_episode_reward": -47.34, "episode_reward_trend_value": 0.0043890816626338215, "biggest_recent_change": 0.08877123190831071},
{"total_number_of_episodes": 16877, "number_of_timesteps": 4092198, "per_episode_reward": -47.28, "episode_reward_trend_value": 0.004046611084888478, "biggest_recent_change": 0.07356977618593419},
{"total_number_of_episodes": 16887, "number_of_timesteps": 4099063, "per_episode_reward": -47.25, "episode_reward_trend_value": 0.004259998649925794, "biggest_recent_change": 0.07356977618593419},
{"total_number_of_episodes": 16897, "number_of_timesteps": 4105613, "per_episode_reward": -47.22, "episode_reward_trend_value": 0.0036792041396793707, "biggest_recent_change": 0.062315924589015026},
{"total_number_of_episodes": 16907, "number_of_timesteps": 4109697, "per_episode_reward": -47.15, "episode_reward_trend_value": 0.004089777953139636, "biggest_recent_change": 0.07543661002735291},
{"total_number_of_episodes": 16917, "number_of_timesteps": 4113212, "per_episode_reward": -47.12, "episode_reward_trend_value": 0.004092153697793795, "biggest_recent_change": 0.07543661002735291},
{"total_number_of_episodes": 16927, "number_of_timesteps": 4117033, "per_episode_reward": -47.09, "episode_reward_trend_value": 0.0037434493983429067, "biggest_recent_change": 0.07543661002735291},
{"total_number_of_episodes": 16937, "number_of_timesteps": 4120741, "per_episode_reward": -47.04, "episode_reward_trend_value": 0.0037879097199387327, "biggest_recent_change": 0.07543661002735291},
{"total_number_of_episodes": 16947, "number_of_timesteps": 4126096, "per_episode_reward": -47.02, "episode_reward_trend_value": 0.003622110398249845, "biggest_recent_change": 0.07543661002735291},
{"total_number_of_episodes": 16957, "number_of_timesteps": 4133206, "per_episode_reward": -46.96, "episode_reward_trend_value": 0.004239888481646482, "biggest_recent_change": 0.07543661002735291},
{"total_number_of_episodes": 16968, "number_of_timesteps": 4141345, "per_episode_reward": -46.91, "episode_reward_trend_value": 0.0041423294401304305, "biggest_recent_change": 0.07543661002735291},
{"total_number_of_episodes": 16978, "number_of_timesteps": 4147726, "per_episode_reward": -46.88, "episode_reward_trend_value": 0.0041056035433168206, "biggest_recent_change": 0.07543661002735291},
{"total_number_of_episodes": 16988, "number_of_timesteps": 4154472, "per_episode_reward": -46.84, "episode_reward_trend_value": 0.004255841142639601, "biggest_recent_change": 0.07543661002735291},
{"total_number_of_episodes": 16998, "number_of_timesteps": 4157967, "per_episode_reward": -46.84, "episode_reward_trend_value": 0.003463023757453243, "biggest_recent_change": 0.060529987567321086},
{"total_number_of_episodes": 17009, "number_of_timesteps": 4163645, "per_episode_reward": -46.78, "episode_reward_trend_value": 0.0037142483395953716, "biggest_recent_change": 0.060529987567321086},
{"total_number_of_episodes": 17019, "number_of_timesteps": 4168019, "per_episode_reward": -46.67, "episode_reward_trend_value": 0.004634027397182905, "biggest_recent_change": 0.11371265282131304},
{"total_number_of_episodes": 17029, "number_of_timesteps": 4171428, "per_episode_reward": -46.66, "episode_reward_trend_value": 0.00418467791394082, "biggest_recent_change": 0.11371265282131304},
{"total_number_of_episodes": 17039, "number_of_timesteps": 4174478, "per_episode_reward": -46.5, "episode_reward_trend_value": 0.005771133290225015, "biggest_recent_change": 0.16670935399243092},
{"total_number_of_episodes": 17049, "number_of_timesteps": 4177562, "per_episode_reward": -46.46, "episode_reward_trend_value": 0.005537571934758903, "biggest_recent_change": 0.16670935399243092},
{"total_number_of_episodes": 17059, "number_of_timesteps": 4180604, "per_episode_reward": -46.42, "episode_reward_trend_value": 0.005392763881083498, "biggest_recent_change": 0.16670935399243092},
{"total_number_of_episodes": 17069, "number_of_timesteps": 4183105, "per_episode_reward": -46.39, "episode_reward_trend_value": 0.005353691132389019, "biggest_recent_change": 0.16670935399243092},
{"total_number_of_episodes": 17079, "number_of_timesteps": 4185121, "per_episode_reward": -46.33, "episode_reward_trend_value": 0.005650858423943658, "biggest_recent_change": 0.16670935399243092},
{"total_number_of_episodes": 17089, "number_of_timesteps": 4187358, "per_episode_reward": -46.3, "episode_reward_trend_value": 0.005973298474162192, "biggest_recent_change": 0.16670935399243092},
{"total_number_of_episodes": 17099, "number_of_timesteps": 4190922, "per_episode_reward": -46.27, "episode_reward_trend_value": 0.005718553084794406, "biggest_recent_change": 0.16670935399243092},
{"total_number_of_episodes": 17109, "number_of_timesteps": 4193328, "per_episode_reward": -46.23, "episode_reward_trend_value": 0.004931977294715592, "biggest_recent_change": 0.16670935399243092},
{"total_number_of_episodes": 17119, "number_of_timesteps": 4195110, "per_episode_reward": -46.2, "episode_reward_trend_value": 0.005180137830594194, "biggest_recent_change": 0.16670935399243092},
{"total_number_of_episodes": 17129, "number_of_timesteps": 4198320, "per_episode_reward": -46.18, "episode_reward_trend_value": 0.0035584925331464652, "biggest_recent_change": 0.061564710442723936},
{"total_number_of_episodes": 17139, "number_of_timesteps": 4200229, "per_episode_reward": -46.14, "episode_reward_trend_value": 0.0035876947814777794, "biggest_recent_change": 0.061564710442723936},
{"total_number_of_episodes": 17149, "number_of_timesteps": 4202505, "per_episode_reward": -46.06, "episode_reward_trend_value": 0.004071066679972151, "biggest_recent_change": 0.07963931220849219},
{"total_number_of_episodes": 17159, "number_of_timesteps": 4204813, "per_episode_reward": -46.02, "episode_reward_trend_value": 0.004120058198766527, "biggest_recent_change": 0.07963931220849219},
{"total_number_of_episodes": 17169, "number_of_timesteps": 4206297, "per_episode_reward": -45.99, "episode_reward_trend_value": 0.0038077709484198074, "biggest_recent_change": 0.07963931220849219},
{"total_number_of_episodes": 17179, "number_of_timesteps": 4207913, "per_episode_reward": -45.96, "episode_reward_trend_value": 0.003723103973129424, "biggest_recent_change": 0.07963931220849219},
{"total_number_of_episodes": 17189, "number_of_timesteps": 4209557, "per_episode_reward": -45.9, "episode_reward_trend_value": 0.00407181263614444, "biggest_recent_change": 0.07963931220849219},
{"total_number_of_episodes": 17199, "number_of_timesteps": 4211111, "per_episode_reward": -45.86, "episode_reward_trend_value": 0.004011443902512232, "biggest_recent_change": 0.07963931220849219},
{"total_number_of_episodes": 17209, "number_of_timesteps": 4213430, "per_episode_reward": -45.84, "episode_reward_trend_value": 0.003957209719797245, "biggest_recent_change": 0.07963931220849219},
{"total_number_of_episodes": 17219, "number_of_timesteps": 4215008, "per_episode_reward": -45.83, "episode_reward_trend_value": 0.00385881225675446, "biggest_recent_change": 0.07963931220849219},
{"total_number_of_episodes": 17229, "number_of_timesteps": 4216555, "per_episode_reward": -45.78, "episode_reward_trend_value": 0.003966906895379038, "biggest_recent_change": 0.07963931220849219},
{"total_number_of_episodes": 17239, "number_of_timesteps": 4217927, "per_episode_reward": -45.75, "episode_reward_trend_value": 0.0034511793612442116, "biggest_recent_change": 0.06237102575809672},
{"total_number_of_episodes": 17250, "number_of_timesteps": 4219498, "per_episode_reward": -45.68, "episode_reward_trend_value": 0.0037661956480694097, "biggest_recent_change": 0.06237102575809672},
{"total_number_of_episodes": 17260, "number_of_timesteps": 4221778, "per_episode_reward": -45.62, "episode_reward_trend_value": 0.004074116312170082, "biggest_recent_change": 0.06237102575809672},
{"total_number_of_episodes": 17270, "number_of_timesteps": 4224328, "per_episode_reward": -45.58, "episode_reward_trend_value": 0.004326133481196513, "biggest_recent_change": 0.06237102575809672},
{"total_number_of_episodes": 17280, "number_of_timesteps": 4226098, "per_episode_reward": -45.53, "episode_reward_trend_value": 0.00415692895029104, "biggest_recent_change": 0.06117171768057972},
{"total_number_of_episodes": 17290, "number_of_timesteps": 4228259, "per_episode_reward": -45.5, "episode_reward_trend_value": 0.004100598964795507, "biggest_recent_change": 0.06117171768057972},
{"total_number_of_episodes": 17300, "number_of_timesteps": 4230735, "per_episode_reward": -45.46, "episode_reward_trend_value": 0.004226762344795057, "biggest_recent_change": 0.06117171768057972},
{"total_number_of_episodes": 17310, "number_of_timesteps": 4232584, "per_episode_reward": -45.42, "episode_reward_trend_value": 0.004609263900549524, "biggest_recent_change": 0.06117171768057972},
{"total_number_of_episodes": 17320, "number_of_timesteps": 4234248, "per_episode_reward": -45.39, "episode_reward_trend_value": 0.004315439260532293, "biggest_recent_change": 0.06117171768057972},
{"total_number_of_episodes": 17330, "number_of_timesteps": 4236535, "per_episode_reward": -45.34, "episode_reward_trend_value": 0.004472769122789879, "biggest_recent_change": 0.06117171768057972},
{"total_number_of_episodes": 17340, "number_of_timesteps": 4238189, "per_episode_reward": -45.32, "episode_reward_trend_value": 0.004010903784415534, "biggest_recent_change": 0.06117171768057972},
{"total_number_of_episodes": 17351, "number_of_timesteps": 4240077, "per_episode_reward": -45.22, "episode_reward_trend_value": 0.004503129890170262, "biggest_recent_change": 0.10547206719850521},
{"total_number_of_episodes": 17361, "number_of_timesteps": 4242625, "per_episode_reward": -45.16, "episode_reward_trend_value": 0.004660166452785733, "biggest_recent_change": 0.10547206719850521},
{"total_number_of_episodes": 17371, "number_of_timesteps": 4245331, "per_episode_reward": -45.09, "episode_reward_trend_value": 0.0048166625626475616, "biggest_recent_change": 0.10547206719850521},
{"total_number_of_episodes": 17381, "number_of_timesteps": 4248917, "per_episode_reward": -45.09, "episode_reward_trend_value": 0.004517955678521998, "biggest_recent_change": 0.10547206719850521},
{"total_number_of_episodes": 17391, "number_of_timesteps": 4252514, "per_episode_reward": -45.07, "episode_reward_trend_value": 0.0043788670135596255, "biggest_recent_change": 0.10547206719850521},
{"total_number_of_episodes": 17401, "number_of_timesteps": 4255991, "per_episode_reward": -45.07, "episode_reward_trend_value": 0.003865206052583482, "biggest_recent_change": 0.10547206719850521},
{"total_number_of_episodes": 17411, "number_of_timesteps": 4261779, "per_episode_reward": -45.03, "episode_reward_trend_value": 0.003959728511399005, "biggest_recent_change": 0.10547206719850521},
{"total_number_of_episodes": 17421, "number_of_timesteps": 4265075, "per_episode_reward": -45.0, "episode_reward_trend_value": 0.0037718496394084076, "biggest_recent_change": 0.10547206719850521},
{"total_number_of_episodes": 17431, "number_of_timesteps": 4267847, "per_episode_reward": -44.97, "episode_reward_trend_value": 0.003905521286464856, "biggest_recent_change": 0.10547206719850521},
{"total_number_of_episodes": 17441, "number_of_timesteps": 4273977, "per_episode_reward": -44.83, "episode_reward_trend_value": 0.004275653278762567, "biggest_recent_change": 0.13878394650529913},
{"total_number_of_episodes": 17451, "number_of_timesteps": 4279222, "per_episode_reward": -44.8, "episode_reward_trend_value": 0.00392813692568931, "biggest_recent_change": 0.13878394650529913},
{"total_number_of_episodes": 17462, "number_of_timesteps": 4283869, "per_episode_reward": -44.79, "episode_reward_trend_value": 0.0034090580046927084, "biggest_recent_change": 0.13878394650529913},
{"total_number_of_episodes": 17472, "number_of_timesteps": 4286933, "per_episode_reward": -44.76, "episode_reward_trend_value": 0.003679340818068747, "biggest_recent_change": 0.13878394650529913},
{"total_number_of_episodes": 17482, "number_of_timesteps": 4294298, "per_episode_reward": -44.72, "episode_reward_trend_value": 0.0038174034527487938, "biggest_recent_change": 0.13878394650529913},
{"total_number_of_episodes": 17492, "number_of_timesteps": 4300531, "per_episode_reward": -44.72, "episode_reward_trend_value": 0.0038656829441557584, "biggest_recent_change": 0.13878394650529913},
{"total_number_of_episodes": 17502, "number_of_timesteps": 4306839, "per_episode_reward": -44.7, "episode_reward_trend_value": 0.0037247785080041576, "biggest_recent_change": 0.13878394650529913},
{"total_number_of_episodes": 17512, "number_of_timesteps": 4311831, "per_episode_reward": -44.63, "episode_reward_trend_value": 0.004119453985190328, "biggest_recent_change": 0.13878394650529913},
{"total_number_of_episodes": 17522, "number_of_timesteps": 4316277, "per_episode_reward": -44.56, "episode_reward_trend_value": 0.004567992616717002, "biggest_recent_change": 0.13878394650529913},
{"total_number_of_episodes": 17532, "number_of_timesteps": 4319742, "per_episode_reward": -44.47, "episode_reward_trend_value": 0.003994542056305761, "biggest_recent_change": 0.08717339606828745},
{"total_number_of_episodes": 17542, "number_of_timesteps": 4323872, "per_episode_reward": -44.36, "episode_reward_trend_value": 0.004913535930903063, "biggest_recent_change": 0.11373043488904955},
{"total_number_of_episodes": 17552, "number_of_timesteps": 4329303, "per_episode_reward": -44.29, "episode_reward_trend_value": 0.005517699156515397, "biggest_recent_change": 0.11373043488904955},
{"total_number_of_episodes": 17562, "number_of_timesteps": 4335230, "per_episode_reward": -44.08, "episode_reward_trend_value": 0.00754084147718667, "biggest_recent_change": 0.21194258948568034},
{"total_number_of_episodes": 17572, "number_of_timesteps": 4339357, "per_episode_reward": -43.96, "episode_reward_trend_value": 0.008445137192310723, "biggest_recent_change": 0.21194258948568034},
{"total_number_of_episodes": 17582, "number_of_timesteps": 4342991, "per_episode_reward": -43.9, "episode_reward_trend_value": 0.009074244487966373, "biggest_recent_change": 0.21194258948568034},
{"total_number_of_episodes": 17592, "number_of_timesteps": 4347067, "per_episode_reward": -43.84, "episode_reward_trend_value": 0.009576756190506961, "biggest_recent_change": 0.21194258948568034},
{"total_number_of_episodes": 17602, "number_of_timesteps": 4351285, "per_episode_reward": -43.82, "episode_reward_trend_value": 0.009022133416216131, "biggest_recent_change": 0.21194258948568034},
{"total_number_of_episodes": 17614, "number_of_timesteps": 4355184, "per_episode_reward": -43.78, "episode_reward_trend_value": 0.008686214990561405, "biggest_recent_change": 0.21194258948568034},
{"total_number_of_episodes": 17624, "number_of_timesteps": 4357487, "per_episode_reward": -43.75, "episode_reward_trend_value": 0.008090038977278466, "biggest_recent_change": 0.21194258948568034},
{"total_number_of_episodes": 17634, "number_of_timesteps": 4361938, "per_episode_reward": -43.73, "episode_reward_trend_value": 0.007042394157506651, "biggest_recent_change": 0.21194258948568034},
{"total_number_of_episodes": 17644, "number_of_timesteps": 4366530, "per_episode_reward": -43.7, "episode_reward_trend_value": 0.006536363674921672, "biggest_recent_change": 0.21194258948568034},
{"total_number_of_episodes": 17654, "number_of_timesteps": 4370247, "per_episode_reward": -43.67, "episode_reward_trend_value": 0.004495195274484745, "biggest_recent_change": 0.11546370881814028},
{"total_number_of_episodes": 17664, "number_of_timesteps": 4374208, "per_episode_reward": -43.65, "episode_reward_trend_value": 0.0034665923633302974, "biggest_recent_change": 0.06647364306825665},
{"total_number_of_episodes": 17675, "number_of_timesteps": 4378648, "per_episode_reward": -43.62, "episode_reward_trend_value": 0.0031253647251681905, "biggest_recent_change": 0.06647364306825665},
{"total_number_of_episodes": 17685, "number_of_timesteps": 4381388, "per_episode_reward": -43.47, "episode_reward_trend_value": 0.004025839709695431, "biggest_recent_change": 0.1475163916757083},
{"total_number_of_episodes": 17695, "number_of_timesteps": 4383893, "per_episode_reward": -43.43, "episode_reward_trend_value": 0.004386527786343603, "biggest_recent_change": 0.1475163916757083},
{"total_number_of_episodes": 17706, "number_of_timesteps": 4386487, "per_episode_reward": -43.4, "episode_reward_trend_value": 0.0042675005043292915, "biggest_recent_change": 0.1475163916757083},
{"total_number_of_episodes": 17716, "number_of_timesteps": 4388831, "per_episode_reward": -43.34, "episode_reward_trend_value": 0.004545614301855889, "biggest_recent_change": 0.1475163916757083},
{"total_number_of_episodes": 17726, "number_of_timesteps": 4391723, "per_episode_reward": -43.29, "episode_reward_trend_value": 0.00483523969816741, "biggest_recent_change": 0.1475163916757083},
{"total_number_of_episodes": 17736, "number_of_timesteps": 4394725, "per_episode_reward": -43.25, "episode_reward_trend_value": 0.005051971194298785, "biggest_recent_change": 0.1475163916757083},
{"total_number_of_episodes": 17746, "number_of_timesteps": 4397894, "per_episode_reward": -43.23, "episode_reward_trend_value": 0.0049669124482609244, "biggest_recent_change": 0.1475163916757083},
{"total_number_of_episodes": 17756, "number_of_timesteps": 4402382, "per_episode_reward": -43.2, "episode_reward_trend_value": 0.0050214707432530755, "biggest_recent_change": 0.1475163916757083},
{"total_number_of_episodes": 17766, "number_of_timesteps": 4406536, "per_episode_reward": -43.19, "episode_reward_trend_value": 0.004788882038355524, "biggest_recent_change": 0.1475163916757083},
{"total_number_of_episodes": 17776, "number_of_timesteps": 4410055, "per_episode_reward": -43.15, "episode_reward_trend_value": 0.0036367514040032724, "biggest_recent_change": 0.05854779665021681},
{"total_number_of_episodes": 17786, "number_of_timesteps": 4414410, "per_episode_reward": -43.07, "episode_reward_trend_value": 0.003961262571443472, "biggest_recent_change": 0.07774709848892059},
{"total_number_of_episodes": 17796, "number_of_timesteps": 4418580, "per_episode_reward": -43.05, "episode_reward_trend_value": 0.0038871833199237136, "biggest_recent_change": 0.07774709848892059},
{"total_number_of_episodes": 17807, "number_of_timesteps": 4422101, "per_episode_reward": -42.97, "episode_reward_trend_value": 0.004048717161683158, "biggest_recent_change": 0.07774709848892059},
{"total_number_of_episodes": 17818, "number_of_timesteps": 4424427, "per_episode_reward": -42.93, "episode_reward_trend_value": 0.004067744806989992, "biggest_recent_change": 0.07774709848892059},
{"total_number_of_episodes": 17828, "number_of_timesteps": 4427278, "per_episode_reward": -42.84, "episode_reward_trend_value": 0.004487491979578095, "biggest_recent_change": 0.08062519203168961},
{"total_number_of_episodes": 17838, "number_of_timesteps": 4430015, "per_episode_reward": -42.76, "episode_reward_trend_value": 0.005158204742061341, "biggest_recent_change": 0.08094629492644145},
{"total_number_of_episodes": 17848, "number_of_timesteps": 4433490, "per_episode_reward": -42.75, "episode_reward_trend_value": 0.004971059503253075, "biggest_recent_change": 0.08094629492644145},
{"total_number_of_episodes": 17858, "number_of_timesteps": 4436034, "per_episode_reward": -42.7, "episode_reward_trend_value": 0.00544582953384752, "biggest_recent_change": 0.08094629492644145},
{"total_number_of_episodes": 17868, "number_of_timesteps": 4438201, "per_episode_reward": -42.63, "episode_reward_trend_value": 0.005703302087510704, "biggest_recent_change": 0.08094629492644145},
{"total_number_of_episodes": 17878, "number_of_timesteps": 4441494, "per_episode_reward": -42.62, "episode_reward_trend_value": 0.005021360242400874, "biggest_recent_change": 0.08094629492644145},
{"total_number_of_episodes": 17888, "number_of_timesteps": 4443879, "per_episode_reward": -42.61, "episode_reward_trend_value": 0.004822550055090128, "biggest_recent_change": 0.08094629492644145},
{"total_number_of_episodes": 17898, "number_of_timesteps": 4446843, "per_episode_reward": -42.56, "episode_reward_trend_value": 0.004563942742893801, "biggest_recent_change": 0.08094629492644145},
{"total_number_of_episodes": 17908, "number_of_timesteps": 4448792, "per_episode_reward": -42.52, "episode_reward_trend_value": 0.004536028856831661, "biggest_recent_change": 0.08094629492644145},
{"total_number_of_episodes": 17919, "number_of_timesteps": 4450951, "per_episode_reward": -42.47, "episode_reward_trend_value": 0.004149051662327707, "biggest_recent_change": 0.08094629492644145},
{"total_number_of_episodes": 17930, "number_of_timesteps": 4452782, "per_episode_reward": -42.44, "episode_reward_trend_value": 0.0036305996000775857, "biggest_recent_change": 0.06699716441369219},
{"total_number_of_episodes": 17940, "number_of_timesteps": 4454623, "per_episode_reward": -42.38, "episode_reward_trend_value": 0.004115945263427139, "biggest_recent_change": 0.06699716441369219},
{"total_number_of_episodes": 17950, "number_of_timesteps": 4456446, "per_episode_reward": -42.32, "episode_reward_trend_value": 0.004252915962878885, "biggest_recent_change": 0.06699716441369219},
{"total_number_of_episodes": 17960, "number_of_timesteps": 4458506, "per_episode_reward": -42.3, "episode_reward_trend_value": 0.003730957109903304, "biggest_recent_change": 0.06447916474275672},
{"total_number_of_episodes": 17972, "number_of_timesteps": 4460292, "per_episode_reward": -42.24, "episode_reward_trend_value": 0.0041477348442757345, "biggest_recent_change": 0.06447916474275672},
{"total_number_of_episodes": 17982, "number_of_timesteps": 4461837, "per_episode_reward": -42.2, "episode_reward_trend_value": 0.004601620172825784, "biggest_recent_change": 0.06447916474275672},
{"total_number_of_episodes": 17992, "number_of_timesteps": 4463306, "per_episode_reward": -42.16, "episode_reward_trend_value": 0.004478845566643249, "biggest_recent_change": 0.06447916474275672},
{"total_number_of_episodes": 18002, "number_of_timesteps": 4464801, "per_episode_reward": -42.1, "episode_reward_trend_value": 0.004628842202208479, "biggest_recent_change": 0.06447916474275672},
{"total_number_of_episodes": 18012, "number_of_timesteps": 4466169, "per_episode_reward": -42.07, "episode_reward_trend_value": 0.004491494233761825, "biggest_recent_change": 0.06447916474275672},
{"total_number_of_episodes": 18022, "number_of_timesteps": 4467595, "per_episode_reward": -42.04, "episode_reward_trend_value": 0.004423474669886455, "biggest_recent_change": 0.06447916474275672},
{"total_number_of_episodes": 18032, "number_of_timesteps": 4468913, "per_episode_reward": -42.01, "episode_reward_trend_value": 0.004143224559090994, "biggest_recent_change": 0.06447916474275672},
{"total_number_of_episodes": 18044, "number_of_timesteps": 4470614, "per_episode_reward": -41.88, "episode_reward_trend_value": 0.004905832031454101, "biggest_recent_change": 0.13311383725543635},
{"total_number_of_episodes": 18055, "number_of_timesteps": 4472020, "per_episode_reward": -41.79, "episode_reward_trend_value": 0.005634477561708846, "biggest_recent_change": 0.13311383725543635},
{"total_number_of_episodes": 18065, "number_of_timesteps": 4473314, "per_episode_reward": -41.78, "episode_reward_trend_value": 0.00517244120777502, "biggest_recent_change": 0.13311383725543635},
{"total_number_of_episodes": 18075, "number_of_timesteps": 4474820, "per_episode_reward": -41.77, "episode_reward_trend_value": 0.004741068006535917, "biggest_recent_change": 0.13311383725543635},
{"total_number_of_episodes": 18085, "number_of_timesteps": 4476361, "per_episode_reward": -41.72, "episode_reward_trend_value": 0.0049208317795683834, "biggest_recent_change": 0.13311383725543635},
{"total_number_of_episodes": 18096, "number_of_timesteps": 4477926, "per_episode_reward": -41.69, "episode_reward_trend_value": 0.004556728327696646, "biggest_recent_change": 0.13311383725543635},
{"total_number_of_episodes": 18106, "number_of_timesteps": 4479302, "per_episode_reward": -41.66, "episode_reward_trend_value": 0.0045651580350935545, "biggest_recent_change": 0.13311383725543635},
{"total_number_of_episodes": 18116, "number_of_timesteps": 4480688, "per_episode_reward": -41.62, "episode_reward_trend_value": 0.004637133757774671, "biggest_recent_change": 0.13311383725543635},
{"total_number_of_episodes": 18126, "number_of_timesteps": 4482082, "per_episode_reward": -41.55, "episode_reward_trend_value": 0.005051861014064545, "biggest_recent_change": 0.13311383725543635},
{"total_number_of_episodes": 18137, "number_of_timesteps": 4483546, "per_episode_reward": -41.51, "episode_reward_trend_value": 0.00410963768071421, "biggest_recent_change": 0.08559896536881695},
{"total_number_of_episodes": 18149, "number_of_timesteps": 4485141, "per_episode_reward": -41.47, "episode_reward_trend_value": 0.0035987435108777296, "biggest_recent_change": 0.06674067466674671},
{"total_number_of_episodes": 18159, "number_of_timesteps": 4486552, "per_episode_reward": -41.4, "episode_reward_trend_value": 0.004241582251276713, "biggest_recent_change": 0.07015454330441884},
{"total_number_of_episodes": 18170, "number_of_timesteps": 4488099, "per_episode_reward": -41.33, "episode_reward_trend_value": 0.004865772683138106, "biggest_recent_change": 0.07015454330441884},
{"total_number_of_episodes": 18180, "number_of_timesteps": 4489524, "per_episode_reward": -41.3, "episode_reward_trend_value": 0.004652137792193796, "biggest_recent_change": 0.07015454330441884},
{"total_number_of_episodes": 18190, "number_of_timesteps": 4491222, "per_episode_reward": -41.25, "episode_reward_trend_value": 0.004848511972166689, "biggest_recent_change": 0.07015454330441884},
{"total_number_of_episodes": 18200, "number_of_timesteps": 4492539, "per_episode_reward": -41.18, "episode_reward_trend_value": 0.005305252741457246, "biggest_recent_change": 0.0753012702680067},
{"total_number_of_episodes": 18210, "number_of_timesteps": 4494081, "per_episode_reward": -40.97, "episode_reward_trend_value": 0.007204582223376358, "biggest_recent_change": 0.20558131698916782},
{"total_number_of_episodes": 18220, "number_of_timesteps": 4495502, "per_episode_reward": -40.96, "episode_reward_trend_value": 0.006638269427226914, "biggest_recent_change": 0.20558131698916782},
{"total_number_of_episodes": 18230, "number_of_timesteps": 4497166, "per_episode_reward": -40.9, "episode_reward_trend_value": 0.0067552809687428965, "biggest_recent_change": 0.20558131698916782},
{"total_number_of_episodes": 18240, "number_of_timesteps": 4498574, "per_episode_reward": -40.87, "episode_reward_trend_value": 0.0065909081065527175, "biggest_recent_change": 0.20558131698916782},
{"total_number_of_episodes": 18250, "number_of_timesteps": 4500277, "per_episode_reward": -40.86, "episode_reward_trend_value": 0.00598202006693861, "biggest_recent_change": 0.20558131698916782},
{"total_number_of_episodes": 18260, "number_of_timesteps": 4501655, "per_episode_reward": -40.84, "episode_reward_trend_value": 0.005460671483870369, "biggest_recent_change": 0.20558131698916782},
{"total_number_of_episodes": 18270, "number_of_timesteps": 4503339, "per_episode_reward": -40.83, "episode_reward_trend_value": 0.0052386848496701706, "biggest_recent_change": 0.20558131698916782},
{"total_number_of_episodes": 18280, "number_of_timesteps": 4504786, "per_episode_reward": -40.8, "episode_reward_trend_value": 0.005065417163086197, "biggest_recent_change": 0.20558131698916782},
{"total_number_of_episodes": 18290, "number_of_timesteps": 4506315, "per_episode_reward": -40.75, "episode_reward_trend_value": 0.004751667874405601, "biggest_recent_change": 0.20558131698916782},
{"total_number_of_episodes": 18300, "number_of_timesteps": 4508107, "per_episode_reward": -40.71, "episode_reward_trend_value": 0.002926076981652888, "biggest_recent_change": 0.058844775990344544},
{"total_number_of_episodes": 18310, "number_of_timesteps": 4509661, "per_episode_reward": -40.67, "episode_reward_trend_value": 0.003144141640913508, "biggest_recent_change": 0.058844775990344544},
{"total_number_of_episodes": 18320, "number_of_timesteps": 4511276, "per_episode_reward": -40.62, "episode_reward_trend_value": 0.003111177514585961, "biggest_recent_change": 0.05587800462086534},
{"total_number_of_episodes": 18330, "number_of_timesteps": 4512821, "per_episode_reward": -40.57, "episode_reward_trend_value": 0.003316189735877531, "biggest_recent_change": 0.05587800462086534},
{"total_number_of_episodes": 18340, "number_of_timesteps": 4514650, "per_episode_reward": -40.44, "episode_reward_trend_value": 0.004651783556169183, "biggest_recent_change": 0.1355580635653979},
{"total_number_of_episodes": 18350, "number_of_timesteps": 4516436, "per_episode_reward": -40.42, "episode_reward_trend_value": 0.004655171845721719, "biggest_recent_change": 0.1355580635653979},
{"total_number_of_episodes": 18360, "number_of_timesteps": 4518868, "per_episode_reward": -40.4, "episode_reward_trend_value": 0.004751845367122106, "biggest_recent_change": 0.1355580635653979},
{"total_number_of_episodes": 18370, "number_of_timesteps": 4521080, "per_episode_reward": -40.35, "episode_reward_trend_value": 0.004963001834814346, "biggest_recent_change": 0.1355580635653979},
{"total_number_of_episodes": 18380, "number_of_timesteps": 4522767, "per_episode_reward": -40.29, "episode_reward_trend_value": 0.005116333185784564, "biggest_recent_change": 0.1355580635653979},
{"total_number_of_episodes": 18391, "number_of_timesteps": 4524733, "per_episode_reward": -40.25, "episode_reward_trend_value": 0.005077628818785879, "biggest_recent_change": 0.1355580635653979},
{"total_number_of_episodes": 18401, "number_of_timesteps": 4526756, "per_episode_reward": -40.19, "episode_reward_trend_value": 0.005378781000691961, "biggest_recent_change": 0.1355580635653979},
{"total_number_of_episodes": 18411, "number_of_timesteps": 4529384, "per_episode_reward": -40.12, "episode_reward_trend_value": 0.005540624670571424, "biggest_recent_change": 0.1355580635653979},
{"total_number_of_episodes": 18421, "number_of_timesteps": 4531349, "per_episode_reward": -40.06, "episode_reward_trend_value": 0.00569458058222136, "biggest_recent_change": 0.1355580635653979},
{"total_number_of_episodes": 18431, "number_of_timesteps": 4533237, "per_episode_reward": -40.0, "episode_reward_trend_value": 0.004856835820276552, "biggest_recent_change": 0.07044393491001699},
{"total_number_of_episodes": 18441, "number_of_timesteps": 4534946, "per_episode_reward": -39.98, "episode_reward_trend_value": 0.0049605551450015006, "biggest_recent_change": 0.07044393491001699},
{"total_number_of_episodes": 18451, "number_of_timesteps": 4536972, "per_episode_reward": -39.93, "episode_reward_trend_value": 0.005165948339722585, "biggest_recent_change": 0.07044393491001699},
{"total_number_of_episodes": 18462, "number_of_timesteps": 4539498, "per_episode_reward": -39.92, "episode_reward_trend_value": 0.004810522125784348, "biggest_recent_change": 0.07044393491001699},
{"total_number_of_episodes": 18472, "number_of_timesteps": 4542160, "per_episode_reward": -39.74, "episode_reward_trend_value": 0.006076636446725637, "biggest_recent_change": 0.17481394475878886},
{"total_number_of_episodes": 18482, "number_of_timesteps": 4544081, "per_episode_reward": -39.69, "episode_reward_trend_value": 0.006270332150715615, "biggest_recent_change": 0.17481394475878886},
{"total_number_of_episodes": 18493, "number_of_timesteps": 4546326, "per_episode_reward": -39.59, "episode_reward_trend_value": 0.006632500440665092, "biggest_recent_change": 0.17481394475878886},
{"total_number_of_episodes": 18504, "number_of_timesteps": 4548314, "per_episode_reward": -39.51, "episode_reward_trend_value": 0.006733794636775849, "biggest_recent_change": 0.17481394475878886},
{"total_number_of_episodes": 18514, "number_of_timesteps": 4550263, "per_episode_reward": -39.47, "episode_reward_trend_value": 0.006628229952914448, "biggest_recent_change": 0.17481394475878886},
{"total_number_of_episodes": 18524, "number_of_timesteps": 4551970, "per_episode_reward": -39.43, "episode_reward_trend_value": 0.006321338345542433, "biggest_recent_change": 0.17481394475878886},
{"total_number_of_episodes": 18534, "number_of_timesteps": 4553748, "per_episode_reward": -39.4, "episode_reward_trend_value": 0.0064269375518102995, "biggest_recent_change": 0.17481394475878886},
{"total_number_of_episodes": 18544, "number_of_timesteps": 4555506, "per_episode_reward": -39.35, "episode_reward_trend_value": 0.0064919525083236675, "biggest_recent_change": 0.17481394475878886},
{"total_number_of_episodes": 18554, "number_of_timesteps": 4557313, "per_episode_reward": -39.26, "episode_reward_trend_value": 0.007301774426996843, "biggest_recent_change": 0.17481394475878886},
{"total_number_of_episodes": 18564, "number_of_timesteps": 4559744, "per_episode_reward": -39.2, "episode_reward_trend_value": 0.005985716968970836, "biggest_recent_change": 0.09509718481375273},
{"total_number_of_episodes": 18574, "number_of_timesteps": 4562665, "per_episode_reward": -39.17, "episode_reward_trend_value": 0.005797209267634823, "biggest_recent_change": 0.09509718481375273},
{"total_number_of_episodes": 18584, "number_of_timesteps": 4564968, "per_episode_reward": -39.09, "episode_reward_trend_value": 0.005623889552698418, "biggest_recent_change": 0.08741859156550902},
{"total_number_of_episodes": 18594, "number_of_timesteps": 4567200, "per_episode_reward": -39.0, "episode_reward_trend_value": 0.005667996638319453, "biggest_recent_change": 0.08741859156550902},
{"total_number_of_episodes": 18604, "number_of_timesteps": 4570562, "per_episode_reward": -38.95, "episode_reward_trend_value": 0.005784492922097052, "biggest_recent_change": 0.08741859156550902},
{"total_number_of_episodes": 18614, "number_of_timesteps": 4572842, "per_episode_reward": -38.91, "episode_reward_trend_value": 0.005841855229996343, "biggest_recent_change": 0.08741859156550902},
{"total_number_of_episodes": 18624, "number_of_timesteps": 4575969, "per_episode_reward": -38.89, "episode_reward_trend_value": 0.005590714342869142, "biggest_recent_change": 0.08741859156550902},
{"total_number_of_episodes": 18634, "number_of_timesteps": 4578926, "per_episode_reward": -38.86, "episode_reward_trend_value": 0.00538060872306916, "biggest_recent_change": 0.08741859156550902},
{"total_number_of_episodes": 18644, "number_of_timesteps": 4581610, "per_episode_reward": -38.84, "episode_reward_trend_value": 0.004726214604187993, "biggest_recent_change": 0.08353005026587823},
{"total_number_of_episodes": 18654, "number_of_timesteps": 4583769, "per_episode_reward": -38.8, "episode_reward_trend_value": 0.0044642521607173875, "biggest_recent_change": 0.08353005026587823},
{"total_number_of_episodes": 18664, "number_of_timesteps": 4586733, "per_episode_reward": -38.8, "episode_reward_trend_value": 0.0041175465397064355, "biggest_recent_change": 0.08353005026587823},
{"total_number_of_episodes": 18674, "number_of_timesteps": 4588738, "per_episode_reward": -38.76, "episode_reward_trend_value": 0.003601200364948672, "biggest_recent_change": 0.08353005026587823},
{"total_number_of_episodes": 18684, "number_of_timesteps": 4591087, "per_episode_reward": -38.71, "episode_reward_trend_value": 0.003289500874282601, "biggest_recent_change": 0.05811590844361092},
{"total_number_of_episodes": 18694, "number_of_timesteps": 4593038, "per_episode_reward": -38.67, "episode_reward_trend_value": 0.0030560348908014448, "biggest_recent_change": 0.05547709610593188},
{"total_number_of_episodes": 18704, "number_of_timesteps": 4595021, "per_episode_reward": -38.6, "episode_reward_trend_value": 0.003425639350924175, "biggest_recent_change": 0.07096779944886578},
{"total_number_of_episodes": 18714, "number_of_timesteps": 4597670, "per_episode_reward": -38.55, "episode_reward_trend_value": 0.003772251433419566, "biggest_recent_change": 0.07096779944886578},
{"total_number_of_episodes": 18724, "number_of_timesteps": 4600895, "per_episode_reward": -38.53, "episode_reward_trend_value": 0.0037283102154406027, "biggest_recent_change": 0.07096779944886578},
{"total_number_of_episodes": 18735, "number_of_timesteps": 4603820, "per_episode_reward": -38.32, "episode_reward_trend_value": 0.005696147322915045, "biggest_recent_change": 0.20562846053890382},
{"total_number_of_episodes": 18745, "number_of_timesteps": 4606588, "per_episode_reward": -38.29, "episode_reward_trend_value": 0.00570017682934826, "biggest_recent_change": 0.20562846053890382},
{"total_number_of_episodes": 18755, "number_of_timesteps": 4609003, "per_episode_reward": -38.21, "episode_reward_trend_value": 0.006527251683966126, "biggest_recent_change": 0.20562846053890382},
{"total_number_of_episodes": 18765, "number_of_timesteps": 4613976, "per_episode_reward": -38.19, "episode_reward_trend_value": 0.006379372110412934, "biggest_recent_change": 0.20562846053890382},
{"total_number_of_episodes": 18775, "number_of_timesteps": 4619057, "per_episode_reward": -38.13, "episode_reward_trend_value": 0.006373203095038112, "biggest_recent_change": 0.20562846053890382},
{"total_number_of_episodes": 18786, "number_of_timesteps": 4624003, "per_episode_reward": -38.05, "episode_reward_trend_value": 0.006884002655406915, "biggest_recent_change": 0.20562846053890382},
{"total_number_of_episodes": 18796, "number_of_timesteps": 4628947, "per_episode_reward": -37.93, "episode_reward_trend_value": 0.007443193154748684, "biggest_recent_change": 0.20562846053890382},
{"total_number_of_episodes": 18806, "number_of_timesteps": 4633552, "per_episode_reward": -37.87, "episode_reward_trend_value": 0.007630267018248954, "biggest_recent_change": 0.20562846053890382},
{"total_number_of_episodes": 18816, "number_of_timesteps": 4640498, "per_episode_reward": -37.83, "episode_reward_trend_value": 0.007732375518786622, "biggest_recent_change": 0.20562846053890382},
{"total_number_of_episodes": 18826, "number_of_timesteps": 4645787, "per_episode_reward": -37.79, "episode_reward_trend_value": 0.005957036223994865, "biggest_recent_change": 0.12129494438962496},
{"total_number_of_episodes": 18836, "number_of_timesteps": 4649586, "per_episode_reward": -37.72, "episode_reward_trend_value": 0.006313146864353235, "biggest_recent_change": 0.12129494438962496},
{"total_number_of_episodes": 18846, "number_of_timesteps": 4652558, "per_episode_reward": -37.69, "episode_reward_trend_value": 0.005744666451719145, "biggest_recent_change": 0.12129494438962496},
{"total_number_of_episodes": 18856, "number_of_timesteps": 4655457, "per_episode_reward": -37.64, "episode_reward_trend_value": 0.0061026740911076325, "biggest_recent_change": 0.12129494438962496},
{"total_number_of_episodes": 18867, "number_of_timesteps": 4659762, "per_episode_reward": -37.61, "episode_reward_trend_value": 0.005848959391627773, "biggest_recent_change": 0.12129494438962496},
{"total_number_of_episodes": 18877, "number_of_timesteps": 4662599, "per_episode_reward": -37.59, "episode_reward_trend_value": 0.005119741687076148, "biggest_recent_change": 0.12129494438962496},
{"total_number_of_episodes": 18887, "number_of_timesteps": 4665886, "per_episode_reward": -37.57, "episode_reward_trend_value": 0.004018500950719231, "biggest_recent_change": 0.06520476683533616},
{"total_number_of_episodes": 18897, "number_of_timesteps": 4670387, "per_episode_reward": -37.47, "episode_reward_trend_value": 0.004453346030606693, "biggest_recent_change": 0.10066366441704133},
{"total_number_of_episodes": 18907, "number_of_timesteps": 4675586, "per_episode_reward": -37.44, "episode_reward_trend_value": 0.004319609749903938, "biggest_recent_change": 0.10066366441704133},
{"total_number_of_episodes": 18918, "number_of_timesteps": 4679417, "per_episode_reward": -37.41, "episode_reward_trend_value": 0.004236403801390923, "biggest_recent_change": 0.10066366441704133},
{"total_number_of_episodes": 18928, "number_of_timesteps": 4682833, "per_episode_reward": -37.32, "episode_reward_trend_value": 0.004464260700889453, "biggest_recent_change": 0.10066366441704133},
{"total_number_of_episodes": 18938, "number_of_timesteps": 4688206, "per_episode_reward": -37.29, "episode_reward_trend_value": 0.004444673826296963, "biggest_recent_change": 0.10066366441704133},
{"total_number_of_episodes": 18948, "number_of_timesteps": 4691891, "per_episode_reward": -37.23, "episode_reward_trend_value": 0.004518174572021078, "biggest_recent_change": 0.10066366441704133},
{"total_number_of_episodes": 18958, "number_of_timesteps": 4696016, "per_episode_reward": -37.21, "episode_reward_trend_value": 0.004452377710363938, "biggest_recent_change": 0.10066366441704133},
{"total_number_of_episodes": 18968, "number_of_timesteps": 4699469, "per_episode_reward": -37.16, "episode_reward_trend_value": 0.00479965070401723, "biggest_recent_change": 0.10066366441704133},
{"total_number_of_episodes": 18978, "number_of_timesteps": 4702292, "per_episode_reward": -37.1, "episode_reward_trend_value": 0.005209582684714951, "biggest_recent_change": 0.10066366441704133},
{"total_number_of_episodes": 18988, "number_of_timesteps": 4704578, "per_episode_reward": -36.97, "episode_reward_trend_value": 0.0055171950123178385, "biggest_recent_change": 0.12834877390130117},
{"total_number_of_episodes": 18998, "number_of_timesteps": 4707741, "per_episode_reward": -36.89, "episode_reward_trend_value": 0.0061834326693302605, "biggest_recent_change": 0.12834877390130117},
{"total_number_of_episodes": 19008, "number_of_timesteps": 4711065, "per_episode_reward": -36.76, "episode_reward_trend_value": 0.007175585255983839, "biggest_recent_change": 0.12834877390130117},
{"total_number_of_episodes": 19018, "number_of_timesteps": 4715222, "per_episode_reward": -36.69, "episode_reward_trend_value": 0.006979368557108343, "biggest_recent_change": 0.12834877390130117},
{"total_number_of_episodes": 19028, "number_of_timesteps": 4719742, "per_episode_reward": -36.67, "episode_reward_trend_value": 0.006950382364053415, "biggest_recent_change": 0.12834877390130117},
{"total_number_of_episodes": 19038, "number_of_timesteps": 4723016, "per_episode_reward": -36.64, "episode_reward_trend_value": 0.006631059382479283, "biggest_recent_change": 0.12834877390130117},
{"total_number_of_episodes": 19048, "number_of_timesteps": 4728123, "per_episode_reward": -36.62, "episode_reward_trend_value": 0.006566058893125791, "biggest_recent_change": 0.12834877390130117},
{"total_number_of_episodes": 19058, "number_of_timesteps": 4732539, "per_episode_reward": -36.56, "episode_reward_trend_value": 0.006643203652442508, "biggest_recent_change": 0.12834877390130117},
{"total_number_of_episodes": 19068, "number_of_timesteps": 4734914, "per_episode_reward": -36.55, "episode_reward_trend_value": 0.006097416949936334, "biggest_recent_change": 0.12834877390130117},
{"total_number_of_episodes": 19078, "number_of_timesteps": 4739757, "per_episode_reward": -36.52, "episode_reward_trend_value": 0.00498045264910516, "biggest_recent_change": 0.1276531214402965},
{"total_number_of_episodes": 19088, "number_of_timesteps": 4743397, "per_episode_reward": -36.5, "episode_reward_trend_value": 0.004323856330339816, "biggest_recent_change": 0.1276531214402965},
{"total_number_of_episodes": 19098, "number_of_timesteps": 4746474, "per_episode_reward": -36.46, "episode_reward_trend_value": 0.0032777149294795373, "biggest_recent_change": 0.06805238489140919},
{"total_number_of_episodes": 19108, "number_of_timesteps": 4750618, "per_episode_reward": -36.45, "episode_reward_trend_value": 0.002736841159148816, "biggest_recent_change": 0.0556439347211537},
{"total_number_of_episodes": 19118, "number_of_timesteps": 4755170, "per_episode_reward": -36.42, "episode_reward_trend_value": 0.0027059801965821054, "biggest_recent_change": 0.0556439347211537},
{"total_number_of_episodes": 19128, "number_of_timesteps": 4758649, "per_episode_reward": -36.34, "episode_reward_trend_value": 0.003329447178406911, "biggest_recent_change": 0.08592680780418505},
{"total_number_of_episodes": 19138, "number_of_timesteps": 4762284, "per_episode_reward": -36.31, "episode_reward_trend_value": 0.0033793748232546425, "biggest_recent_change": 0.08592680780418505},
{"total_number_of_episodes": 19148, "number_of_timesteps": 4765654, "per_episode_reward": -36.28, "episode_reward_trend_value": 0.0031226780105744153, "biggest_recent_change": 0.08592680780418505},
{"total_number_of_episodes": 19158, "number_of_timesteps": 4768738, "per_episode_reward": -36.25, "episode_reward_trend_value": 0.003356785642565777, "biggest_recent_change": 0.08592680780418505},
{"total_number_of_episodes": 19168, "number_of_timesteps": 4772316, "per_episode_reward": -36.23, "episode_reward_trend_value": 0.0032930172289541795, "biggest_recent_change": 0.08592680780418505},
{"total_number_of_episodes": 19178, "number_of_timesteps": 4778428, "per_episode_reward": -36.19, "episode_reward_trend_value": 0.003401696959697079, "biggest_recent_change": 0.08592680780418505},
{"total_number_of_episodes": 19188, "number_of_timesteps": 4781154, "per_episode_reward": -36.15, "episode_reward_trend_value": 0.003462045653237232, "biggest_recent_change": 0.08592680780418505},
{"total_number_of_episodes": 19198, "number_of_timesteps": 4784322, "per_episode_reward": -36.14, "episode_reward_trend_value": 0.0034169897873456514, "biggest_recent_change": 0.08592680780418505},
{"total_number_of_episodes": 19208, "number_of_timesteps": 4787971, "per_episode_reward": -36.1, "episode_reward_trend_value": 0.003526769331964709, "biggest_recent_change": 0.08592680780418505},
{"total_number_of_episodes": 19219, "number_of_timesteps": 4790713, "per_episode_reward": -36.1, "episode_reward_trend_value": 0.002676261354256108, "biggest_recent_change": 0.038931777781485266},
{"total_number_of_episodes": 19229, "number_of_timesteps": 4794170, "per_episode_reward": -36.07, "episode_reward_trend_value": 0.002663697280885123, "biggest_recent_change": 0.038931777781485266},
{"total_number_of_episodes": 19239, "number_of_timesteps": 4798889, "per_episode_reward": -36.03, "episode_reward_trend_value": 0.00273821591105098, "biggest_recent_change": 0.039247898294860306},
{"total_number_of_episodes": 19249, "number_of_timesteps": 4800773, "per_episode_reward": -35.91, "episode_reward_trend_value": 0.0037944634463387044, "biggest_recent_change": 0.12608831820985955},
{"total_number_of_episodes": 19259, "number_of_timesteps": 4803745, "per_episode_reward": -35.9, "episode_reward_trend_value": 0.003654894118510773, "biggest_recent_change": 0.12608831820985955},
{"total_number_of_episodes": 19269, "number_of_timesteps": 4807975, "per_episode_reward": -35.87, "episode_reward_trend_value": 0.0036175249288151667, "biggest_recent_change": 0.12608831820985955},
{"total_number_of_episodes": 19279, "number_of_timesteps": 4814461, "per_episode_reward": -35.86, "episode_reward_trend_value": 0.0032596869454185337, "biggest_recent_change": 0.12608831820985955},
{"total_number_of_episodes": 19289, "number_of_timesteps": 4816625, "per_episode_reward": -35.81, "episode_reward_trend_value": 0.0036968112837173174, "biggest_recent_change": 0.12608831820985955},
{"total_number_of_episodes": 19299, "number_of_timesteps": 4821132, "per_episode_reward": -35.75, "episode_reward_trend_value": 0.0039661078992558095, "biggest_recent_change": 0.12608831820985955},
{"total_number_of_episodes": 19309, "number_of_timesteps": 4824654, "per_episode_reward": -35.69, "episode_reward_trend_value": 0.004556783333455883, "biggest_recent_change": 0.12608831820985955},
{"total_number_of_episodes": 19319, "number_of_timesteps": 4828793, "per_episode_reward": -35.65, "episode_reward_trend_value": 0.004647667041700663, "biggest_recent_change": 0.12608831820985955},
{"total_number_of_episodes": 19329, "number_of_timesteps": 4832899, "per_episode_reward": -35.63, "episode_reward_trend_value": 0.004526421732832139, "biggest_recent_change": 0.12608831820985955},
{"total_number_of_episodes": 19339, "number_of_timesteps": 4836930, "per_episode_reward": -35.56, "episode_reward_trend_value": 0.003876666836857999, "biggest_recent_change": 0.06761037757218702},
{"total_number_of_episodes": 19349, "number_of_timesteps": 4839578, "per_episode_reward": -35.52, "episode_reward_trend_value": 0.004193841694464831, "biggest_recent_change": 0.06761037757218702},
{"total_number_of_episodes": 19359, "number_of_timesteps": 4842094, "per_episode_reward": -35.42, "episode_reward_trend_value": 0.00499764537000868, "biggest_recent_change": 0.10268890692199761},
{"total_number_of_episodes": 19370, "number_of_timesteps": 4844188, "per_episode_reward": -35.37, "episode_reward_trend_value": 0.005458524556051161, "biggest_recent_change": 0.10268890692199761},
{"total_number_of_episodes": 19380, "number_of_timesteps": 4846227, "per_episode_reward": -35.32, "episode_reward_trend_value": 0.00536004043912865, "biggest_recent_change": 0.10268890692199761},
{"total_number_of_episodes": 19390, "number_of_timesteps": 4849573, "per_episode_reward": -35.26, "episode_reward_trend_value": 0.005412016306035462, "biggest_recent_change": 0.10268890692199761},
{"total_number_of_episodes": 19401, "number_of_timesteps": 4852840, "per_episode_reward": -35.24, "episode_reward_trend_value": 0.004927074182343776, "biggest_recent_change": 0.10268890692199761},
{"total_number_of_episodes": 19411, "number_of_timesteps": 4857422, "per_episode_reward": -35.2, "episode_reward_trend_value": 0.00500731898160609, "biggest_recent_change": 0.10268890692199761},
{"total_number_of_episodes": 19421, "number_of_timesteps": 4860431, "per_episode_reward": -35.14, "episode_reward_trend_value": 0.005348361469054671, "biggest_recent_change": 0.10268890692199761},
{"total_number_of_episodes": 19431, "number_of_timesteps": 4863745, "per_episode_reward": -35.09, "episode_reward_trend_value": 0.005184020942447631, "biggest_recent_change": 0.10268890692199761},
{"total_number_of_episodes": 19441, "number_of_timesteps": 4865970, "per_episode_reward": -35.07, "episode_reward_trend_value": 0.005000873034191026, "biggest_recent_change": 0.10268890692199761},
{"total_number_of_episodes": 19451, "number_of_timesteps": 4868733, "per_episode_reward": -35.0, "episode_reward_trend_value": 0.00465065122162645, "biggest_recent_change": 0.07116894379118577},
{"total_number_of_episodes": 19461, "number_of_timesteps": 4870713, "per_episode_reward": -34.91, "episode_reward_trend_value": 0.0051044830120201504, "biggest_recent_change": 0.08905034715504456},
{"total_number_of_episodes": 19471, "number_of_timesteps": 4874742, "per_episode_reward": -34.83, "episode_reward_trend_value": 0.005523913631393245, "biggest_recent_change": 0.08905034715504456},
{"total_number_of_episodes": 19481, "number_of_timesteps": 4877850, "per_episode_reward": -34.77, "episode_reward_trend_value": 0.005433366544912843, "biggest_recent_change": 0.08905034715504456},
{"total_number_of_episodes": 19491, "number_of_timesteps": 4880085, "per_episode_reward": -34.73, "episode_reward_trend_value": 0.005670646871604627, "biggest_recent_change": 0.08905034715504456},
{"total_number_of_episodes": 19501, "number_of_timesteps": 4883142, "per_episode_reward": -34.6, "episode_reward_trend_value": 0.006649684009674752, "biggest_recent_change": 0.1271934297129107},
{"total_number_of_episodes": 19511, "number_of_timesteps": 4885240, "per_episode_reward": -34.56, "episode_reward_trend_value": 0.006488008102890635, "biggest_recent_change": 0.1271934297129107},
{"total_number_of_episodes": 19521, "number_of_timesteps": 4887875, "per_episode_reward": -34.49, "episode_reward_trend_value": 0.006687193160967869, "biggest_recent_change": 0.1271934297129107},
{"total_number_of_episodes": 19531, "number_of_timesteps": 4889949, "per_episode_reward": -34.46, "episode_reward_trend_value": 0.006743240857385441, "biggest_recent_change": 0.1271934297129107},
{"total_number_of_episodes": 19541, "number_of_timesteps": 4892418, "per_episode_reward": -34.4, "episode_reward_trend_value": 0.006609304258820477, "biggest_recent_change": 0.1271934297129107},
{"total_number_of_episodes": 19552, "number_of_timesteps": 4895363, "per_episode_reward": -34.35, "episode_reward_trend_value": 0.00624378911535604, "biggest_recent_change": 0.1271934297129107},
{"total_number_of_episodes": 19562, "number_of_timesteps": 4897726, "per_episode_reward": -34.29, "episode_reward_trend_value": 0.006003091128397387, "biggest_recent_change": 0.1271934297129107},
{"total_number_of_episodes": 19572, "number_of_timesteps": 4899521, "per_episode_reward": -34.23, "episode_reward_trend_value": 0.0059853061936758125, "biggest_recent_change": 0.1271934297129107},
{"total_number_of_episodes": 19582, "number_of_timesteps": 4901109, "per_episode_reward": -34.2, "episode_reward_trend_value": 0.00586938501428441, "biggest_recent_change": 0.1271934297129107},
{"total_number_of_episodes": 19592, "number_of_timesteps": 4904616, "per_episode_reward": -34.16, "episode_reward_trend_value": 0.004976134140317849, "biggest_recent_change": 0.07074638540450451},
{"total_number_of_episodes": 19602, "number_of_timesteps": 4907229, "per_episode_reward": -34.14, "episode_reward_trend_value": 0.0046153972655743145, "biggest_recent_change": 0.07074638540450451},
{"total_number_of_episodes": 19612, "number_of_timesteps": 4909793, "per_episode_reward": -34.1, "episode_reward_trend_value": 0.004294807162673603, "biggest_recent_change": 0.06188227447256622},
{"total_number_of_episodes": 19622, "number_of_timesteps": 4911881, "per_episode_reward": -34.06, "episode_reward_trend_value": 0.004446709180896767, "biggest_recent_change": 0.06188227447256622},
{"total_number_of_episodes": 19632, "number_of_timesteps": 4914873, "per_episode_reward": -34.01, "episode_reward_trend_value": 0.004395125319272273, "biggest_recent_change": 0.06188227447256622},
{"total_number_of_episodes": 19642, "number_of_timesteps": 4919336, "per_episode_reward": -33.9, "episode_reward_trend_value": 0.005003590593094663, "biggest_recent_change": 0.1109158588872603},
{"total_number_of_episodes": 19652, "number_of_timesteps": 4922146, "per_episode_reward": -33.83, "episode_reward_trend_value": 0.005078572602039265, "biggest_recent_change": 0.1109158588872603},
{"total_number_of_episodes": 19662, "number_of_timesteps": 4924617, "per_episode_reward": -33.78, "episode_reward_trend_value": 0.004981130815705686, "biggest_recent_change": 0.1109158588872603},
{"total_number_of_episodes": 19672, "number_of_timesteps": 4927658, "per_episode_reward": -33.76, "episode_reward_trend_value": 0.004873009072053946, "biggest_recent_change": 0.1109158588872603},
{"total_number_of_episodes": 19682, "number_of_timesteps": 4932017, "per_episode_reward": -33.74, "episode_reward_trend_value": 0.0046362368731635685, "biggest_recent_change": 0.1109158588872603},
{"total_number_of_episodes": 19692, "number_of_timesteps": 4936134, "per_episode_reward": -33.7, "episode_reward_trend_value": 0.004949470535684321, "biggest_recent_change": 0.1109158588872603},
{"total_number_of_episodes": 19702, "number_of_timesteps": 4940945, "per_episode_reward": -33.69, "episode_reward_trend_value": 0.004584288307071994, "biggest_recent_change": 0.1109158588872603},
{"total_number_of_episodes": 19712, "number_of_timesteps": 4943322, "per_episode_reward": -33.65, "episode_reward_trend_value": 0.004603823115280411, "biggest_recent_change": 0.1109158588872603},
{"total_number_of_episodes": 19722, "number_of_timesteps": 4946636, "per_episode_reward": -33.62, "episode_reward_trend_value": 0.004286676633460078, "biggest_recent_change": 0.1109158588872603},
{"total_number_of_episodes": 19732, "number_of_timesteps": 4949484, "per_episode_reward": -33.54, "episode_reward_trend_value": 0.003988572668340298, "biggest_recent_change": 0.08408650202648005},
{"total_number_of_episodes": 19742, "number_of_timesteps": 4951671, "per_episode_reward": -33.45, "episode_reward_trend_value": 0.004189864682048968, "biggest_recent_change": 0.08674693651136067},
{"total_number_of_episodes": 19752, "number_of_timesteps": 4954955, "per_episode_reward": -33.42, "episode_reward_trend_value": 0.004096500418923515, "biggest_recent_change": 0.08674693651136067},
{"total_number_of_episodes": 19762, "number_of_timesteps": 4958944, "per_episode_reward": -33.38, "episode_reward_trend_value": 0.004268971055206489, "biggest_recent_change": 0.08674693651136067},
{"total_number_of_episodes": 19772, "number_of_timesteps": 4962754, "per_episode_reward": -33.26, "episode_reward_trend_value": 0.005337889199741616, "biggest_recent_change": 0.12169398616394744},
{"total_number_of_episodes": 19783, "number_of_timesteps": 4966913, "per_episode_reward": -33.2, "episode_reward_trend_value": 0.005490263993081928, "biggest_recent_change": 0.12169398616394744},
{"total_number_of_episodes": 19793, "number_of_timesteps": 4971432, "per_episode_reward": -33.09, "episode_reward_trend_value": 0.006707456305316287, "biggest_recent_change": 0.12169398616394744},
{"total_number_of_episodes": 19803, "number_of_timesteps": 4976167, "per_episode_reward": -33.0, "episode_reward_trend_value": 0.007252606590655672, "biggest_recent_change": 0.12169398616394744},
{"total_number_of_episodes": 19813, "number_of_timesteps": 4977828, "per_episode_reward": -32.89, "episode_reward_trend_value": 0.008152207092986983, "biggest_recent_change": 0.12169398616394744},
{"total_number_of_episodes": 19824, "number_of_timesteps": 4980428, "per_episode_reward": -32.77, "episode_reward_trend_value": 0.008578155449631532, "biggest_recent_change": 0.12242185412448947},
{"total_number_of_episodes": 19834, "number_of_timesteps": 4983405, "per_episode_reward": -32.67, "episode_reward_trend_value": 0.008660630450664463, "biggest_recent_change": 0.12242185412448947},
{"total_number_of_episodes": 19844, "number_of_timesteps": 4986350, "per_episode_reward": -32.6, "episode_reward_trend_value": 0.009121168593979689, "biggest_recent_change": 0.12242185412448947},
{"total_number_of_episodes": 19854, "number_of_timesteps": 4988503, "per_episode_reward": -32.52, "episode_reward_trend_value": 0.009532247576196874, "biggest_recent_change": 0.12242185412448947},
{"total_number_of_episodes": 19864, "number_of_timesteps": 4991078, "per_episode_reward": -32.46, "episode_reward_trend_value": 0.008860142693543021, "biggest_recent_change": 0.12242185412448947},
{"total_number_of_episodes": 19874, "number_of_timesteps": 4993114, "per_episode_reward": -32.43, "episode_reward_trend_value": 0.008620882450541718, "biggest_recent_change": 0.12242185412448947},
{"total_number_of_episodes": 19884, "number_of_timesteps": 4995212, "per_episode_reward": -32.4, "episode_reward_trend_value": 0.007602400734665021, "biggest_recent_change": 0.12242185412448947},
{"total_number_of_episodes": 19894, "number_of_timesteps": 4998604, "per_episode_reward": -32.37, "episode_reward_trend_value": 0.006947155153465919, "biggest_recent_change": 0.12242185412448947},
{"total_number_of_episodes": 19904, "number_of_timesteps": 5001154, "per_episode_reward": -32.3, "episode_reward_trend_value": 0.006554726664979348, "biggest_recent_change": 0.12242185412448947},
{"total_number_of_episodes": 19914, "number_of_timesteps": 5003766, "per_episode_reward": -32.25, "episode_reward_trend_value": 0.005750690080474246, "biggest_recent_change": 0.09416968660432445},
{"total_number_of_episodes": 19924, "number_of_timesteps": 5007261, "per_episode_reward": -32.2, "episode_reward_trend_value": 0.005237552878462913, "biggest_recent_change": 0.07650328399335393},
{"total_number_of_episodes": 19934, "number_of_timesteps": 5009010, "per_episode_reward": -32.18, "episode_reward_trend_value": 0.004644415049896366, "biggest_recent_change": 0.07260791974955794},
{"total_number_of_episodes": 19944, "number_of_timesteps": 5010666, "per_episode_reward": -32.15, "episode_reward_trend_value": 0.004143574868458128, "biggest_recent_change": 0.07157440025633122},
{"total_number_of_episodes": 19954, "number_of_timesteps": 5013361, "per_episode_reward": -32.13, "episode_reward_trend_value": 0.00369417539526356, "biggest_recent_change": 0.07157440025633122},
{"total_number_of_episodes": 19964, "number_of_timesteps": 5015043, "per_episode_reward": -32.09, "episode_reward_trend_value": 0.0037976707345376013, "biggest_recent_change": 0.07157440025633122},
{"total_number_of_episodes": 19974, "number_of_timesteps": 5016732, "per_episode_reward": -32.05, "episode_reward_trend_value": 0.003865091969941719, "biggest_recent_change": 0.07157440025633122},
{"total_number_of_episodes": 19984, "number_of_timesteps": 5019212, "per_episode_reward": -32.03, "episode_reward_trend_value": 0.003821214939395566, "biggest_recent_change": 0.07157440025633122},
{"total_number_of_episodes": 19995, "number_of_timesteps": 5020649, "per_episode_reward": -31.95, "episode_reward_trend_value": 0.003826382182145159, "biggest_recent_change": 0.07203945210379459},
{"total_number_of_episodes": 20005, "number_of_timesteps": 5022262, "per_episode_reward": -31.92, "episode_reward_trend_value": 0.0036269460274748074, "biggest_recent_change": 0.07203945210379459},
{"total_number_of_episodes": 20015, "number_of_timesteps": 5024947, "per_episode_reward": -31.88, "episode_reward_trend_value": 0.0035409791687849275, "biggest_recent_change": 0.07203945210379459},
{"total_number_of_episodes": 20025, "number_of_timesteps": 5026443, "per_episode_reward": -31.86, "episode_reward_trend_value": 0.0035352376271073163, "biggest_recent_change": 0.07203945210379459},
{"total_number_of_episodes": 20036, "number_of_timesteps": 5028373, "per_episode_reward": -31.74, "episode_reward_trend_value": 0.004542766586482551, "biggest_recent_change": 0.11820990976388757},
{"total_number_of_episodes": 20047, "number_of_timesteps": 5032778, "per_episode_reward": -31.72, "episode_reward_trend_value": 0.004564821943093141, "biggest_recent_change": 0.11820990976388757},
{"total_number_of_episodes": 20057, "number_of_timesteps": 5035109, "per_episode_reward": -31.69, "episode_reward_trend_value": 0.004405555589490125, "biggest_recent_change": 0.11820990976388757},
{"total_number_of_episodes": 20068, "number_of_timesteps": 5037070, "per_episode_reward": -31.67, "episode_reward_trend_value": 0.0042504219925527074, "biggest_recent_change": 0.11820990976388757},
{"total_number_of_episodes": 20078, "number_of_timesteps": 5038811, "per_episode_reward": -31.63, "episode_reward_trend_value": 0.004393785476297848, "biggest_recent_change": 0.11820990976388757},
{"total_number_of_episodes": 20088, "number_of_timesteps": 5040806, "per_episode_reward": -31.6, "episode_reward_trend_value": 0.0039507652785485525, "biggest_recent_change": 0.11820990976388757},
{"total_number_of_episodes": 20098, "number_of_timesteps": 5042239, "per_episode_reward": -31.53, "episode_reward_trend_value": 0.004337677677012408, "biggest_recent_change": 0.11820990976388757},
{"total_number_of_episodes": 20108, "number_of_timesteps": 5043901, "per_episode_reward": -31.46, "episode_reward_trend_value": 0.004674538214556318, "biggest_recent_change": 0.11820990976388757},
{"total_number_of_episodes": 20118, "number_of_timesteps": 5045955, "per_episode_reward": -31.41, "episode_reward_trend_value": 0.004943588609830445, "biggest_recent_change": 0.11820990976388757},
{"total_number_of_episodes": 20129, "number_of_timesteps": 5047982, "per_episode_reward": -31.36, "episode_reward_trend_value": 0.004275252381562409, "biggest_recent_change": 0.07056776952016719},
{"total_number_of_episodes": 20139, "number_of_timesteps": 5050335, "per_episode_reward": -31.33, "episode_reward_trend_value": 0.004271859434574705, "biggest_recent_change": 0.07056776952016719},
{"total_number_of_episodes": 20149, "number_of_timesteps": 5052789, "per_episode_reward": -31.29, "episode_reward_trend_value": 0.00445180055179281, "biggest_recent_change": 0.07056776952016719},
{"total_number_of_episodes": 20159, "number_of_timesteps": 5056044, "per_episode_reward": -31.19, "episode_reward_trend_value": 0.005389169996562594, "biggest_recent_change": 0.10337996673180427},
{"total_number_of_episodes": 20169, "number_of_timesteps": 5059116, "per_episode_reward": -31.12, "episode_reward_trend_value": 0.0056464368167763405, "biggest_recent_change": 0.10337996673180427},
{"total_number_of_episodes": 20179, "number_of_timesteps": 5061530, "per_episode_reward": -31.07, "episode_reward_trend_value": 0.005903284341975261, "biggest_recent_change": 0.10337996673180427},
{"total_number_of_episodes": 20189, "number_of_timesteps": 5063793, "per_episode_reward": -31.05, "episode_reward_trend_value": 0.005359503710283025, "biggest_recent_change": 0.10337996673180427},
