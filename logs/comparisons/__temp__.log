config = {
    "evaluation": {
        "enabled": True, 
        "number_of_episodes_before_eval": 130, 
        "number_of_epsiodes_during_eval": 10, 
        "final_eval": {
            "number_of_steps": 125000, 
            "number_of_episodes": None, 
        }, 
    }, 
    "verbose": True, 
    "number_of_processes": 10, 
    "number_of_malicious_processes": 3, 
    "expected_number_of_malicious_processes": 3, 
    "logarithmic_scale_reference": {
        0: 0.1, 
        1: 0.08, 
        2: 0.063, 
        3: 0.05, 
        4: 0.04, 
        5: 0.032, 
        6: 0.025, 
        7: 0.02, 
        8: 0.016, 
        9: 0.012, 
        10: 0.01, 
        11: 0.008, 
        12: 0.0063, 
        13: 0.005, 
        14: 0.004, 
        15: 0.0032, 
        16: 0.0025, 
        17: 0.002, 
        18: 0.0016, 
        19: 0.0012, 
        20: 0.001, 
        21: 0.0008, 
        22: 0.00063, 
        23: 0.0005, 
        24: 0.0004, 
        25: 0.00032, 
        26: 0.00025, 
        27: 0.0002, 
        28: 0.00016, 
        29: 0.00012, 
        30: 1e-05, 
        31: 8e-06, 
        32: 6.3e-06, 
        33: 5e-06, 
        34: 4e-06, 
        35: 3.2e-06, 
        36: 2.5e-06, 
        37: 2e-06, 
        38: 1.6e-06, 
        39: 1.2e-06, 
    }, 
    "attack_method": "sign", 
    "use_frozen_random_seed": False, 
    "random_seeds": {0: 0, }, 
    "value_trend_lookback_size": 10, 
    "early_stopping": {
        "lowerbound_for_max_recent_change": 0, 
        "min_number_of_episodes": 30, 
        "thresholds": {}, 
    }, 
    "tuning": {
        "number_of_trials": 300, 
        "phase_1": {
            "categorical_options": {"activation": {0: 0, 1: 1, 2: 2, }, }, 
            "sequential_options": {
                "t_max": {0: 3, 1: 5, 2: 10, 3: 20, 4: 30, 5: 50, }, 
                "hidden_size": {0: 16, 1: 32, 2: 64, 3: 128, }, 
                "learning_rate": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
                "beta": {
                    0: 0.1, 
                    1: 0.08, 
                    2: 0.063, 
                    3: 0.05, 
                    4: 0.04, 
                    5: 0.032, 
                    6: 0.025, 
                    7: 0.02, 
                    8: 0.016, 
                    9: 0.012, 
                    10: 0.01, 
                    11: 0.008, 
                    12: 0.0063, 
                    13: 0.005, 
                    14: 0.004, 
                    15: 0.0032, 
                    16: 0.0025, 
                    17: 0.002, 
                    18: 0.0016, 
                    19: 0.0012, 
                    20: 0.001, 
                    21: 0.0008, 
                    22: 0.00063, 
                    23: 0.0005, 
                    24: 0.0004, 
                    25: 0.00032, 
                    26: 0.00025, 
                    27: 0.0002, 
                    28: 0.00016, 
                    29: 0.00012, 
                    30: 1e-05, 
                    31: 8e-06, 
                    32: 6.3e-06, 
                    33: 5e-06, 
                    34: 4e-06, 
                    35: 3.2e-06, 
                    36: 2.5e-06, 
                    37: 2e-06, 
                    38: 1.6e-06, 
                    39: 1.2e-06, 
                }, 
            }, 
            "sequential_exponential_options": {
                "learning_rate": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
                "beta": {
                    "base": {0: 1, 1: 3, 2: 5, 3: 7, 4: 9, }, 
                    "exponent": {
                        0: -1, 
                        1: -2, 
                        2: -3, 
                        3: -4, 
                        4: -5, 
                        5: -6, 
                        6: -7, 
                        7: -8, 
                    }, 
                }, 
            }, 
        }, 
    }, 
    "training": {"episode_count": 21000, }, 
    "env_config": {
        "env_name": "CartPole-v1", 
        "learning_rate": 0.001, 
        "beta": 2e-05, 
        "t_max": 5, 
        "activation": 1, 
        "hidden_size": 64, 
        "permaban_threshold": 500, 
        "variance_scaling_factor": 1, 
    }, 
}
args = {
    "processes": 10, 
    "env": "CartPole-v1", 
    "seed": 3011416527, 
    "outdir": "results", 
    "t_max": 5, 
    "beta": 2e-05, 
    "profile": False, 
    "steps": 21000, 
    "max_frames": (108000, ), 
    "lr": 0.001, 
    "demo": False, 
    "load_pretrained": False, 
    "pretrained_type": "best", 
    "load": "", 
    "log_level": 20, 
    "render": False, 
    "monitor": False, 
    "permaban_threshold": 500, 
    "malicious": 3, 
    "mal_type": "sign", 
    "rew_scale": 1.0, 
    "hidden_size": 64, 
    "activation": 1, 
}
[starting train_a3c()]
[starting train_agent_async()]
[about to call async_.run_async()]
[starting run_func()]
[starting train_loop()]
Step 0 0 visits [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]Step 1 0 visits [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 0 q_vals: [-2.64, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]Step 2 1 visits [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 1 q_vals: [-2.64, -4.681, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]Step 3 2 visits [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 4 q_vals: [-2.64, -4.681, -9.762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]Step 4 3 visits [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 7 q_vals: [-2.64, -4.681, -9.762, -4.388, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]Step 5 4 visits [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 8 q_vals: [-2.64, -4.681, -9.762, -4.388, -7.369, 0.0, 0.0, 0.0, 0.0, 0.0]Step 6 5 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 10 q_vals: [-2.64, -4.681, -9.762, -4.388, -7.369, -7.512, 0.0, 0.0, 0.0, 0.0]Step 7 6 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 12 q_vals: [-2.64, -4.681, -9.762, -4.388, -7.369, -7.512, -8.206, 0.0, 0.0, 0.0]Step 8 7 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 14 q_vals: [-2.64, -4.681, -9.762, -4.388, -7.369, -7.512, -8.206, -2.646, 0.0, 0.0]Step 9 8 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 15 q_vals: [-2.64, -4.681, -9.762, -4.388, -7.369, -7.512, -8.206, -2.646, -4.083, 0.0]Step 10 9 visits [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 15 q_vals: [-2.64, -4.681, -9.762, -4.388, -7.369, -7.512, -8.206, -2.646, -4.083, -7.387]Step 11 0 visits [2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 18 q_vals: [-1.32, -4.681, -9.762, -4.388, -7.369, -7.512, -8.206, -2.646, -4.083, -7.387]Step 12 0 visits [3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 20 q_vals: [-1.815, -4.681, -9.762, -4.388, -7.369, -7.512, -8.206, -2.646, -4.083, -7.387]Step 13 0 visits [4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 22 q_vals: [-3.694, -4.681, -9.762, -4.388, -7.369, -7.512, -8.206, -2.646, -4.083, -7.387]Step 14 7 visits [4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0]  episode_count: 23 q_vals: [-3.694, -4.681, -9.762, -4.388, -7.369, -7.512, -8.206, -3.146, -4.083, -7.387]Step 15 7 visits [4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0]  episode_count: 25 q_vals: [-3.694, -4.681, -9.762, -4.388, -7.369, -7.512, -8.206, -4.696, -4.083, -7.387]Step 16 8 visits [4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0]  episode_count: 29 q_vals: [-3.694, -4.681, -9.762, -4.388, -7.369, -7.512, -8.206, -4.696, -4.012, -7.387]{"total_number_of_episodes": 31, "number_of_timesteps": 655, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": NaN},
Step 17 3 visits [4.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0]  episode_count: 31 q_vals: [-3.694, -4.681, -9.762, -3.696, -7.369, -7.512, -8.206, -4.696, -4.012, -7.387]Step 18 3 visits [4.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0]  episode_count: 33 q_vals: [-3.694, -4.681, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -4.012, -7.387]Step 19 8 visits [4.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 34 q_vals: [-3.694, -4.681, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 20 0 visits [5.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 40 q_vals: [-4.009, -4.681, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]{"total_number_of_episodes": 41, "number_of_timesteps": 886, "per_episode_reward": 22.25, "episode_reward_trend_value": 0.20500000000000007, "biggest_recent_change": NaN},
Step 21 1 visits [5.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 41 q_vals: [-4.009, -3.682, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 22 1 visits [5.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 43 q_vals: [-4.009, -3.624, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 23 1 visits [5.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 47 q_vals: [-4.009, -3.402, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 24 1 visits [5.0, 5.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 49 q_vals: [-4.009, -3.261, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]{"total_number_of_episodes": 51, "number_of_timesteps": 1067, "per_episode_reward": 19.65, "episode_reward_trend_value": -0.027500000000000035, "biggest_recent_change": NaN},
Step 25 1 visits [5.0, 6.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 51 q_vals: [-4.009, -3.216, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 26 1 visits [5.0, 7.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 52 q_vals: [-4.009, -3.211, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 27 1 visits [5.0, 8.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 54 q_vals: [-4.009, -3.236, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 28 1 visits [5.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 56 q_vals: [-4.009, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 29 0 visits [6.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 59 q_vals: [-3.95, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]{"total_number_of_episodes": 61, "number_of_timesteps": 1269, "per_episode_reward": 19.0, "episode_reward_trend_value": -0.03999999999999997, "biggest_recent_change": NaN},
Step 30 0 visits [7.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 61 q_vals: [-3.825, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 31 0 visits [8.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 64 q_vals: [-3.676, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 32 0 visits [9.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 66 q_vals: [-3.605, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 33 0 visits [10.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 68 q_vals: [-3.245, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 34 0 visits [11.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 70 q_vals: [-3.642, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]{"total_number_of_episodes": 74, "number_of_timesteps": 1519, "per_episode_reward": 18.6, "episode_reward_trend_value": -0.039999999999999945, "biggest_recent_change": NaN},
Step 35 0 visits [12.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 74 q_vals: [-3.603, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 36 0 visits [13.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 76 q_vals: [-3.525, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 37 0 visits [14.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 76 q_vals: [-3.565, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 38 0 visits [15.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 81 q_vals: [-3.501, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 39 0 visits [16.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 82 q_vals: [-3.282, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]{"total_number_of_episodes": 84, "number_of_timesteps": 1720, "per_episode_reward": 18.5, "episode_reward_trend_value": -0.03399999999999999, "biggest_recent_change": NaN},
Step 40 0 visits [17.0, 9.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 84 q_vals: [-3.821, -3.887, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 41 1 visits [17.0, 10.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 87 q_vals: [-3.821, -3.77, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 42 1 visits [17.0, 11.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 88 q_vals: [-3.821, -3.688, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 43 1 visits [17.0, 12.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 89 q_vals: [-3.821, -3.617, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 44 1 visits [17.0, 13.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 93 q_vals: [-3.821, -3.383, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]{"total_number_of_episodes": 95, "number_of_timesteps": 1928, "per_episode_reward": 18.55, "episode_reward_trend_value": -0.027499999999999976, "biggest_recent_change": NaN},
Step 45 1 visits [17.0, 14.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 95 q_vals: [-3.821, -3.372, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 46 1 visits [17.0, 15.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 96 q_vals: [-3.821, -3.977, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 47 0 visits [18.0, 15.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 98 q_vals: [-3.795, -3.977, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 48 0 visits [19.0, 15.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 100 q_vals: [-4.055, -3.977, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 49 1 visits [19.0, 16.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 102 q_vals: [-4.055, -3.901, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]{"total_number_of_episodes": 106, "number_of_timesteps": 2197, "per_episode_reward": 18.7, "episode_reward_trend_value": -0.02142857142857143, "biggest_recent_change": NaN},
Step 50 1 visits [19.0, 17.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 106 q_vals: [-4.055, -3.966, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 51 1 visits [19.0, 18.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 108 q_vals: [-4.055, -3.895, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 52 1 visits [19.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0]  episode_count: 112 q_vals: [-4.055, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.696, -6.649, -7.387]Step 53 7 visits [19.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0]  episode_count: 115 q_vals: [-4.055, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.207, -6.649, -7.387]{"total_number_of_episodes": 117, "number_of_timesteps": 2386, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.02437499999999999, "biggest_recent_change": NaN},
Step 54 7 visits [19.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 5.0, 3.0, 1.0]  episode_count: 117 q_vals: [-4.055, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -3.98, -6.649, -7.387]Step 55 7 visits [19.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 117 q_vals: [-4.055, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 56 0 visits [20.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 119 q_vals: [-3.999, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 57 0 visits [21.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 121 q_vals: [-3.809, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 58 0 visits [22.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 122 q_vals: [-3.778, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 59 0 visits [23.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 124 q_vals: [-3.764, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]{"total_number_of_episodes": 127, "number_of_timesteps": 2609, "per_episode_reward": 18.1, "episode_reward_trend_value": -0.02333333333333331, "biggest_recent_change": 2.6000000000000014},
Step 60 0 visits [24.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 127 q_vals: [-4.141, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 61 0 visits [25.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 129 q_vals: [-4.175, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 62 0 visits [26.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 132 q_vals: [-4.159, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 63 0 visits [27.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 135 q_vals: [-4.122, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 64 0 visits [28.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 135 q_vals: [-3.975, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]{"total_number_of_episodes": 137, "number_of_timesteps": 2826, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.04722222222222222, "biggest_recent_change": 2.6000000000000014},
Step 65 0 visits [29.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 137 q_vals: [-4.112, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 66 0 visits [30.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 139 q_vals: [-3.975, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 67 0 visits [31.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 141 q_vals: [-3.946, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 68 0 visits [32.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 143 q_vals: [-3.823, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 69 0 visits [33.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 145 q_vals: [-3.826, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]{"total_number_of_episodes": 151, "number_of_timesteps": 3143, "per_episode_reward": 18.65, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.6499999999999986},
Step 70 0 visits [34.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 151 q_vals: [-3.714, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 71 0 visits [35.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 152 q_vals: [-3.816, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 72 0 visits [36.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 153 q_vals: [-3.812, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 73 0 visits [37.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 155 q_vals: [-3.905, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 74 0 visits [38.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 159 q_vals: [-3.895, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 75 0 visits [39.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 160 q_vals: [-3.869, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 76 0 visits [40.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 160 q_vals: [-3.821, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]{"total_number_of_episodes": 165, "number_of_timesteps": 3428, "per_episode_reward": 18.35, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.6499999999999986},
Step 77 0 visits [41.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 165 q_vals: [-3.802, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 78 0 visits [42.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 168 q_vals: [-3.809, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 79 0 visits [43.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 169 q_vals: [-3.973, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 80 0 visits [44.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 169 q_vals: [-3.959, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 81 0 visits [45.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 174 q_vals: [-3.953, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 82 0 visits [46.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 174 q_vals: [-4.041, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]Step 83 0 visits [47.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 6.0, 3.0, 1.0]  episode_count: 174 q_vals: [-4.127, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.609, -6.649, -7.387]{"total_number_of_episodes": 178, "number_of_timesteps": 3710, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.6499999999999986},
Step 84 7 visits [47.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 7.0, 3.0, 1.0]  episode_count: 178 q_vals: [-4.127, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -3.951, -6.649, -7.387]Step 85 7 visits [47.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 8.0, 3.0, 1.0]  episode_count: 179 q_vals: [-4.127, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -3.873, -6.649, -7.387]Step 86 7 visits [47.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 9.0, 3.0, 1.0]  episode_count: 181 q_vals: [-4.127, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -3.805, -6.649, -7.387]Step 87 7 visits [47.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 10.0, 3.0, 1.0]  episode_count: 183 q_vals: [-4.127, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -3.551, -6.649, -7.387]Step 88 7 visits [47.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 11.0, 3.0, 1.0]  episode_count: 186 q_vals: [-4.127, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.105, -6.649, -7.387]{"total_number_of_episodes": 188, "number_of_timesteps": 3958, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.6499999999999986},
Step 89 7 visits [47.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 12.0, 3.0, 1.0]  episode_count: 188 q_vals: [-4.127, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.051, -6.649, -7.387]Step 90 7 visits [47.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 13.0, 3.0, 1.0]  episode_count: 191 q_vals: [-4.127, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -3.991, -6.649, -7.387]Step 91 7 visits [47.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 14.0, 3.0, 1.0]  episode_count: 193 q_vals: [-4.127, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.239, -6.649, -7.387]Step 92 7 visits [47.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 196 q_vals: [-4.127, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]{"total_number_of_episodes": 198, "number_of_timesteps": 4128, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.6499999999999986},
Step 93 0 visits [48.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 198 q_vals: [-4.098, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 94 0 visits [49.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 200 q_vals: [-4.129, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 95 0 visits [50.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 203 q_vals: [-4.047, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 96 0 visits [51.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 204 q_vals: [-4.132, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 97 0 visits [52.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 204 q_vals: [-4.053, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]{"total_number_of_episodes": 208, "number_of_timesteps": 4308, "per_episode_reward": 18.3, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.6499999999999986},
Step 98 0 visits [53.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 208 q_vals: [-4.058, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 99 0 visits [54.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 209 q_vals: [-4.047, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 100 0 visits [55.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 210 q_vals: [-4.038, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 101 0 visits [56.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 214 q_vals: [-4.111, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 102 0 visits [57.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 214 q_vals: [-4.115, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 103 0 visits [58.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 217 q_vals: [-4.099, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]{"total_number_of_episodes": 219, "number_of_timesteps": 4599, "per_episode_reward": 18.25, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.6499999999999986},
Step 104 0 visits [59.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 219 q_vals: [-4.029, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 105 0 visits [60.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 221 q_vals: [-4.018, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 106 0 visits [61.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 223 q_vals: [-4.009, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 107 0 visits [62.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 227 q_vals: [-4.096, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]{"total_number_of_episodes": 229, "number_of_timesteps": 4840, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.6499999999999986},
Step 108 0 visits [63.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 15.0, 3.0, 1.0]  episode_count: 229 q_vals: [-4.143, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.422, -6.649, -7.387]Step 109 7 visits [63.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 16.0, 3.0, 1.0]  episode_count: 231 q_vals: [-4.143, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.348, -6.649, -7.387]Step 110 7 visits [63.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 17.0, 3.0, 1.0]  episode_count: 234 q_vals: [-4.143, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.278, -6.649, -7.387]Step 111 7 visits [63.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 18.0, 3.0, 1.0]  episode_count: 236 q_vals: [-4.143, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.224, -6.649, -7.387]Step 112 7 visits [63.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 19.0, 3.0, 1.0]  episode_count: 236 q_vals: [-4.143, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.144, -6.649, -7.387]{"total_number_of_episodes": 239, "number_of_timesteps": 5030, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.6499999999999986},
Step 113 7 visits [63.0, 19.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 239 q_vals: [-4.143, -4.365, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]Step 114 1 visits [63.0, 20.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 243 q_vals: [-4.143, -4.34, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]Step 115 1 visits [63.0, 21.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 246 q_vals: [-4.143, -4.133, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]Step 116 1 visits [63.0, 22.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 246 q_vals: [-4.143, -4.1, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]{"total_number_of_episodes": 249, "number_of_timesteps": 5233, "per_episode_reward": 18.55, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.5},
Step 117 1 visits [63.0, 23.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 249 q_vals: [-4.143, -4.059, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]Step 118 1 visits [63.0, 24.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 253 q_vals: [-4.143, -4.092, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]Step 119 1 visits [63.0, 25.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 255 q_vals: [-4.143, -4.327, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]Step 120 0 visits [64.0, 25.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 257 q_vals: [-4.145, -4.327, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]Step 121 0 visits [65.0, 25.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 258 q_vals: [-4.213, -4.327, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]{"total_number_of_episodes": 261, "number_of_timesteps": 5448, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.5},
Step 122 1 visits [65.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 261 q_vals: [-4.213, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]Step 123 0 visits [66.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 263 q_vals: [-4.232, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]Step 124 0 visits [67.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 265 q_vals: [-4.215, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]Step 125 0 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 20.0, 3.0, 1.0]  episode_count: 268 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.454, -6.649, -7.387]Step 126 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 21.0, 3.0, 1.0]  episode_count: 270 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.242, -6.649, -7.387]Step 127 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 22.0, 3.0, 1.0]  episode_count: 270 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.226, -6.649, -7.387]{"total_number_of_episodes": 273, "number_of_timesteps": 5662, "per_episode_reward": 18.25, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.5},
Step 128 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 23.0, 3.0, 1.0]  episode_count: 273 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.203, -6.649, -7.387]Step 129 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 24.0, 3.0, 1.0]  episode_count: 277 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.372, -6.649, -7.387]Step 130 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 25.0, 3.0, 1.0]  episode_count: 277 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.393, -6.649, -7.387]Step 131 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 26.0, 3.0, 1.0]  episode_count: 280 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.283, -6.649, -7.387]{"total_number_of_episodes": 283, "number_of_timesteps": 5845, "per_episode_reward": 18.0, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.5},
Step 132 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 27.0, 3.0, 1.0]  episode_count: 283 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.124, -6.649, -7.387]Step 133 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 28.0, 3.0, 1.0]  episode_count: 286 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.097, -6.649, -7.387]Step 134 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 29.0, 3.0, 1.0]  episode_count: 288 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.245, -6.649, -7.387]Step 135 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 30.0, 3.0, 1.0]  episode_count: 290 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.104, -6.649, -7.387]Step 136 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 31.0, 3.0, 1.0]  episode_count: 291 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.253, -6.649, -7.387]{"total_number_of_episodes": 294, "number_of_timesteps": 6114, "per_episode_reward": 17.8, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.5},
Step 137 7 visits [68.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 32.0, 3.0, 1.0]  episode_count: 294 q_vals: [-4.276, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.403, -6.649, -7.387]Step 138 0 visits [69.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 32.0, 3.0, 1.0]  episode_count: 296 q_vals: [-4.29, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.403, -6.649, -7.387]Step 139 7 visits [69.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 33.0, 3.0, 1.0]  episode_count: 297 q_vals: [-4.29, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.444, -6.649, -7.387]Step 140 0 visits [70.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 33.0, 3.0, 1.0]  episode_count: 301 q_vals: [-4.28, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.444, -6.649, -7.387]Step 141 0 visits [71.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 33.0, 3.0, 1.0]  episode_count: 302 q_vals: [-4.272, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.444, -6.649, -7.387]{"total_number_of_episodes": 305, "number_of_timesteps": 6353, "per_episode_reward": 17.7, "episode_reward_trend_value": -0.006666666666666682, "biggest_recent_change": 0.3000000000000007},
Step 142 0 visits [72.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 33.0, 3.0, 1.0]  episode_count: 305 q_vals: [-4.33, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.444, -6.649, -7.387]Step 143 7 visits [72.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 34.0, 3.0, 1.0]  episode_count: 307 q_vals: [-4.33, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.417, -6.649, -7.387]Step 144 7 visits [72.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 35.0, 3.0, 1.0]  episode_count: 310 q_vals: [-4.33, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.29, -6.649, -7.387]Step 145 7 visits [72.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 36.0, 3.0, 1.0]  episode_count: 311 q_vals: [-4.33, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.171, -6.649, -7.387]Step 146 7 visits [72.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 37.0, 3.0, 1.0]  episode_count: 314 q_vals: [-4.33, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.305, -6.649, -7.387]{"total_number_of_episodes": 315, "number_of_timesteps": 6538, "per_episode_reward": 18.05, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.3500000000000014},
Step 147 7 visits [72.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 315 q_vals: [-4.33, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]Step 148 0 visits [73.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 316 q_vals: [-4.33, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]Step 149 0 visits [74.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 322 q_vals: [-4.388, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]Step 150 0 visits [75.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 324 q_vals: [-4.373, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]Step 151 0 visits [76.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 324 q_vals: [-4.355, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]{"total_number_of_episodes": 329, "number_of_timesteps": 6826, "per_episode_reward": 17.65, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.40000000000000213},
Step 152 0 visits [77.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 329 q_vals: [-4.351, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]Step 153 0 visits [78.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 333 q_vals: [-4.295, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]Step 154 0 visits [79.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 335 q_vals: [-4.292, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]Step 155 0 visits [80.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 338 q_vals: [-4.277, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]Step 156 0 visits [81.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 338 q_vals: [-4.343, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]{"total_number_of_episodes": 344, "number_of_timesteps": 7072, "per_episode_reward": 17.5, "episode_reward_trend_value": -0.008888888888888896, "biggest_recent_change": 0.40000000000000213},
Step 157 0 visits [82.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 344 q_vals: [-4.29, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]Step 158 0 visits [83.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 38.0, 3.0, 1.0]  episode_count: 345 q_vals: [-4.437, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.522, -6.649, -7.387]Step 159 7 visits [83.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 39.0, 3.0, 1.0]  episode_count: 346 q_vals: [-4.437, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.534, -6.649, -7.387]Step 160 7 visits [83.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 350 q_vals: [-4.437, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 161 0 visits [84.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 351 q_vals: [-4.429, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 162 0 visits [85.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 353 q_vals: [-4.445, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]{"total_number_of_episodes": 358, "number_of_timesteps": 7301, "per_episode_reward": 17.45, "episode_reward_trend_value": -0.012222222222222238, "biggest_recent_change": 0.40000000000000213},
Step 163 0 visits [86.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 358 q_vals: [-4.435, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 164 0 visits [87.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 359 q_vals: [-4.432, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 165 0 visits [88.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 361 q_vals: [-4.425, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 166 0 visits [89.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 364 q_vals: [-4.417, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 167 0 visits [90.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 367 q_vals: [-4.418, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]{"total_number_of_episodes": 368, "number_of_timesteps": 7492, "per_episode_reward": 17.25, "episode_reward_trend_value": -0.01111111111111111, "biggest_recent_change": 0.40000000000000213},
Step 168 0 visits [91.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 368 q_vals: [-4.435, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 169 0 visits [92.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 369 q_vals: [-4.43, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 170 0 visits [93.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 373 q_vals: [-4.382, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 171 0 visits [94.0, 26.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 374 q_vals: [-4.455, -4.653, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 172 1 visits [94.0, 27.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 375 q_vals: [-4.455, -4.623, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 173 1 visits [94.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 377 q_vals: [-4.455, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]{"total_number_of_episodes": 379, "number_of_timesteps": 7694, "per_episode_reward": 17.3, "episode_reward_trend_value": -0.010555555555555547, "biggest_recent_change": 0.40000000000000213},
Step 174 0 visits [95.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 379 q_vals: [-4.449, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 175 0 visits [96.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 382 q_vals: [-4.445, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 176 0 visits [97.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 383 q_vals: [-4.45, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]Step 177 0 visits [98.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 40.0, 3.0, 1.0]  episode_count: 386 q_vals: [-4.562, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.655, -6.649, -7.387]{"total_number_of_episodes": 390, "number_of_timesteps": 7957, "per_episode_reward": 17.15, "episode_reward_trend_value": -0.00944444444444446, "biggest_recent_change": 0.40000000000000213},
Step 178 7 visits [98.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 41.0, 3.0, 1.0]  episode_count: 390 q_vals: [-4.562, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.542, -6.649, -7.387]Step 179 7 visits [98.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 42.0, 3.0, 1.0]  episode_count: 392 q_vals: [-4.562, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.555, -6.649, -7.387]Step 180 7 visits [98.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 43.0, 3.0, 1.0]  episode_count: 394 q_vals: [-4.562, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.719, -6.649, -7.387]Step 181 0 visits [99.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 43.0, 3.0, 1.0]  episode_count: 397 q_vals: [-4.516, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.719, -6.649, -7.387]{"total_number_of_episodes": 400, "number_of_timesteps": 8150, "per_episode_reward": 17.25, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.40000000000000213},
Step 182 0 visits [100.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 43.0, 3.0, 1.0]  episode_count: 400 q_vals: [-4.568, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.719, -6.649, -7.387]Step 183 0 visits [101.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 43.0, 3.0, 1.0]  episode_count: 403 q_vals: [-4.643, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.719, -6.649, -7.387]Step 184 7 visits [101.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 44.0, 3.0, 1.0]  episode_count: 404 q_vals: [-4.643, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.702, -6.649, -7.387]Step 185 7 visits [101.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 45.0, 3.0, 1.0]  episode_count: 406 q_vals: [-4.643, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.694, -6.649, -7.387]{"total_number_of_episodes": 410, "number_of_timesteps": 8316, "per_episode_reward": 17.1, "episode_reward_trend_value": -0.006666666666666643, "biggest_recent_change": 0.40000000000000213},
Step 186 7 visits [101.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 410 q_vals: [-4.643, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]Step 187 0 visits [102.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 412 q_vals: [-4.644, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]Step 188 0 visits [103.0, 28.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 414 q_vals: [-4.695, -4.856, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]{"total_number_of_episodes": 420, "number_of_timesteps": 8476, "per_episode_reward": 17.0, "episode_reward_trend_value": -0.011666666666666676, "biggest_recent_change": 0.40000000000000213},
Step 189 1 visits [103.0, 29.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 420 q_vals: [-4.695, -4.813, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]Step 190 1 visits [103.0, 30.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 421 q_vals: [-4.695, -4.787, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]Step 191 1 visits [103.0, 31.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 423 q_vals: [-4.695, -4.804, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]{"total_number_of_episodes": 430, "number_of_timesteps": 8627, "per_episode_reward": 16.85, "episode_reward_trend_value": -0.008888888888888858, "biggest_recent_change": 0.1999999999999993},
Step 192 1 visits [103.0, 32.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 430 q_vals: [-4.695, -4.654, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]Step 193 1 visits [103.0, 33.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 431 q_vals: [-4.695, -4.654, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]Step 194 1 visits [103.0, 34.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 432 q_vals: [-4.695, -4.812, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]Step 195 1 visits [103.0, 35.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 436 q_vals: [-4.695, -4.82, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]Step 196 1 visits [103.0, 36.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 438 q_vals: [-4.695, -4.686, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]Step 197 1 visits [103.0, 37.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 439 q_vals: [-4.695, -4.686, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]{"total_number_of_episodes": 443, "number_of_timesteps": 8831, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.1999999999999993},
Step 198 1 visits [103.0, 38.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 443 q_vals: [-4.695, -4.563, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]Step 199 1 visits [103.0, 39.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 448 q_vals: [-4.695, -4.568, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]Step 200 1 visits [103.0, 40.0, 1.0, 3.0, 1.0, 1.0, 1.0, 46.0, 3.0, 1.0]  episode_count: 449 q_vals: [-4.695, -4.846, -9.762, -6.847, -7.369, -7.512, -8.206, -4.782, -6.649, -7.387]{"total_number_of_episodes": 453, "number_of_timesteps": 8977, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.008333333333333333, "biggest_recent_change": 0.1999999999999993},
Step 201 7 visits [103.0, 40.0, 1.0, 3.0, 1.0, 1.0, 1.0, 47.0, 3.0, 1.0]  episode_count: 453 q_vals: [-4.695, -4.846, -9.762, -6.847, -7.369, -7.512, -8.206, -4.766, -6.649, -7.387]Step 202 7 visits [103.0, 40.0, 1.0, 3.0, 1.0, 1.0, 1.0, 48.0, 3.0, 1.0]  episode_count: 456 q_vals: [-4.695, -4.846, -9.762, -6.847, -7.369, -7.512, -8.206, -4.714, -6.649, -7.387]Step 203 7 visits [103.0, 40.0, 1.0, 3.0, 1.0, 1.0, 1.0, 49.0, 3.0, 1.0]  episode_count: 461 q_vals: [-4.695, -4.846, -9.762, -6.847, -7.369, -7.512, -8.206, -4.699, -6.649, -7.387]{"total_number_of_episodes": 463, "number_of_timesteps": 9139, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.15000000000000213},
Step 204 7 visits [103.0, 40.0, 1.0, 3.0, 1.0, 1.0, 1.0, 50.0, 3.0, 1.0]  episode_count: 463 q_vals: [-4.695, -4.846, -9.762, -6.847, -7.369, -7.512, -8.206, -4.844, -6.649, -7.387]Step 205 0 visits [104.0, 40.0, 1.0, 3.0, 1.0, 1.0, 1.0, 50.0, 3.0, 1.0]  episode_count: 465 q_vals: [-4.693, -4.846, -9.762, -6.847, -7.369, -7.512, -8.206, -4.844, -6.649, -7.387]Step 206 0 visits [105.0, 40.0, 1.0, 3.0, 1.0, 1.0, 1.0, 50.0, 3.0, 1.0]  episode_count: 469 q_vals: [-4.76, -4.846, -9.762, -6.847, -7.369, -7.512, -8.206, -4.844, -6.649, -7.387]Step 207 1 visits [105.0, 41.0, 1.0, 3.0, 1.0, 1.0, 1.0, 50.0, 3.0, 1.0]  episode_count: 470 q_vals: [-4.76, -4.897, -9.762, -6.847, -7.369, -7.512, -8.206, -4.844, -6.649, -7.387]{"total_number_of_episodes": 475, "number_of_timesteps": 9331, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.00777777777777777, "biggest_recent_change": 0.15000000000000213},
Step 208 7 visits [105.0, 41.0, 1.0, 3.0, 1.0, 1.0, 1.0, 51.0, 3.0, 1.0]  episode_count: 475 q_vals: [-4.76, -4.897, -9.762, -6.847, -7.369, -7.512, -8.206, -4.84, -6.649, -7.387]Step 209 7 visits [105.0, 41.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 479 q_vals: [-4.76, -4.897, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 210 0 visits [106.0, 41.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 480 q_vals: [-4.715, -4.897, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 211 0 visits [107.0, 41.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 484 q_vals: [-4.671, -4.897, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]{"total_number_of_episodes": 485, "number_of_timesteps": 9452, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.006111111111111079, "biggest_recent_change": 0.14999999999999858},
Step 212 0 visits [108.0, 41.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 485 q_vals: [-4.656, -4.897, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 213 0 visits [109.0, 41.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 488 q_vals: [-4.672, -4.897, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 214 0 visits [110.0, 41.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 490 q_vals: [-4.785, -4.897, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 215 1 visits [110.0, 42.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 492 q_vals: [-4.785, -5.078, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 216 0 visits [111.0, 42.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 494 q_vals: [-4.867, -5.078, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]{"total_number_of_episodes": 500, "number_of_timesteps": 9743, "per_episode_reward": 16.75, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
Step 217 0 visits [112.0, 42.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 500 q_vals: [-4.872, -5.078, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 218 0 visits [113.0, 42.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 501 q_vals: [-4.869, -5.078, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 219 0 visits [114.0, 42.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 503 q_vals: [-4.869, -5.078, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 220 0 visits [115.0, 42.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 505 q_vals: [-4.888, -5.078, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 221 0 visits [116.0, 42.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 508 q_vals: [-4.949, -5.078, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]{"total_number_of_episodes": 510, "number_of_timesteps": 9909, "per_episode_reward": 16.7, "episode_reward_trend_value": -0.004444444444444468, "biggest_recent_change": 0.14999999999999858},
Step 222 1 visits [116.0, 43.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 510 q_vals: [-4.949, -5.062, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 223 1 visits [116.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 52.0, 3.0, 1.0]  episode_count: 512 q_vals: [-4.949, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.043, -6.649, -7.387]Step 224 7 visits [116.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 516 q_vals: [-4.949, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]{"total_number_of_episodes": 520, "number_of_timesteps": 10086, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
Step 225 0 visits [117.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 520 q_vals: [-4.907, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 226 0 visits [118.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 522 q_vals: [-4.93, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 227 0 visits [119.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 524 q_vals: [-4.932, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 228 0 visits [120.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 525 q_vals: [-5.011, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]{"total_number_of_episodes": 531, "number_of_timesteps": 10244, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.25},
Step 229 0 visits [121.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 531 q_vals: [-5.017, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 230 0 visits [122.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 533 q_vals: [-5.026, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 231 0 visits [123.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 536 q_vals: [-5.03, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 232 0 visits [124.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 537 q_vals: [-5.049, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 233 0 visits [125.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 540 q_vals: [-5.053, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]{"total_number_of_episodes": 545, "number_of_timesteps": 10474, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
Step 234 0 visits [126.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 545 q_vals: [-5.066, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 235 0 visits [127.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 545 q_vals: [-5.074, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 236 0 visits [128.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 547 q_vals: [-5.077, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 237 0 visits [129.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 552 q_vals: [-5.074, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 238 0 visits [130.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 552 q_vals: [-5.074, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]Step 239 0 visits [131.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 53.0, 3.0, 1.0]  episode_count: 553 q_vals: [-5.15, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.215, -6.649, -7.387]{"total_number_of_episodes": 557, "number_of_timesteps": 10695, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.25},
Step 240 7 visits [131.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 54.0, 3.0, 1.0]  episode_count: 557 q_vals: [-5.15, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.217, -6.649, -7.387]Step 241 7 visits [131.0, 44.0, 1.0, 3.0, 1.0, 1.0, 1.0, 55.0, 3.0, 1.0]  episode_count: 559 q_vals: [-5.15, -5.281, -9.762, -6.847, -7.369, -7.512, -8.206, -5.245, -6.649, -7.387]Step 242 1 visits [131.0, 45.0, 1.0, 3.0, 1.0, 1.0, 1.0, 55.0, 3.0, 1.0]  episode_count: 560 q_vals: [-5.15, -5.265, -9.762, -6.847, -7.369, -7.512, -8.206, -5.245, -6.649, -7.387]Step 243 1 visits [131.0, 46.0, 1.0, 3.0, 1.0, 1.0, 1.0, 55.0, 3.0, 1.0]  episode_count: 561 q_vals: [-5.15, -5.232, -9.762, -6.847, -7.369, -7.512, -8.206, -5.245, -6.649, -7.387]Step 244 1 visits [131.0, 47.0, 1.0, 3.0, 1.0, 1.0, 1.0, 55.0, 3.0, 1.0]  episode_count: 566 q_vals: [-5.15, -5.215, -9.762, -6.847, -7.369, -7.512, -8.206, -5.245, -6.649, -7.387]{"total_number_of_episodes": 568, "number_of_timesteps": 10948, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.25},
Step 245 1 visits [131.0, 48.0, 1.0, 3.0, 1.0, 1.0, 1.0, 55.0, 3.0, 1.0]  episode_count: 568 q_vals: [-5.15, -5.192, -9.762, -6.847, -7.369, -7.512, -8.206, -5.245, -6.649, -7.387]Step 246 1 visits [131.0, 49.0, 1.0, 3.0, 1.0, 1.0, 1.0, 55.0, 3.0, 1.0]  episode_count: 570 q_vals: [-5.15, -5.214, -9.762, -6.847, -7.369, -7.512, -8.206, -5.245, -6.649, -7.387]Step 247 1 visits [131.0, 50.0, 1.0, 3.0, 1.0, 1.0, 1.0, 55.0, 3.0, 1.0]  episode_count: 572 q_vals: [-5.15, -5.207, -9.762, -6.847, -7.369, -7.512, -8.206, -5.245, -6.649, -7.387]Step 248 1 visits [131.0, 51.0, 1.0, 3.0, 1.0, 1.0, 1.0, 55.0, 3.0, 1.0]  episode_count: 573 q_vals: [-5.15, -5.153, -9.762, -6.847, -7.369, -7.512, -8.206, -5.245, -6.649, -7.387]Step 249 1 visits [131.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 55.0, 3.0, 1.0]  episode_count: 575 q_vals: [-5.15, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.245, -6.649, -7.387]{"total_number_of_episodes": 578, "number_of_timesteps": 11133, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.25},
Step 250 7 visits [131.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 56.0, 3.0, 1.0]  episode_count: 578 q_vals: [-5.15, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.246, -6.649, -7.387]Step 251 7 visits [131.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 581 q_vals: [-5.15, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 252 0 visits [132.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 584 q_vals: [-5.111, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 253 0 visits [133.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 587 q_vals: [-5.109, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 254 0 visits [134.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 587 q_vals: [-5.109, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]{"total_number_of_episodes": 590, "number_of_timesteps": 11381, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.002222222222222254, "biggest_recent_change": 0.25},
Step 255 0 visits [135.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 590 q_vals: [-5.11, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 256 0 visits [136.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 593 q_vals: [-5.106, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 257 0 visits [137.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 596 q_vals: [-5.105, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 258 0 visits [138.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 597 q_vals: [-5.158, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 259 0 visits [139.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 599 q_vals: [-5.16, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]{"total_number_of_episodes": 601, "number_of_timesteps": 11592, "per_episode_reward": 16.45, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.25},
Step 260 0 visits [140.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 601 q_vals: [-5.159, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 261 0 visits [141.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 605 q_vals: [-5.162, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 262 0 visits [142.0, 52.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 606 q_vals: [-5.257, -5.307, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 263 1 visits [142.0, 53.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 607 q_vals: [-5.257, -5.302, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 264 1 visits [142.0, 54.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 609 q_vals: [-5.257, -5.287, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]{"total_number_of_episodes": 613, "number_of_timesteps": 11817, "per_episode_reward": 16.6, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.25},
Step 265 1 visits [142.0, 55.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 613 q_vals: [-5.257, -5.311, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 266 1 visits [142.0, 56.0, 1.0, 3.0, 1.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 615 q_vals: [-5.257, -5.411, -9.762, -6.847, -7.369, -7.512, -8.206, -5.375, -6.649, -7.387]Step 267 4 visits [142.0, 56.0, 1.0, 3.0, 2.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 617 q_vals: [-5.257, -5.411, -9.762, -6.847, -4.128, -7.512, -8.206, -5.375, -6.649, -7.387]Step 268 4 visits [142.0, 56.0, 1.0, 3.0, 3.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 618 q_vals: [-5.257, -5.411, -9.762, -6.847, -4.316, -7.512, -8.206, -5.375, -6.649, -7.387]{"total_number_of_episodes": 624, "number_of_timesteps": 12058, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.25},
Step 269 4 visits [142.0, 56.0, 1.0, 3.0, 4.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 624 q_vals: [-5.257, -5.411, -9.762, -6.847, -4.496, -7.512, -8.206, -5.375, -6.649, -7.387]Step 270 4 visits [142.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 1.0]  episode_count: 625 q_vals: [-5.257, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.387]Step 271 9 visits [142.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 2.0]  episode_count: 627 q_vals: [-5.257, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -6.163]Step 272 9 visits [142.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 631 q_vals: [-5.257, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]{"total_number_of_episodes": 634, "number_of_timesteps": 12235, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.15000000000000213},
Step 273 0 visits [143.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 634 q_vals: [-5.257, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 274 0 visits [144.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 636 q_vals: [-5.254, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 275 0 visits [145.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 639 q_vals: [-5.249, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 276 0 visits [146.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 640 q_vals: [-5.247, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 277 0 visits [147.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 643 q_vals: [-5.251, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]{"total_number_of_episodes": 647, "number_of_timesteps": 12456, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000213},
Step 278 0 visits [148.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 647 q_vals: [-5.248, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 279 0 visits [149.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 649 q_vals: [-5.248, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 280 0 visits [150.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 651 q_vals: [-5.25, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 281 0 visits [151.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 655 q_vals: [-5.247, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 282 0 visits [152.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 656 q_vals: [-5.248, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]{"total_number_of_episodes": 658, "number_of_timesteps": 12654, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000213},
Step 283 0 visits [153.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 658 q_vals: [-5.213, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 284 0 visits [154.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 660 q_vals: [-5.191, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 285 0 visits [155.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 665 q_vals: [-5.193, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 286 0 visits [156.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 666 q_vals: [-5.246, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]{"total_number_of_episodes": 670, "number_of_timesteps": 12866, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 287 0 visits [157.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 670 q_vals: [-5.244, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 288 0 visits [158.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 57.0, 3.0, 3.0]  episode_count: 673 q_vals: [-5.259, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.375, -6.649, -7.683]Step 289 7 visits [158.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 675 q_vals: [-5.259, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.51, -6.649, -7.683]Step 290 0 visits [159.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 677 q_vals: [-5.259, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.51, -6.649, -7.683]Step 291 0 visits [160.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 679 q_vals: [-5.226, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.51, -6.649, -7.683]{"total_number_of_episodes": 683, "number_of_timesteps": 13077, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 292 0 visits [161.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 683 q_vals: [-5.226, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.51, -6.649, -7.683]Step 293 0 visits [162.0, 56.0, 1.0, 3.0, 5.0, 1.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 684 q_vals: [-5.29, -5.411, -9.762, -6.847, -6.192, -7.512, -8.206, -5.51, -6.649, -7.683]Step 294 1 visits [162.0, 57.0, 1.0, 3.0, 5.0, 1.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 686 q_vals: [-5.29, -5.532, -9.762, -6.847, -6.192, -7.512, -8.206, -5.51, -6.649, -7.683]Step 295 0 visits [163.0, 57.0, 1.0, 3.0, 5.0, 1.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 689 q_vals: [-5.269, -5.532, -9.762, -6.847, -6.192, -7.512, -8.206, -5.51, -6.649, -7.683]{"total_number_of_episodes": 693, "number_of_timesteps": 13267, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.15000000000000213},
Step 296 0 visits [164.0, 57.0, 1.0, 3.0, 5.0, 1.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 693 q_vals: [-5.266, -5.532, -9.762, -6.847, -6.192, -7.512, -8.206, -5.51, -6.649, -7.683]Step 297 0 visits [165.0, 57.0, 1.0, 3.0, 5.0, 1.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 694 q_vals: [-5.31, -5.532, -9.762, -6.847, -6.192, -7.512, -8.206, -5.51, -6.649, -7.683]Step 298 0 visits [166.0, 57.0, 1.0, 3.0, 5.0, 1.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 695 q_vals: [-5.312, -5.532, -9.762, -6.847, -6.192, -7.512, -8.206, -5.51, -6.649, -7.683]Step 299 4 visits [166.0, 57.0, 1.0, 3.0, 6.0, 1.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 698 q_vals: [-5.312, -5.532, -9.762, -6.847, -7.6, -7.512, -8.206, -5.51, -6.649, -7.683]Step 300 5 visits [166.0, 57.0, 1.0, 3.0, 6.0, 2.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 701 q_vals: [-5.312, -5.532, -9.762, -6.847, -7.6, -4.33, -8.206, -5.51, -6.649, -7.683]{"total_number_of_episodes": 706, "number_of_timesteps": 13503, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 301 5 visits [166.0, 57.0, 1.0, 3.0, 6.0, 3.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 706 q_vals: [-5.312, -5.532, -9.762, -6.847, -7.6, -4.777, -8.206, -5.51, -6.649, -7.683]Step 302 5 visits [166.0, 57.0, 1.0, 3.0, 6.0, 4.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 708 q_vals: [-5.312, -5.532, -9.762, -6.847, -7.6, -4.737, -8.206, -5.51, -6.649, -7.683]Step 303 5 visits [166.0, 57.0, 1.0, 3.0, 6.0, 5.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 709 q_vals: [-5.312, -5.532, -9.762, -6.847, -7.6, -5.021, -8.206, -5.51, -6.649, -7.683]Step 304 5 visits [166.0, 57.0, 1.0, 3.0, 6.0, 6.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 709 q_vals: [-5.312, -5.532, -9.762, -6.847, -7.6, -6.015, -8.206, -5.51, -6.649, -7.683]Step 305 5 visits [166.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 712 q_vals: [-5.312, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]{"total_number_of_episodes": 716, "number_of_timesteps": 13679, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.15000000000000213},
Step 306 0 visits [167.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 716 q_vals: [-5.308, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]Step 307 0 visits [168.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 719 q_vals: [-5.346, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]Step 308 0 visits [169.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 720 q_vals: [-5.355, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]Step 309 0 visits [170.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 722 q_vals: [-5.352, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]Step 310 0 visits [171.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 724 q_vals: [-5.349, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]{"total_number_of_episodes": 726, "number_of_timesteps": 13897, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.002222222222222254, "biggest_recent_change": 0.15000000000000213},
Step 311 0 visits [172.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 726 q_vals: [-5.346, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]Step 312 0 visits [173.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 729 q_vals: [-5.315, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]Step 313 0 visits [174.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 730 q_vals: [-5.374, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]Step 314 0 visits [175.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 733 q_vals: [-5.375, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]{"total_number_of_episodes": 736, "number_of_timesteps": 14081, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999787},
Step 315 0 visits [176.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 736 q_vals: [-5.375, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]Step 316 0 visits [177.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 738 q_vals: [-5.344, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]Step 317 0 visits [178.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 740 q_vals: [-5.342, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]Step 318 0 visits [179.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 58.0, 3.0, 3.0]  episode_count: 741 q_vals: [-5.39, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.51, -6.649, -7.683]{"total_number_of_episodes": 746, "number_of_timesteps": 14324, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
Step 319 7 visits [179.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 3.0, 3.0]  episode_count: 746 q_vals: [-5.39, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -6.649, -7.683]Step 320 0 visits [180.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 3.0, 3.0]  episode_count: 747 q_vals: [-5.391, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -6.649, -7.683]Step 321 0 visits [181.0, 57.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 3.0, 3.0]  episode_count: 749 q_vals: [-5.445, -5.532, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -6.649, -7.683]Step 322 1 visits [181.0, 58.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 3.0, 3.0]  episode_count: 751 q_vals: [-5.445, -5.539, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -6.649, -7.683]Step 323 1 visits [181.0, 59.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 3.0, 3.0]  episode_count: 752 q_vals: [-5.445, -5.445, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -6.649, -7.683]Step 324 1 visits [181.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 3.0, 3.0]  episode_count: 753 q_vals: [-5.445, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -6.649, -7.683]Step 325 8 visits [181.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 4.0, 3.0]  episode_count: 755 q_vals: [-5.445, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -6.314, -7.683]{"total_number_of_episodes": 758, "number_of_timesteps": 14590, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
Step 326 8 visits [181.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 758 q_vals: [-5.445, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 327 0 visits [182.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 759 q_vals: [-5.444, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 328 0 visits [183.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 762 q_vals: [-5.414, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 329 0 visits [184.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 765 q_vals: [-5.416, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 330 0 visits [185.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 766 q_vals: [-5.386, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]{"total_number_of_episodes": 770, "number_of_timesteps": 14867, "per_episode_reward": 16.65, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.1999999999999993},
Step 331 0 visits [186.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 770 q_vals: [-5.386, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 332 0 visits [187.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 773 q_vals: [-5.388, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 333 0 visits [188.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 773 q_vals: [-5.36, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 334 0 visits [189.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 778 q_vals: [-5.331, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]{"total_number_of_episodes": 780, "number_of_timesteps": 15026, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.25},
Step 335 0 visits [190.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 780 q_vals: [-5.33, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 336 0 visits [191.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 783 q_vals: [-5.328, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 337 0 visits [192.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 785 q_vals: [-5.381, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 338 0 visits [193.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 786 q_vals: [-5.377, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]{"total_number_of_episodes": 792, "number_of_timesteps": 15224, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.25},
Step 339 0 visits [194.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 792 q_vals: [-5.431, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 340 0 visits [195.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 793 q_vals: [-5.403, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 341 0 visits [196.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 796 q_vals: [-5.403, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 342 0 visits [197.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 801 q_vals: [-5.446, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 343 0 visits [198.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 801 q_vals: [-5.421, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]{"total_number_of_episodes": 808, "number_of_timesteps": 15484, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.25},
Step 344 0 visits [199.0, 60.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 808 q_vals: [-5.466, -5.587, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 345 1 visits [199.0, 61.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 809 q_vals: [-5.466, -5.593, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 346 1 visits [199.0, 62.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 811 q_vals: [-5.466, -5.503, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 347 1 visits [199.0, 63.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 812 q_vals: [-5.466, -5.522, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 348 1 visits [199.0, 64.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 815 q_vals: [-5.466, -5.529, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 349 1 visits [199.0, 65.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 817 q_vals: [-5.466, -5.536, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]{"total_number_of_episodes": 818, "number_of_timesteps": 15637, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.25},
Step 350 1 visits [199.0, 66.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 818 q_vals: [-5.466, -5.673, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 351 0 visits [200.0, 66.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 819 q_vals: [-5.473, -5.673, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 352 0 visits [201.0, 66.0, 1.0, 3.0, 6.0, 7.0, 1.0, 59.0, 5.0, 3.0]  episode_count: 823 q_vals: [-5.518, -5.673, -9.762, -6.847, -7.6, -6.917, -8.206, -5.635, -8.264, -7.683]Step 353 7 visits [201.0, 66.0, 1.0, 3.0, 6.0, 7.0, 1.0, 60.0, 5.0, 3.0]  episode_count: 826 q_vals: [-5.518, -5.673, -9.762, -6.847, -7.6, -6.917, -8.206, -5.673, -8.264, -7.683]{"total_number_of_episodes": 828, "number_of_timesteps": 15896, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.25},
Step 354 0 visits [202.0, 66.0, 1.0, 3.0, 6.0, 7.0, 1.0, 60.0, 5.0, 3.0]  episode_count: 828 q_vals: [-5.523, -5.673, -9.762, -6.847, -7.6, -6.917, -8.206, -5.673, -8.264, -7.683]Step 355 0 visits [203.0, 66.0, 1.0, 3.0, 6.0, 7.0, 1.0, 60.0, 5.0, 3.0]  episode_count: 830 q_vals: [-5.532, -5.673, -9.762, -6.847, -7.6, -6.917, -8.206, -5.673, -8.264, -7.683]Step 356 7 visits [203.0, 66.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 833 q_vals: [-5.532, -5.673, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 357 0 visits [204.0, 66.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 833 q_vals: [-5.539, -5.673, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 358 0 visits [205.0, 66.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 835 q_vals: [-5.518, -5.673, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]{"total_number_of_episodes": 841, "number_of_timesteps": 16140, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.25},
Step 359 0 visits [206.0, 66.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 841 q_vals: [-5.587, -5.673, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 360 1 visits [206.0, 67.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 843 q_vals: [-5.587, -5.706, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 361 1 visits [206.0, 68.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 843 q_vals: [-5.587, -5.673, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 362 1 visits [206.0, 69.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 848 q_vals: [-5.587, -5.59, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 363 1 visits [206.0, 70.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 849 q_vals: [-5.587, -5.604, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 364 1 visits [206.0, 71.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 850 q_vals: [-5.587, -5.72, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]{"total_number_of_episodes": 852, "number_of_timesteps": 16328, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.25},
Step 365 0 visits [207.0, 71.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 852 q_vals: [-5.598, -5.72, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 366 0 visits [208.0, 71.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 854 q_vals: [-5.571, -5.72, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 367 0 visits [209.0, 71.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 858 q_vals: [-5.571, -5.72, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]{"total_number_of_episodes": 863, "number_of_timesteps": 16573, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.25},
Step 368 0 visits [210.0, 71.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 863 q_vals: [-5.578, -5.72, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 369 0 visits [211.0, 71.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 864 q_vals: [-5.578, -5.72, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 370 0 visits [212.0, 71.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 866 q_vals: [-5.588, -5.72, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 371 0 visits [213.0, 71.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 869 q_vals: [-5.629, -5.72, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 372 1 visits [213.0, 72.0, 1.0, 3.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 870 q_vals: [-5.629, -5.731, -9.762, -6.847, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 373 3 visits [213.0, 72.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 872 q_vals: [-5.629, -5.731, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]{"total_number_of_episodes": 874, "number_of_timesteps": 16728, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.003333333333333302, "biggest_recent_change": 0.25},
Step 374 1 visits [213.0, 73.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 874 q_vals: [-5.629, -5.742, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 375 1 visits [213.0, 74.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 876 q_vals: [-5.629, -5.745, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 376 1 visits [213.0, 75.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 879 q_vals: [-5.629, -5.752, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 377 0 visits [214.0, 75.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 881 q_vals: [-5.603, -5.752, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]{"total_number_of_episodes": 885, "number_of_timesteps": 16966, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
Step 378 0 visits [215.0, 75.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 885 q_vals: [-5.609, -5.752, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 379 0 visits [216.0, 75.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 887 q_vals: [-5.616, -5.752, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 380 0 visits [217.0, 75.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 887 q_vals: [-5.627, -5.752, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 381 0 visits [218.0, 75.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 889 q_vals: [-5.601, -5.752, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 382 0 visits [219.0, 75.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 892 q_vals: [-5.648, -5.752, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 383 1 visits [219.0, 76.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 893 q_vals: [-5.648, -5.78, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]{"total_number_of_episodes": 897, "number_of_timesteps": 17254, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.1999999999999993},
Step 384 0 visits [220.0, 76.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 897 q_vals: [-5.658, -5.78, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 385 0 visits [221.0, 76.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 899 q_vals: [-5.672, -5.78, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 386 1 visits [221.0, 77.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 904 q_vals: [-5.672, -5.791, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 387 0 visits [222.0, 77.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 906 q_vals: [-5.72, -5.791, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]{"total_number_of_episodes": 908, "number_of_timesteps": 17435, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.000555555555555524, "biggest_recent_change": 0.1999999999999993},
Step 388 1 visits [222.0, 78.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 908 q_vals: [-5.72, -5.81, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 389 1 visits [222.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 909 q_vals: [-5.72, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 390 0 visits [223.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 914 q_vals: [-5.726, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 391 0 visits [224.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 914 q_vals: [-5.711, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 392 0 visits [225.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 917 q_vals: [-5.721, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]{"total_number_of_episodes": 918, "number_of_timesteps": 17602, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
Step 393 0 visits [226.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 918 q_vals: [-5.727, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 394 0 visits [227.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 61.0, 5.0, 3.0]  episode_count: 923 q_vals: [-5.737, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -5.887, -8.264, -7.683]Step 395 7 visits [227.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 923 q_vals: [-5.737, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 396 0 visits [228.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 923 q_vals: [-5.787, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]{"total_number_of_episodes": 930, "number_of_timesteps": 17868, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
Step 397 0 visits [229.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 930 q_vals: [-5.761, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 398 0 visits [230.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 933 q_vals: [-5.771, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 399 0 visits [231.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 933 q_vals: [-5.746, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 400 0 visits [232.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 936 q_vals: [-5.748, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]{"total_number_of_episodes": 940, "number_of_timesteps": 18028, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.1999999999999993},
Step 401 0 visits [233.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 940 q_vals: [-5.75, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 402 0 visits [234.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 942 q_vals: [-5.803, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 403 0 visits [235.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 944 q_vals: [-5.812, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 404 0 visits [236.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 948 q_vals: [-5.799, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]{"total_number_of_episodes": 951, "number_of_timesteps": 18209, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.1999999999999993},
Step 405 0 visits [237.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 951 q_vals: [-5.801, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 406 0 visits [238.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 953 q_vals: [-5.776, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 407 0 visits [239.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 955 q_vals: [-5.779, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 408 0 visits [240.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 958 q_vals: [-5.782, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 409 0 visits [241.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 959 q_vals: [-5.758, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]{"total_number_of_episodes": 963, "number_of_timesteps": 18391, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.1999999999999993},
Step 410 0 visits [242.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 963 q_vals: [-5.762, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 411 0 visits [243.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 964 q_vals: [-5.771, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 412 0 visits [244.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 964 q_vals: [-5.777, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 413 0 visits [245.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 967 q_vals: [-5.819, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 414 0 visits [246.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 972 q_vals: [-5.823, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]{"total_number_of_episodes": 974, "number_of_timesteps": 18651, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.1999999999999993},
Step 415 0 visits [247.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 974 q_vals: [-5.8, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 416 0 visits [248.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 976 q_vals: [-5.803, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 417 0 visits [249.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 978 q_vals: [-5.812, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 418 0 visits [250.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 979 q_vals: [-5.788, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 419 0 visits [251.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 979 q_vals: [-5.771, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 420 0 visits [252.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 982 q_vals: [-5.827, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]{"total_number_of_episodes": 987, "number_of_timesteps": 18913, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.1999999999999993},
Step 421 0 visits [253.0, 79.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 987 q_vals: [-5.869, -5.968, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 422 1 visits [253.0, 80.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 990 q_vals: [-5.869, -5.993, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 423 0 visits [254.0, 80.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 991 q_vals: [-5.873, -5.993, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 424 1 visits [254.0, 81.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 996 q_vals: [-5.873, -6.011, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]{"total_number_of_episodes": 998, "number_of_timesteps": 19095, "per_episode_reward": 16.4, "episode_reward_trend_value": -0.0016666666666666902, "biggest_recent_change": 0.1999999999999993},
Step 425 0 visits [255.0, 81.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 998 q_vals: [-5.877, -6.011, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 426 0 visits [256.0, 81.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 1001 q_vals: [-5.885, -6.011, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 427 0 visits [257.0, 81.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 1003 q_vals: [-5.893, -6.011, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 428 1 visits [257.0, 82.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 1007 q_vals: [-5.893, -5.965, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]{"total_number_of_episodes": 1010, "number_of_timesteps": 19276, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.14999999999999858},
Step 429 1 visits [257.0, 83.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 1010 q_vals: [-5.893, -5.988, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 430 1 visits [257.0, 84.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 1010 q_vals: [-5.893, -6.011, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 431 0 visits [258.0, 84.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 1014 q_vals: [-5.896, -6.011, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 432 1 visits [258.0, 85.0, 1.0, 4.0, 6.0, 7.0, 1.0, 62.0, 5.0, 3.0]  episode_count: 1017 q_vals: [-5.896, -6.033, -9.762, -7.111, -7.6, -6.917, -8.206, -6.107, -8.264, -7.683]Step 433 6 visits [258.0, 85.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1018 q_vals: [-5.896, -6.033, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 434 0 visits [259.0, 85.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1019 q_vals: [-5.9, -6.033, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]{"total_number_of_episodes": 1021, "number_of_timesteps": 19467, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
Step 435 0 visits [260.0, 85.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1021 q_vals: [-5.905, -6.033, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 436 0 visits [261.0, 85.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1024 q_vals: [-5.911, -6.033, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 437 0 visits [262.0, 85.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1026 q_vals: [-5.916, -6.033, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 438 0 visits [263.0, 85.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1027 q_vals: [-5.902, -6.033, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]{"total_number_of_episodes": 1031, "number_of_timesteps": 19720, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 439 0 visits [264.0, 85.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1031 q_vals: [-5.946, -6.033, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 440 1 visits [264.0, 86.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1032 q_vals: [-5.946, -6.055, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 441 1 visits [264.0, 87.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1033 q_vals: [-5.946, -6.067, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 442 0 visits [265.0, 87.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1036 q_vals: [-5.923, -6.067, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 443 0 visits [266.0, 87.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1036 q_vals: [-5.927, -6.067, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 444 0 visits [267.0, 87.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1039 q_vals: [-5.913, -6.067, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]{"total_number_of_episodes": 1041, "number_of_timesteps": 19944, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
Step 445 0 visits [268.0, 87.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1041 q_vals: [-5.92, -6.067, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 446 0 visits [269.0, 87.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1043 q_vals: [-5.927, -6.067, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 447 0 visits [270.0, 87.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1045 q_vals: [-5.935, -6.067, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 448 0 visits [271.0, 87.0, 1.0, 4.0, 6.0, 7.0, 2.0, 62.0, 5.0, 3.0]  episode_count: 1047 q_vals: [-5.979, -6.067, -9.762, -7.111, -7.6, -6.917, -7.97, -6.107, -8.264, -7.683]Step 449 7 visits [271.0, 87.0, 1.0, 4.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1049 q_vals: [-5.979, -6.067, -9.762, -7.111, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]{"total_number_of_episodes": 1052, "number_of_timesteps": 20199, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
Step 450 1 visits [271.0, 88.0, 1.0, 4.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1052 q_vals: [-5.979, -6.087, -9.762, -7.111, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]Step 451 1 visits [271.0, 89.0, 1.0, 4.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1053 q_vals: [-5.979, -6.234, -9.762, -7.111, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]Step 452 0 visits [272.0, 89.0, 1.0, 4.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1054 q_vals: [-5.986, -6.234, -9.762, -7.111, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]Step 453 0 visits [273.0, 89.0, 1.0, 4.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1056 q_vals: [-5.993, -6.234, -9.762, -7.111, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]Step 454 0 visits [274.0, 89.0, 1.0, 4.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1060 q_vals: [-6.0, -6.234, -9.762, -7.111, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]Step 455 0 visits [275.0, 89.0, 1.0, 4.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1061 q_vals: [-6.007, -6.234, -9.762, -7.111, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]Step 456 0 visits [276.0, 89.0, 1.0, 4.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1061 q_vals: [-6.014, -6.234, -9.762, -7.111, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]{"total_number_of_episodes": 1062, "number_of_timesteps": 20417, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.15000000000000213},
Step 457 0 visits [277.0, 89.0, 1.0, 4.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1062 q_vals: [-6.042, -6.234, -9.762, -7.111, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]Step 458 3 visits [277.0, 89.0, 1.0, 5.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1064 q_vals: [-6.042, -6.234, -9.762, -9.639, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]Step 459 0 visits [278.0, 89.0, 1.0, 5.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1067 q_vals: [-6.091, -6.234, -9.762, -9.639, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]Step 460 0 visits [279.0, 89.0, 1.0, 5.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1068 q_vals: [-6.14, -6.234, -9.762, -9.639, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]Step 461 1 visits [279.0, 90.0, 1.0, 5.0, 6.0, 7.0, 2.0, 63.0, 5.0, 3.0]  episode_count: 1069 q_vals: [-6.14, -6.25, -9.762, -9.639, -7.6, -6.917, -7.97, -6.291, -8.264, -7.683]{"total_number_of_episodes": 1072, "number_of_timesteps": 20736, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.15000000000000213},
Step 462 7 visits [279.0, 90.0, 1.0, 5.0, 6.0, 7.0, 2.0, 64.0, 5.0, 3.0]  episode_count: 1072 q_vals: [-6.14, -6.25, -9.762, -9.639, -7.6, -6.917, -7.97, -6.316, -8.264, -7.683]Step 463 5 visits [279.0, 90.0, 1.0, 5.0, 6.0, 8.0, 2.0, 64.0, 5.0, 3.0]  episode_count: 1076 q_vals: [-6.14, -6.25, -9.762, -9.639, -7.6, -7.04, -7.97, -6.316, -8.264, -7.683]Step 464 1 visits [279.0, 91.0, 1.0, 5.0, 6.0, 8.0, 2.0, 64.0, 5.0, 3.0]  episode_count: 1079 q_vals: [-6.14, -6.251, -9.762, -9.639, -7.6, -7.04, -7.97, -6.316, -8.264, -7.683]Step 465 1 visits [279.0, 92.0, 1.0, 5.0, 6.0, 8.0, 2.0, 64.0, 5.0, 3.0]  episode_count: 1079 q_vals: [-6.14, -6.398, -9.762, -9.639, -7.6, -7.04, -7.97, -6.316, -8.264, -7.683]Step 466 0 visits [280.0, 92.0, 1.0, 5.0, 6.0, 8.0, 2.0, 64.0, 5.0, 3.0]  episode_count: 1081 q_vals: [-6.18, -6.398, -9.762, -9.639, -7.6, -7.04, -7.97, -6.316, -8.264, -7.683]{"total_number_of_episodes": 1083, "number_of_timesteps": 20964, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000213},
Step 467 7 visits [280.0, 92.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1083 q_vals: [-6.18, -6.398, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 468 0 visits [281.0, 92.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1086 q_vals: [-6.225, -6.398, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 469 0 visits [282.0, 92.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1088 q_vals: [-6.231, -6.398, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 470 0 visits [283.0, 92.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1088 q_vals: [-6.234, -6.398, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 471 0 visits [284.0, 92.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1092 q_vals: [-6.238, -6.398, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 472 0 visits [285.0, 92.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1092 q_vals: [-6.286, -6.398, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]{"total_number_of_episodes": 1095, "number_of_timesteps": 21239, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.15000000000000213},
Step 473 0 visits [286.0, 92.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1095 q_vals: [-6.286, -6.398, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 474 1 visits [286.0, 93.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1095 q_vals: [-6.286, -6.366, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 475 1 visits [286.0, 94.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1101 q_vals: [-6.286, -6.508, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 476 0 visits [287.0, 94.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1103 q_vals: [-6.288, -6.508, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]{"total_number_of_episodes": 1105, "number_of_timesteps": 21490, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.15000000000000213},
Step 477 0 visits [288.0, 94.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1105 q_vals: [-6.293, -6.508, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 478 0 visits [289.0, 94.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1108 q_vals: [-6.297, -6.508, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 479 0 visits [290.0, 94.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1110 q_vals: [-6.301, -6.508, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 480 0 visits [291.0, 94.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1114 q_vals: [-6.288, -6.508, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]{"total_number_of_episodes": 1117, "number_of_timesteps": 21672, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000213},
Step 481 0 visits [292.0, 94.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1117 q_vals: [-6.293, -6.508, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 482 0 visits [293.0, 94.0, 1.0, 5.0, 6.0, 8.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1121 q_vals: [-6.328, -6.508, -9.762, -9.639, -7.6, -7.04, -7.97, -6.523, -8.264, -7.683]Step 483 5 visits [293.0, 94.0, 1.0, 5.0, 6.0, 9.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1121 q_vals: [-6.328, -6.508, -9.762, -9.639, -7.6, -7.136, -7.97, -6.523, -8.264, -7.683]Step 484 0 visits [294.0, 94.0, 1.0, 5.0, 6.0, 9.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1123 q_vals: [-6.332, -6.508, -9.762, -9.639, -7.6, -7.136, -7.97, -6.523, -8.264, -7.683]{"total_number_of_episodes": 1129, "number_of_timesteps": 21860, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.15000000000000213},
Step 485 0 visits [295.0, 94.0, 1.0, 5.0, 6.0, 9.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1129 q_vals: [-6.337, -6.508, -9.762, -9.639, -7.6, -7.136, -7.97, -6.523, -8.264, -7.683]Step 486 0 visits [296.0, 94.0, 1.0, 5.0, 6.0, 9.0, 2.0, 65.0, 5.0, 3.0]  episode_count: 1131 q_vals: [-6.373, -6.508, -9.762, -9.639, -7.6, -7.136, -7.97, -6.523, -8.264, -7.683]Step 487 6 visits [296.0, 94.0, 1.0, 5.0, 6.0, 9.0, 3.0, 65.0, 5.0, 3.0]  episode_count: 1132 q_vals: [-6.373, -6.508, -9.762, -9.639, -7.6, -7.136, -10.834, -6.523, -8.264, -7.683]Step 488 7 visits [296.0, 94.0, 1.0, 5.0, 6.0, 9.0, 3.0, 66.0, 5.0, 3.0]  episode_count: 1137 q_vals: [-6.373, -6.508, -9.762, -9.639, -7.6, -7.136, -10.834, -6.424, -8.264, -7.683]{"total_number_of_episodes": 1139, "number_of_timesteps": 22018, "per_episode_reward": 16.65, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.15000000000000213},
Step 489 7 visits [296.0, 94.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 3.0]  episode_count: 1139 q_vals: [-6.373, -6.508, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.683]Step 490 0 visits [297.0, 94.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 3.0]  episode_count: 1143 q_vals: [-6.377, -6.508, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.683]Step 491 0 visits [298.0, 94.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 3.0]  episode_count: 1147 q_vals: [-6.381, -6.508, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.683]Step 492 0 visits [299.0, 94.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 3.0]  episode_count: 1147 q_vals: [-6.386, -6.508, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.683]{"total_number_of_episodes": 1152, "number_of_timesteps": 22210, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.15000000000000213},
Step 493 0 visits [300.0, 94.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 3.0]  episode_count: 1152 q_vals: [-6.391, -6.508, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.683]Step 494 9 visits [300.0, 94.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 4.0]  episode_count: 1155 q_vals: [-6.391, -6.508, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.737]Step 495 0 visits [301.0, 94.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 4.0]  episode_count: 1158 q_vals: [-6.395, -6.508, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.737]Step 496 0 visits [302.0, 94.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 4.0]  episode_count: 1160 q_vals: [-6.389, -6.508, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.737]{"total_number_of_episodes": 1165, "number_of_timesteps": 22400, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.15000000000000213},
Step 497 0 visits [303.0, 94.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 4.0]  episode_count: 1165 q_vals: [-6.433, -6.508, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.737]Step 498 1 visits [303.0, 95.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 4.0]  episode_count: 1166 q_vals: [-6.433, -6.523, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.737]Step 499 1 visits [303.0, 96.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 4.0]  episode_count: 1168 q_vals: [-6.433, -6.661, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.737]Step 500 0 visits [304.0, 96.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 4.0]  episode_count: 1173 q_vals: [-6.438, -6.661, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.737]{"total_number_of_episodes": 1177, "number_of_timesteps": 22579, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.14999999999999858},
Step 501 0 visits [305.0, 96.0, 1.0, 5.0, 6.0, 9.0, 3.0, 67.0, 5.0, 4.0]  episode_count: 1177 q_vals: [-6.482, -6.661, -9.762, -9.639, -7.6, -7.136, -10.834, -6.618, -8.264, -7.737]Step 502 5 visits [305.0, 96.0, 1.0, 5.0, 6.0, 10.0, 3.0, 67.0, 5.0, 4.0]  episode_count: 1179 q_vals: [-6.482, -6.661, -9.762, -9.639, -7.6, -7.212, -10.834, -6.618, -8.264, -7.737]Step 503 7 visits [305.0, 96.0, 1.0, 5.0, 6.0, 10.0, 3.0, 68.0, 5.0, 4.0]  episode_count: 1182 q_vals: [-6.482, -6.661, -9.762, -9.639, -7.6, -7.212, -10.834, -6.594, -8.264, -7.737]{"total_number_of_episodes": 1188, "number_of_timesteps": 22715, "per_episode_reward": 16.35, "episode_reward_trend_value": -0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
Step 504 7 visits [305.0, 96.0, 1.0, 5.0, 6.0, 10.0, 3.0, 69.0, 5.0, 4.0]  episode_count: 1188 q_vals: [-6.482, -6.661, -9.762, -9.639, -7.6, -7.212, -10.834, -6.613, -8.264, -7.737]Step 505 7 visits [305.0, 96.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1189 q_vals: [-6.482, -6.661, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]Step 506 0 visits [306.0, 96.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1191 q_vals: [-6.487, -6.661, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]Step 507 0 visits [307.0, 96.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1196 q_vals: [-6.528, -6.661, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]{"total_number_of_episodes": 1200, "number_of_timesteps": 22872, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.14999999999999858},
Step 508 0 visits [308.0, 96.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1200 q_vals: [-6.57, -6.661, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]Step 509 1 visits [308.0, 97.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1201 q_vals: [-6.57, -6.673, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]Step 510 1 visits [308.0, 98.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1201 q_vals: [-6.57, -6.646, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]Step 511 1 visits [308.0, 99.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1208 q_vals: [-6.57, -6.659, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]Step 512 1 visits [308.0, 100.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1208 q_vals: [-6.57, -6.592, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]{"total_number_of_episodes": 1213, "number_of_timesteps": 23083, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
Step 513 1 visits [308.0, 101.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1213 q_vals: [-6.57, -6.527, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]Step 514 1 visits [308.0, 102.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1216 q_vals: [-6.57, -6.539, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]Step 515 1 visits [308.0, 103.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1218 q_vals: [-6.57, -6.551, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]Step 516 1 visits [308.0, 104.0, 1.0, 5.0, 6.0, 10.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1222 q_vals: [-6.57, -6.678, -9.762, -9.639, -7.6, -7.212, -10.834, -6.752, -8.264, -7.737]{"total_number_of_episodes": 1223, "number_of_timesteps": 23217, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.006111111111111119, "biggest_recent_change": 0.14999999999999858},
Step 517 5 visits [308.0, 104.0, 1.0, 5.0, 6.0, 11.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1223 q_vals: [-6.57, -6.678, -9.762, -9.639, -7.6, -8.353, -10.834, -6.752, -8.264, -7.737]Step 518 0 visits [309.0, 104.0, 1.0, 5.0, 6.0, 11.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1227 q_vals: [-6.549, -6.678, -9.762, -9.639, -7.6, -8.353, -10.834, -6.752, -8.264, -7.737]Step 519 0 visits [310.0, 104.0, 1.0, 5.0, 6.0, 11.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1230 q_vals: [-6.591, -6.678, -9.762, -9.639, -7.6, -8.353, -10.834, -6.752, -8.264, -7.737]Step 520 1 visits [310.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1231 q_vals: [-6.591, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.752, -8.264, -7.737]{"total_number_of_episodes": 1234, "number_of_timesteps": 23402, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
Step 521 0 visits [311.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 70.0, 5.0, 4.0]  episode_count: 1234 q_vals: [-6.596, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.752, -8.264, -7.737]Step 522 7 visits [311.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 4.0]  episode_count: 1238 q_vals: [-6.596, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.737]Step 523 0 visits [312.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 4.0]  episode_count: 1239 q_vals: [-6.6, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.737]Step 524 0 visits [313.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 4.0]  episode_count: 1242 q_vals: [-6.604, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.737]{"total_number_of_episodes": 1245, "number_of_timesteps": 23596, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.14999999999999858},
Step 525 0 visits [314.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 4.0]  episode_count: 1245 q_vals: [-6.607, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.737]Step 526 0 visits [315.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 4.0]  episode_count: 1248 q_vals: [-6.611, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.737]Step 527 0 visits [316.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 4.0]  episode_count: 1249 q_vals: [-6.615, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.737]Step 528 0 visits [317.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 4.0]  episode_count: 1251 q_vals: [-6.657, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.737]Step 529 9 visits [317.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1253 q_vals: [-6.657, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.77]Step 530 0 visits [318.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1253 q_vals: [-6.661, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.77]{"total_number_of_episodes": 1258, "number_of_timesteps": 23839, "per_episode_reward": 16.25, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.14999999999999858},
Step 531 0 visits [319.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1258 q_vals: [-6.664, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.77]Step 532 0 visits [320.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1260 q_vals: [-6.668, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.77]Step 533 0 visits [321.0, 105.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1260 q_vals: [-6.709, -6.802, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.77]Step 534 1 visits [321.0, 106.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1265 q_vals: [-6.709, -6.813, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.77]Step 535 1 visits [321.0, 107.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1266 q_vals: [-6.709, -6.823, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.77]{"total_number_of_episodes": 1269, "number_of_timesteps": 24087, "per_episode_reward": 16.2, "episode_reward_trend_value": -0.003888888888888905, "biggest_recent_change": 0.14999999999999858},
Step 536 0 visits [322.0, 107.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1269 q_vals: [-6.705, -6.823, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.77]Step 537 0 visits [323.0, 107.0, 1.0, 5.0, 6.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1270 q_vals: [-6.745, -6.823, -9.762, -9.639, -7.6, -8.353, -10.834, -6.936, -8.264, -7.77]Step 538 4 visits [323.0, 107.0, 1.0, 5.0, 7.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1270 q_vals: [-6.745, -6.823, -9.762, -9.639, -7.643, -8.353, -10.834, -6.936, -8.264, -7.77]Step 539 1 visits [323.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1274 q_vals: [-6.745, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.936, -8.264, -7.77]Step 540 0 visits [324.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1277 q_vals: [-6.748, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.936, -8.264, -7.77]{"total_number_of_episodes": 1279, "number_of_timesteps": 24319, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
Step 541 0 visits [325.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1279 q_vals: [-6.751, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.936, -8.264, -7.77]Step 542 0 visits [326.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1280 q_vals: [-6.74, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.936, -8.264, -7.77]Step 543 0 visits [327.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1285 q_vals: [-6.744, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.936, -8.264, -7.77]Step 544 0 visits [328.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 71.0, 5.0, 5.0]  episode_count: 1286 q_vals: [-6.783, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.936, -8.264, -7.77]Step 545 7 visits [328.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 5.0]  episode_count: 1288 q_vals: [-6.783, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -7.77]{"total_number_of_episodes": 1289, "number_of_timesteps": 24499, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 546 0 visits [329.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 5.0]  episode_count: 1289 q_vals: [-6.763, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -7.77]Step 547 0 visits [330.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 5.0]  episode_count: 1290 q_vals: [-6.766, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -7.77]Step 548 0 visits [331.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 5.0]  episode_count: 1292 q_vals: [-6.746, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -7.77]Step 549 0 visits [332.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 5.0]  episode_count: 1292 q_vals: [-6.749, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -7.77]Step 550 0 visits [333.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 5.0]  episode_count: 1295 q_vals: [-6.749, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -7.77]{"total_number_of_episodes": 1299, "number_of_timesteps": 24735, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 551 0 visits [334.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 5.0]  episode_count: 1299 q_vals: [-6.752, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -7.77]Step 552 0 visits [335.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 5.0]  episode_count: 1301 q_vals: [-6.756, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -7.77]Step 553 0 visits [336.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 5.0]  episode_count: 1304 q_vals: [-6.759, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -7.77]Step 554 0 visits [337.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 5.0]  episode_count: 1306 q_vals: [-6.763, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -7.77]Step 555 0 visits [338.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 5.0]  episode_count: 1308 q_vals: [-6.801, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -7.77]{"total_number_of_episodes": 1310, "number_of_timesteps": 24972, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.10000000000000142},
Step 556 9 visits [338.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 72.0, 5.0, 6.0]  episode_count: 1310 q_vals: [-6.801, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.949, -8.264, -9.767]Step 557 7 visits [338.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 73.0, 5.0, 6.0]  episode_count: 1313 q_vals: [-6.801, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.962, -8.264, -9.767]Step 558 0 visits [339.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 73.0, 5.0, 6.0]  episode_count: 1315 q_vals: [-6.837, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -6.962, -8.264, -9.767]Step 559 7 visits [339.0, 108.0, 1.0, 5.0, 7.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1317 q_vals: [-6.837, -6.942, -9.762, -9.639, -7.643, -8.353, -10.834, -7.135, -8.264, -9.767]{"total_number_of_episodes": 1321, "number_of_timesteps": 25185, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.10000000000000142},
Step 560 4 visits [339.0, 108.0, 1.0, 5.0, 8.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1321 q_vals: [-6.837, -6.942, -9.762, -9.639, -7.675, -8.353, -10.834, -7.135, -8.264, -9.767]Step 561 0 visits [340.0, 108.0, 1.0, 5.0, 8.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1322 q_vals: [-6.875, -6.942, -9.762, -9.639, -7.675, -8.353, -10.834, -7.135, -8.264, -9.767]Step 562 1 visits [340.0, 109.0, 1.0, 5.0, 8.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1326 q_vals: [-6.875, -7.06, -9.762, -9.639, -7.675, -8.353, -10.834, -7.135, -8.264, -9.767]Step 563 0 visits [341.0, 109.0, 1.0, 5.0, 8.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1327 q_vals: [-6.878, -7.06, -9.762, -9.639, -7.675, -8.353, -10.834, -7.135, -8.264, -9.767]Step 564 0 visits [342.0, 109.0, 1.0, 5.0, 8.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1328 q_vals: [-6.915, -7.06, -9.762, -9.639, -7.675, -8.353, -10.834, -7.135, -8.264, -9.767]{"total_number_of_episodes": 1331, "number_of_timesteps": 25357, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 565 0 visits [343.0, 109.0, 1.0, 5.0, 8.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1331 q_vals: [-6.895, -7.06, -9.762, -9.639, -7.675, -8.353, -10.834, -7.135, -8.264, -9.767]Step 566 0 visits [344.0, 109.0, 1.0, 5.0, 8.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1336 q_vals: [-6.932, -7.06, -9.762, -9.639, -7.675, -8.353, -10.834, -7.135, -8.264, -9.767]Step 567 4 visits [344.0, 109.0, 1.0, 5.0, 9.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1337 q_vals: [-6.932, -7.06, -9.762, -9.639, -7.701, -8.353, -10.834, -7.135, -8.264, -9.767]Step 568 0 visits [345.0, 109.0, 1.0, 5.0, 9.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1337 q_vals: [-6.932, -7.06, -9.762, -9.639, -7.701, -8.353, -10.834, -7.135, -8.264, -9.767]{"total_number_of_episodes": 1342, "number_of_timesteps": 25602, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
Step 569 0 visits [346.0, 109.0, 1.0, 5.0, 9.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1342 q_vals: [-6.935, -7.06, -9.762, -9.639, -7.701, -8.353, -10.834, -7.135, -8.264, -9.767]Step 570 0 visits [347.0, 109.0, 1.0, 5.0, 9.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1342 q_vals: [-6.972, -7.06, -9.762, -9.639, -7.701, -8.353, -10.834, -7.135, -8.264, -9.767]Step 571 1 visits [347.0, 110.0, 1.0, 5.0, 9.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1345 q_vals: [-6.972, -7.077, -9.762, -9.639, -7.701, -8.353, -10.834, -7.135, -8.264, -9.767]Step 572 0 visits [348.0, 110.0, 1.0, 5.0, 9.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1349 q_vals: [-6.975, -7.077, -9.762, -9.639, -7.701, -8.353, -10.834, -7.135, -8.264, -9.767]Step 573 1 visits [348.0, 111.0, 1.0, 5.0, 9.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1350 q_vals: [-6.975, -7.04, -9.762, -9.639, -7.701, -8.353, -10.834, -7.135, -8.264, -9.767]{"total_number_of_episodes": 1352, "number_of_timesteps": 25756, "per_episode_reward": 16.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 574 1 visits [348.0, 112.0, 1.0, 5.0, 9.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1352 q_vals: [-6.975, -7.135, -9.762, -9.639, -7.701, -8.353, -10.834, -7.135, -8.264, -9.767]Step 575 0 visits [349.0, 112.0, 1.0, 5.0, 9.0, 11.0, 3.0, 74.0, 5.0, 6.0]  episode_count: 1354 q_vals: [-7.011, -7.135, -9.762, -9.639, -7.701, -8.353, -10.834, -7.135, -8.264, -9.767]Step 576 7 visits [349.0, 112.0, 1.0, 5.0, 9.0, 11.0, 3.0, 75.0, 5.0, 6.0]  episode_count: 1354 q_vals: [-7.011, -7.135, -9.762, -9.639, -7.701, -8.353, -10.834, -7.04, -8.264, -9.767]Step 577 7 visits [349.0, 112.0, 1.0, 5.0, 9.0, 11.0, 3.0, 76.0, 5.0, 6.0]  episode_count: 1360 q_vals: [-7.011, -7.135, -9.762, -9.639, -7.701, -8.353, -10.834, -7.051, -8.264, -9.767]{"total_number_of_episodes": 1362, "number_of_timesteps": 26003, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
Step 578 7 visits [349.0, 112.0, 1.0, 5.0, 9.0, 11.0, 3.0, 77.0, 5.0, 6.0]  episode_count: 1362 q_vals: [-7.011, -7.135, -9.762, -9.639, -7.701, -8.353, -10.834, -6.959, -8.264, -9.767]Step 579 7 visits [349.0, 112.0, 1.0, 5.0, 9.0, 11.0, 3.0, 78.0, 5.0, 6.0]  episode_count: 1363 q_vals: [-7.011, -7.135, -9.762, -9.639, -7.701, -8.353, -10.834, -7.123, -8.264, -9.767]Step 580 7 visits [349.0, 112.0, 1.0, 5.0, 9.0, 11.0, 3.0, 79.0, 5.0, 6.0]  episode_count: 1365 q_vals: [-7.011, -7.135, -9.762, -9.639, -7.701, -8.353, -10.834, -7.133, -8.264, -9.767]Step 581 7 visits [349.0, 112.0, 1.0, 5.0, 9.0, 11.0, 3.0, 80.0, 5.0, 6.0]  episode_count: 1368 q_vals: [-7.011, -7.135, -9.762, -9.639, -7.701, -8.353, -10.834, -7.044, -8.264, -9.767]Step 582 7 visits [349.0, 112.0, 1.0, 5.0, 9.0, 11.0, 3.0, 81.0, 5.0, 6.0]  episode_count: 1371 q_vals: [-7.011, -7.135, -9.762, -9.639, -7.701, -8.353, -10.834, -7.051, -8.264, -9.767]{"total_number_of_episodes": 1372, "number_of_timesteps": 26179, "per_episode_reward": 16.35, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999787},
Step 583 7 visits [349.0, 112.0, 1.0, 5.0, 9.0, 11.0, 3.0, 82.0, 5.0, 6.0]  episode_count: 1372 q_vals: [-7.011, -7.135, -9.762, -9.639, -7.701, -8.353, -10.834, -7.206, -8.264, -9.767]Step 584 4 visits [349.0, 112.0, 1.0, 5.0, 10.0, 11.0, 3.0, 82.0, 5.0, 6.0]  episode_count: 1374 q_vals: [-7.011, -7.135, -9.762, -9.639, -7.676, -8.353, -10.834, -7.206, -8.264, -9.767]Step 585 0 visits [350.0, 112.0, 1.0, 5.0, 10.0, 11.0, 3.0, 82.0, 5.0, 6.0]  episode_count: 1375 q_vals: [-6.991, -7.135, -9.762, -9.639, -7.676, -8.353, -10.834, -7.206, -8.264, -9.767]Step 586 0 visits [351.0, 112.0, 1.0, 5.0, 10.0, 11.0, 3.0, 82.0, 5.0, 6.0]  episode_count: 1376 q_vals: [-6.994, -7.135, -9.762, -9.639, -7.676, -8.353, -10.834, -7.206, -8.264, -9.767]Step 587 0 visits [352.0, 112.0, 1.0, 5.0, 10.0, 11.0, 3.0, 82.0, 5.0, 6.0]  episode_count: 1380 q_vals: [-7.03, -7.135, -9.762, -9.639, -7.676, -8.353, -10.834, -7.206, -8.264, -9.767]{"total_number_of_episodes": 1383, "number_of_timesteps": 26486, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
Step 588 4 visits [352.0, 112.0, 1.0, 5.0, 11.0, 11.0, 3.0, 82.0, 5.0, 6.0]  episode_count: 1383 q_vals: [-7.03, -7.135, -9.762, -9.639, -8.774, -8.353, -10.834, -7.206, -8.264, -9.767]Step 589 0 visits [353.0, 112.0, 1.0, 5.0, 11.0, 11.0, 3.0, 82.0, 5.0, 6.0]  episode_count: 1385 q_vals: [-7.066, -7.135, -9.762, -9.639, -8.774, -8.353, -10.834, -7.206, -8.264, -9.767]Step 590 1 visits [353.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 82.0, 5.0, 6.0]  episode_count: 1387 q_vals: [-7.066, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.206, -8.264, -9.767]Step 591 7 visits [353.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 83.0, 5.0, 6.0]  episode_count: 1390 q_vals: [-7.066, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.214, -8.264, -9.767]Step 592 0 visits [354.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 83.0, 5.0, 6.0]  episode_count: 1390 q_vals: [-7.069, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.214, -8.264, -9.767]Step 593 0 visits [355.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 83.0, 5.0, 6.0]  episode_count: 1392 q_vals: [-7.104, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.214, -8.264, -9.767]{"total_number_of_episodes": 1395, "number_of_timesteps": 26721, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 594 7 visits [355.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 84.0, 5.0, 6.0]  episode_count: 1395 q_vals: [-7.104, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.128, -8.264, -9.767]Step 595 7 visits [355.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 85.0, 5.0, 6.0]  episode_count: 1398 q_vals: [-7.104, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.137, -8.264, -9.767]Step 596 7 visits [355.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 86.0, 5.0, 6.0]  episode_count: 1400 q_vals: [-7.104, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.145, -8.264, -9.767]Step 597 7 visits [355.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 87.0, 5.0, 6.0]  episode_count: 1400 q_vals: [-7.104, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.147, -8.264, -9.767]Step 598 7 visits [355.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1402 q_vals: [-7.104, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 599 0 visits [356.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1404 q_vals: [-7.106, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 600 0 visits [357.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1404 q_vals: [-7.1, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]{"total_number_of_episodes": 1406, "number_of_timesteps": 26950, "per_episode_reward": 16.3, "episode_reward_trend_value": -0.0011111111111110875, "biggest_recent_change": 0.14999999999999858},
Step 601 0 visits [358.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1406 q_vals: [-7.103, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 602 0 visits [359.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1409 q_vals: [-7.105, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 603 0 visits [360.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1413 q_vals: [-7.107, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 604 0 visits [361.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1414 q_vals: [-7.087, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 605 0 visits [362.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1415 q_vals: [-7.081, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]{"total_number_of_episodes": 1420, "number_of_timesteps": 27300, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.14999999999999858},
Step 606 0 visits [363.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1420 q_vals: [-7.116, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 607 0 visits [364.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1421 q_vals: [-7.118, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 608 0 visits [365.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1423 q_vals: [-7.12, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 609 0 visits [366.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1424 q_vals: [-7.122, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 610 0 visits [367.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1427 q_vals: [-7.124, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 611 0 visits [368.0, 113.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1429 q_vals: [-7.159, -7.247, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]{"total_number_of_episodes": 1430, "number_of_timesteps": 27502, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.14999999999999858},
Step 612 1 visits [368.0, 114.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1430 q_vals: [-7.159, -7.253, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 613 1 visits [368.0, 115.0, 1.0, 5.0, 11.0, 11.0, 3.0, 88.0, 5.0, 6.0]  episode_count: 1431 q_vals: [-7.159, -7.258, -9.762, -9.639, -8.774, -8.353, -10.834, -7.29, -8.264, -9.767]Step 614 7 visits [368.0, 115.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1434 q_vals: [-7.159, -7.258, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]Step 615 1 visits [368.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1436 q_vals: [-7.159, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]Step 616 0 visits [369.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1437 q_vals: [-7.161, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]Step 617 0 visits [370.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1439 q_vals: [-7.163, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]{"total_number_of_episodes": 1441, "number_of_timesteps": 27743, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.000555555555555524, "biggest_recent_change": 0.14999999999999858},
Step 618 0 visits [371.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1441 q_vals: [-7.165, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]Step 619 0 visits [372.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1444 q_vals: [-7.167, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]Step 620 0 visits [373.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1445 q_vals: [-7.169, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]Step 621 0 visits [374.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1450 q_vals: [-7.171, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]Step 622 0 visits [375.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1450 q_vals: [-7.173, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]{"total_number_of_episodes": 1453, "number_of_timesteps": 28054, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000284},
Step 623 0 visits [376.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1453 q_vals: [-7.206, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]Step 624 0 visits [377.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1458 q_vals: [-7.239, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]Step 625 0 visits [378.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 5.0, 6.0]  episode_count: 1458 q_vals: [-7.272, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -8.264, -9.767]Step 626 8 visits [378.0, 116.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1460 q_vals: [-7.272, -7.366, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]{"total_number_of_episodes": 1464, "number_of_timesteps": 28227, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.20000000000000284},
Step 627 1 visits [378.0, 117.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1464 q_vals: [-7.272, -7.303, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]Step 628 1 visits [378.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1467 q_vals: [-7.272, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]Step 629 0 visits [379.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1468 q_vals: [-7.274, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]Step 630 0 visits [380.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1469 q_vals: [-7.276, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]Step 631 0 visits [381.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1473 q_vals: [-7.277, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]Step 632 0 visits [382.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1473 q_vals: [-7.279, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]Step 633 0 visits [383.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1473 q_vals: [-7.281, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]{"total_number_of_episodes": 1477, "number_of_timesteps": 28478, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.20000000000000284},
Step 634 0 visits [384.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1477 q_vals: [-7.282, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]Step 635 0 visits [385.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1478 q_vals: [-7.284, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]Step 636 0 visits [386.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1480 q_vals: [-7.285, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]Step 637 0 visits [387.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1482 q_vals: [-7.287, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]Step 638 0 visits [388.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1484 q_vals: [-7.289, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]Step 639 0 visits [389.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 89.0, 6.0, 6.0]  episode_count: 1485 q_vals: [-7.29, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.43, -10.179, -9.767]{"total_number_of_episodes": 1490, "number_of_timesteps": 28805, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.20000000000000284},
Step 640 7 visits [389.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 90.0, 6.0, 6.0]  episode_count: 1490 q_vals: [-7.29, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.436, -10.179, -9.767]Step 641 0 visits [390.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 90.0, 6.0, 6.0]  episode_count: 1493 q_vals: [-7.322, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.436, -10.179, -9.767]Step 642 7 visits [390.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 91.0, 6.0, 6.0]  episode_count: 1494 q_vals: [-7.322, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.441, -10.179, -9.767]Step 643 7 visits [390.0, 118.0, 1.0, 5.0, 11.0, 11.0, 3.0, 92.0, 6.0, 6.0]  episode_count: 1497 q_vals: [-7.322, -7.409, -9.762, -9.639, -8.774, -8.353, -10.834, -7.446, -10.179, -9.767]{"total_number_of_episodes": 1501, "number_of_timesteps": 29009, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.20000000000000284},
Step 644 1 visits [390.0, 119.0, 1.0, 5.0, 11.0, 11.0, 3.0, 92.0, 6.0, 6.0]  episode_count: 1501 q_vals: [-7.322, -7.413, -9.762, -9.639, -8.774, -8.353, -10.834, -7.446, -10.179, -9.767]Step 645 1 visits [390.0, 120.0, 1.0, 5.0, 11.0, 11.0, 3.0, 92.0, 6.0, 6.0]  episode_count: 1501 q_vals: [-7.322, -7.516, -9.762, -9.639, -8.774, -8.353, -10.834, -7.446, -10.179, -9.767]Step 646 7 visits [390.0, 120.0, 1.0, 5.0, 11.0, 11.0, 3.0, 93.0, 6.0, 6.0]  episode_count: 1501 q_vals: [-7.322, -7.516, -9.762, -9.639, -8.774, -8.353, -10.834, -7.366, -10.179, -9.767]Step 647 7 visits [390.0, 120.0, 1.0, 5.0, 11.0, 11.0, 3.0, 94.0, 6.0, 6.0]  episode_count: 1506 q_vals: [-7.322, -7.516, -9.762, -9.639, -8.774, -8.353, -10.834, -7.48, -10.179, -9.767]Step 648 0 visits [391.0, 120.0, 1.0, 5.0, 11.0, 11.0, 3.0, 94.0, 6.0, 6.0]  episode_count: 1507 q_vals: [-7.324, -7.516, -9.762, -9.639, -8.774, -8.353, -10.834, -7.48, -10.179, -9.767]Step 649 0 visits [392.0, 120.0, 1.0, 5.0, 11.0, 11.0, 3.0, 94.0, 6.0, 6.0]  episode_count: 1508 q_vals: [-7.323, -7.516, -9.762, -9.639, -8.774, -8.353, -10.834, -7.48, -10.179, -9.767]{"total_number_of_episodes": 1513, "number_of_timesteps": 29301, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.20000000000000284},
Step 650 0 visits [393.0, 120.0, 1.0, 5.0, 11.0, 11.0, 3.0, 94.0, 6.0, 6.0]  episode_count: 1513 q_vals: [-7.354, -7.516, -9.762, -9.639, -8.774, -8.353, -10.834, -7.48, -10.179, -9.767]Step 651 2 visits [393.0, 120.0, 2.0, 5.0, 11.0, 11.0, 3.0, 94.0, 6.0, 6.0]  episode_count: 1514 q_vals: [-7.354, -7.516, -4.881, -9.639, -8.774, -8.353, -10.834, -7.48, -10.179, -9.767]Step 652 2 visits [393.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 94.0, 6.0, 6.0]  episode_count: 1516 q_vals: [-7.354, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.48, -10.179, -9.767]Step 653 7 visits [393.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1518 q_vals: [-7.354, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 654 0 visits [394.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1520 q_vals: [-7.356, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 655 0 visits [395.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1522 q_vals: [-7.357, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]{"total_number_of_episodes": 1524, "number_of_timesteps": 29508, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.20000000000000284},
Step 656 0 visits [396.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1524 q_vals: [-7.359, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 657 0 visits [397.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1525 q_vals: [-7.39, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 658 0 visits [398.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1528 q_vals: [-7.391, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 659 0 visits [399.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1531 q_vals: [-7.392, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 660 0 visits [400.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1531 q_vals: [-7.394, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 661 0 visits [401.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1532 q_vals: [-7.395, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]{"total_number_of_episodes": 1538, "number_of_timesteps": 29830, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.20000000000000284},
Step 662 0 visits [402.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1538 q_vals: [-7.396, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 663 0 visits [403.0, 120.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1539 q_vals: [-7.427, -7.516, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 664 1 visits [403.0, 121.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1539 q_vals: [-7.427, -7.454, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 665 1 visits [403.0, 122.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1539 q_vals: [-7.427, -7.457, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 666 1 visits [403.0, 123.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1542 q_vals: [-7.427, -7.461, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 667 1 visits [403.0, 124.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1543 q_vals: [-7.427, -7.56, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 668 0 visits [404.0, 124.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1545 q_vals: [-7.428, -7.56, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]{"total_number_of_episodes": 1548, "number_of_timesteps": 30131, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.20000000000000284},
Step 669 0 visits [405.0, 124.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1548 q_vals: [-7.458, -7.56, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 670 1 visits [405.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1550 q_vals: [-7.458, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 671 0 visits [406.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1552 q_vals: [-7.459, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 672 0 visits [407.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1553 q_vals: [-7.461, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 673 0 visits [408.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1554 q_vals: [-7.462, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 674 0 visits [409.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 95.0, 6.0, 6.0]  episode_count: 1554 q_vals: [-7.492, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.609, -10.179, -9.767]Step 675 7 visits [409.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 96.0, 6.0, 6.0]  episode_count: 1557 q_vals: [-7.492, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.583, -10.179, -9.767]{"total_number_of_episodes": 1561, "number_of_timesteps": 30450, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 676 7 visits [409.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1561 q_vals: [-7.492, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 677 0 visits [410.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1563 q_vals: [-7.522, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 678 0 visits [411.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1565 q_vals: [-7.551, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 679 0 visits [412.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1567 q_vals: [-7.552, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]{"total_number_of_episodes": 1571, "number_of_timesteps": 30697, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 680 0 visits [413.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1571 q_vals: [-7.551, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 681 0 visits [414.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1575 q_vals: [-7.532, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 682 0 visits [415.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1575 q_vals: [-7.533, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 683 0 visits [416.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1579 q_vals: [-7.534, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]{"total_number_of_episodes": 1581, "number_of_timesteps": 30858, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 684 0 visits [417.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1581 q_vals: [-7.535, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 685 0 visits [418.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1582 q_vals: [-7.517, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 686 0 visits [419.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1584 q_vals: [-7.546, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 687 0 visits [420.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1587 q_vals: [-7.547, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 688 0 visits [421.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1588 q_vals: [-7.548, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]{"total_number_of_episodes": 1591, "number_of_timesteps": 31066, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 689 0 visits [422.0, 125.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1591 q_vals: [-7.577, -7.658, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 690 1 visits [422.0, 126.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1593 q_vals: [-7.577, -7.659, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 691 1 visits [422.0, 127.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1596 q_vals: [-7.577, -7.599, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 692 1 visits [422.0, 128.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1597 q_vals: [-7.577, -7.602, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]{"total_number_of_episodes": 1602, "number_of_timesteps": 31295, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
Step 693 1 visits [422.0, 129.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1602 q_vals: [-7.577, -7.604, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 694 1 visits [422.0, 130.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1604 q_vals: [-7.577, -7.606, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 695 1 visits [422.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 97.0, 6.0, 6.0]  episode_count: 1606 q_vals: [-7.577, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.708, -10.179, -9.767]Step 696 7 visits [422.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 98.0, 6.0, 6.0]  episode_count: 1607 q_vals: [-7.577, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.71, -10.179, -9.767]Step 697 7 visits [422.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 99.0, 6.0, 6.0]  episode_count: 1609 q_vals: [-7.577, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.712, -10.179, -9.767]{"total_number_of_episodes": 1613, "number_of_timesteps": 31485, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 698 0 visits [423.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 99.0, 6.0, 6.0]  episode_count: 1613 q_vals: [-7.577, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.712, -10.179, -9.767]Step 699 0 visits [424.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 99.0, 6.0, 6.0]  episode_count: 1616 q_vals: [-7.578, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.712, -10.179, -9.767]Step 700 0 visits [425.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 99.0, 6.0, 6.0]  episode_count: 1617 q_vals: [-7.579, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.712, -10.179, -9.767]Step 701 0 visits [426.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 99.0, 6.0, 6.0]  episode_count: 1622 q_vals: [-7.58, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.712, -10.179, -9.767]{"total_number_of_episodes": 1625, "number_of_timesteps": 31691, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 702 7 visits [426.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1625 q_vals: [-7.58, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 703 0 visits [427.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1627 q_vals: [-7.562, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 704 0 visits [428.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1628 q_vals: [-7.59, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 705 0 visits [429.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1631 q_vals: [-7.591, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 706 0 visits [430.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1633 q_vals: [-7.592, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]{"total_number_of_episodes": 1635, "number_of_timesteps": 31846, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 707 0 visits [431.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1635 q_vals: [-7.593, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 708 0 visits [432.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1639 q_vals: [-7.593, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 709 0 visits [433.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1639 q_vals: [-7.594, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 710 0 visits [434.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1642 q_vals: [-7.595, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 711 0 visits [435.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1644 q_vals: [-7.595, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]{"total_number_of_episodes": 1647, "number_of_timesteps": 32119, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 712 0 visits [436.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1647 q_vals: [-7.578, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 713 0 visits [437.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1648 q_vals: [-7.579, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 714 0 visits [438.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1650 q_vals: [-7.58, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 715 0 visits [439.0, 131.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1650 q_vals: [-7.607, -7.699, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 716 1 visits [439.0, 132.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1654 q_vals: [-7.607, -7.7, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]{"total_number_of_episodes": 1658, "number_of_timesteps": 32387, "per_episode_reward": 16.5, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 717 1 visits [439.0, 133.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1658 q_vals: [-7.607, -7.702, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 718 1 visits [439.0, 134.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1658 q_vals: [-7.607, -7.703, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 719 1 visits [439.0, 135.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1660 q_vals: [-7.607, -7.646, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 720 1 visits [439.0, 136.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1666 q_vals: [-7.607, -7.735, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]{"total_number_of_episodes": 1668, "number_of_timesteps": 32558, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 721 0 visits [440.0, 136.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1668 q_vals: [-7.608, -7.735, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 722 0 visits [441.0, 136.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1670 q_vals: [-7.609, -7.735, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 723 0 visits [442.0, 136.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1673 q_vals: [-7.609, -7.735, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 724 0 visits [443.0, 136.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1675 q_vals: [-7.61, -7.735, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 725 0 visits [444.0, 136.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1676 q_vals: [-7.611, -7.735, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]{"total_number_of_episodes": 1680, "number_of_timesteps": 32759, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 726 0 visits [445.0, 136.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1680 q_vals: [-7.608, -7.735, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 727 0 visits [446.0, 136.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1681 q_vals: [-7.609, -7.735, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 728 0 visits [447.0, 136.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1683 q_vals: [-7.609, -7.735, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 729 0 visits [448.0, 136.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1684 q_vals: [-7.636, -7.735, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 730 0 visits [449.0, 136.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1687 q_vals: [-7.663, -7.735, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 731 1 visits [449.0, 137.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1689 q_vals: [-7.663, -7.737, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 732 1 visits [449.0, 138.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1689 q_vals: [-7.663, -7.824, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]{"total_number_of_episodes": 1692, "number_of_timesteps": 33011, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 733 0 visits [450.0, 138.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1692 q_vals: [-7.664, -7.824, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 734 0 visits [451.0, 138.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1696 q_vals: [-7.691, -7.824, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 735 0 visits [452.0, 138.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1697 q_vals: [-7.691, -7.824, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 736 0 visits [453.0, 138.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1698 q_vals: [-7.692, -7.824, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 737 0 visits [454.0, 138.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1700 q_vals: [-7.692, -7.824, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]{"total_number_of_episodes": 1702, "number_of_timesteps": 33274, "per_episode_reward": 16.65, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
Step 738 0 visits [455.0, 138.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1702 q_vals: [-7.693, -7.824, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 739 0 visits [456.0, 138.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1706 q_vals: [-7.693, -7.824, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 740 0 visits [457.0, 138.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1707 q_vals: [-7.693, -7.824, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]Step 741 0 visits [458.0, 138.0, 3.0, 5.0, 11.0, 11.0, 3.0, 100.0, 6.0, 6.0]  episode_count: 1709 q_vals: [-7.72, -7.824, -9.838, -9.639, -8.774, -8.353, -10.834, -7.833, -10.179, -9.767]{"total_number_of_episodes": 1712, "number_of_timesteps": 33482, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999787},
Step 742 7 visits [458.0, 138.0, 3.0, 5.0, 11.0, 11.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1712 q_vals: [-7.72, -7.824, -9.838, -9.639, -8.774, -8.353, -10.834, -7.951, -10.179, -9.767]Step 743 5 visits [458.0, 138.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1715 q_vals: [-7.72, -7.824, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 744 0 visits [459.0, 138.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1715 q_vals: [-7.746, -7.824, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 745 1 visits [459.0, 139.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1717 q_vals: [-7.746, -7.824, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]{"total_number_of_episodes": 1722, "number_of_timesteps": 33687, "per_episode_reward": 16.55, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.09999999999999787},
Step 746 1 visits [459.0, 140.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1722 q_vals: [-7.746, -7.768, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 747 1 visits [459.0, 141.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1724 q_vals: [-7.746, -7.769, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 748 1 visits [459.0, 142.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1724 q_vals: [-7.746, -7.77, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 749 1 visits [459.0, 143.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1726 q_vals: [-7.746, -7.771, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 750 1 visits [459.0, 144.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1729 q_vals: [-7.746, -7.772, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 751 1 visits [459.0, 145.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1730 q_vals: [-7.746, -7.718, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]{"total_number_of_episodes": 1733, "number_of_timesteps": 33921, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
Step 752 1 visits [459.0, 146.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1733 q_vals: [-7.746, -7.72, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 753 1 visits [459.0, 147.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1736 q_vals: [-7.746, -7.802, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 754 1 visits [459.0, 148.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1738 q_vals: [-7.746, -7.749, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 755 1 visits [459.0, 149.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1740 q_vals: [-7.746, -7.75, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]{"total_number_of_episodes": 1743, "number_of_timesteps": 34125, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
Step 756 1 visits [459.0, 150.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1743 q_vals: [-7.746, -7.83, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 757 1 visits [459.0, 151.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1744 q_vals: [-7.746, -7.83, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 758 1 visits [459.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1745 q_vals: [-7.746, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 759 0 visits [460.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1746 q_vals: [-7.746, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 760 0 visits [461.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1749 q_vals: [-7.747, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 761 0 visits [462.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1749 q_vals: [-7.73, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 762 0 visits [463.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1752 q_vals: [-7.73, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]{"total_number_of_episodes": 1753, "number_of_timesteps": 34358, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
Step 763 0 visits [464.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1753 q_vals: [-7.731, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 764 0 visits [465.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1755 q_vals: [-7.731, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 765 0 visits [466.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1756 q_vals: [-7.731, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 766 0 visits [467.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1759 q_vals: [-7.732, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 767 0 visits [468.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1761 q_vals: [-7.715, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]{"total_number_of_episodes": 1763, "number_of_timesteps": 34659, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.14999999999999858},
Step 768 0 visits [469.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1763 q_vals: [-7.716, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 769 0 visits [470.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1763 q_vals: [-7.741, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 770 0 visits [471.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1763 q_vals: [-7.742, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 771 0 visits [472.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1766 q_vals: [-7.742, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 772 0 visits [473.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1770 q_vals: [-7.767, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 773 0 visits [474.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1772 q_vals: [-7.768, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]{"total_number_of_episodes": 1773, "number_of_timesteps": 34920, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
Step 774 0 visits [475.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1773 q_vals: [-7.768, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 775 0 visits [476.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1775 q_vals: [-7.793, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 776 0 visits [477.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1779 q_vals: [-7.793, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 777 0 visits [478.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1780 q_vals: [-7.794, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]Step 778 0 visits [479.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 101.0, 6.0, 6.0]  episode_count: 1781 q_vals: [-7.818, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -7.951, -10.179, -9.767]{"total_number_of_episodes": 1784, "number_of_timesteps": 35151, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
Step 779 7 visits [479.0, 152.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1784 q_vals: [-7.818, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 780 1 visits [479.0, 153.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1785 q_vals: [-7.818, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 781 1 visits [479.0, 154.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1787 q_vals: [-7.818, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 782 0 visits [480.0, 154.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1791 q_vals: [-7.819, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 783 1 visits [480.0, 155.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1793 q_vals: [-7.819, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]{"total_number_of_episodes": 1797, "number_of_timesteps": 35436, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.14999999999999858},
Step 784 0 visits [481.0, 155.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1797 q_vals: [-7.819, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 785 0 visits [482.0, 155.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1798 q_vals: [-7.819, -7.909, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 786 1 visits [482.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1802 q_vals: [-7.819, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 787 0 visits [483.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1803 q_vals: [-7.819, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 788 0 visits [484.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1805 q_vals: [-7.819, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]{"total_number_of_episodes": 1808, "number_of_timesteps": 35630, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
Step 789 0 visits [485.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1808 q_vals: [-7.82, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 790 0 visits [486.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1813 q_vals: [-7.844, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 791 0 visits [487.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1813 q_vals: [-7.839, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 792 0 visits [488.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1817 q_vals: [-7.839, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]{"total_number_of_episodes": 1819, "number_of_timesteps": 35818, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
Step 793 0 visits [489.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1819 q_vals: [-7.839, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 794 0 visits [490.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1821 q_vals: [-7.823, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 795 0 visits [491.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1824 q_vals: [-7.823, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 796 0 visits [492.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1828 q_vals: [-7.807, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]{"total_number_of_episodes": 1829, "number_of_timesteps": 35990, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
Step 797 0 visits [493.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1829 q_vals: [-7.808, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 798 0 visits [494.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1834 q_vals: [-7.792, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 799 0 visits [495.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1837 q_vals: [-7.792, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 800 0 visits [496.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1837 q_vals: [-7.792, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]{"total_number_of_episodes": 1842, "number_of_timesteps": 36178, "per_episode_reward": 16.65, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
Step 801 0 visits [497.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1842 q_vals: [-7.792, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 802 0 visits [498.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1846 q_vals: [-7.777, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 803 0 visits [499.0, 156.0, 3.0, 5.0, 11.0, 12.0, 3.0, 102.0, 6.0, 6.0]  episode_count: 1847 q_vals: [-7.801, -7.985, -9.838, -9.639, -8.774, -9.303, -10.834, -8.066, -10.179, -9.767]Step 804 0 visits [500.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 1851 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]{"total_number_of_episodes": 1853, "number_of_timesteps": 36343, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.018333333333333337, "biggest_recent_change": 1.549999999999999},
Step 805 1 visits [500.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 1853 q_vals: [-inf, -21.875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]Step 806 2 visits [500.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 1856 q_vals: [-inf, -21.875, -8.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]Step 807 3 visits [500.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 1858 q_vals: [-inf, -21.875, -8.75, -8.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]{"total_number_of_episodes": 1863, "number_of_timesteps": 36503, "per_episode_reward": 15.05, "episode_reward_trend_value": -0.019444444444444445, "biggest_recent_change": 1.549999999999999},
Step 808 4 visits [500.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 1863 q_vals: [-inf, -21.875, -8.75, -8.75, -21.875, 0.0, 0.0, 0.0, 0.0, 0.0]Step 809 5 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]  episode_count: 1864 q_vals: [-inf, -21.875, -8.75, -8.75, -21.875, -8.75, 0.0, 0.0, 0.0, 0.0]Step 810 6 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]  episode_count: 1867 q_vals: [-inf, -21.875, -8.75, -8.75, -21.875, -8.75, -21.875, 0.0, 0.0, 0.0]Step 811 7 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]  episode_count: 1871 q_vals: [-inf, -21.875, -8.75, -8.75, -21.875, -8.75, -21.875, -21.875, 0.0, 0.0]{"total_number_of_episodes": 1873, "number_of_timesteps": 36644, "per_episode_reward": 15.05, "episode_reward_trend_value": -0.019444444444444445, "biggest_recent_change": 1.549999999999999},
Step 812 8 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]  episode_count: 1873 q_vals: [-inf, -21.875, -8.75, -8.75, -21.875, -8.75, -21.875, -21.875, -21.875, 0.0]Step 813 9 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 1879 q_vals: [-inf, -21.875, -8.75, -8.75, -21.875, -8.75, -21.875, -21.875, -21.875, -8.75]Step 814 3 visits [500.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 1881 q_vals: [-inf, -21.875, -8.75, -8.75, -21.875, -8.75, -21.875, -21.875, -21.875, -8.75]{"total_number_of_episodes": 1883, "number_of_timesteps": 36782, "per_episode_reward": 15.1, "episode_reward_trend_value": -0.0188888888888889, "biggest_recent_change": 1.549999999999999},
Step 815 5 visits [500.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0]  episode_count: 1883 q_vals: [-inf, -21.875, -8.75, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 816 9 visits [500.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 1889 q_vals: [-inf, -21.875, -8.75, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 817 2 visits [500.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 1890 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 818 3 visits [500.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0]  episode_count: 1891 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]{"total_number_of_episodes": 1894, "number_of_timesteps": 36929, "per_episode_reward": 15.05, "episode_reward_trend_value": -0.019444444444444445, "biggest_recent_change": 1.549999999999999},
Step 819 9 visits [500.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 1894 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 820 3 visits [500.0, 1.0, 2.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 1898 q_vals: [-inf, -21.875, -15.313, -6.562, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 821 3 visits [500.0, 1.0, 2.0, 5.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 1898 q_vals: [-inf, -21.875, -15.313, -7.0, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 822 3 visits [500.0, 1.0, 2.0, 6.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 1901 q_vals: [-inf, -21.875, -15.313, -5.833, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 823 3 visits [500.0, 1.0, 2.0, 7.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 1903 q_vals: [-inf, -21.875, -15.313, -5.0, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]{"total_number_of_episodes": 1905, "number_of_timesteps": 37145, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.549999999999999},
Step 824 3 visits [500.0, 1.0, 2.0, 8.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 1905 q_vals: [-inf, -21.875, -15.313, -7.109, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 825 3 visits [500.0, 1.0, 2.0, 9.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0]  episode_count: 1907 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 826 9 visits [500.0, 1.0, 2.0, 9.0, 1.0, 2.0, 1.0, 1.0, 1.0, 4.0]  episode_count: 1907 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -6.562]Step 827 9 visits [500.0, 1.0, 2.0, 9.0, 1.0, 2.0, 1.0, 1.0, 1.0, 5.0]  episode_count: 1914 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -5.25]{"total_number_of_episodes": 1915, "number_of_timesteps": 37338, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.020000000000000007, "biggest_recent_change": 1.549999999999999},
Step 828 9 visits [500.0, 1.0, 2.0, 9.0, 1.0, 2.0, 1.0, 1.0, 1.0, 6.0]  episode_count: 1915 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.021]Step 829 9 visits [500.0, 1.0, 2.0, 9.0, 1.0, 2.0, 1.0, 1.0, 1.0, 7.0]  episode_count: 1917 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.125]Step 830 9 visits [500.0, 1.0, 2.0, 9.0, 1.0, 2.0, 1.0, 1.0, 1.0, 8.0]  episode_count: 1919 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.203]Step 831 9 visits [500.0, 1.0, 2.0, 9.0, 1.0, 2.0, 1.0, 1.0, 1.0, 9.0]  episode_count: 1921 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.264]Step 832 9 visits [500.0, 1.0, 2.0, 9.0, 1.0, 2.0, 1.0, 1.0, 1.0, 10.0]  episode_count: 1921 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -7.437]{"total_number_of_episodes": 1926, "number_of_timesteps": 37568, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 1.549999999999999},
Step 833 9 visits [500.0, 1.0, 2.0, 9.0, 1.0, 2.0, 1.0, 1.0, 1.0, 11.0]  episode_count: 1926 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 834 3 visits [500.0, 1.0, 2.0, 10.0, 1.0, 2.0, 1.0, 1.0, 1.0, 11.0]  episode_count: 1930 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 835 3 visits [500.0, 1.0, 2.0, 11.0, 1.0, 2.0, 1.0, 1.0, 1.0, 11.0]  episode_count: 1932 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 836 3 visits [500.0, 1.0, 2.0, 12.0, 1.0, 2.0, 1.0, 1.0, 1.0, 11.0]  episode_count: 1934 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]{"total_number_of_episodes": 1938, "number_of_timesteps": 37783, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.01888888888888888, "biggest_recent_change": 1.549999999999999},
Step 837 9 visits [500.0, 1.0, 2.0, 12.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1938 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 838 3 visits [500.0, 1.0, 2.0, 13.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1939 q_vals: [-inf, -21.875, -15.313, -9.76, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 839 3 visits [500.0, 1.0, 2.0, 14.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1940 q_vals: [-inf, -21.875, -15.313, -9.687, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 840 3 visits [500.0, 1.0, 2.0, 15.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1943 q_vals: [-inf, -21.875, -15.313, -9.042, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 841 3 visits [500.0, 1.0, 2.0, 16.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1947 q_vals: [-inf, -21.875, -15.313, -9.023, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]{"total_number_of_episodes": 1948, "number_of_timesteps": 37975, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 842 3 visits [500.0, 1.0, 2.0, 17.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1948 q_vals: [-inf, -21.875, -15.313, -9.007, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 843 3 visits [500.0, 1.0, 2.0, 18.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1953 q_vals: [-inf, -21.875, -15.313, -9.722, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 844 3 visits [500.0, 1.0, 2.0, 19.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1955 q_vals: [-inf, -21.875, -15.313, -9.211, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 845 3 visits [500.0, 1.0, 2.0, 20.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1956 q_vals: [-inf, -21.875, -15.313, -9.187, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 846 3 visits [500.0, 1.0, 2.0, 21.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1957 q_vals: [-inf, -21.875, -15.313, -9.167, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]{"total_number_of_episodes": 1961, "number_of_timesteps": 38200, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 847 3 visits [500.0, 1.0, 2.0, 22.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1961 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 848 3 visits [500.0, 1.0, 2.0, 23.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1964 q_vals: [-inf, -21.875, -15.313, -8.75, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 849 3 visits [500.0, 1.0, 2.0, 24.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1964 q_vals: [-inf, -21.875, -15.313, -8.385, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 850 3 visits [500.0, 1.0, 2.0, 25.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1965 q_vals: [-inf, -21.875, -15.313, -8.925, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 851 3 visits [500.0, 1.0, 2.0, 26.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1967 q_vals: [-inf, -21.875, -15.313, -8.582, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]{"total_number_of_episodes": 1972, "number_of_timesteps": 38440, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 852 3 visits [500.0, 1.0, 2.0, 27.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1972 q_vals: [-inf, -21.875, -15.313, -8.588, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 853 3 visits [500.0, 1.0, 2.0, 28.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1972 q_vals: [-inf, -21.875, -15.313, -8.594, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 854 3 visits [500.0, 1.0, 2.0, 29.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1975 q_vals: [-inf, -21.875, -15.313, -8.599, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 855 3 visits [500.0, 1.0, 2.0, 30.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1976 q_vals: [-inf, -21.875, -15.313, -8.604, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 856 3 visits [500.0, 1.0, 2.0, 31.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1980 q_vals: [-inf, -21.875, -15.313, -9.032, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]{"total_number_of_episodes": 1982, "number_of_timesteps": 38668, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 857 3 visits [500.0, 1.0, 2.0, 32.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1982 q_vals: [-inf, -21.875, -15.313, -9.434, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 858 3 visits [500.0, 1.0, 2.0, 33.0, 1.0, 2.0, 1.0, 1.0, 1.0, 12.0]  episode_count: 1984 q_vals: [-inf, -21.875, -15.313, -9.811, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 859 9 visits [500.0, 1.0, 2.0, 33.0, 1.0, 2.0, 1.0, 1.0, 1.0, 13.0]  episode_count: 1984 q_vals: [-inf, -21.875, -15.313, -9.811, -21.875, -15.313, -21.875, -21.875, -21.875, -9.76]Step 860 9 visits [500.0, 1.0, 2.0, 33.0, 1.0, 2.0, 1.0, 1.0, 1.0, 14.0]  episode_count: 1987 q_vals: [-inf, -21.875, -15.313, -9.811, -21.875, -15.313, -21.875, -21.875, -21.875, -9.687]Step 861 9 visits [500.0, 1.0, 2.0, 33.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 1989 q_vals: [-inf, -21.875, -15.313, -9.811, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 862 3 visits [500.0, 1.0, 2.0, 34.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 1989 q_vals: [-inf, -21.875, -15.313, -9.779, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 863 3 visits [500.0, 1.0, 2.0, 35.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 1990 q_vals: [-inf, -21.875, -15.313, -9.75, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]{"total_number_of_episodes": 1992, "number_of_timesteps": 38857, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 864 3 visits [500.0, 1.0, 2.0, 36.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 1992 q_vals: [-inf, -21.875, -15.313, -9.722, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 865 3 visits [500.0, 1.0, 2.0, 37.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 1993 q_vals: [-inf, -21.875, -15.313, -9.459, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 866 3 visits [500.0, 1.0, 2.0, 38.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 1996 q_vals: [-inf, -21.875, -15.313, -9.211, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 867 3 visits [500.0, 1.0, 2.0, 39.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 1999 q_vals: [-inf, -21.875, -15.313, -9.199, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 868 3 visits [500.0, 1.0, 2.0, 40.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2000 q_vals: [-inf, -21.875, -15.313, -9.516, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]{"total_number_of_episodes": 2002, "number_of_timesteps": 39182, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 869 3 visits [500.0, 1.0, 2.0, 41.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2002 q_vals: [-inf, -21.875, -15.313, -9.497, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 870 3 visits [500.0, 1.0, 2.0, 42.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2005 q_vals: [-inf, -21.875, -15.313, -9.479, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 871 3 visits [500.0, 1.0, 2.0, 43.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2006 q_vals: [-inf, -21.875, -15.313, -9.462, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 872 3 visits [500.0, 1.0, 2.0, 44.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2009 q_vals: [-inf, -21.875, -15.313, -9.446, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]{"total_number_of_episodes": 2013, "number_of_timesteps": 39422, "per_episode_reward": 15.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 873 3 visits [500.0, 1.0, 2.0, 45.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2013 q_vals: [-inf, -21.875, -15.313, -9.431, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 874 3 visits [500.0, 1.0, 2.0, 46.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2015 q_vals: [-inf, -21.875, -15.313, -9.226, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 875 3 visits [500.0, 1.0, 2.0, 47.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2019 q_vals: [-inf, -21.875, -15.313, -9.495, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 876 3 visits [500.0, 1.0, 2.0, 48.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2022 q_vals: [-inf, -21.875, -15.313, -9.297, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]{"total_number_of_episodes": 2024, "number_of_timesteps": 39593, "per_episode_reward": 15.05, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 877 3 visits [500.0, 1.0, 2.0, 49.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2024 q_vals: [-inf, -21.875, -15.313, -9.107, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 878 3 visits [500.0, 1.0, 2.0, 50.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2027 q_vals: [-inf, -21.875, -15.313, -9.362, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 879 3 visits [500.0, 1.0, 2.0, 51.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2032 q_vals: [-inf, -21.875, -15.313, -9.608, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]{"total_number_of_episodes": 2035, "number_of_timesteps": 39738, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.09999999999999964},
Step 880 3 visits [500.0, 1.0, 2.0, 52.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2035 q_vals: [-inf, -21.875, -15.313, -9.844, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 881 3 visits [500.0, 1.0, 2.0, 53.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2040 q_vals: [-inf, -21.875, -15.313, -9.658, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 882 3 visits [500.0, 1.0, 2.0, 54.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2042 q_vals: [-inf, -21.875, -15.313, -9.641, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 883 3 visits [500.0, 1.0, 2.0, 55.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2044 q_vals: [-inf, -21.875, -15.313, -9.864, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]{"total_number_of_episodes": 2049, "number_of_timesteps": 39904, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 884 3 visits [500.0, 1.0, 2.0, 56.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2049 q_vals: [-inf, -21.875, -15.313, -9.844, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 885 3 visits [500.0, 1.0, 2.0, 57.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2052 q_vals: [-inf, -21.875, -15.313, -10.055, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 886 3 visits [500.0, 1.0, 2.0, 58.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2054 q_vals: [-inf, -21.875, -15.313, -10.032, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 887 3 visits [500.0, 1.0, 2.0, 59.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2058 q_vals: [-inf, -21.875, -15.313, -10.011, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]{"total_number_of_episodes": 2062, "number_of_timesteps": 40078, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.09999999999999964},
Step 888 3 visits [500.0, 1.0, 2.0, 60.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2062 q_vals: [-inf, -21.875, -15.313, -10.208, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 889 3 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 15.0]  episode_count: 2062 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.5]Step 890 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 16.0]  episode_count: 2066 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.391]Step 891 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 17.0]  episode_count: 2068 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.294]Step 892 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 18.0]  episode_count: 2071 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.208]{"total_number_of_episodes": 2073, "number_of_timesteps": 40256, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 893 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 19.0]  episode_count: 2073 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.671]Step 894 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 20.0]  episode_count: 2078 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.187]Step 895 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 21.0]  episode_count: 2081 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.792]{"total_number_of_episodes": 2083, "number_of_timesteps": 40414, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 896 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 22.0]  episode_count: 2083 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.744]Step 897 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 23.0]  episode_count: 2086 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.701]Step 898 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 24.0]  episode_count: 2089 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.297]Step 899 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 25.0]  episode_count: 2091 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.925]{"total_number_of_episodes": 2094, "number_of_timesteps": 40593, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 900 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 26.0]  episode_count: 2094 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.918]Step 901 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 27.0]  episode_count: 2097 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.912]Step 902 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 28.0]  episode_count: 2099 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.594]{"total_number_of_episodes": 2104, "number_of_timesteps": 40744, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 903 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 29.0]  episode_count: 2104 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.297]Step 904 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 30.0]  episode_count: 2105 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.312]Step 905 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 31.0]  episode_count: 2107 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.327]Step 906 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 32.0]  episode_count: 2108 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]Step 907 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 33.0]  episode_count: 2112 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.75]{"total_number_of_episodes": 2114, "number_of_timesteps": 40912, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 908 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 34.0]  episode_count: 2114 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.493]Step 909 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 35.0]  episode_count: 2118 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.5]Step 910 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 36.0]  episode_count: 2122 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.507]{"total_number_of_episodes": 2125, "number_of_timesteps": 41098, "per_episode_reward": 15.0, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 911 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 37.0]  episode_count: 2125 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.514]Step 912 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 38.0]  episode_count: 2128 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.52]Step 913 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 39.0]  episode_count: 2134 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.526]Step 914 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 40.0]  episode_count: 2134 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.531]{"total_number_of_episodes": 2138, "number_of_timesteps": 41261, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 915 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 41.0]  episode_count: 2138 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.857]Step 916 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 42.0]  episode_count: 2141 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.854]Step 917 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 43.0]  episode_count: 2145 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.852]Step 918 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 44.0]  episode_count: 2146 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.849]{"total_number_of_episodes": 2151, "number_of_timesteps": 41454, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 919 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 45.0]  episode_count: 2151 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.139]Step 920 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 46.0]  episode_count: 2155 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.13]Step 921 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 47.0]  episode_count: 2156 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -8.936]Step 922 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 48.0]  episode_count: 2158 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.206]{"total_number_of_episodes": 2163, "number_of_timesteps": 41614, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 923 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 49.0]  episode_count: 2163 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.196]Step 924 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 50.0]  episode_count: 2164 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.45]Step 925 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 51.0]  episode_count: 2169 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.694]Step 926 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 52.0]  episode_count: 2172 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.675]{"total_number_of_episodes": 2177, "number_of_timesteps": 41828, "per_episode_reward": 14.95, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 927 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 53.0]  episode_count: 2177 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.906]Step 928 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 54.0]  episode_count: 2177 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.127]Step 929 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 55.0]  episode_count: 2184 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.341]{"total_number_of_episodes": 2187, "number_of_timesteps": 41956, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 930 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 56.0]  episode_count: 2187 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.156]Step 931 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 57.0]  episode_count: 2189 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.132]Step 932 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 58.0]  episode_count: 2195 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.108]{"total_number_of_episodes": 2197, "number_of_timesteps": 42076, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 933 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 59.0]  episode_count: 2197 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.085]Step 934 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 60.0]  episode_count: 2198 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.062]Step 935 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 61.0]  episode_count: 2204 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.898]Step 936 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 62.0]  episode_count: 2206 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.879]{"total_number_of_episodes": 2209, "number_of_timesteps": 42225, "per_episode_reward": 14.9, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 937 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 63.0]  episode_count: 2209 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.861]Step 938 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 64.0]  episode_count: 2214 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.707]Step 939 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 65.0]  episode_count: 2218 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.894]{"total_number_of_episodes": 2223, "number_of_timesteps": 42402, "per_episode_reward": 14.85, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 940 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 66.0]  episode_count: 2223 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.076]Step 941 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 67.0]  episode_count: 2227 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.056]Step 942 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 68.0]  episode_count: 2230 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.037]{"total_number_of_episodes": 2235, "number_of_timesteps": 42538, "per_episode_reward": 14.8, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 943 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 69.0]  episode_count: 2235 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.891]Step 944 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 70.0]  episode_count: 2239 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.875]Step 945 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 71.0]  episode_count: 2243 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.859]{"total_number_of_episodes": 2245, "number_of_timesteps": 42651, "per_episode_reward": 14.75, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
Step 946 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 72.0]  episode_count: 2245 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.844]Step 947 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 73.0]  episode_count: 2250 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.829]Step 948 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 74.0]  episode_count: 2254 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.814]{"total_number_of_episodes": 2257, "number_of_timesteps": 42785, "per_episode_reward": 14.55, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
Step 949 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 75.0]  episode_count: 2257 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.975]Step 950 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 76.0]  episode_count: 2263 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.959]Step 951 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 77.0]  episode_count: 2266 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.943]{"total_number_of_episodes": 2271, "number_of_timesteps": 42929, "per_episode_reward": 14.35, "episode_reward_trend_value": -0.007222222222222225, "biggest_recent_change": 0.20000000000000107},
Step 952 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 78.0]  episode_count: 2271 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.816]Step 953 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 79.0]  episode_count: 2274 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.802]Step 954 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 80.0]  episode_count: 2277 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.789]{"total_number_of_episodes": 2281, "number_of_timesteps": 43050, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.007222222222222206, "biggest_recent_change": 0.20000000000000107},
Step 955 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 81.0]  episode_count: 2281 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.776]Step 956 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 82.0]  episode_count: 2285 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.764]Step 957 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 83.0]  episode_count: 2288 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.752]{"total_number_of_episodes": 2293, "number_of_timesteps": 43184, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
Step 958 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 84.0]  episode_count: 2293 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.635]Step 959 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 85.0]  episode_count: 2296 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.625]Step 960 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 86.0]  episode_count: 2299 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.615]Step 961 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 87.0]  episode_count: 2302 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.571]{"total_number_of_episodes": 2308, "number_of_timesteps": 43361, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
Step 962 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 88.0]  episode_count: 2308 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.562]Step 963 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 89.0]  episode_count: 2309 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.7]Step 964 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 90.0]  episode_count: 2311 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.69]{"total_number_of_episodes": 2318, "number_of_timesteps": 43494, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.006666666666666663, "biggest_recent_change": 0.20000000000000107},
Step 965 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 91.0]  episode_count: 2318 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.824]Step 966 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 92.0]  episode_count: 2318 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.812]Step 967 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 93.0]  episode_count: 2321 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.795]Step 968 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 94.0]  episode_count: 2326 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.924]{"total_number_of_episodes": 2330, "number_of_timesteps": 43664, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.006111111111111099, "biggest_recent_change": 0.20000000000000107},
Step 969 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 95.0]  episode_count: 2330 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.911]Step 970 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 96.0]  episode_count: 2335 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.899]Step 971 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 97.0]  episode_count: 2338 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.887]{"total_number_of_episodes": 2341, "number_of_timesteps": 43782, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.005555555555555555, "biggest_recent_change": 0.20000000000000107},
Step 972 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 98.0]  episode_count: 2341 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.876]Step 973 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 99.0]  episode_count: 2345 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.997]Step 974 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 100.0]  episode_count: 2348 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.897]{"total_number_of_episodes": 2352, "number_of_timesteps": 43917, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.20000000000000107},
Step 975 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 101.0]  episode_count: 2352 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.799]Step 976 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 102.0]  episode_count: 2353 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.703]Step 977 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 103.0]  episode_count: 2357 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.694]Step 978 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 104.0]  episode_count: 2360 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.684]{"total_number_of_episodes": 2365, "number_of_timesteps": 44107, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.20000000000000107},
Step 979 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 105.0]  episode_count: 2365 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.592]Step 980 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 106.0]  episode_count: 2367 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.584]Step 981 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 107.0]  episode_count: 2371 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.576]{"total_number_of_episodes": 2375, "number_of_timesteps": 44228, "per_episode_reward": 14.3, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 982 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 108.0]  episode_count: 2375 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.69]Step 983 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 109.0]  episode_count: 2378 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.802]Step 984 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 110.0]  episode_count: 2381 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.793]{"total_number_of_episodes": 2385, "number_of_timesteps": 44342, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 985 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 111.0]  episode_count: 2385 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.783]Step 986 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 112.0]  episode_count: 2387 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.891]Step 987 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 113.0]  episode_count: 2389 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.881]Step 988 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 114.0]  episode_count: 2393 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.986]Step 989 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 115.0]  episode_count: 2394 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.899]{"total_number_of_episodes": 2397, "number_of_timesteps": 44549, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 990 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 116.0]  episode_count: 2397 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.003]Step 991 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 117.0]  episode_count: 2399 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.992]Step 992 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 118.0]  episode_count: 2403 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -9.981]Step 993 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 119.0]  episode_count: 2405 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.081]{"total_number_of_episodes": 2407, "number_of_timesteps": 44732, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 994 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 120.0]  episode_count: 2407 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.07]Step 995 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 121.0]  episode_count: 2411 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.168]Step 996 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 122.0]  episode_count: 2413 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.085]Step 997 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 123.0]  episode_count: 2415 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.179]{"total_number_of_episodes": 2420, "number_of_timesteps": 44940, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 998 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 124.0]  episode_count: 2420 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.167]Step 999 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 125.0]  episode_count: 2422 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.261]Step 1000 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 126.0]  episode_count: 2424 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.249]Step 1001 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 127.0]  episode_count: 2428 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.215]{"total_number_of_episodes": 2431, "number_of_timesteps": 45114, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1002 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 128.0]  episode_count: 2431 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.203]Step 1003 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 129.0]  episode_count: 2435 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.294]Step 1004 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 130.0]  episode_count: 2437 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.282]Step 1005 9 visits [500.0, 1.0, 2.0, 61.0, 1.0, 2.0, 1.0, 1.0, 1.0, 131.0]  episode_count: 2439 q_vals: [-inf, -21.875, -15.313, -10.4, -21.875, -15.313, -21.875, -21.875, -21.875, -10.357]{"total_number_of_episodes": 2443, "number_of_timesteps": 45266, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1006 3 visits [500.0, 1.0, 2.0, 62.0, 1.0, 2.0, 1.0, 1.0, 1.0, 131.0]  episode_count: 2443 q_vals: [-inf, -21.875, -15.313, -10.336, -21.875, -15.313, -21.875, -21.875, -21.875, -10.357]Step 1007 3 visits [500.0, 1.0, 2.0, 63.0, 1.0, 2.0, 1.0, 1.0, 1.0, 131.0]  episode_count: 2448 q_vals: [-inf, -21.875, -15.313, -10.172, -21.875, -15.313, -21.875, -21.875, -21.875, -10.357]Step 1008 3 visits [500.0, 1.0, 2.0, 64.0, 1.0, 2.0, 1.0, 1.0, 1.0, 131.0]  episode_count: 2450 q_vals: [-inf, -21.875, -15.313, -10.15, -21.875, -15.313, -21.875, -21.875, -21.875, -10.357]Step 1009 3 visits [500.0, 1.0, 2.0, 65.0, 1.0, 2.0, 1.0, 1.0, 1.0, 131.0]  episode_count: 2451 q_vals: [-inf, -21.875, -15.313, -10.129, -21.875, -15.313, -21.875, -21.875, -21.875, -10.357]{"total_number_of_episodes": 2459, "number_of_timesteps": 45492, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1010 3 visits [500.0, 1.0, 2.0, 66.0, 1.0, 2.0, 1.0, 1.0, 1.0, 131.0]  episode_count: 2459 q_vals: [-inf, -21.875, -15.313, -9.975, -21.875, -15.313, -21.875, -21.875, -21.875, -10.357]Step 1011 3 visits [500.0, 1.0, 2.0, 67.0, 1.0, 2.0, 1.0, 1.0, 1.0, 131.0]  episode_count: 2459 q_vals: [-inf, -21.875, -15.313, -9.957, -21.875, -15.313, -21.875, -21.875, -21.875, -10.357]Step 1012 3 visits [500.0, 1.0, 2.0, 68.0, 1.0, 2.0, 1.0, 1.0, 1.0, 131.0]  episode_count: 2462 q_vals: [-inf, -21.875, -15.313, -10.132, -21.875, -15.313, -21.875, -21.875, -21.875, -10.357]Step 1013 3 visits [500.0, 1.0, 2.0, 69.0, 1.0, 2.0, 1.0, 1.0, 1.0, 131.0]  episode_count: 2465 q_vals: [-inf, -21.875, -15.313, -10.294, -21.875, -15.313, -21.875, -21.875, -21.875, -10.357]{"total_number_of_episodes": 2469, "number_of_timesteps": 45626, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1014 3 visits [500.0, 1.0, 2.0, 70.0, 1.0, 2.0, 1.0, 1.0, 1.0, 131.0]  episode_count: 2469 q_vals: [-inf, -21.875, -15.313, -10.272, -21.875, -15.313, -21.875, -21.875, -21.875, -10.357]Step 1015 3 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 131.0]  episode_count: 2472 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.357]Step 1016 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 132.0]  episode_count: 2476 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.345]Step 1017 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 133.0]  episode_count: 2478 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.267]{"total_number_of_episodes": 2483, "number_of_timesteps": 45807, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1018 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 134.0]  episode_count: 2483 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.19]Step 1019 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 135.0]  episode_count: 2486 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.115]Step 1020 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 136.0]  episode_count: 2490 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.101]Step 1021 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 137.0]  episode_count: 2492 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.092]{"total_number_of_episodes": 2495, "number_of_timesteps": 45966, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1022 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 138.0]  episode_count: 2495 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.082]Step 1023 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 139.0]  episode_count: 2500 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.072]Step 1024 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 140.0]  episode_count: 2502 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.063]Step 1025 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 141.0]  episode_count: 2503 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.053]{"total_number_of_episodes": 2507, "number_of_timesteps": 46131, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1026 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 142.0]  episode_count: 2507 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.137]Step 1027 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 143.0]  episode_count: 2511 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.066]Step 1028 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 144.0]  episode_count: 2511 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.996]Step 1029 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 145.0]  episode_count: 2515 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.078]{"total_number_of_episodes": 2517, "number_of_timesteps": 46296, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1030 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 146.0]  episode_count: 2517 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.009]Step 1031 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 147.0]  episode_count: 2519 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.0]Step 1032 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 148.0]  episode_count: 2522 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.992]Step 1033 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 149.0]  episode_count: 2524 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.983]{"total_number_of_episodes": 2527, "number_of_timesteps": 46462, "per_episode_reward": 14.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1034 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 150.0]  episode_count: 2527 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.975]Step 1035 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 151.0]  episode_count: 2532 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.967]Step 1036 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 152.0]  episode_count: 2533 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.959]{"total_number_of_episodes": 2538, "number_of_timesteps": 46642, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1037 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 153.0]  episode_count: 2538 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.951]Step 1038 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 154.0]  episode_count: 2542 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.943]Step 1039 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 155.0]  episode_count: 2544 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.879]Step 1040 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 156.0]  episode_count: 2547 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.872]{"total_number_of_episodes": 2552, "number_of_timesteps": 46826, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1041 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 157.0]  episode_count: 2552 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.865]Step 1042 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 158.0]  episode_count: 2555 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.802]Step 1043 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 159.0]  episode_count: 2556 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.878]{"total_number_of_episodes": 2563, "number_of_timesteps": 46957, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
Step 1044 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 160.0]  episode_count: 2563 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.871]Step 1045 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 161.0]  episode_count: 2564 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.863]Step 1046 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 162.0]  episode_count: 2567 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.802]Step 1047 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 163.0]  episode_count: 2571 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.796]{"total_number_of_episodes": 2575, "number_of_timesteps": 47117, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 1048 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 164.0]  episode_count: 2575 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.736]Step 1049 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 165.0]  episode_count: 2577 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.73]Step 1050 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 166.0]  episode_count: 2579 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.724]Step 1051 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 167.0]  episode_count: 2583 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.797]{"total_number_of_episodes": 2586, "number_of_timesteps": 47289, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1052 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 168.0]  episode_count: 2586 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.791]Step 1053 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 169.0]  episode_count: 2588 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.862]Step 1054 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 170.0]  episode_count: 2592 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.804]Step 1055 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 171.0]  episode_count: 2594 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.798]Step 1056 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 172.0]  episode_count: 2595 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.868]{"total_number_of_episodes": 2600, "number_of_timesteps": 47504, "per_episode_reward": 14.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.09999999999999964},
Step 1057 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 173.0]  episode_count: 2600 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.862]Step 1058 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 174.0]  episode_count: 2602 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.855]Step 1059 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 175.0]  episode_count: 2605 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.924]Step 1060 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 176.0]  episode_count: 2608 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.917]{"total_number_of_episodes": 2610, "number_of_timesteps": 47671, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1061 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 177.0]  episode_count: 2610 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.911]Step 1062 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 178.0]  episode_count: 2611 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.855]Step 1063 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 179.0]  episode_count: 2614 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.922]Step 1064 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 180.0]  episode_count: 2616 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.989]{"total_number_of_episodes": 2621, "number_of_timesteps": 47863, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
Step 1065 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 181.0]  episode_count: 2621 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.982]Step 1066 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 182.0]  episode_count: 2622 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.975]Step 1067 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 183.0]  episode_count: 2626 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.968]Step 1068 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 184.0]  episode_count: 2628 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.962]Step 1069 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 185.0]  episode_count: 2628 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.955]Step 1070 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 186.0]  episode_count: 2629 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.949]{"total_number_of_episodes": 2632, "number_of_timesteps": 48092, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
Step 1071 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 187.0]  episode_count: 2632 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.012]Step 1072 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 188.0]  episode_count: 2632 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.006]Step 1073 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 189.0]  episode_count: 2634 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.953]Step 1074 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 190.0]  episode_count: 2639 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.9]Step 1075 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 191.0]  episode_count: 2639 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.894]Step 1076 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 192.0]  episode_count: 2640 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.888]{"total_number_of_episodes": 2645, "number_of_timesteps": 48384, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1077 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 193.0]  episode_count: 2645 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.883]Step 1078 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 194.0]  episode_count: 2647 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.944]Step 1079 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 195.0]  episode_count: 2649 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.938]Step 1080 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 196.0]  episode_count: 2650 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.932]Step 1081 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 197.0]  episode_count: 2652 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.993]Step 1082 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 198.0]  episode_count: 2653 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.987]{"total_number_of_episodes": 2655, "number_of_timesteps": 48615, "per_episode_reward": 14.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1083 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 199.0]  episode_count: 2655 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.046]Step 1084 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 200.0]  episode_count: 2656 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.996]Step 1085 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 201.0]  episode_count: 2660 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.99]Step 1086 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 202.0]  episode_count: 2661 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.984]Step 1087 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 203.0]  episode_count: 2663 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.935]{"total_number_of_episodes": 2666, "number_of_timesteps": 48880, "per_episode_reward": 14.15, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.09999999999999964},
Step 1088 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 204.0]  episode_count: 2666 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.993]Step 1089 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 205.0]  episode_count: 2668 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.987]Step 1090 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 206.0]  episode_count: 2669 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.981]Step 1091 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 207.0]  episode_count: 2670 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.975]Step 1092 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 208.0]  episode_count: 2675 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.927]{"total_number_of_episodes": 2676, "number_of_timesteps": 49123, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1093 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 209.0]  episode_count: 2676 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.921]Step 1094 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 210.0]  episode_count: 2677 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.916]Step 1095 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 211.0]  episode_count: 2682 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.869]Step 1096 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 212.0]  episode_count: 2684 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.822]Step 1097 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 213.0]  episode_count: 2685 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.879]{"total_number_of_episodes": 2689, "number_of_timesteps": 49367, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1098 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 214.0]  episode_count: 2689 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.874]Step 1099 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 215.0]  episode_count: 2691 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.868]Step 1100 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 216.0]  episode_count: 2691 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.863]Step 1101 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 217.0]  episode_count: 2692 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.919]Step 1102 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 218.0]  episode_count: 2693 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.913]Step 1103 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 219.0]  episode_count: 2694 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.908]Step 1104 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 220.0]  episode_count: 2696 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.903]{"total_number_of_episodes": 2699, "number_of_timesteps": 49612, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1105 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 221.0]  episode_count: 2699 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.897]Step 1106 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 222.0]  episode_count: 2701 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.892]Step 1107 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 223.0]  episode_count: 2702 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.887]Step 1108 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 224.0]  episode_count: 2705 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.941]Step 1109 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 225.0]  episode_count: 2708 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.935]{"total_number_of_episodes": 2712, "number_of_timesteps": 49972, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 1110 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 226.0]  episode_count: 2712 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.891]Step 1111 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 227.0]  episode_count: 2713 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.886]Step 1112 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 228.0]  episode_count: 2715 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.843]Step 1113 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 229.0]  episode_count: 2715 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.896]Step 1114 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 230.0]  episode_count: 2718 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.891]Step 1115 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 231.0]  episode_count: 2719 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.942]{"total_number_of_episodes": 2722, "number_of_timesteps": 50161, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1116 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 232.0]  episode_count: 2722 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.9]Step 1117 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 233.0]  episode_count: 2723 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.951]Step 1118 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 234.0]  episode_count: 2725 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.946]Step 1119 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 235.0]  episode_count: 2725 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.997]Step 1120 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 236.0]  episode_count: 2726 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.047]Step 1121 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 237.0]  episode_count: 2730 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.042]{"total_number_of_episodes": 2732, "number_of_timesteps": 50453, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1122 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 238.0]  episode_count: 2732 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.036]Step 1123 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 239.0]  episode_count: 2733 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.031]Step 1124 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 240.0]  episode_count: 2735 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.025]Step 1125 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 241.0]  episode_count: 2737 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.02]Step 1126 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 242.0]  episode_count: 2737 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.979]Step 1127 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 243.0]  episode_count: 2740 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.974]{"total_number_of_episodes": 2742, "number_of_timesteps": 50714, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1128 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 244.0]  episode_count: 2742 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.969]Step 1129 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 245.0]  episode_count: 2744 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.964]Step 1130 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 246.0]  episode_count: 2748 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.012]Step 1131 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 247.0]  episode_count: 2748 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.007]Step 1132 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 248.0]  episode_count: 2751 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.002]{"total_number_of_episodes": 2754, "number_of_timesteps": 50976, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1133 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 249.0]  episode_count: 2754 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.962]Step 1134 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 250.0]  episode_count: 2755 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.957]Step 1135 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 251.0]  episode_count: 2757 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.952]Step 1136 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 252.0]  episode_count: 2760 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.999]Step 1137 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 253.0]  episode_count: 2762 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -9.994]{"total_number_of_episodes": 2764, "number_of_timesteps": 51196, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1138 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 254.0]  episode_count: 2764 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.041]Step 1139 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 255.0]  episode_count: 2764 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.036]Step 1140 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 256.0]  episode_count: 2769 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.082]Step 1141 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 257.0]  episode_count: 2769 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.077]Step 1142 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 258.0]  episode_count: 2773 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.123]{"total_number_of_episodes": 2776, "number_of_timesteps": 51469, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.049999999999998934},
Step 1143 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 259.0]  episode_count: 2776 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.118]Step 1144 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 260.0]  episode_count: 2777 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.163]Step 1145 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 261.0]  episode_count: 2780 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.157]Step 1146 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 262.0]  episode_count: 2784 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.152]{"total_number_of_episodes": 2786, "number_of_timesteps": 51639, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1147 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 263.0]  episode_count: 2786 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.113]Step 1148 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 264.0]  episode_count: 2787 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.108]Step 1149 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 265.0]  episode_count: 2790 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.07]Step 1150 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 266.0]  episode_count: 2793 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.065]Step 1151 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 267.0]  episode_count: 2795 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.06]{"total_number_of_episodes": 2799, "number_of_timesteps": 51861, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1152 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 268.0]  episode_count: 2799 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.023]Step 1153 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 269.0]  episode_count: 2801 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.018]Step 1154 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 270.0]  episode_count: 2804 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.062]Step 1155 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 271.0]  episode_count: 2807 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.025]{"total_number_of_episodes": 2810, "number_of_timesteps": 52065, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1156 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 272.0]  episode_count: 2810 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.02]Step 1157 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 273.0]  episode_count: 2811 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.015]Step 1158 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 274.0]  episode_count: 2815 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.011]Step 1159 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 275.0]  episode_count: 2816 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.006]Step 1160 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 276.0]  episode_count: 2818 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.049]{"total_number_of_episodes": 2824, "number_of_timesteps": 52290, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1161 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 277.0]  episode_count: 2824 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.045]Step 1162 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 278.0]  episode_count: 2824 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.087]Step 1163 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 279.0]  episode_count: 2828 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.129]Step 1164 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 280.0]  episode_count: 2831 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.093]{"total_number_of_episodes": 2834, "number_of_timesteps": 52469, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1165 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 281.0]  episode_count: 2834 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.135]Step 1166 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 282.0]  episode_count: 2837 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.13]Step 1167 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 283.0]  episode_count: 2840 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.172]Step 1168 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 284.0]  episode_count: 2842 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.167]{"total_number_of_episodes": 2847, "number_of_timesteps": 52652, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1169 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 285.0]  episode_count: 2847 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.162]Step 1170 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 286.0]  episode_count: 2848 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.126]Step 1171 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 287.0]  episode_count: 2849 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.167]Step 1172 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 288.0]  episode_count: 2855 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.162]Step 1173 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 289.0]  episode_count: 2856 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.203]{"total_number_of_episodes": 2857, "number_of_timesteps": 52797, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1174 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 290.0]  episode_count: 2857 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.192]Step 1175 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 291.0]  episode_count: 2861 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.233]Step 1176 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 292.0]  episode_count: 2863 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.228]Step 1177 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 293.0]  episode_count: 2863 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.222]{"total_number_of_episodes": 2871, "number_of_timesteps": 53084, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1178 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 294.0]  episode_count: 2871 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.262]Step 1179 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 295.0]  episode_count: 2872 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.257]Step 1180 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 296.0]  episode_count: 2874 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.252]Step 1181 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 297.0]  episode_count: 2879 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.247]Step 1182 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 298.0]  episode_count: 2880 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.242]{"total_number_of_episodes": 2884, "number_of_timesteps": 53260, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1183 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 299.0]  episode_count: 2884 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.237]Step 1184 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 300.0]  episode_count: 2885 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.203]Step 1185 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 301.0]  episode_count: 2890 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.198]Step 1186 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 302.0]  episode_count: 2891 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.237]Step 1187 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 303.0]  episode_count: 2893 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.275]{"total_number_of_episodes": 2896, "number_of_timesteps": 53454, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1188 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 304.0]  episode_count: 2896 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.241]Step 1189 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 305.0]  episode_count: 2897 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.236]Step 1190 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 306.0]  episode_count: 2899 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.274]Step 1191 9 visits [500.0, 1.0, 2.0, 71.0, 1.0, 2.0, 1.0, 1.0, 1.0, 307.0]  episode_count: 2904 q_vals: [-inf, -21.875, -15.313, -10.435, -21.875, -15.313, -21.875, -21.875, -21.875, -10.312]Step 1192 3 visits [500.0, 1.0, 2.0, 72.0, 1.0, 2.0, 1.0, 1.0, 1.0, 307.0]  episode_count: 2904 q_vals: [-inf, -21.875, -15.313, -10.29, -21.875, -15.313, -21.875, -21.875, -21.875, -10.312]Step 1193 3 visits [500.0, 1.0, 2.0, 73.0, 1.0, 2.0, 1.0, 1.0, 1.0, 307.0]  episode_count: 2905 q_vals: [-inf, -21.875, -15.313, -10.262, -21.875, -15.313, -21.875, -21.875, -21.875, -10.312]{"total_number_of_episodes": 2911, "number_of_timesteps": 53703, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1194 3 visits [500.0, 1.0, 2.0, 74.0, 1.0, 2.0, 1.0, 1.0, 1.0, 307.0]  episode_count: 2911 q_vals: [-inf, -21.875, -15.313, -10.123, -21.875, -15.313, -21.875, -21.875, -21.875, -10.312]Step 1195 3 visits [500.0, 1.0, 2.0, 75.0, 1.0, 2.0, 1.0, 1.0, 1.0, 307.0]  episode_count: 2915 q_vals: [-inf, -21.875, -15.313, -10.28, -21.875, -15.313, -21.875, -21.875, -21.875, -10.312]Step 1196 3 visits [500.0, 1.0, 2.0, 76.0, 1.0, 2.0, 1.0, 1.0, 1.0, 307.0]  episode_count: 2915 q_vals: [-inf, -21.875, -15.313, -10.432, -21.875, -15.313, -21.875, -21.875, -21.875, -10.312]Step 1197 3 visits [500.0, 1.0, 2.0, 77.0, 1.0, 2.0, 1.0, 1.0, 1.0, 307.0]  episode_count: 2920 q_vals: [-inf, -21.875, -15.313, -10.411, -21.875, -15.313, -21.875, -21.875, -21.875, -10.312]{"total_number_of_episodes": 2923, "number_of_timesteps": 53947, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1198 3 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 307.0]  episode_count: 2923 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.312]Step 1199 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 308.0]  episode_count: 2923 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.307]Step 1200 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 309.0]  episode_count: 2925 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.344]Step 1201 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 310.0]  episode_count: 2928 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.311]Step 1202 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 311.0]  episode_count: 2932 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.278]{"total_number_of_episodes": 2934, "number_of_timesteps": 54153, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1203 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 312.0]  episode_count: 2934 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.314]Step 1204 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 313.0]  episode_count: 2935 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.309]Step 1205 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 314.0]  episode_count: 2940 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.346]Step 1206 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 315.0]  episode_count: 2940 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.341]Step 1207 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 316.0]  episode_count: 2943 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.336]{"total_number_of_episodes": 2946, "number_of_timesteps": 54388, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1208 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 317.0]  episode_count: 2946 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.331]Step 1209 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 318.0]  episode_count: 2948 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.326]Step 1210 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 319.0]  episode_count: 2948 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.294]Step 1211 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 320.0]  episode_count: 2950 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.262]Step 1212 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 321.0]  episode_count: 2952 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.257]Step 1213 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 322.0]  episode_count: 2955 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.252]{"total_number_of_episodes": 2956, "number_of_timesteps": 54623, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1214 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 323.0]  episode_count: 2956 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.247]Step 1215 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 324.0]  episode_count: 2959 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.283]Step 1216 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 325.0]  episode_count: 2960 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.319]Step 1217 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 326.0]  episode_count: 2964 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.287]Step 1218 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 327.0]  episode_count: 2965 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.323]{"total_number_of_episodes": 2967, "number_of_timesteps": 54797, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1219 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 328.0]  episode_count: 2967 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.318]Step 1220 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 329.0]  episode_count: 2968 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.287]Step 1221 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 330.0]  episode_count: 2970 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.282]Step 1222 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 331.0]  episode_count: 2972 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.277]Step 1223 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 332.0]  episode_count: 2973 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.273]{"total_number_of_episodes": 2978, "number_of_timesteps": 55126, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1224 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 333.0]  episode_count: 2978 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.268]Step 1225 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 334.0]  episode_count: 2979 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.264]Step 1226 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 335.0]  episode_count: 2980 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.259]Step 1227 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 336.0]  episode_count: 2985 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.255]Step 1228 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 337.0]  episode_count: 2987 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.224]{"total_number_of_episodes": 2988, "number_of_timesteps": 55344, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1229 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 338.0]  episode_count: 2988 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.194]Step 1230 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 339.0]  episode_count: 2989 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.19]Step 1231 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 340.0]  episode_count: 2993 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.16]Step 1232 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 341.0]  episode_count: 2995 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.194]Step 1233 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 342.0]  episode_count: 2996 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.19]{"total_number_of_episodes": 2999, "number_of_timesteps": 55561, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1234 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 343.0]  episode_count: 2999 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.186]Step 1235 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 344.0]  episode_count: 3002 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.156]Step 1236 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 345.0]  episode_count: 3003 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.127]Step 1237 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 346.0]  episode_count: 3005 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.123]Step 1238 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 347.0]  episode_count: 3007 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.152]{"total_number_of_episodes": 3012, "number_of_timesteps": 55798, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1239 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 348.0]  episode_count: 3012 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.148]Step 1240 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 349.0]  episode_count: 3014 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.144]Step 1241 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 350.0]  episode_count: 3018 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.14]Step 1242 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 351.0]  episode_count: 3019 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.111]Step 1243 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 352.0]  episode_count: 3021 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.082]{"total_number_of_episodes": 3026, "number_of_timesteps": 56060, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1244 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 353.0]  episode_count: 3026 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.078]Step 1245 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 354.0]  episode_count: 3028 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.075]Step 1246 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 355.0]  episode_count: 3030 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.071]Step 1247 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 356.0]  episode_count: 3035 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.067]{"total_number_of_episodes": 3036, "number_of_timesteps": 56217, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1248 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 357.0]  episode_count: 3036 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.1]Step 1249 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 358.0]  episode_count: 3040 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.097]Step 1250 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 359.0]  episode_count: 3043 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.068]Step 1251 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 360.0]  episode_count: 3045 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.065]{"total_number_of_episodes": 3049, "number_of_timesteps": 56413, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1252 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 361.0]  episode_count: 3049 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.061]Step 1253 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 362.0]  episode_count: 3050 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.058]Step 1254 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 363.0]  episode_count: 3054 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.03]Step 1255 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 364.0]  episode_count: 3057 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.026]{"total_number_of_episodes": 3059, "number_of_timesteps": 56562, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1256 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 365.0]  episode_count: 3059 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -9.999]Step 1257 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 366.0]  episode_count: 3062 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -9.995]Step 1258 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 367.0]  episode_count: 3066 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -9.992]{"total_number_of_episodes": 3069, "number_of_timesteps": 56715, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1259 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 368.0]  episode_count: 3069 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.024]Step 1260 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 369.0]  episode_count: 3072 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.056]Step 1261 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 370.0]  episode_count: 3076 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.053]Step 1262 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 371.0]  episode_count: 3076 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.049]{"total_number_of_episodes": 3079, "number_of_timesteps": 56872, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1263 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 372.0]  episode_count: 3079 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.046]Step 1264 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 373.0]  episode_count: 3082 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.042]Step 1265 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 374.0]  episode_count: 3085 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.039]Step 1266 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 375.0]  episode_count: 3087 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.036]{"total_number_of_episodes": 3090, "number_of_timesteps": 57050, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1267 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 376.0]  episode_count: 3090 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.009]Step 1268 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 377.0]  episode_count: 3092 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.005]Step 1269 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 378.0]  episode_count: 3096 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.002]Step 1270 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 379.0]  episode_count: 3097 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.034]{"total_number_of_episodes": 3101, "number_of_timesteps": 57210, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1271 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 380.0]  episode_count: 3101 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.065]Step 1272 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 381.0]  episode_count: 3103 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.038]Step 1273 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 382.0]  episode_count: 3105 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.035]Step 1274 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 383.0]  episode_count: 3110 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.009]{"total_number_of_episodes": 3113, "number_of_timesteps": 57431, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1275 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 384.0]  episode_count: 3113 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.04]Step 1276 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 385.0]  episode_count: 3113 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.036]Step 1277 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 386.0]  episode_count: 3114 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.033]Step 1278 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 387.0]  episode_count: 3116 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.03]Step 1279 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 388.0]  episode_count: 3119 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.06]Step 1280 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 389.0]  episode_count: 3121 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.057]Step 1281 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 390.0]  episode_count: 3122 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.087]{"total_number_of_episodes": 3124, "number_of_timesteps": 57648, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1282 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 391.0]  episode_count: 3124 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.084]Step 1283 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 392.0]  episode_count: 3126 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.08]Step 1284 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 393.0]  episode_count: 3127 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.077]Step 1285 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 394.0]  episode_count: 3130 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.107]Step 1286 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 395.0]  episode_count: 3130 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.103]Step 1287 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 396.0]  episode_count: 3132 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.1]{"total_number_of_episodes": 3135, "number_of_timesteps": 57889, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1288 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 397.0]  episode_count: 3135 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.13]Step 1289 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 398.0]  episode_count: 3135 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.159]Step 1290 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 399.0]  episode_count: 3139 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.134]Step 1291 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 400.0]  episode_count: 3142 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.13]Step 1292 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 401.0]  episode_count: 3143 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.159]{"total_number_of_episodes": 3146, "number_of_timesteps": 58211, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1293 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 402.0]  episode_count: 3146 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.189]Step 1294 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 403.0]  episode_count: 3148 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.218]Step 1295 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 404.0]  episode_count: 3151 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.192]Step 1296 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 405.0]  episode_count: 3153 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.167]Step 1297 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 406.0]  episode_count: 3154 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.164]Step 1298 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 407.0]  episode_count: 3155 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.192]{"total_number_of_episodes": 3158, "number_of_timesteps": 58445, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1299 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 408.0]  episode_count: 3158 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.189]Step 1300 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 409.0]  episode_count: 3162 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.217]Step 1301 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 410.0]  episode_count: 3162 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.214]Step 1302 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 411.0]  episode_count: 3165 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.189]Step 1303 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 412.0]  episode_count: 3166 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.217]Step 1304 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 413.0]  episode_count: 3167 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.214]{"total_number_of_episodes": 3169, "number_of_timesteps": 58692, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1305 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 414.0]  episode_count: 3169 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.242]Step 1306 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 415.0]  episode_count: 3172 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.27]Step 1307 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 416.0]  episode_count: 3172 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.266]Step 1308 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 417.0]  episode_count: 3176 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.263]Step 1309 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 418.0]  episode_count: 3178 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.238]{"total_number_of_episodes": 3180, "number_of_timesteps": 58962, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1310 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 419.0]  episode_count: 3180 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.235]Step 1311 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 420.0]  episode_count: 3181 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.262]Step 1312 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 421.0]  episode_count: 3182 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.238]Step 1313 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 422.0]  episode_count: 3184 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.214]Step 1314 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 423.0]  episode_count: 3187 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.21]Step 1315 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 424.0]  episode_count: 3189 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.207]{"total_number_of_episodes": 3191, "number_of_timesteps": 59253, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1316 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 425.0]  episode_count: 3191 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.183]Step 1317 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 426.0]  episode_count: 3193 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.179]Step 1318 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 427.0]  episode_count: 3195 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.207]Step 1319 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 428.0]  episode_count: 3196 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.203]Step 1320 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 429.0]  episode_count: 3198 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.231]Step 1321 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 430.0]  episode_count: 3200 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.207]{"total_number_of_episodes": 3202, "number_of_timesteps": 59485, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1322 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 431.0]  episode_count: 3202 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.183]Step 1323 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 432.0]  episode_count: 3206 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.18]Step 1324 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 433.0]  episode_count: 3207 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.177]Step 1325 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 434.0]  episode_count: 3211 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.173]Step 1326 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 435.0]  episode_count: 3211 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.15]{"total_number_of_episodes": 3213, "number_of_timesteps": 59710, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1327 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 436.0]  episode_count: 3213 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.147]Step 1328 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 437.0]  episode_count: 3216 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.143]Step 1329 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 438.0]  episode_count: 3219 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.14]Step 1330 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 439.0]  episode_count: 3220 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.137]Step 1331 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 440.0]  episode_count: 3221 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.134]{"total_number_of_episodes": 3224, "number_of_timesteps": 59967, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1332 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 441.0]  episode_count: 3224 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.111]Step 1333 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 442.0]  episode_count: 3226 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.108]Step 1334 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 443.0]  episode_count: 3227 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.105]Step 1335 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 444.0]  episode_count: 3231 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.102]{"total_number_of_episodes": 3234, "number_of_timesteps": 60152, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1336 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 445.0]  episode_count: 3234 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.099]Step 1337 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 446.0]  episode_count: 3237 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.125]Step 1338 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 447.0]  episode_count: 3240 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.122]Step 1339 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 448.0]  episode_count: 3242 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.119]{"total_number_of_episodes": 3246, "number_of_timesteps": 60389, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1340 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 449.0]  episode_count: 3246 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.116]Step 1341 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 450.0]  episode_count: 3246 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.142]Step 1342 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 451.0]  episode_count: 3248 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.168]Step 1343 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 452.0]  episode_count: 3250 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.165]Step 1344 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 453.0]  episode_count: 3254 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.143]{"total_number_of_episodes": 3257, "number_of_timesteps": 60611, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1345 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 454.0]  episode_count: 3257 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.12]Step 1346 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 455.0]  episode_count: 3258 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.117]Step 1347 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 456.0]  episode_count: 3265 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.114]Step 1348 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 457.0]  episode_count: 3266 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.111]{"total_number_of_episodes": 3267, "number_of_timesteps": 60754, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1349 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 458.0]  episode_count: 3267 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.137]Step 1350 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 459.0]  episode_count: 3269 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.162]Step 1351 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 460.0]  episode_count: 3270 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.188]Step 1352 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 461.0]  episode_count: 3272 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.185]Step 1353 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 462.0]  episode_count: 3274 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.182]{"total_number_of_episodes": 3280, "number_of_timesteps": 61041, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1354 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 463.0]  episode_count: 3280 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.16]Step 1355 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 464.0]  episode_count: 3281 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.138]Step 1356 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 465.0]  episode_count: 3283 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.163]Step 1357 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 466.0]  episode_count: 3287 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.16]Step 1358 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 467.0]  episode_count: 3288 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.157]{"total_number_of_episodes": 3294, "number_of_timesteps": 61262, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1359 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 468.0]  episode_count: 3294 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.135]Step 1360 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 469.0]  episode_count: 3297 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.16]Step 1361 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 470.0]  episode_count: 3298 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.157]Step 1362 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 471.0]  episode_count: 3299 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.154]Step 1363 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 472.0]  episode_count: 3303 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.151]{"total_number_of_episodes": 3304, "number_of_timesteps": 61413, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1364 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 473.0]  episode_count: 3304 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.148]Step 1365 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 474.0]  episode_count: 3305 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.145]Step 1366 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 475.0]  episode_count: 3308 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.124]Step 1367 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 476.0]  episode_count: 3310 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.149]Step 1368 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 477.0]  episode_count: 3310 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.146]{"total_number_of_episodes": 3314, "number_of_timesteps": 61657, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1369 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 478.0]  episode_count: 3314 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.143]Step 1370 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 479.0]  episode_count: 3314 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.14]Step 1371 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 480.0]  episode_count: 3315 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.137]Step 1372 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 481.0]  episode_count: 3318 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.116]Step 1373 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 482.0]  episode_count: 3322 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.113]Step 1374 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 483.0]  episode_count: 3323 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.138]{"total_number_of_episodes": 3324, "number_of_timesteps": 61896, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1375 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 484.0]  episode_count: 3324 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.162]Step 1376 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 485.0]  episode_count: 3325 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.159]Step 1377 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 486.0]  episode_count: 3330 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.156]Step 1378 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 487.0]  episode_count: 3332 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.18]Step 1379 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 488.0]  episode_count: 3332 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.177]{"total_number_of_episodes": 3334, "number_of_timesteps": 62100, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1380 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 489.0]  episode_count: 3334 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.201]Step 1381 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 490.0]  episode_count: 3338 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.18]Step 1382 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 491.0]  episode_count: 3341 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.177]Step 1383 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 492.0]  episode_count: 3343 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.157]{"total_number_of_episodes": 3346, "number_of_timesteps": 62366, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1384 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 493.0]  episode_count: 3346 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.154]Step 1385 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 494.0]  episode_count: 3348 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.151]Step 1386 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 495.0]  episode_count: 3351 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.13]Step 1387 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 496.0]  episode_count: 3353 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.154]{"total_number_of_episodes": 3357, "number_of_timesteps": 62548, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1388 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 497.0]  episode_count: 3357 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.151]Step 1389 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 498.0]  episode_count: 3360 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.175]Step 1390 9 visits [500.0, 1.0, 2.0, 78.0, 1.0, 2.0, 1.0, 1.0, 1.0, 499.0]  episode_count: 3361 q_vals: [-inf, -21.875, -15.313, -10.558, -21.875, -15.313, -21.875, -21.875, -21.875, -10.198]Step 1391 9 visits [500.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 3361 q_vals: [-inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf]Step 1392 1 visits [500.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 3364 q_vals: [-inf, -24.49, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf]{"total_number_of_episodes": 3368, "number_of_timesteps": 62745, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 1.5999999999999996},
Step 1393 2 visits [500.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 3368 q_vals: [-inf, -24.49, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf]Step 1394 3 visits [500.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 3368 q_vals: [-inf, -24.49, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf]Step 1395 4 visits [500.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 3369 q_vals: [-inf, -24.49, 0.0, 0.0, -9.796, 0.0, 0.0, 0.0, 0.0, -inf]Step 1396 5 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 3371 q_vals: [-inf, -24.49, 0.0, 0.0, -9.796, -24.49, 0.0, 0.0, 0.0, -inf]Step 1397 6 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 500.0]  episode_count: 3372 q_vals: [-inf, -24.49, 0.0, 0.0, -9.796, -24.49, -9.796, 0.0, 0.0, -inf]Step 1398 7 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 500.0]  episode_count: 3374 q_vals: [-inf, -24.49, 0.0, 0.0, -9.796, -24.49, -9.796, -9.796, 0.0, -inf]Step 1399 8 visits [500.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3376 q_vals: [-inf, -24.49, 0.0, 0.0, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1400 2 visits [500.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3377 q_vals: [-inf, -24.49, 0.0, 0.0, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]{"total_number_of_episodes": 3378, "number_of_timesteps": 63022, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 1.5999999999999996},
Step 1401 3 visits [500.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3378 q_vals: [-inf, -24.49, 0.0, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1402 2 visits [500.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3381 q_vals: [-inf, -24.49, 0.0, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1403 2 visits [500.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3383 q_vals: [-inf, -24.49, -6.122, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1404 2 visits [500.0, 1.0, 5.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3386 q_vals: [-inf, -24.49, -6.857, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]{"total_number_of_episodes": 3390, "number_of_timesteps": 63328, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 1.5999999999999996},
Step 1405 2 visits [500.0, 1.0, 6.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3390 q_vals: [-inf, -24.49, -5.714, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1406 2 visits [500.0, 1.0, 7.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3391 q_vals: [-inf, -24.49, -4.898, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1407 2 visits [500.0, 1.0, 8.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3395 q_vals: [-inf, -24.49, -4.286, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1408 2 visits [500.0, 1.0, 9.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3397 q_vals: [-inf, -24.49, -4.898, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]{"total_number_of_episodes": 3400, "number_of_timesteps": 63498, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 1.5999999999999996},
Step 1409 2 visits [500.0, 1.0, 10.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3400 q_vals: [-inf, -24.49, -5.388, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1410 2 visits [500.0, 1.0, 11.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3403 q_vals: [-inf, -24.49, -5.788, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1411 2 visits [500.0, 1.0, 12.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3408 q_vals: [-inf, -24.49, -6.122, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1412 2 visits [500.0, 1.0, 13.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3408 q_vals: [-inf, -24.49, -6.405, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]{"total_number_of_episodes": 3414, "number_of_timesteps": 63691, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 1.5999999999999996},
Step 1413 2 visits [500.0, 1.0, 14.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3414 q_vals: [-inf, -24.49, -5.948, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1414 2 visits [500.0, 1.0, 15.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3415 q_vals: [-inf, -24.49, -6.204, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1415 2 visits [500.0, 1.0, 16.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3416 q_vals: [-inf, -24.49, -6.429, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1416 2 visits [500.0, 1.0, 17.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3419 q_vals: [-inf, -24.49, -6.627, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1417 2 visits [500.0, 1.0, 18.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3422 q_vals: [-inf, -24.49, -6.259, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]{"total_number_of_episodes": 3427, "number_of_timesteps": 63945, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 1.5999999999999996},
Step 1418 2 visits [500.0, 1.0, 19.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3427 q_vals: [-inf, -24.49, -6.445, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1419 2 visits [500.0, 1.0, 20.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3429 q_vals: [-inf, -24.49, -7.347, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1420 2 visits [500.0, 1.0, 21.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3432 q_vals: [-inf, -24.49, -7.464, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1421 2 visits [500.0, 1.0, 22.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3434 q_vals: [-inf, -24.49, -7.57, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]{"total_number_of_episodes": 3438, "number_of_timesteps": 64091, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 1.5999999999999996},
Step 1422 2 visits [500.0, 1.0, 23.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3438 q_vals: [-inf, -24.49, -7.24, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1423 2 visits [500.0, 1.0, 24.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3441 q_vals: [-inf, -24.49, -7.347, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1424 2 visits [500.0, 1.0, 25.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3443 q_vals: [-inf, -24.49, -7.445, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1425 2 visits [500.0, 1.0, 26.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3446 q_vals: [-inf, -24.49, -7.159, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]{"total_number_of_episodes": 3448, "number_of_timesteps": 64253, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 1.5999999999999996},
Step 1426 2 visits [500.0, 1.0, 27.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3448 q_vals: [-inf, -24.49, -7.256, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1427 2 visits [500.0, 1.0, 28.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3449 q_vals: [-inf, -24.49, -7.347, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1428 2 visits [500.0, 1.0, 29.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3453 q_vals: [-inf, -24.49, -7.431, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1429 2 visits [500.0, 1.0, 30.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3454 q_vals: [-inf, -24.49, -8.0, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1430 2 visits [500.0, 1.0, 31.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3457 q_vals: [-inf, -24.49, -7.742, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]{"total_number_of_episodes": 3459, "number_of_timesteps": 64447, "per_episode_reward": 12.6, "episode_reward_trend_value": -0.017777777777777774, "biggest_recent_change": 1.5999999999999996},
Step 1431 2 visits [500.0, 1.0, 32.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3459 q_vals: [-inf, -24.49, -7.806, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1432 2 visits [500.0, 1.0, 33.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3460 q_vals: [-inf, -24.49, -7.57, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1433 2 visits [500.0, 1.0, 34.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3463 q_vals: [-inf, -24.49, -8.067, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1434 2 visits [500.0, 1.0, 35.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3463 q_vals: [-inf, -24.49, -8.117, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1435 2 visits [500.0, 1.0, 36.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3468 q_vals: [-inf, -24.49, -7.891, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]{"total_number_of_episodes": 3470, "number_of_timesteps": 64687, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1436 2 visits [500.0, 1.0, 37.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3470 q_vals: [-inf, -24.49, -7.678, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1437 2 visits [500.0, 1.0, 38.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3471 q_vals: [-inf, -24.49, -7.734, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1438 2 visits [500.0, 1.0, 39.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3475 q_vals: [-inf, -24.49, -8.163, -12.245, -9.796, -24.49, -9.796, -9.796, -9.796, -inf]Step 1439 4 visits [500.0, 1.0, 39.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 500.0]  episode_count: 3475 q_vals: [-inf, -24.49, -8.163, -12.245, -17.143, -24.49, -9.796, -9.796, -9.796, -inf]Step 1440 8 visits [500.0, 1.0, 39.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 500.0]  episode_count: 3478 q_vals: [-inf, -24.49, -8.163, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]Step 1441 6 visits [500.0, 1.0, 39.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 500.0]  episode_count: 3479 q_vals: [-inf, -24.49, -8.163, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]{"total_number_of_episodes": 3483, "number_of_timesteps": 65004, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1442 7 visits [500.0, 1.0, 39.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 500.0]  episode_count: 3483 q_vals: [-inf, -24.49, -8.163, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]Step 1443 2 visits [500.0, 1.0, 40.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 500.0]  episode_count: 3485 q_vals: [-inf, -24.49, -8.204, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]Step 1444 2 visits [500.0, 1.0, 41.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 500.0]  episode_count: 3487 q_vals: [-inf, -24.49, -8.004, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]Step 1445 2 visits [500.0, 1.0, 42.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 500.0]  episode_count: 3489 q_vals: [-inf, -24.49, -8.047, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]Step 1446 2 visits [500.0, 1.0, 43.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 500.0]  episode_count: 3492 q_vals: [-inf, -24.49, -8.087, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]{"total_number_of_episodes": 3494, "number_of_timesteps": 65211, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1447 2 visits [500.0, 1.0, 44.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 500.0]  episode_count: 3494 q_vals: [-inf, -24.49, -8.46, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]Step 1448 2 visits [500.0, 1.0, 45.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 500.0]  episode_count: 3496 q_vals: [-inf, -24.49, -8.49, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]Step 1449 2 visits [500.0, 1.0, 46.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 500.0]  episode_count: 3498 q_vals: [-inf, -24.49, -8.518, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]Step 1450 2 visits [500.0, 1.0, 47.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 500.0]  episode_count: 3501 q_vals: [-inf, -24.49, -8.545, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]Step 1451 2 visits [500.0, 1.0, 48.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 500.0]  episode_count: 3502 q_vals: [-inf, -24.49, -8.571, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]{"total_number_of_episodes": 3505, "number_of_timesteps": 65412, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1452 2 visits [500.0, 1.0, 49.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 500.0]  episode_count: 3505 q_vals: [-inf, -24.49, -8.896, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]Step 1453 6 visits [500.0, 1.0, 49.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 500.0]  episode_count: 3509 q_vals: [-inf, -24.49, -8.896, -12.245, -17.143, -24.49, -9.796, -9.796, -17.143, -inf]Step 1454 7 visits [500.0, 1.0, 49.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 500.0]  episode_count: 3512 q_vals: [-inf, -24.49, -8.896, -12.245, -17.143, -24.49, -9.796, -6.531, -17.143, -inf]Step 1455 7 visits [500.0, 1.0, 49.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 500.0]  episode_count: 3514 q_vals: [-inf, -24.49, -8.896, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]{"total_number_of_episodes": 3518, "number_of_timesteps": 65653, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1456 2 visits [500.0, 1.0, 50.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 500.0]  episode_count: 3518 q_vals: [-inf, -24.49, -8.718, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1457 2 visits [500.0, 1.0, 51.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 500.0]  episode_count: 3518 q_vals: [-inf, -24.49, -8.547, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1458 2 visits [500.0, 1.0, 52.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 500.0]  episode_count: 3518 q_vals: [-inf, -24.49, -8.571, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1459 2 visits [500.0, 1.0, 53.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 500.0]  episode_count: 3523 q_vals: [-inf, -24.49, -8.595, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1460 2 visits [500.0, 1.0, 54.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 500.0]  episode_count: 3524 q_vals: [-inf, -24.49, -8.435, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1461 2 visits [500.0, 1.0, 55.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 500.0]  episode_count: 3526 q_vals: [-inf, -24.49, -8.727, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1462 2 visits [500.0, 1.0, 56.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 500.0]  episode_count: 3527 q_vals: [-inf, -24.49, -8.746, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]{"total_number_of_episodes": 3530, "number_of_timesteps": 65924, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1463 2 visits [500.0, 1.0, 57.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 500.0]  episode_count: 3530 q_vals: [-inf, -24.49, -8.593, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1464 2 visits [500.0, 1.0, 58.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 500.0]  episode_count: 3532 q_vals: [-inf, -24.49, -8.614, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1465 2 visits [500.0, 1.0, 59.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 500.0]  episode_count: 3534 q_vals: [-inf, -24.49, -8.883, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1466 6 visits [500.0, 1.0, 59.0, 2.0, 2.0, 1.0, 4.0, 4.0, 2.0, 500.0]  episode_count: 3537 q_vals: [-inf, -24.49, -8.883, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1467 2 visits [500.0, 1.0, 60.0, 2.0, 2.0, 1.0, 4.0, 4.0, 2.0, 500.0]  episode_count: 3538 q_vals: [-inf, -24.49, -8.898, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]{"total_number_of_episodes": 3541, "number_of_timesteps": 66158, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1468 2 visits [500.0, 1.0, 61.0, 2.0, 2.0, 1.0, 4.0, 4.0, 2.0, 500.0]  episode_count: 3541 q_vals: [-inf, -24.49, -8.913, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1469 2 visits [500.0, 1.0, 62.0, 2.0, 2.0, 1.0, 4.0, 4.0, 2.0, 500.0]  episode_count: 3542 q_vals: [-inf, -24.49, -9.164, -12.245, -17.143, -24.49, -9.796, -11.02, -17.143, -inf]Step 1470 6 visits [500.0, 1.0, 62.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3542 q_vals: [-inf, -24.49, -9.164, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1471 2 visits [500.0, 1.0, 63.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3543 q_vals: [-inf, -24.49, -9.018, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1472 2 visits [500.0, 1.0, 64.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3545 q_vals: [-inf, -24.49, -8.878, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1473 2 visits [500.0, 1.0, 65.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3548 q_vals: [-inf, -24.49, -9.118, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1474 2 visits [500.0, 1.0, 66.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3548 q_vals: [-inf, -24.49, -8.98, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1475 2 visits [500.0, 1.0, 67.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3550 q_vals: [-inf, -24.49, -8.846, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3552, "number_of_timesteps": 66413, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1476 2 visits [500.0, 1.0, 68.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3552 q_vals: [-inf, -24.49, -8.86, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1477 2 visits [500.0, 1.0, 69.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3554 q_vals: [-inf, -24.49, -8.731, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1478 2 visits [500.0, 1.0, 70.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3557 q_vals: [-inf, -24.49, -8.606, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1479 2 visits [500.0, 1.0, 71.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3560 q_vals: [-inf, -24.49, -8.623, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1480 2 visits [500.0, 1.0, 72.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3560 q_vals: [-inf, -24.49, -8.639, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3562, "number_of_timesteps": 66679, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1481 2 visits [500.0, 1.0, 73.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3562 q_vals: [-inf, -24.49, -8.521, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1482 2 visits [500.0, 1.0, 74.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3565 q_vals: [-inf, -24.49, -8.406, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1483 2 visits [500.0, 1.0, 75.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3565 q_vals: [-inf, -24.49, -8.424, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1484 2 visits [500.0, 1.0, 76.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3566 q_vals: [-inf, -24.49, -8.443, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3572, "number_of_timesteps": 66886, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1485 2 visits [500.0, 1.0, 77.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3572 q_vals: [-inf, -24.49, -8.46, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1486 2 visits [500.0, 1.0, 78.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3572 q_vals: [-inf, -24.49, -8.352, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1487 2 visits [500.0, 1.0, 79.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3573 q_vals: [-inf, -24.49, -8.37, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1488 2 visits [500.0, 1.0, 80.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3579 q_vals: [-inf, -24.49, -8.388, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1489 2 visits [500.0, 1.0, 81.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3580 q_vals: [-inf, -24.49, -8.284, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1490 2 visits [500.0, 1.0, 82.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3581 q_vals: [-inf, -24.49, -8.303, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3584, "number_of_timesteps": 67230, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1491 2 visits [500.0, 1.0, 83.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3584 q_vals: [-inf, -24.49, -8.321, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1492 2 visits [500.0, 1.0, 84.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3588 q_vals: [-inf, -24.49, -8.338, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1493 2 visits [500.0, 1.0, 85.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3589 q_vals: [-inf, -24.49, -8.528, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1494 2 visits [500.0, 1.0, 86.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3590 q_vals: [-inf, -24.49, -8.543, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3594, "number_of_timesteps": 67393, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1495 2 visits [500.0, 1.0, 87.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3594 q_vals: [-inf, -24.49, -8.557, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1496 2 visits [500.0, 1.0, 88.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3597 q_vals: [-inf, -24.49, -8.46, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1497 2 visits [500.0, 1.0, 89.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3598 q_vals: [-inf, -24.49, -8.475, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1498 2 visits [500.0, 1.0, 90.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3599 q_vals: [-inf, -24.49, -8.49, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1499 2 visits [500.0, 1.0, 91.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3600 q_vals: [-inf, -24.49, -8.666, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1500 2 visits [500.0, 1.0, 92.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3600 q_vals: [-inf, -24.49, -8.678, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1501 2 visits [500.0, 1.0, 93.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3603 q_vals: [-inf, -24.49, -8.69, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3604, "number_of_timesteps": 67611, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1502 2 visits [500.0, 1.0, 94.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3604 q_vals: [-inf, -24.49, -8.702, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1503 2 visits [500.0, 1.0, 95.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3608 q_vals: [-inf, -24.49, -8.713, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1504 2 visits [500.0, 1.0, 96.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3609 q_vals: [-inf, -24.49, -8.622, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1505 2 visits [500.0, 1.0, 97.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3611 q_vals: [-inf, -24.49, -8.534, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1506 2 visits [500.0, 1.0, 98.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3613 q_vals: [-inf, -24.49, -8.546, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3615, "number_of_timesteps": 67942, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1507 2 visits [500.0, 1.0, 99.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3615 q_vals: [-inf, -24.49, -8.46, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1508 2 visits [500.0, 1.0, 100.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3616 q_vals: [-inf, -24.49, -8.376, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1509 2 visits [500.0, 1.0, 101.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3619 q_vals: [-inf, -24.49, -8.39, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1510 2 visits [500.0, 1.0, 102.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3622 q_vals: [-inf, -24.49, -8.547, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1511 2 visits [500.0, 1.0, 103.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3624 q_vals: [-inf, -24.49, -8.464, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3626, "number_of_timesteps": 68203, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1512 2 visits [500.0, 1.0, 104.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3626 q_vals: [-inf, -24.49, -8.477, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1513 2 visits [500.0, 1.0, 105.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3629 q_vals: [-inf, -24.49, -8.49, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1514 2 visits [500.0, 1.0, 106.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3631 q_vals: [-inf, -24.49, -8.641, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1515 2 visits [500.0, 1.0, 107.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3633 q_vals: [-inf, -24.49, -8.652, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1516 2 visits [500.0, 1.0, 108.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3635 q_vals: [-inf, -24.49, -8.662, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3638, "number_of_timesteps": 68407, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1517 2 visits [500.0, 1.0, 109.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3638 q_vals: [-inf, -24.49, -8.673, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1518 2 visits [500.0, 1.0, 110.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3640 q_vals: [-inf, -24.49, -8.683, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1519 2 visits [500.0, 1.0, 111.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3644 q_vals: [-inf, -24.49, -8.605, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1520 2 visits [500.0, 1.0, 112.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3645 q_vals: [-inf, -24.49, -8.615, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3648, "number_of_timesteps": 68604, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1521 2 visits [500.0, 1.0, 113.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3648 q_vals: [-inf, -24.49, -8.539, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1522 2 visits [500.0, 1.0, 114.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3652 q_vals: [-inf, -24.49, -8.464, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1523 2 visits [500.0, 1.0, 115.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3652 q_vals: [-inf, -24.49, -8.476, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1524 2 visits [500.0, 1.0, 116.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3656 q_vals: [-inf, -24.49, -8.487, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3658, "number_of_timesteps": 68762, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1525 2 visits [500.0, 1.0, 117.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3658 q_vals: [-inf, -24.49, -8.498, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1526 2 visits [500.0, 1.0, 118.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3658 q_vals: [-inf, -24.49, -8.509, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1527 2 visits [500.0, 1.0, 119.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3659 q_vals: [-inf, -24.49, -8.52, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1528 2 visits [500.0, 1.0, 120.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3666 q_vals: [-inf, -24.49, -8.449, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3668, "number_of_timesteps": 69013, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1529 2 visits [500.0, 1.0, 121.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3668 q_vals: [-inf, -24.49, -8.46, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1530 2 visits [500.0, 1.0, 122.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3668 q_vals: [-inf, -24.49, -8.471, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1531 2 visits [500.0, 1.0, 123.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3672 q_vals: [-inf, -24.49, -8.601, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1532 2 visits [500.0, 1.0, 124.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3675 q_vals: [-inf, -24.49, -8.532, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1533 2 visits [500.0, 1.0, 125.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3676 q_vals: [-inf, -24.49, -8.66, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3679, "number_of_timesteps": 69167, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1534 2 visits [500.0, 1.0, 126.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3679 q_vals: [-inf, -24.49, -8.669, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1535 2 visits [500.0, 1.0, 127.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3682 q_vals: [-inf, -24.49, -8.6, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1536 2 visits [500.0, 1.0, 128.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3684 q_vals: [-inf, -24.49, -8.61, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1537 2 visits [500.0, 1.0, 129.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3687 q_vals: [-inf, -24.49, -8.733, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3690, "number_of_timesteps": 69378, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1538 2 visits [500.0, 1.0, 130.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3690 q_vals: [-inf, -24.49, -8.741, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1539 2 visits [500.0, 1.0, 131.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3693 q_vals: [-inf, -24.49, -8.861, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1540 2 visits [500.0, 1.0, 132.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3694 q_vals: [-inf, -24.49, -8.794, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1541 2 visits [500.0, 1.0, 133.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3695 q_vals: [-inf, -24.49, -8.912, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1542 2 visits [500.0, 1.0, 134.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3696 q_vals: [-inf, -24.49, -8.919, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1543 2 visits [500.0, 1.0, 135.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3698 q_vals: [-inf, -24.49, -8.925, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3701, "number_of_timesteps": 69600, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1544 2 visits [500.0, 1.0, 136.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3701 q_vals: [-inf, -24.49, -8.932, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1545 2 visits [500.0, 1.0, 137.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3702 q_vals: [-inf, -24.49, -8.866, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1546 2 visits [500.0, 1.0, 138.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3704 q_vals: [-inf, -24.49, -8.802, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1547 2 visits [500.0, 1.0, 139.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3705 q_vals: [-inf, -24.49, -8.739, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1548 2 visits [500.0, 1.0, 140.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3708 q_vals: [-inf, -24.49, -8.746, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1549 2 visits [500.0, 1.0, 141.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3709 q_vals: [-inf, -24.49, -8.754, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3711, "number_of_timesteps": 69846, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1550 2 visits [500.0, 1.0, 142.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3711 q_vals: [-inf, -24.49, -8.761, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1551 2 visits [500.0, 1.0, 143.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3712 q_vals: [-inf, -24.49, -8.768, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1552 2 visits [500.0, 1.0, 144.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3715 q_vals: [-inf, -24.49, -8.776, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1553 2 visits [500.0, 1.0, 145.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3716 q_vals: [-inf, -24.49, -8.783, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1554 2 visits [500.0, 1.0, 146.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3718 q_vals: [-inf, -24.49, -8.789, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3721, "number_of_timesteps": 70108, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1555 2 visits [500.0, 1.0, 147.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3721 q_vals: [-inf, -24.49, -8.796, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1556 2 visits [500.0, 1.0, 148.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3722 q_vals: [-inf, -24.49, -8.803, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1557 2 visits [500.0, 1.0, 149.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3725 q_vals: [-inf, -24.49, -8.81, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1558 2 visits [500.0, 1.0, 150.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3729 q_vals: [-inf, -24.49, -8.816, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3731, "number_of_timesteps": 70346, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1559 2 visits [500.0, 1.0, 151.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3731 q_vals: [-inf, -24.49, -8.823, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1560 2 visits [500.0, 1.0, 152.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3731 q_vals: [-inf, -24.49, -8.829, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1561 2 visits [500.0, 1.0, 153.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3735 q_vals: [-inf, -24.49, -8.772, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1562 2 visits [500.0, 1.0, 154.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3738 q_vals: [-inf, -24.49, -8.715, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3742, "number_of_timesteps": 70539, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1563 2 visits [500.0, 1.0, 155.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3742 q_vals: [-inf, -24.49, -8.722, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1564 2 visits [500.0, 1.0, 156.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3745 q_vals: [-inf, -24.49, -8.728, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1565 2 visits [500.0, 1.0, 157.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3747 q_vals: [-inf, -24.49, -8.735, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1566 2 visits [500.0, 1.0, 158.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3748 q_vals: [-inf, -24.49, -8.68, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3753, "number_of_timesteps": 70698, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1567 2 visits [500.0, 1.0, 159.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3753 q_vals: [-inf, -24.49, -8.687, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1568 2 visits [500.0, 1.0, 160.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3757 q_vals: [-inf, -24.49, -8.694, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1569 2 visits [500.0, 1.0, 161.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3758 q_vals: [-inf, -24.49, -8.701, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3766, "number_of_timesteps": 70866, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1570 2 visits [500.0, 1.0, 162.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3766 q_vals: [-inf, -24.49, -8.707, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1571 2 visits [500.0, 1.0, 163.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3768 q_vals: [-inf, -24.49, -8.654, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1572 2 visits [500.0, 1.0, 164.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3772 q_vals: [-inf, -24.49, -8.601, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3777, "number_of_timesteps": 70984, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1573 2 visits [500.0, 1.0, 165.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3777 q_vals: [-inf, -24.49, -8.698, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1574 2 visits [500.0, 1.0, 166.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3780 q_vals: [-inf, -24.49, -8.704, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1575 2 visits [500.0, 1.0, 167.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3784 q_vals: [-inf, -24.49, -8.711, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3787, "number_of_timesteps": 71094, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1576 2 visits [500.0, 1.0, 168.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3787 q_vals: [-inf, -24.49, -8.717, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1577 2 visits [500.0, 1.0, 169.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3792 q_vals: [-inf, -24.49, -8.666, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1578 2 visits [500.0, 1.0, 170.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3796 q_vals: [-inf, -24.49, -8.759, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3801, "number_of_timesteps": 71249, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1579 2 visits [500.0, 1.0, 171.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3801 q_vals: [-inf, -24.49, -8.851, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1580 2 visits [500.0, 1.0, 172.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3804 q_vals: [-inf, -24.49, -8.856, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1581 2 visits [500.0, 1.0, 173.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3808 q_vals: [-inf, -24.49, -8.862, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3812, "number_of_timesteps": 71368, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1582 2 visits [500.0, 1.0, 174.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3812 q_vals: [-inf, -24.49, -8.867, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1583 2 visits [500.0, 1.0, 175.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3814 q_vals: [-inf, -24.49, -8.872, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1584 2 visits [500.0, 1.0, 176.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3819 q_vals: [-inf, -24.49, -8.878, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3822, "number_of_timesteps": 71488, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1585 2 visits [500.0, 1.0, 177.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3822 q_vals: [-inf, -24.49, -8.883, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1586 2 visits [500.0, 1.0, 178.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3826 q_vals: [-inf, -24.49, -8.97, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1587 2 visits [500.0, 1.0, 179.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3830 q_vals: [-inf, -24.49, -8.975, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3835, "number_of_timesteps": 71630, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1588 2 visits [500.0, 1.0, 180.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3835 q_vals: [-inf, -24.49, -9.061, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1589 2 visits [500.0, 1.0, 181.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3837 q_vals: [-inf, -24.49, -9.146, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1590 2 visits [500.0, 1.0, 182.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3844 q_vals: [-inf, -24.49, -9.096, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3845, "number_of_timesteps": 71741, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1591 2 visits [500.0, 1.0, 183.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3845 q_vals: [-inf, -24.49, -9.1, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1592 2 visits [500.0, 1.0, 184.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3850 q_vals: [-inf, -24.49, -9.104, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3855, "number_of_timesteps": 71850, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1593 2 visits [500.0, 1.0, 185.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3855 q_vals: [-inf, -24.49, -9.055, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1594 2 visits [500.0, 1.0, 186.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3857 q_vals: [-inf, -24.49, -9.059, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1595 2 visits [500.0, 1.0, 187.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3861 q_vals: [-inf, -24.49, -9.063, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3865, "number_of_timesteps": 71964, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1596 2 visits [500.0, 1.0, 188.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3865 q_vals: [-inf, -24.49, -9.066, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1597 2 visits [500.0, 1.0, 189.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3869 q_vals: [-inf, -24.49, -9.018, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1598 2 visits [500.0, 1.0, 190.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3873 q_vals: [-inf, -24.49, -9.023, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3878, "number_of_timesteps": 72107, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1599 2 visits [500.0, 1.0, 191.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3878 q_vals: [-inf, -24.49, -8.975, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1600 2 visits [500.0, 1.0, 192.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3880 q_vals: [-inf, -24.49, -9.056, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1601 2 visits [500.0, 1.0, 193.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3887 q_vals: [-inf, -24.49, -9.06, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3889, "number_of_timesteps": 72225, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1602 2 visits [500.0, 1.0, 194.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3889 q_vals: [-inf, -24.49, -9.064, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1603 2 visits [500.0, 1.0, 195.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3894 q_vals: [-inf, -24.49, -9.068, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1604 2 visits [500.0, 1.0, 196.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3898 q_vals: [-inf, -24.49, -9.071, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3901, "number_of_timesteps": 72345, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1605 2 visits [500.0, 1.0, 197.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3901 q_vals: [-inf, -24.49, -9.075, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1606 2 visits [500.0, 1.0, 198.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3907 q_vals: [-inf, -24.49, -9.153, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1607 2 visits [500.0, 1.0, 199.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3910 q_vals: [-inf, -24.49, -9.156, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3917, "number_of_timesteps": 72508, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1608 2 visits [500.0, 1.0, 200.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3917 q_vals: [-inf, -24.49, -9.159, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1609 2 visits [500.0, 1.0, 201.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3920 q_vals: [-inf, -24.49, -9.162, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1610 2 visits [500.0, 1.0, 202.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3924 q_vals: [-inf, -24.49, -9.165, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3930, "number_of_timesteps": 72632, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1611 2 visits [500.0, 1.0, 203.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3930 q_vals: [-inf, -24.49, -9.169, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1612 2 visits [500.0, 1.0, 204.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3932 q_vals: [-inf, -24.49, -9.172, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1613 2 visits [500.0, 1.0, 205.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3937 q_vals: [-inf, -24.49, -9.175, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3942, "number_of_timesteps": 72756, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1614 2 visits [500.0, 1.0, 206.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3942 q_vals: [-inf, -24.49, -9.178, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1615 2 visits [500.0, 1.0, 207.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3947 q_vals: [-inf, -24.49, -9.181, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1616 2 visits [500.0, 1.0, 208.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3951 q_vals: [-inf, -24.49, -9.137, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3955, "number_of_timesteps": 72885, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1617 2 visits [500.0, 1.0, 209.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3955 q_vals: [-inf, -24.49, -9.093, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1618 2 visits [500.0, 1.0, 210.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3961 q_vals: [-inf, -24.49, -9.05, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3965, "number_of_timesteps": 72987, "per_episode_reward": 12.55, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1619 2 visits [500.0, 1.0, 211.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3965 q_vals: [-inf, -24.49, -9.053, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1620 2 visits [500.0, 1.0, 212.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3969 q_vals: [-inf, -24.49, -9.057, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1621 2 visits [500.0, 1.0, 213.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3972 q_vals: [-inf, -24.49, -9.014, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3979, "number_of_timesteps": 73136, "per_episode_reward": 12.5, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1622 2 visits [500.0, 1.0, 214.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3979 q_vals: [-inf, -24.49, -9.018, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1623 2 visits [500.0, 1.0, 215.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3982 q_vals: [-inf, -24.49, -9.021, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1624 2 visits [500.0, 1.0, 216.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3987 q_vals: [-inf, -24.49, -9.025, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 3992, "number_of_timesteps": 73263, "per_episode_reward": 12.45, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1625 2 visits [500.0, 1.0, 217.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3992 q_vals: [-inf, -24.49, -9.096, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1626 2 visits [500.0, 1.0, 218.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 3996 q_vals: [-inf, -24.49, -9.099, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1627 2 visits [500.0, 1.0, 219.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4000 q_vals: [-inf, -24.49, -9.103, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4004, "number_of_timesteps": 73380, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 1628 2 visits [500.0, 1.0, 220.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4004 q_vals: [-inf, -24.49, -9.061, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1629 2 visits [500.0, 1.0, 221.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4010 q_vals: [-inf, -24.49, -9.065, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1630 2 visits [500.0, 1.0, 222.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4013 q_vals: [-inf, -24.49, -9.068, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4019, "number_of_timesteps": 73529, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 1631 2 visits [500.0, 1.0, 223.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4019 q_vals: [-inf, -24.49, -9.071, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1632 2 visits [500.0, 1.0, 224.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4023 q_vals: [-inf, -24.49, -9.074, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1633 2 visits [500.0, 1.0, 225.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4027 q_vals: [-inf, -24.49, -9.034, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4033, "number_of_timesteps": 73667, "per_episode_reward": 12.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
Step 1634 2 visits [500.0, 1.0, 226.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4033 q_vals: [-inf, -24.49, -9.102, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1635 2 visits [500.0, 1.0, 227.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4035 q_vals: [-inf, -24.49, -9.105, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1636 2 visits [500.0, 1.0, 228.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4041 q_vals: [-inf, -24.49, -9.173, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4045, "number_of_timesteps": 73787, "per_episode_reward": 12.25, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
Step 1637 2 visits [500.0, 1.0, 229.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4045 q_vals: [-inf, -24.49, -9.176, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1638 2 visits [500.0, 1.0, 230.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4050 q_vals: [-inf, -24.49, -9.136, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1639 2 visits [500.0, 1.0, 231.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4054 q_vals: [-inf, -24.49, -9.096, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4060, "number_of_timesteps": 73930, "per_episode_reward": 12.2, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
Step 1640 2 visits [500.0, 1.0, 232.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4060 q_vals: [-inf, -24.49, -9.099, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1641 2 visits [500.0, 1.0, 233.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4064 q_vals: [-inf, -24.49, -9.102, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1642 2 visits [500.0, 1.0, 234.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4068 q_vals: [-inf, -24.49, -9.105, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4074, "number_of_timesteps": 74070, "per_episode_reward": 12.15, "episode_reward_trend_value": -0.004999999999999992, "biggest_recent_change": 0.15000000000000036},
Step 1643 2 visits [500.0, 1.0, 235.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4074 q_vals: [-inf, -24.49, -9.108, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1644 2 visits [500.0, 1.0, 236.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4077 q_vals: [-inf, -24.49, -9.111, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1645 2 visits [500.0, 1.0, 237.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4083 q_vals: [-inf, -24.49, -9.114, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4087, "number_of_timesteps": 74200, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.005000000000000012, "biggest_recent_change": 0.15000000000000036},
Step 1646 2 visits [500.0, 1.0, 238.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4087 q_vals: [-inf, -24.49, -9.117, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1647 2 visits [500.0, 1.0, 239.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4091 q_vals: [-inf, -24.49, -9.12, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1648 2 visits [500.0, 1.0, 240.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4096 q_vals: [-inf, -24.49, -9.122, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4101, "number_of_timesteps": 74336, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
Step 1649 2 visits [500.0, 1.0, 241.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4101 q_vals: [-inf, -24.49, -9.125, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1650 2 visits [500.0, 1.0, 242.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4105 q_vals: [-inf, -24.49, -9.189, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1651 2 visits [500.0, 1.0, 243.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4110 q_vals: [-inf, -24.49, -9.252, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4114, "number_of_timesteps": 74461, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
Step 1652 2 visits [500.0, 1.0, 244.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4114 q_vals: [-inf, -24.49, -9.254, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1653 2 visits [500.0, 1.0, 245.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4118 q_vals: [-inf, -24.49, -9.216, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4124, "number_of_timesteps": 74561, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
Step 1654 2 visits [500.0, 1.0, 246.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4124 q_vals: [-inf, -24.49, -9.278, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1655 2 visits [500.0, 1.0, 247.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4128 q_vals: [-inf, -24.49, -9.241, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1656 2 visits [500.0, 1.0, 248.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4132 q_vals: [-inf, -24.49, -9.243, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4138, "number_of_timesteps": 74694, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
Step 1657 2 visits [500.0, 1.0, 249.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4138 q_vals: [-inf, -24.49, -9.245, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1658 2 visits [500.0, 1.0, 250.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4141 q_vals: [-inf, -24.49, -9.247, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1659 2 visits [500.0, 1.0, 251.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4145 q_vals: [-inf, -24.49, -9.308, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4151, "number_of_timesteps": 74828, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
Step 1660 2 visits [500.0, 1.0, 252.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4151 q_vals: [-inf, -24.49, -9.31, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1661 2 visits [500.0, 1.0, 253.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4152 q_vals: [-inf, -24.49, -9.312, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1662 2 visits [500.0, 1.0, 254.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4160 q_vals: [-inf, -24.49, -9.314, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4162, "number_of_timesteps": 74943, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1663 2 visits [500.0, 1.0, 255.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4162 q_vals: [-inf, -24.49, -9.316, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1664 2 visits [500.0, 1.0, 256.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4168 q_vals: [-inf, -24.49, -9.318, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4172, "number_of_timesteps": 75048, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1665 2 visits [500.0, 1.0, 257.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4172 q_vals: [-inf, -24.49, -9.281, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1666 2 visits [500.0, 1.0, 258.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4177 q_vals: [-inf, -24.49, -9.283, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4182, "number_of_timesteps": 75144, "per_episode_reward": 12.1, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1667 2 visits [500.0, 1.0, 259.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4182 q_vals: [-inf, -24.49, -9.285, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1668 2 visits [500.0, 1.0, 260.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4185 q_vals: [-inf, -24.49, -9.25, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4192, "number_of_timesteps": 75241, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1669 2 visits [500.0, 1.0, 261.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4192 q_vals: [-inf, -24.49, -9.214, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1670 2 visits [500.0, 1.0, 262.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4195 q_vals: [-inf, -24.49, -9.216, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1671 2 visits [500.0, 1.0, 263.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4201 q_vals: [-inf, -24.49, -9.274, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4205, "number_of_timesteps": 75363, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1672 2 visits [500.0, 1.0, 264.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4205 q_vals: [-inf, -24.49, -9.276, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1673 2 visits [500.0, 1.0, 265.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4209 q_vals: [-inf, -24.49, -9.278, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1674 2 visits [500.0, 1.0, 266.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4212 q_vals: [-inf, -24.49, -9.28, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4217, "number_of_timesteps": 75494, "per_episode_reward": 12.0, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
Step 1675 2 visits [500.0, 1.0, 267.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4217 q_vals: [-inf, -24.49, -9.282, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1676 2 visits [500.0, 1.0, 268.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4222 q_vals: [-inf, -24.49, -9.248, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1677 2 visits [500.0, 1.0, 269.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4226 q_vals: [-inf, -24.49, -9.25, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4230, "number_of_timesteps": 75621, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1678 2 visits [500.0, 1.0, 270.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4230 q_vals: [-inf, -24.49, -9.306, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1679 2 visits [500.0, 1.0, 271.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4235 q_vals: [-inf, -24.49, -9.308, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1680 2 visits [500.0, 1.0, 272.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4238 q_vals: [-inf, -24.49, -9.274, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4244, "number_of_timesteps": 75760, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1681 2 visits [500.0, 1.0, 273.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4244 q_vals: [-inf, -24.49, -9.24, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1682 2 visits [500.0, 1.0, 274.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4248 q_vals: [-inf, -24.49, -9.206, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1683 2 visits [500.0, 1.0, 275.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4250 q_vals: [-inf, -24.49, -9.262, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4257, "number_of_timesteps": 75890, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1684 2 visits [500.0, 1.0, 276.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4257 q_vals: [-inf, -24.49, -9.264, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1685 2 visits [500.0, 1.0, 277.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4260 q_vals: [-inf, -24.49, -9.265, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1686 2 visits [500.0, 1.0, 278.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4266 q_vals: [-inf, -24.49, -9.232, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4269, "number_of_timesteps": 76010, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1687 2 visits [500.0, 1.0, 279.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4269 q_vals: [-inf, -24.49, -9.234, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1688 2 visits [500.0, 1.0, 280.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4274 q_vals: [-inf, -24.49, -9.201, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1689 2 visits [500.0, 1.0, 281.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4277 q_vals: [-inf, -24.49, -9.168, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4282, "number_of_timesteps": 76148, "per_episode_reward": 11.9, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
Step 1690 2 visits [500.0, 1.0, 282.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4282 q_vals: [-inf, -24.49, -9.171, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1691 2 visits [500.0, 1.0, 283.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4287 q_vals: [-inf, -24.49, -9.225, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4292, "number_of_timesteps": 76242, "per_episode_reward": 11.85, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
Step 1692 2 visits [500.0, 1.0, 284.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4292 q_vals: [-inf, -24.49, -9.227, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1693 2 visits [500.0, 1.0, 285.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4296 q_vals: [-inf, -24.49, -9.229, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1694 2 visits [500.0, 1.0, 286.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4300 q_vals: [-inf, -24.49, -9.197, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4306, "number_of_timesteps": 76383, "per_episode_reward": 11.8, "episode_reward_trend_value": -0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
Step 1695 2 visits [500.0, 1.0, 287.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4306 q_vals: [-inf, -24.49, -9.199, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1696 2 visits [500.0, 1.0, 288.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4308 q_vals: [-inf, -24.49, -9.201, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1697 2 visits [500.0, 1.0, 289.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4315 q_vals: [-inf, -24.49, -9.203, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4317, "number_of_timesteps": 76491, "per_episode_reward": 11.75, "episode_reward_trend_value": -0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
Step 1698 2 visits [500.0, 1.0, 290.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4317 q_vals: [-inf, -24.49, -9.205, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1699 2 visits [500.0, 1.0, 291.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4322 q_vals: [-inf, -24.49, -9.173, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1700 2 visits [500.0, 1.0, 292.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4326 q_vals: [-inf, -24.49, -9.142, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4331, "number_of_timesteps": 76634, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
Step 1701 2 visits [500.0, 1.0, 293.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4331 q_vals: [-inf, -24.49, -9.194, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1702 2 visits [500.0, 1.0, 294.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4335 q_vals: [-inf, -24.49, -9.196, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4341, "number_of_timesteps": 76732, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 1703 2 visits [500.0, 1.0, 295.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4341 q_vals: [-inf, -24.49, -9.198, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1704 2 visits [500.0, 1.0, 296.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4344 q_vals: [-inf, -24.49, -9.167, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1705 2 visits [500.0, 1.0, 297.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4350 q_vals: [-inf, -24.49, -9.169, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4354, "number_of_timesteps": 76859, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 1706 2 visits [500.0, 1.0, 298.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4354 q_vals: [-inf, -24.49, -9.171, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1707 2 visits [500.0, 1.0, 299.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4357 q_vals: [-inf, -24.49, -9.223, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1708 2 visits [500.0, 1.0, 300.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4362 q_vals: [-inf, -24.49, -9.224, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4366, "number_of_timesteps": 76979, "per_episode_reward": 11.7, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 1709 2 visits [500.0, 1.0, 301.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4366 q_vals: [-inf, -24.49, -9.194, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1710 2 visits [500.0, 1.0, 302.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4369 q_vals: [-inf, -24.49, -9.196, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1711 2 visits [500.0, 1.0, 303.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4375 q_vals: [-inf, -24.49, -9.198, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4377, "number_of_timesteps": 77096, "per_episode_reward": 11.65, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
Step 1712 2 visits [500.0, 1.0, 304.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4377 q_vals: [-inf, -24.49, -9.168, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1713 2 visits [500.0, 1.0, 305.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4385 q_vals: [-inf, -24.49, -9.138, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1714 2 visits [500.0, 1.0, 306.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4386 q_vals: [-inf, -24.49, -9.14, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4393, "number_of_timesteps": 77253, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
Step 1715 2 visits [500.0, 1.0, 307.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4393 q_vals: [-inf, -24.49, -9.11, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1716 2 visits [500.0, 1.0, 308.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4396 q_vals: [-inf, -24.49, -9.112, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1717 2 visits [500.0, 1.0, 309.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4398 q_vals: [-inf, -24.49, -9.162, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4404, "number_of_timesteps": 77368, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
Step 1718 2 visits [500.0, 1.0, 310.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4404 q_vals: [-inf, -24.49, -9.164, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1719 2 visits [500.0, 1.0, 311.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4407 q_vals: [-inf, -24.49, -9.166, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1720 2 visits [500.0, 1.0, 312.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4413 q_vals: [-inf, -24.49, -9.137, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4416, "number_of_timesteps": 77492, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
Step 1721 2 visits [500.0, 1.0, 313.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4416 q_vals: [-inf, -24.49, -9.107, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1722 2 visits [500.0, 1.0, 314.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4422 q_vals: [-inf, -24.49, -9.11, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4426, "number_of_timesteps": 77588, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
Step 1723 2 visits [500.0, 1.0, 315.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4426 q_vals: [-inf, -24.49, -9.112, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1724 2 visits [500.0, 1.0, 316.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4431 q_vals: [-inf, -24.49, -9.083, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1725 2 visits [500.0, 1.0, 317.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4435 q_vals: [-inf, -24.49, -9.085, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4440, "number_of_timesteps": 77724, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1726 2 visits [500.0, 1.0, 318.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4440 q_vals: [-inf, -24.49, -9.087, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1727 2 visits [500.0, 1.0, 319.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4443 q_vals: [-inf, -24.49, -9.059, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1728 2 visits [500.0, 1.0, 320.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4447 q_vals: [-inf, -24.49, -9.061, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4452, "number_of_timesteps": 77851, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1729 2 visits [500.0, 1.0, 321.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4452 q_vals: [-inf, -24.49, -9.064, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1730 2 visits [500.0, 1.0, 322.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4457 q_vals: [-inf, -24.49, -9.066, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1731 2 visits [500.0, 1.0, 323.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4459 q_vals: [-inf, -24.49, -9.114, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4465, "number_of_timesteps": 77982, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1732 2 visits [500.0, 1.0, 324.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4465 q_vals: [-inf, -24.49, -9.116, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1733 2 visits [500.0, 1.0, 325.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4469 q_vals: [-inf, -24.49, -9.118, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1734 2 visits [500.0, 1.0, 326.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4472 q_vals: [-inf, -24.49, -9.165, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4477, "number_of_timesteps": 78108, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1735 2 visits [500.0, 1.0, 327.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4477 q_vals: [-inf, -24.49, -9.167, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1736 2 visits [500.0, 1.0, 328.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4481 q_vals: [-inf, -24.49, -9.169, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1737 2 visits [500.0, 1.0, 329.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4485 q_vals: [-inf, -24.49, -9.171, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4488, "number_of_timesteps": 78225, "per_episode_reward": 11.6, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1738 2 visits [500.0, 1.0, 330.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4488 q_vals: [-inf, -24.49, -9.173, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1739 2 visits [500.0, 1.0, 331.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4491 q_vals: [-inf, -24.49, -9.174, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1740 2 visits [500.0, 1.0, 332.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4496 q_vals: [-inf, -24.49, -9.176, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4499, "number_of_timesteps": 78358, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1741 2 visits [500.0, 1.0, 333.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4499 q_vals: [-inf, -24.49, -9.178, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1742 2 visits [500.0, 1.0, 334.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4503 q_vals: [-inf, -24.49, -9.18, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1743 2 visits [500.0, 1.0, 335.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4508 q_vals: [-inf, -24.49, -9.182, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4510, "number_of_timesteps": 78479, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1744 2 visits [500.0, 1.0, 336.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4510 q_vals: [-inf, -24.49, -9.184, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1745 2 visits [500.0, 1.0, 337.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4517 q_vals: [-inf, -24.49, -9.185, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1746 2 visits [500.0, 1.0, 338.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4518 q_vals: [-inf, -24.49, -9.231, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4523, "number_of_timesteps": 78611, "per_episode_reward": 11.45, "episode_reward_trend_value": -0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
Step 1747 2 visits [500.0, 1.0, 339.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4523 q_vals: [-inf, -24.49, -9.232, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1748 2 visits [500.0, 1.0, 340.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4527 q_vals: [-inf, -24.49, -9.205, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1749 2 visits [500.0, 1.0, 341.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4529 q_vals: [-inf, -24.49, -9.207, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4535, "number_of_timesteps": 78753, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 1750 2 visits [500.0, 1.0, 342.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4535 q_vals: [-inf, -24.49, -9.18, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1751 2 visits [500.0, 1.0, 343.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4537 q_vals: [-inf, -24.49, -9.153, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1752 2 visits [500.0, 1.0, 344.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4541 q_vals: [-inf, -24.49, -9.127, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4545, "number_of_timesteps": 78869, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 1753 2 visits [500.0, 1.0, 345.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4545 q_vals: [-inf, -24.49, -9.1, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1754 2 visits [500.0, 1.0, 346.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4548 q_vals: [-inf, -24.49, -9.074, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1755 2 visits [500.0, 1.0, 347.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4554 q_vals: [-inf, -24.49, -9.048, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4558, "number_of_timesteps": 79009, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 1756 2 visits [500.0, 1.0, 348.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4558 q_vals: [-inf, -24.49, -9.022, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1757 2 visits [500.0, 1.0, 349.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4560 q_vals: [-inf, -24.49, -9.066, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1758 2 visits [500.0, 1.0, 350.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4564 q_vals: [-inf, -24.49, -9.068, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4570, "number_of_timesteps": 79145, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 1759 2 visits [500.0, 1.0, 351.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4570 q_vals: [-inf, -24.49, -9.07, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1760 2 visits [500.0, 1.0, 352.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4572 q_vals: [-inf, -24.49, -9.045, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1761 2 visits [500.0, 1.0, 353.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4575 q_vals: [-inf, -24.49, -9.019, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4580, "number_of_timesteps": 79264, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 1762 2 visits [500.0, 1.0, 354.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4580 q_vals: [-inf, -24.49, -8.993, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1763 2 visits [500.0, 1.0, 355.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4581 q_vals: [-inf, -24.49, -8.996, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1764 2 visits [500.0, 1.0, 356.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4586 q_vals: [-inf, -24.49, -8.998, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1765 2 visits [500.0, 1.0, 357.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4589 q_vals: [-inf, -24.49, -9.0, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4593, "number_of_timesteps": 79420, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 1766 2 visits [500.0, 1.0, 358.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4593 q_vals: [-inf, -24.49, -9.002, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1767 2 visits [500.0, 1.0, 359.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4597 q_vals: [-inf, -24.49, -8.977, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1768 2 visits [500.0, 1.0, 360.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4598 q_vals: [-inf, -24.49, -8.98, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4604, "number_of_timesteps": 79559, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 1769 2 visits [500.0, 1.0, 361.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4604 q_vals: [-inf, -24.49, -8.982, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1770 2 visits [500.0, 1.0, 362.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4608 q_vals: [-inf, -24.49, -8.984, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1771 2 visits [500.0, 1.0, 363.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4610 q_vals: [-inf, -24.49, -8.986, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4617, "number_of_timesteps": 79707, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0022222222222222144, "biggest_recent_change": 0.15000000000000036},
Step 1772 2 visits [500.0, 1.0, 364.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4617 q_vals: [-inf, -24.49, -8.989, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1773 2 visits [500.0, 1.0, 365.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4618 q_vals: [-inf, -24.49, -8.991, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1774 2 visits [500.0, 1.0, 366.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4621 q_vals: [-inf, -24.49, -9.033, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4627, "number_of_timesteps": 79844, "per_episode_reward": 11.4, "episode_reward_trend_value": -0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1775 2 visits [500.0, 1.0, 367.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4627 q_vals: [-inf, -24.49, -9.009, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1776 2 visits [500.0, 1.0, 368.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4628 q_vals: [-inf, -24.49, -8.984, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1777 2 visits [500.0, 1.0, 369.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4629 q_vals: [-inf, -24.49, -9.026, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1778 2 visits [500.0, 1.0, 370.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4634 q_vals: [-inf, -24.49, -9.002, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4638, "number_of_timesteps": 80007, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1779 2 visits [500.0, 1.0, 371.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4638 q_vals: [-inf, -24.49, -9.004, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1780 2 visits [500.0, 1.0, 372.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4640 q_vals: [-inf, -24.49, -9.045, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1781 2 visits [500.0, 1.0, 373.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4645 q_vals: [-inf, -24.49, -9.021, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1782 2 visits [500.0, 1.0, 374.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4646 q_vals: [-inf, -24.49, -9.023, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4651, "number_of_timesteps": 80168, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1783 2 visits [500.0, 1.0, 375.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4651 q_vals: [-inf, -24.49, -8.999, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1784 2 visits [500.0, 1.0, 376.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4655 q_vals: [-inf, -24.49, -9.04, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1785 2 visits [500.0, 1.0, 377.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4658 q_vals: [-inf, -24.49, -9.042, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1786 2 visits [500.0, 1.0, 378.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4659 q_vals: [-inf, -24.49, -9.018, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4663, "number_of_timesteps": 80324, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1787 2 visits [500.0, 1.0, 379.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4663 q_vals: [-inf, -24.49, -8.995, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1788 2 visits [500.0, 1.0, 380.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4668 q_vals: [-inf, -24.49, -9.035, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1789 2 visits [500.0, 1.0, 381.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4670 q_vals: [-inf, -24.49, -9.037, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4674, "number_of_timesteps": 80470, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1790 2 visits [500.0, 1.0, 382.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4674 q_vals: [-inf, -24.49, -9.039, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1791 2 visits [500.0, 1.0, 383.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4677 q_vals: [-inf, -24.49, -9.041, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1792 2 visits [500.0, 1.0, 384.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4679 q_vals: [-inf, -24.49, -9.018, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1793 2 visits [500.0, 1.0, 385.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4682 q_vals: [-inf, -24.49, -9.02, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1794 2 visits [500.0, 1.0, 386.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4683 q_vals: [-inf, -24.49, -9.022, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4688, "number_of_timesteps": 80691, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1795 2 visits [500.0, 1.0, 387.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4688 q_vals: [-inf, -24.49, -9.024, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1796 2 visits [500.0, 1.0, 388.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4689 q_vals: [-inf, -24.49, -9.001, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1797 2 visits [500.0, 1.0, 389.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4692 q_vals: [-inf, -24.49, -9.003, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1798 2 visits [500.0, 1.0, 390.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4692 q_vals: [-inf, -24.49, -8.98, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1799 2 visits [500.0, 1.0, 391.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4694 q_vals: [-inf, -24.49, -8.957, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1800 2 visits [500.0, 1.0, 392.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4696 q_vals: [-inf, -24.49, -8.996, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4698, "number_of_timesteps": 80876, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1801 2 visits [500.0, 1.0, 393.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4698 q_vals: [-inf, -24.49, -8.998, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1802 2 visits [500.0, 1.0, 394.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4700 q_vals: [-inf, -24.49, -9.038, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1803 2 visits [500.0, 1.0, 395.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4704 q_vals: [-inf, -24.49, -9.015, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1804 2 visits [500.0, 1.0, 396.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4705 q_vals: [-inf, -24.49, -8.992, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1805 2 visits [500.0, 1.0, 397.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4707 q_vals: [-inf, -24.49, -8.994, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4709, "number_of_timesteps": 81107, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1806 2 visits [500.0, 1.0, 398.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4709 q_vals: [-inf, -24.49, -8.971, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1807 2 visits [500.0, 1.0, 399.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4713 q_vals: [-inf, -24.49, -8.973, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1808 2 visits [500.0, 1.0, 400.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4714 q_vals: [-inf, -24.49, -8.976, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1809 2 visits [500.0, 1.0, 401.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4716 q_vals: [-inf, -24.49, -9.014, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1810 2 visits [500.0, 1.0, 402.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4718 q_vals: [-inf, -24.49, -9.053, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4721, "number_of_timesteps": 81363, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1811 2 visits [500.0, 1.0, 403.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4721 q_vals: [-inf, -24.49, -9.055, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1812 2 visits [500.0, 1.0, 404.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4724 q_vals: [-inf, -24.49, -9.049, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1813 2 visits [500.0, 1.0, 405.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4727 q_vals: [-inf, -24.49, -9.027, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4732, "number_of_timesteps": 81592, "per_episode_reward": 11.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
Step 1814 2 visits [500.0, 1.0, 406.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4732 q_vals: [-inf, -24.49, -9.029, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1815 2 visits [500.0, 1.0, 407.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4732 q_vals: [-inf, -24.49, -9.067, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1816 2 visits [500.0, 1.0, 408.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4734 q_vals: [-inf, -24.49, -9.045, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1817 2 visits [500.0, 1.0, 409.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4737 q_vals: [-inf, -24.49, -9.023, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1818 2 visits [500.0, 1.0, 410.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4739 q_vals: [-inf, -24.49, -9.06, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1819 2 visits [500.0, 1.0, 411.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4739 q_vals: [-inf, -24.49, -9.098, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1820 2 visits [500.0, 1.0, 412.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4740 q_vals: [-inf, -24.49, -9.1, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4745, "number_of_timesteps": 81838, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
Step 1821 2 visits [500.0, 1.0, 413.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4745 q_vals: [-inf, -24.49, -9.101, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1822 2 visits [500.0, 1.0, 414.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4746 q_vals: [-inf, -24.49, -9.103, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1823 2 visits [500.0, 1.0, 415.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4748 q_vals: [-inf, -24.49, -9.105, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1824 2 visits [500.0, 1.0, 416.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4751 q_vals: [-inf, -24.49, -9.099, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1825 2 visits [500.0, 1.0, 417.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4753 q_vals: [-inf, -24.49, -9.136, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4756, "number_of_timesteps": 82102, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1826 2 visits [500.0, 1.0, 418.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4756 q_vals: [-inf, -24.49, -9.114, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1827 2 visits [500.0, 1.0, 419.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4759 q_vals: [-inf, -24.49, -9.092, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1828 2 visits [500.0, 1.0, 420.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4762 q_vals: [-inf, -24.49, -9.07, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1829 2 visits [500.0, 1.0, 421.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4764 q_vals: [-inf, -24.49, -9.049, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1830 2 visits [500.0, 1.0, 422.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4765 q_vals: [-inf, -24.49, -9.085, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4766, "number_of_timesteps": 82273, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 1831 2 visits [500.0, 1.0, 423.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4766 q_vals: [-inf, -24.49, -9.087, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1832 2 visits [500.0, 1.0, 424.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4766 q_vals: [-inf, -24.49, -9.089, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1833 2 visits [500.0, 1.0, 425.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4769 q_vals: [-inf, -24.49, -9.09, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1834 2 visits [500.0, 1.0, 426.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4773 q_vals: [-inf, -24.49, -9.127, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1835 2 visits [500.0, 1.0, 427.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4774 q_vals: [-inf, -24.49, -9.128, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1836 2 visits [500.0, 1.0, 428.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4775 q_vals: [-inf, -24.49, -9.13, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4778, "number_of_timesteps": 82516, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 1837 2 visits [500.0, 1.0, 429.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4778 q_vals: [-inf, -24.49, -9.108, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1838 2 visits [500.0, 1.0, 430.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4779 q_vals: [-inf, -24.49, -9.11, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1839 2 visits [500.0, 1.0, 431.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4781 q_vals: [-inf, -24.49, -9.089, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1840 2 visits [500.0, 1.0, 432.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4783 q_vals: [-inf, -24.49, -9.091, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1841 2 visits [500.0, 1.0, 433.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4786 q_vals: [-inf, -24.49, -9.07, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4789, "number_of_timesteps": 82836, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1842 2 visits [500.0, 1.0, 434.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4789 q_vals: [-inf, -24.49, -9.071, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1843 2 visits [500.0, 1.0, 435.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4790 q_vals: [-inf, -24.49, -9.073, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1844 2 visits [500.0, 1.0, 436.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4793 q_vals: [-inf, -24.49, -9.052, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1845 2 visits [500.0, 1.0, 437.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4794 q_vals: [-inf, -24.49, -9.031, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1846 2 visits [500.0, 1.0, 438.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4796 q_vals: [-inf, -24.49, -9.011, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4799, "number_of_timesteps": 83031, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1847 2 visits [500.0, 1.0, 439.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4799 q_vals: [-inf, -24.49, -9.013, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1848 2 visits [500.0, 1.0, 440.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4802 q_vals: [-inf, -24.49, -8.992, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1849 2 visits [500.0, 1.0, 441.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4805 q_vals: [-inf, -24.49, -8.994, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1850 2 visits [500.0, 1.0, 442.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4805 q_vals: [-inf, -24.49, -9.029, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4810, "number_of_timesteps": 83253, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1851 2 visits [500.0, 1.0, 443.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4810 q_vals: [-inf, -24.49, -9.031, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1852 2 visits [500.0, 1.0, 444.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4811 q_vals: [-inf, -24.49, -9.065, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1853 2 visits [500.0, 1.0, 445.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4814 q_vals: [-inf, -24.49, -9.1, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1854 2 visits [500.0, 1.0, 446.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4818 q_vals: [-inf, -24.49, -9.102, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1855 2 visits [500.0, 1.0, 447.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4819 q_vals: [-inf, -24.49, -9.136, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4820, "number_of_timesteps": 83420, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
Step 1856 2 visits [500.0, 1.0, 448.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4820 q_vals: [-inf, -24.49, -9.138, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1857 2 visits [500.0, 1.0, 449.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4824 q_vals: [-inf, -24.49, -9.139, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1858 2 visits [500.0, 1.0, 450.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4824 q_vals: [-inf, -24.49, -9.14, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1859 2 visits [500.0, 1.0, 451.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4827 q_vals: [-inf, -24.49, -9.12, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1860 2 visits [500.0, 1.0, 452.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4829 q_vals: [-inf, -24.49, -9.154, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4832, "number_of_timesteps": 83704, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
Step 1861 2 visits [500.0, 1.0, 453.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4832 q_vals: [-inf, -24.49, -9.188, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1862 2 visits [500.0, 1.0, 454.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4832 q_vals: [-inf, -24.49, -9.189, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1863 2 visits [500.0, 1.0, 455.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4835 q_vals: [-inf, -24.49, -9.169, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1864 2 visits [500.0, 1.0, 456.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4840 q_vals: [-inf, -24.49, -9.171, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1865 2 visits [500.0, 1.0, 457.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4841 q_vals: [-inf, -24.49, -9.172, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4844, "number_of_timesteps": 83941, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1866 2 visits [500.0, 1.0, 458.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4844 q_vals: [-inf, -24.49, -9.205, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1867 2 visits [500.0, 1.0, 459.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4846 q_vals: [-inf, -24.49, -9.207, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1868 2 visits [500.0, 1.0, 460.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4849 q_vals: [-inf, -24.49, -9.24, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1869 2 visits [500.0, 1.0, 461.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4852 q_vals: [-inf, -24.49, -9.241, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1870 2 visits [500.0, 1.0, 462.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4852 q_vals: [-inf, -24.49, -9.242, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1871 2 visits [500.0, 1.0, 463.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4853 q_vals: [-inf, -24.49, -9.244, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4856, "number_of_timesteps": 84172, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1872 2 visits [500.0, 1.0, 464.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4856 q_vals: [-inf, -24.49, -9.276, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1873 2 visits [500.0, 1.0, 465.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4859 q_vals: [-inf, -24.49, -9.278, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1874 2 visits [500.0, 1.0, 466.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4860 q_vals: [-inf, -24.49, -9.279, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1875 2 visits [500.0, 1.0, 467.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4863 q_vals: [-inf, -24.49, -9.259, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4866, "number_of_timesteps": 84399, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1876 2 visits [500.0, 1.0, 468.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4866 q_vals: [-inf, -24.49, -9.239, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1877 2 visits [500.0, 1.0, 469.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4866 q_vals: [-inf, -24.49, -9.271, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1878 2 visits [500.0, 1.0, 470.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4870 q_vals: [-inf, -24.49, -9.252, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1879 2 visits [500.0, 1.0, 471.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4874 q_vals: [-inf, -24.49, -9.253, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1880 2 visits [500.0, 1.0, 472.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4875 q_vals: [-inf, -24.49, -9.254, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4877, "number_of_timesteps": 84619, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1881 2 visits [500.0, 1.0, 473.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4877 q_vals: [-inf, -24.49, -9.255, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1882 2 visits [500.0, 1.0, 474.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4879 q_vals: [-inf, -24.49, -9.256, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1883 2 visits [500.0, 1.0, 475.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4882 q_vals: [-inf, -24.49, -9.237, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1884 2 visits [500.0, 1.0, 476.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4882 q_vals: [-inf, -24.49, -9.269, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1885 2 visits [500.0, 1.0, 477.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4886 q_vals: [-inf, -24.49, -9.27, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4888, "number_of_timesteps": 84855, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1886 2 visits [500.0, 1.0, 478.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4888 q_vals: [-inf, -24.49, -9.251, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1887 2 visits [500.0, 1.0, 479.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4891 q_vals: [-inf, -24.49, -9.252, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1888 2 visits [500.0, 1.0, 480.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4893 q_vals: [-inf, -24.49, -9.232, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1889 2 visits [500.0, 1.0, 481.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4894 q_vals: [-inf, -24.49, -9.234, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1890 2 visits [500.0, 1.0, 482.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4897 q_vals: [-inf, -24.49, -9.214, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4899, "number_of_timesteps": 85073, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1891 2 visits [500.0, 1.0, 483.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4899 q_vals: [-inf, -24.49, -9.216, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1892 2 visits [500.0, 1.0, 484.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4900 q_vals: [-inf, -24.49, -9.197, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1893 2 visits [500.0, 1.0, 485.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4900 q_vals: [-inf, -24.49, -9.198, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1894 2 visits [500.0, 1.0, 486.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4900 q_vals: [-inf, -24.49, -9.179, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1895 2 visits [500.0, 1.0, 487.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4904 q_vals: [-inf, -24.49, -9.18, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1896 2 visits [500.0, 1.0, 488.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4906 q_vals: [-inf, -24.49, -9.161, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1897 2 visits [500.0, 1.0, 489.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4908 q_vals: [-inf, -24.49, -9.163, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4910, "number_of_timesteps": 85329, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1898 2 visits [500.0, 1.0, 490.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4910 q_vals: [-inf, -24.49, -9.164, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1899 2 visits [500.0, 1.0, 491.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4911 q_vals: [-inf, -24.49, -9.145, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1900 2 visits [500.0, 1.0, 492.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4913 q_vals: [-inf, -24.49, -9.127, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1901 2 visits [500.0, 1.0, 493.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4916 q_vals: [-inf, -24.49, -9.108, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1902 2 visits [500.0, 1.0, 494.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4918 q_vals: [-inf, -24.49, -9.09, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4921, "number_of_timesteps": 85635, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
Step 1903 2 visits [500.0, 1.0, 495.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4921 q_vals: [-inf, -24.49, -9.121, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1904 2 visits [500.0, 1.0, 496.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4921 q_vals: [-inf, -24.49, -9.122, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1905 2 visits [500.0, 1.0, 497.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4923 q_vals: [-inf, -24.49, -9.153, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1906 2 visits [500.0, 1.0, 498.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4927 q_vals: [-inf, -24.49, -9.135, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]Step 1907 2 visits [500.0, 1.0, 499.0, 2.0, 2.0, 1.0, 5.0, 4.0, 2.0, 500.0]  episode_count: 4929 q_vals: [-inf, -24.49, -9.117, -12.245, -17.143, -24.49, -12.735, -11.02, -17.143, -inf]{"total_number_of_episodes": 4931, "number_of_timesteps": 85887, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
Step 1908 2 visits [500.0, 0.0, 500.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 500.0]  episode_count: 4931 q_vals: [-inf, 0.0, -inf, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -inf]{"total_number_of_episodes": 4942, "number_of_timesteps": 86114, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
{"total_number_of_episodes": 4954, "number_of_timesteps": 86363, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
{"total_number_of_episodes": 4965, "number_of_timesteps": 86507, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
{"total_number_of_episodes": 4976, "number_of_timesteps": 86709, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
{"total_number_of_episodes": 4986, "number_of_timesteps": 86840, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
{"total_number_of_episodes": 4997, "number_of_timesteps": 86987, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
{"total_number_of_episodes": 5007, "number_of_timesteps": 87158, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
{"total_number_of_episodes": 5017, "number_of_timesteps": 87284, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
{"total_number_of_episodes": 5028, "number_of_timesteps": 87438, "per_episode_reward": 10.1, "episode_reward_trend_value": -0.015555555555555559, "biggest_recent_change": 1.4000000000000004},
{"total_number_of_episodes": 5040, "number_of_timesteps": 87690, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5052, "number_of_timesteps": 87968, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5062, "number_of_timesteps": 88235, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5074, "number_of_timesteps": 88460, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5085, "number_of_timesteps": 88635, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5095, "number_of_timesteps": 88846, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5106, "number_of_timesteps": 89072, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5118, "number_of_timesteps": 89277, "per_episode_reward": 10.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5128, "number_of_timesteps": 89480, "per_episode_reward": 10.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5142, "number_of_timesteps": 89751, "per_episode_reward": 10.25, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 5154, "number_of_timesteps": 89967, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 5166, "number_of_timesteps": 90211, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 5176, "number_of_timesteps": 90435, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 5188, "number_of_timesteps": 90727, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 5198, "number_of_timesteps": 90960, "per_episode_reward": 10.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 5209, "number_of_timesteps": 91206, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 5219, "number_of_timesteps": 91533, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 5229, "number_of_timesteps": 91775, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 5241, "number_of_timesteps": 91981, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 5253, "number_of_timesteps": 92175, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 5264, "number_of_timesteps": 92321, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 5275, "number_of_timesteps": 92478, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 5286, "number_of_timesteps": 92668, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 5298, "number_of_timesteps": 92818, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 5308, "number_of_timesteps": 92986, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5318, "number_of_timesteps": 93162, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5328, "number_of_timesteps": 93295, "per_episode_reward": 10.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5338, "number_of_timesteps": 93450, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5350, "number_of_timesteps": 93655, "per_episode_reward": 10.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5363, "number_of_timesteps": 93871, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5374, "number_of_timesteps": 94114, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5385, "number_of_timesteps": 94332, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5396, "number_of_timesteps": 94545, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5407, "number_of_timesteps": 94785, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5417, "number_of_timesteps": 95058, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5427, "number_of_timesteps": 95263, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5438, "number_of_timesteps": 95556, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5448, "number_of_timesteps": 95705, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 5458, "number_of_timesteps": 96012, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5469, "number_of_timesteps": 96226, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5483, "number_of_timesteps": 96544, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5494, "number_of_timesteps": 96780, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5506, "number_of_timesteps": 96956, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5517, "number_of_timesteps": 97113, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5528, "number_of_timesteps": 97337, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5541, "number_of_timesteps": 97671, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5553, "number_of_timesteps": 97889, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5568, "number_of_timesteps": 98264, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5578, "number_of_timesteps": 98461, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5588, "number_of_timesteps": 98633, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5600, "number_of_timesteps": 98929, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5611, "number_of_timesteps": 99182, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5621, "number_of_timesteps": 99344, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5631, "number_of_timesteps": 99510, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5641, "number_of_timesteps": 99670, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5653, "number_of_timesteps": 99857, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5664, "number_of_timesteps": 100018, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5679, "number_of_timesteps": 100235, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5690, "number_of_timesteps": 100383, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5702, "number_of_timesteps": 100531, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5712, "number_of_timesteps": 100653, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5722, "number_of_timesteps": 100777, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5734, "number_of_timesteps": 100957, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5746, "number_of_timesteps": 101137, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5756, "number_of_timesteps": 101320, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5767, "number_of_timesteps": 101517, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5777, "number_of_timesteps": 101700, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5788, "number_of_timesteps": 101982, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5798, "number_of_timesteps": 102174, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5810, "number_of_timesteps": 102377, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5825, "number_of_timesteps": 102667, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5836, "number_of_timesteps": 102846, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5847, "number_of_timesteps": 103005, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5857, "number_of_timesteps": 103131, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5868, "number_of_timesteps": 103361, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5878, "number_of_timesteps": 103489, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5891, "number_of_timesteps": 103715, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5904, "number_of_timesteps": 103927, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5914, "number_of_timesteps": 104103, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5925, "number_of_timesteps": 104289, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5935, "number_of_timesteps": 104472, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5945, "number_of_timesteps": 104660, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5958, "number_of_timesteps": 104852, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5969, "number_of_timesteps": 105050, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5982, "number_of_timesteps": 105237, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 5994, "number_of_timesteps": 105388, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6007, "number_of_timesteps": 105612, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6017, "number_of_timesteps": 105752, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6029, "number_of_timesteps": 105951, "per_episode_reward": 10.25, "episode_reward_trend_value": -0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 6039, "number_of_timesteps": 106128, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 6052, "number_of_timesteps": 106401, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 6063, "number_of_timesteps": 106600, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 6073, "number_of_timesteps": 106768, "per_episode_reward": 10.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 6083, "number_of_timesteps": 107004, "per_episode_reward": 10.2, "episode_reward_trend_value": -0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 6096, "number_of_timesteps": 107301, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 6107, "number_of_timesteps": 107528, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 6117, "number_of_timesteps": 107706, "per_episode_reward": 10.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 6130, "number_of_timesteps": 108153, "per_episode_reward": 10.35, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 6140, "number_of_timesteps": 108391, "per_episode_reward": 10.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 6150, "number_of_timesteps": 108599, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 6162, "number_of_timesteps": 108839, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 6173, "number_of_timesteps": 109088, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 6183, "number_of_timesteps": 109241, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 6194, "number_of_timesteps": 109514, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 6204, "number_of_timesteps": 109677, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 6215, "number_of_timesteps": 109999, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 6227, "number_of_timesteps": 110208, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 6240, "number_of_timesteps": 110431, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 6252, "number_of_timesteps": 110598, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6262, "number_of_timesteps": 110731, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6272, "number_of_timesteps": 110922, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6282, "number_of_timesteps": 111187, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6296, "number_of_timesteps": 111473, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6308, "number_of_timesteps": 111665, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6318, "number_of_timesteps": 111866, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6331, "number_of_timesteps": 112160, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6342, "number_of_timesteps": 112367, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6353, "number_of_timesteps": 112635, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6365, "number_of_timesteps": 112925, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6378, "number_of_timesteps": 113263, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6388, "number_of_timesteps": 113494, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6398, "number_of_timesteps": 113733, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6409, "number_of_timesteps": 114024, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6419, "number_of_timesteps": 114234, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6429, "number_of_timesteps": 114535, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6440, "number_of_timesteps": 114729, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6451, "number_of_timesteps": 114950, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6463, "number_of_timesteps": 115182, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6473, "number_of_timesteps": 115390, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6486, "number_of_timesteps": 115678, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6499, "number_of_timesteps": 115993, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6509, "number_of_timesteps": 116212, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6521, "number_of_timesteps": 116599, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6533, "number_of_timesteps": 116900, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6543, "number_of_timesteps": 117130, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6553, "number_of_timesteps": 117344, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6565, "number_of_timesteps": 117630, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6576, "number_of_timesteps": 117901, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6587, "number_of_timesteps": 118107, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6597, "number_of_timesteps": 118357, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6609, "number_of_timesteps": 118691, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6621, "number_of_timesteps": 119005, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6632, "number_of_timesteps": 119258, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6643, "number_of_timesteps": 119636, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6654, "number_of_timesteps": 119905, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6664, "number_of_timesteps": 120126, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6674, "number_of_timesteps": 120486, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6684, "number_of_timesteps": 120717, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6694, "number_of_timesteps": 120893, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6705, "number_of_timesteps": 121129, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6715, "number_of_timesteps": 121315, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6725, "number_of_timesteps": 121477, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6735, "number_of_timesteps": 121711, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6745, "number_of_timesteps": 122009, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6756, "number_of_timesteps": 122269, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6769, "number_of_timesteps": 122601, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6779, "number_of_timesteps": 122893, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6790, "number_of_timesteps": 123113, "per_episode_reward": 10.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6802, "number_of_timesteps": 123408, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 6813, "number_of_timesteps": 123755, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 6823, "number_of_timesteps": 124006, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 6833, "number_of_timesteps": 124320, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 6845, "number_of_timesteps": 124574, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 6856, "number_of_timesteps": 124791, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 6867, "number_of_timesteps": 125064, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 6877, "number_of_timesteps": 125282, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 6887, "number_of_timesteps": 125492, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 6900, "number_of_timesteps": 125838, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6911, "number_of_timesteps": 126110, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6922, "number_of_timesteps": 126365, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6933, "number_of_timesteps": 126579, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6943, "number_of_timesteps": 126840, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6955, "number_of_timesteps": 127051, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6966, "number_of_timesteps": 127273, "per_episode_reward": 10.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 6978, "number_of_timesteps": 127671, "per_episode_reward": 10.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 6988, "number_of_timesteps": 127968, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 6998, "number_of_timesteps": 128161, "per_episode_reward": 10.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7008, "number_of_timesteps": 128369, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7018, "number_of_timesteps": 128559, "per_episode_reward": 10.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7029, "number_of_timesteps": 128857, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7039, "number_of_timesteps": 129115, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7050, "number_of_timesteps": 129402, "per_episode_reward": 10.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7060, "number_of_timesteps": 129585, "per_episode_reward": 10.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7071, "number_of_timesteps": 129861, "per_episode_reward": 10.65, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7081, "number_of_timesteps": 130141, "per_episode_reward": 10.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 7094, "number_of_timesteps": 130390, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 7106, "number_of_timesteps": 130739, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 7118, "number_of_timesteps": 131076, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 7128, "number_of_timesteps": 131324, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 7138, "number_of_timesteps": 131606, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 7149, "number_of_timesteps": 131837, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 7159, "number_of_timesteps": 132023, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 7169, "number_of_timesteps": 132307, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 7179, "number_of_timesteps": 132603, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 7189, "number_of_timesteps": 132822, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7199, "number_of_timesteps": 133001, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7210, "number_of_timesteps": 133329, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7220, "number_of_timesteps": 133609, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7231, "number_of_timesteps": 133841, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7242, "number_of_timesteps": 134069, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7252, "number_of_timesteps": 134314, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7262, "number_of_timesteps": 134586, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7273, "number_of_timesteps": 134809, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7284, "number_of_timesteps": 135140, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7295, "number_of_timesteps": 135468, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7305, "number_of_timesteps": 135803, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7317, "number_of_timesteps": 136186, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7327, "number_of_timesteps": 136495, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7337, "number_of_timesteps": 136687, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7347, "number_of_timesteps": 136952, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7357, "number_of_timesteps": 137231, "per_episode_reward": 10.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7368, "number_of_timesteps": 137516, "per_episode_reward": 10.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 7379, "number_of_timesteps": 137853, "per_episode_reward": 10.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 7389, "number_of_timesteps": 138107, "per_episode_reward": 10.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 7400, "number_of_timesteps": 138325, "per_episode_reward": 10.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 7410, "number_of_timesteps": 138665, "per_episode_reward": 10.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 7420, "number_of_timesteps": 138877, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7431, "number_of_timesteps": 139118, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7443, "number_of_timesteps": 139491, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7453, "number_of_timesteps": 139720, "per_episode_reward": 11.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7464, "number_of_timesteps": 139961, "per_episode_reward": 11.0, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7475, "number_of_timesteps": 140287, "per_episode_reward": 11.05, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7488, "number_of_timesteps": 140647, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7499, "number_of_timesteps": 140884, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7509, "number_of_timesteps": 141074, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7519, "number_of_timesteps": 141437, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7530, "number_of_timesteps": 141857, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7540, "number_of_timesteps": 142282, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7552, "number_of_timesteps": 142557, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7562, "number_of_timesteps": 142823, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 7572, "number_of_timesteps": 143126, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 7582, "number_of_timesteps": 143322, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7592, "number_of_timesteps": 143495, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7604, "number_of_timesteps": 143727, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7614, "number_of_timesteps": 144004, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7624, "number_of_timesteps": 144295, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7635, "number_of_timesteps": 144501, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7647, "number_of_timesteps": 144869, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7657, "number_of_timesteps": 145105, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7668, "number_of_timesteps": 145327, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7680, "number_of_timesteps": 145533, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7693, "number_of_timesteps": 145821, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7703, "number_of_timesteps": 146111, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7713, "number_of_timesteps": 146363, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7724, "number_of_timesteps": 146632, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7734, "number_of_timesteps": 146974, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7745, "number_of_timesteps": 147231, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7755, "number_of_timesteps": 147533, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7765, "number_of_timesteps": 147905, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7777, "number_of_timesteps": 148133, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7788, "number_of_timesteps": 148381, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7798, "number_of_timesteps": 148664, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7808, "number_of_timesteps": 148903, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7818, "number_of_timesteps": 149273, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7828, "number_of_timesteps": 149519, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7840, "number_of_timesteps": 149876, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7852, "number_of_timesteps": 150159, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7863, "number_of_timesteps": 150409, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7875, "number_of_timesteps": 150674, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7886, "number_of_timesteps": 150997, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7898, "number_of_timesteps": 151245, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7910, "number_of_timesteps": 151506, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7920, "number_of_timesteps": 151702, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7930, "number_of_timesteps": 151975, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7940, "number_of_timesteps": 152192, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7950, "number_of_timesteps": 152492, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7962, "number_of_timesteps": 152908, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7973, "number_of_timesteps": 153232, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7983, "number_of_timesteps": 153495, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 7994, "number_of_timesteps": 153800, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8005, "number_of_timesteps": 154040, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8015, "number_of_timesteps": 154273, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8026, "number_of_timesteps": 154615, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8037, "number_of_timesteps": 154853, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8047, "number_of_timesteps": 155051, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8057, "number_of_timesteps": 155406, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8067, "number_of_timesteps": 155670, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8078, "number_of_timesteps": 156035, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8088, "number_of_timesteps": 156307, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8098, "number_of_timesteps": 156757, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8108, "number_of_timesteps": 157100, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8118, "number_of_timesteps": 157322, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8128, "number_of_timesteps": 157603, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8140, "number_of_timesteps": 157931, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8152, "number_of_timesteps": 158250, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8163, "number_of_timesteps": 158513, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8173, "number_of_timesteps": 158797, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8185, "number_of_timesteps": 159290, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8196, "number_of_timesteps": 159723, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8206, "number_of_timesteps": 160007, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8216, "number_of_timesteps": 160441, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8229, "number_of_timesteps": 160864, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8240, "number_of_timesteps": 161298, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8250, "number_of_timesteps": 161585, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8261, "number_of_timesteps": 161875, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8272, "number_of_timesteps": 162153, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8282, "number_of_timesteps": 162448, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8292, "number_of_timesteps": 162726, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8302, "number_of_timesteps": 162986, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8312, "number_of_timesteps": 163299, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8322, "number_of_timesteps": 163578, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8332, "number_of_timesteps": 163898, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8342, "number_of_timesteps": 164333, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8352, "number_of_timesteps": 164661, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8362, "number_of_timesteps": 164988, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8372, "number_of_timesteps": 165331, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8383, "number_of_timesteps": 165687, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8393, "number_of_timesteps": 166087, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8403, "number_of_timesteps": 166440, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8415, "number_of_timesteps": 166916, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8427, "number_of_timesteps": 167375, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8437, "number_of_timesteps": 167727, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8447, "number_of_timesteps": 168108, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8458, "number_of_timesteps": 168502, "per_episode_reward": 11.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8470, "number_of_timesteps": 168873, "per_episode_reward": 11.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8480, "number_of_timesteps": 169258, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8491, "number_of_timesteps": 169720, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8501, "number_of_timesteps": 170067, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8512, "number_of_timesteps": 170382, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8522, "number_of_timesteps": 170983, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8532, "number_of_timesteps": 171365, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8543, "number_of_timesteps": 171715, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8554, "number_of_timesteps": 172235, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8564, "number_of_timesteps": 172646, "per_episode_reward": 11.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 8574, "number_of_timesteps": 173004, "per_episode_reward": 11.35, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 8584, "number_of_timesteps": 173513, "per_episode_reward": 11.45, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 8596, "number_of_timesteps": 174054, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 8606, "number_of_timesteps": 174442, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 8616, "number_of_timesteps": 174689, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 8626, "number_of_timesteps": 174937, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 8638, "number_of_timesteps": 175480, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 8648, "number_of_timesteps": 175707, "per_episode_reward": 11.5, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 8659, "number_of_timesteps": 176103, "per_episode_reward": 11.55, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 8669, "number_of_timesteps": 176610, "per_episode_reward": 11.55, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 8680, "number_of_timesteps": 177171, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8690, "number_of_timesteps": 177473, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8701, "number_of_timesteps": 178031, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8711, "number_of_timesteps": 178654, "per_episode_reward": 11.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8723, "number_of_timesteps": 179305, "per_episode_reward": 11.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8733, "number_of_timesteps": 179696, "per_episode_reward": 11.75, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 8744, "number_of_timesteps": 180079, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 8754, "number_of_timesteps": 180570, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 8764, "number_of_timesteps": 180920, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 8777, "number_of_timesteps": 181380, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 8787, "number_of_timesteps": 181680, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 8797, "number_of_timesteps": 181998, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 8807, "number_of_timesteps": 182335, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 8817, "number_of_timesteps": 182829, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 8827, "number_of_timesteps": 183361, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 8839, "number_of_timesteps": 184043, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8849, "number_of_timesteps": 184524, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8859, "number_of_timesteps": 185128, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8869, "number_of_timesteps": 185737, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8880, "number_of_timesteps": 186381, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8891, "number_of_timesteps": 186869, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8901, "number_of_timesteps": 187317, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8911, "number_of_timesteps": 187999, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8921, "number_of_timesteps": 188522, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8934, "number_of_timesteps": 189353, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8945, "number_of_timesteps": 189914, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8958, "number_of_timesteps": 190734, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8969, "number_of_timesteps": 191210, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8979, "number_of_timesteps": 191725, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 8990, "number_of_timesteps": 192288, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9000, "number_of_timesteps": 193192, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9010, "number_of_timesteps": 194182, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9020, "number_of_timesteps": 194930, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9030, "number_of_timesteps": 195966, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9040, "number_of_timesteps": 197124, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9050, "number_of_timesteps": 198082, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9060, "number_of_timesteps": 199000, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9070, "number_of_timesteps": 200349, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9080, "number_of_timesteps": 201566, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9091, "number_of_timesteps": 202568, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9101, "number_of_timesteps": 203764, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9111, "number_of_timesteps": 204896, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9121, "number_of_timesteps": 206488, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9131, "number_of_timesteps": 207520, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9141, "number_of_timesteps": 208578, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9151, "number_of_timesteps": 210048, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9161, "number_of_timesteps": 211625, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9171, "number_of_timesteps": 212985, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9182, "number_of_timesteps": 214898, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9192, "number_of_timesteps": 216541, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9203, "number_of_timesteps": 218161, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9213, "number_of_timesteps": 218984, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9223, "number_of_timesteps": 220231, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9234, "number_of_timesteps": 221669, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9244, "number_of_timesteps": 222556, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9254, "number_of_timesteps": 223378, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9265, "number_of_timesteps": 224459, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9276, "number_of_timesteps": 225046, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9287, "number_of_timesteps": 225685, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9297, "number_of_timesteps": 226252, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9307, "number_of_timesteps": 226779, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9317, "number_of_timesteps": 227958, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9328, "number_of_timesteps": 229076, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9338, "number_of_timesteps": 229903, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9348, "number_of_timesteps": 230478, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9359, "number_of_timesteps": 230957, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9369, "number_of_timesteps": 231539, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9379, "number_of_timesteps": 232305, "per_episode_reward": 11.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9389, "number_of_timesteps": 233390, "per_episode_reward": 11.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 9399, "number_of_timesteps": 234745, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 9410, "number_of_timesteps": 235650, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 9421, "number_of_timesteps": 236914, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 9431, "number_of_timesteps": 238598, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 9441, "number_of_timesteps": 240478, "per_episode_reward": 12.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 9451, "number_of_timesteps": 242705, "per_episode_reward": 12.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 9461, "number_of_timesteps": 245322, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 9471, "number_of_timesteps": 247039, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 9482, "number_of_timesteps": 248197, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9494, "number_of_timesteps": 249146, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9507, "number_of_timesteps": 249873, "per_episode_reward": 12.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9517, "number_of_timesteps": 250235, "per_episode_reward": 12.15, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9528, "number_of_timesteps": 250691, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9538, "number_of_timesteps": 251035, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9548, "number_of_timesteps": 251421, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9558, "number_of_timesteps": 251981, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9568, "number_of_timesteps": 252737, "per_episode_reward": 12.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9578, "number_of_timesteps": 253478, "per_episode_reward": 12.25, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9589, "number_of_timesteps": 254100, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9599, "number_of_timesteps": 254833, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9609, "number_of_timesteps": 255611, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9619, "number_of_timesteps": 257109, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9629, "number_of_timesteps": 258978, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9639, "number_of_timesteps": 261226, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9650, "number_of_timesteps": 264046, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9660, "number_of_timesteps": 266393, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9670, "number_of_timesteps": 268167, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9680, "number_of_timesteps": 269944, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9690, "number_of_timesteps": 271502, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9700, "number_of_timesteps": 274918, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9710, "number_of_timesteps": 277026, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9721, "number_of_timesteps": 279754, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9731, "number_of_timesteps": 282568, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9741, "number_of_timesteps": 284767, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9751, "number_of_timesteps": 288455, "per_episode_reward": 12.3, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9761, "number_of_timesteps": 291516, "per_episode_reward": 12.35, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 9771, "number_of_timesteps": 295823, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9781, "number_of_timesteps": 299902, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9791, "number_of_timesteps": 303773, "per_episode_reward": 12.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9801, "number_of_timesteps": 308323, "per_episode_reward": 12.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9811, "number_of_timesteps": 312840, "per_episode_reward": 12.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9821, "number_of_timesteps": 317424, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9831, "number_of_timesteps": 321878, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9841, "number_of_timesteps": 326610, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9851, "number_of_timesteps": 330992, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9861, "number_of_timesteps": 335388, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9871, "number_of_timesteps": 340008, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9881, "number_of_timesteps": 344710, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9891, "number_of_timesteps": 349435, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9901, "number_of_timesteps": 353746, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 9911, "number_of_timesteps": 358094, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9921, "number_of_timesteps": 363094, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9931, "number_of_timesteps": 366779, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9941, "number_of_timesteps": 371420, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9951, "number_of_timesteps": 375430, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9961, "number_of_timesteps": 380086, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9971, "number_of_timesteps": 384588, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9981, "number_of_timesteps": 389388, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 9991, "number_of_timesteps": 394278, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10001, "number_of_timesteps": 399158, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10011, "number_of_timesteps": 403971, "per_episode_reward": 12.5, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10021, "number_of_timesteps": 408421, "per_episode_reward": 12.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10031, "number_of_timesteps": 412750, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10041, "number_of_timesteps": 417580, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10051, "number_of_timesteps": 422036, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10061, "number_of_timesteps": 427036, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10071, "number_of_timesteps": 431788, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10081, "number_of_timesteps": 436788, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10091, "number_of_timesteps": 441788, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10101, "number_of_timesteps": 446788, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10111, "number_of_timesteps": 451351, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 10121, "number_of_timesteps": 456323, "per_episode_reward": 12.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10131, "number_of_timesteps": 461323, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10141, "number_of_timesteps": 465821, "per_episode_reward": 12.65, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10151, "number_of_timesteps": 470703, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10161, "number_of_timesteps": 475337, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10171, "number_of_timesteps": 479702, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10181, "number_of_timesteps": 484425, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10191, "number_of_timesteps": 489425, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10201, "number_of_timesteps": 494425, "per_episode_reward": 12.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10211, "number_of_timesteps": 499283, "per_episode_reward": 12.75, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10221, "number_of_timesteps": 504283, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10231, "number_of_timesteps": 509283, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10241, "number_of_timesteps": 513837, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10251, "number_of_timesteps": 518837, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10261, "number_of_timesteps": 523446, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10271, "number_of_timesteps": 528435, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10282, "number_of_timesteps": 533478, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10292, "number_of_timesteps": 538478, "per_episode_reward": 12.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10302, "number_of_timesteps": 542669, "per_episode_reward": 12.85, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10312, "number_of_timesteps": 547352, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10322, "number_of_timesteps": 552131, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10332, "number_of_timesteps": 556970, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10342, "number_of_timesteps": 561805, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10352, "number_of_timesteps": 566489, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10362, "number_of_timesteps": 571489, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10372, "number_of_timesteps": 576350, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10382, "number_of_timesteps": 581031, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10392, "number_of_timesteps": 585723, "per_episode_reward": 12.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10402, "number_of_timesteps": 590723, "per_episode_reward": 12.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 10412, "number_of_timesteps": 595074, "per_episode_reward": 13.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10422, "number_of_timesteps": 600074, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10432, "number_of_timesteps": 604728, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10442, "number_of_timesteps": 609728, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10452, "number_of_timesteps": 614535, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10462, "number_of_timesteps": 619424, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10472, "number_of_timesteps": 624057, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10482, "number_of_timesteps": 629057, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10492, "number_of_timesteps": 634057, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 10502, "number_of_timesteps": 638631, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 10512, "number_of_timesteps": 643631, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10522, "number_of_timesteps": 648426, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10532, "number_of_timesteps": 653426, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10542, "number_of_timesteps": 658392, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10552, "number_of_timesteps": 663392, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10562, "number_of_timesteps": 668392, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10572, "number_of_timesteps": 673392, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10582, "number_of_timesteps": 678392, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10592, "number_of_timesteps": 683392, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10602, "number_of_timesteps": 688392, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10612, "number_of_timesteps": 693392, "per_episode_reward": 13.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10622, "number_of_timesteps": 698100, "per_episode_reward": 13.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10632, "number_of_timesteps": 702889, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10642, "number_of_timesteps": 707889, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10652, "number_of_timesteps": 712889, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10662, "number_of_timesteps": 717889, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10672, "number_of_timesteps": 722889, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10682, "number_of_timesteps": 727889, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10692, "number_of_timesteps": 732657, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10702, "number_of_timesteps": 737657, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10712, "number_of_timesteps": 742363, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 10722, "number_of_timesteps": 747128, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10732, "number_of_timesteps": 751845, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10742, "number_of_timesteps": 756845, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10752, "number_of_timesteps": 761845, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10762, "number_of_timesteps": 766051, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10772, "number_of_timesteps": 771051, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10782, "number_of_timesteps": 776051, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10792, "number_of_timesteps": 780977, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10802, "number_of_timesteps": 785912, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10812, "number_of_timesteps": 790626, "per_episode_reward": 13.2, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 10822, "number_of_timesteps": 795565, "per_episode_reward": 13.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10832, "number_of_timesteps": 800565, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10842, "number_of_timesteps": 805565, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10852, "number_of_timesteps": 810354, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10862, "number_of_timesteps": 815354, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10872, "number_of_timesteps": 820354, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10882, "number_of_timesteps": 825354, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10892, "number_of_timesteps": 830354, "per_episode_reward": 13.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10902, "number_of_timesteps": 835134, "per_episode_reward": 13.35, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10912, "number_of_timesteps": 840022, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10922, "number_of_timesteps": 844738, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10932, "number_of_timesteps": 849738, "per_episode_reward": 13.4, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10942, "number_of_timesteps": 854738, "per_episode_reward": 13.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10952, "number_of_timesteps": 859738, "per_episode_reward": 13.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10962, "number_of_timesteps": 864738, "per_episode_reward": 13.55, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10972, "number_of_timesteps": 869738, "per_episode_reward": 13.6, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10982, "number_of_timesteps": 874618, "per_episode_reward": 13.65, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 10992, "number_of_timesteps": 879618, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11002, "number_of_timesteps": 884198, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11012, "number_of_timesteps": 888925, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11022, "number_of_timesteps": 893925, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11032, "number_of_timesteps": 898832, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11042, "number_of_timesteps": 903832, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11052, "number_of_timesteps": 908807, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11062, "number_of_timesteps": 913807, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11072, "number_of_timesteps": 918807, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 11082, "number_of_timesteps": 923807, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11092, "number_of_timesteps": 928807, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11102, "number_of_timesteps": 933786, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11112, "number_of_timesteps": 938738, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11122, "number_of_timesteps": 943738, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11132, "number_of_timesteps": 948544, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11142, "number_of_timesteps": 953404, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11152, "number_of_timesteps": 958404, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11162, "number_of_timesteps": 963404, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11172, "number_of_timesteps": 968019, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11182, "number_of_timesteps": 973019, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11192, "number_of_timesteps": 978001, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11202, "number_of_timesteps": 983001, "per_episode_reward": 13.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11212, "number_of_timesteps": 988001, "per_episode_reward": 13.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11222, "number_of_timesteps": 993001, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11232, "number_of_timesteps": 997914, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11242, "number_of_timesteps": 1002914, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11252, "number_of_timesteps": 1007914, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11262, "number_of_timesteps": 1012914, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11272, "number_of_timesteps": 1017914, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11282, "number_of_timesteps": 1022914, "per_episode_reward": 13.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11292, "number_of_timesteps": 1027914, "per_episode_reward": 13.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11302, "number_of_timesteps": 1032914, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11312, "number_of_timesteps": 1037914, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11322, "number_of_timesteps": 1042914, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11332, "number_of_timesteps": 1047914, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11342, "number_of_timesteps": 1052899, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11352, "number_of_timesteps": 1057816, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11362, "number_of_timesteps": 1062816, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11372, "number_of_timesteps": 1067816, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11382, "number_of_timesteps": 1072816, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11392, "number_of_timesteps": 1077508, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11402, "number_of_timesteps": 1082508, "per_episode_reward": 13.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11412, "number_of_timesteps": 1087508, "per_episode_reward": 13.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 11422, "number_of_timesteps": 1092508, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11432, "number_of_timesteps": 1097508, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11442, "number_of_timesteps": 1102508, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11452, "number_of_timesteps": 1107508, "per_episode_reward": 14.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11462, "number_of_timesteps": 1112508, "per_episode_reward": 14.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11472, "number_of_timesteps": 1117508, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11482, "number_of_timesteps": 1122508, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11492, "number_of_timesteps": 1127437, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11502, "number_of_timesteps": 1132175, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11512, "number_of_timesteps": 1137175, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11522, "number_of_timesteps": 1142175, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11532, "number_of_timesteps": 1147175, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11542, "number_of_timesteps": 1152175, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11552, "number_of_timesteps": 1156777, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 11562, "number_of_timesteps": 1161777, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11572, "number_of_timesteps": 1166777, "per_episode_reward": 14.1, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11582, "number_of_timesteps": 1171777, "per_episode_reward": 14.15, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11592, "number_of_timesteps": 1176777, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11602, "number_of_timesteps": 1181777, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11612, "number_of_timesteps": 1186777, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11622, "number_of_timesteps": 1191777, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11632, "number_of_timesteps": 1196777, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11642, "number_of_timesteps": 1201777, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11652, "number_of_timesteps": 1206460, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11662, "number_of_timesteps": 1211460, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11672, "number_of_timesteps": 1216460, "per_episode_reward": 14.2, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 11682, "number_of_timesteps": 1221460, "per_episode_reward": 14.25, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11692, "number_of_timesteps": 1226460, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11702, "number_of_timesteps": 1231460, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11712, "number_of_timesteps": 1236460, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11722, "number_of_timesteps": 1241460, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11732, "number_of_timesteps": 1246460, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11742, "number_of_timesteps": 1251460, "per_episode_reward": 14.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11752, "number_of_timesteps": 1256460, "per_episode_reward": 14.35, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 11762, "number_of_timesteps": 1261225, "per_episode_reward": 14.45, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11772, "number_of_timesteps": 1266225, "per_episode_reward": 14.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11782, "number_of_timesteps": 1270798, "per_episode_reward": 14.6, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11792, "number_of_timesteps": 1275798, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11802, "number_of_timesteps": 1280798, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11812, "number_of_timesteps": 1285461, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11822, "number_of_timesteps": 1290050, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11832, "number_of_timesteps": 1295050, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11842, "number_of_timesteps": 1300050, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11852, "number_of_timesteps": 1305050, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11862, "number_of_timesteps": 1310050, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11872, "number_of_timesteps": 1315050, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 11882, "number_of_timesteps": 1320050, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11892, "number_of_timesteps": 1325050, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11902, "number_of_timesteps": 1330050, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11912, "number_of_timesteps": 1335050, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11922, "number_of_timesteps": 1340050, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11932, "number_of_timesteps": 1344948, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11942, "number_of_timesteps": 1349948, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11952, "number_of_timesteps": 1354948, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11962, "number_of_timesteps": 1359948, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11972, "number_of_timesteps": 1364948, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11982, "number_of_timesteps": 1369503, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 11992, "number_of_timesteps": 1374503, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12002, "number_of_timesteps": 1379443, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12012, "number_of_timesteps": 1384443, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12022, "number_of_timesteps": 1389168, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12032, "number_of_timesteps": 1394168, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12042, "number_of_timesteps": 1399168, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12052, "number_of_timesteps": 1404168, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12062, "number_of_timesteps": 1409168, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12072, "number_of_timesteps": 1414168, "per_episode_reward": 14.7, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12082, "number_of_timesteps": 1419168, "per_episode_reward": 14.75, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12092, "number_of_timesteps": 1424000, "per_episode_reward": 14.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12102, "number_of_timesteps": 1429000, "per_episode_reward": 14.85, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12112, "number_of_timesteps": 1433914, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12122, "number_of_timesteps": 1438914, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12132, "number_of_timesteps": 1443914, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12142, "number_of_timesteps": 1448914, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12152, "number_of_timesteps": 1453914, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12162, "number_of_timesteps": 1458914, "per_episode_reward": 14.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12172, "number_of_timesteps": 1463914, "per_episode_reward": 14.95, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12182, "number_of_timesteps": 1468914, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12192, "number_of_timesteps": 1473914, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12202, "number_of_timesteps": 1478752, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12212, "number_of_timesteps": 1483752, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12222, "number_of_timesteps": 1488752, "per_episode_reward": 15.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12232, "number_of_timesteps": 1493752, "per_episode_reward": 15.15, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12242, "number_of_timesteps": 1498752, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12252, "number_of_timesteps": 1503752, "per_episode_reward": 15.2, "episode_reward_trend_value": 0.0033333333333333214, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12262, "number_of_timesteps": 1508752, "per_episode_reward": 15.25, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12272, "number_of_timesteps": 1513752, "per_episode_reward": 15.35, "episode_reward_trend_value": 0.003888888888888885, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12282, "number_of_timesteps": 1518752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12292, "number_of_timesteps": 1523752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12302, "number_of_timesteps": 1528752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12312, "number_of_timesteps": 1533752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.004444444444444448, "biggest_recent_change": 0.15000000000000036},
{"total_number_of_episodes": 12322, "number_of_timesteps": 1538752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12332, "number_of_timesteps": 1543752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12342, "number_of_timesteps": 1548752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12352, "number_of_timesteps": 1553752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12362, "number_of_timesteps": 1558752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12372, "number_of_timesteps": 1563752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12382, "number_of_timesteps": 1568752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12392, "number_of_timesteps": 1573752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12402, "number_of_timesteps": 1578752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12412, "number_of_timesteps": 1583752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12422, "number_of_timesteps": 1588752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12432, "number_of_timesteps": 1593752, "per_episode_reward": 15.4, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12442, "number_of_timesteps": 1598752, "per_episode_reward": 15.45, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 12452, "number_of_timesteps": 1603752, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12462, "number_of_timesteps": 1608752, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12472, "number_of_timesteps": 1613752, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12482, "number_of_timesteps": 1618752, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12492, "number_of_timesteps": 1623752, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12502, "number_of_timesteps": 1628505, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12512, "number_of_timesteps": 1633505, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12522, "number_of_timesteps": 1638505, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12532, "number_of_timesteps": 1643505, "per_episode_reward": 15.5, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12542, "number_of_timesteps": 1648505, "per_episode_reward": 15.55, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12552, "number_of_timesteps": 1653505, "per_episode_reward": 15.65, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12562, "number_of_timesteps": 1658505, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12572, "number_of_timesteps": 1663383, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12582, "number_of_timesteps": 1668383, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12592, "number_of_timesteps": 1673126, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12602, "number_of_timesteps": 1678126, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12612, "number_of_timesteps": 1683126, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12622, "number_of_timesteps": 1688126, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12632, "number_of_timesteps": 1693126, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12642, "number_of_timesteps": 1698126, "per_episode_reward": 15.7, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 12652, "number_of_timesteps": 1703024, "per_episode_reward": 15.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 12662, "number_of_timesteps": 1708024, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 12672, "number_of_timesteps": 1713024, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 12682, "number_of_timesteps": 1718024, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 12692, "number_of_timesteps": 1723024, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 12702, "number_of_timesteps": 1728024, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 12712, "number_of_timesteps": 1732696, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 12722, "number_of_timesteps": 1737696, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 12732, "number_of_timesteps": 1742696, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 12742, "number_of_timesteps": 1747696, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.09999999999999964},
{"total_number_of_episodes": 12752, "number_of_timesteps": 1752696, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12762, "number_of_timesteps": 1757230, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12772, "number_of_timesteps": 1761645, "per_episode_reward": 15.9, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 12782, "number_of_timesteps": 1766645, "per_episode_reward": 15.95, "episode_reward_trend_value": 0.0005555555555555437, "biggest_recent_change": 0.049999999999998934},
{"total_number_of_episodes": 12792, "number_of_timesteps": 1771645, "per_episode_reward": 16.0, "episode_reward_trend_value": 0.0011111111111111072, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12802, "number_of_timesteps": 1776645, "per_episode_reward": 16.05, "episode_reward_trend_value": 0.0016666666666666705, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12812, "number_of_timesteps": 1781645, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12822, "number_of_timesteps": 1786645, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12832, "number_of_timesteps": 1791645, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12842, "number_of_timesteps": 1796645, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12852, "number_of_timesteps": 1801645, "per_episode_reward": 16.1, "episode_reward_trend_value": 0.002222222222222234, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12862, "number_of_timesteps": 1806322, "per_episode_reward": 16.15, "episode_reward_trend_value": 0.0027777777777777584, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12872, "number_of_timesteps": 1811322, "per_episode_reward": 16.25, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 12882, "number_of_timesteps": 1816231, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 12892, "number_of_timesteps": 1821231, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 12902, "number_of_timesteps": 1826231, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 12912, "number_of_timesteps": 1831231, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 12922, "number_of_timesteps": 1836231, "per_episode_reward": 16.4, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 12932, "number_of_timesteps": 1841231, "per_episode_reward": 16.45, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 12942, "number_of_timesteps": 1846231, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 12952, "number_of_timesteps": 1851231, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 12962, "number_of_timesteps": 1856231, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 12972, "number_of_timesteps": 1861013, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12982, "number_of_timesteps": 1866013, "per_episode_reward": 16.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 12992, "number_of_timesteps": 1871013, "per_episode_reward": 16.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13002, "number_of_timesteps": 1876013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13012, "number_of_timesteps": 1881013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13022, "number_of_timesteps": 1886013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13032, "number_of_timesteps": 1891013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13042, "number_of_timesteps": 1896013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13052, "number_of_timesteps": 1901013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13062, "number_of_timesteps": 1906013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13072, "number_of_timesteps": 1911013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13082, "number_of_timesteps": 1916013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13092, "number_of_timesteps": 1921013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13102, "number_of_timesteps": 1926013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13112, "number_of_timesteps": 1931013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13122, "number_of_timesteps": 1936013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13132, "number_of_timesteps": 1941013, "per_episode_reward": 16.6, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 13142, "number_of_timesteps": 1946013, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13152, "number_of_timesteps": 1951013, "per_episode_reward": 16.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13162, "number_of_timesteps": 1956013, "per_episode_reward": 16.75, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13172, "number_of_timesteps": 1960882, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13182, "number_of_timesteps": 1965882, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13192, "number_of_timesteps": 1970882, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13202, "number_of_timesteps": 1975882, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13212, "number_of_timesteps": 1980882, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13222, "number_of_timesteps": 1985882, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13232, "number_of_timesteps": 1990882, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13242, "number_of_timesteps": 1995882, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13252, "number_of_timesteps": 2000521, "per_episode_reward": 16.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13262, "number_of_timesteps": 2005521, "per_episode_reward": 16.85, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13272, "number_of_timesteps": 2010521, "per_episode_reward": 16.95, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13282, "number_of_timesteps": 2015521, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13292, "number_of_timesteps": 2020521, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13302, "number_of_timesteps": 2025521, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13312, "number_of_timesteps": 2030521, "per_episode_reward": 17.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13322, "number_of_timesteps": 2035521, "per_episode_reward": 17.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13332, "number_of_timesteps": 2040521, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13342, "number_of_timesteps": 2045521, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13352, "number_of_timesteps": 2050521, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13362, "number_of_timesteps": 2055521, "per_episode_reward": 17.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13372, "number_of_timesteps": 2060521, "per_episode_reward": 17.15, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13382, "number_of_timesteps": 2065521, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13392, "number_of_timesteps": 2070521, "per_episode_reward": 17.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13402, "number_of_timesteps": 2075521, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13412, "number_of_timesteps": 2080521, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13422, "number_of_timesteps": 2085521, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13432, "number_of_timesteps": 2090521, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13442, "number_of_timesteps": 2095521, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13452, "number_of_timesteps": 2100521, "per_episode_reward": 17.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13462, "number_of_timesteps": 2105521, "per_episode_reward": 17.35, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13472, "number_of_timesteps": 2110521, "per_episode_reward": 17.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13482, "number_of_timesteps": 2115521, "per_episode_reward": 17.45, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13492, "number_of_timesteps": 2120521, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13502, "number_of_timesteps": 2125521, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13512, "number_of_timesteps": 2130521, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13522, "number_of_timesteps": 2135521, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13532, "number_of_timesteps": 2140521, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13542, "number_of_timesteps": 2145521, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13552, "number_of_timesteps": 2150521, "per_episode_reward": 17.5, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13562, "number_of_timesteps": 2155521, "per_episode_reward": 17.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13572, "number_of_timesteps": 2160521, "per_episode_reward": 17.6, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13582, "number_of_timesteps": 2165521, "per_episode_reward": 17.65, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13592, "number_of_timesteps": 2170521, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13602, "number_of_timesteps": 2175521, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13612, "number_of_timesteps": 2180521, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13622, "number_of_timesteps": 2185521, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13632, "number_of_timesteps": 2190513, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13642, "number_of_timesteps": 2195513, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13652, "number_of_timesteps": 2200513, "per_episode_reward": 17.7, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13662, "number_of_timesteps": 2205513, "per_episode_reward": 17.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13672, "number_of_timesteps": 2210513, "per_episode_reward": 17.9, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13682, "number_of_timesteps": 2215478, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13692, "number_of_timesteps": 2220478, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13702, "number_of_timesteps": 2225478, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13712, "number_of_timesteps": 2230478, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13722, "number_of_timesteps": 2235478, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13732, "number_of_timesteps": 2240478, "per_episode_reward": 18.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13742, "number_of_timesteps": 2245478, "per_episode_reward": 18.05, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13752, "number_of_timesteps": 2250478, "per_episode_reward": 18.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13762, "number_of_timesteps": 2255188, "per_episode_reward": 18.15, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13772, "number_of_timesteps": 2260188, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13782, "number_of_timesteps": 2265188, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13792, "number_of_timesteps": 2270188, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13802, "number_of_timesteps": 2275188, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13812, "number_of_timesteps": 2280188, "per_episode_reward": 18.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13822, "number_of_timesteps": 2285188, "per_episode_reward": 18.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13832, "number_of_timesteps": 2290188, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13842, "number_of_timesteps": 2295188, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13852, "number_of_timesteps": 2300188, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13862, "number_of_timesteps": 2305188, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13872, "number_of_timesteps": 2310188, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13882, "number_of_timesteps": 2315188, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13892, "number_of_timesteps": 2320188, "per_episode_reward": 18.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 13902, "number_of_timesteps": 2325188, "per_episode_reward": 18.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 13912, "number_of_timesteps": 2330188, "per_episode_reward": 18.5, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13922, "number_of_timesteps": 2335188, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13932, "number_of_timesteps": 2340188, "per_episode_reward": 18.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13942, "number_of_timesteps": 2345188, "per_episode_reward": 18.65, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13952, "number_of_timesteps": 2350188, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13962, "number_of_timesteps": 2355188, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13972, "number_of_timesteps": 2360188, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13982, "number_of_timesteps": 2365188, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 13992, "number_of_timesteps": 2370188, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14002, "number_of_timesteps": 2375188, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14012, "number_of_timesteps": 2380188, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14022, "number_of_timesteps": 2385188, "per_episode_reward": 18.7, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14032, "number_of_timesteps": 2390188, "per_episode_reward": 18.75, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14042, "number_of_timesteps": 2395188, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14052, "number_of_timesteps": 2400188, "per_episode_reward": 18.8, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14062, "number_of_timesteps": 2405188, "per_episode_reward": 18.85, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14072, "number_of_timesteps": 2410188, "per_episode_reward": 18.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14082, "number_of_timesteps": 2415188, "per_episode_reward": 18.95, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14092, "number_of_timesteps": 2420188, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14102, "number_of_timesteps": 2425188, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14112, "number_of_timesteps": 2430188, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14122, "number_of_timesteps": 2435188, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14132, "number_of_timesteps": 2440188, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14142, "number_of_timesteps": 2445188, "per_episode_reward": 19.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14152, "number_of_timesteps": 2450188, "per_episode_reward": 19.05, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14162, "number_of_timesteps": 2455188, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14172, "number_of_timesteps": 2460188, "per_episode_reward": 19.1, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14182, "number_of_timesteps": 2465188, "per_episode_reward": 19.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 14192, "number_of_timesteps": 2470188, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14202, "number_of_timesteps": 2475188, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14212, "number_of_timesteps": 2480188, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14222, "number_of_timesteps": 2485188, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14232, "number_of_timesteps": 2490188, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14242, "number_of_timesteps": 2495188, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14252, "number_of_timesteps": 2500188, "per_episode_reward": 19.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14262, "number_of_timesteps": 2505188, "per_episode_reward": 19.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14272, "number_of_timesteps": 2510188, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14282, "number_of_timesteps": 2515188, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14292, "number_of_timesteps": 2520188, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14302, "number_of_timesteps": 2525188, "per_episode_reward": 19.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14312, "number_of_timesteps": 2530188, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14322, "number_of_timesteps": 2535188, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14332, "number_of_timesteps": 2540188, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14342, "number_of_timesteps": 2545188, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14352, "number_of_timesteps": 2550188, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14362, "number_of_timesteps": 2555188, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14372, "number_of_timesteps": 2560188, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14382, "number_of_timesteps": 2565188, "per_episode_reward": 19.5, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14392, "number_of_timesteps": 2570188, "per_episode_reward": 19.55, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14402, "number_of_timesteps": 2575188, "per_episode_reward": 19.65, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 14412, "number_of_timesteps": 2580188, "per_episode_reward": 19.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 14422, "number_of_timesteps": 2585188, "per_episode_reward": 19.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 14432, "number_of_timesteps": 2590188, "per_episode_reward": 19.7, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 14442, "number_of_timesteps": 2595188, "per_episode_reward": 19.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 14452, "number_of_timesteps": 2600188, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 14462, "number_of_timesteps": 2605188, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 14472, "number_of_timesteps": 2610188, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 14482, "number_of_timesteps": 2615188, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 14492, "number_of_timesteps": 2620188, "per_episode_reward": 20.0, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 14502, "number_of_timesteps": 2625188, "per_episode_reward": 20.1, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 14512, "number_of_timesteps": 2630188, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 14522, "number_of_timesteps": 2635188, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.1999999999999993},
{"total_number_of_episodes": 14532, "number_of_timesteps": 2640188, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14542, "number_of_timesteps": 2645188, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14552, "number_of_timesteps": 2650188, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14562, "number_of_timesteps": 2655188, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14572, "number_of_timesteps": 2660188, "per_episode_reward": 20.2, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14582, "number_of_timesteps": 2665188, "per_episode_reward": 20.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14592, "number_of_timesteps": 2670188, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 14602, "number_of_timesteps": 2675188, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14612, "number_of_timesteps": 2680188, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14622, "number_of_timesteps": 2685188, "per_episode_reward": 20.3, "episode_reward_trend_value": 0.001111111111111127, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14632, "number_of_timesteps": 2690188, "per_episode_reward": 20.35, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14642, "number_of_timesteps": 2695188, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14652, "number_of_timesteps": 2700188, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14662, "number_of_timesteps": 2705188, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14672, "number_of_timesteps": 2710188, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14682, "number_of_timesteps": 2715188, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14692, "number_of_timesteps": 2720188, "per_episode_reward": 20.4, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14702, "number_of_timesteps": 2725188, "per_episode_reward": 20.45, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14712, "number_of_timesteps": 2730188, "per_episode_reward": 20.55, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14722, "number_of_timesteps": 2735188, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14732, "number_of_timesteps": 2740188, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14742, "number_of_timesteps": 2745188, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14752, "number_of_timesteps": 2750188, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14762, "number_of_timesteps": 2755188, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14772, "number_of_timesteps": 2760188, "per_episode_reward": 20.6, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14782, "number_of_timesteps": 2765188, "per_episode_reward": 20.65, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14792, "number_of_timesteps": 2770188, "per_episode_reward": 20.7, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14802, "number_of_timesteps": 2775188, "per_episode_reward": 20.75, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14812, "number_of_timesteps": 2780188, "per_episode_reward": 20.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14822, "number_of_timesteps": 2785188, "per_episode_reward": 20.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14832, "number_of_timesteps": 2790188, "per_episode_reward": 20.9, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 14842, "number_of_timesteps": 2795188, "per_episode_reward": 20.9, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 14852, "number_of_timesteps": 2800188, "per_episode_reward": 20.9, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 14862, "number_of_timesteps": 2805188, "per_episode_reward": 20.95, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.09999999999999787},
{"total_number_of_episodes": 14872, "number_of_timesteps": 2810188, "per_episode_reward": 21.05, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14882, "number_of_timesteps": 2815188, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14892, "number_of_timesteps": 2820188, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14902, "number_of_timesteps": 2825188, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14912, "number_of_timesteps": 2830188, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14922, "number_of_timesteps": 2835188, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14932, "number_of_timesteps": 2840188, "per_episode_reward": 21.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14942, "number_of_timesteps": 2845188, "per_episode_reward": 21.15, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14952, "number_of_timesteps": 2850188, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 14962, "number_of_timesteps": 2855188, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14972, "number_of_timesteps": 2860188, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14982, "number_of_timesteps": 2865188, "per_episode_reward": 21.2, "episode_reward_trend_value": 0.0011111111111110875, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 14992, "number_of_timesteps": 2870188, "per_episode_reward": 21.25, "episode_reward_trend_value": 0.001666666666666651, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15002, "number_of_timesteps": 2875188, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15012, "number_of_timesteps": 2880188, "per_episode_reward": 21.3, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15022, "number_of_timesteps": 2885188, "per_episode_reward": 21.35, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15032, "number_of_timesteps": 2890188, "per_episode_reward": 21.4, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15042, "number_of_timesteps": 2895188, "per_episode_reward": 21.55, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 15052, "number_of_timesteps": 2900188, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 15062, "number_of_timesteps": 2905188, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 15072, "number_of_timesteps": 2910188, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 15082, "number_of_timesteps": 2915188, "per_episode_reward": 21.7, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 15092, "number_of_timesteps": 2920188, "per_episode_reward": 21.8, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 15102, "number_of_timesteps": 2925188, "per_episode_reward": 21.85, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 15112, "number_of_timesteps": 2930188, "per_episode_reward": 21.9, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 15122, "number_of_timesteps": 2935188, "per_episode_reward": 21.9, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.15000000000000213},
{"total_number_of_episodes": 15132, "number_of_timesteps": 2940188, "per_episode_reward": 21.9, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15142, "number_of_timesteps": 2945188, "per_episode_reward": 21.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15152, "number_of_timesteps": 2950188, "per_episode_reward": 21.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15162, "number_of_timesteps": 2955188, "per_episode_reward": 21.9, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15172, "number_of_timesteps": 2960188, "per_episode_reward": 21.95, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15182, "number_of_timesteps": 2965188, "per_episode_reward": 22.05, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15192, "number_of_timesteps": 2970188, "per_episode_reward": 22.1, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15202, "number_of_timesteps": 2975188, "per_episode_reward": 22.15, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15212, "number_of_timesteps": 2980188, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15222, "number_of_timesteps": 2985188, "per_episode_reward": 22.2, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15232, "number_of_timesteps": 2990188, "per_episode_reward": 22.25, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15242, "number_of_timesteps": 2995188, "per_episode_reward": 22.35, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15252, "number_of_timesteps": 3000188, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15262, "number_of_timesteps": 3005188, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15272, "number_of_timesteps": 3010188, "per_episode_reward": 22.4, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15282, "number_of_timesteps": 3015188, "per_episode_reward": 22.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15292, "number_of_timesteps": 3020188, "per_episode_reward": 22.6, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15302, "number_of_timesteps": 3025188, "per_episode_reward": 22.6, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15312, "number_of_timesteps": 3030188, "per_episode_reward": 22.65, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15322, "number_of_timesteps": 3035188, "per_episode_reward": 22.7, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15332, "number_of_timesteps": 3040188, "per_episode_reward": 22.7, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15342, "number_of_timesteps": 3044950, "per_episode_reward": 22.7, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15352, "number_of_timesteps": 3049950, "per_episode_reward": 22.8, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15362, "number_of_timesteps": 3054950, "per_episode_reward": 22.85, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15372, "number_of_timesteps": 3059950, "per_episode_reward": 22.9, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15382, "number_of_timesteps": 3064950, "per_episode_reward": 22.95, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15392, "number_of_timesteps": 3069950, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15402, "number_of_timesteps": 3074950, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15412, "number_of_timesteps": 3079950, "per_episode_reward": 23.0, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15422, "number_of_timesteps": 3084950, "per_episode_reward": 23.05, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15432, "number_of_timesteps": 3089950, "per_episode_reward": 23.1, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15442, "number_of_timesteps": 3094950, "per_episode_reward": 23.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15452, "number_of_timesteps": 3099950, "per_episode_reward": 23.1, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15462, "number_of_timesteps": 3104950, "per_episode_reward": 23.1, "episode_reward_trend_value": 0.002222222222222254, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15472, "number_of_timesteps": 3109950, "per_episode_reward": 23.15, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15482, "number_of_timesteps": 3114950, "per_episode_reward": 23.25, "episode_reward_trend_value": 0.0027777777777777775, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15492, "number_of_timesteps": 3119950, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15502, "number_of_timesteps": 3124950, "per_episode_reward": 23.3, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15512, "number_of_timesteps": 3129950, "per_episode_reward": 23.35, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15522, "number_of_timesteps": 3134950, "per_episode_reward": 23.5, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15532, "number_of_timesteps": 3139950, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15542, "number_of_timesteps": 3144950, "per_episode_reward": 23.6, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15552, "number_of_timesteps": 3149950, "per_episode_reward": 23.65, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15562, "number_of_timesteps": 3154950, "per_episode_reward": 23.75, "episode_reward_trend_value": 0.006666666666666682, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15572, "number_of_timesteps": 3159950, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15582, "number_of_timesteps": 3164950, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15592, "number_of_timesteps": 3169950, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15602, "number_of_timesteps": 3174747, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15612, "number_of_timesteps": 3179747, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15622, "number_of_timesteps": 3184747, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15632, "number_of_timesteps": 3189747, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15642, "number_of_timesteps": 3194747, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0016666666666666902, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15652, "number_of_timesteps": 3199747, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15662, "number_of_timesteps": 3204747, "per_episode_reward": 23.8, "episode_reward_trend_value": 0.0, "biggest_recent_change": 0.0},
{"total_number_of_episodes": 15672, "number_of_timesteps": 3209567, "per_episode_reward": 23.85, "episode_reward_trend_value": 0.0005555555555555635, "biggest_recent_change": 0.05000000000000071},
{"total_number_of_episodes": 15682, "number_of_timesteps": 3214567, "per_episode_reward": 24.0, "episode_reward_trend_value": 0.0022222222222222144, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15692, "number_of_timesteps": 3219567, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15702, "number_of_timesteps": 3224567, "per_episode_reward": 24.1, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15712, "number_of_timesteps": 3229567, "per_episode_reward": 24.15, "episode_reward_trend_value": 0.0038888888888888654, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15722, "number_of_timesteps": 3234567, "per_episode_reward": 24.25, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15732, "number_of_timesteps": 3239567, "per_episode_reward": 24.3, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15742, "number_of_timesteps": 3244567, "per_episode_reward": 24.3, "episode_reward_trend_value": 0.005555555555555555, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15752, "number_of_timesteps": 3249567, "per_episode_reward": 24.35, "episode_reward_trend_value": 0.006111111111111119, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15762, "number_of_timesteps": 3254567, "per_episode_reward": 24.4, "episode_reward_trend_value": 0.006111111111111079, "biggest_recent_change": 0.14999999999999858},
{"total_number_of_episodes": 15772, "number_of_timesteps": 3259567, "per_episode_reward": 24.4, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15782, "number_of_timesteps": 3264567, "per_episode_reward": 24.4, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15792, "number_of_timesteps": 3269567, "per_episode_reward": 24.4, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15802, "number_of_timesteps": 3274567, "per_episode_reward": 24.5, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15812, "number_of_timesteps": 3279567, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15822, "number_of_timesteps": 3284567, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15832, "number_of_timesteps": 3289567, "per_episode_reward": 24.6, "episode_reward_trend_value": 0.003333333333333341, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15842, "number_of_timesteps": 3294567, "per_episode_reward": 24.65, "episode_reward_trend_value": 0.003333333333333302, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15852, "number_of_timesteps": 3299567, "per_episode_reward": 24.75, "episode_reward_trend_value": 0.003888888888888905, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15862, "number_of_timesteps": 3304567, "per_episode_reward": 24.8, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15872, "number_of_timesteps": 3309567, "per_episode_reward": 24.8, "episode_reward_trend_value": 0.004444444444444468, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15882, "number_of_timesteps": 3314567, "per_episode_reward": 24.85, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15892, "number_of_timesteps": 3319567, "per_episode_reward": 24.95, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15902, "number_of_timesteps": 3324567, "per_episode_reward": 25.0, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15912, "number_of_timesteps": 3329567, "per_episode_reward": 25.0, "episode_reward_trend_value": 0.004444444444444429, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15922, "number_of_timesteps": 3334567, "per_episode_reward": 25.05, "episode_reward_trend_value": 0.004999999999999992, "biggest_recent_change": 0.10000000000000142},
{"total_number_of_episodes": 15932, "number_of_timesteps": 3339567, "per_episode_reward": 25.1, "episode_reward_trend_value": 0.005000000000000031, "biggest_recent_change": 0.10000000000000142},
